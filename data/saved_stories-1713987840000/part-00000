{"aid": "40144307", "title": "Consistent overhead byte stuffing for binary logs. (2021)", "url": "https://pvk.ca/Blog/2021/01/11/stuff-your-logs/", "domain": "pvk.ca", "votes": 1, "user": "fanf2", "posted_at": "2024-04-24 13:42:04", "comments": 0, "source_title": "Stuff your logs!", "source_text": "Stuff your logs! - Paul Khuong: some Lisp\n\n# Paul Khuong: some Lisp\n\n# Stuff your logs!\n\nJan 11th, 2021 | Comments\n\nOriginally cross-posted on the Backtrace.io engineering blog.\n\nNine months ago, we embarked on a format migration for the persistent (on-\ndisk) representation of variable-length strings like symbolicated call stacks\nin the Backtrace server. We chose a variant of consistent overhead byte\nstuffing (COBS), a self-synchronising code, for the metadata (variable-length\nas well). This choice let us improve our software\u2019s resilience to data\ncorruption in local files, and then parallelise data hydration, which improved\nstartup times by a factor of 10... without any hard migration from the old to\nthe current on-disk data format.\n\nIn this post, I will explain why I believe that the representation of first\nresort for binary logs (write-ahead, recovery, replay, or anything else that\nmay be consumed by a program) should be self-synchronising, backed by this\nmigration and by prior experience with COBS-style encoding. I will also\ndescribe the specific algorithm (available under the MIT license) we\nimplemented for our server software.\n\nThis encoding offers low space overhead for framing, fast encoding and faster\ndecoding, resilience to data corruption, and a restricted form of random\naccess. Maybe it makes sense to use it for your own data!\n\n## What is self-synchronisation, and why is it important?\n\nA code is self-synchronising when it\u2019s always possible to unambiguously detect\nwhere a valid code word (record) starts in a stream of symbols (bytes). That\u2019s\na stronger property than prefix codes like Huffman codes, which only detect\nwhen valid code words end. For example, the UTF-8 encoding is self-\nsynchronising, because initial bytes and continuation bytes differ in their\nhigh bits. That\u2019s why it\u2019s possible to decode multi-byte code points when\ntailing a UTF-8 stream.\n\nThe UTF-8 code was designed for small integers (Unicode code points), and can\ndouble the size of binary data. Other encodings are more appropriate for\narbitrary bytes; for example, consistent overhead byte stuffing (COBS), a\nself-synchronising code for byte streams, offers a worst-case space overhead\nof one byte plus a 0.4% space blow-up.\n\nSelf-synchronisation is important for binary logs because it lets us\nefficiently (with respect to both run time and space overhead) frame records\nin a simple and robust manner... and we want simplicity and robustness because\nlogs are most useful when something has gone wrong.\n\nOf course, the storage layer should detect and correct errors, but things will\nsometimes fall through, especially for on-premises software, where no one\nfully controls deployments. When that happens, graceful partial failure is\npreferable to, e.g., losing all the information in a file because one of its\npages went to the great bit bucket in the sky.\n\nOne easy solution is to spread the data out over multiple files or blobs.\nHowever, there\u2019s a trade-off between keeping data fragmentation and file\nmetadata overhead in check, and minimising the blast radius of minor\ncorruption. Our server must be able to run on isolated nodes, so we can\u2019t rely\non design options available to replicated systems... plus bugs tend to be\ncorrelated across replicas, so there is something to be said for defense in\ndepth, even with distributed storage.\n\nWhen each record is converted with a self-synchronising code like COBS before\npersisting to disk, we can decode all records that weren\u2019t directly impacted\nby corruption, exactly like decoding a stream of mostly valid UTF-8 bytes. Any\nform of corruption will only make us lose the records whose bytes were\ncorrupted, and, at most, the two records that immediately precede or follow\nthe corrupt byte range. This guarantee covers overwritten data (e.g., when a\nnetwork switch flips a bit, or a read syscall silently errors out with a zero-\nfilled page), as well as bytes removed or garbage inserted in the middle of\nlog files.\n\nThe coding doesn\u2019t store redundant information: replication or erasure coding\nis the storage layer\u2019s responsibility. It instead guarantees to always\nminimise the impact of corruption, and only lose records that were adjacent to\nor directly hit by corruption.\n\nA COBS encoding for log records achieves that by unambiguously separating\nrecords with a reserved byte (e.g., 0), and re-encoding each record to avoid\nthat separator byte. A reader can thus assume that potential records start and\nend at a log file\u2019s first and last bytes, and otherwise look for separator\nbytes to determine where to cut all potential records. These records may be\ninvalid: a separator byte could be introduced or removed by corruption, and\nthe contents of a correctly framed record may be corrupt. When that happens,\nreaders can simply scan for the next separator byte and try to validate that\nnew potential record. The decoder\u2019s state resets after each separator byte, so\nany corruption is \u201cforgotten\u201d as soon as the decoder finds valid a separator\nbyte.\n\nOn the write side, the encoding logic is simple (a couple dozen lines of C\ncode), and uses a predictable amount of space, as expected from an algorithm\nsuitable for microcontrollers.\n\nActually writing encoded data is also easy: on POSIX filesystems, we can make\nsure each record is delimited (e.g., prefixed with the delimiter byte), and\nissue a regular O_APPEND write(2). Vectored writes can even insert delimiters\nwithout copying in userspace. Realistically, our code is probably less stable\nthan operating system and the hardware it runs on, so we make sure our writes\nmake it to the kernel as soon as possible, and let fsyncs happen on a timer.\n\nWhen a write errors out, we can blindly (maybe once or twice) try again: the\nencoding is independent of the output file\u2019s state. When a write is cut short,\nwe can still issue the same^1 write call, without trying to \u201cfix\u201d the short\nwrite: the encoding and the read-side logic already protect against that kind\nof corruption.\n\nWhat if multiple threads or processes write to the same log file? When we open\nwith O_APPEND, the operating system can handle the rest. This doesn\u2019t make\ncontention disappear, but at least we\u2019re not adding a bottleneck in userspace\non top of what is necessary to append to the same file. Buffering is also\ntrivial: the encoding is independent of the state of the destination file, so\nwe can always concatenate buffered records and write the result with a single\nsyscall.\n\nThis simplicity also plays well with high-throughput I/O primitives like\nio_uring, and with blob stores that support appends: independent workers can\nconcurrently queue up blind append requests and retry on failure. There\u2019s no\nneed for application-level mutual exclusion or rollback.\n\n## Fun tricks with robust readers\n\nOur log encoding will recover from bad bytes, as long as readers can detect\nand reject invalid records as a whole; the processing logic should also handle\nduplicated valid records. These are table stakes for a reliable log consumer.\n\nIn our variable-length metadata use case, each record describes a symbolicated\ncall stack, and we recreate in-memory data structures by replaying an append-\nonly log of metadata records, one for each unique call stack. The hydration\nphase handles invalid records by ignoring (not recreating) any call stack with\ncorrupt metadata, but only those call stacks. That\u2019s definitely an improvement\nover the previous situation, where corruption in a size header would prevent\nus from decoding the remainder of the file, and thus make us forget about all\ncall stacks stored at file offsets after the corruption.\n\nOf course, losing data should be avoided, so we are careful to fsync regularly\nand recommend reasonable storage configurations. However, one can only make\ndata loss unlikely, not impossible (if only due to fat fingering), especially\nwhen cost is a factor. With the COBS encoding, we can recover gracefully and\nautomatically from any unfortunate data corruption event.\n\nWe can also turn this robustness into new capabilities.\n\nIt\u2019s often useful to process the tail of a log at a regular cadence. For\nexample, I once maintained a system that regularly tailed hourly logs to\nupdate approximate views. One could support that use case with length footers.\nCOBS framing lets us instead scan for a valid record from an arbitrary byte\nlocation, and read the rest of the data normally.\n\nWhen logs grow large enough, we want to process them in parallel. The standard\nsolution is to shard log streams, which unfortunately couples the\nparallelisation and storage strategies, and adds complexity to the write side.\n\nCOBS framing lets us parallelise readers independently of the writer. The\ndownside is that the read-side code and I/O patterns are now more complex,\nbut, all other things being equal, that\u2019s a trade-off I\u2019ll gladly accept,\nespecially given that our servers run on independent machines and store their\ndata in files, where reads are fine-grained and latency relatively low.\n\nA parallel COBS reader partitions a data file arbitrarily (e.g., in fixed size\nchunks) for independent workers. A worker will scan for the first valid record\nstarting inside its assigned chunk, and handle every record that starts in its\nchunk. Filtering on the start byte means that a worker may read past the\nlogical end of its chunk, when it fully decodes the last record that starts in\nthe chunk: that\u2019s how we unambiguously assign a worker to every record,\nincluding records that straddle chunk boundaries.\n\nRandom access even lets us implement a form of binary or interpolation search\non raw unindexed logs, when we know the records are (k-)sorted on the search\nkey! This lets us, e.g., access the metadata for a few call stacks without\nparsing the whole log.\n\nEventually, we might also want to truncate our logs.\n\nContemporary filesystems like XFS (and even Ext4) support large sparse files.\nFor example, sparse files can reach \\\\(2^{63} - 1\\\\) bytes on XFS with a\nminimal metadata-only footprint: the on-disk data for such sparse files is\nonly allocated when we issue actual writes. Nowadays, we can sparsify files\nafter the fact, and convert ranges of non-zero data into zero-filled \u201choles\u201d\nin order to release storage without messing with file offsets (or even\natomically collapse old data away).\n\nFilesystems can only execute these operations at coarse granularity, but\nthat\u2019s not an issue for our readers: they must merely remember to skip sparse\nholes, and the decoding loop will naturally handle any garbage partial record\nleft behind.\n\n## The original consistent overhead byte stuffing scheme\n\nCheshire and Baker\u2019s original byte stuffing scheme targets small machines and\nslow transports (amateur radio and phone lines). That\u2019s why it bounds the\namount of buffering needed to 254 bytes for writers and 9 bits of state for\nreaders, and attempts to minimise space overhead, beyond its worst-case bound\nof 0.4%.\n\nThe algorithm is also reasonable. The encoder buffers data until it encounters\na reserved 0 byte (a delimiter byte), or there are 254 bytes of buffered data.\nWhenever the encoder stops buffering, it outputs a block whose contents are\ndescribed by its first byte. If the writer stopped buffering because it found\na reserved byte, it emits one byte with buffer_size + 1 before writing and\nclearing the buffer. Otherwise, it outputs 255 (one more than the buffer\nsize), followed by the buffer\u2019s contents.\n\nOn the decoder side, we know that the first byte of each block describes its\nsize and decoded value (255 means 254 bytes of literal data, any other value\nis one more than the number of literal bytes to copy, followed by a reserved 0\nbyte). We denote the end of a record with an implicit delimiter: when we run\nout of data to decode, we should have just decoded an extra delimiter byte\nthat\u2019s not really part of the data.\n\nWith framing, an encoded record surrounded by delimiters thus looks like the\nfollowing\n\n    \n    \n    |0 |blen|(blen - 1) literal data bytes....|blen|literal data bytes ...|0 |\n\nThe delimiting \u201c0\u201d bytes are optional at the beginning and end of a file, and\neach blen size prefix is one byte with value in \\\\([1, 255]\\\\). A value\n\\\\(\\mathtt{blen} \\in [1, 254]\\\\) represents a block \\\\(\\mathtt{blen} - 1\\\\)\nliteral bytes, followed by an implicit 0 byte. If we instead have\n\\\\(\\mathtt{blen} = 255\\\\), we have a block of \\\\(254\\\\) bytes, without any\nimplicit byte. Readers only need to remember how many bytes remain until the\nend of the current block (eight bits for a counter), and whether they should\ninsert an implicit 0 byte before decoding the next block (one binary flag).\n\n## Backtrace\u2019s word stuffing variant\n\nWe have different goals for the software we write at Backtrace. For our\nlogging use case, we pass around fully constructed records, and we want to\nissue a single write syscall per record, with periodic fsync.^2 Buffering is\nbaked in, so there\u2019s no point in making sure we can work with a small write\nbuffer. We also don\u2019t care as much about the space overhead (the worst-case\nbound is already pretty good) as much as we do about encoding and decoding\nspeed.\n\nThese different design goals lead us to an updated hybrid word/byte stuffing\nscheme:\n\n  1. it uses a two-byte \u201creserved sequence,\u201d carefully chosen to appear infrequently in our data\n  2. the size limit for the first block is slightly smaller (252 bytes instead of 254)\n  3. ... but the limit for every subsequent block is much larger, 65008 bytes, for an asymptotic space overhead of 0.0031%.\n\nThis hybrid scheme improves encoding and decoding speed compared to COBS, and\neven marginally improves the asymptotic space overhead. At the low end, the\nworst-case overhead is only slightly worse than that of traditional COBS: we\nneed three additional bytes, including the framing separator, for records of\n252 bytes or fewer, and five bytes for records of 253-64260 bytes.\n\nIn the past, I\u2019ve seen \u201cword\u201d stuffing schemes aim to reduce the run-time\noverhead of COBS codecs by scaling up the COBS loops to work on two or four\nbytes at a time. However, a byte search is trivial to vectorise, and there is\nno guarantee that frameshift corruption will be aligned to word boundaries\n(for example, POSIX allows short writes of an arbitrary number of bytes).\n\n### Much ado about two bytes\n\nOur hybrid word-stuffing looks for a reserved two-byte delimiter sequence at\narbitrary byte offsets. We must still conceptually process bytes one at a\ntime, but delimiting with a pair of bytes instead of with a single byte makes\nit easier to craft a delimiter that\u2019s unlikely to appear in our data.\n\nCheshire and Baker do the opposite, and use a frequent byte (0) to eliminate\nthe space overhead in the common case. We care a lot more about encoding and\ndecoding speed, so an unlikely delimiter makes more sense for us. We picked\n0xfe 0xfd because that sequence doesn\u2019t appear in small integers (unsigned,\ntwo\u2019s complement, varint, single or double float) regardless of endianness,\nnor in valid UTF-8 strings.\n\nAny positive integer with 0xfe 0xfd (254 253) in its byte must be around\n\\\\(2^{16}\\\\) or more. If the integer is instead negative in little-endian\ntwo\u2019s complement, 0xfe 0xfd equals -514 as a little-endian int16_t, and -259\nin big endian (not as great, but not nothing). Of course, the sequence could\nappear in two adjacent uint8_ts, but otherwise, for 0xfe or 0xfd can only\nappear in most significant byte of large 32- or 64-bit integers (unlike 0xff,\nwhich could be sign extension for, e.g., -1).\n\nAny (U)LEB varint that includes 0xfe 0xfd must span at least 3 bytes (i.e., 15\nbits), since both these bytes have the most significant bit set to 1. Even a\nnegative SLEB has to be at least as negative as \\\\(- 2^{14} = -16384\\\\).\n\nFor floating point types, we can observe that 0xfe 0xfd in the significand\nwould represent an awful fraction in little or big endian, so can only happen\nfor the IEEE-754 representation of large integers (approximately \\\\(\\pm\n2^{15}\\\\)). If we instead assume that 0xfd or 0xfe appear in the sign and\nexponent fields, we find either very positive or very negative exponents (the\nexponent is biased, instead of complemented). A semi-exhaustive search\nconfirms that the smallest integer-valued single float that includes the\nsequence is 32511.0 in little endian and 130554.0 in big endian; among\ninteger-valued double floats, we find 122852.0 and 126928.0 respectively.\n\nFinally, the sequence isn\u2019t valid UTF-8 because both 0xfe and 0xfd have their\ntop bit set (indicating a multi-byte code point), but neither looks like a\ncontinuation byte: the two most significant bits are 0b11 in both cases, while\nUTF-8 continuations must have 0b10.\n\n### Encoding data to avoid the reserved sequence\n\nConsistent overhead byte stuffing rewrites reserved 0 bytes away by counting\nthe number of bytes from the beginning of a record until the next 0, and\nstoring that count in a block size header followed by the non-reserved bytes,\nthen resetting the counter, and doing the same thing for the remaining of the\nrecord. A complete record is stored as a sequence of encoded blocks, none of\nwhich include the reserved byte 0. Each block header spans exactly one byte,\nand must never itself be 0, so the byte count is capped at 254, and\nincremented by one (e.g., a header value of 1 represents a count of 0); when\nthe count in the header is equal to the maximum, the decoder knows that the\nencoder stopped short without finding a 0.\n\nWith our two-byte reserved sequence, we can encode the size of each block in\nradix 253 (0xfd); given a two-byte header for each block, sizes can go up to\n\\\\(253^2 - 1 = 64008\\\\). That\u2019s a reasonable granularity for memcpy. This\nradix conversion replaces the off-by-one weirdness in COBS: that part of the\noriginal algorithm merely encodes values from \\\\([0, 254]\\\\) into one byte\nwhile avoiding the reserved byte 0.\n\nA two-byte size prefix is a bit ridiculous for small records (ours tend to be\non the order of 30-50 bytes). We thus encode the first block specially, with a\nsingle byte in \\\\([0, 252]\\\\) for the size prefix. Since the reserved sequence\n0xfe 0xfd is unlikely to appear in our data, the encoding for short record\noften boils down to adding a uint8_t length prefix.\n\nA framed encoded record now looks like\n\n    \n    \n    |0xfe|0xfd|blen|blen literal bytes...|blen_1|blen_2|literal bytes...|0xfe|0xfd|\n\nThe first blen is in \\\\([0, 252]\\\\) and tells us how many literal bytes follow\nin the initial block. If the initial \\\\(\\mathtt{blen} = 252\\\\), the literal\nbytes are immediately followed by the next block\u2019s decoded contents.\nOtherwise, we must first append an implicit 0xfe 0xfd sequence... which may be\nthe artificial reserved sequence that mark the end of every record.\n\nEvery subsequent block comes with a two-byte size prefix, in little-endian\nradix-253. In other words, |blen_1|blen_2| represents the block size\n\\\\(\\mathtt{blen}\\sb{1} + 253 \\cdot \\mathtt{blen}\\sb{2}\\\\), where\n\\\\(\\mathtt{blen}_{{1, 2}} \\in [0, 252]\\\\). Again, if the block size is the\nmaximum encodable size, \\\\(253^2 - 1 = 64008\\\\), we have literal data followed\nby the next block; otherwise, we must append a 0xfe 0xfd sequence to the\noutput before moving on to the next block.\n\nThe encoding algorithm is only a bit more complex than for the original COBS\nscheme.\n\nAssume the data to encode is suffixed with an artificial two-byte reserved\nsequence 0xfe 0xfd.\n\nFor the first block, look for the reserved sequence in the first 252 bytes. If\nwe find it, emit its position (must be less than 251) in one byte, then all\nthe data bytes up to but not including the reserved sequence, and enter\nregular encoding after the reserved sequence. If the sequence isn\u2019t in the\nfirst block, emit 252, followed by 252 bytes of data, and enter regular\nencoding after those bytes.\n\nFor regular (all but the first) blocks, look for the reserved sequence in the\nnext 64008 bytes. If we find it, emit the sequence\u2019s byte offset (must be less\nthan 64008) in little-endian radix 253, followed by the data up to but not\nincluding the reserved sequence, and skip that sequence before encoding the\nrest of the data. If we don\u2019t find the reserved sequence, emit 64008 in radix\n253 (0xfc 0xfc), copy the next 64008 bytes of data, and encode the rest of the\ndata without skipping anything.\n\nRemember that we conceptually padded the data with a reserved sequence at the\nend. This means we\u2019ll always observe that we fully consumed the input data at\na block boundary. When we encode the block that stops at the artificial\nreserved sequence, we stop (and frame with a reserved sequence to delimit a\nrecord boundary).\n\nYou can find our implementation in the stuffed-record-stream repository.\n\nWhen writing short records, we already noted that the encoding step is often\nequivalent to adding a one-byte size prefix. In fact, we can encode and decode\nall records of size up to \\\\(252 + 64008 = 64260\\\\) bytes in place, and only\never have to slide the initial 252-byte block: whenever a block is shorter\nthan the maximum length (252 bytes for the first block, 64008 for subsequent\nones), that\u2019s because we found a reserved sequence in the decoded data. When\nthat happens, we can replace the reserved sequence with a size header when\nencoding, and undo the substitution when decoding.\n\nOur code does not implement these optimisations because encoding and decoding\nstuffed bytes aren\u2019t bottlenecks for our use case, but it\u2019s good to know that\nwe\u2019re nowhere near the performance ceiling.\n\n## A resilient record stream on top of word stuffing\n\nThe stuffing scheme only provides resilient framing. That\u2019s essential, but not\nenough for an abstract stream or sequence of records. At the very least, we\nneed checksums in order to detect invalid records that happen to be correctly\nencoded (e.g., when a block\u2019s literal data is overwritten).\n\nOur pre-stuffed records start with the little-endian header\n\n    \n    \n    struct record_header { uint32_t crc; uint32_t generation; };\n\nwhere crc is the crc32c of whole record, including the header,^3 and\ngeneration is a yet-unused arbitrary 32-bit payload that we added for forward\ncompatibility. There is no size field: the framing already handles that.\n\nThe remaining bytes in a record are an arbitrary payload. We use protobuf\nmessages to help with schema evolution (and keep messages small and flat for\ndecoding performance), but there\u2019s no special relationship between the stream\nof word-stuffed records and the payload\u2019s format.\n\nOur implementation let writers output to buffered FILE streams, or directly to\nfile descriptors.\n\nBuffered streams offer higher write throughput, but are only safe when the\ncaller handles synchronisation and flushing; we use them as part of a commit\nprotocol that fsyncs and publishes files with atomic rename syscalls.\n\nDuring normal operations, we instead write to file descriptors opened with\nO_APPEND and a background fsync worker: in practice, the hardware and\noperating system are more stable than our software, so it\u2019s more important\nthat encoded records immediately make it to the kernel than all the way to\npersistent storage. We also avoid batching write syscalls because we would\noften have to wait several minutes if not hours to buffer more than two or\nthree records.\n\nFor readers, we can either read from a buffer, or mmap in a file, and read\nfrom the resulting buffer. While we expose a linear iterator interface, we can\nalso override the start and stop byte offset of an iterator; we use that\ncapability to replay logs in parallel. Finally, when readers advance an\niterator, they can choose to receive a raw data buffer, or have it decoded\nwith a protobuf message descriptor.\n\n## What\u2019s next?\n\nWe have happily been using this log format for more than nine months to store\na log of metadata records that we replay every time the Backtrace server\nrestarts.\n\nDecoupling writes from the parallel read strategy let us improve our startup\ntime incrementally, without any hard migration. Serialising with flexible\nschemas (protocol buffers) also made it easier to start small and slowly add\noptional metadata, and only enforce a hard switch-over when we chose to delete\nbackward compatibility code.\n\nThis piecemeal approach let us transition from a length-prefixed data format\nto one where all important metadata lives in a resilient record stream,\nwithout any breaking change. We slowly added more metadata to records and\neventually parallelised loading from the metadata record stream, all while\npreserving backward and forward compatibility. Six months after the initial\nroll out, we flipped the switch and made the new, more robust, format\nmandatory; the old length-prefixed files still exist, but are now bags of\narbitrary checksummed data bytes, with metadata in record streams.\n\nIn the past nine months, we\u2019ve gained a respectable amount of pleasant\noperational experience with the format. Moreover, while performance is good\nenough for us (the parallel loading phase is currently dominated by disk I/O\nand parsing in protobuf-c), we also know there\u2019s plenty of headroom: our\nrecords are short enough that they can usually be decoded without any write,\nand always in place.\n\nWe\u2019re now starting laying the groundwork to distribute our single-node\nembedded database and making it interact more fluently with other data stores.\nThe first step will be generating a change data capture stream, and re-using\nthe word-stuffed record format was an obvious choice.\n\nWord stuffing is simple, efficient, and robust. If you can\u2019t just defer to a\nreal database (maybe you\u2019re trying to write one yourself) for your log\nrecords, give it a shot! Feel free to play with our code if you don\u2019t want to\nroll your own.\n\nThank you, Ruchir and Alex, for helping me clarify and restructure an earlier\nversion.\n\n  1. If you append with the delimiter, it probably makes sense to special-case short writes and also prepend with the delimiter after failures, in order to make sure readers will observe a delimiter before the new record. \u21a9\n\n  2. High-throughput writers should batch records. We do syscall-per-record because the write load for the current use case is so sporadic that any batching logic would usually end up writing individual records. For now, batching would introduce complexity and bug potential for a minimal impact on write throughput. \u21a9\n\n  3. We overwrite the crc field with UINT32_MAX before computing a checksum for the header and its trailing data. It\u2019s important to avoid zero prefixes because the result of crc-ing a 0 byte into a 0 state is... 0. \u21a9\n\nText authored by Paul Khuong Jan 11th, 2021\n\n\u00ab 1.5x the PH bits for one more CLMUL Baseline implementations should be\npredictable \u00bb\n\n# Comments\n\nWebsite copyright \u00a9 2024 - Paul Khuong | Powered by Octopress | Themed with K\u00f6nigspress\n\n", "frontpage": false}
