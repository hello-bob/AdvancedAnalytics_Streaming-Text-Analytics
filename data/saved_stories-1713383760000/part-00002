{"aid": "40064646", "title": "Mixtral-8x22B-Instruct-v0.1", "url": "https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1", "domain": "huggingface.co", "votes": 13, "user": "tosh", "posted_at": "2024-04-17 13:54:35", "comments": 2, "source_title": "mistralai/Mixtral-8x22B-Instruct-v0.1 \u00b7 Hugging Face", "source_text": "mistralai/Mixtral-8x22B-Instruct-v0.1 \u00b7 Hugging Face\n\nHugging Face\n\n#\n\nmistralai\n\n/\n\nMixtral-8x22B-Instruct-v0.1\n\nText Generation Transformers Safetensors mixtral conversational Inference\nEndpoints text-generation-inference\n\nModel card Files Files and versions Community\n\n1\n\nEdit model card\n\n# Model Card for Mixtral-8x22B-Instruct-v0.1\n\nThe Mixtral-8x22B-Instruct-v0.1 Large Language Model (LLM) is an instruct\nfine-tuned version of the Mixtral-8x22B-v0.1.\n\n## Run the model\n\n    \n    \n    from transformers import AutoModelForCausalLM from mistral_common.protocol.instruct.messages import ( AssistantMessage, UserMessage, ) from mistral_common.tokens.tokenizers.mistral import MistralTokenizer from mistral_common.tokens.instruct.normalize import ChatCompletionRequest device = \"cuda\" # the device to load the model onto tokenizer_v3 = MistralTokenizer.v3() mistral_query = ChatCompletionRequest( tools=[ Tool( function=Function( name=\"get_current_weather\", description=\"Get the current weather\", parameters={ \"type\": \"object\", \"properties\": { \"location\": { \"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\", }, \"format\": { \"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"], \"description\": \"The temperature unit to use. Infer this from the users location.\", }, }, \"required\": [\"location\", \"format\"], }, ) ) ], messages=[ UserMessage(content=\"What's the weather like today in Paris\"), ], model=\"test\", ) encodeds = tokenizer_v3.encode_chat_completion(mistral_query).tokens model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mixtral-8x22B-Instruct-v0.1\") model_inputs = encodeds.to(device) model.to(device) generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True) sp_tokenizer = tokenizer_v3.instruct_tokenizer.tokenizer decoded = sp_tokenizer.decode(generated_ids[0]) print(decoded)\n\n# Instruct tokenizer\n\nThe HuggingFace tokenizer included in this release should match our own. To\ncompare: pip install mistral-common\n\n    \n    \n    from mistral_common.protocol.instruct.messages import ( AssistantMessage, UserMessage, ) from mistral_common.tokens.tokenizers.mistral import MistralTokenizer from mistral_common.tokens.instruct.normalize import ChatCompletionRequest from transformers import AutoTokenizer tokenizer_v3 = MistralTokenizer.v3() mistral_query = ChatCompletionRequest( messages=[ UserMessage(content=\"How many experts ?\"), AssistantMessage(content=\"8\"), UserMessage(content=\"How big ?\"), AssistantMessage(content=\"22B\"), UserMessage(content=\"Noice \ud83c\udf89 !\"), ], model=\"test\", ) hf_messages = mistral_query.model_dump()['messages'] tokenized_mistral = tokenizer_v3.encode_chat_completion(mistral_query).tokens tokenizer_hf = AutoTokenizer.from_pretrained('mistralai/Mixtral-8x22B-Instruct-v0.1') tokenized_hf = tokenizer_hf.apply_chat_template(hf_messages, tokenize=True) assert tokenized_hf == tokenized_mistral\n\n# Function calling and special tokens\n\nThis tokenizer includes more special tokens, related to function calling :\n\n  * [TOOL_CALLS]\n  * [AVAILABLE_TOOLS]\n  * [/AVAILABLE_TOOLS]\n  * [TOOL_RESULT]\n  * [/TOOL_RESULTS]\n\nIf you want to use this model with function calling, please be sure to apply\nit similarly to what is done in our SentencePieceTokenizerV3.\n\n# The Mistral AI Team\n\nAlbert Jiang, Alexandre Sablayrolles, Alexis Tacnet, Antoine Roux, Arthur\nMensch, Audrey Herblin-Stoop, Baptiste Bout, Baudouin de Monicault, Blanche\nSavary, Bam4d, Caroline Feldman, Devendra Singh Chaplot, Diego de las Casas,\nEleonore Arcelin, Emma Bou Hanna, Etienne Metzger, Gianna Lengyel, Guillaume\nBour, Guillaume Lample, Harizo Rajaona, Jean-Malo Delignon, Jia Li, Justus\nMurke, Louis Martin, Louis Ternon, Lucile Saulnier, L\u00e9lio Renard Lavaud,\nMargaret Jennings, Marie Pellat, Marie Torelli, Marie-Anne Lachaux, Nicolas\nSchuhl, Patrick von Platen, Pierre Stock, Sandeep Subramanian, Sophia Yang,\nSzymon Antoniak, Teven Le Scao, Thibaut Lavril, Timoth\u00e9e Lacroix, Th\u00e9ophile\nGervet, Thomas Wang, Valera Nemychnikova, William El Sayed, William Marshall\n\nDownloads last month\n\n    0\n\nSafetensors\n\nModel size\n\n141B params\n\nTensor type\n\nBF16\n\n\u00b7\n\n", "frontpage": true}
