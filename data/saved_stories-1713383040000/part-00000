{"aid": "40064448", "title": "Show HN: Python library for querying all major LLM's with a user friendly API", "url": "https://github.com/allegro/allms", "domain": "github.com/allegro", "votes": 1, "user": "allegro-tech", "posted_at": "2024-04-17 13:41:52", "comments": 0, "source_title": "GitHub - allegro/allms: A versatile and powerful library designed to streamline the process of querying LLMs", "source_text": "GitHub - allegro/allms: A versatile and powerful library designed to\nstreamline the process of querying LLMs\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nallegro / allms Public\n\n  * Notifications\n  * Fork 1\n  * Star 58\n\nA versatile and powerful library designed to streamline the process of\nquerying LLMs\n\nallms.allegro.tech\n\n### License\n\nApache-2.0 license\n\n58 stars 1 fork Branches Tags Activity\n\nStar\n\nNotifications\n\n# allegro/allms\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n8 Branches\n\n3 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nalicja-raczkowskaMerge pull request #21 from allegro/response-json-\nextractionMar 22, 202479a0b38 \u00b7 Mar 22, 2024Mar 22, 2024\n\n## History\n\n68 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| mock VertexAI class adn remove gcp auth| Mar 6, 2024  \n  \n### allms\n\n|\n\n### allms\n\n| Removed format instruction injection for open-souce models| Mar 22, 2024  \n  \n### docs\n\n|\n\n### docs\n\n| Removed format instruction injection for open-souce models| Mar 22, 2024  \n  \n### examples\n\n|\n\n### examples\n\n| Migrating from llm-wrapper to allms. All code refactored, docs and RE...|\nFeb 27, 2024  \n  \n### resources/images\n\n|\n\n### resources/images\n\n| initial commit| Feb 6, 2024  \n  \n### tests\n\n|\n\n### tests\n\n| Changed mock LLM name in conftest| Mar 22, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| initial commit| Feb 6, 2024  \n  \n### .pylintrc\n\n|\n\n### .pylintrc\n\n| initial commit| Feb 6, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Initial commit| Feb 6, 2024  \n  \n### Makefile\n\n|\n\n### Makefile\n\n| Migrating from llm-wrapper to allms. All code refactored, docs and RE...|\nFeb 27, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| update README.md and docs| Mar 4, 2024  \n  \n### mkdocs.yml\n\n|\n\n### mkdocs.yml\n\n| Updating mkdocs.yml and pyproject.toml with new version release| Mar 5, 2024  \n  \n### poetry.lock\n\n|\n\n### poetry.lock\n\n| Removed format instruction injection for open-souce models| Mar 22, 2024  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| Removed format instruction injection for open-souce models| Mar 22, 2024  \n  \n## Repository files navigation\n\n# allms\n\n## About\n\nallms is a versatile and powerful library designed to streamline the process\nof querying Large Language Models (LLMs) \ud83e\udd16\ud83d\udcac\n\nDeveloped by the Allegro engineers, allms is based on popular libraries like\ntransformers, pydantic, and langchain. It takes care of the boring boiler-\nplate code you write around your LLM applications, quickly enabling you to\nprototype ideas, and eventually helping you to scale up for production use-\ncases!\n\nAmong the allms most notable features, you will find:\n\n  * \ud83d\ude0a Simple and User-Friendly Interface: The module offers an intuitive and easy-to-use interface, making it straightforward to work with the model.\n\n  * \ud83d\udd00 Asynchronous Querying: Requests to the model are processed asynchronously by default, ensuring efficient and non-blocking interactions.\n\n  * \ud83d\udd04 Automatic Retrying Mechanism : The module includes an automatic retrying mechanism, which helps handle transient errors and ensures that queries to the model are robust.\n\n  * \ud83d\udee0\ufe0f Error Handling and Management: Errors that may occur during interactions with the model are handled and managed gracefully, providing informative error messages and potential recovery options.\n\n  * \u2699\ufe0f Output Parsing: The module simplifies the process of defining the model's output format as well as parsing and working with it, allowing you to easily extract the information you need.\n\n## Supported Models\n\nLLM Family| Hosting| Supported LLMs  \n---|---|---  \nGPT(s)| OpenAI endpoint| gpt-3.5-turbo, gpt-4, gpt-4-turbo  \nGoogle LLMs| VertexAI deployment| text-bison@001, gemini-pro  \nLlama2| Azure deployment| llama2-7b, llama2-13b, llama2-70b  \nMistral| Azure deployment| Mistral-7b, Mixtral-7bx8  \nGemma| GCP deployment| gemma  \n  \n  * Do you already have a subscription to a Cloud Provider for any the models above? Configure the model using your credentials and start querying!\n  * Are you interested in knowing how to self-deploy open-source models in Azure and GCP? Consult our guide\n\n## Documentation\n\nFull documentation available at allms.allegro.tech\n\nGet familiar with allms \ud83d\ude80: introductory jupyter notebook\n\n## Quickstart\n\n### Installation \ud83d\udea7\n\nInstall the package via pip:\n\n    \n    \n    pip install allms\n\n### Basic Usage \u2b50\n\nConfigure endpoint credentials and start querying the model with any prompt:\n\n    \n    \n    from allms.models import AzureOpenAIModel from allms.domain.configuration import AzureOpenAIConfiguration configuration = AzureOpenAIConfiguration( api_key=\"your-secret-api-key\", base_url=\"https://endpoint.openai.azure.com/\", api_version=\"2023-03-15-preview\", deployment=\"gpt-35-turbo\", model_name=\"gpt-3.5-turbo\" ) gpt_model = AzureOpenAIModel(config=configuration) gpt_response = gpt_model.generate(prompt=\"Plan me a 3-day holiday trip to Italy\")\n\nYou can pass also a system prompt:\n\n    \n    \n    gpt_response = gpt_model.generate( system_prompt=\"You are an AI assistant acting as a trip planner\", prompt=\"Plan me a 3-day holiday trip to Italy\" )\n\n### Advanced Usage \ud83d\udd25\n\n### Batch Querying and Symbolic Variables\n\nIf you want to generate responses for a batch of examples, you can achieve\nthis by preparing a prompt with symbolic variables and providing input data\nthat will be injected into the prompt. Symbolic variables can be more than\none.\n\n    \n    \n    positive_review_0 = \"Very good coffee, lightly roasted, with good aroma and taste. The taste of sourness is barely noticeable (which is good because I don't like sour coffees). After grinding, the aroma spreads throughout the room. I recommend it to all those who do not like strongly roasted and pitch-black coffees. A very good solution is to close the package with string, which allows you to preserve the aroma and freshness.\" positive_review_1 = \"Delicious coffee!! Delicate, just the way I like it, and the smell after opening is amazing. It smells freshly roasted. Faithful to Lavazza coffee for years, I decided to look for other flavors. Based on the reviews, I blindly bought it and it was a 10-shot, it outperformed Lavazze in taste. For me the best.\" negative_review = \"Marketing is doing its job and I was tempted too, but this coffee is nothing above the level of coffees from the supermarket. And the method of brewing or grinding does not help here. The coffee is simply weak - both in terms of strength and taste. I do not recommend.\" prompt = \"You'll be provided with a review of a coffe. Decide if the review is positive or negative. Review: {review}\" input_data = [ InputData(input_mappings={\"review\": positive_review_0}, id=\"0\"), InputData(input_mappings={\"review\": positive_review_1}, id=\"1\"), InputData(input_mappings={\"review\": negative_review}, id=\"2\") ] responses = model.generate(prompt=prompt, input_data=input_data) # >>> {f\"review_id={response.input_data.id}\": response.response for response in responses} # { # 'review_id=0': 'The review is positive.', # 'review_id=1': 'The review is positive.', # 'review_id=2': 'The review is negative.' # }\n\n### Forcing Structured Output Format\n\nThrough pydantic integration, in allms you can pass an output dataclass and\nforce the LLM to provide you the response in a structured way.\n\n    \n    \n    from pydantic import BaseModel, Field class ReviewOutputDataModel(BaseModel): summary: str = Field(description=\"Summary of a product description\") should_buy: bool = Field(description=\"Recommendation whether I should buy the product or not\") brand_name: str = Field(description=\"Brand of the coffee\") aroma:str = Field(description=\"Description of the coffee aroma\") cons: list[str] = Field(description=\"List of cons of the coffee\") review = \"Marketing is doing its job and I was tempted too, but this Blue Orca coffee is nothing above the level of coffees from the supermarket. And the method of brewing or grinding does not help here. The coffee is simply weak - both in terms of strength and taste. I do not recommend.\" prompt = \"Summarize review of the coffee. Review: {review}\" input_data = [InputData(input_mappings={\"review\": review}, id=\"0\")] responses = model.generate( prompt=prompt, input_data=input_data, output_data_model_class=ReviewOutputDataModel ) response = responses[0].response # >>> type(response) # ReviewOutputDataModel # # >>> response.should_buy # False # # >>> response.brand_name # \"Blue Orca\" # # >>> response.aroma # \"Not mentioned in the review\" # # >>> response.cons # ['Weak in terms of strength', 'Weak in terms of taste']\n\n## Local Development \ud83d\udee0\ufe0f\n\n### Installation from the source\n\nWe assume that you have python 3.10.* installed on your machine. You can set\nit up using pyenv (How to install pyenv on MacOS). To install allms env\nlocally:\n\n  * Activate your pyenv;\n  * Install Poetry via:\n\n    \n    \n    make install-poetry\n\n  * Install allms dependencies with the command:\n\n    \n    \n    make install-env\n\n  * Now you can use this venv for development. You can activate it in your shell by running:\n\n    \n    \n    make activate-env # or simply, poetry shell\n\n### Tests\n\nIn order to execute tests, run:\n\n    \n    \n    make tests\n\n### Updating the documentation\n\nRun mkdocs serve to serve a local instance of the documentation.\n\nModify the content of docs directory to update the documentation. The updated\ncontent will be deployed via the github action .github/workflows/docs.yml\n\n### Make a new release\n\nWhen a new version of allms is ready to be released, do the following\noperations:\n\n  1. Merge to master the dev branch in which the new version has been specified:\n\n    1. In this branch, version under [tool.poetry] section in pyproject.toml should be updated, e.g 0.1.0;\n    2. Update the CHANGELOG, specifying the new release.\n  2. Tag the new master with the name of the newest version:\n\n    1. e.g v0.1.0.\n  3. Publish package to PyPI:\n\n    1. Go to Actions \u2192 Manual Publish To PyPI;\n    2. Select \"master\" as branch and click Run workflow;\n    3. If successful, you will find the package under # TODO: open-source.\n  4. Make a GitHub release:\n\n    1. Go to Releases \u2192 Draft a new release;\n    2. Select the recently created tag in Choose a tag window;\n    3. Copy/paste all the content present in the CHANGELOG under the version you are about to release;\n    4. Upload allms-<NEW-VERSION>.whl and allms-<NEW-VERSION>.tar.gz as assets;\n    5. Click Publish release.\n\n## About\n\nA versatile and powerful library designed to streamline the process of\nquerying LLMs\n\nallms.allegro.tech\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\nActivity\n\nCustom properties\n\n### Stars\n\n58 stars\n\n### Watchers\n\n3 watching\n\n### Forks\n\n1 fork\n\nReport repository\n\n## Releases 3\n\n1.0.2 Latest\n\nMar 22, 2024\n\n\\+ 2 releases\n\n## Packages 0\n\nNo packages published\n\n## Contributors 4\n\n  * riccardo-alle Riccardo Belluzzo\n  * megatron6000 Piotr Zieli\u0144ski\n  * bgalek Bartosz Ga\u0142ek\n  * alicja-raczkowska Alicja R\u0105czkowska\n\n## Languages\n\n  * Python 99.4%\n  * Makefile 0.6%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
