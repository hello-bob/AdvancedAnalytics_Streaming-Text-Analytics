{"aid": "40199716", "title": "Dopamine: Everything you need to know (and quite a bit more)", "url": "https://erringtowardsanswers.substack.com/p/dopamine-everything-you-need-to-know", "domain": "erringtowardsanswers.substack.com", "votes": 2, "user": "buzzmerchant", "posted_at": "2024-04-29 15:39:06", "comments": 3, "source_title": "Dopamine: Everything you need to know", "source_text": "Dopamine: Everything you need to know - by Frazer Mawson\n\n# Erring Towards Answers\n\nShare this post\n\n#### Dopamine: Everything you need to know\n\nerringtowardsanswers.substack.com\n\n#### Discover more from Erring Towards Answers\n\nBy bringing together insights from Philosophy, Psychology, and Neuroscience,\nI'm trying to work out how I \u2013 and how others \u2013 can live the best life\npossible.\n\nContinue reading\n\nSign in\n\n# Dopamine: Everything you need to know\n\n### This is my attempt to give a more or less complete, up-to-the-minute\naccount of what we know about dopamine. It's long, but it's thorough.\n\nFrazer Mawson\n\nDec 05, 2023\n\n17\n\nShare this post\n\n#### Dopamine: Everything you need to know\n\nerringtowardsanswers.substack.com\n\n9\n\nShare\n\nIt's official: based on google trends data, dopamine is the most popular\nneurochemical of them all. Serotonin was number one up until 2021, but since\nthen, dopamine has ruled the roost.\n\nGoogle trends data on the most searched for neurochemicals\n\nIntuitively, this feels about right: awareness of behavioural addictions and\nthe role dopamine plays in them has risen a lot in recent years. It also just\nfeels like more people than ever before \u2013 people otherwise completely innocent\nof neuroscience \u2013 are using the word dopamine colloquially to refer to\nsomething like 'a neural correlate of pleasure'.\n\nThanks for reading Erring Towards Answers! Subscribe for free to receive new\nposts and support my work.\n\nDespite this rise in popularity \u2013 and despite my searching \u2013 never have I\nactually come across any content that gives a comprehensive accounting of what\ndopamine is or how it works. Given how apparently important a neurochemical\ndopamine is, this is surely a gap worth plugging.\n\nThis post \u2013 the fruit of far more time and research than I had originally\nplanned \u2013 is my attempt to do exactly that.\n\nTurns out there are a number of widespread misconceptions about exactly what\ndopamine does and doesn't do. In this post, I\u2019m going to try and dispel all of\nthem while presenting an up-to-the-minute picture of what we do actually know\nabout dopamine.\n\nHere goes.\n\nP.S. For the sake of brevity and readability, I'm going to assume readers have\na basic understanding of neuroscience. For anyone who finds themselves\nstruggling with certain parts, here's a fairly succinct neuroscience primer\nthat will hopefully give you the rudiments needed to make sense of everything\nI say here.\n\nP.P.S. I\u2019ve done so much research \u2013 and come across so many interesting\nfindings \u2013 that I'm reluctant to leave any of it out. I\u2019ve therefore thrown in\nan appendix at the bottom of this piece, where I've included all of the cool,\nslightly peripheral things I've discovered during my travels. I\u2019ll also be\ndoing a follow-up post where I\u2019ll be discussing the plausibility of dopamine\nfasts. Stay tuned.\n\n##\n\nDopamine and the dopaminergic system\n\nIn the interest of not ruining the flow of later parts of this post, I'm going\nto do a little bit of an exposition dump here to give you the basic knowledge\nyou need to understand later sections. Where possible, I'll keep this sketch\nfairly low-resolution, because I don't want to burden you with details that\ndon't actually enhance your understanding of how this stuff works.\n\nSo:\n\nDopamine is a signalling molecule in the brain known as a neurotransmitter.\nFor a long time, researchers thought that dopamine was just a precursor of\nnoradrenaline \u2013 another important neurotransmitter \u2013 but it turns out dopamine\nis directly involved in a range of important phenomena and pathologies,\nincluding movement, learning, motivation, habit-formation, addiction,\nparkinsons, huntingtons, and more.\n\nThere are certain neurons, i.e. nerve cells, in the brain that produce\ndopamine. When these neurons are activated in specific ways, they release that\ndopamine into the space outside the cell, i.e. the extracellular space, where\nit binds with receptors on other neurons and thereby influences their firing\npatterns.\n\nWith many other types of neuron, the upstream neuron \u2013 otherwise known as the\npresynaptic neuron \u2013 pretty much locks directly onto the downstream neuron \u2013\ni.e. the postsynaptic neuron. The tiny space between these two cells, into\nwhich the neurotransmitter is released, is known as the synapse, and this kind\nof intercellular communication is called synaptic transmission.\n\nExample of synaptic transmission taken from here\n\nWith dopamine neurons, on the other hand, the majority of their signalling\nseems to be done via volume transmission, which is essentially where they\nrelease a ton of dopamine into the space outside the cell, without targeting\nany specific downstream neurons or receptor sites in particular.\n\nVolume transmission is way less precise than synaptic transmission, but it\ncomes with a number of advantages that allow dopamine to do its job. One quick\nexample: there\u2019s evidence that dopamine is involved in learning (to be\ndiscussed soon) and that it plays a role in promoting plasticity (2). By being\nsprayed far and wide, dopamine may be able to identify and strengthen certain\nrecently active neural pathways associated with behaviours that preceded some\nkind of a reward.\n\nTo make things slightly more complicated, there are 5 specific types of\nreceptors that dopamine can bind to, named D1 through to D5. D1 and D5 are\ngenerally classed in the D1-like family; and D2, D3, D4 are classed in the\nD2-like family.\n\nDopamine's effects on downstream neurons depends on the specific receptors\nthat those neurons have built into their cell membranes. As I understand\nthings, each downstream neuron will only have one class of dopamine receptor,\ni.e. either D1-like or D2-like receptors, which makes things a bit easier for\nus to grasp.\n\nAlthough there are dopamine-containing neurons distributed all across the\ncentral nervous system \u2013 including the retina, the olfactory bulb, and the\nperiventricular hypothalamus \u2013 the two most important populations, or nuclei,\nare located next to each other in the midbrain:\n\n1\\. The substantia nigra (SN)\n\n2\\. The ventral tegmental Area (VTA)\n\nThe first population in the SN connects mostly to the dorsal (i.e. top part of\nthe) striatum. Known as the nigrostriatal pathway, this pathway is mostly\ninvolved in action-selection, habits, and goal-directed behaviour.\n\nDegeneration of the dopamine-containing cells in the substantia nigra is all\nthat's needed to cause the motor deficits associated with Parkinson's.\n\nThe second population in the VTA connects mostly to the ventral (i.e. bottom\npart of the) striatum, as well as various parts of the prefrontal cortex\n(PFC). Known as the mesocorticolimbic pathway, this pathway is mostly involved\nin movement, motivation, and reinforcement learning.\n\nOne thing worth knowing is that there\u2019s an important population of neurons in\nthe ventral striatum called the nucleus accumbens (NA). Throughout this\narticle, you can pretty much assume that the terms ventral striatum and NA are\nbeing used interchangeably, since the NA seems to be (by far) the most\nimportant part of the ventral striatum insofar as dopamine is concerned.\n\nHere's a diagram to clear some of this up:\n\n(Note: this diagram treats the mesocortical and the mesolimbic pathways as two\nseparate things, but in this post (and in much of the academic literature,\ntoo) we\u2019re treating them as a single pathway \u2013 hence \u2018mesocorticolimbic\u2019.\nAlso, ignore the tubero-infundibular pathway \u2013 it isn\u2019t important for what\nwe\u2019re talking about here.)\n\nIt seems that there's evidence for there being more overlap between the\nmesocorticolimbic and nigrostriatal pathways than initially believed (3), but\nfor our purposes here, let's just leave it there for now.\n\nThere are one or two additional features of the dopamine system's neuroanatomy\nthat it will be worth your knowing, but in the interest of not getting too\nbogged down in detail at the start, this gives us enough to get going.\n\nQuick summary:\n\n  * Dopamine is a signalling molecule in the brain\n\n  * Unlike certain other neurotransmitters, e.g. glutamate, which are distributed via precise synaptic transmission, dopamine is mostly distributed via volume transmission\n\n  * It is primarily produced by two populations of neurons found in the SN and the VTA\n\n  * Dopamine neurons in the SN connect mostly to the dorsal striatum, giving rise to the nigrostriatal pathway; those in the VTA connect mostly to the ventral striatum and PFC, giving rise to the mesocorticolimbic pathway\n\n  * There are two main classes of dopamine receptors: D1-like receptors and D2-like receptors\n\n##\n\nDopamine and pleasure\n\nAs mentioned in the intro, when most people talk about dopamine, they seem to\nbe talking about something like 'a neural correlate of pleasure'. In other\nwords: when I eat chocolate, my brain releases dopamine, and it is this\ndopamine release that causes, or is correlated with, my sensation of pleasure.\n\nWhile this was once \u2013 briefly \u2013 the accepted scientific view, it isn't any\nmore. Here's the full story:\n\nIn 1954, it was discovered that rats and humans will voluntarily administer\nbrief bursts of weak electrical stimulation to certain sites in their brains.\nThis phenomenon is known as intracranial self-stimulation, and it was\noriginally theorised that parts of the brain that people and rats choose to\nself-stimulate may be involved in the generation of pleasure \u2013 hence why we\nchoose to stimulate them (1).\n\nFrom there, the race was on to map these sites and establish the 'pleasure'\ncircuitry of the brain (1).\n\nAfter not too long, it became apparent that the mesocorticolimbic pathway \u2013 as\ndiscussed above \u2013 and dopamine were deeply implicated in intracranial self-\nstimulation. Four pieces of strong evidence for this:\n\n  1. Many of the brain sites at which brain stimulation occurs are part of the mesocorticolimbic pathway (1).\n\n  2. Intracranial self-stimulation often causes an increase in dopamine release in the mesocorticolimbic pathway (1).\n\n  3. Dopamine agonists, i.e. drugs that enhance the effects of dopamine, tend to increase intracranial self-stimulation; and dopamine antagonists, i.e. drugs that inhibit the effects of dopamine, tend to decrease it (1).\n\n  4. Lesions of the mesocorticolimbic pathway tend to disrupt intracranial self-stimulation (1).\n\nAs a result of all this data, it was suggested that dopamine is a key player\nin the generation of pleasure in the brain \u2013 a hypothesis known as the\n'dopamine pleasure' or 'dopamine hedonia' hypothesis.\n\nWe now have some pretty good evidence that this is almost certainly wrong.\n\nIn fact, even Roy Wise, the guy who originally proposed the hypothesis (and\nwho was also involved in a lot of the intracranial self-stimulation research),\nhas come out and said \u2018\u2018I no longer believe that the amount of pleasure felt\nis proportional to the amount of dopamine floating around in the brain\u2019\u2019 (6).\n\nHere's why he (and pretty much everyone else) thinks this:\n\nIt turns out that what we typically think of as pleasure can be broken down\ninto three constituent neurobiological processes (5):\n\n  1. Liking \u2013 the actual pleasure or hedonic component of a reward. This is what we normally think of when we use the word pleasure.\n\n  2. Wanting \u2013 motivation for a reward. It's possible, as we will soon see, to want something that is not pleasurable or, likewise, to not want something that is.\n\n  3. Learning \u2013 associations and representations about future rewards based on past rewards, e.g. I have a chocolate bar, I learn that chocolate is enjoyable, ergo next time I encounter chocolate, I want it.\n\nIn essence, wanting happens when you start to desire and pursue a specific\nthing; liking happens while you are consuming that thing; and learning happens\nthroughout, because you're learning about both the cues and behaviours that\npreceded the pleasurable thing, as well as the intensity of the pleasure that\nthing produces.\n\nIt can be quite tricky to tease these components apart because rewarding\nstimuli, e.g. a chocolate bar, tend to activate all three components more or\nless simultaneously. Saying that, neuroscientists have developed some quite\nsmart ways of doing this, which to my mind aren't exactly perfect but that\nseem to (mostly) get the job done. Here's how:\n\nAlmost all species of animal, including humans, show objective signs of liking\nsomething. For example, if you give a baby a sweet taste, they\u2019ll consistently\nrelax their facial muscles; if you give them a bitter taste, they'll produce a\nscrunched up, disgusted reaction. The same is true of a whole host of animals,\nincluding apes, monkeys, and mice (6).\n\nTaken from Pecina, Smith, and Berridge (2006) \u2013 \u2018Hedonic hotspots in the\nbrain\u2019\n\nBy measuring the intensity of their objective liking reactions, we can\nessentially get a read on how much an animal actually likes, i.e. enjoys,\nsomething.\n\nAnyway, back to dopamine and why we're now convinced that it\u2019s not the cause\nof pleasure:\n\n  1. Rats with almost complete destruction of their mesocorticolimbic and nigrostriatal neurons via lesions show no difference whatsoever in orofacial liking reactions to sweet tastes. In other words, you remove all the neurons in their brains that produce dopamine and they still seem to experience liking reactions (6).\n\n  2. In humans, Parkinson's sufferers whose dopamine neurons have been more or less completely destroyed give normal hedonic ratings to the sensory pleasure of sweet tastes (6).\n\n  3. In humans, subjective pleasure ratings of cocaine aren't reduced by pharmacological disruption of the dopamine system \u2013 but, interestingly, 'wanting' ratings are (6).\n\n  4. Dopamine elevations in the NA (recall, a part of the ventral striatum) don\u2019t increase liking for a sweet taste despite increasing motivational wanting to obtain the reward (6).\n\nFinally, here's a particularly interesting study that sort of summarises why\nwe believe dopamine plays no role in liking \u2013 and that also hints at what it\ndoes actually seem to do (10):\n\nBerridge and his team used mice with a dopamine transporter knockdown mutation\nto investigate the effects of dopamine in Liking and Wanting. This mutation\nessentially means that the mutant mice have 70% elevated levels of\nextracellular dopamine in the striatum, so by comparing their reactions and\nperformance in specific tasks with those of wild mice with normal dopamine\nlevels, these researchers were able to get a read on what dopamine is actually\nup to.\n\nIn the first part of the experiment, they simply gave these mice pretty much\nunlimited access to food and water over a four week period and monitored their\nconsumption levels. It was found that the mutant mice with elevated dopamine\nate and drank slightly more than their wild-mice colleagues. Interesting\nresult but nothing shocking.\n\nThe next part of the experiment involved a runway task, which is basically\nwhere you monitor the speed, trajectory \u2013 and other slightly more qualitative\nthings \u2013 at which an animal traverses a runway in order to acquire some kind\nof rewarding stimulus. In this experiment, the rewarding stimulus was a sweet\nbreakfast cereal that the mice had already been habituated to.\n\nTaken from Berridge et al (2003) \u2013 \u2018Hyperdopaminergic Mutant Mice Have Higher\n\u201cWanting\u201d But Not \u201cLiking\u201d for Sweet Rewards\u2019\n\nAs shown in the graphs above, after the initial goal pre-exposure phase (in\nwhich the mice were simply placed in the \u2018goal box\u2019 at the end of the runway\nand given access to the cereal), the mutant mice traversed the runway much\nmore quickly than the wild mice, and they reached peak performance much more\nquickly too.\n\nDigging deeper, researchers found that the mutant mice left the start box more\nquickly, required fewer trials to learn, paused less often in the runway, were\nmore resistant to distractions, and proceeded more directly to the goal,\n\nThese results might lead you to believe that mutant mice had an increased\ncapacity for pleasure when compared with the wild mice, hence why they \u2013 the\nmutant mice \u2013 were apparently more eager to obtain the reward.\n\nHowever, in the final part of this experiment, the researchers used taste\nreactivity tests to measure the objective liking reactions of these mice in\nresponse to a sweet sucrose taste. Turns out that these mutant mice did not\nshow enhanced liking reactions at all. In fact, at higher concentrations of\nsucrose, it appeared that the mutant mice liked the sweet taste less than the\nwild mice.\n\nSo, in short: higher extracellular dopamine levels as seen in the mutant mice\nseem to be linked to increased wanting \u2013 i.e. motivation \u2013 but not increased\nliking \u2013 i.e. pleasure.\n\nTldr; the Dopamine Pleasure Hypothesis is almost certainly wrong.\n\n##\n\nDopamine and learning\n\nIn the 70s, when it became possible to completely lesion dopamine pathways in\nthe brain, many experts believed that dopamine's main role was tied to\nmovement and behavioural activation, mainly because lesions of dopamine\npathways resulted in significant reductions in movement. This hypothesis fit\nnicely with the observation that conditions associated with damage to dopamine\nneurons, e.g. things like Parkinsons and Encephalitis, often result in a\nreduction or even complete loss of certain motor functions (2).\n\nUnfortunately, there were a few refractory pieces of evidence that refused to\nfit with this theory. For one, animals with complete dopamine pathway lesions\ncould still swim if you put them in water. Also, akinetic patients with severe\ndamage to their dopamine neurons could still respond if there was a fire alarm\n(2).\n\nThis tension was eventually resolved thanks to a series of pioneering studies\nthat involved recording dopamine neurons in the VTA.\n\nIn one study, Wolfram Schultz and colleagues trained monkeys to expect juice\nat a fixed interval after a visual or auditory cue was presented. For example,\nevery time a specific light flashed, juice would be delivered twenty seconds\nlater. While they were doing this, these researchers recorded the firing rates\nof dopamine neurons in the VTA (8).\n\nThey found that before the monkeys had learned the cues (and the juice was\ntherefore unexpected), dopamine neurons fired above baseline levels when the\njuice was delivered. However, once the monkeys learned that certain cues\npredicted the juice, the timing of the firing changed: neurons no longer fired\nin response to the presentation of the juice \u2013 the reward. Instead, they\nresponded earlier, when the predictive visual or auditory cue was presented,\ne.g. the flashing light (8).\n\nAs I understand things, these findings were initially interpreted as\nconfirming the then-in-vogue movement theory of dopamine, i.e. that the\nrewarding stimuli triggered immediate movements that showed up as spikes in\ndopamine firing (2).\n\nHowever, a number of additional findings from the study pointed to an\nalternative interpretation:\n\n  * If the cue was presented but the reward was withheld, firing paused at the time the reward would have been presented, sending firing rates below baseline.\n\n  * If a reward exceeded expectation or was unexpected (because it appeared without a prior cue), firing rates were enhanced.\n\n  * If the reward was exactly as expected, firing patterns upon receipt of the reward would stay more or less steady \u2013 neither a spike nor a dip.\n\nTaken from Sure (2002) \u2013 \u2018TD Models of reward predictive responses in dopamine\nneurons\u2019\n\nA decade after the paper's original publication, its findings were\nreinterpreted and the Reward Prediction Error (RPE) theory of dopamine was\nborn. Under the RPE view, the absolute size of a reward does not dictate the\nfiring rates of dopamine neurons; instead, it is the difference between the\nsize of the actual reward and the expected reward that counts.\n\nThe RPE idea originated in the computer science field of reinforcement\nlearning, where RPEs were used as a learning signal to update the estimated\nvalues of future rewards \u2013 estimates that could be used to guide future\nbehaviour. Since dopamine cell firing resembles RPEs, and since RPEs \u2013 in the\ncontext of reinforcement learning, at least \u2013 are used for learning, it became\ncommon to think of dopamine as a learning signal.\n\nHere\u2019s a nice diagram to explain how this kind of learning seems to work:\n\nTaken from Berke (2018) \u2013 \u2018What does dopamine mean?\u2019\n\nCircles represent specific states, and the arrows represent potential actions\nfrom those states. Arrow widths represent the learned values of each action.\nIn the second panel, the red circle represents reward and dopamine release,\nwhich then retroactively updates the values of the actions that preceded the\nreward (shown in pink). The bottom panel represents the updated values\n(changes in thickness) that result from the learning that occurred in the\nsecond panel.\n\nSo, to give an example: let\u2019s say that I\u2019m in my bedroom lying on my bed. This\nsituation represents a \u2018state\u2019. I could do a number of things, but my past\nlearning suggests that playing xbox is likely to be the most rewarding thing I\ncan do in this state. I therefore choose to play xbox, and this activity is\nindeed rewarding \u2013 more so than expected \u2013 which results in a dopamine spike.\nAs a result of this dopamine spike, the value associated with playing xbox\nincreases, which means that the next time I encounter this state, I am more\nlikely to select to play xbox once again.\n\nIn addition to nicely explaining the results of the Schultz experiment, the\nRPE theory of dopamine has a number of other things to recommend it:\n\n  * The RPE hypothesis fits nicely with the finding that dopamine modulates plasticity, i.e. cell change, in the striatum. For example, we now know that dopamine release in the striatum (along with a few other coincident factors) causes dendrite spines to grow (2).\n\n  * Addictive drugs also boost striatal dopamine release, so the RPE theory fits in with this too: the drug consistently creates a positive RPE, forcing the brain to continually update its value estimate associated with the drug (2).\n\n  * Even serious akinesia (inability to voluntarily move one's muscles and limbs) can be explained by the RPE theory: lack of dopamine may be treated as a constantly negative RPE that progressively updates all values to zero (2).\n\n  * Also, since these initial experiments, optogenetic studies have confirmed the dopaminergic identity of RPE-coding cells, and showed that they do in fact modulate learning (2).\n\n##\n\nReconciling learning and motivational theories of dopamine\n\nAs far as I can tell, the RPE theory of dopamine has dominated the field for\nthe last twenty to thirty years, but as we saw earlier, there\u2019s also good\nevidence that dopamine is closely tied up with motivation \u2013 i.e. wanting \u2013 as\nwell.\n\nHere's some more evidence in support of that claim:\n\n  * Recent genetic studies have shown that dopamine-deficient mice displayed a complete lack of motivation for engaging in goal-directed behaviours, including feeding (3).\n\n  * Likewise, in dopamine deficient mice, restoration of dopamine signalling in the dorsal striatum results in restored motivation and feeding behaviour (3).\n\n  * Microdialysis (used to measure dopamine concentrations) shows a positive correlation between dopamine in the NA core and locomotor activity (as well as other indices of motivation) (2).\n\n  * Optogenetic stimulation of VTA dopamine cells makes rats more likely to begin work in a probabilistic reward task, as if they had greater motivation (2).\n\n  * Optogenetic stimulation of the SN core dopamine neurons or their axons in dorsal striatum increases the probability of movement. These behaviour effects are observable within a couple hundred milliseconds of optogenetic stimulation (2).\n\nOne reason why it\u2019s been quite tricky interpreting the literature on dopamine\nis that one large part of it seems to only talk about the RPE theory, without\nany mention of the motivation side of things; and the other albeit smaller\npart of the literature does the opposite.\n\nThere are, however, one or two papers that bridge this gap and that point to\nthe possibility \u2013 as well as the difficulty \u2013 of reconciling these two views\n(2).\n\nOne of the traditional ways that neuroscientists have tried to do this is by\narguing that the learning and motivation roles of dopamine happen on different\ntimescales. At baseline, dopamine neurons tend to fire at a few spikes per\nminute \u2013 this is known as tonic firing. When they\u2019re triggered, on the other\nhand, e.g. by a rewarding stimulus resulting in an RPE, their firing rate\nincreases rapidly \u2013 this is known as phasic firing.\n\nThe traditional theory has been that slow changes in tonic firing are\nresponsible for general motivation and that fast phasic firing is responsible\nfor learning.\n\nBut here\u2019s the issue with this \u2018tonic firing = motivation, phasic firing =\nlearning\u2019 theory:\n\nMany of the methods that have been used to establish a relationship between\nslow-changing, tonic dopamine levels and motivation have suffered from\nextremely low temporal resolution. So, for example, with microdialysis, the\nlength of the sampling intervals is usually a couple of minutes, meaning, as I\nunderstand things, that we don\u2019t get fine-grained information about how\ndopamine levels are fluctuating on a second-by-second or even subsecond-by-\nsubsecond basis. In other words, just because microdialysis measures dopamine\nlevels slowly does not mean that these levels are actually changing slowly.\n\nIn a bid to fill this gap in knowledge, Hamid et al examined rat NAc dopamine\nlevels in a probabilistic reward task using both microdialysis and fast-scan\ncyclic voltammetry (a technique with much finer temporal resolution) (2).\nHere\u2019s what they found:\n\nDopamine in the NAc, as measured by microdialysis, correlated with reward rate\n(rewards per minute), but even with improved microdialysis temporal\nresolution, which uses sample intervals of 1 minute, dopamine still fluctuated\nas fast as they could sample it. When they used voltammetry, however, which\nhas a much finer temporal resolution, they observed a tight relationship\nbetween subsecond dopamine fluctuations and motivation.\n\nSo, in essence, dopamine levels, which correlated closely with reward\nrate/motivation, were fluctuating extremely quickly, suggesting that the whole\n\u2018phasic firing = learning, tonic firing = motivation\u2019 theory is probably\nwrong.\n\nBut here\u2019s another cool thing the study showed:\n\nAs rats performed a sequence of actions in order to obtain a reward, dopamine\nlevels rose progressively higher and higher as they moved towards the reward,\nreaching a peak just as they obtained the reward.\n\nThese researchers showed that dopamine levels correlated strongly with\ninstantaneous reward value (or \u2018value\u2019, as they call it), which is defined as\nthe expected reward minus the expected time needed to receive it. It has\ntherefore been suggested that motivation levels are essentially equal to\n\u2018value\u2019.\n\nTo see what all of this looks like in practice, take a look at the chart\nbelow:\n\nTaken from Berke (2018) \u2013 \u2018What does dopamine mean?\u2019\n\nThese findings are consistent with voltammetry results from other studies,\nwhich also showed that dopamine levels climb with increasing proximity to\nreward \u2013 a phenomenon known as ramping.\n\nOne other interesting finding was that as the subjects received cues\nsuggesting that rewards were either larger, closer, or more certain than\npreviously expected, the dopamine ramp shifted upwards \u2013 representing an\nincrease in motivation (see graph below). It has been suggested that these\nupward shifts in the dopamine curves represent what essentially amount to\nRPEs.\n\nTaken from Berke (2018) \u2013 \u2018What does dopamine mean?\u2019\n\nAs such, it seems that dopamine might indicate the value of work \u2013 consistent\nwith which is the finding that dopamine increases with signals instructing\nmovement but not signals instructing stillness, even when such signals\nindicate similar future rewards (2).\n\nInterestingly, this finding actually aligns with many earlier experiments that\nused classical conditioning tasks (like the Schultz one discussed above).\nAfter all, if the task simply involves the animal remaining still while cues\nand rewards are presented to them, then there is no benefit to active work.\nSince dopamine is posited to signal value of work, then dopamine ramps\nobserved by Hamid and others are not expected to occur in these classical\nconditioning studies \u2013 which, of course, they don\u2019t!\n\nOne question you might still have is \u2018how are both of these signals, i.e.\nlearning and motivation, encoded by the same circuitry?\u2019 I don\u2019t want to get\nbogged down in the minutiae here, so I've added a section in the appendix\nwhere I quickly run through an interesting \u2013 and, by the looks of things,\nplausible \u2013 hypothesis as to how this might work. For those interested, see\nthe \u2018Switching between learning and motivation\u2019 section.\n\n##\n\nBringing this all together: What does dopamine mean?\n\nSo, we now know that dopamine appears to encode two things: first, the\nexpected value of a reward, discounted by expected time needed to receive it.\nSecond, reward prediction errors. Or, in other words, motivation and learning.\n\nUnfortunately, digging deeper, microdialysis studies show that dopamine is\nonly correlated with the expected value of a reward in the NAc and\nventromedial frontal cortex, but not in other parts of the striatum and\nfrontal cortex. This kind of finding challenges the idea that there is a\nglobal dopamine message that produces similar effects across the brain.\n\nFrom such observations, we might well conclude that there are all kinds of\ndifferent dopamine functions and that this is just one neurochemical that\nwon\u2019t be corralled into a neat and parsimonious theory.\n\nHowever, thankfully there does appear to be a slightly more elegant\nexplanation that chimes with other things we know and that ties this all much\nmore neatly. Here it is:\n\nEach part of the striatum receives inputs from specific regions of the cortex.\nFor example, the dorsolateral striatum gets inputs from motor regions of the\ncortex; the dorsomedial striatum gets inputs from cognitive parts of the\ncortex, etc. What\u2019s more, each of these striatal subregions shares a common\nmicrocircuit architecture, including separate D1 vs. D2 receptor-bearing\nneurons, cholinergic interneurons, etc.\n\nIt has therefore been proposed, I think quite uncontroversially, that each of\nthese subregions \u2013 although not as sharply separated from one another as\ninitially believed \u2013 processes a specific type of information that has been\nsent down from the associated region of the cortex.\n\nInsofar as this ties into the dopamine stuff we\u2019ve learnt about so far, it\u2019s\nbeen theorised that dopamine signals essentially provide information about how\nworthwhile it is to expend specific types of limited resource at any given\ntime.\n\nFor example,\n\n  * In the dorsolateral striatum, which processes motor information, the limited resource in question is the energy required to move. We know that increasing dopamine in this region makes it more likely that an animal will choose to expend effort to move, so this makes sense.\n\n  * In the dorsomedial striatum, which processes cognitive information, the limited resources are attention and working memory. We know that dopamine, particularly in this region, is important for deciding whether cognitive effort is worthwhile, so this makes sense too.\n\n  * In the NA, which processes motivational information, the limited resource is time \u2013 should I spend my limited time on this or that? We know that dopamine in this region indicates that an effortful, temporally-extended action is worth pursuing, so, again, this makes sense.\n\nAll of this also chimes with something else we know about the basal ganglia, a\nnetwork of nuclei that includes, among other things, the striatum, the VTA/SN,\nand various regions of the cortex (i.e. all the key dopaminergic circuitry).\n\nThe basal ganglia includes two pathways: the direct pathway and the indirect\npathway. Though the circuitry isn\u2019t as neat as we might like, it appears that\nthe direct pathway is responsible for selecting a specific action, whereas the\nindirect pathway is involved in inhibiting all other courses of action.\n\nHere\u2019s a diagram of the basal ganglia\u2019s circuitry (the image on the left was\nwhat they initially believed the circuitry looked like; the one on the right\nis what we now think it looks like):\n\nTaken from Kandel (2021) \u2013 Principles of neural science \u2013 chapter 38: The\nbasal ganglia\n\n(Don\u2019t worry if this image makes little sense to you \u2013 it\u2019s not overly\nimportant for our purposes here. The only thing worth knowing \u2013 which isn\u2019t\nlabelled in this diagram \u2013 is that the direct pathway is represented by the\nlines going from the D1 receptor in the striatum box down to the GPi/SNr box,\nand the indirect pathway is represented by the lines going from the D2\nreceptor in the Striatum box down to the GPe, STN, and GPi/SNr boxes).\n\nAgain, all of this makes intuitive sense:\n\nIf a rat decides that it wants to seek out a piece of cheese, then it cannot\nalso lie around and sleep, it cannot also play with its other rat chums, it\ncannot also drink from a receptacle on the other side of its cage, etc. A\ndefinitive course of action has to be taken, which requires the selection of a\nspecific action as well as the inhibition of all other courses of action.\n\nAnother interesting thing about this circuitry is that direct pathway neurons\nin the striatum seem to exclusively contain D1 receptors, whereas indirect\npathway neurons in the striatum almost exclusively contain D2 receptors. This\nis relevant to some stuff I talk about in the appendix \u2013 e.g. that in drug and\nfood addicts, D2 receptors are downregulated \u2013 but possibly not too\ninteresting for our purposes right here.\n\nSo essentially what seems to happen is that, for example, when dopamine levels\nstart to rise, two things occur:\n\n  1. Dopamine binds to D1 receptors in the striatum, which results in motivation, attention, physical energy, etc., getting assigned to a specific course of action.\n\n  2. Dopamine binds to D2 receptors in the striatum, which works to inhibit the assignment of motivation, attention, working memory, physical energy, etc. to other possible options.\n\nTo add a bit of graphical representation, recall this diagram from earlier\nthat was used to illustrate dopamine\u2019s role in learning :\n\nTaken from Berke (2018) \u2013 \u2018What does dopamine mean?\u2019\n\nIt seems that the RPE signal allows us to update the values associated with\nspecific types of actions, whereas the motivational signal works to invigorate\nspecific, high-value courses of action (represented by a thick arrow) when\nspecific states are encountered. Moreover, while all of this is going on, this\nmotivational signal is also inhibiting all of the other, lower-value actions\nthat are not being selected.\n\nSo, there you have it.\n\nThat\u2019s my best attempt at covering the subject of dopamine.\n\nThere\u2019s still lots we don\u2019t know about the dopamine system, but as this review\nhopefully shows, there\u2019s quite a lot we do now know as well.\n\nI\u2019ve done my best to present the research as I understand it at the moment,\nbut if you feel like I've missed anything or that I've got anything wrong,\nplease do let me know and I\u2019ll do my best to correct any errors.\n\n##\n\nAppendix\n\n###\n\nSwitching between learning and motivation\n\nAs you\u2019ll hopefully know by now, the upshot of this entire post is essentially\n\u2018dopamine is key to both motivation and learning\u2019, but this still begs a\nfurther question:\n\nHow can dopamine mean both of these things at the same time \u2013 especially since\nwe\u2019ve now dismissed the whole \u2018tonic=motivation, phasic=learning \u2019 hypothesis?\n\nWe don\u2019t have a watertight explanation here, but there is some interesting\nspeculation (2):\n\nIt has been suggested that in order to interpret learning and motivational\nsignals appropriately, dopaminergic circuitry may well switch from one mode to\nanother, and that acetylcholine may play a key role in this process:\n\nAt the same time as dopamine cells fire in response to unexpected cues,\ncholinergic interneurons (CINs) in the striatum pause firing. These pauses\ncould be caused by a number of things, including activation by GABA neurons in\nthe VTA, and it\u2019s been proposed that these pauses may open up something like a\nlearning window for striatal plasticity.\n\nWe know that dopamine-dependent plasticity is continually suppressed by\nmuscarinic receptors (which are activated by acetylcholine) in the indirect\npathway, so this all makes good sense.\n\nIn essence, while these CINs are temporarily deactivated, dopamine has the\npower to bring about changes in the striatum, allowing learnings to be\nimprinted into our neural tissue. When these CINs are active, on the other\nhand, dopamine-dependent plasticity is blocked, meaning dopamine\u2019s role is\nlimited to motivating behaviour.\n\n###\n\nAversive and novel stimuli: a couple of other complicating facts\n\nIf you\u2019re still with me, you\u2019re probably sick of all the additional layers of\ncomplexity that have been built into this picture with each passing section.\n\nUnfortunately, here\u2019s another one for you:\n\nThere\u2019s a ton of evidence showing that dopamine neurons not only fire in\nresponse to rewarding stimuli, but also in response to novel and even aversive\nstimuli (11).\n\nDelving deeper, it looks like there are different subpopulations of dopamine\nneurons in the VTA and SN that encode different things. For example:\n\n  * Multiple studies have shown that noxious stimuli presented to anaesthetized animals excite some dopamine neurons but inhibit others (11).\n\n  * Different groups of dopamine neurons have been shown to be phasically excited or inhibited by aversive events, including noxious stimulation of the skin, sensory cues predicting aversive shocks, and sensory cues predicting aversive airpuffs (11).\n\nThis may seem to throw everything that we\u2019ve just said into confusion, but\nthere are some smart researchers that have found a way to make sense of this\nmadness (11). They suggest that there are two broad types of dopamine neurons:\n\n  1. Motivational value encoding neurons \u2013 these neurons encode the value of an event or stimulus using accurate reward prediction errors. Such neurons are strongly inhibited if a reward is omitted and mildly excited if an aversive event is avoided. These are likely the kinds of neurons Schultz et al were recording in the experiment discussed above.\n\n  2. Motivational salience encoding neurons \u2013 these neurons are excited by both rewarding and aversive events. It seems that rather than encode value, they instead encode the motivational salience, i.e. relevance/importance, of an event. These neurons respond when salient events are present, but not when they\u2019re absent.\n\nMotivational value neurons are involved in motivating us to seek out and\nexplore rewarding events \u2013 and also in learning to reproduce behaviours that\nled to rewards in the past.\n\nMotivational salience neurons, on the other hand, allow us to detect, predict,\nand respond to situations of high importance. They may be involved in\norienting our attention and also mustering cognitive control for things like\nworking memory, action selection, etc.\n\nBased on the specific regions of the brain to which these different\npopulations of neurons connect \u2013 which I won\u2019t go into here \u2013 this account\nseems quite plausible.\n\nAs one tiny and final \u2013 I promise \u2013 additional layer of complexity, it turns\nout that the majority of dopamine neurons, including both value- and salience-\nencoding neurons, show burst responses to several kinds of sensory events that\ncan be thought of as \u2018alerting signals\u2019 (11).\n\nThese dopamine alerting signals can be triggered by surprising sensory events\nlike an unexpected auditory click or a light flash, and they\u2019ve been shown to\nproduce burst firing in 60-90% of dopamine neurons across the SN and VTA. The\nsize of the alerting signal seems to reflect the extent to which the stimulus\nis surprising (11).\n\nBringing this all together, then:\n\nDopamine neurons often respond to a stimulus with two signals: a fast,\nalerting signal that encodes whether it is potentially important, and then a\nsecond, slower signal that encodes the stimulus\u2019s motivational meaning \u2013\neither value or salience, depending on the neuron (11).\n\nThese findings add detail and texture to the picture presented above, but I\ndon\u2019t think they conflict with it in a way that forces us to update our broad-\nstrokes understanding of what dopamine is or does.\n\n###\n\nIf dopamine doesn't cause pleasure, why are dopamine-spiking drugs like\ncocaine and amphetamine so pleasant?\n\nWhile going through this literature, one thing that bothered me was that it\nseems like drugs that spike dopamine through one mechanism or other \u2013 things\nlike cocaine and amphetamine \u2013 do actually seem to produce pleasure, despite\nall of this evidence suggesting that dopamine\u2019s relationship with pleasure is\nnot causative.\n\nWhat\u2019s up with that?\n\nI\u2019ve come across some sensible discussion on what might be going on here \u2013\nseems like it could be one of three things (or maybe a combination of them\nall?):\n\nFirst, it might just be that a drug like cocaine makes everything in our\nenvironment appear more appealing.\n\nI\u2019ve seen speculation that certain forms of anhedonia \u2013 including those\nassociated with schizophrenia and depression \u2013 aren\u2019t actually reductions in\npleasure, i.e. liking, but are instead deficits in motivation, i.e. wanting.\nIn essence, nothing seems appealing. Nothing spikes their dopamine levels. As\na result, they can\u2019t bring themselves to do anything.\n\nBeing under the influence of cocaine may just be the complete opposite of\nthis. Everything within our environment glitters with promise and appeal.\nConversations are more interesting, drinks are more drinkable, cigarettes are\nmore smokable. Everything is exciting, and we want to explore it all.\n\nThis experience, while not exactly \u2018liking\u2019, is sufficiently positively\nvalenced as to be interpreted by the cocaine user as pleasureful.\n\nAnother possibility is that this heightened wanting \u2013 and the expanded\nincentive salience that comes with it \u2013 is actually being misinterpreted as\npleasure, when in reality it is just empty wanting that has sufficiently\ndisoriented us to distort our interpretation of how we are feeling.\n\nThis kind of strikes me as plausible as well.\n\nAnd the final explanation is simply that dopamine-spiking drugs cause both\nliking and wanting. This is supported by the fact that drugs like cocaine and\namphetamines result in the elevation of endogenous opioid and GABA signals in\nthe NA \u2013 neurotransmitters associated with liking rather than wanting \u2013 which\ncould very well be producing the sensation of pleasure (6).\n\n###\n\nSome other interesting facts about dopamine that I've come across in my\ntravels\n\nTo tie this off, I'm just going to dump down a load of interesting facts that\nI\u2019ve come across while doing my research for this piece. Here they are:\n\n  * Sleep deprivation seems to downregulate D2 receptors. Given that D2 downregulation is associated with hypofrontality in the form of loss of executive function, impulsivity, etc., it's suggested that this may be a factor worth addressing with addiction treatments. For example, if you can sort out an addict's sleep, bump up those D2 receptor numbers, maybe you can bring the prefrontal cortex back into play (13).\n\n  * VTA dopamine neurons are innervated by parts of the brain associated with maintaining homeostasis, e.g. the hypothalamus. In essence, this means the firing of these VTA neurons can be inhibited or excited based on whether we are hungry, thirsty, etc. This makes sense: if we are hungry, the ability of a Big Mac to motivate us to action should go up \u2013 and it does (3).\n\n  * Using positron emission tomography, researchers found that people who are disposed to experience intrinsically motivated flow states during their daily lives have greater dopamine D2 availability in striatal regions, particularly the putamen (4).\n\n  * Gyukovics et al found that carriers of a genetic polymorphism that affects striatal D2 receptor availability were more prone to experience flow during study and work related activities (4). Combined with the study above and what I talked about earlier wrt the basal ganglia and the direct/indirect pathway, I can\u2019t help but speculate that this is because people with increased D2 expression may be more capable of inhibiting other behaviours/thoughts, allowing for the heightened focus and singularity of purpose that we associate with flow states.\n\n  * Addictive drugs cause downregulation of D2 receptors and opioid receptors in the ventral striatum. This may account for both a reduction in motivation and a reduced capacity to feel pleasure (9).\n\n  * Exercise has been shown to be effective for preventing and treating substance abuses. A rat study showed that exercise seems to reduce the expression of D1 receptors and increase the expression of D2 receptors in certain parts of the striatum (12).\n\n  * Monkeys expressed a strong preference to view informative visual cues that would allow them to predict the size of a future reward (rather than uninformative cues that provided no reward info). Likewise, dopamine neurons were shown to be excited by the opportunity to view the informative cues in a manner that was correlated with the animal's behavioural preference. This suggests dopamine neurons not only motivate actions to gain rewards but that they also motivate actions to gain information that supports making accurate predictions about those rewards (22).\n\n  * In macaque monkeys, the same midbrain dopamine neurons that signal the amount of water expected also signal the expectation of information. Data show that single dopamine neurons process both primitive and cognitive rewards (22). Combined with the study above, this might shine a bit of light on why some of us spend so much time reading/learning \u2013 it looks like our brains respond to certain types of information in the same way that they respond to more typical rewarding stimuli.\n\n  * It's known that the anterior cingulate cortex is implicated in encoding whether an action is worth performing in view of the expected benefit and cost of performing the action. Schweimer et al found that a D1 blockade in this part of the brain resulted in rats preferentially choosing a low-reward, low-effort option vs. a high-reward, high-effort option. Conversely, rats with the D2 blocker in this region performed the same as normal rats. Seems D1 receptors in this region are key for motivated behaviour (15).\n\n  * Lever pressing schedules that have minimal work requirements are largely unaffected by dopamine depletion in the NA, BUT reinforcement schedules that require lots of work are substantially impaired by NA dopamine depletion. Moreover, rats with NA dopamine depletion reallocate their behaviour away from food-reinforced tasks that require lots of energy and towards less-effortful type of food-seeking behaviour. Is this almost the rat equivalent of procrastination (16)?\n\n  * In non-human primates, D2 receptor numbers were measured with PET scans initially while these animals were housed apart and again when they were housed together. Animals that became dominant showed an increase in D2 receptors in striatum, whereas subordinate animals did not. Dominant animals with higher D2 levels self-administered much less cocaine (17).\n\n  * They gave rats that had been previously trained to self-administer alcohol a D2 receptor gene to increase D2 expression. Subsequently, self-administration of alcohol massively fell, until D2 receptor levels returned to baseline, at which point alcohol levels returned to where they had been before (18).\n\n##\n\nReferences\n\nQuick note about my approach to referencing: this isn't an academic paper, but\nI am aspiring to something vaguely approaching rigour. As a result, I wanted\nto include references to support everything I\u2019ve said, but I'm finding the\ntask of doing so quite painful. I'm therefore just going to cite the paper \u2013\nor the textbook chapter \u2013 where I came across a specific fact, so that if you\nwish to follow up on or confirm anything I've written, you can do so without\ntoo much trouble. I realise this is a bit lazy of me, but honestly, this piece\nis never going to get written if I have to cite every single study precisely,\nso this is a lesser of two evils approach. Also, apologies for the weird order\nof references in the text \u2013 don\u2019t ask.\n\n1\\. Pinel and Barnes (2018) \u2013 Biospsychology \u2013 Chapter 15: Drug use, drug\naddiction, and the brain\u2019s reward circuits\n\n2\\. Barker (2018) \u2013 What does dopamine mean?\n\n3\\. Volkow, Wise, and Baler (2017) \u2013 The dopamine motive system: implications\nfor drug and food addiction\n\n4\\. Domenico and Ryan (2017) \u2013The Emerging Neuroscience of Intrinsic\nMotivation: A New Frontier in Self-Determination Research\n\n5\\. Berridge and Kringelbach (2008) \u2013 Affective neuroscience of pleasure:\nrewards in humans and animals\n\n6\\. Berridge and Kringelbach (2015) \u2013 Pleasure systems in the brain\n\n7\\. Volkow, Fowler, and Wang (2003) \u2013 The addicted human brain: insights from\nimaging studies\n\n8\\. Kandel (2021) \u2013 Principles of neural science \u2013 chapter 43. motivation,\nreward, and addictive states\n\n9\\. Berridge and Dayan (2021) \u2013 Liking\n\n10\\. Berridge et al (2003) \u2013 Hyperdopaminergic Mutant Mice Have Higher\n\u201cWanting\u201d But Not \u201cLiking\u201d for Sweet Rewards\n\n11\\. Bromberg-Martin, Matsumoto, and Hikosaka (2010) \u2013 Dopamine in\nmotivational control\n\n12\\. Baik (2013) \u2013 Exercise Reduces Dopamine D1R and Increases D2R in Rats:\nImplications for Addiction\n\n13\\. Volkow et al (2012) \u2013 Evidence That Sleep Deprivation Downregulates\nDopamine D2R in Ventral Striatum in the Human Brain\n\n14\\. Schweimer et al (2006) \u2013 Dopamine D1 receptors in the anterior cingulate\ncortex regulate effort-based decision making\n\n15\\. Salamone et al (2008) \u2013 Effort-related functions of nucleus accumbens\ndopamine and associated forebrain circuits\n\n16\\. Schultz and Baez-Mendoza (2013) \u2013 The role of the striatum in social\nbehaviour\n\n17\\. Thanos et al (2001) \u2013 Overexpression of dopamine D2 receptors reduces\nalcohol self-administration\n\n18\\. Bromberg-Martin and Hikosaka (2009) \u2013 Midbrain Dopamine Neurons Signal\nPreference for Advance Information about Upcoming Rewards\n\nThanks for reading Erring Towards Answers! Subscribe for free to receive new\nposts and support my work.\n\n17 Likes\n\n17\n\nShare this post\n\n#### Dopamine: Everything you need to know\n\nerringtowardsanswers.substack.com\n\n9\n\nShare\n\n9 Comments\n\nJeff KayApr 21Liked by Frazer MawsonReally excellent post. Brings together a\nlot of what I have seen concerning the role of dopamine in substance addiction\nand reward. Very well presented and thought through as much of it has seemed\ncontradictory to my amateur understanding. It does seem that the basic model\ncurrently incorporates the findings of Volkow, Koob, and Berridge/Robinson as\nongoing processes contributing to the addiction cycle.Sadly the recovery\ncommunity is inundated by pop science promising to \u201cboost your dopamine\u201d with\nsupplements and sunshine or dismissing neurobiology and the disease model\naltogether writing it off as normal adaptation to stressors and emotional\npain.I was wondering if it would be OK to post a link to this page on my\nwebsite sobersynthesis.com it is non commercial and just a hobby I started\nwith the goal of providing information to the recovery community.Expand full\ncommentLike (1)ReplyShare  \n---  \n  \n3 replies by Frazer Mawson and others\n\nC.Sobbing At RestaurantsFeb 19Liked by Frazer MawsonGreat post, thank you!It\nmade me think of how across most theories presented here stimuli tend to take\nan \"a priori\" value, and posited as a \"source\" or \"cause\" for different\ndopaminergic mechanisms. I was wondering whether you'd come across (or even if\nit makes sense to you given your research), anything that inverts that\ndirection of causality and instead begins with the availability/amount of\ndopamine in an individual's system?For instance, well-studied mutations to the\nCOMT gene have been found to significantly alter how dopamine is processed and\ntherefore how much dopamine is available at any given time for different\nindividuals. To follow one of your examples, maybe someone with recurrent\nlower-levels of dopamine in their system might develop either hyper-focused\nmotivation (possibly survival based) ie. all their dopamine goes into\nsignalling one particular effort as rewarding but then \"there's not enough\nleft\" to motivate other behaviours, or are simply chronically under-motivated\n(and potentially under-engaged and under-learned?).I know this boils down to\nthe classic, never-ending \"nature vs. nurture\" dilemma, and the answer is\nalmost always \"probably both\", but still worth discussing hopefully.Expand\nfull commentLike (1)ReplyShare  \n---  \n  \n7 more comments...\n\nReady for more?\n\n\u00a9 2024 Frazer Mawson\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}
