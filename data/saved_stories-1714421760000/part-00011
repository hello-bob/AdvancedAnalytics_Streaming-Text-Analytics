{"aid": "40198458", "title": "Answering Legal Questions with LLMs", "url": "https://hugodutka.com/posts/answering-legal-questions-with-llms/", "domain": "hugodutka.com", "votes": 42, "user": "hugodutka", "posted_at": "2024-04-29 14:01:47", "comments": 12, "source_title": "Hugo Dutka", "source_text": "Answering Legal Questions with LLMs - Hugo Dutka\n\n# Hugo Dutka\n\nContact\n\n# Answering Legal Questions with LLMs\n\nApr 29, 2024\n\nIf you asked a lawyer whether ChatGPT could do his job, he would laugh you out\nof the room. The tool is often useful, but can\u2019t handle legal questions end to\nend. It makes up sources, its reasoning can be flawed, and it may overlook key\naspects of the law.\n\nWe decided to tackle this problem at Hotseat. After iterating multiple times,\nimplementing advanced agentic workflows, and testing with dozens of lawyer,\nwe\u2019re certain that the product has glaring limitations and it won\u2019t replace\nany jobs soon. However, we figured out an unintuitive, LLM-only method of\ndoing RAG, and we leveraged it to make LLMs answer complex questions about\nselect EU regulations.\n\nIn this post, you\u2019re going to learn how to implement a system that can perform\nadvanced reasoning over very long documents.\n\n## The Problem\n\nA great answer to a legal question must at least:\n\n  * Be based on sound reasoning;\n  * Quote the source text of the law to be verifiable; and\n  * Take into account all relevant parts of the law.\n\nTo meet these requirements, we had to put the relevant documents in the prompt\n- we couldn\u2019t just hope that the LLM was trained on all of the law. We also\nlimited our scope to a single regulation. It made the problem approachable,\nand we could scale later.\n\nIn our first attempts, we^1 fed the entire 226 pages of the EU\u2019s AI Act into\nGPT-4 and asked a sample question:\n\n> Does the deployment of an LLM acting as a proxy to optimize SQL queries fall\n> within the regulatory scope of the EU\u2019s AI Act?\n\nAnd we found that GPT-4 couldn\u2019t give us a good answer.\n\nA lawyer would start by asking some helper questions:\n\n  1. Does the proxy meet the definition of an AI system?\n  2. Can the proxy be classified as a high-risk AI system?\n  3. Will the proxy process personal or sensitive data?\n\nBut in a single response, GPT-4 couldn\u2019t both break down the question and\nanswer it. The former task requires a high-level analysis of the document, and\nthe latter - low-level focus on details.\n\n## The Solution\n\nWe split answering the question into subtasks.\n\nThe rough idea is to:\n\n  1. Make GPT-4 figure out which subquestions it should ask; then\n  2. Answer each subquestion independently; and\n  3. Aggregate the findings into a single response.\n\n### Breaking Down the Question\n\nTo answer a legal question based on a single regulation, GPT-4 must first find\nthe relevant sections. It requires high-level reasoning across the entire\ndocument.\n\nWe discovered that GPT-4 can complete this task well, provided you prompt it\ncarefully. All the standard prompt engineering guidelines apply. Crucial were:\n\n  * Structuring the document with Markdown. Without it, reasoning over 80,000 tokens wouldn\u2019t work.\n  * Roleplaying. We framed the task as a senior lawyer planning out work for a junior lawyer.\n  * Tokens to \u201cthink.\u201d We gave the model space to produce internal notes about the task - like how it understands the user\u2019s question - before asking for the plan itself.\n\nWe designed the output so it corresponds to a list of subquestions required to\nanswer the main question. Each point is self-contained; it includes specific\ninstructions and references to sections of the document. If a lawyer looked at\nany single step, they could carry it out themselves.\n\nHere\u2019s what GPT-4 gave us:\n\n#### Plan for the Junior Lawyer\n\n  1. Identify Relevant High-Risk Categories:\n\n     * Analyze Annex III for high-risk AI systems to see if the language model fits under any listed categories.\n  2. Examine Requirements for High-Risk AI Systems:\n\n     * Look at Articles 8-15 to understand general requirements for high-risk AI systems.\n  3. ...\n\n(The other 7 points truncated for brevity. Full plan here, and the prompt\nhere.)\n\nThe quality of the plans still surprises me. When we analyzed them for\nquestions from actual lawyers, we found that GPT-4 generally covers all\nnecessary subquestions.\n\n### Answering Subquestions\n\nThe plan is executed by a simple AI agent. In fact, just a single conversation\nthat GPT-4 has with itself.\n\nGPT-4 is prompted with instructions to assume the role of a \u201cmaster agent\u201d\ntasked with answering a legal question based on the pre-generated plan. It can\ndelegate subquestions to \u201cjunior lawyers\u201d - in fact, separate GPT-4 chats - by\ncalling functions.\n\nHere\u2019s an example function call:\n\n    \n    \n    AnnexAnalysis({ \"task\": \"Analyze Annex III for high-risk AI systems to see if the language model fits under any listed categories.\", \"annexes\": [\"Annex III\"], \"legal_question\": \"Does the deployment of an LLM acting as a proxy to optimize SQL queries fall within the regulatory scope of the EU's AI Act?\" })\n\nWe convert such calls into prompts that contain the task, the question, the\nspecified parts of the regulation, and instructions to carry out the task.\nWhatever GPT-4 outputs is fed back into the master chat as the junior lawyer\u2019s\nanswer.\n\nWe preprocess the regulation so that when a call contains a reference to\n\u201cAnnex III,\u201d we know which pages to put into the \u201cjunior lawyer\u2019s\u201d prompt.\nThis is the LLM-based RAG I mentioned in the introduction.\n\nCompared to analyzing the entire AI Act, GPT-4\u2019s reasoning is massively\nboosted when it\u2019s given a clear task and a short context. With a 5k-token-long\nprompt, you can even usually trust the LLM to correctly quote the source,\nwhich is useful to a user verifying the final answer.\n\nWe implemented the master AI agent as a while loop. It goes on as long as\nGPT-4 calls functions, going through the plan step by step. Eventually, after\nall subquestions are answered, it outputs the final answer in a format we can\ndetect with a regex. We then break the loop and return the answer to the user.\n\nYou can see the final answer here, in the \u201cLegal trace\u201d section.\n\nHere\u2019s the master prompt along with function definitions, and here\u2019s the\njunior lawyer\u2019s prompt.\n\n## Results and Limitations\n\nAnswering a question this way takes 5 to 10 minutes and costs about $2 with\nGPT-4.\n\nThe highlight of testing the system with dozens of lawyers was when a GDPR\nspecialist reviewed its answers. The lawyer ranked 8 out of 10 responses as\nexcellent, and the remaining 2 as overly cautious in interpreting the law.\n\nHowever, over the long term, we found that GPT-4 can identify subquestions\nvery well but often can\u2019t answer them correctly. In non-trivial scenarios, it\nmakes logical errors.^2\n\nLawyers also told us that when they answer a question, they rarely touch upon\na single regulation. Not only do they analyze multiple regulations, but they\nalso take into account supporting documents such as various guidelines,\nregulatory technical standards, and court rulings. In contrast, this system\ncan only process a single document at a time.\n\nWe\u2019ve learned that the combination of high latency, faulty reasoning, and\nlimited document scope kills usage. No lawyer wants to expend effort to ask a\ndetailed question, wait 10 minutes for an answer, wade through a 2-pages-long\nresponse, and find that the AI made an error.\n\n## Conclusion\n\nKeeping all the limitations in mind, dividing complex jobs into simple tasks\nimproves the reasoning capabilities of LLMs dramatically.\n\nWhile the system isn\u2019t directly useful for lawyers yet, the underlying\narchitecture can be generalized to other problems. If less-than-perfect\nreasoning and high latency are acceptable, you could use it to answer\narbitrary questions about arbitrary documents.\n\nIf solving such problems is interesting to you, we\u2019re looking for another co-\nfounder. We\u2019re still early, but we\u2019ve learned a ton about how lawyers do legal\nresearch. Our next steps will be focused on semantic search that actually\nworks, helping law firms navigate through thousands of legal documents.^3 If\nyou\u2019d like to build a meaningful product in the legal tech space, please check\nout our request for a co-founder. We\u2019d love to hear from you.\n\n  1. By \u201cwe,\u201d I mostly mean my co-founder, Grzegorz. I was focused on stabilizing the system after he developed a proof of concept. \u21a9\ufe0e\n\n  2. A real error a lawyer found in our system: he asked whether his client\u2019s business falls into the scope of the EU\u2019s Digital Services Act. GPT-4 correctly identified that the business falls into the scope if it qualifies as an \u201cintermediary service,\u201d and one of the subcategories of that is an \u201conline platform.\u201d To qualify as an online platform, a product must have at least 50 million users. GPT-4 correctly identified that the client\u2019s business doesn\u2019t operate such a product, so it\u2019s not an online platform. Therefore, it concluded, the business is not an intermediary service. \u21a9\ufe0e\n\n  3. Yes, we\u2019ll be building yet another AI for PDFs app, but with more focus on accuracy and relevance. We think we can innovate on the UX to deal with the present shortcomings of LLMs. \u21a9\ufe0e\n\n\u00a9 2024 Hugo Dutka\n\n", "frontpage": true}
