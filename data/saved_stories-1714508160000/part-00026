{"aid": "40210534", "title": "Building a self-updating profile README for GitHub (2020)", "url": "https://simonwillison.net/2020/Jul/10/self-updating-profile-readme/", "domain": "simonwillison.net", "votes": 1, "user": "8organicbits", "posted_at": "2024-04-30 12:58:03", "comments": 0, "source_title": "Building a self-updating profile README for GitHub", "source_text": "Building a self-updating profile README for GitHub\n\n# Simon Willison\u2019s Weblog\n\nSubscribe\n\n## Building a self-updating profile README for GitHub\n\n10th July 2020\n\nGitHub quietly released a new feature at some point in the past few days:\nprofile READMEs. Create a repository with the same name as your GitHub account\n(in my case that\u2019s github.com/simonw/simonw), add a README.md to it and GitHub\nwill render the contents at the top of your personal profile page\u2014for me\nthat\u2019s github.com/simonw\n\nI couldn\u2019t resist re-using the trick from this blog post and implementing a\nGitHub Action to automatically keep my profile README up-to-date.\n\nVisit github.com/simonw and you\u2019ll see a three-column README showing my latest\nGitHub project releases, my latest blog entries and my latest TILs.\n\nI\u2019m doing this with a GitHub Action in build.yml. It\u2019s configured to run on\nevery push to the repo, on a schedule at 32 minutes past the hour and on the\nnew workflow_dispatch event which means I get a manual button I can click to\ntrigger it on demand.\n\nThe Action runs a Python script called build_readme.py which does the\nfollowing:\n\n  * Hits the GitHub GraphQL API to retrieve the latest release for every one of my 300+ repositories\n  * Hits my blog\u2019s full entries Atom feed to retrieve the most recent posts (using the feedparser Python library)\n  * Hits my TILs website\u2019s Datasette API running this SQL query to return the latest TIL links\n\nIt then turns the results from those various sources into a markdown list of\nlinks and replaces commented blocks in the README that look like this:\n\n    \n    \n    <!-- recent_releases starts --> ... <!-- recent_releases ends -->\n\nThe whole script is less than 150 lines of Python.\n\n#### GitHub GraphQL\n\nI have a bunch of experience working with GitHub\u2019s regular REST APIs, but for\nthis project I decided to go with their newer GraphQL API.\n\nI wanted to show the most recent \u201creleases\u201d for all of my projects. I have\nover 300 GitHub repositories now, and only a portion of them use the releases\nfeature.\n\nUsing REST, I would have to make over 300 API calls to figure out which ones\nhave releases.\n\nWith GraphQL, I can do this instead:\n\n    \n    \n    query { viewer { repositories(first: 100, privacy: PUBLIC) { pageInfo { hasNextPage endCursor } nodes { name releases(last:1) { totalCount nodes { name publishedAt url } } } } } }\n\nThis query returns the most recent release (last:1) for each of the first 100\nof my public repositories.\n\nYou can paste it into the GitHub GraphQL explorer to run it against your own\nprofile.\n\nThere\u2019s just one catch: pagination. I have more than 100 repos but their\nGraphQL can only return 100 nodes at a time.\n\nTo paginate, you need to request the endCursor and then pass that as the\nafter: parameter for the next request. I wrote up how to do this in this TIL.\n\n#### Next steps\n\nI\u2019m pretty happy with this as a first attempt at automating my profile.\nThere\u2019s something extremely satsifying about having a GitHub profile that\nself-updates itself using GitHub Actions\u2014it feels appropriate.\n\nThere\u2019s so much more stuff I could add to this: my tweets, my sidebar blog\nlinks, maybe even download statistics from PyPI. I\u2019ll see what takes my fancy\nin the future.\n\nI\u2019m not sure if there\u2019s a size limit on the README that is displayed on the\nprofile page, so deciding how much information is appropriate is appears to be\nmainly a case of personal taste.\n\nBuilding these automated profile pages is pretty easy, so I\u2019m looking forward\nto seeing what kind of things other nerds come up with!\n\nPosted 10th July 2020 at 4:41 am \u00b7 Follow me on Mastodon or Twitter or\nsubscribe to my newsletter\n\n## More recent articles\n\n  * Weeknotes: Llama 3, AI for Data Journalism, llm-evals and datasette-secrets - 23rd April 2024\n  * Options for accessing Llama 3 from the terminal using LLM - 22nd April 2024\n  * AI for Data Journalism: demonstrating what we can do with this stuff right now - 17th April 2024\n  * Three major LLM releases in 24 hours (plus weeknotes) - 10th April 2024\n  * Building files-to-prompt entirely using Claude 3 Opus - 8th April 2024\n  * Running OCR against PDFs and images directly in your browser - 30th March 2024\n  * llm cmd undo last git commit - a new plugin for LLM - 26th March 2024\n  * Building and testing C extensions for SQLite with ChatGPT Code Interpreter - 23rd March 2024\n  * Claude and ChatGPT for ad-hoc sidequests - 22nd March 2024\n  * Weeknotes: the aftermath of NICAR - 16th March 2024\n\nThis is Building a self-updating profile README for GitHub by Simon Willison,\nposted on 10th July 2020.\n\ngithub 122 projects 372 graphql 18 githubactions 42\n\nNext: Weeknotes: datasette-auth-passwords, a Datasette logo and a whole lot\nmore\n\nPrevious: Weeknotes: SBA Covid-19 PPP loans, Datasette talks, Datasette plugin\nupgrades\n\n> Wrote this up on my blog: Building a self-updating profile README for\n> GitHubhttps://t.co/M4epbZxdKa\n>\n> \u2014 Simon Willison (@simonw) July 10, 2020\n\n  * Source code\n  * \u00a9\n  * 2002\n  * 2003\n  * 2004\n  * 2005\n  * 2006\n  * 2007\n  * 2008\n  * 2009\n  * 2010\n  * 2011\n  * 2012\n  * 2013\n  * 2014\n  * 2015\n  * 2016\n  * 2017\n  * 2018\n  * 2019\n  * 2020\n  * 2021\n  * 2022\n  * 2023\n  * 2024\n\n", "frontpage": false}
