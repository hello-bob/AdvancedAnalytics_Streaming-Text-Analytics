{"aid": "40274484", "title": "Integrity games: an online teaching tool on academic integrity for undergrads", "url": "https://edintegrity.biomedcentral.com/articles/10.1007/s40979-024-00154-7", "domain": "biomedcentral.com", "votes": 1, "user": "tokai", "posted_at": "2024-05-06 13:33:46", "comments": 0, "source_title": "Integrity games: an online teaching tool on academic integrity for undergraduate students - International Journal for Educational Integrity", "source_text": "Integrity games: an online teaching tool on academic integrity for undergraduate students | International Journal for Educational Integrity | Full Text\n\nLoading [MathJax]/jax/output/SVG/jax.js\n\nSkip to main content\n\nAdvertisement\n\nInternational Journal for Educational Integrity\n\nIntegrity games: an online teaching tool on academic integrity for\nundergraduate students\n\nDownload PDF\n\nDownload PDF\n\n  * Original article\n  * Open access\n  * Published: 02 May 2024\n\n# Integrity games: an online teaching tool on academic integrity for\nundergraduate students\n\n  * Mads Paludan Goddiksen ORCID: orcid.org/0000-0001-9790-1662^1,\n  * Aur\u00e9lien Allard^2,\n  * Anna Catharina Vieira Armond^3,\n  * Christine Clavien^2,\n  * Hillar Loor^4,\n  * C\u00e9line Sch\u00f6pfer^2,\n  * Orsolya Varga^3 &\n  * ...\n  * Mikkel Willum Johansen^5\n\nInternational Journal for Educational Integrity volume 20, Article number: 7\n(2024) Cite this article\n\n  * 85 Accesses\n\n  * Metrics details\n\n## Abstract\n\nIn this paper, we introduce Integrity Games (https://integgame.eu/) \u2013 a freely\navailable, gamified online teaching tool on academic integrity. In addition,\nwe present results from a randomized controlled experiment measuring the\nlearning outcomes from playing Integrity Games.\n\nIntegrity Games engages students in reflections on realistic and relevant\nacademic integrity issues that lie in the grey zone between good practice and\nmisconduct. Thereby, it aims to 1) motivate students to learn more about\nacademic integrity, 2) increase their awareness of the grey-zone issues, and\n3) increase their awareness of misconduct. To achieve these aims, the tool\npresents four gamified cases that lead students through an engaging narrative.\n\nThe experiment to measure learning outcomes was conducted in three European\ncountries, and included N = 257 participants from across natural science,\nsocial science and the humanities. We show that the participants enjoyed\nplaying Integrity Games, and that it increased their sensitivity to grey-zone\nissues and misconduct. However, the increases identified were similar to those\nachieved by the participants in the control group reading a non-gamified text.\n\nWe end by discussing the value of gamification in online academic integrity\ntraining in light of these results.\n\n## Introduction\n\nPromoting academic integrity is central to creating thriving learning\nenvironments in higher education. Furthermore, when students develop academic\nintegrity during their studies, they are more likely to also take integrity\ninto their professional careers (Guerro-Dib et al. 2020; Carpenter et al.\n2004). Academic integrity has been promoted through several strategies in\nhigher education, ranging from sanctions and oversight to preventive measures\nsuch as training and promotion of students\u2019 ethical awareness through honour\ncodes ((McCabe, Trevi\u00f1o & Butterfield 2001).\n\nRecent studies show that a substantial fraction of European undergraduate\nstudents lack knowledge about academic integrity (Goddiksen et al. 2023a).\nThese students\u2019 understanding of basic rules of academic integrity is limited,\nand they struggle to navigate realistic grey-zone situations where the rules\ncannot be applied in a straightforward way. Similar results have been found in\nNorth America (Childers & Bruton 2016; Roig 1997). Given this lack of\nknowledge and skill, strategies to promote academic integrity and prevent\ndeviations from academic integrity should arguably not rely on oversight and\nsanctions. Strategies for promoting academic integrity among students in\nhigher education should also take an educational approach \u2013 an approach\nrecognized by central actors in European higher education (e.g., Lerouge & Hol\n2020).\n\nWe believe that undergraduate students\u2019 lack of knowledge and skill related to\nacademic integrity calls for dedicated training sessions where students are\nintroduced to the rules and norms of academic integrity while at the same time\nbeing trained in navigating the grey-zone dilemmas they are likely to face\nduring their studies. A recent meta-analysis (Katsarov et al. 2022 ) found\nthat academic integrity training is most effective when participants are\nchallenged to \u201cimagine how they would personally deal with ethically\nproblematic situations\u201d (p. 939). Rules and codes of conduct should also be\npresented, but ethically problematic situations should not be reduced to a\nmere application of rules and codes, as such an approach will hamper students\u2019\nability to make real-life judgements (p. 949\u2013951).\n\nThis paper presents, and discusses the effectiveness of, the research-based\nonline teaching tool Integrity Games (https://integgame.eu/), which we\ndeveloped to enable training sessions where students engage personally with\nrealistic dilemmas on academic integrity. The tool is aimed at university\nundergraduate students from all major fields of study, and is available at no\ncost to users and in five different languages: English, French, Portuguese,\nHungarian and Danish.\n\nIn this paper, we first introduce Integrity Games and the ideas behind it\n(Integrity Games Section). Second, we present and discuss the results of a\nrandomized controlled experiment that tested the effect of the tool on a)\nstudents\u2019 sensitivity to grey-zone issues and misconduct, and b) their\nmotivation to learn more about academic integrity (Assessment materials and\nmethods, Results, Discussion Sections).\n\n### Existing online tools\n\nIntegrity Games supplements existing online tools that aim to educate\nundergraduate students on aspects of academic integrity. Studies of eight such\nonline tools were reviewed by Stoesz & Yudintseva (2018) in a review of in all\n21 studies on the effectiveness of academic integrity training. In addition,\nKier (2019) tested Goblin Threat, a gamified online tool on plagiarism\n(https://www.lycoming.edu/library/plagiarism-game/). All nine online tools \u2013\nand almost all the other studies reviewed by Stoesz & Yudintseva \u2013 focus\nexclusively on one (very important) aspect of academic integrity: plagiarism\nand citation practice. In particular, they focus on avoidance of severe\nplagiarism and the introduction of correct citation techniques. All 21 studies\nin the review showed positive results, although, as noted by Stoesz &\nYudintzeva (2018, p. 14), the quality of the evidence was lacking in some\nstudies.\n\nLike other available tools, Integrity Games also covers plagiarism and good\ncitation practice, but, as described in detail in The gamified cases Section,\nit is, to our knowledge, unique among tools aimed at undergraduate students in\nits strong emphasis on grey-zone issues rather than clear-cut misconduct\n(defined in detail in The gamified cases Section). Furthermore, Integrity\nGames incorporates a broader take on academic integrity as relating not just\nto citation and plagiarism, but also to collaborative practice and working\nwith data.\n\nWhile tools for training academic integrity aimed at undergraduate students\nlack focus on grey zones, online teaching tools on research integrity aimed at\nearly career researchers often have a particular focus on grey zones (for a\ncollection of tools see: https://embassy.science/wiki/Main_Page). Examples\ninclude the Dilemma Game (https://www.eur.nl/en/about-eur/policy-and-\nregulations/integrity/research-integrity/dilemma-game) developed by\nresearchers at Rotterdam University. While there is some overlap in the\nintegrity issues faced by early career researchers and undergraduate students,\nthe overlap is not complete, and the issues of integrity play out differently\nat different levels. For instance, while both undergraduate students and early\ncareer researchers may face integrity issues when collaborating with peers,\nthe specifics may be significantly different (partly because authorship has\nvery different functions in teaching and learning compared to research).\nTrying to teach academic integrity to undergraduates using material designed\nfor early career researchers therefore risks alienating the students from the\ntopic. This is especially true for students who have no ambition to become\nresearchers. So, although the approach in Integrity Games is similar to some\ntools on research integrity, it is unique in its focus on grey-zone issues\nfaced by undergraduate students.\n\nIn addition to teaching tools that focus on academic and research integrity,\nthere are a range of online teaching tools that focus on other aspects of\nethics training for undergraduates. One such tool is Animal Ethics Dilemma\n(http://www.aedilemma.net/), a highly successful platform on animal ethics\naimed at undergraduate students, which at the time of writing has over 100,000\nregistered users (Hanlon et al. 2007). Like the Rotterdam Dilemma Game\nmentioned above, Animal Ethics Dilemma engages players in ethical reflection\nby presenting a series of dilemmas, but unlike the Dilemma Game, Animal Ethics\nDilemma sets the dilemmas in engaging narratives that change depending on the\nchoices made by the player. This structural feature was a major inspiration\nfor the structure of Integrity Games (see Integrity Games Section).\n\n### Gamification of online tools\n\nLike other online tools on academic integrity, Integrity Games is partially\ngamified. There seems to be a trend towards gamification of online training.\nThe tutorial Goblin Threat mentioned above is an example in point, as are the\ngames recently developed by the BRIDGE project\n(https://www.academicintegrity.eu/wp/bridge-games/). There is conflicting\nevidence on the effect of gamified teaching. Recent reviews on the effect of\ngamified teaching by Bai, Hew & Huang (2020) and van Gaalen et al. (2021)\nindicate moderately positive effects on average, but also substantial\nvariations. Bai, Hew & Huang (2020) found that the characteristics shared by\nmost successful gamified teaching are that they involve some kind of scoring\nwhere the player earns points and a badge upon completion, and players are\nable to compare their performance to that of other players via a leader board.\nKeeping a score is one of six factors suggested by Anneta (2010) that\ncontribute to making gamified teaching successful. The other factors include\nidentity, which refers to the game\u2019s ability to \u201ccapture the player\u2019s mind\ninto believing that he or she is a unique individual within the environment\u201d\n(ibid, p. 106). When combined with a clear goal of the game, identity can lead\nto immersion where the player is intrinsically motivated to succeed in the\ngame. In addition, the game should be interactive, it should show increasing\ncomplexity as the player proceeds, and provide relevant feedback to the player\nafter completing a task. As described in The gamified cases Section, Integrity\nGames incorporates all of these elements to some extent, except for the\nscoring element.\n\nAlthough there is some evidence for the effect of the gamified tools on\nacademic integrity mentioned above, this evidence does not allow us to assess\ntheir effectiveness relative to non-gamified training. We therefore have\nlittle empirical evidence to help us decide between gamified and non-gamified\napproaches to academic integrity training. Given this lack of evidence, we\ndecided to include a control group in our experiment who received non-gamified\nteaching that covered the same topics as Integrity Games to see which form of\nteaching would perform better (Assessment materials and methods Section).\n\n## Integrity Games\n\nThe core of Integrity Games (https://integgame.eu/) is four gamified cases\npresented in The gamified cases Section. In addition, the platform contains a\ndictionary of central concepts, a user guide for teachers, and an optional\nquiz designed partly to provide personalized suggestions on what cases to\nplay, and partly to spark curiosity about the topics covered. The potential of\nthe quiz to nudge players to spend more time on the games was explored in a\nseparate experiment (Allard et al. 2023).\n\n### The gamified cases\n\nCases, be they historical or fictional, are a standard tool in integrity\nteaching. Typically, cases describe specific situations where academic\nintegrity is at stake and encourage students to discuss appropriate actions.\nCases are valuable in academic integrity training partly because they can help\nstudents develop ethical sensitivity and train their ability to navigate grey-\nzone issues (Katsarov et al. 2022; Committee on Assessing Integrity in\nResearch Environments 2002, Ch. 5). Integrity Games builds on this well-known\napproach and adds some gaming elements.\n\nThe cases are fictional, but the dilemmas presented in them are drawn from an\nextensive empirical knowledge base originating from a mixed-methods study of\nstudents\u2019 understanding and experiences with academic integrity. The study\ninvolved more than 6,000 students (including 1,639 undergraduate students)\nfrom universities in nine European countries, representing all faculties (some\nresults are reported in Johansen et al. 2022; Goddiksen et al. 2023a; 2023b;\n2021). This research, combined with the existing literature (particularly Roig\n1997, Johansen & Christiansen 2020, and Childers & Bruton 2016), and the\nteaching experience of the authors formed the research basis for the\ndevelopment of the cases. The research base helped ensure that the dilemmas\npresented in the cases are among those that students within the target groups\nare most likely to face during their studies.\n\n#### Contents of the cases\n\nThe four cases that are currently in Integrity Games cover three central\ntopics under academic integrity:\n\n  1. 1.\n\nCitation practice\n\n  2. 2.\n\nCollaborating with, and getting help from, others\n\n  3. 3.\n\nCollecting, analysing, and presenting data\n\nFor each topic, academic integrity training may cover clear examples of good\npractice, obvious misconduct and the grey zones in between \u2013 often called\ndetrimental or questionable practices.\n\nMisconduct refers to the most severe deviations from good practice. Misconduct\nwill typically be defined in an institution\u2019s disciplinary rules and codes of\nconduct, which may in turn be based on national and international codes (e.g.,\nALLEA 2017, or WCRI 2010). For researchers, misconduct is often narrowly\ndefined as plagiarism, falsification and fabrication (ALLEA 2017), but for\nundergraduate students misconduct will also cover other forms of intentional\ncheating, including cheating in tests and exams. Although Integrity Games\nincludes examples of clear-cut misconduct, it focuses primarily on\nquestionable practices.\n\nQuestionable practices are questionable in the sense that their ethical\nacceptability often depends heavily on the context. One example is deleting\ndeviating data points from a report on an experiment (Johansen & Christiansen\n2020). Is this ethically acceptable? As illustrated in two dilemmas in\nIntegrity Games, the answer to this question depends heavily on why and how\nthe deleting was done. If a student deletes deviating data without being\ntransparent about it in order to avoid having to discuss it in the report, it\nwould be akin to misconduct in the form of falsification. If, on the other\nhand, a student deletes deviating data based on an informed discussion with\nthe instructor where they have identified a clear error in the measurement,\nthe practice may be perfectly acceptable.\n\nIn addition to their context dependence, questionable practices are, in many\ncases, characterized by being less severe deviations from good practice than\nclear-cut cheating (Ravn & S\u00f8rensen 2021). They may not even be covered by\nlocal disciplinary rules. Freeriding in group work, for instance, will in many\ncases not be directly against a specific disciplinary rule, but is in many\ncontexts still unethical, as it gives the free rider an unfair advantage, is\ndetrimental to the free rider\u2019s learning, and potentially also to the learning\nof the fellow group members.\n\nWhen local disciplinary rules cover questionable practices, they can be harder\nto apply to concrete instances, partly due to the above-mentioned context\ndependence (Schmidt 2014). Additionally, the enforcement of rules on\nquestionable practices may be less consistent, and the sanctions will\ntypically be less severe. It is therefore more likely that students will end\nup in trade-off situations between, on the one hand, the risk of sanctions and\nblame from the institution that comes with deviating from good practice and,\non the other hand, the risk of negative consequences of, for example, failing\nan exam or standing up against a fellow student. These trade-off situations\nhave previously been shown to be among those that students find particularly\nethically challenging (Goddiksen et al. 2021).\n\nBy focusing mainly on questionable practices, we hoped that the cases in\nIntegrity Games would encourage reflection on both compliant practice, good\npractice, ethically acceptable practice and the potential differences between\nthese. As discussed further in Intended use and learning outcomes Section, the\nreflections that Integrity Games is designed to inspire are not sufficient to\ndevelop the knowledge and competences to navigate real-life situations where\nintegrity is at stake. As a minimum, students should always be given the\nopportunity to ask questions and discuss how rules and norms apply to their\nspecific institutional and disciplinary context. Integrity Games is thus not\nintended to be a stand-alone tool that can replace classroom sessions. It is\ndesigned to be combined with other types of teaching.\n\nThe cases are constructed such that each case focuses on one of the three\nthemes mentioned above. To enable students from a broad range of study\nprogrammes to relate to the dilemmas, the tool includes two different cases on\ncollection, analysis and presentation of data; one was designed to be\nrelatable for students working primarily with qualitative data (e.g.,\ninterview data) and one was designed for students primarily working with\nquantitative data (e.g., numerical data from laboratory experiments). Although\nthere is overlap, the two cases are also different. For instance, the case on\nquantitative data includes dilemmas related to the collection and\ninterpretation of personal data and potentially sensitive data.\n\nThe case on citation practice covers topics such as appropriate paraphrasing,\nself-plagiarism, plagiarism of ideas and responsibility when suspecting\nplagiarism by others.\n\nThe case on collaboration covers issues such as freeriding in group work,\nvarious ways of getting help on individual assignments, and one\u2019s\nresponsibility in cases when other group members deviate from good practice.\n\n#### Structure of the cases\n\nThe cases are constructed using a branching narrative structure (Fig. 1), and\ndraw on basic dramaturgical principles for engaging writing (Egri 1972; Pearce\n1997). Each case starts with a concrete situation where the player is faced\nwith a realistic, relatable dilemma involving academic integrity. The\nsituation is described in the first-person present tense (\u201cYou are writing an\nassignment ...\u201d) and always includes an element of tension or conflict. In\naddition, there is often an element of pressure such as an upcoming exam or\nthe need to impress a future supervisor. The presentation of the situations is\ndesigned to create identification and immersion (two of the characteristics of\neffective gamified teaching described in Gamification of online tools\nSection). To proceed in the case, the player has to choose between two or\nthree pre-defined reactions to the dilemma. When the player has made their\nchoice, they are given immediate feedback \u2013 another gamification element \u2013 in\nthe sense that they are informed of the immediate consequences of her choice.\nFor instance, if the player decides that the best reaction to having\ndiscovered a group member has plagiarized is to tell their teacher about this\ndiscovery, they are told that the teacher praised their decision, but their\ncollaboration in the group was strained, and the group member was angry with\nher. Of course, this is not what will always happen, but it is a possible\noutcome of the choice. This approach to giving feedback \u2013 describing\nconsequences, rather than telling the player that they gave a correct or\nincorrect answer \u2013 is to our knowledge unique among online teaching tools on\nacademic integrity. We took this approach for several reasons. Firstly, there\nis not one way of handling many of the dilemmas presented to the students that\nis clearly the correct way, just as there are no simple solutions to the\nintegrity dilemmas that face the students in real life. This is an important\nmessage to get across. Secondly, by describing consequences, the game avoids\njudging the player. Further, the focus on consequences makes it possible to\nshow that doing the right thing sometimes has a cost. For instance, reporting\ncheating may be the right thing to do in some cases, but it may come at a cost\nto the relationship between the one who reported and the one who cheated\n(Goddiksen et al. 2021).\n\nFig. 1\n\nThe branching structure of the cases\n\nFull size image\n\nThe pages describing the consequence of a choice also include an expandable\ntextbox called \u201cAbout your choice\u201d. The textbox takes the concrete dilemma\nthat the player has just faced to a more general level. For instance, the case\non collaboration starts with a dilemma about a specific instance of group work\nand a specific person, the player\u2019s good friend Kim, who is not contributing.\nThe concrete dilemma is one version of a more general issue with free riders\nin group work. This is explained in the \u201cAbout your choice\u201d textbox, where the\nplayer is also challenged to consider to what extent the specifics of the\ndilemma matter for their choice. Would they, for instance, chose differently\nif Kim had not been a close friend, but a more distant classmate? The \u201cAbout\nyour choice\u201d texts are thus designed to help the player realize that the\ndilemma they just faced is an example of a more general issue that can take\ndifferent forms depending on the context, and that, in some cases, the context\nis central to the choices they make.\n\nThe second and third dilemma presented to the player depend on the player\u2019s\nprevious choices in two ways. Firstly, the dilemmas are the direct result of\nthe player\u2019s previous choices. This gives the player a sense of being part of\na narrative where a story unfolds and choices have consequences. Secondly,\nplayers who make choices that indicate sensitivity to the norms of academic\nintegrity in one dilemma are given a more subtle dilemma in the next level\n(building on the gaming characteristic increased complexity mentioned in\nGamification of online tools Section). Conversely, players who choose against\nthe norms of academic integrity in one dilemma are faced with a subsequent\nchoice that involves more severe breaches of the norms in the following\ndilemmas. Players are thus faced with dilemmas that match their knowledge and\nsensitivity to academic integrity norms throughout the cases.\n\nWhen the player has seen the consequences of the choice made in the first\ndilemma, the narrative continues, and the player is presented with a new\ndilemma which is again followed by a page describing the consequences of the\nchoice made and an \u201cAbout your choice\u201d text. When the player has answered\nthree dilemmas the case ends, and the player is presented with the final\nresult in the form of a conclusion to the story. The cases do not have inbuilt\nnotions of \u2018winning\u2019 or \u2018losing\u2019, nor does the player get any kind of score.\nIn this sense, Integrity Games is a simulation, not a serious game (Annetta\n2010).\n\nThroughout the cases, a mouseover function allows the player to access\ninformation on central concepts from a dictionary built into Integrity Games.\n\n### Intended use and learning outcomes\n\nIntegrity Games is highly flexible and can be incorporated into teaching\nsessions in several ways. The uses discussed in the teacher manual\n(https://integgame.eu/forTeachers) include:\n\n  * Playing selected cases as part of the preparation for a session on academic integrity,\n\nPlaying selected cases, individually or in groups, during a session on\nacademic integrity.\n\nAdditionally, the platform allows access to the individual dilemmas through\nthe \u201cdilemmas\u201d tab in the main menu. A teacher may thus consider assigning\nspecific dilemmas for consideration as either preparation or as an exercise\nduring class. This has the benefit that all students will have considered the\nsame dilemmas, which will not be the case if they play through the cases on\ntheir own (as the dilemmas they face depend on the choices they make).\n\nThe tool was designed with the dual aim of 1) motivating students to learn\nabout academic integrity and 2) developing students\u2019 competencies about\nintegrity issues. Concerning the latter, for each of the three themes\ndescribed above (The gamified cases Section), the tool aims to contribute to\nthe development of competences that enable students to act with integrity in\nreal-life situations where academic integrity is at stake, including grey-zone\nsituations. Following Stephens and Wangaard (2016), these competences include:\n\n  * Sensitivity: Being able to identify and distinguish misconduct and grey-zone issues and knowing when it is one\u2019s responsibility to act,\n\n  * Skills in identifying appropriate actions, and\n\n  * Will and courage to act.\n\nFollowing Goddiksen & Gjerris (2022), both sensitivity and skills in\nidentifying appropriate actions when facing grey-zone situations include a\nsubstantial knowledge component. For each of the three topics described in The\ngamified cases Section, Integrity Games was designed with the aim of\ncontributing to the construction of:\n\n  * Knowledge of the core academic integrity values and principles and how they are applied,\n\n  * Knowledge of common grey-zone issues and the reasons why they are \u2018grey\u2019.\n\nIntegrity Games was not developed directly to develop will and courage in the\nplayers to act with integrity in real-life situations, although developing\nsuch will and courage may sometimes be a positive side-effect of gaining\nknowledge and sensitivity (Goddiksen & Gjerris 2022).\n\nThe randomized controlled experiment described in the following sections was\ndeveloped to test the extent to which the aims related to motivation and\nsensitivity are realized when students play Integrity Games as part of a class\non academic integrity.\n\n## Assessment materials and methods\n\n### Hypotheses tested in the experiment\n\nThe experiment described below was designed to test six hypotheses about the\nlearning outcome from an intervention consisting of playing two cases in\nIntegrity Games followed by a short group work session simulating a classroom\ndiscussion (details in Study intervention Section). The first three hypotheses\nconcerned the participants\u2019 absolute outcome of playing the cases:\n\n  1. 1.\n\nMotivation: We hypothesized that the participants would be more motivated to\nlearn more about academic integrity after the intervention.\n\n  2. 2.\n\nSensitivity to grey-zone issues: We hypothesized that participants would be\nmore sensitive to the existence of grey-zone issues after the intervention.\n\n  3. 3.\n\nSensitivity to misconduct: We hypothesized that participants would be more\nsensitive to misconduct after the intervention.\n\nThe last three hypotheses concerned the outcome of playing the cases relative\nto traditional integrity teaching. We hypothesized that the participants who\nhad received the intervention would show a greater improvement on all three\nparameters (motivation, sensitivity to grey-zone issues, and sensitivity to\nmisconduct) than participants in a control group who had engaged in the same\ngroup discussions, but read a non-gamified text covering the same topics\n(Appendix C) instead of playing Integrity Games (see Study intervention\nSection).\n\n### Ethical approval and recruitment\n\nPrior to recruitment, the experiment was reviewed by the relevant research\nethics committees at the three participating universities: in Denmark, the\nResearch Ethics Committee for Science and Health at the University of\nCopenhagen approved the study (Ref: 504\u20130238/21\u20135000 Decision date:\n02.02.2021), and in Switzerland, the Geneva Commission Cantonale d\u2019Ethique de\nla Recherche approved the study (Req-ID: 2020\u201301397. Decision date:\n01.04.2021). In Hungary, studies such as this one are not subject to ethical\napproval, but the Regional Ethics Committee did acknowledge the study\n(Registration ID: DE/ KK RKEB/IKEB 5660\u20132021, decision date: 02.08.2021).\n\nData were collected from February to November 2021 in 12 different course\nsessions (4 in Denmark, 6 in Switzerland, and 2 in Hungary). Each session\nlasted 2*45 min. At the beginning of the session, students were informed about\nthe study\u2019s aims and procedure, and could choose between participating in the\nstudy or not. Students who decided to participate checked a consent box in the\nanonymous online questionnaire that was part of the course procedure\n(Materials Section). Since the questionnaire included questions that were\npedagogically meaningful, participants who did not wish to participate in the\nstudy were asked to respond to an identical questionnaire from which no data\nwas stored. With this procedure, we made sure that all students received the\nsame teaching content and that anonymity was guaranteed: teachers and\nresearchers could not know which student participated in the study, nor could\nthey trace participants\u2019 responses to individual students.\n\n### Participants\n\nParticipants were recruited among students in mandatory or elective courses on\nethics and philosophy of science at three major European research\nuniversities: the University of Copenhagen, the University of Debrecen and the\nUniversity of Geneva.\n\nIn Denmark, participants were recruited among students in three mandatory\nphilosophy of science courses for students in undergraduate programmes in\nagricultural economics, biotechnology, food science and natural resource\nmanagement. These courses already contained a session on academic integrity,\nand one of the authors was allowed to take over the session to test the tool.\n\nIn Hungary, participants were recruited in mandatory bioethics courses for\npharmacy and dentistry students.\n\nIn Switzerland, participants were recruited among students following elective\ncourses in applied ethics, bioethics and epistemology of science, designed for\ninterdisciplinary groups of students in philosophy, biology, biochemistry,\npharmacy, neuroscience, and medicine. The intervention used in this study\nreplaced a lesson ordinarily dedicated to academic integrity.\n\n### Study intervention\n\nAll intervention sessions followed the same detailed schedule (described\nbelow, further details in Appendix A). Sessions in Denmark were conducted by\nMG in Danish. Sessions in Switzerland were conducted by AA, CC, and CS in\nFrench. ACVA and OV conducted the sessions in Hungary in Hungarian and\nEnglish.\n\nAll sessions took place online using the Zoom video conferencing platform (due\nto the ongoing COVID-19 pandemic). After a brief introduction, about 10 min,\non what academic integrity means, and why it is important, we informed\nstudents about the aim of the experiment and the procedure of the study. We\nmade it clear that participation in the study was anonymous and voluntary. We\nused the same introductory slides in each session.\n\nAfter the introduction, we provided a link to the anonymous questionnaire in\nwhich participants could express whether they consented to participating in\nthe study and take the pre-test (Materials Section). Thereafter, we randomly\ndivided all participants into two breakout rooms using the inbuilt \u201cAssign\nautomatically\u201d function in Zoom. Each breakout room was then given\ninstructions separately. Participants in the treatment group were instructed\nto go to Integrity Games and play the \u201ccollaboration case\u201d and the \u201cplagiarism\ncase\u201d. Participants in the control group were instructed to read a text on\nintegrity issues related to collaboration and plagiarism (See Appendix C).\nAfter 25 to 30 min of completing these individual tasks, participants in both\ngroups were subdivided again in groups of 2\u20133 participants (participants from\nthe control and intervention groups were not mixed). The groups were given the\ntask of discussing integrity issues for 25 to 30 min based on a discussion\ngrid (see Appendix A). To minimize the confounding effect of the different\ninstructors, the instructors did not partake in these discussions. Thereafter,\nparticipants took the post-test (10 min). Finally, all participants joined the\nmain session for concluding remarks by the instructor.\n\n### Materials\n\nWe designed the online questionnaire (presented in Appendix B) as a pre- and\npost-test with some questions being asked twice. Questions were designed to\nobtain information about participants\u2019 motivation to learn about academic\nintegrity and their sensitivity to grey-zone issues and misconduct. In\naddition, the post-test included questions on demographics (gender, age,\ncountry of study, and study direction), two questions relating to the user\nexperience of the integrity website, and five questions relating to the\nexperience of the group work (the latter are not reported in this paper).\n\nTo assess participants\u2019 motivation to learn, we used a battery of questions\nadapted from the relevant subset of the Intrinsic Motivation Inventory (CSDT\n2021) that deals specifically with students\u2019 motivation to learn more. The\nbattery contained six claims about the relevance and value of academic\nintegrity training, which participant evaluated using a five-point Likert\nscale from \u201cfully agree\u201d to \u201cfully disagree\u201d. There was also an option to\nanswer \u201cI don\u2019t know\u201d. Examples of claims include \u201cI believe that\nparticipating in teaching on academic integrity could be of some value to me\u201d\nand \u201cI think learning about academic integrity is not important for my future\nstudies\u201d (see Appendix B for complete list). Additionally, we asked\nparticipants to indicate how many hours they would be willing to spend on\nacademic integrity training (not reported).\n\nTo assess participants\u2019 sensitivity to grey-zone issues and misconduct, we\nexpanded on the approach employed by Goddiksen et al. (2023a): in random\norder, the participants were presented with descriptions of ten different\nactions (see Table 1) and were asked whether they would \u201cviolate the rules\nthat apply to them\u201d. All questions called for answers picked from among five\nanswer options: \u201cYes, it is a violation\u201d, \u201cNo, it is not a violation\u201d, \u201cI\ndon\u2019t know\u201d, \u201cThe rules are unclear\u201d and \u201cIt depends on the situation\u201d. These\ntwo latter answer options allowed the participant to indicate that an action\nis in a grey zone.\n\nTable 1 Actions presented to the participants and their classification\n\nFull size table\n\nThe actions were constructed such that for the actions in the column with\nacceptable practices in Table 1, the most correct answer to whether the\nactions are against the rules would be \u201cNo, it is not a violation\u201d. For the\nactions in the column with non-compliant practices, the most correct answer\nwould be \u201cYes, it is a violation\u201d, whereas the most correct response to the\nactions in the grey-zone practices would be either \u201cThe rules are unclear\u201d or\n\u201cIt depends on the situation\u201d (we did not distinguish between these two\ncorrect answers for grey-zone practices in our data analysis).\n\nThe questionnaire and the text for the control group were translated from\nEnglish into the students\u2019 relevant languages: Danish, Hungarian, or French.\n\n### Data analysis\n\nTo develop a \u2018Motivation-for-Academic-Integrity Score\u2019, we first scored the\nmotivation questions on a scale of 1 to 5, with 5 indicating the highest level\nof motivation. For instance, answering \u201cfully agree\u201d to the question \u201cI\nbelieve that participating in teaching on academic integrity could be of some\nvalue to me\u201d would be coded as 5, while answering \u201cfully disagree\u201d would be\ncoded as 1. We then averaged the scores for the six questions.\n\nWe constituted a \u2018Sensitivity-to-Misconduct Score\u2019 by coding each participant\nanswer as 0 if the participant chose an unjustifiable option, and 1 if the\nparticipant chose a justifiable answer. We then averaged the participant\u2019s\nscore, so that the final score represents the percentage of questions that the\nparticipant answered correctly. We proceeded similarly to constitute a\n\u2018Sensitivity-to-Grey-Zones Score\u2019.\n\nTo analyse the three scores for which we have both a pre- and post-\nexperimental measure, we used a linear mixed-effect model using the R package\nlmer (Bates et al. 2015), using a random intercept nested within participants,\nand predicting the score using country of study, time (before the experiment\nvs. after the experiment), experimental condition, and an interaction between\ntime and experimental condition as fixed effects. We were interested in\ndiscovering whether participant scores increased between the pre-test and the\npost-test, regardless of the intervention, and in knowing whether the final\nscore was higher in the Integrity Games group than in the control group. Thus,\nthe two coefficients of interest are the effect of time, and the interaction\nbetween time and experimental condition. Descriptive statistics were used\n(mean and SD) to describe baseline characteristics of both groups.\n\n## Results\n\nIn total, 408 participants started the experiment, 272 finished it. Among the\nparticipants who completed the post-test questionnaire, 128 were from Denmark,\n63 from Switzerland, 81 from Hungary. Of these 272 participants, 157 were in\nthe control group, and 115 were in the intervention group. There were\nstatistically significantly less participants in the intervention group,\nindicating a possible failure of randomization or differential attrition\n(proportion=0.42, 95% CI [0.36, 0.48], p=.013).\n\nUsing the items of the motivation score, we excluded participants who had a\nMahalanobis distance greater than the 99% predicted percentile based on the 12\nitems (including items from pre-test and post-test). This procedure led to the\nexclusion of 15 participants. We considered that a high Mahalanobis distance\nwas likely a sign of inattention (for instance, a high Mahalanobis distance\ncould indicate that participants provided divergent answers on items that are\nhighly correlated). Our final sample size for all analyses was 257\nparticipants.\n\nTable 2 shows the demographics of the control and intervention groups.\n\nTable 2 Demographic and dependent variables by groups. For numeric variables,\nthe indicated numbers represent the Mean (SD)\n\nFull size table\n\n### Enjoyment and recommendation of the tool\n\nAs can be seen from Table 2, participants gave a mean agreement of 4.1 out of\n5 (95% CI [3.9, 4.3]) with the claim \u201cI would recommend 'Integrity Games' to\nteachers preparing classes on academic integrity for undergraduate students\u201d,\nand indicated a mean agreement of 4.0 (95% CI [3.8, 4.1]) with the claim\n\u201cPlaying through the cases in 'Integrity Games' was fun\u201d.\n\n### Motivation to learn\n\nEven before starting the sessions, participants were, on average, fairly\nmotivated to learn more about academic integrity, with a mean motivation of\n3.8 (with 5 being the highest possible score) in the pre-test. The sessions\ndid not result in significant changes in the participants\u2019 motivation to\nlearn. Across the experimental conditions, on average, participants did not\nsignificantly change their motivation to learn more about research integrity\n(b= 0.00, 95\\mathrm{\\% CI }\\left[-0.05,0.06\\right], t\\left(255\\right)=0.12,\np=.909. For further details, see Table 3). Moreover, the motivation of\nparticipants in the intervention group did not increase significantly more\nthan participants in the control group (b= -0.03, 95\\mathrm{\\% CI\n}\\left[-0.11,0.06\\right], t\\left(255\\right)=-0.58, p=.564. For further\ndetails, see Table 3).\n\nTable 3 Predicting motivation score, based on experimental condition, time and\ncountry\n\nFull size table\n\n### Sensitivity to grey zones\n\nParticipants generally showed a poor understanding of grey-zone issues in the\npre-test. Students in the intervention group on average scored 0.28 and\nparticipants in the control group on average scored 0.27 in the pre-test (with\n1 being the optimal score and 0 being the worst possible score) (see Table 2).\n\nAcross both experimental conditions, participants improved their sensitivity\nto grey-zone issues (b = 0.18, 95% CI \\left[0.12,0.23\\right],\nt\\left(255\\right)=6.33, p<.001. For further details, see Table 4). However,\nthe Sensitivity-to-Grey-Zones score of participants in the Integrity Games\nintervention group did not increase significantly more than that of\nparticipants in the control group (b= -0.01, 95\\mathrm{\\% CI\n}\\left[-0.09,0.08\\right], t\\left(255\\right)=-0.22, p=.827. For further\ndetails, see Table 4.\n\nTable 4 Predicting sensitivity-to-grey-zones scores, based on experimental\ncondition, time, and country\n\nFull size table\n\n### Sensitivity to misconduct\n\nAlready in the pre-test, participants generally showed a good understanding of\nthe questions about non-compliant practice. Students in the intervention group\non average scored 0.65 and participants in the control group on average scored\n0.61 in the pre-test (with 1 being the optimal score and 0 being the worst\npossible score). Both groups improved slightly from pre-test to post-test\n(b=0.09, 95\\mathrm{\\% CI }\\left[0.06,0.12\\right], t\\left(255\\right)=5.30,\np<.001. Further details in Table 5), with both groups scoring an average of\n0.7 in the post-test (Table 2). However, the Sensitivity-to-Misconduct Score\nof participants in the Integrity Games intervention group did not increase\nsignificantly more than that of participants in the control group (b=-0.03,\n95\\mathrm{\\% CI }\\left[-0.08,0.02\\right], t\\left(255\\right)=-1.20, p=.231. For\nfurther details, see Table 5).\n\nTable 5 Predicting sensitivity-to-misconduct score, based on time,\nexperimental condition, and country\n\nFull size table\n\n## Discussion\n\nWe set out to introduce the gamified online teaching tool Integrity Games, and\ntest six hypotheses about the tool\u2019s effectiveness. The hypotheses addressed\nthe tool\u2019s potential to motivate players to learn about academic integrity,\nand its potential to increase their sensitivity to grey-zone issues and\nmisconduct (specifically plagiarism and falsification). In addition, we asked\nparticipants if they enjoyed playing the game and would recommend it to\nteachers preparing teaching in academic integrity for undergraduate students.\n\nWe found that the participants generally enjoyed playing Integrity Games, and\nwould recommend it to teachers.\n\nRegarding motivation to learn more about academic integrity, we showed that,\nin the specific experimental setup, playing two of the cases in Integrity\nGames followed by a group discussion did not increase the participants\u2019\nmotivation to learn about academic integrity. In fact, neither the\nintervention group nor the control group showed any significant development in\ntheir motivation. One possible explanation for this is that the participants\nwere, on average, already quite motivated to learn about academic integrity\n(the average motivation score in the pre-test was 3.8 out of 5) when starting\nthe sessions. The potential to increase the motivation was thus somewhat\nlimited. In addition, the literature on gamification mainly suggests that\ngamification may increase the player\u2019s motivation to complete the task at hand\n(e.g., playing through the game rather than reading through a text). This is\ndifferent from what we measured in the test. Further research is needed to\ninvestigate whether students who are assigned cases in Integrity Games as\npreparation for a class are more likely to prepare than students who are\nassigned a text.\n\nRegarding sensitivity to misconduct and grey zones, we showed that there was a\nsignificant but small positive development from pre-test to post-test in the\nsensitivity to misconduct of the participants in the Integrity Games\nintervention group and a more substantial positive development in their\nsensitivity to grey-zone issues. These results indicate that, in absolute\nterms, Integrity Games is an effective teaching tool that can improve\nundergraduate students\u2019 sensitivity to grey zones and misconduct. Most other\ntools on academic integrity (see Existing online tools Section) have, at best,\nonly been effect tested in a pre-test/post-test setup, and in such a setup\nIntegrity Games performs rather well when it comes to improving students\u2019\nsensitivity. However, as discussed below, the addition of the control group in\nour study adds important nuances to this result.\n\nWhile our test showed that Integrity Games has the potential to increase\nplayers\u2019 sensitivity to misconduct, it also showed that the participants in\nthe control group developed their sensitivity to a similar extent. Thus, while\nIntegrity Games has the potential to improve students\u2019 sensitivity to grey-\nzone issues and misconduct, this potential may not be greater than non-\ngamified approaches. This is counter to what we had hypothesized (Hypotheses\ntested in the experiment Section). There are several possible explanations for\nthis, some of which relate to the design of the tool, and some to the design\nof the test.\n\nA central difference between Integrity Games and the text read by the control\ngroup is that Integrity Games incorporates some of the elements of effective\ngamified teaching tools listed in Gamification of online tools Section. In\nparticular, it incorporates immersion, identification, increased complexity\nand immediate feedback. However, it does not, on its own, incorporate all\ncharacteristics listed in Gamification of online tools Section, nor were these\nadditional elements incorporated in the experimental setup. Specifically, the\nsetup did not involve any kind of \u201cscoring\u201d where students are told how well\nthey did in the game (on an absolute or relative scale), nor was there a\n\u201cprize\u201d for completing the game (e.g., in the form of a badge). Both of these\nare characteristics of serious games that have been found to be successful in\nthe past (Bai, Hew & Huang 2020).\n\nGiven that gamification has been found to have a positive impact on learning\nin other instances (Bai, Hew & Huang 2020), the missing effect in this case\nraises the question of whether the best explanation is found in the missing\ngamification elements, the potentially partial or poor implementation of the\nincluded gamification elements, or in a potential mismatch between the\ncontents \u2013 ethically nuanced issues with no clear answers \u2013 and gamification.\nOur data do not offer a clear answer to this question, and we are not aware of\nother tests of gamified training tools on academic integrity that include a\ncontrol group that receives non-gamified training.\n\nFurther possible explanations for the null result in the comparison between\nIntegrity Games and the non-gamified text relate to the limitations of the\ntest, of which there are several.\n\nFirst, since the experiment did not include a second control group receiving\nno teaching between pre-test and post-test, it is not possible to directly\nassess the pre-test effect in the experiment. As argued by Hartley (1973), the\nteaching potential of a pre-test may be significant in studies where the\nlearning outcome of the teaching is small, and the time between pre-test and\npost-test is relatively short. It is thus possible that much of the measured\neffect between pre-tests and post-tests in both the intervention and control-\ngroups are due to participants having taken the same pre-test, and improving\nas a result of having taken the same test twice. This is perhaps most worrying\nfor the results concerning sensitivity to misconduct, as the effect is quite\nsmall. In the test on sensitivity to grey zones, the pre-test effect may also\nbe present, but is unlikely to account for the entire effect between pre-test\nand post-test. The effect on the sensitivity to grey zones was larger than the\neffect on sensitivity to misconduct, but the tests are very similar. We\ntherefore see no reason to think the pre-test effect would be bigger for these\nquestions than for the questions probing sensitivity to misconduct.\n\nSecond, since the participants studying in Switzerland were recruited from\nelective courses on various aspects of ethics and epistemology of science,\nthey cannot be considered fully representative for undergraduate students in\nSwitzerland e.g. when it comes to motivation to learn about ethics.\n\nThird, it may be argued that the study setup was rather artificial in the\nsense that the group discussion was set up in a way that few teachers would do\nin a standard session. This design was chosen in order to increase the\ninternal validity of the study by reducing the potential confounding effect of\nhaving different instructors in the different sessions (a common problem in\ntests of gamified teaching according to Bai, Hew & Huang, (2020). However,\nthis study setup does limit the external validity of the study, as it is more\ndifficult to transfer to classroom situations.\n\nAdditionally, the tests only provided data on sensitivity and motivation. We\nhave no data on the students\u2019 ability to make judgements in concrete cases\ninvolving grey-zone issues, nor do we have data on their actual behaviour\nafter the test. Furthermore, the test does not tell us about the knowledge and\nmotivation retention of the participants in the two groups. Stoesz &\nYudintseva (2018) note that this is a common issue in tests of academic\nintegrity training (see also Katsarov et al. 2022). Further research is needed\nto assess whether gamified training on academic integrity in general, and\nIntegrity Games in particular, help improve the long-term retention of the\nunderstanding gained through the training, and whether it has a greater impact\non the students\u2019 behaviour and their ability to make judgements in the long-\nterm.\n\nFinally, the study design may to some extent have limited the positive effect\nof the gaming features of Integrity Games. As mentioned above, one reason why\ngamified teaching is thought to work is that it motivates students to finish\nthe task at hand. This seems particularly important in situations where\nstudents are more easily distracted or where it is unclear how long the task\nwill take. In this study, participants in both the control and intervention\ngroups were asked to spend a specific, and rather limited, amount of time on\ntheir tasks, and they knew that the class would continue after they had\nfinished the task. This is rather different from a normal preparation\nsituation, where students would be asked to work on the task until it was done\nwithout knowing how long it will take, and it is likely that the gaming\nfeatures of the tool would be more effective in an actual preparation\nsituation than in the experimental setup.\n\nGiven these limitations, we can only tentatively conclude that the improved\nsensitivity to misconduct and grey-zone issues from pre-test to post-test for\nparticipants playing Integrity Games indicates that the tool can be valuable\nin academic integrity training aiming to help undergraduate students become\nmore aware of the many grey-zone issues they are likely to encounter during\ntheir studies. We believe that, although the effect was modest in our\nexperimental setup, the effect can be improved when properly integrated into\nclassroom teaching which incorporates teacher feedback and discussion. The\ntest therefore indicates that Integrity Games is a positive addition to the\ntoolbox available to teachers who develop academic integrity training that\ngoes beyond simply informing about clear-cut cheating.\n\nHowever, our study also calls for further research on the educational\npotential of Integrity Games. In addition, our results raise more general\nquestions about the value of gamification in academic integrity training on\ngrey-zone issues. If, as indicated in recent reviews (Bai, Hew & Huang 2020;\nvan Gaalen et al. 2021), gamification works mainly when elements of\ncompetition, scoring and winning can be built into the gamified tools, then it\nseems that gamification has the greatest potential when it is possible to\nclearly discern who performed best, for example by seeing who had the most\ncorrect answers. However, when dealing with grey-zone issues in academic\nintegrity, a central caveat is that there may not be one correct way to deal\nwith them (although some ways are clearly wrong). In dilemma-based games like\nIntegrity Games, this makes it challenging to score students\u2019 performance\npurely on their responses to how they would handle the dilemmas they are\npresented with. Furthermore, it may be argued that it is not the answers to\nthe dilemmas themselves that are the most important. Rather, it is the\nreasoning that the students go through in order to get to the answers that is\nimportant. Is this reasoning based on the right values and understandings, and\ndo students display the proper patterns of thought? These may be among the\nmore appropriate questions to ask, but they are perhaps also more difficult\n(though not impossible) to use as the basis for a scoring system that enables\nthe player to compete with other players and win the game. Thus, it can be\nparticularly challenging to harvest the benefits of gamified training in\nacademic integrity training.\n\n## Conclusion\n\nWe conclude that Integrity Games is a potentially valuable teaching tool on\nacademic integrity for undergraduate students. Participants in our study found\nit fun to play, and they would recommend it to teachers of academic integrity.\nFurthermore, it has the potential to improve students\u2019 sensitivity to grey-\nzone issues and to some extent also their sensitivity to misconduct. However,\nthis potential may not be bigger than that of non-gamified teaching. Our study\nalso calls for further research into the long-term retention of the positive\neffects of the understanding gained through playing Integrity Games, and\nsimilar gamified teaching tools, on academic integrity, and whether they have\na positive effect on students\u2019 long-term behaviour and their ability to make\nappropriate judgements in complex real-life cases.\n\n## Availability of data and materials\n\nThe raw data from the effect tests are available here:\nhttps://doi.org/https://doi.org/10.17894/ucph.dce5432a-a9ee-4fd0-b9c8-d99557a50ed3.\n\n## Abbreviations\n\nAA:\n\n    \n\nAur\u00e9lien Allard\n\nACVA:\n\n    \n\nAnna Catharina Vieira Armond\n\nCC:\n\n    \n\nChristine Clavien\n\nCI:\n\n    \n\nConfidence Interval\n\nCS:\n\n    \n\nC\u00e9line Sch\u00f6pfer\n\ndf :\n\n    \n\nDegree of freedom\n\nHL:\n\n    \n\nHillar Loor\n\nMG:\n\n    \n\nMads Goddiksen\n\nMWJ:\n\n    \n\nMikkel Willum Johansen\n\nOV:\n\n    \n\nOrsolya Varga\n\n## References\n\n  * Allard A, Armond A, Goddiksen M, Johansen M, Loor H, Sh\u00f6pfer C, Varga O, Clavien C (2023) The quizzical failure of a nudge aimed at promoting academic integrity. Res Integr Peer Rev\n\n  * ALLEA (2017). The European Code of Conduct for Research Integrity - revised edition. Available from: https://www.allea.org/publications/joint-publications/european-code-conduct-research-integrity/\n\n  * Annetta L (2010) The \u201cI\u2019s\u201d Have It: a framework for serious educational game design. Rev Gen Psychol 14(2):105\u2013113. https://doi.org/10.1037/a0018985\n\nArticle Google Scholar\n\n  * Bai S, Hew K, Huang B (2020) Does gamification improve student learning outcome? Evidence from a meta-analysis and synthesis of qualitative data in educational contexts. Educational Reseach Review 30 https://doi.org/10.1016/j.edurev.2020.100322\n\n  * Bates D, M\u00e4chler M, Bolker B, Walker S (2015) \u201cFitting Linear Mixed-Effects Models Using lme4.\u201d Journal of Statistical Software 67(1):1\u201348 https://doi.org/10.18637/jss.v067.i01\n\n  * Carpenter DD, Harding TS, Finelli CJ, Passow H (2004) Does academic dishonesty relate to unethical behavior in professional practice? An exploratory study. Sci Eng Ethics 10:311\u2013324. https://doi.org/10.1007/s11948-004-0027-3\n\nArticle Google Scholar\n\n  * Childers D, Bruton S (2016) \u201cShould It Be Considered Plagiarism?\u201d Student Perceptions of Complex Citation Issues. J Acad Ethics 14:1\u201317. https://doi.org/10.1007/s10805-015-9250-6\n\nArticle Google Scholar\n\n  * Committee on Assessing Integrity in Research Environments (2002) Integrity in scientific research: creating an environment that promotes responsible conduct. National Academies Press, Washington, DC\n\nGoogle Scholar\n\n  * CSDT (2021). Intrinsic Motivation Inventory. Centre for Self-Determination Theory. URL= https://selfdeterminationtheory.org/intrinsic-motivation-inventory/. Accessed Dec 2021\n\n  * Egri L (1972) The Art of Dramatic Writing: Its Basis in the Creative Interpretation of Human Motives. Simon and Schuster, New York\n\nGoogle Scholar\n\n  * Goddiksen M, Quinn U, Kov\u00e1cs N, Lund T, Sand\u00f8e P, Varga O (2021) Good friend or good student? An interview study of perceived conflicts between personal and academic integrity among students in three European countries. Account Res 10(1080/08989621):1826319\n\nGoogle Scholar\n\n  * Goddiksen M, Johansen M, Armond A, Centa M, Clavien C, Gefenas E, Globokar R, Hogan L, Kov\u00e1cs N, Merit M, Olsson I, Po\u0161kut\u0117 M, Quinn U, Santos J, Santos R, Sch\u00f6pfer C, Strahovnik V, Varga O, Wall P, Sand\u00f8e P (2023a) Lund T (2023a) Grey zones and good practice: A European survey of academic integrity among undergraduate students. Ethics Behav 10(1080/10508422):2187804\n\nGoogle Scholar\n\n  * Goddiksen M, Gjerris M (2022) Teaching phronesis in a research integrity course. FACETS 7(1) https://doi.org/10.1139/facets-2021-0064\n\n  * Goddiksen M, Johansen M, Armond A, Clavien C, Hogan L, Kov\u00e1cs N, Merit M, Olsson I, Quinn U, Santos J, Santos R, Sch\u00f6pfer C, Varga O, Wall P, Sand\u00f8e P, Lund T (2023b) \u201cThe person in power told me to\u201d - European PhD students\u2019 perspectives on guest authorship and good authorship practice. PLoS ONE 18(1):e0280018. https://doi.org/10.1371/journal.pone.0280018\n\nArticle Google Scholar\n\n  * Guerrero-Dib JG, Portales L, Heredia-Escorza Y (2020) Impact of academic integrity on workplace ethical behaviour. Int J Educ Integr 16:2. https://doi.org/10.1007/s40979-020-0051-3\n\nArticle Google Scholar\n\n  * Hanlon, A., Algers, A., Dich, T., Hansen, T., Loor, H. & Sand\u00f8e, P (2007). \u2018Animal Ethics Dilemma\u2019: an interactive learning tool for university and professional training. Animal Welfare 16(S), 155\u2013158\n\n  * Hartley J (1973) The effect of pre-testing on post-test performance. Instr Sci 2:193\u2013214. https://doi.org/10.1007/BF00139871\n\nArticle Google Scholar\n\n  * Johansen M, Christiansen F (2020) Handling Anomalous Data in the Lab: Students\u2019 Perspectives on Deleting and Discarding. Sci Eng Ethics 26:1107\u20131128\n\nArticle Google Scholar\n\n  * Johansen MW, Goddiksen MP, Centa M et al (2022) Lack of ethics or lack of knowledge? European upper secondary students\u2019 doubts and misconceptions about integrity issues. Int J Educ Integr 18:20\n\nArticle Google Scholar\n\n  * Katsarov J, Andorno R, Krom A, et al (2022) Effective Strategies for Research Integrity Training\u2014a Meta-analysis Educ Psychol Rev 34:935\u2013955 https://doi.org/10.1007/s10648-021-09630-9\n\n  * Kier C (2019) Plagiarism Intervention Using a Game-Based Tutorial in an Online Distance Education Course. Journal of Academic Ethics 17:429\u2013439. https://doi.org/10.1007/s10805-019-09340-6\n\nArticle Google Scholar\n\n  * Lerouge I, Hol A (2020) Towards a Research Integrity Culture at Universities: From Recommendations to Implementation. LERU. Available at: https://www.leru.org/files/Towards-a-Research-Integrity-Culture-at-Universities-full-paper.pdf\n\n  * McCabe D, Trevino L, Butterfield K (2001) Cheating in Academic Institutions: A Decade of Research. Ethics & Behaviour 11(3):219\u2013232\n\nArticle Google Scholar\n\n  * Pearce C (1997) The Interactive Book: A Guide to the Interactive Revolution. MacMillan Technical Publishing\n\n  * Ravn T, S\u00f8rensen M (2021) Exploring the Gray Area: Similarities and Differences in Questionable Research Practices (QRPs) Across Main Areas of Research. Sci Eng Ethics 27(40) https://doi.org/10.1007/s11948-021-00310-z\n\n  * Roig M (1997) Can undergraduate students determine whether text has been plagiarized? The Psychological Record 47:113\u2013122\n\nArticle Google Scholar\n\n  * Schmidt J (2014) Changing the paradigm for engineering ethics. Sci Eng Ethics 20(4):985\u20131010. https://doi.org/10.1007/s11948-013-9491-y\n\nArticle Google Scholar\n\n  * Stephens J, Wangaard D (2016) The achieving with integrity seminar: an integrative approach to promoting moral development in secondary school classrooms. Int J Educ Integr 12(1):1\u201316. https://doi.org/10.1007/s40979-016-0010-1\n\nArticle Google Scholar\n\n  * Stoesz BM, Yudintseva A (2018) Effectiveness of tutorials for promoting educational integrity: a synthesis paper. Int J Educ Integr 14:6. https://doi.org/10.1007/s40979-018-0030-0b\n\nArticle Google Scholar\n\n  * van Gaalen A, Brouwer J, Sch\u00f6nrock-Adema J, Bouwkamp-Timmer T, Jaarsma A, Georgiadis J (2021) Gamification of health professions education: a systematic review. Adv Health Sci Educ Theory Pract 26(2):683\u2013711. https://doi.org/10.1007/s10459-020-10000-3\n\nArticle Google Scholar\n\n  * WCRI (2010) Singapore Statement on Research Integrity. Available from www.singaporestatement.org\n\nDownload references\n\n## Acknowledgements\n\nThe authors would like to thank Peter Sand\u00f8e for his input to the early design\nphase of Integrity Games, and the staff at imCode Partner AB for their\ntechnical assistance in setting up the online portal. We also thank all\nparticipants in the effect study, and N\u00f3ra Kov\u00e1cs for her comments on the\nanalysis. In addition, we thank Mark Harvey Simpson of Global Denmark A/S, for\nlanguage editing, and all partners in INTEGRITY for input and feedback on\nIntegrity Games.\n\n## Funding\n\nOpen access funding provided by Copenhagen University The study was funded by\nEuropean Union\u2019s Horizon 2020 research and innovation programme under grant\nagreement No 824586. The funder had no influence on the design of the study or\nthe analysis of the findings.\n\n## Author information\n\n### Authors and Affiliations\n\n  1. Department of Food and Resource Economics, University of Copenhagen, Copenhagen, Denmark\n\nMads Paludan Goddiksen\n\n  2. Institute For Ethics, History, and the Humanities, University of Geneva, Geneva, Switzerland\n\nAur\u00e9lien Allard, Christine Clavien & C\u00e9line Sch\u00f6pfer\n\n  3. Department of Public Health and Epidemiology, University of Debrecen, Debrecen, Hungary\n\nAnna Catharina Vieira Armond & Orsolya Varga\n\n  4. imCode Partner AB, Visby, Sweden\n\nHillar Loor\n\n  5. Department of Science Education, University of Copenhagen, Copenhagen, Denmark\n\nMikkel Willum Johansen\n\nAuthors\n\n  1. Mads Paludan Goddiksen\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  2. Aur\u00e9lien Allard\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  3. Anna Catharina Vieira Armond\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  4. Christine Clavien\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  5. Hillar Loor\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  6. C\u00e9line Sch\u00f6pfer\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  7. Orsolya Varga\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  8. Mikkel Willum Johansen\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n### Contributions\n\nPlatform design and development| Test design| Data collection| Data analysis|\nData interpretation| Writing first complete draft| Revising and commenting  \n---|---|---|---|---|---|---  \nMPG| x| x| x| x| x| x  \nAA| x| x| x| x| x| x  \nACVA| x| x| x  \nCC| x| x| x| x| x| x  \nHL| x| x  \nCS| x| x| x  \nOV| x| x| x| x| x| x  \nMWJ| x| x| x| x| x  \n  \n### Corresponding author\n\nCorrespondence to Mads Paludan Goddiksen.\n\n## Ethics declarations\n\n### Competing interests\n\nThe authors have collectively designed and developed the content of the\nIntegrity Games website. Hillar Loor is the CEO of imCode Partner AB, the\ncompany that was paid to develop the website. The website is and will remain\nfreely available. The other authors have no financial conflict of interest\nregarding the promotion of the Integrity Games website.\n\n## Additional information\n\n### Publisher\u2019s Note\n\nSpringer Nature remains neutral with regard to jurisdictional claims in\npublished maps and institutional affiliations.\n\n## Supplementary Information\n\n### Supplementary Material 1.\n\n### Supplementary Material 2.\n\n### Supplementary Material 3.\n\n## Rights and permissions\n\nOpen Access This article is licensed under a Creative Commons Attribution 4.0\nInternational License, which permits use, sharing, adaptation, distribution\nand reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the\nCreative Commons licence, and indicate if changes were made. The images or\nother third party material in this article are included in the article's\nCreative Commons licence, unless indicated otherwise in a credit line to the\nmaterial. If material is not included in the article's Creative Commons\nlicence and your intended use is not permitted by statutory regulation or\nexceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder. To view a copy of this licence, visit\nhttp://creativecommons.org/licenses/by/4.0/. The Creative Commons Public\nDomain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/)\napplies to the data made available in this article, unless otherwise stated in\na credit line to the data.\n\nReprints and permissions\n\n## About this article\n\n### Cite this article\n\nGoddiksen, M.P., Allard, A., Armond, A.C.V. et al. Integrity games: an online\nteaching tool on academic integrity for undergraduate students. Int J Educ\nIntegr 20, 7 (2024). https://doi.org/10.1007/s40979-024-00154-7\n\nDownload citation\n\n  * Received: 02 October 2023\n\n  * Accepted: 13 March 2024\n\n  * Published: 02 May 2024\n\n  * DOI: https://doi.org/10.1007/s40979-024-00154-7\n\n### Share this article\n\nAnyone you share the following link with will be able to read this content:\n\nSorry, a shareable link is not currently available for this article.\n\nProvided by the Springer Nature SharedIt content-sharing initiative\n\n### Keywords\n\n  * Academic integrity\n  * Cheating\n  * Academic dishonesty\n  * Gamification\n  * Training\n\nDownload PDF\n\nAdvertisement\n\n#### International Journal for Educational Integrity\n\nISSN: 1833-2595\n\n#### Contact us\n\n  * Submission enquiries: Access here and click Contact Us\n  * General enquiries: info@biomedcentral.com\n\n  * Read more on our blogs\n  * Receive BMC newsletters\n  * Manage article alerts\n  * Language editing for authors\n  * Scientific editing for authors\n\n  * Policies\n  * Accessibility\n  * Press center\n\n  * Support and Contact\n  * Leave feedback\n  * Careers\n\n### Follow BMC\n\n  * BMC Twitter page\n  * BMC Facebook page\n  * BMC Weibo page\n\nBy using this website, you agree to our Terms and Conditions, Your US state\nprivacy rights, Privacy statement and Cookies policy. Your privacy\nchoices/Manage cookies we use in the preference centre.\n\n\u00a9 2024 BioMed Central Ltd unless otherwise stated. Part of Springer Nature.\n\n", "frontpage": false}
