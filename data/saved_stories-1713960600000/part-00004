{"aid": "40139793", "title": "Tweet-Archive", "url": "https://github.com/mcthomas/tweet-archive", "domain": "github.com/mcthomas", "votes": 1, "user": "Bondi_Blue", "posted_at": "2024-04-24 02:28:39", "comments": 0, "source_title": "GitHub - mcthomas/tweet-archive: Archive tweets en masse (including media) into a personal offline feed.", "source_text": "GitHub - mcthomas/tweet-archive: Archive tweets en masse (including media)\ninto a personal offline feed.\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nmcthomas / tweet-archive Public\n\n  * Notifications\n  * Fork 0\n  * Star 0\n\nArchive tweets en masse (including media) into a personal offline feed.\n\n### License\n\nMIT license\n\n0 stars 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# mcthomas/tweet-archive\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nmcthomasAdd scripts, index, dockerfileMar 18, 202414feea5 \u00b7 Mar 18, 2024Mar\n18, 2024\n\n## History\n\n2 Commits  \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n| Add scripts, index, dockerfile| Mar 18, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Initial commit| Mar 9, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| Add scripts, index, dockerfile| Mar 18, 2024  \n  \n### create_pages.sh\n\n|\n\n### create_pages.sh\n\n| Add scripts, index, dockerfile| Mar 18, 2024  \n  \n### gen_index.sh\n\n|\n\n### gen_index.sh\n\n| Add scripts, index, dockerfile| Mar 18, 2024  \n  \n### page_index.html\n\n|\n\n### page_index.html\n\n| Add scripts, index, dockerfile| Mar 18, 2024  \n  \n## Repository files navigation\n\n# tweet-archive\n\nGoal: Provide a functional workflow to create an offline archive of scraped\ntweets- uninhibited by the platform's API restrictions- as a more complete\nalternative to the native archive feature available from a platform account.\n\nNote: The majority of the value here lies in the hacky shell scripts which\nassemble the tweet data into a static frontend that you can enjoy. After\nintial setup, if you do not want the tweets pooled together (regardless of\nwhether they are from your Likes, Bookmarks, etc.) and sorted by date posted,\nor you want to customize the pages' appearances, you would be best to fork\nthis repo and customize the shell scripts to your liking.\n\nDependencies:\n\n  * a twitter account (can be a temporary account)\n  * WFDownloader\n  * Docker Desktop\n  * At the moment, unfortunately Chrome\n  * A Unix-like shell\n\n## Part 1 - Pulling Down Tweet Data\n\n  * clone down this repository and unzip it\n  * open WFDownloader\n\n    * on macOS, you will likely need to allow the applets through Gatekeeper, and launch via EnableStart.command\n  * with WFDownloader open, navigate to Tasks \u2192 Login via inbuilt browser\n  * load the following url into the inbuilt browser and log into your account: https://twitter.com/i/flow/login\n\n    * you may now close the inbuilt browser window if you'd prefer, since it has your current session login (or you can continue using it for retrieving urls in the following procedure if you prefer)\n  * for each page's tweets you would like to archive (e.g. the url to your likes, to your bookmarks, to your profile, to another user's profile, etc.) you will need to copy out the url of that page and follow this procedure:\n\n    1. from the main WFDownloader window, select Add\n\n       * paste the url into the Link Address field\n       * browse to, or set the path to, the recently downloaded and decompressed repository directory\n       * select Config and ensure that the Fetch_Mode field is set to Fetch media only; then select Accept\n       * select Confirm and wait for all resolveable tweets' media links to be found\n       * select Confirm again to close this window, and from the main window, select Resume (the new batch should already be selected)\n    2. wait for the downloads in the batch to complete, and then once again select Add\n\n       * your previous url and folder path should already be present in the fields; this time, select Config and set the Fetch_Mode field to Fetch tweet urls for export; then select Accept\n       * select Confirm and wait for all resolveable tweets' links to be found\n       * select Confirm again to close this window, and from the main window, select Resume (the new batch should already be selected)\n       * at this point, you should have both the media and json data, for the tweets served at the current url, saved locally\n\n## Part 2 - Generating a Static Frontend\n\n  * open Docker Desktop so that it is running in the background\n  * open your terminal emulator and navigate to the repository directory\n  * run docker build -t tweet-archive .; docker run -it --rm -v \"$(pwd):/scripts\" tweet-archive (repeat these two commands any time you want to re-generate the archive after making your own changes)\n\n    * if you have the gnu core utilities installed, you can try running bash create_pages.sh instead of using Docker (errors may persist due to different flags available from the BSD package equivalents; this is why I suggest using Docker)\n\n## Viewing Your Tweet Archive\n\n  * quit Chrome if it is running\n  * in your terminal emulator, launch a Chrome session with reduced security to disable CORS restrictions: (for you convenience, you may want to save the below command to a .command file, a .cmd file, or an alias, per your platform)\n\n    * macOS: open /Applications/Google\\ Chrome.app --args --user-data-dir=\"/var/tmp/Chrome dev session\" --disable-web-security\n    * Linux: google-chrome --disable-web-security\n    * Windows: chrome.exe --user-data-dir=\"C:/Chrome dev session\" --disable-web-security\n  * in your file manager, navigate to the top level of the repository directory and then right-click open the index.html file with this active Chrome session\n  * on the index page, you should see that the tweets are divided into chronological subgroups of 15 tweets per hyperlinked page (this prevents long load times for media)\n\n    * each page is hyperlinked with the earliest tweet's post date per subgrouping\n  * when you're finished viewing your archive, quit Chrome to end this session with reduced security\n\n## Known Issues\n\n  * intermittent playback issues without the autoplay attribute\n  * intermittent playback issues on local servers, partially due to using autoplay\n  * inability to open archive on alternative browsers (disabling CORS restrictions is increasingly difficult on Safari, Firefox, and others)\n\n## About\n\nArchive tweets en masse (including media) into a personal offline feed.\n\n### Topics\n\njavascript css shell html api bash docker unix scraper automation browser\ntwitter web offline tool feed archive tweet x wfdownloader\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\nActivity\n\n### Stars\n\n0 stars\n\n### Watchers\n\n2 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Languages\n\n  * HTML 62.5%\n  * Shell 35.6%\n  * Dockerfile 1.9%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
