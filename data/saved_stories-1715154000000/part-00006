{"aid": "40293095", "title": "DeepSeek V2, near GPT4 performance with 30% GPT3.5 cost ($0.14M input tokens)", "url": "https://www.deepseek.com/", "domain": "deepseek.com", "votes": 8, "user": "zinccat", "posted_at": "2024-05-08 00:29:19", "comments": 0, "source_title": "DeepSeek", "source_text": "DeepSeek\n\nDeepSeek-V2: 236 billion MoE model. Leading performance. Ultra-affordable.\nUnparalleled experience. Chat and API upgraded to the latest model.\n\nBrand new experience, redefining possibilities\n\nTry Now\n\nFree to Use. Ignite questions, illuminate solutions.\n\nAccess API\n\n5 million FREE tokens. $0.14-$0.28 for 1 million more.\n\n\u4e2d\u6587\n\nDeepSeek-V2 Capabilities\n\nDeepSeek-V2 delivers impressive results on current major large model\nleaderboards.\n\nPlaces top 3 in AlignBench\n\nSurpassing GPT-4 and close to GPT-4-Turbo\n\nRanks top-tier in MT-Bench\n\nRivaling LLaMA3-70B and outperforming Mixtral 8x22B\n\nSpecializes in math, code and reasoning\n\nThe open-source model supports 128K context length, while the Chat/API\nsupports 32K context length\n\nOpen source| Chinese General| English General| Knowledge| Arithmetic| Math|\nReasoning| Coding  \n---|---|---|---|---|---|---|---  \nAlignBench| MT-Bench| MMLU| GSM8K| MATH| BBH| HumanEval  \nDeepSeek-V2| Yes| 7.91| 8.97| 77.8| 92.2| 53.9| 79.7| 81.1  \nGPT-4-Turbo-1106| -| 8.01| 9.32| 84.6| 93.0| 64.1| -| 82.2  \nGPT-4-0613| -| 7.53| 8.96| 86.4| 92.0| 52.9| 83.1| 84.1  \nGPT-3.5| -| 6.08| 8.21| 70.0| 57.1| 34.1| 66.6| 48.1  \nGemini1.5 Pro| -| 7.33| 8.93| 81.9| 91.7| 58.5| 84.0| 71.9  \nClaude3 Opus| -| 7.62| 9.00| 86.8| 95.0| 61.0| 86.8| 84.9  \nClaude3 Sonnet| -| 6.70| 8.47| 79.0| 92.3| 40.5| 82.9| 73.0  \nClaude3 Haiku| -| 6.42| 8.39| 75.2| 88.9| 40.9| 73.7| 75.9  \nabab-6.5| -| 7.97| 8.82| 79.5| 91.7| 51.4| 82.0| 78.0  \nabab-6.5s| -| 7.34| 8.69| 74.6| 87.3| 42.0| 76.8| 68.3  \nERNIE-4.0| -| 7.89| 7.69| -| 91.3| 52.2| -| 72.0  \nGLM-4| -| 7.88| 8.60| 81.5| 87.6| 47.9| 82.3| 72.0  \nMoonshot-v1| -| 7.22| 8.59| -| 89.5| 44.2| -| 82.9  \nBaichuan 3| -| -| 8.70| 81.7| 88.2| 49.2| 84.5| 70.1  \nQwen1.5 72B| Yes| 7.19| 8.61| 76.2| 81.9| 40.6| 65.9| 68.9  \nLLaMA 3 70B| Yes| 7.42| 8.95| 80.3| 93.2| 48.5| 80.1| 76.2  \nMixtral 8x22B| Yes| 6.49| 8.66| 77.8| 87.9| 49.8| 78.4| 75.0  \n  \nDeepSeek-V2 API Pricing\n\nPer Million Input Tokens\n\n0.14$\n\nPer Million Output Tokens\n\n0.28$\n\nChinese Performance vs. API Price\n\nElites in AlignBench, DeepSeek-V2's performance is in the top tier globally\nwith unbeatable API pricing.\n\nWhy DeepSeek-V2?\n\nAPI Access\n\n236B parameters 32K context (Chat/API)\n\nCapable\n\n$0.14/M input tokens $0.28/M output tokens\n\nCost-effective\n\nCompatible with OpenAI API\n\nSeamless\n\n\u00a9 2023-2024 DeepSeek. All rights reserved.\n\n\u6d59 ICP \u5907 2023025841 \u53f7\u6d59\u516c\u7f51\u5b89\u5907 33010502011812\n\nResearch\n\nDeepSeek LLMDeepSeek CoderDeepSeek MathDeepSeek VLDeepSeek V2\n\nProduct\n\nDeepSeek ChatDeepSeek PlatformAPI Pricing\n\nLegal & Safety\n\nPrivacy PolicyTerms of Use\n\n", "frontpage": true}
