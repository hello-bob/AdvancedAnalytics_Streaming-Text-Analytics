{"aid": "40246386", "title": "Delay Slot", "url": "https://en.wikipedia.org/wiki/Delay_slot", "domain": "wikipedia.org", "votes": 1, "user": "ankitg12", "posted_at": "2024-05-03 11:22:06", "comments": 0, "source_title": "Delay slot", "source_text": "Delay slot - Wikipedia\n\nJump to content\n\nSearch\n\nWiki Loves Earth\n\nPhotograph nature for Wikipedia and win!\n\n# Delay slot\n\n  * Catal\u00e0\n  * Deutsch\n  * Espa\u00f1ol\n  * Italiano\n  * \u65e5\u672c\u8a9e\n  * \u4e2d\u6587\n\nEdit links\n\nFrom Wikipedia, the free encyclopedia\n\nInstruction slot being executed without the effects of a preceding instruction\n\nThis article needs additional citations for verification. Please help improve\nthis article by adding citations to reliable sources. Unsourced material may\nbe challenged and removed. Find sources: \"Delay slot\" \u2013 news \u00b7 newspapers \u00b7\nbooks \u00b7 scholar \u00b7 JSTOR (October 2023) (Learn how and when to remove this\nmessage)  \n---  \n  \nIn computer architecture, a delay slot is an instruction slot being executed\nwithout the effects of a preceding instruction.^[1] The most common form is a\nsingle arbitrary instruction located immediately after a branch instruction on\na RISC or DSP architecture; this instruction will execute even if the\npreceding branch is taken. This makes the instruction execute out-of-order\ncompared to its location in the original assembler language code.\n\nModern processor designs generally do not use delay slots, and instead perform\never more complex forms of branch prediction to solve this problem. In these\nsystems, the CPU immediately moves on to what it believes will be the correct\nside of the branch and thereby eliminates the need for the code to specify\nsome unrelated instruction, which may not always be obvious at compile-time.\nIf the assumption is wrong, and the other side of the branch has to be called,\nthis can introduce a lengthy delay. This occurs rarely enough that the speed\nup of avoiding the delay slot is easily made up by the smaller number of wrong\ndecisions.\n\n## Pipelining[edit]\n\nA central processing unit generally performs instructions from the machine\ncode using a four-step process; the instruction is first read from memory,\nthen decoded to understand what needs to be performed, those actions are then\nexecuted, and finally, any results are written back to memory. In early\ndesigns, each of these stages was performed in series, so that instructions\ntook some multiple of the machine's clock cycle to complete. For instance, in\nthe Zilog Z80, the minimum number of clocks needed to complete an instruction\nwas four, but could be as many as 23 clocks for some (rare) instructions.^[2]\n\nAt any given stage of the instruction's processing, only one part of the chip\nis involved. For instance, during the execution stage, typically only the\narithmetic logic unit (ALU) is active, while other units, like those that\ninteract with main memory or decode the instruction, are idle. One way to\nimprove the overall performance of a computer is through the use of an\ninstruction pipeline. This adds some additional circuitry to hold the\nintermediate states of the instruction as it flows through the units. While\nthis does not improve the cycle timing of any single instruction, the idea is\nto allow a second instruction to use the other CPU sub-units when the previous\ninstruction has moved on.^[3]\n\nFor instance, while one instruction is using the ALU, the next instruction\nfrom the program can be in the decoder, and a third can be fetched from\nmemory. In this assembly line type arrangement, the total number of\ninstructions processed at any time can be improved by up to the number of\npipeline stages. In the Z80, for example, a four-stage pipeline could improve\noverall throughput by four times. However, due to the complexity of the\ninstruction timing, this would not be easy to implement. The much simpler\ninstruction set architecture (ISA) of the MOS 6502 allowed a two-stage\npipeline to be included, which gave it performance that was about double that\nof the Z80 at any given clock speed.^[4]\n\n## Branching problems[edit]\n\nA major issue with the implementation of pipelines in early systems was that\ninstructions had widely varying cycle counts. For instance, the instruction to\nadd two values would often be offered in multiple versions, or opcodes, which\nvaried on where they read in the data. One version of add might take the value\nfound in one processor register and add it to the value in another, another\nversion might add the value found in memory to a register, while another might\nadd the value in one memory location to another memory location. Each of these\ninstructions takes a different amount of bytes to represent it in memory,\nmeaning they take different amounts of time to fetch, may require multiple\ntrips through the memory interface to gather values, etc. This greatly\ncomplicates the pipeline logic. One of the goals of the RISC chip design\nconcept was to remove these variants so that the pipeline logic was\nsimplified, which leads to the classic RISC pipeline which completes one\ninstruction every cycle.\n\nHowever, there is one problem that comes up in pipeline systems that can slow\nperformance. This occurs when the next instruction may change depending on the\nresults of the last. In most systems, this happens when a branch occurs. For\ninstance, consider the following pseudo-code:\n\n    \n    \n    top: read a number from memory and store it in a register read another number and store it in a different register add the two numbers into a third register write the result to memory read a number from memory and store it in another register ...\n\nIn this case, the program is linear and can be easily pipelined. As soon as\nthe first read instruction has been read and is being decoded, the second read\ninstruction can be read from memory. When the first moves to execute, the add\nis being read from memory while the second read is decoding, and so forth.\nAlthough it still takes the same number of cycles to complete the first read,\nby the time it is complete the value from the second is ready and the CPU can\nimmediately add them. In a non-pipelined processor the first four instructions\nwill take 16 cycles to complete, in a pipelined one, it takes only five.\n\nNow consider what occurs when a branch is added:\n\n    \n    \n    top: read a number from memory and store it in a register read another number and store it in a different register add the two numbers into a third register if the result in the 3rd register is greater than 1000, then go back to top: (if it is not) write the result to memory read a number from memory and store it in another register ...\n\nIn this example the outcome of the comparison on line four will cause the\n\"next instruction\" to change; sometimes it will be the following write to\nmemory, and sometimes it will be the read from memory at the top. The\nprocessor's pipeline will normally have already read the next instruction, the\nwrite, by the time the ALU has calculated which path it will take. This is\nknown as a branch hazard. If it has to return to the top, the write\ninstruction has to be discarded and the read instruction read from memory\ninstead. That takes one full instruction cycle, at a minimum, and results in\nthe pipeline being empty for at least one instruction's time. This is known as\na \"pipeline stall\" or \"bubble\", and, depending on the number of branches in\nthe code, can have a noticeable impact on overall performance.\n\n## Branch delay slots[edit]\n\nOne strategy for dealing with this problem is to use a delay slot, which\nrefers to the instruction slot after any instruction that needs more time to\ncomplete. In the examples above, the instruction that requires more time is\nthe branch, which is by far the most common type of delay slot, and these are\nmore commonly referred to as a branch delay slot.\n\nIn early implementations, the instruction following the branch would be filled\nwith a no-operation, or NOP, simply to fill out the pipeline to ensure the\ntiming was right such that by the time the NOP had been loaded from memory the\nbranch was complete and the program counter could be updated with the correct\nvalue. This simple solution wastes the processing time available. More\nadvanced solutions would instead try to identify another instruction,\ntypically nearby in the code, to place in the delay slot so that useful work\nwould be accomplished.\n\nIn the examples above, the read instruction at the end is completely\nindependent, it does not rely on any other information and can be performed at\nany time. This makes it suitable for placement in the branch delay slot.\nNormally this would be handled automatically by the assembler program or\ncompiler, which would re-order the instructions:\n\n    \n    \n    read a number from memory and store it in a register read another number and store it in a different register add the two numbers into a third register if the result in the 3rd register is greater than 1000, then go back to the top read a number from memory and store it in another register (if it is not) write the result to memory ...\n\nNow when the branch is executing, it goes ahead and performs the next\ninstruction. By the time that instruction is read into the processor and\nstarts to decode, the result of the comparison is ready and the processor can\nnow decide which instruction to read next, the read at the top or the write at\nthe bottom. This prevents any wasted time and keeps the pipeline full at all\ntimes.\n\nFinding an instruction to fill the slot can be difficult. The compilers\ngenerally have a limited \"window\" to examine and may not find a suitable\ninstruction in that range of code. Moreover, the instruction cannot rely on\nany of the data within the branch; if an add instruction takes a previous\ncalculation as one of its inputs, that input cannot be part of the code in a\nbranch that might be taken. Deciding if this is true can be very complex in\nthe presence of register renaming, in which the processor may place data in\nregisters other than what the code specifies without the compiler being aware\nof this.\n\nAnother side effect is that special handling is needed when managing\nbreakpoints on instructions as well as stepping while debugging within the\nbranch delay slot. An interrupt is unable to occur during a branch delay slot\nand is deferred until after the branch delay slot.^[5]^[6] Placing branch\ninstruction in the branch delay slot is prohibited or deprecated.^[7]^[8]^[9]\n\nThe ideal number of branch delay slots in a particular pipeline implementation\nis dictated by the number of pipeline stages, the presence of register\nforwarding, what stage of the pipeline the branch conditions are computed,\nwhether or not a branch target buffer (BTB) is used and many other factors.\nSoftware compatibility requirements dictate that an architecture may not\nchange the number of delay slots from one generation to the next. This\ninevitably requires that newer hardware implementations contain extra hardware\nto ensure that the architectural behaviour is followed despite no longer being\nrelevant.\n\n## Implementations[edit]\n\nBranch delay slots are found mainly in DSP architectures and older RISC\narchitectures. MIPS, PA-RISC (delayed or non-delayed branch can be\nspecified),^[10] ETRAX CRIS, SuperH (unconditional branch instructions have\none delay slot),^[11] Am29000,^[12] Intel i860 (unconditional branch\ninstructions have one delay slot),^[13] MC88000 (delayed or non-delayed branch\ncan be specified),^[14] and SPARC are RISC architectures that each have a\nsingle branch delay slot; PowerPC, ARM, Alpha, V850, and RISC-V do not have\nany. DSP architectures that each have a single branch delay slot include\n\u03bcPD77230^[15] and the VS DSP. The SHARC DSP and MIPS-X use a double branch\ndelay slot;^[16] such a processor will execute a pair of instructions\nfollowing a branch instruction before the branch takes effect. Both\nTMS320C3x^[17] and TMS320C4x^[8] use a triple branch delay slot. The TMS320C4x\nhas both non-delayed and delayed branches.^[8]\n\nThe following example shows delayed branches in assembly language for the\nSHARC DSP including a pair after the RTS instruction. Registers R0 through R9\nare cleared to zero in order by number (the register cleared after R6 is R7,\nnot R9). No instruction executes more than once.\n\n    \n    \n    R0 = 0; CALL fn (DB); /* call a function, below at label \"fn\" */ R1 = 0; /* first delay slot */ R2 = 0; /* second delay slot */ /***** discontinuity here (the CALL takes effect) *****/ R6 = 0; /* the CALL/RTS comes back here, not at \"R1 = 0\" */ JUMP end (DB); R7 = 0; /* first delay slot */ R8 = 0; /* second delay slot */ /***** discontinuity here (the JUMP takes effect) *****/ /* next 4 instructions are called from above, as function \"fn\" */ fn: R3 = 0; RTS (DB); /* return to caller, past the caller's delay slots */ R4 = 0; /* first delay slot */ R5 = 0; /* second delay slot */ /***** discontinuity here (the RTS takes effect) *****/ end: R9 = 0;\n\n## Load delay slot[edit]\n\nA load delay slot is an instruction which executes immediately after a load\n(of a register from memory) but does not see, and need not wait for, the\nresult of the load. Load delay slots are very uncommon because load delays are\nhighly unpredictable on modern hardware. A load may be satisfied from RAM or\nfrom a cache, and may be slowed by resource contention. Load delays were seen\non very early RISC processor designs. The MIPS I ISA (implemented in the R2000\nand R3000 microprocessors) suffers from this problem.\n\nThe following example is MIPS I assembly code, showing both a load delay slot\nand a branch delay slot.\n\n    \n    \n    lw v0,4(v1) # load word from address v1+4 into v0 nop # wasted load delay slot jr v0 # jump to the address specified by v0 nop # wasted branch delay slot\n\n## See also[edit]\n\n  * Control flow\n  * Bubble (computing)\n  * Branch predication\n\n## References[edit]\n\n  1. ^ A.Patterson, David; L.Hennessy, John (1990). Computer Archtecture A Quantitative Approach. Morgan Kaufmann Publishers. p. 275. ISBN 1-55860-069-8.\n  2. ^ \"MSX Assembly Page\".\n  3. ^ \"CMSC 411 Lecture 19, Pipelining Data Forwarding\". University of Maryland Baltimore County Computer Science and Electrical Engineering Department. Retrieved 2020-01-22.\n  4. ^ Cox, Russ (3 January 2011). \"The MOS 6502 and the Best Layout Guy in the World\".\n  5. ^ \"\u03bcPD77230 Advanced Signal Processor\" (PDF). pp. 38(3-39), 70(3-41). Retrieved 2023-11-17.\n  6. ^ \"TMS320C4x User's Guide\" (PDF). p. 75(3-15). Retrieved 2023-12-02.\n  7. ^ \"\u03bcPD77230 Advanced Signal Processor\" (PDF). p. 191(4-76). Retrieved 2023-10-28.\n  8. ^ Jump up to: ^a ^b ^c \"TMS320C4x User's Guide\" (PDF). p. 171(7-9). Retrieved 2023-10-29.\n  9. ^ \"MC88100 RISC Microprocessor User's Manual\" (PDF). p. 88(3-33). Retrieved 2023-12-30.\n  10. ^ DeRosa, John A.; Levy, Henry M. \"An Evaluation of Branch Architectures\". p. 1. Retrieved 2024-01-27.\n  11. ^ \"SH7020 and SH7021 Hardware ManualSuperHTM RISC engine\". p. 42,70. Retrieved 2023-12-17.\n  12. ^ \"Evaluating and Programming the 29K RISC Family Third Edition \u2013 DRAFT\" (PDF). p. 54. Retrieved 2023-12-20.\n  13. ^ \"i860TM 64-bit Microprocessor Programmer's Reference Manual\" (PDF). p. 70(5-11). Retrieved 2023-12-21.\n  14. ^ \"MC88100 RISC Microprocessor User's Manual\" (PDF). p. 81(3-26). Retrieved 2023-12-21.\n  15. ^ \"\u03bcPD77230 Advanced Signal Processor\" (PDF). p. 191(4-76). Retrieved 2023-11-05.\n  16. ^ \"MIPS-X Instruction Set and Programmer's Manual\" (PDF). p. 18. Retrieved 2023-12-03.\n  17. ^ \"The TMS320C30 Floating-Point Digital Signal Processor\" (PDF). ti.com. p. 14. Retrieved 2023-11-04.\n\n## External links[edit]\n\n  * DeRosa, J.A.; Levy, H.M. (1987). \"An evaluation of branch architectures \u00a72 Delayed Branches\". Proceedings of the 14th annual international symposium on Computer architecture (ISCA '87). Association for Computing Machinery. pp. 10\u201316. doi:10.1145/30350.30352. ISBN 978-0-8186-0776-9. S2CID 1870852.\n  * Prabhu, Gurpur M. \"Branch Prediction Schemes\". Computer Architecture Tutorial. Iowa State University. Archived from the original on 2020-08-07.\n\nRetrieved from\n\"https://en.wikipedia.org/w/index.php?title=Delay_slot&oldid=1219881204\"\n\nCategory:\n\n  * Instruction processing\n\nHidden categories:\n\n  * Articles with short description\n  * Short description is different from Wikidata\n  * Articles needing additional references from October 2023\n  * All articles needing additional references\n\n  * This page was last edited on 20 April 2024, at 12:12 (UTC).\n  * Text is available under the Creative Commons Attribution-ShareAlike License 4.0; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia\u00ae is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\n\n  * Privacy policy\n  * About Wikipedia\n  * Disclaimers\n  * Contact Wikipedia\n  * Code of Conduct\n  * Developers\n  * Statistics\n  * Cookie statement\n  * Mobile view\n  * Edit preview settings\n\n", "frontpage": false}
