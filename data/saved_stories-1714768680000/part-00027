{"aid": "40246751", "title": "Packrat Parsing from Scratch", "url": "https://blog.bruce-hill.com/packrat-parsing-from-scratch", "domain": "bruce-hill.com", "votes": 1, "user": "sph", "posted_at": "2024-05-03 12:08:48", "comments": 0, "source_title": "Packrat Parsing from Scratch", "source_text": "Packrat Parsing from Scratch \u2013 Naming Things\n\nNaming Things\n\nArchive RSS About\n\n\ud83c\udf18\n\n# Packrat Parsing from Scratch\n\nHow to implement a packrat parser from scratch, one easy piece at a time.\n\nEstimated reading time: 12 mins\n\nBruce Hill June 5, 2021\n\nPackrat parsing is a relatively new approach to parsing code introduced by\nBryan Ford in his 2002 Master\u2019s thesis. Packrat parsers are capable of very\nefficiently parsing a class of grammars called Parsing Expression Grammars\n(PEGs). I covered PEGs in more depth in my previous post, PEGs and the\nStructure of Languages, so if you\u2019re new to the topic, I recommend you begin\nthere. The packrat parser is based on earlier work on recursive descent\nparsers, dating back to the 70s, but focused specifically on Parsing\nExpression Grammars. In this post, I\u2019ll attempt to demystify packrat parsers\nby walking through a complete packrat parser implementation that fits in a few\ndozen lines of Javascript code.\n\nThe core idea of the packrat parsing algorithm is incredibly simple. It boils\ndown to: when you attempt to match a rule at a particular position, remember\nwhether it succeeds, and if so, how much input it consumes. Because PEGs have\nno context-dependencies, if a pattern matches in a particular place in a\nstring, it will always match there, exactly the same, regardless of where it\nfits into a larger structure. This means there\u2019s a fixed number of\ncombinations of grammar rules to match and string positions to match them at.\nThere\u2019s no need to try matching the same pattern in different ways at the same\nposition. Here, you can see what the parsing algorithm looks like in action\n(click \u201cRun\u201d to run the demo):\n\n## Making a Packrat Parser\n\nThe architecture I\u2019m going to use is a functional style that represents\ngrammar rules as functions that will either match an input string or not, and\nreturn some information if it does match. This makes the implementation easy,\nbut a more efficient approach might be to use a virtual machine. We\u2019re going\nto start with a simple container class that stores info about the match:\n\nHere, start is inclusive and end is exclusive, i.e. start is the index where\nthe match begins, and end is the index where subsequent matches would begin. A\nzero-length match would have start == end.\n\n    \n    \n    class Match { constructor(text, start, end, children=[]) { this.text = text; this.start = start; this.end = end; this.children = children; } }\n\n## Pattern Building Blocks\n\nNext, let\u2019s begin implementing support for matching different pattern types.\nThe first and simplest pattern is one that matches literal text. The literal\npattern will check whether the exact string match occurs at the starting\nstring position:\n\nIn Javascript, functions implicitly return undefined if they run to the end\nwithout an explicit return statement, so that will represent \u201cno match.\u201d\n\n    \n    \n    function literal(pattern) { return ((text, i)=> { if (text.startsWith(pattern, i)) return new Match(text, i, i+pattern.length); }); }\n\nUsing this, we can perform simple string matching:\n\n    \n    \n    var HelloPattern = literal(\"hello\"); HelloPattern(\"hello world\", 0); // -> new Match(text, 0, 5)) HelloPattern(\"goodbye\", 0); // -> no match (undefined) HelloPattern(\"hello world\", 5); // -> no match at index 5\n\nGreat, that works! Let\u2019s get to the meatier patterns. The next pattern is a\nchain or sequence of other patterns one after the other:\n\n    \n    \n    function chain(...patterns) { return ((text, i)=> { let children = [], start = i; for (let pattern of patterns) { let result = pattern(text, i); if (!result) return; children.push(result); i = result.end; } return new Match(text, start, i, children); }); }\n\nWe can use it like this:\n\n    \n    \n    var HelloWorldPattern = chain( literal(\"hello\"), literal(\" \"), literal(\"world\")); HelloWorldPattern(\"hello world\", 0); // -> new Match(text, 0, 11)) HelloWorldPattern(\"goodbye\", 0); // -> undefined\n\nNow, let\u2019s get to the first really interesting pattern: a branching choice\noption. This will walk through a list of patterns one at a time, and return\nthe results of the first one that succeeds:\n\n    \n    \n    function oneof(...patterns) { return ((text, i)=> { for (let pattern of patterns) { let result = pattern(text, i); if (result) return result; } }); }\n\nWe can use it like this:\n\n    \n    \n    var AddressWorldPattern = chain( oneof(literal(\"hello\"), literal(\"goodbye\")), literal(\" \"), literal(\"world\")); AddressWorldPattern(\"hello world\", 0); // -> new Match(text, 0, 11)) AddressWorldPattern(\"goodbye world\", 0); // -> new Match(text, 0, 13) AddressWorldPattern(\"hello sky\", 0); // -> undefined\n\nAt this point, we need a way to match repeating patterns. There\u2019s two ways to\ndo that: looping and recursion. I\u2019m going to choose recursion here because it\nwill make it easier to have a fine-grained cache in the future (this will have\none recursive function call per iteration). The approach for recursion is to\nrecursively define \u201c0 or more repetitions of a pattern\u201d to mean: either the\npattern followed by 0 or more repetitions of the pattern, or the empty string\n(in PEG syntax: repeating <\\- (pat repeating) / \"\"). Because PEGs formally\nspecify parsing order, the empty string will only match if \u201cone or more\nrepetitions\u201d doesn\u2019t match:\n\nThe code here uses a lazy lookup of zero_or_more using a function closure.\nThis is a little hacky, but later, we will implement a less hacky way to do\nthis.\n\n    \n    \n    function repeat(pattern) { let zero_or_more = oneof( chain(pattern, (text,i)=>zero_or_more(text,i)), literal(\"\")); return zero_or_more }\n\nThese four primitive pattern types (literals, chains, options, and repeating)\nare incredibly powerful, and you can define a huge range of PEG grammars in\nwith only these tools, but there\u2019s one thing missing: negation. Negation will\nallow us to specify that something shouldn\u2019t match a pattern (e.g. variables\ncan\u2019t be keywords). A successful negation will return a zero-length result\nthat means \u201cthe pattern I\u2019m negating doesn\u2019t match at my starting position:\u201d\n\n    \n    \n    function not(pattern) { return ((text, i) => { if (!pattern(text, i)) return new Match(text,i,i); }); }\n\nNow, the last component here isn\u2019t strictly necessary, but it\u2019s very handy to\nhave a wildcard pattern that matches any single character, the equivalent of .\nin regular expressions. You could achieve the same goal by creating a oneof()\nthat has a literal() corresponding to every character, but that\u2019s just\ntedious.\n\n    \n    \n    function anychar() { return ((text, i)=> { if (i < text.length) return new Match(text, i, i+1); }); }\n\n## A Simple CSV Parser\n\nWith these functions, we can implement a parser for a full language! Let\u2019s try\nit out with a CSV parser (comma separated values) to see what it will look\nlike:\n\n    \n    \n    // Equivalent to the regex: [^,\\n]* let CSVItem = repeat(chain(not(\",\"), not(\"\\n\"), anychar())); // Sorta like: CSVItem (\",\" CSVItem)* let CSVLine = chain(CSVItem, repeat(chain(\",\", CSVItem))); // Sorta like: CSVLine (\"\\n\" CSVLine)* let CSVFile = chain(CSVLine, repeat(chain(\"\\n\", CSVLine))); // It works (but only for validation) let my_file = \"x,y,z\\na,b,c\"; Console.assert(CSVFile(my_file)) // new Match(...)\n\n## Capturing Data\n\nRight now, the parsing framework is very flexible, but it\u2019s not very useful\nbecause the return value it produces is just a bunch of string indices. Let\u2019s\nadd the ability to explicitly capture snippets of the source text and the\nability to tag a match with a descriptive name.\n\n    \n    \n    function capture(pattern) { return (text, i)=> { let result = pattern(text, i); if (result) { let match = new Match( text, result.start, result.end, [result]); match.captured = text.substring(i, result.end); return match; } }; } function named(name, pattern) { return (text, i)=> { let result = pattern(text, i); if (result) { let match = new Match(text, i, result.end, [result]); match.name = name; return match; } }; }\n\nNow we can define our earlier grammar with captures:\n\n    \n    \n    let CSVItem = named(\"Item\", capture(repeat(chain(not(literal(','), not(literal(\"\\n\")), anychar())))); let CSVLine = named(\"Line\", chain(CSVItem, repeat(chain(literal(','), CSVItem)))) let CSVFile = named(\"File\", chain(CSVLine, repeat(chain(literal(\"\\n\"), CSVLine))))\n\nThis finally gets us to a usable result! Here\u2019s a program that uses our CSV\nparser to print the sum of the numbers on each row.\n\n    \n    \n    let my_file = \"1,2,3\\n4,5,6\" let csv_data = CSVFile(my_file): // Extract the captured values from the tree structure // of chain()s and oneof()s and so forth: function* get_captures(n) { if (n.captured) yield n.captured; for (let child of n.children) { yield from get_captures(child); } } // Print the sum of the numbers on each row: for (let row of csv_data.children) { let total = 0; for (let item_text of get_captures(row)) { total += parseInt(item_text); } console.log(total); // First logs 6, then 15 }\n\n## Recursion\n\nEarlier, when we defined the repeat rule, we had to use a somewhat hacky\nversion of recursion that relied on local variables and function closures. It\nworked, but it wasn\u2019t clean. The way to solve this more elegantly is to use\nlazy rule lookups on a single grammar object:\n\n    \n    \n    class Grammar { ref(name) { return (text, i) => this[name](text, i); } }\n\nUsing this object, we can implement recursive (and corecursive) definitions by\nusing grammar.ref() instead of referencing the rule directly, and the lookup\nwill be delayed until after the rule is defined:\n\n    \n    \n    let g = new Grammar(); g.A = chain(\"A\", oneof(g.ref(\"A\"), g.ref(\"B\"), literal(\"\"))); g.B = chain(\"B\", oneof(g.ref(\"B\"), g.ref(\"A\"), literal(\"\"))); g.AB = oneof(g.A, g.B); Console.assert(g.AB(\"ABBBAAABA\", 0));\n\n## Some Conveniences\n\nThere\u2019s also a few other helper functions that provide some features you might\nexpect or desire to have, like lookaheads (&patt), optionals (patt?),\ncharacter ranges ([a-z]), character sets ([aeiou]), and inverted character\nsets ([^,;]). All of these can be implemented in terms of the previously\ndefined functions, but they\u2019re common enough that it makes sense to make\nslightly more optimized versions of them and provide an API to access them\neasily.\n\n    \n    \n    // Equivalent to not(not(pattern)) function ahead(pattern) { return (text,i)=> (pattern(text, i) && new Match(text, i,i)); } // Equivalent to oneof(pattern, literal(\"\")) function maybe(pattern) { return (text,i)=> (pattern(text, i) || new Match(text, i,i)); } // Equivalent to oneof(literal(min), ..., literal(max)) function between(min, max) { return ((text, i)=> { if (i < text.length && min <= text[i] && text[i] <= max) return new Match(text, i, i+1); }); } // Equivalent to oneof(literal(allowed[0], allowed[1], ...)) // or chain(not(oneof(...)), anychar()) when inclusive=false function charfrom(allowed, inclusive=true) { if (!inclusive) return chain(not(charfrom(allowed)), anychar()); return oneof(...allowed); }\n\nAll right! That\u2019s it. In total, it\u2019s about 100 lines of code for a full\nparsing library that can parse any arbitrary PEG. Unfortunately, it\u2019s kinda\nslow because it\u2019s not a proper packrat parser. The defining feature of packrat\nparsers is that they memoize everything, which is what gives them their\namazing speed.\n\n## Packrat Parsing\n\nWe can make this code orders of magnitude faster with 10 lines of code, and\none tiny tweak. All it takes adding caching to the definitions:\n\n    \n    \n    function cached(fn) { let cache = {}, cache_text = \"\"; return (text, i)=> { if (text != cache_text) // cache is per-input-text cache = {}, cache_text = text; if (!(i in cache)) cache[i] = fn(text, i); return cache[i]; } }\n\nAnd then, wrap all the returned functions with cached(). For example, with\nliteral():\n\n    \n    \n    function literal(pattern) { return cached((text, i)=> { if (text.startsWith(pattern, i)) return new Match(text, i, i+pattern.length); }); }\n\nThat\u2019s it! This is a complete packrat parser! As you\u2019ve seen, the fundamental\ncomponents of a packrat parser are individually quite simple, and there aren\u2019t\nvery many of them. At its heart, a packrat parser is nothing more than a\nmemoized matcher of literals, chains, choices, negations, and recursive\nreferences. There\u2019s nothing that\u2019s fundamentally difficult to understand, just\na simple idea that can be implemented in a few dozen lines of code and\nendlessly tweaked and improved on.\n\n## Future Improvements\n\nThe parser that I\u2019ve walked you through implementing in this post is\nasymptotically quite fast. It runs in time, where is the size of the grammar\nand is the size of input text; in other words, for a fixed grammar, you will\nget performance for arbitrary input text. It will also use memory space ( for\na fixed grammar). For comparison, packrat parsers are capable of matching\nrecursive grammars that are impossible to match with extended regular\nexpressions, but can do so in linear time, while extended regular expressions\nhave potentially unbounded runtime. The downside is that packrat parsers use\nan amount of memory proportional to the length of the input text. Packrat\nparser runtime may be close to for arbitrary real-world (non-malicious)\ngrammars, since grammars tend to follow power-law distributions, where a few\nrules are called often, but the rest are only rarely called. When this is the\ncase, the expected number of rules tested at each string index is bounded by a\nconstant number that doesn\u2019t grow as the grammar adds more rules. However, the\nimplementation here has a lot of constant-time overhead on common operations\nand it can potentially use quite a lot of stack space. Using a virtual machine\nwith a heap-allocated stack instead of recursive function calls will lower\nfunction call overhead and prevent stack overflow, but the overall performance\nwould need to be tuned using a profiler to find performance bottlenecks if you\ntruly cared about speed. In other words, this blog post is intended to give\nyou an understanding of the concepts behind a packrat parser, but the code\nhere won\u2019t outperform a real parsing library.\n\nBesides performance, the programming ergonomics could also use a lot of\nimprovement. The code repeat(charfrom('aeiou'))(input_text, 0) is much more\ncumbersome than regex pattern matching: input_text.match(/[aeiou]*/).\nFortunately, the regex/BNF-like PEG grammar discussed in PEGs and the\nstructure of languages is itself a grammar that can be parsed by a packrat\nparser. In my next post, I\u2019ll discuss how to write a program that\nautomatically converts PEG-syntax grammars into runnable parsers\u2013in other\nwords, how to make a parser-generator. As a quick teaser, here is how we might\nstart building it:\n\n    \n    \n    let g = new Grammar(); g.AnyChar = named(\"AnyChar\", literal(\".\")); g.CharSet = named(\"CharSet\", chain(literal(\"[\"), repeat(not(literal(\"]\")), capture(anychar())), literal(\"]\"))); // ... g.Expression = oneof( g.ref(\"AnyChar\"), g.ref(\"CharSet\"), ...); function make_parser(grammar_text) { let match = g.Expression(grammar_text, 0); if (!match) throw \"Grammar failed to compile\"; switch (match.name) { case \"AnyChar\": return anychar(); case \"CharSet\": return charfrom(get_captures(match)); //... } } function match(grammar, text, offset=0) { return make_parser(grammar)(text, offset) } let result = match(\"[aeiou]\", input_text);\n\nLook forward to a new post coming soon!\n\n\u2190 PEGs and the Structure of Languages\n\nComments, corrections, or other feedback? Send them to blog@bruce-hill.com\n\nUnless otherwise specified, all code is released under the MIT license with\nthe Commons Clause\n\nThis page has been visited ~5.7K times\n\n", "frontpage": false}
