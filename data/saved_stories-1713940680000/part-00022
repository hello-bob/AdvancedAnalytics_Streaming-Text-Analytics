{"aid": "40136774", "title": "The End of Foreign-Language Education", "url": "https://www.theatlantic.com/technology/archive/2024/03/generative-ai-translation-education/677883/", "domain": "theatlantic.com", "votes": 2, "user": "simonebrunozzi", "posted_at": "2024-04-23 20:18:31", "comments": 0, "source_title": "The End of Foreign-Language Education", "source_text": "The End of Foreign-Language Education - The Atlantic\n\n## More From Artificial Intelligence\n\n## More From Artificial Intelligence\n\nExplore This Series\n\n  * ### It\u2019s the End of the Web as We Know It\n\nJudith DonathBruce Schneier\n\n  * ### The AI Revolution Is Crushing Thousands of Languages\n\nMatteo Wong\n\n  * ### Why a Cognitive Scientist Put a Head Cam on His Baby\n\nSarah Zhang\n\n  * ### AI Has Lost Its Magic\n\nIan Bogost\n\nTechnology\n\n# The End of Foreign-Language Education\n\nThanks to AI, people may no longer feel the need to learn a second language.\n\nBy Louise Matsakis\n\nIllustration by Matteo Giuseppe Pani\n\nMarch 26, 2024\n\nListen to this article\n\n00:00\n\n10:58\n\nProduced by ElevenLabs and News Over Audio (NOA) using AI narration.\n\nA few days ago, I watched a video of myself talking in perfect Chinese. I\u2019ve\nbeen studying the language on and off for only a few years, and I\u2019m far from\nfluent. But there I was, pronouncing each character flawlessly in the correct\ntone, just as a native speaker would. Gone were my grammar mistakes and\nawkward pauses, replaced by a smooth and slightly alien-sounding voice. \u201cMy\nfavorite food is sushi,\u201d I said\u2014wo zui xihuan de shiwu shi shousi\u2014with no hint\nof excitement or joy.\n\nI\u2019d created the video using software from a Los Angeles\u2013based artificial-\nintelligence start-up called HeyGen. It allows users to generate deepfake\nvideos of real people \u201csaying\u201d almost anything based on a single picture of\ntheir face and a script, which is paired with a synthetic voice and can be\ntranslated into more than 40 languages. By merely uploading a selfie taken on\nmy iPhone, I was able to glimpse a level of Mandarin fluency that may elude me\nfor the rest of my life.\n\nHeyGen\u2019s visuals are flawed\u2014the way it animates selfies almost reminded me of\nthe animatronics in Disney\u2019s It\u2019s a Small World ride\u2014but its language\ntechnology is good enough to make me question whether learning Mandarin is a\nwasted effort. Neural networks, the machine-learning systems that power\ngenerative-AI programs such as ChatGPT, have rapidly improved the quality of\nautomatic translation over the past several years, making even older tools\nlike Google Translate far more accurate.\n\nAt the same time, the number of students studying foreign languages in the\nU.S. and other countries is shrinking. Total enrollment in language courses\nother than English at American colleges decreased 29.3 percent from 2009 to\n2021, according to the latest data from the Modern Language Association,\nbetter known as the MLA. In Australia, only 8.6 percent of high-school seniors\nwere studying a foreign language in 2021\u2014a historic low. In South Korea and\nNew Zealand, universities are closing their French, German, and Italian\ndepartments. One recent study from the education company EF Education First\nfound that English proficiency is decreasing among young people in some\nplaces.\n\nMany factors could help explain the downward trend, including pandemic-related\nschool disruptions, growing isolationism, and funding cuts to humanities\nprograms. But whether the cause of the shift is political, cultural, or some\nmix of things, it\u2019s clear that people are turning away from language learning\njust as automatic translation becomes ubiquitous across the internet.\n\nRead: High-school English needed a makeover before ChatGPT\n\nWithin a few years, AI translation may become so commonplace and frictionless\nthat billions of people take for granted the fact that the emails they\nreceive, videos they watch, and albums they listen to were originally produced\nin a language other than their native one. Something enormous will be lost in\nexchange for that convenience. Studies have suggested that language shapes the\nway people interpret reality. Learning a different way to speak, read, and\nwrite helps people discover new ways to see the world\u2014experts I spoke with\nlikened it to discovering a new way to think. No machine can replace such a\nprofoundly human experience. Yet tech companies are weaving automatic\ntranslation into more and more products. As the technology becomes normalized,\nwe may find that we\u2019ve allowed deep human connections to be replaced by\ncommunication that\u2019s technically proficient but ultimately hollow.\n\nAI language tools are now in social-media apps, messaging platforms, and\nstreaming sites. Spotify is experimenting with using a voice-generation tool\nfrom the ChatGPT maker OpenAI to translate podcasts in the host\u2019s own voice,\nwhile Samsung is touting that its new Galaxy S24 smartphone can translate\nphone calls as they\u2019re occurring. Roblox, meanwhile, claimed last month that\nits AI translation tool is so fast and accurate, its English-speaking users\nmight not realize that their conversation partner \u201cis actually in Korea.\u201d The\ntechnology\u2014which works especially well for \u201chigh-resource languages\u201d such as\nEnglish and Chinese, and less so for languages such as Swahili and Urdu\u2014is\nbeing used in much more high-stakes situations as well, such as translating\nthe testimony of asylum seekers and firsthand accounts from conflict zones.\nMusicians are already using it to translate songs, and at least one couple\ncredited it with helping them to fall in love.\n\nOne of the most telling use cases comes from a start-up called Jumpspeak,\nwhich makes a language-learning app similar to Duolingo and Babbel. Instead of\nhiring actual bilingual actors, Jumpspeak appears to have used AI-generated\n\u201cpeople\u201d reading AI-translated scripts in at least four ads on Instagram and\nFacebook. At least some of the personas shown in the ads appear to be default\ncharacters available on HeyGen\u2019s platform. \u201cI struggled to learn languages my\nwhole life. Then I learned Spanish in six months, I got a job opportunity in\nFrance, and I learned French. I learned Mandarin before visiting China,\u201d a\nsynthetic avatar says in one of the ads, while switching between all three\nlanguages. Even a language-learning app is surrendering to the allure of AI,\nat least in its marketing.\n\nAlexandru Voica, a communications professional who works for another video-\ngenerating AI service, told me he came across Jumpspeak\u2019s ads while looking\nfor a program to teach his children Romanian, the language spoken by their\ngrandparents. He argued that the ads demonstrated how deepfakes and automated-\ntranslation software could be used to mislead or deceive people. \u201cI'm worried\nthat some in the industry are currently in a race to the bottom on AI safety,\u201d\nhe told me in an email. (The ads were taken down after I started reporting\nthis story, but it\u2019s not clear if Meta or Jumpspeak removed them; neither\ncompany returned requests for comment. HeyGen also did not immediately respond\nto a request for comment about its product being used in Jumpspeak\u2019s\nmarketing.)\n\nThe world is already seeing how all of this can go wrong. Earlier this month,\na far-right conspiracy theorist shared several AI-generated clips on X of\nAdolf Hitler giving a 1939 speech in English instead of the original German.\nThe videos, which were purportedly produced using software from a company\ncalled ElevenLabs, featured a re-creation of Hitler\u2019s own voice. It was a\nstrange experience, hearing Hitler speak in English, and some people left\ncomments suggesting that they found him easy to empathize with: \u201cIt sounds\nlike these people cared about their country above all else,\u201d one X user\nreportedly wrote in response to the videos. ElevenLabs did not immediately\nrespond to a request for comment. (The Atlantic uses ElevenLabs\u2019 AI voice\ngenerator to narrate some articles.)\n\nRead: The last frontier of machine translation\n\nGabriel Nicholas, a research fellow at the nonprofit Center for Democracy and\nTechnology, told me that part of the problem with machine-translation programs\nis that they\u2019re often falsely perceived as being neutral, rather than\n\u201cbringing their own perspective upon how to move text from one language to\nanother.\u201d The truth is that there is no single right or correct way to\ntranspose a sentence from French to Russian or any other language\u2014it\u2019s an art\nrather than a science. \u201cStudents will ask, \u2018How do you say this in Spanish?\u2019\nand I\u2019ll say, \u2018You just don\u2019t say it the same way in Spanish; the way you\nwould approach it is different,\u2019\u201d Deborah Cohn, a Spanish- and Portuguese-\nlanguage professor at Indiana University Bloomington who has written about the\nimportance of language learning for bolstering U.S. national security, told\nme.\n\nI recently came across a beautiful and particularly illustrative example of\nthis fact in an article written by a translator in China named Anne. \u201cBuilding\na ladder between widely different languages, such as Chinese and English, is\nsometimes as difficult as a doctor building a bridge in a patient's heart,\u201d\nshe wrote. The metaphor initially struck me as slightly odd, but thankfully I\nwasn\u2019t relying on ChatGPT to translate Anne\u2019s words from their original\nMandarin. I was reading a human translation by a professor named Jeffrey Ding,\nwho helpfully noted that Anne may have been referring to a type of heart\nsurgery that has recently become common in China. It's a small detail, but\nunderstanding that context brought me much closer to the true meaning of what\nAnne was trying to say.\n\nRead: The college essay is dead\n\nBut most students will likely never achieve anything close to the fluency\nrequired to tell whether a translation rings close enough to the original or\nnot. If professors accept that automated technology will far outpace the\ntechnical skills of the average Russian or Arabic major, their focus would\nideally shift from grammar drills to developing cultural competency, or\nunderstanding the beliefs and practices of people from different backgrounds.\nInstead of cutting language courses in response to AI, schools should \u201cstress\nmore than ever the intercultural components of language learning that\ntremendously benefit the students taking these classes,\u201d Jen William, the head\nof the School of Languages and Cultures at Purdue University and a member of\nthe executive committee of the Association of Language Departments, told me.\n\nPaula Krebs, the executive director of the MLA, referenced a beloved 1991\nepisode of Star Trek: The Next Generation to make a similar point. In\n\u201cDarmok,\u201d the crew aboard the starship Enterprise struggles to communicate\nwith aliens living on a planet called El-Adrel IV. They have access to a\n\u201cuniversal translator\u201d that allows them to understand the basic syntax and\nsemantics of what the Tamarians are saying, but the greater meaning of their\nutterances remains a mystery.\n\nIt later becomes clear that their language revolves around allegories rooted\nin the Tamarians\u2019 unique history and practices. Even though Captain Picard was\ntranslating all the words they were saying, he \u201ccouldn\u2019t understand the\nmetaphors of their culture,\u201d Krebs told me. More than 30 years later,\nsomething like a universal translator is now being developed on Earth. But it\nsimilarly doesn\u2019t have the power to bridge cultural divides the way that\nhumans can.\n\nLouise Matsakis is a freelance journalist covering technology and China. She\nis the author of You May Also Like, a newsletter about e-commerce and the\nglobal rise of Chinese tech giants.\n\n", "frontpage": false}
