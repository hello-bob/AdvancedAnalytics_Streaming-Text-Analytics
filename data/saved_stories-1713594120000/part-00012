{"aid": "40091815", "title": "Build a Rate Limiter in TypeScript", "url": "https://smudge.ai/blog/ratelimit", "domain": "smudge.ai", "votes": 2, "user": "seabass", "posted_at": "2024-04-19 20:58:37", "comments": 0, "source_title": "rate limiter \u2013 smudge.ai blog", "source_text": "rate limiter \u2013 smudge.ai blog\n\n# Building a rate limiter in TypeScript (and some Lua)\n\nApril 19, 2024\n\n## What we\u2019re building\n\nIn order to add the free tier for smudge.ai, I needed a way to limit the\nnumber of commands free users could run over a set period of time. Existing\nNode.js rate limiters didn\u2019t quite fit the bill (more on that below), so I\nrolled my own.\n\nI used Redis as the data store. One catch for a TypeScript dev like myself:\nRedis scripting is all Lua. The approach I took was to prototype using the\nlanguage I know, then port the solution to Lua once I had proved that the\nlogic was sound. While the specific problem of building a custom rate limiter\nis fairly niche, defining custom Redis commands that you can call from Node.js\nis quite useful! With that in mind, I\u2019m sharing what I\u2019ve learned about this\nso far and hope you get something out of it, too.\n\nIn this post we\u2019ll...\n\n  * Prototype the logic for a custom rate limiter in TypeScript\n  * Add persistence by swapping out the in-memory store for a Redis store\n  * Then move the heavy lifting into a custom Redis command that\u2019ll be defined in a Lua script\n\nBefore we get into all that, there\u2019s an important question to answer.\n\n## What is a day?\n\nIn order to limit free tier users to n commands per day, we first need to\nanswer the question: what is a day? Seems simple, but there are some nuances.\n\n  * A day could be a fixed window beginning at midnight in the user\u2019s timezone and lasting for 24 hours. While this definition aligns with most people\u2019s natural understanding of a day, implementing it requires tracking each user\u2019s timezone as well as handling complexities like daylight savings or users changing timezones.\n\n> (In the visualizations,\n>\n> will represent a successful request and\n>\n> will represent a request that has been blocked by the rate limiter. You can\n> add a simulated request manually with the Hit button, which pauses the\n> automatic stream.)\n\n  * A day can also be a 24-hour sliding window during which a maximum of n commands can be run. With this approach, commands become available one by one as they are freed up. Another way think of this is: \u201cthe limit defines the maximum number of windows that can exist at any given time\u201d. For my use case, users tend to use the demo in short bursts, so they\u2019d be frustrated by the slow drip of commands being freed up sequentially and might find it hard to keep track of when commands become available again.\n\n  * A day can also be a 24-hour fixed window starting with your first command. This is the approach we ended up using. With a fixed window with a user-defined start time, we don\u2019t need any timezone handling logic. And predictability is better in comparison to a sliding window.\n\nBecause an important tradeoff with this approach is that it\u2019s less clear when\nthe next window begins compared to, say, a fixed window in the user\u2019s\ntimezone, we show the time remaining in the UI so there is no guesswork.\n\n## Let\u2019s look at some code.\n\nWe\u2019ll need a function to record each hit to the rate limiter, which returns\nwhether the request should be blocked (limited: true) and if so, how long\nuntil a retry is allowed (retryAfter: windowDuration -\ntimeSinceWindowCreation).\n\nTo allow each user 10 requests per 24-hour period, we\u2019ll set the following\nparameters:\n\n    \n    \n    const limit = 10;\n    \n    const windowDuration = 24 * 60 * 60 * 1000;\n\nWe also need a place to store the records containing the number of times each\nuser has triggered the rate limiter since their windowStart timestamp.\n\n    \n    \n    type LimitRecord = {\n    \n    count: number;\n    \n    windowStart: Date;\n    \n    };\n    \n    const store = new Map<string, LimitRecord>();\n\nLastly, we need the function that registers a hit, incrementing a user\u2019s count\nin the store and returning whether they should be limited.\n\n    \n    \n    // hit('user-001'); { limited: false }\n    \n    // hit('user-001'); { limited: false }\n    \n    // ... 8 more times ...\n    \n    // hit('user-001'); { limited: true, retryAfter: 24h }\n    \n    export function hit(id: string) {\n    \n    const now = new Date();\n    \n    const record = store.get(id);\n    \n    const timeElapsed = record ? now.getTime() - record.windowStart.getTime() : 0;\n    \n    // if no record or it expired, set a new one\n    \n    if (!record || timeElapsed > windowDuration) {\n    \n    store.set(id, { count: 1, windowStart: now });\n    \n    return { limited: false };\n    \n    }\n    \n    // increment the counter if it's within the limit\n    \n    if (record.count < limit) {\n    \n    record.count += 1;\n    \n    return { limited: false };\n    \n    }\n    \n    return {\n    \n    limited: true, // the request has been rate limited\n    \n    retryAfter: windowDuration - timeElapsed,\n    \n    };\n    \n    }\n\n### Problems with this solution\n\n  1. It\u2019s in memory.\n\n     * Rate limiting is isolated to a single long-running process, so say goodbye to horizontal scaling or serverless code.\n     * Restarting the server will nuke the store, resetting everybody\u2019s rate limit windows.\n  2. It\u2019s not configurable. The max and windowDuration are hard-coded constants.\n\n     * Easy fix: wrap the whole thing in a function that accepts those two parameters. Leaving this as an exercise for the reader.\n  3. It grows indefinitely. Not an issue in practice unless you have an enormous number of IDs in the store, but because expired records are never pruned this will consume more and more memory with use.\n\n## Adding persistence and scalability with Redis\n\nLet\u2019s address the first issue and move the store somewhere off-server and with\npersistence. Redis (or any of its forks) tends to be the go-to solution when\nit comes to rate limiting due to its speed and built-in functions that support\nexpiring keys, which make it a breeze to build a rate limiter.\n\nWe can essentially swap out the in-memory store for a Redis hash map.\n\n    \n    \n    import { Redis } from 'ioredis';\n    \n    const redis = new Redis(process.env.REDIS_URL);\n    \n    export function hit(id: string) {\n    \n    export async function hit(id: string) {\n    \n    const now = new Date();\n    \n    const record = store.get(id);\n    \n    const record = await store.hgetall(id);\n    \n    const timeElapsed = record ? now.getTime() - record.windowStart.getTime() : 0;\n    \n    // if no record or it expired, set a new one\n    \n    if (!record || timeElapsed > windowDuration) { // [1]\n    \n    store.set(id, { count: 1, windowStart: now });\n    \n    await redis.hset(id, 'windowStart', now, 'count', 1);\n    \n    await redis.pexpire(id, windowDuration); // new!\n    \n    return { limited: false };\n    \n    }\n    \n    // increment the counter if it's within the limit\n    \n    if (record.count < limit) {\n    \n    record.count += 1;\n    \n    await redis.hincrby(id, 'count', 1);\n    \n    return { limited: false };\n    \n    }\n    \n    return {\n    \n    limited: true, // the request has been rate limited\n    \n    retryAfter: windowDuration - timeElapsed,\n    \n    };\n    \n    }\n\n[1]Aside: I\u2019ve been curious whether I can safely remove the second half of\nthis condition, since the timeElapsed can never exceed windowDuration now that\nthere\u2019s a pexpire. On the other hand, I am not sure how much pexpire can be\nrelied upon between restarts. If anyone with a definitive answer wants to let\nme know, please do!\n\n### Problems with this solution\n\n  1. Race conditions. In the time between await store.hgetall(id) and the commands that update the record, a parallel update could have arrived. It\u2019s for this reason we can\u2019t just solve all our problems with a pipeline.\n  2. Redis return types. I confess! The code above won\u2019t run. I simplified some Redis types to avoid a distracting noisy diff.\n\n  3. It can go faster. We\u2019re making sequential async requests to another server. What if there were a way to run these all in a single command?\n\n## Lua time!\n\nYou can run as many Redis functions as you would like within a single async\ncommand using Lua scripting, reducing the waterfall of round trips to just a\nsingle request/response.\n\nUsing ioredis we\u2019ll define a rateLimit command in Lua that gets called in\nplace of most of our previous logic. (If you prefer not to use ioredis, you\ncan always use other Redis clients and call the underlying SCRIPT LOAD and\nEVALSHA commands manually.)\n\nThe goal will be to write a script that we can pass all the same inputs to,\nwhich will still return whether the request was limited, and if so include the\ntime remaining until a retry is allowed.\n\nA brief implementation note: instead of returning an object like { limited:\ntrue, retryAfter 2500 }, for this implementation we\u2019ll be using a tuple, like\n[true, 2500] to represent the same information. But because booleans from the\nLua script show up as numbers, that tuple will actually be [1, 2500].\n\n    \n    \n    import { Redis, type Result } from 'ioredis';\n    \n    const redis = new Redis(process.env.REDIS_URL);\n    \n    // 1. write a script in lua to execute in redis,\n    \n    // then use it to define a custom command\n    \n    redis.defineCommand('rateLimit', {\n    \n    numberOfKeys: 1,\n    \n    lua: `[a string of lua]`, // implemented later\n    \n    });\n    \n    // 2. let ts know the lua command's types [2]\n    \n    declare module 'ioredis' {\n    \n    interface RedisCommander<Context> {\n    \n    rateLimit(\n    \n    key: string,\n    \n    limit: number,\n    \n    windowDuration: number,\n    \n    now: number,\n    \n    ): Result<[number, number], Context>;\n    \n    }\n    \n    }\n    \n    export async function hit(id: string) {\n    \n    const now = new Date();\n    \n    // 3. run the custom command\n    \n    const [limited, retryAfter] = await redis.rateLimit(\n    \n    id,\n    \n    limit,\n    \n    windowDuration,\n    \n    now.getTime(),\n    \n    );\n    \n    // we're representing bools as numbers [3]\n    \n    if (limited === 0) {\n    \n    return { limited: false };\n    \n    }\n    \n    return { limited: true, retryAfter };\n    \n    }\n\n[2] Because the TypeScript compiler has no way to know the custom command\u2019s\ntypes, we have to declare them manually. There\u2019s no type-safety with this. We\nhave to carefully ensure that the Lua script adheres to these types. (Probably\na good case for a unit test.) The type declaration is copied from this\nscripting example.[3]From my tests, returning { false, 0 } in Lua becomes\n[null, 0] in js, whereas a return value of { true, 0 } becomes [1, 0]. So, for\nconsistency, I\u2019m sticking with numbers.\n\nThe arguments passed in to the custom rateLimit command from our TypeScript\ncode are then read within the Lua script similar to how one would read CLI\narguments.\n\n    \n    \n    -- (within the lua string above)\n    \n    local key = KEYS[1] -- lua uses 1-based indexing\n    \n    local limit = tonumber(ARGV[1])\n    \n    local windowDuration = tonumber(ARGV[2])\n    \n    local now = tonumber(ARGV[3])\n\nFinally, here\u2019s the Lua equivalent to the logic from the previous iteration.\n\n    \n    \n    -- (continued from above)\n    \n    -- attempt to fetch an existing record\n    \n    -- (see https://redis.io/commands/hmget/)\n    \n    local record = redis.call('HMGET', key, 'windowStart', 'count')\n    \n    local windowStart = record[1]\n    \n    local count = record[2]\n    \n    -- if no record or it expired, set a new one\n    \n    -- (we get all false values if no record exists)\n    \n    if windowStart == false then\n    \n    redis.call('HSET', key, 'windowStart', now, 'count', 1)\n    \n    redis.call('PEXPIRE', key, windowDuration)\n    \n    return { 0, 0 } -- becomes the tuple `[0, 0]` in js\n    \n    end\n    \n    -- increment the counter if it's within the limit\n    \n    -- (tonumber because all values are saved as strings)\n    \n    if tonumber(count) < limit then\n    \n    redis.call('HINCRBY', key, 'count', 1)\n    \n    return { 0, 0 }\n    \n    end\n    \n    local timeElapsed = now - tonumber(windowStart);\n    \n    -- the request has been rate limited\n    \n    -- (return `1` for `true`)\n    \n    return { 1, windowDuration - timeElapsed }\n\n## Why this is worthwhile\n\nWe make a lot of concessions in this code. There\u2019s a call to another language,\nwhich needs to be loaded and evaluated. We sacrifice some type safety and\nreadability. And the Lua code is in a string! But in exchange we get:\n\n  * Speed. In the hot path, there\u2019s a single request to our Redis instance instead of 2-3 round trips. For our app, the Redis instance that the server connects to will be in the same datacenter, so rate limiting typically has sub-millisecond timing.\n  * Reliability. We\u2019ve removed the race conditions from the previous iteration.\n  * Memory efficiency. With PEXPIRE any expired windows will delete themselves automatically.\n  * Scalability. We can scale our application server horizontally without potentially spreading the window records across multiple servers.\n  * Persistence. When the server restarts, the store in Redis remains intact.\n\n## Conclusion\n\nHonestly, you should probably just use something like Upstash for your rate\nlimiting and call it a day! If your use case requires a fixed window (and you\ndon\u2019t care about the exact window start time), or if it requires a sliding\nwindow or token bucket approach, then their API is a joy to use.\n\nOn the other hand, if you need finer control over the start time for your\nfixed window rate limiter or simply enjoy building things yourself, consider\ngiving an approach like this a try.\n\n### Where to go from here\n\nThere are many further improvements I\u2019d like to make. Adding an ephemeral\ncache in memory would allow skipping the hit to Redis while the rate limiter\nis hot. For multi-region apps, the limiter could support multiple Redis\ninstances, selecting the one closest to the requesting server\u2019s region and\nthen propagating updates across the other instances. And adding support for\nmultiple limiters, each with its own configurable limit and windowDuration,\ncan be done by prefixing each key with a string unique to that limiter.\n\nWhat would you change? Feel free to submit corrections, ideas, or any feedback\nto feedback@smudge.ai.\n\nThank you for reading!\n\nAnd a huge thank you to @onsclom for inspiring this project, working with me\nto make it happen, and showing me how to make those canvas visualizations.\n\n> Smudge.ai is a Chrome extension that lets you save custom ChatGPT commands\n> into your right-click menu. If that\u2019s something you\u2019re interested in, as a\n> thank you for taking the time to read this post, you can take 20% off\n> forever with the discount code RATELIMIT20. Cheers!\n\n", "frontpage": false}
