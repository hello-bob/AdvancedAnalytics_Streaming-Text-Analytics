{"aid": "40279416", "title": "Fundamental Issues in Computer Vision Still Unresolved", "url": "https://semiengineering.com/fundamental-issues-in-computer-vision-still-unresolved/", "domain": "semiengineering.com", "votes": 1, "user": "PaulHoule", "posted_at": "2024-05-06 20:56:22", "comments": 0, "source_title": "Fundamental Issues In Computer Vision Still Unresolved", "source_text": "Fundamental Issues In Computer Vision Still Unresolved\n\nSubscribe\n\nChinese (Simplified) English\n\n  * Home\n  * Systems & Design\n  * Low Power - High Performance\n  * Manufacturing, Packaging & Materials\n  * Test, Measurement & Analytics\n  * Auto, Security & Pervasive Computing\n\n  * Special Reports\n  * Business & Startups\n  * Jobs\n  * Knowledge Center\n  * Technical Papers\n\n    * Home\n\n';\n\n    * AI/ML/DL\n    * Architectures\n    * Automotive/ Aerospace\n    * Communication/Data Movement\n    * Design & Verification\n    * Lithography\n    * Manufacturing\n    * Materials\n    * Memory\n    * Optoelectronics / Photonics\n    * Packaging\n    * Power & Performance\n    * Quantum\n    * Security\n    * Test, Measurement & Analytics\n    * Transistors\n    * Z-End Applications\n  * Events & Webinars\n\n    * Events\n    * Webinars\n  * Videos & Research\n\n    * Videos\n    * Industry Research\n  * Newsletters & Store\n\n    * Newsletters\n    * Store\n\n  * MENU\n\n    * Home\n    * Special Reports\n    * Systems & Design\n    * Low Power-High Performance\n    * Manufacturing, Packaging & Materials\n    * Test, Measurement & Analytics\n    * Auto, Security & Pervasive Computing\n    * Knowledge Center\n    * Videos\n    * Startup Corner\n    * Business & Startups\n    * Jobs\n    * Technical Papers\n    * Events\n    * Webinars\n    * Industry Research\n    * Newsletters\n    * Store\n    * Special Reports\n\nHome > Auto, Security & Pervasive Computing > Fundamental Issues In Computer\nVision Still Unresolved\n\n13 Shares\n\n7\n\n5\n\nAuto, Security & Pervasive Computing\n\n# Fundamental Issues In Computer Vision Still Unresolved\n\n13 Shares\n\n7\n\n5\n\nIndustry and academia are addressing next steps.\n\nMay 2nd, 2024 - By: Karen Heyman\n\nGiven computer vision\u2019s place as the cornerstone of an increasing number of\napplications from ADAS to medical diagnosis and robotics, it is critical that\nits weak points be mitigated, such as the ability to identify corner cases or\nif algorithms are trained on shallow datasets. While well-known bloopers are\noften the result of human decisions, there are also fundamental technical\nissues that require further research.\n\n\u201cComputer vision\u201d and \u201cmachine vision\u201d were once used nearly interchangeably,\nwith machine vision most often referring to the hardware embodiment of vision,\nsuch as in robots. Computer vision (CV), which started as the academic amalgam\nof neuroscience and AI research, has now become the dominant idea and\npreferred term.\n\n\u201cIn today\u2019s world, even the robotics people now call it computer vision,\u201d said\nJay Pathak, senior director of research and development at Ansys. \u201cThe\nclassical computer vision that used to happen outside of deep learning has\nbeen completely superseded. In terms of the success of AI, computer vision has\na proven track record. Anytime self-driving is involved, any kind of robot\nthat is doing work \u2014 its ability to perceive and take action \u2014 that\u2019s all\ndriven by deep learning.\u201d\n\nThe original intent of CV was to replicate the power and versatility of human\nvision. Because vision is such a basic sense, the problem seemed like it would\nbe far easier than higher-order cognitive challenges, like playing chess.\nIndeed, in the canonical anecdote about the field\u2019s initial na\u00efve optimism,\nMarvin Minsky, co-founder of the MIT AI Lab, having forgotten to include a\nvisual system in a robot, assigned the task to undergraduates. But instead of\nbeing quick to solve, the problem consumed a generation of researchers.\n\nBoth academic and industry researchers work on problems that roughly can be\nsplit into three categories:\n\n  * Image capture: The realm of digital cameras and sensors. It may use AI for refinements or it may rely on established software and hardware.\n  * Image classification/detection: A subset of AI/ML that uses image datasets as training material to build models for visual recognition.\n  * Image generation: The most recent work, which uses tools like LLMs to create novel images, and with the breakthrough demonstration of OpenAI\u2019s Sora, even photorealistic videos.\n\nEach one alone has spawned dozens of PhD dissertations and industry patents.\nImage classification/detection, the primary focus of this article, underlies\nADAS, as well as many inspection applications.\n\nThe change from lab projects to everyday uses came as researchers switched\nfrom rules-based systems that simulated visual processing as a series of\nif/then statements (if red and round, then apple) to neural networks (NNs), in\nwhich computers learned to derive salient features by training on image\ndatasets. NNs are basically layered graphs. The earliest model, 1943\u2019s\nPerceptron, was a one-layer simulation of a biological neuron, which is one\nelement in a vast network of interconnecting brain cells. Neurons have inputs\n(dendrites) and outputs (axons), driven by electrical and chemical signaling.\nThe Perceptron and its descendant neural networks emulated the form but\nskipped the chemistry, instead focusing on electrical signals with algorithms\nthat weighted input values. Over the decades, researchers refined different\nforms of neural nets with vastly increased inputs and layers, eventually\nbecoming the deep learning networks that underlie the current advances in AI.\n\nThe most recent forms of these network models are convolutional neural\nnetworks (CNNs) and transformers. In highly simplified terms, the primary\ndifference between them is that CNNs are very good at distinguishing local\nfeatures, while transformers perceive a more globalized picture.\n\nThus, transformers are a natural evolution from CNNs and recurrent neural\nnetworks, as well as long short-term memory approaches (RNNs/LSTMs), according\nto Gordon Cooper, product marketing manager for Synopsys\u2019 embedded vision\nprocessor family.\n\n\u201cYou get more accuracy at the expense of more computations and parameters.\nMore data movement, therefore more power,\u201d said Cooper. \u201cBut there are cases\nwhere accuracy is the most important metric for a computer vision application.\nPedestrian detection comes to mind. While some vision designs still will be\nwell served with CNNs, some of our customers have determined they are moving\ncompletely to transformers. Ten years ago, some embedded vision applications\nthat used DSPs moved to NNs, but there remains a need for both NNs and DSPs in\na vision system. Developers still need a good handle on both technologies and\nare better served to find a vendor that can provide a combined solution.\u201d\n\nThe emergence of CNN-based neural networks began supplanting traditional CV\ntechniques for object detection and recognition.\n\n\u201cWhile first implemented using hardwired CNN accelerator hardware blocks, many\nof those CNN techniques then quickly migrated to programmable solutions on\nsoftware-driven NPUs and GPNPUs,\u201d said Aman Sikka, chief architect at Quadric.\n\nTwo parallel trends continue to reshape CV systems. \u201cThe first is that\ntransformer networks for object detection and recognition, with greater\naccuracy and usability than their convolution-based predecessors, are\nbeginning to leave the theoretical labs and enter production service in\ndevices,\u201d Sikka explained. \u201cThe second is that CV experts are reinventing the\nclassical ISP functions with NN and transformer-based models that offer\nsuperior results. Thus, we\u2019ve seen waves of ISP functionality migrating first\nfrom pure hardwired to C++ algorithmic form, and now into advanced ML network\nformats, with a modern design today in 2024 consisting of numerous machine-\nlearning models working together.\u201d\n\nCV for inspection While CV is well-known for its essential role in ADAS,\nanother primary application is inspection. CV has helped detect everything\nfrom cancer tumors to manufacturing errors, or in the case of IBM\u2019s\nproductized research, critical flaws in the built environment. For example, a\ndrone equipped with the IBM system could check if a bridge had cracks, a far\nsafer and more precise way to perform visual inspection than having a human\nclimb to dangerous heights.\n\nBy combining visual transformers with self-supervised learning, the annotation\nrequirement is vastly reduced. In addition, the company has introduced a new\nprocess named \u201cvisual prompting,\u201d where the AI can be taught to make the\ncorrect distinctions with limited supervision by using \u201cin-context learning,\u201d\nsuch as a scribble as a prompt. The optimal end result is that it should be\nable to respond to LLM-like prompts, such as \u201cfind all six-inch cracks.\u201d\n\n\u201cEven if it makes mistakes and needs the help of human annotations, you\u2019re\ndoing far less labeling work than you would with traditional CNNs, where you\u2019d\nhave to do hundreds if not thousands of labels,\u201d said Jayant Kalagnanam,\ndirector, AI applications at IBM Research.\n\nBeware the humans Ideally, domain-specific datasets should increase the\naccuracy of identification. They are often created by expanding on foundation\nmodels already trained on general datasets, such as ImageNet. Both types of\ndatasets are subject to human and technical biases. Google\u2019s infamous racial\nidentification gaffes resulted from both technical issues and subsequent human\novercorrections.\n\nMeanwhile, IBM was working on infrastructure identification, and the company\u2019s\nexperience of getting its model to correctly identify cracks, including the\nproblem of having too many images of one kind of defect, suggests a potential\nsolution to the bias problem, which is to allow the inclusion of contradictory\nannotations.\n\n\u201cEverybody who is not a civil engineer can easily say what a crack is,\u201d said\nCristiano Malossi, IBM principal research scientist. \u201cSurprisingly, when we\ndiscuss which crack has to be repaired with domain experts, the amount of\ndisagreement is very high because they\u2019re taking different considerations into\naccount and, as a result, they come to different conclusions. For a model,\nthis means if there\u2019s ambiguity in the annotations, it may be because the\nannotations have been done by multiple people, which may actually have the\nadvantage of introducing less bias.\u201d\n\nFig. 1: IBM\u2019s Self-supervised learning model. Source: IBM\n\nCorner cases and other challenges to accuracy The true image dataset is\ninfinity, which in practical terms leaves most computer vision systems\nvulnerable to corner cases, potentially with fatal results, noted Alan Yuille,\nBloomberg distinguished professor of cognitive science and computer science at\nJohns Hopkins University.\n\n\u201cSo-called \u2018corner cases\u2019 are rare events that likely aren\u2019t included in the\ndataset and may not even happen in everyday life,\u201d said Yuille.\n\u201cUnfortunately, all datasets have biases, and algorithms aren\u2019t necessarily\ngoing to generalize to data that differs from the datasets they\u2019re trained on.\nAnd one thing we have found with deep nets is if there is any bias in the\ndataset, the deep nets are wonderful at finding it and exploiting it.\u201d\n\nThus, corner cases remain a problem to watch for. \u201cA classic example is the\nidea of a baby in the road. If you\u2019re training a car, you\u2019re typically not\ngoing to have many examples of images with babies in the road, but you\ndefinitely want your car to stop if it sees a baby,\u201d said Yuille. \u201cIf the\ncompanies are working in constrained domains, and they\u2019re very careful about\nit, that\u2019s not necessarily going to be a problem for them. But if the dataset\nis in any way biased, the algorithms may exploit the biases and corner cases,\nand may not be able to detect them, even if they may be of critical\nimportance.\u201d\n\nThis includes instances, such as real-world weather conditions, where an image\nmay be partly occluded. \u201cIn academic cases, you could have algorithms that\nwhen evaluated on standard datasets like ImageNet are getting almost perfect\nresults, but then you can give them an image which is occluded, for example,\nby a heavy rain,\u201d he said. \u201cIn cases like that, the algorithms may fail to\nwork, even if they work very well under normal weather conditions. A term for\nthis is \u2018out of domain.\u2019 So you train in one domain and that may be cars in\nnice weather conditions, you test in out of domain, where there haven\u2019t been\nmany training images, and the algorithms would fail.\u201d\n\nThe underlying reasons go back to the fundamental challenge of trying to\nreplicate a human brain\u2019s visual processing in a computer system.\n\n\u201cObjects are three-dimensional entities. Humans have this type of knowledge,\nand one reason for that is humans learn in a very different way than machine\nlearning AI algorithms,\u201d Yuille said. \u201cHumans learn over a period of several\nyears, where they don\u2019t only see objects. They play with them, they touch\nthem, they taste them, they throw them around.\u201d\n\nBy contrast, current algorithms do not have that type of knowledge.\n\n\u201cThey are trained as classifiers,\u201d said Yuille. \u201cThey are trained to take\nimages and output a class label \u2014 object one, object two, etc. They are not\ntrained to estimate the 3D structure of objects. They have some sort of\nimplicit knowledge of some aspects of 3D, but they don\u2019t have it properly.\nThat\u2019s one reason why if you take some of those models, and you\u2019ve\ncontaminated the images in some way, the algorithms start degrading badly,\nbecause the vision community doesn\u2019t have datasets of images with 3D ground\ntruth. Only for humans, do we have datasets with 3D ground truth.\u201d\n\nHardware implementation, challenges The hardware side is becoming a\nbottleneck, as academics and industry work to resolve corner cases and create\never-more comprehensive and precise results. \u201cThe complexity of the operation\nbehind the transformer is quadratic,\u201c said Malossi. \u201cAs a result, they don\u2019t\nscale linearly with the size of the problem or the size of the model.\u201c\n\nWhile the situation might be improved with a more scalable iteration of\ntransformers, for now progress has been stalled as the industry looks for more\npowerful hardware or any suitable hardware. \u201cWe\u2019re at a point right now where\nprogress in AI is actually being limited by the supply of silicon, which is\nwhy there\u2019s so much demand, and tremendous growth in hardware companies\ndelivering AI,\u201d said Tony Chan Carusone, CTO of Alphawave Semi. \u201cIn the next\nyear or two, you\u2019re going to see more supply of these chips come online, which\nwill fuel rapid progress, because that\u2019s the only thing holding it back. The\nmassive investments being made by hyperscalers is evidence about the backlogs\nin delivering silicon. People wouldn\u2019t be lining up to write big checks unless\nthere were very specific projects they had ready to run as soon as they get\nthe silicon.\u201d\n\nAs more AI silicon is developed, designers should think holistically about CV,\nsince visual fidelity depends not only on sophisticated algorithms, but image\ncapture by a chain of co-optimized hardware and software, according to Pulin\nDesai, group director of product marketing and management for Tensilica\nvision, radar, lidar, and communication DSPs at Cadence. \u201cWhen you capture an\nimage, you have to look at the full optical path. You may start with a camera,\nbut you\u2019ll likely also have radar and lidar, as well as different sensors. You\nhave to ask questions like, \u2018Do I have a good lens that can focus on the\nproper distance and capture the light? Can my sensor perform the DAC\ncorrectly? Will the light levels be accurate? Do I have enough dynamic range?\nWill noise cause the levels to shift?\u2019 You have to have the right equipment\nand do a lot of pre-processing before you send what\u2019s been captured to the AI.\nRemember, as you design, don\u2019t think of it as a point solution. It\u2019s an end-\nto-end solution. Every different system requires a different level of full\npath, starting from the lens to the sensor to the processing to the AI.\u201d\n\nOne of the more important automotive CV applications is passenger monitoring,\nwhich can help reduce the tragedies of parents forgetting children who are\nstrapped into child seats. But such systems depend on sensors, which can be\nchallenged by noise to the point of being ineffective.\n\n\u201cYou have to build a sensor so small it goes into your rearview mirror,\u201d said\nJayson Bethurem, vice president of marketing and business development at Flex\nLogix. \u201cThen the issue becomes the conditions of your car. The car can have\nthe sun shining right in your face, saturating everything, to the complete\nopposite, where it\u2019s completely dark and the only light in the car is emitting\noff your dashboard. For that sensor to have that much dynamic range and the\nlevel of detail that it needs to have, that\u2019s where noise creeps in, because\nyou can\u2019t build a sensor of that much dynamic range to be perfect. On the\nedges, or when it\u2019s really dark or oversaturated bright, it\u2019s losing quality.\nAnd those are sometimes the most dangerous times.\u201d\n\nBreaking into the black box Finally, yet another serious concern for computer\nvision systems is the fact that they can\u2019t be tested. Transformers,\nespecially, are a notorious black box.\n\n\u201cWe need to have algorithms that are more interpretable so that we can\nunderstand what\u2019s going on inside them,\u201d Yuille added. \u201cAI will not be\nsatisfactory till we move to a situation where we evaluate algorithms by being\nable to find the failure mode. In academia, and I hope companies are more\ncareful, we test them on random samples. But if those random samples are\nbiased in some way \u2014 and often they are \u2014 they may discount situations like\nthe baby in the road, which don\u2019t happen often. To find those issues, you\u2019ve\ngot to let your worst enemy test your algorithm and find the images that break\nit.\u201d\n\nRelated Reading Dealing With AI/ML Uncertainty How neural network-based AI\nsystems perform under the hood is currently unknown, but the industry is\nfinding ways to live with a black box.\n\n13 Shares\n\n7\n\n5\n\nTags: AI/ML Alan Yuille Alphawave Semi ANSYS Cadence CNNs computer vision Flex\nLogix IBM IBM Research image capture image generation image identification\nJohns Hopkins University LLMs LSTMs Marvin Minsky MIT neural networks Quadric\nRNNs Synopsys Terry Sejnowski transformers\n\n### Karen Heyman\n\n(all posts) Karen Heyman is a technology editor at Semiconductor Engineering.\n\n### Leave a Reply Cancel reply\n\n### Technical Papers\n\n  * Optimizing Offload Performance In Heterogeneous Multi-Processor SoCs (ETH Zurich) May 3, 2024 by Technical Paper Link\n  * Distributing RTL Simulation Across Thousands Of Cores On 4 IPU Sockets (EPFL) May 2, 2024 by Technical Paper Link\n  * A Micro Light-Emitting Transistor With An N-Channel GaN FET In Series With A GaN LED May 2, 2024 by Technical Paper Link\n  * Voltage Reference Architectures For Harsh Environments: Quantum Computing And Space May 2, 2024 by Technical Paper Link\n  * Framework For Early Anomaly Detection In AMS Components Of Automotive SoCs April 30, 2024 by Technical Paper Link\n\n## Knowledge Centers Entities, people and technologies explored\n\n## Related Articles\n\n### The Rising Price Of Power In Chips\n\nMore data requires faster processing, which leads to a whole bunch of problems\n\u2014 not all of which are obvious or even solvable.\n\nby Ed Sperling\n\n### Chiplet IP Standards Are Just The Beginning\n\nData and protocol interoperability standards are needed for EDA tools, and\nthere are more hurdles ahead. Customized chiplets will be required for AI\napplications.\n\nby Ann Mutschler\n\n### The Future Of Memory\n\nFrom attempts to resolve thermal and power issues to the roles of CXL and\nUCIe, the future holds a number of opportunities for memory.\n\nby Karen Heyman\n\n### Electromigration Concerns Grow In Advanced Packages\n\nHigher density, heat, and more materials make it harder to ensure reliability.\n\nby Laura Peters\n\n### Silicon Photonics Manufacturing Ramps Up\n\nThe promise of photonics ICs is spurring innovation, but complex processes and\na lack of open foundries are keeping it from reaching its full potential.\n\nby Gregory Haley\n\n### Backside Power Delivery Gears Up For 2nm Devices\n\nBut this novel approach to optimizing logic performance depends on advancing\nlithography, etching, polishing, and bonding processes.\n\nby Laura Peters\n\n### X-ray Inspection In The Semiconductor Industry\n\nUtilizing multiple technologies helps create a more complete inspection\npicture.\n\nby Chris Rand\n\n### SRAM Scaling Issues, And What Comes Next\n\nWhile it will remain a workhorse memory, using SRAM at advanced nodes requires\nnew approaches.\n\nby Karen Heyman\n\n  * ### Sponsors\n\n  * Advertise with us\n\n  * Advertise with us\n\n  * Advertise with us\n\n  * ### Newsletter Signup\n\nThank you. Please check your email to confirm your subscription.\n\n* ### Popular Tags\n\n2.5D 5G 7nm advanced packaging AI ANSYS Apple Applied Materials ARM automotive\nbusiness Cadence EDA eSilicon EUV finFETs GlobalFoundries Google IBM imec\nInfineon Intel IoT IP Keysight Lam Research machine learning memory Mentor\nMentor Graphics MIT Moore's Law Nvidia NXP Qualcomm Rambus Samsung security\nSEMI Siemens Siemens EDA software Synopsys TSMC verification\n\n* ### Recent Comments\n\n  * David Scott on Is There Any Hope For Asynchronous Design?\n  * Ron Lavallee on Is There Any Hope For Asynchronous Design?\n  * Mahdoum on Multi-Die Design Pushes Complexity To The Max\n  * Cliff Cummings on Is There Any Hope For Asynchronous Design?\n  * Yaron k. on Is There Any Hope For Asynchronous Design?\n  * Shiv Sikand on Is There Any Hope For Asynchronous Design?\n  * Anne Meixner on Too Much Fab And Test Data, Low Utilization\n  * Mark Hahn on CXL: The Future Of Memory Interconnect?\n  * Dr. Richard Roy on Future-Proofing Automotive V2X\n  * Frank-Peter Ludwig on Enabling Advanced Devices With Atomic Layer Processes\n  * Piyush Kumar Mishra on Using AI/ML To Minimize IR Drop\n  * Rakesh on Timing Library LVF Validation For Production Design Flows\n  * Mike Cawthorn on What Will That Chip Cost?\n  * Liz Allan on Early STEM Education Key To Growing Future Chip Workforce\n  * Rob Pearson - RIT on Early STEM Education Key To Growing Future Chip Workforce\n  * Maury Wood on Examining The Impact Of Chip Power Reduction On Data Center Economics\n  * Erik Jan Marinissen on Chiplet IP Standards Are Just The Beginning\n  * Peter Bennet on Design Tool Think Tank Required\n  * Dr. Dev Gupta on Chiplet IP Standards Are Just The Beginning\n  * Jesse on Hunting For Open Defects In Advanced Packages\n  * Matt on Chip Ecosystem Apprenticeships Help Close The Talent Gap\n  * Leonard Schaper IEEE-LF on 2.5D Integration: Big Chip Or Small PCB?\n  * Apex on Nanoimprint Finally Finds Its Footing\n  * AKC on Gearing Up For Hybrid Bonding\n  * Allen Rasafar on Backside Power Delivery Gears Up For 2nm Devices\n  * Nathaniel on Intel, And Others, Inside\n  * Chris G on Intel, And Others, Inside\n  * Richard Collins on Too Much Fab And Test Data, Low Utilization\n  * Jerry Magera on Why Chiplets Are So Critical In Automotive\n  * Jenn Mullen on Shattered Silos: 2024\u2019s Top Technology Trends\n  * Valerio Del Vecchio on Security Becoming Core Part Of Chip Design \u2014 Finally\n  * Lucas on Hybrid Bonding Basics: What Is Hybrid Bonding?\n  * Robin Grindley on Expand Your Semiconductor\u2019s Market With Programmable Data Planes\n  * V.P.Sampath on RISC-V Micro-Architectural Verification\n  * Thermal Guy on Is UCIe Really Universal?\n  * Colt Wright on Shattered Silos: 2024\u2019s Top Technology Trends\n  * Nicolas Dujarrier on The Future Of Memory\n  * Tony on Challenges Of Logic BiST In Automotive ICs\n  * Raymond Meixner's child on Visa Shakeup On Tap To Help Solve Worker Shortage\n  * Michael Alan Bruzzone on How Is The Chip Industry Really Doing?\n  * Art Scott on How Is The Chip Industry Really Doing?\n  * Liz Allan on Rethinking Engineering Education In The U.S.\n  * Telkom University on Rethinking Engineering Education In The U.S.\n  * Ramesh Babu Varadharajan on SRAM\u2019s Role In Emerging Memories\n  * jake_leone on Visa Shakeup On Tap To Help Solve Worker Shortage\n  * d0x on How Secure Are FPGAs?\n  * Mike Bradley on RISC-V Micro-Architectural Verification\n  * Charles E. Bauer ,Ph.D. on Visa Shakeup On Tap To Help Solve Worker Shortage\n  * AMAN SINGH on Power Aware Intent And Structural Verification Of Low-Power Designs\n  * jake_leone on Visa Shakeup On Tap To Help Solve Worker Shortage\n  * Ed Trevis on Visa Shakeup On Tap To Help Solve Worker Shortage\n  * AMAN SINGH on Get To Know The Gate-Level Power Aware Simulation\n  * Pitchumani Guruswamy on RISC-V Micro-Architectural Verification\n  * Manil Vasantha on AI Accelerator Architectures Poised For Big Changes\n  * Ramachandra on Packaging Demands For RF And Microwave Devices\n  * garry on New Insights Into IC Process Defectivity\n  * Brian Bailey on The Good Old Days Of EDA\n  * Ann Mutschler on AI Accelerator Architectures Poised For Big Changes\n  * Ann Mutschler on AI Accelerator Architectures Poised For Big Changes\n  * John Derrick on AI Accelerator Architectures Poised For Big Changes\n  * allan cox on AI Accelerator Architectures Poised For Big Changes\n  * Madhusudhanan RAVISHANKAR on Curbing Automotive Cybersecurity Attacks\n  * Eric Cigan on The Good Old Days Of EDA\n  * Peter Flake on The Good Old Days Of EDA\n  * Mike Cummings on MEMS: New Materials, Markets And Packaging\n  * Brian Bailey on The Good Old Days Of EDA\n  * Bill Martin on The Good Old Days Of EDA\n  * Gretchen Patti on 3D-ICs May Be The Least-Cost Option\n  * Carlos on An Entangled Heterarchy\n  * Ann Mutschler on Flipping Processor Design On Its Head\n  * Gil Russell on Flipping Processor Design On Its Head\n  * Ed Sperling on China Unveils Memory Plans\n  * David on The Limits Of AI-Generated Models\n  * Bill on The Limits Of AI-Generated Models\n  * Dr. Dev Gupta on Gearing Up For Hybrid Bonding\n  * Faizan on China Unveils Memory Plans\n  * Jan Hoppe on Streamlining Failure Analysis Of Chips\n  * Riko R on Why Curvy Design Now? Manufacturing Is Possible And Scaling Needs It\n  * Derrick Meyer on Higher Automotive MCU Performance With Interface IP\n  * Kevin Cameron on Why Silent Data Errors Are So Hard To Find\n  * Rale on How Secure Are RISC-V Chips?\n  * Ed Sperling on Patterns And Issues In AI Chip Design\n  * Chip Greely on Building Better Bridges In Advanced Packaging\n  * Art Scott on Setting Standards For The Chip Industry\n  * Muhammet on Higher Creepage And Clearance Make For More Reliable Systems\n  * Andy Deng on Quantum Plus AI Widens Cyberattack Threat Concerns\n  * Dr. Rahul Razdan on The Threat Of Supply Chain Insecurity\n  * Roger on Patterns And Issues In AI Chip Design\n  * David Leary on Improving Reliability In Chips\n  * Ann Mutschler on The Threat Of Supply Chain Insecurity\n  * Cliff Greenberg on Setting Standards For The Chip Industry\n  * Kevin Parmenter on The Threat Of Supply Chain Insecurity\n  * Esther soria on Automotive Complexity, Supply Chain Strength Demands Tech Collaboration\n  * Kumar Venkatramani on Predicting The Future For Semiconductors\n  * Spike on Is UCIe Really Universal?\n  * David Sempek on Power Semis Usher In The Silicon Carbide Era\n  * Dp on Specialization Vs. Generalization In Processors\n  * Eric on Addressing The ABF Substrate Shortage With In-Line Monitoring\n  * Karl Stevens Logic Designer on Software-Hardware Co-Design Becomes Real\n  * Jim Handy on MRAM Getting More Attention At Smallest Nodes\n  * Nicolas Dujarrier on MRAM Getting More Attention At Smallest Nodes\n  * Lou Covey on Are In-Person Conferences Sustainable?\n  * Cas Wonsowicz on AI Transformer Models Enable Machine Vision Object Detection\n  * Nancy Zavada on Are In-Person Conferences Sustainable?\n  * Fred Chen on High-NA Lithography Starting To Take Shape\n  * Dave Taht on Wi-Fi 7 Moves Forward, Adding Yet Another Protocol\n  * Robert Boissy on Rethinking Engineering Education In The U.S.\n  * Allen Rasafar on High-NA Lithography Starting To Take Shape\n  * Mathias Tomandl on Multi-Beam Writers Are Driving EUV Mask Development\n  * K on High-NA Lithography Starting To Take Shape\n  * Adibhatla krishna Rao on How Do Robots Navigate?\n  * Doug L. on Getting Rid Of Heat In Chips\n  * Ken Rygler on DAC/Semicon West Wednesday\n  * Mark Camenzind on Why IC Industry Is Great Place To Work\n  * Peter Bennet on The True Cost Of Software Changes\n  * ALLEN RASAFAR on Balancing AI And Engineering Expertise In The Fab\n  * Ron Lavallee on The True Cost Of Software Changes\n  * Alex Peterson on Welcome To EDA 4.0 And The AI-Driven Revolution\n  * Allen Rasafar on Managing Yield With EUV Lithography And Stochastics\n  * Art Scott on Rethinking Engineering Education In The U.S.\n\nCan Models Created With AI Be Tr... Brian Bailey\n\nOptimizing Offload Performance I... Technical Paper Link\n\n### About\n\n  * About us\n  * Contact us\n  * Advertising on SemiEng\n  * Newsletter SignUp\n\n### Navigation\n\n  * Homepage\n  * Special Reports\n  * Systems & Design\n  * Low Power-High Perf\n  * Manufacturing, Packaging & Materials\n  * Test, Measurement & Analytics\n  * Auto, Security & Pervasive Computing\n\n  * Videos\n  * Jobs\n  * Technical Papers\n  * Events\n  * Webinars\n  * Knowledge Centers\n  * Industry Research\n  * Business & Startups\n  * Newsletters\n  * Store\n\n### Connect With Us\n\n  * Facebook\n  * Twitter @semiEngineering\n  * LinkedIn\n  * YouTube\n\nCopyright \u00a92013-2024 SMG | Terms of Service | Privacy Policy\n\nThis site uses cookies. By continuing to use our website, you consent to our\nCookies Policy\n\nACCEPT\n\nManage consent\n\n#### Privacy Overview\n\nThis website uses cookies to improve your experience while you navigate\nthrough the website. The cookies that are categorized as necessary are stored\non your browser as they are essential for the working of basic functionalities\nof the website. We al...\n\nNecessary\n\nAlways Enabled\n\nNecessary cookies are absolutely essential for the website to function\nproperly. This category only includes cookies that ensures basic\nfunctionalities and security features of the website. These cookies do not\nstore any personal information.\n\nNon-necessary\n\nAny cookies that may not be particularly necessary for the website to function\nand is used specifically to collect user personal data via analytics, ads,\nother embedded contents are termed as non-necessary cookies. It is mandatory\nto procure user consent prior to running these cookies on your website.\n\nSAVE & ACCEPT\n\n# Search results\n\nFiltersShow filters\n\nSort by:\n\n\u2022\u2022\n\n## No results found\n\n## Filter options\n\n", "frontpage": false}
