{"aid": "40140768", "title": "Contra Hanson on Medical Effectiveness", "url": "https://www.astralcodexten.com/p/contra-hanson-on-medical-effectiveness", "domain": "astralcodexten.com", "votes": 1, "user": "feross", "posted_at": "2024-04-24 05:02:37", "comments": 0, "source_title": "Contra Hanson On Medical Effectiveness", "source_text": "Contra Hanson On Medical Effectiveness - by Scott Alexander\n\n# Astral Codex Ten\n\nShare this post\n\n#### Contra Hanson On Medical Effectiveness\n\nwww.astralcodexten.com\n\n# Contra Hanson On Medical Effectiveness\n\n### ...\n\nApr 24, 2024\n\n9\n\nShare this post\n\n#### Contra Hanson On Medical Effectiveness\n\nwww.astralcodexten.com\n\n38\n\nShare\n\n###\n\nI. Introduction\n\nRobin Hanson of Overcoming Bias more or less believes medicine doesn\u2019t work.\n\nThis is a strong claim. It would be easy to round Hanson\u2019s position off to\nsomething weaker, like \u201cextra health care isn\u2019t valuable on the margin\u201d. This\nis how most people interpret the studies he cites. Still, I think his current,\nactual position is that medicine doesn\u2019t work. For example, he writes:\n\n> Europeans in 1600 likely prided themselves on the ways in which their\n> \u201cmodern\u201d medicine was superior to what \u201cprimitives\u201d had to accept. But we\n> today aren\u2019t so sure: seventeenth century medical theory was based on the\n> four humors, and bloodletting was a common treatment. When we look back at\n> those doctors, we think they may well have done more harm than good.\n>\n> When we look at our own medical practices, however, we tend to be confident\n> we are in good hands, and that the money that goes to buying medical care\u2013in\n> 2020, it was 19.7% of our G.D.P. \u2013is well spent. Most of us know of a family\n> member who credits their life to modern medicine. My own dad said this about\n> his pacemaker, and I, too, am a regular customer: I\u2019m vaccinated, boosted,\n> and recently had surgery to fix a broken arm.\n>\n> We believe in medicine, and this faith has comforted us during the pandemic.\n> But likewise the patients of the seventeenth century; they could probably\n> also have named a relative cured by bloodletting. Yet health outcomes are\n> typically too random for the experience of one family to justify medical\n> confidence. How do we know our belief is justified?\n>\n> This might seem like a silly question: in Europe of the seventeenth century,\n> the average lifespan was in the low 30s. Now it\u2019s the low 80s. Isn\u2019t that\n> difference due to medicine? In fact, the consensus is now that historical\n> lifespan gains are better explained by nutrition, sanitation, and wealth.\n>\n> So let\u2019s turn to medical research. Every year, there are a million new\n> medical journal articles suggesting positive benefits of specific medical\n> treatments. That\u2019s something they didn\u2019t have in the seventeenth century.\n> Unfortunately, we now know the medical literature to be plagued by serious\n> biases, such as data-dredging, p-hacking, selection, attrition, and\n> publication biases. For example, in a recent attempt to replicate 53\n> findings from top cancer labs, 30 papers could not be replicated due to\n> issues like vague protocols and uncooperative authors, and less than half of\n> the others yielded results like the original findings.\n>\n> But surely modern science must have some reliable way to study the aggregate\n> value of medicine? Yes, we do. The key is to keep a study so simple, pre-\n> announced, and well-examined that there isn\u2019t much room for authors to\n> \u201ccheat\u201d by data-dredging, p-hacking, etc. Large trials where we randomly\n> induce some people to consume more medicine overall, and then track how\n> their health differs from a control population\u2013those are the key to reliable\n> estimates. If trials are big and expensive enough, with lots of patients\n> over many years, no one can possibly hide their results in a file drawer.\n\nAfter listing bigger studies that he interprets as showing no effects from\nmedicine, he concludes:\n\n> We spend 20% of G.D.P. on medicine, most people credit it for their long\n> lives, and millions of medical journal articles seem to confirm its enormous\n> value. Yet our lives are long for other reasons, those articles often show\n> huge biases, and when we look to our few best aggregate studies to assuage\n> our doubts, they do no such thing.\n\nOr, even more clearly:\n\n> Imagine someone claimed that casinos produce, not just entertainment, but\n> also money. I would reply that while some people have indeed walked away\n> from casinos with more money than they arrived with, it is very rare for\n> anyone to be able to reasonably expect this result. There may well be a few\n> such people, but there are severe barriers to creating regular social\n> practices wherein large groups of people can reasonably expect to make money\n> from casinos. We have data suggesting such barriers exist, and we have\n> reasonable theories of what could cause such barriers. Regarding medicine\n> (the stuff doctors do), my claims are similar.\n\nHis argument: there have been three big experimental studies of what happens\nwhen people get free (or cut-price) health care: RAND, Oregon, and Karnataka.\nAll three (according to him) find that people use more medicine, but don\u2019t get\nany healthier. Therefore, medicine doesn\u2019t work. If it looks like medicine\nworks, it\u2019s a combination of anecdotal reasoning, biased studies, and giving\nmedicine credit for the positive effects of other good things (better\nnutrition, sanitation, etc).\n\nI\u2019ve spent fifteen years not responding to this argument, because I worry it\nwould be harsh and annoying to use my platform to beat up on one contrarian\nwho nobody else listens to. But I recently learned Bryan Caplan also takes\nthis seriously. Beating up on two contrarians who nobody else listens to is a\ngreat use of a platform!\n\nSo I want to argue:\n\n  * Medicine obviously has to work\n\n  * Examined more closely, the three experiments Robin cites don\u2019t really support his thesis\n\n  * There are other experiments which provide clearer evidence that medicine works\n\nI\u2019ll follow Robin\u2019s lead in dismissing the entire medical literature - every\nRCT of every medication or treatment ever published - because it might have\n\u201chuge biases,\u201d and try to rely on other sources.\n\n###\n\nII. Modern Medicine Improves Survival Rate\n\nWhat do I mean by \u201cmedicine obviously has to work\u201d?\n\nAge-adjusted mortality rate from most diseases has declined significantly over\nthe past few decades. Robin doesn\u2019t want to credit medicine, arguing that this\nmight be due to \u201cnutrition, sanitation, and wealth\u201d.\n\nBut we can more clearly distinguish the effects of medicine by looking at the\neffects of secondary prevention, ie how someone does after they get a specific\ndisease. For example, what percent of cancer patients die in five years? What\npercent of heart attack patients die within the first month after their heart\nattack? This is the kind of thing that depends a lot on how much medical care\nyou get, and is less affected by things like nutrition or sanitation.\n\n(I\u2019m more confident saying this about sanitation and wealth. You can imagine\nnutrition improving this - maybe better-nourished cancer patients are better\nable to fight their disease - but nutrition hasn\u2019t really improved over the\npast few decades in First World countries anyway.)\n\nHere are 5-year survival rates for various cancers, 1970s vs. 2000s:\n\n(source)\n\nPeople with cancer are more likely to survive than fifty years ago.\n\nThis is after you\u2019ve already gotten the cancer, so it\u2019s hard to see how\nnutrition, sanitation, etc could explain this. Some of these changes\n(especially prostate) are a result of earlier diagnosis. But others reflect\ngenuinely better treatment. For example, studies have shown great results from\nthe anti-leukemia drug imatinib and the anti-lymphoma drug rituximab. In\nRobin\u2019s model, these extraordinary studies would have to be bias or chance,\nand totally coincidentally at the same time somehow better nutrition made\nleukemia patients (but not uterine cancer patients) twice as likely to\nsurvive.\n\nMight this be because people are getting cancer younger (and therefore are\nbetter able to deal with it?) I can\u2019t find great data on this; there\u2019s\nincreasing cancer among younger people, but (since people are living longer)\nwe should also expect increasing cancer among older people (since there are\nmore older people). Rather than try to figure out how to balance these\neffects, here\u2019s a graph showing similar survival improvements among childhood\ncancers in particular, where we wouldn\u2019t expect this to be a problem:\n\n(source)\n\nLikewise, here is post-heart attack 30-day mortality rate over time:\n\nSource here.\n\nThe odds of death within 30 days of a heart attack have fallen from 20% in\n1995 to 12.4% in 2015 (source). This is also no mystery; the improvement comes\nfrom increased use of basic drugs like ACEIs, aspirin, and beta-blockers, plus\nmore advanced interventions like thrombolytics and angioplasties, plus\nlogistical improvements like more heart attack patients being placed on\nspecialized cardiac wards.\n\nAgain, can we dismiss this because maybe heart attack victims are younger? The\nstudy this particular graph comes from says their patients were on average 2.7\nyears older at the end than the beginning, so here age effects seem to point\nin the opposite direction. Here\u2019s a graph showing the same decline if you\nbreak it up by under- and over-65s, though I wish I could find something with\nsmaller bins.\n\nSame data for stroke:\n\nSource here. Note that these are age-adjusted data!\n\nIn 2000, a stroke victim is only half as likely to die in the first two years\nafter their illness as they were in 1980. Here we don\u2019t have to worry about\nage effects at all; the graph is already adjusted for age.\n\nYou can see similar survival rate increases for other conditions like\ncongestive heart failure (5-year survival rate went from 29% to 60% since\n1970), multiple sclerosis (standardized mortality rate went from 3.1 to 0.7\nsince 1950), type 1 diabetes (survival rate at 50 from about 40% to 80% since\n1950) and nearly any other condition you look up.\n\nI\u2019m harping on this because it\u2019s in some sense the central example of\nmedicine: you get some deadly disease like cancer, and you want to know if\ndoctors can help you survive or not. All the evidence suggests medicine has\ngotten much better at this in the past fifty years. Robin\u2019s going to have a\nlot of hard-to-interpret studies about what happens to your cholesterol score\nor whatever after you change insurance, and we\u2019ll pick these apart, but to me\nthis seems like a much less central example of \u201cdoes medicine work?\u201d than the\nfact that we\u2019re curing cancer and increasing heart attack survival rates.\n\n###\n\nIII. RAND Health Insurance Experiment\n\nThis is considered the canonical study on the effect of health insurance. In\nthe 1970s, RAND gave thousands of people one of five types of insurance,\nranging from very bad (barely any coverage until a family reached a deductible\nof $1000, ie $5000 in today\u2019s dollars) to very good (all care was free). Then\nthey waited eight years. Then they checked whether the people on the good\ninsurance ended up any healthier than the people on the bad insurance.\n\nThe paper I found measured five questionnaire-based outcomes plus five\nobjective physiological measures, for a total of ten outcomes (Robin says he\nhas a book where they discuss 23 to 30 outcomes, but I don\u2019t have that book,\nso I\u2019m sticking with the paper). The ten in the paper I read were:\n\n  1. Physical functioning questionnaire\n\n  2. Role functioning questionnaire\n\n  3. Mental health questionnaire\n\n  4. Social life questionnaire\n\n  5. Health perceptions questionnaire\n\n  6. Smoking\n\n  7. Weight\n\n  8. Cholesterol\n\n  9. Vision\n\n  10. Blood pressure\n\nThey found no effect of insurance on any of the questionnaires, and modest\npositive effects on vision and blood pressure.\n\nHow surprising is this?\n\nIt seems moderately surprising that nobody improved on any of the\nquestionnaires. These seem to measure overall health. Maybe they were bad\nmeasures? Maybe 10,000 mostly-healthy people over 8 years doesn\u2019t provide\nenough power to detect health improvements on questionnaires? I\u2019m not sure.\n\nIt doesn\u2019t seem surprising to me that nobody improved on smoking, weight, or\ncholesterol. The 1970s didn\u2019t have any good anti-smoking medication - even the\nnicotine patch wasn\u2019t invented until after this study was finished. Likewise\nfor weight loss - the 1970s were in the unfortunate interregnum between the\nfall of methamphetamine and the rise of Ozempic. There were some weak\ncholesterol medications back then - eg nicotinic acid - but they were rarely\nused, and doctors weren\u2019t even entirely convinced that cholesterol was bad.\nFor all three of these things, the 1970s state of the art was doctors saying\n\u201cYou should try to stop smoking and eat better.\u201d RAND found that the better\ninsurances led to 1-2 more doctor visits per year. I don\u2019t think that 3 visits\nto a doctor saying \u201cYou should try to stop smoking and eat better\u201d vs. 4\nvisits to that doctor is going to affect very much.\n\nIt\u2019s also not surprising that vision improved; the good insurances were more\nlikely to cover glasses, and everyone knows that glasses help your vision.\nEven Robin admits this is a real effect; he just classifies it as more physics\nthan medicine.\n\nBlood pressure is more debatable. The 1970s had some okay blood pressure\nmedications, like the beta-blockers, and doctors weren\u2019t afraid to use them.\nSo it seems possible in theory that better medical care could lead to\ndecreased blood pressure. Still, Robin is skeptical. He says that the\nimprovement in blood pressure found during the study was p = 0.03. In a study\nwith 30 measures, one will be positive at 0.03 by coincidence. The version of\nthe study he\u2019s reading has 30 measures (mine has 5 - 10, depending on how you\ncount the questionnaire).\n\nOn the other hand, this paper looks into the blood pressure result in more\ndetail. It finds that \u201cplan effects on blood pressure\u201d were three times higher\nfor hypertensives for non-hypertensives; that is, unlike statistical flukes\n(which we would expect to affect everyone equally), the effect was\nconcentrated in the people we would expect doctors to treat. It also finds\nthat plan effects are higher for poor people; unlike statistical flukes (which\nwould affect everyone equally), the effect was concentrated in the people we\nwould expect insurance to help. And it finds pretty convincing intermediating\nfactors: people with good insurance were 20 percentage points more likely to\nget hypertension treatment, p < 0.001). So I think it\u2019s a stretch to attribute\nthis one to random noise.\n\nThis is the study authors\u2019 conclusion as well. They calculate the benefit from\nthis blood pressure improvement and find that:\n\n> If 1,000 fifty-year-old men at elevated risk were enrolled on a free rather\n> than a cost-sharing plan, then we would anticipate that about 11 of them,\n> who would otherwise have died, would be alive five years later.\n\nStill, they describe their study as having a negative result, because:\n\n> ...these mortality reductions, in and of themselves, are not sufficient to\n> justify free care for all adults.\n\nI assume they\u2019re working off of some kind of reasonable cost-effectiveness\nmodel for government spending here. Still, if I were a fifty year old adult, I\nmight be willing to personally spend a few hundred extra dollars a year to\nincrease my 5-year-survival-rate by 1%. Certainly I don\u2019t think it\u2019s fair to\ndescribe this as \u201cRAND proves medicine doesn\u2019t work.\u201d\n\nRobin has a book with more information than I could get from the papers, so I\nfeel bad contradicting him on this one. I\u2019m more confident in my discussion of\nthe next two experiments, which I think are clear enough that we can go back\nto this one later and apply what we\u2019ve learned.\n\n###\n\nIV. Oregon Health Insurance Experiment\n\nIn 2008, Oregon had extra money and decided to expand Medicaid, a free\ninsurance program for poor people. Many people applied for the free insurance,\nthe state ran out of money, and they distributed the available Medicaid slots\nby lottery. This made the expansion a perfect setup for a randomized\ncontrolled trial on whether government-provided free insurance helps the poor.\n\nScientists monitored the recipients for two years (why not longer? I think at\nsome point the insurance coverage stopped) and found that the people with\nMedicaid did in fact use more medical care than the control group. For\nexample, only 69% of the control group described themselves as getting all the\nmedical care they needed, but 93% of the group with insurance did. People with\nthe insurance used more of almost all categories of medication:\n\nPeople who got the free insurance had less medical debt at the end of the\nstudy period. They described themselves on questionnaires as having better\nhealth (55% vs. 68% at least \u201cgood\u201d, p < 0.0001), and were more likely to say\ntheir health had improved over the past few months (71% vs. 83%, p < 0.001).\nThey described having better mental health and less depression (25% vs. 33%\ndepressed, p = 0.001).\n\nHowever, Robin notes that many of these subjective changes happened\nimmediately, ie before they even had a chance to use their new insurance. This\nmeans they\u2019re more likely to represent mood affiliation (eg \u201cI have insurance\nnow, so I\u2019m optimistic about my health!\u201d). There was no difference on\nobjective health measures, including blood pressure, cholesterol, and HbA1c (a\nmeasure of blood sugar / diabetes control).\n\nWhy not? The authors do the math on diabetes. If you look at the graph above,\nyou see that about 12.5% of controls vs. 17.5% of experimentals took diabetes\nmedications, p < 0.05. Studies find that diabetes medications decrease HbA1c\nby about one percentage point (normal HbA1c is about 5%, so this is a lot). If\n5% of the insurance group took diabetes medications and decreased their HbA1c\nby 1 pp each, then the HbA1c of the experimental group would decline by 0.05\npp compared to the control group. Their 95% confidence interval of the\ndifference was (-0.1, +0.1 pp), which includes the predicted value. So when\nthey say \u201cinsurance didn\u2019t significantly change HbA1c\u201d, what they mean is \u201cthe\nchange in HbA1c is completely consistent with the consensus effect of\nantidiabetic medications\u201d.\n\nCould the same be true of the other results, like hypertension? We find that\nthe experimental group was 1.8 percentage points more likely to get a\nhypertension diagnosis, 0.7 percentage points more likely to get hypertension\nmedications, and had 0.8 points lower blood pressure - but that all of these\nnumbers were nonsignificant. If we take the nonsignificant numbers seriously,\n0.7 pp taking antihypertensives caused an 0.8 point blood pressure drop in the\nfull sample, meaning that antihypertensives caused a 100 point blood pressure\ndrop in each user. This definitely isn\u2019t true - a 100 point blood pressure\ndrop kills you - but it means that a plausible pro-medicine result like\nantihypertensives lowering blood pressure 10 point is well within the study\u2019s\nconfidence interval.\n\nMaybe the anti-medicine position is that, for some reason, good insurance\ndoesn\u2019t lead to hypertension diagnosis or antihypertensive medication use? If\nI understand these numbers right, about 22% of Americans have blood pressure >\n140/90, the level at which doctors recommend medication. I expect the\nmarginally-insured poor people in this experiment to be less healthy than\naverage, so let\u2019s say 25 - 30%. In the experiment, about 13.9% of the control\ngroup and 14.6% of the experimental group got antihypertension medication. Why\nso low? This study found that only about 60% of participants in the Oregon\nstudy who got the insurance even went to the doctor for non-emergency reasons!\nSubtract out the ones who refused to take antihypertensives, or who have too\nmany side effects, or whose doctors let this fall through the cracks, and I\nthink the 13 - 15% numbers make sense.\n\nThis study found that insurance increased hypertension medication use by a\ncentral estimate of 0.7 pp, not significant, confidence interval -4.5 to 5.8.\nLet\u2019s take a convenient central estimate of our likely hypertension rate and\nsay that 28% of our population should have gotten hypertension meds. That\nmeans the central estimate increased the percent of people who got recommended\nhypertension meds from 50% to 53%, and the 95% confidence interval includes up\nto 71%.\n\nSo my assessment of the blood pressure results from this study is:\n\n  * At the beginning of the study, about 50% of people who should have been on hypertension meds were. The study had too low power to really figure out how this changed, but the central estimate is +3%, and the 95% CI rules out improvements beyond +21%\n\n  * The study had too low power to figure out if hypertension meds worked, and basically could not rule out any level of effectiveness, even effectiveness so high that the meds would instantly kill you by lowering your blood pressure to 0.\n\nI don\u2019t think we can summarize this study as \u201cwe\u2019ve proven medication doesn\u2019t\nwork\u201d.\n\n###\n\nV. Karnataka Health Insurance Experiment\n\nSame story, different scenery. This one happened in India. 10,000 families.\nEnd result is:\n\n> Having measured (a) 3 parameters (direct/indirect/total) for (b) 3 ITT and\n> one TOT effect for (c) 82 specified outcomes over 2 surveys, only 3 (0.46%\n> of all estimated coefficients concerning health outcomes) were significant\n> after multiple-testing adjustments. (As Table A8 shows, 55 parameters\n> (8.38%) are significant if we do not adjust for multiple-testing.) We cannot\n> reject the hypothesis that the distribution of p-values from these estimates\n> is consistent with no differences (P=0.31). We also find no effect of access\n> on our summary index of health outcomes (Table A6 and Table A7).\n\nIn other words:\n\n  * They tested a lot of stuff\n\n  * If you don\u2019t adjust for multiple comparisons, they got 55 significant results\n\n  * Once you adjust, they got 3 significant results\n\n  * They can\u2019t prove that getting 3 significant results is itself a significant result\n\n  * Their study was only powered to detect effects of size 0.1 or greater.\n\nIt\u2019s helpful to look at their table of measured outcomes (A7). This has some\nof the usual ones like blood pressure. But it also has things like:\n\n  * Doctor or nurse assisted with childbirth\n\n  * Gave birth in a hospital\n\n  * Had surgery\n\n  * Takes medicine for hypertension\n\n  * Told that they have diabetes\n\n  * Told that they have cancer\n\n...and these were among the majority of their outcomes where the study found\nno effect.\n\nThese don\u2019t cast doubt on the effectiveness of medical treatment. They just\nlook like a study where the intervention didn\u2019t affect the amount of medical\ncare people got very much. This was the authors\u2019 conclusion too. In fact, they\nwere unable to find a direct effect of giving people free insurance on those\npeople using insurance, at all, in the 3.5 year study period! They had to\nrescue this with \u201cspillover effects\u201d, ie the effect of one person getting\ninsurance in a village on other people, in order to even claim that the\ninsurance increased healthcare utilization.\n\nWhy couldn\u2019t they find an effect of giving people insurance on those people\nusing insurance? Insurance is very new in India. These people weren\u2019t really\nfamiliar with it, and in many cases their doctors and hospitals weren\u2019t very\nfamiliar with it. In a few cases it didn\u2019t even seem like the insurance\ncompanies fully understood their product:\n\n> Many households had difficulty using insurance to pay for healthcare. On\n> average across treatment arms, access to insurance increased by 3.34 pp\n> annually the number of households who tried to use their insurance card by\n> 18 months but were unable to do so (from a base of 2.68% in the control\n> group12). (Our TOT estimates suggest that insurance enrollment increased\n> failed use by 4.02 pp off a base of 3% annually.) This excess failure rate\n> is 50.50% of the successful utilization ITT effect.\n>\n> Lack of knowledge about the purpose of insurance and how to use insurance\n> seem likely explanations for the failure rate. Because insurance is a\n> relatively new product, hospitals and beneficiaries may not know how to use\n> it (Rajasekhar, Berg et al. 2011, Nandi, Dasgupta et al. 2016). In our\n> midline and endline surveys, we asked why households did not try to use\n> their insurance card to pay for care and why they were unable to use the\n> card even when they tried (Table A5). Frequent reasons given for not using\n> the card were not knowing that the card could be used for insurance (15% at\n> 18 months, 20% at 3.5 years), forgetting the card at home (13% at 18\n> months), not knowing how or where to use the card (29% and 30% at 3.5\n> years). Besides these beneficiary-side problems, there were also supply-side\n> problems. Of people that tried to use the card, 55% and 69% said that the\n> doctor did not accept the card at 18 months and 3.5 years, and 12% said that\n> the insurance company did not accept the card (i.e., did not approve use) at\n> 3.5 years. (These should be interpreted with caution because we do not know\n> if doctors correctly did not approve the card because a service was truly\n> not covered, or incorrectly did so.) This finding suggests that demand-side\n> education and supply-side logistics may be important for raising utilization\n> of (and thus demand for) insurance in India and similarly situated\n> countries.\n\nI don\u2019t want to over-update on this. They did eventually manage to find a\nmedium effect of free insurance on insurance use when counting the spillover\neffects. I think the main problem with this study is the same as all the other\nstudies - its confidence intervals are wide enough to include medicine working\namazingly well, better than anyone claims it works in real life.\n\nThis is what the authors think too:\n\n> Care should be taken in interpreting the insignificant health effects\n> observed. Perhaps the effect of hospital care on measured outcomes is too\n> small to translate into health improvements that we have power to detect\n> despite our substantial sample size (Das, Hammer et al. 2008). Moreover,\n> confidence intervals reported in Table A6 and Table A7 suggest that\n> medically significant effects for many outcomes cannot be ruled out.\n\n###\n\nVI. Summary Of Robin\u2019s Three Insurance Studies\n\nIf it helps, think of these insurance studies as a sort of funnel:\n\nIn order for more insurance to result in better health on some measurable\nparameter (eg lower blood pressure), you need a chain of four things.\n\n  * First, you need the better insurance to result in more doctors visits.\n\n  * Second, you need the doctors visits to result in more diagnoses (eg of high blood pressure).\n\n  * Third, you need the diagnoses to result in more treatment (eg blood pressure medication).\n\n  * Fourth, you need the treatment to work (actually lower blood pressure).\n\nEach step lowers our ability to detect a signal. That is, going to the doctor\ndoesn\u2019t, with 100% efficacy, result in more diagnoses. Some doctors will miss\nsome diagnoses; that will introduce noise and lower our power / statistical\nsignificance. You can imagine doing a whole paper on whether increasing\ndoctors\u2019 visits increases hypertension diagnoses; that paper would have a\np-value greater than zero / Bayes factor of less than infinity. So even\nassuming that better insurance really does improve health, each step we go\ndown the chain decreases our ability to detect that.\n\nIn fact, in these three studies, we find dropoffs below statistical\nsignificance scattered basically randomly throughout this chain:\n\n  * In some parts of the Karnataka study, we lose statistical significance at step 1. The better insurance didn\u2019t necessarily result in more medical utilization. For example, it didn\u2019t cause people to be (significantly) more likely to give birth in a hospital or get surgery.\n\n  * In the hypertension outcomes of the Oregon study, we lose statistical significance at step 2. The better insurance led to significantly more doctors\u2019 visits. But this didn\u2019t result in significantly more hypertension diagnoses (it only resulted in non-significantly more).\n\n  * I don\u2019t think we see any clear examples of losing significance at step 3, but you could sort of think of the smoking outcomes of the RAND study this way. The RAND participants with better insurance saw the doctor more. Probably the doctor noticed they were smoking and diagnosed them with this, insofar as \u201ctobacco use\u201d was a formal diagnosis at all in 1974. But there were no good anti-smoking treatments in the 1970s, so the doctor didn\u2019t prescribe anything.\n\n  * In the diabetes outcome of the Oregon study, we lose statistical significance at step 4. Diabetics with better health insurance were significantly more likely to see the doctor, significantly more likely to get diagnosed, and significantly more likely to get placed on medication, but only had nonsignificantly better health. Why? Probably because, as mentioned before, if diabetes medication worked as well as studies say it does, the study wouldn\u2019t have enough power to detect its effects.\n\nRobin\u2019s argument (that medicine doesn\u2019t work) assumes that the only possible\nfailure is at step 4, and that the failure must be a true failure rather than\none of statistical significance. But in fact there are failures at every step\n(although I kind of have to stretch it for step 3), and the authors of the\npapers tell us explicitly that these are most likely failures of statistical\npower.\n\nThis helps us think about a remaining question: why did these three studies\nget such different results?\n\n  * In the Oregon study, better insurance caused higher ratings of self-reported health. But in the RAND and Karnataka studies, it didn\u2019t.\n\n  * In the Oregon study, better insurance caused less depression. But in the RAND and Karnataka studies, it didn\u2019t.\n\n  * In the RAND study, better insurance caused increased use of antihypertensive medication. But in the Oregon and Karnataka studies, it didn\u2019t.\n\n  * In the RAND study, better insurance caused lower blood pressure. But in the Oregon and Karnataka studies, it didn\u2019t.\n\n  * In the Oregon study, better insurance caused more use of antidiabetic drugs. But in the Karnataka study, it didn\u2019t (AFAICT RAND didn\u2019t measure this).\n\nI think Robin attributes these differences to noise, ie the results being fake\nin the first place. He writes:\n\n> A muddled appearance of differing studies showing differing effects is to be\n> expected. After all, even if medicine has little effect, random statistical\n> error and biases toward presenting and publishing expected results will\n> ensure that many published studies suggest positive medical benefits.\n\nI think this is implausible. Many of these effects are large and replicable.\nFor example, the Oregon self-rating effects are p <0.0001 on each of four\ndifferent assessment methods, yet these are absolutely null in the other two\nstudies. The RAND blood pressure results are p < 0.03, but match our\nexpectations about subgroups (highest in the poor and sick) and accompanied by\na p < 0.01 finding that insurance results in more hypertension medication\n(which was absent in the Oregon study). The antidiabetic drug result in Oregon\nwas p = 0.008.\n\nCan we explain these through differences in the studies? I think Robin\u2019s\nanalysis here is actually pretty good. Expanding it slightly:\n\n  * RAND was a normal cross-section of Americans\n\n  * Oregon was poor and unhealthy Americans\n\n  * Karnataka was poor Indians who didn\u2019t know how to use insurance, and they only got hospital care (whereas the other two studies included primary care)\n\nWe find that Karnataka didn\u2019t result in as many utilization increases as the\nother two studies because it was only hospital care (which is unlikely to be\ninvolved in managing chronic problems like hypertension) and the recipients\nbarely used the improved insurance.\n\nWe find that Oregon had increased self-reported health because these were poor\nand unhealthy people who were very excited to get the new insurance. Robin\npoints out that 2/3 of the improvement came immediately after getting the\ninsurance, before they had time to use it, so this suggests a placebo effect.\nMaybe these poor unhealthy people were more excited about getting free\ninsurance than the comparatively well-off people in RAND or the insurance-\nnaive people in Karnataka?\n\nBut we can\u2019t dismiss the Oregon mental health findings as easily. Many of them\ncame from depression screening questionnaires that ask pretty specific\nquestions about eg sleep and suicidal thoughts over the past few weeks. I\nthink these findings are plausibly real, especially given the strong effects\nof insurance on mental health medication use (see first graph in section IV\nabove). If so, differences from RAND and Karnataka would be easy to explain:\n1970s Americans and rural Indians mostly don\u2019t have mental health problems (or\nat least don\u2019t think of them in those terms), whereas 2008 Americans do. In\n2008 America, depression is common and easy to measure. Also, antidepressants\nhave very large effect sizes (you may have heard they have small effect sizes,\nbut that\u2019s after you subtract the placebo effect; before you subtract placebo\neffect, they\u2019re extremely effective, and this study isn\u2019t controlling for\nplacebo). So this is exactly the sort of area where you\u2019d expect to see an\neffect. I won\u2019t say for sure it\u2019s real, but nothing about the studies makes me\nthink it isn\u2019t.\n\nThat just leaves the diastolic blood pressure effect in RAND. Remember our\nfunnel again: the difference between RAND and Oregon doesn\u2019t start in Step 4\n(does the drug work?) It starts in Steps 2-3 (did more medical visits result\nin more medication?)\n\nIn RAND, we found that better insurance increased the percent of hypertensives\non appropriate medication by 20 percentage points.\n\nIn Oregon, we found that it increased it by about 2 percentage points, but\nwith the confidence interval including 20.\n\nSo my guess is that the middle-class people in RAND were a bit more likely to\ngo for preventative medicine than the poorer people in Oregon, and that if we\nran both experiments a million times, we would get something like 5-10 pp out\nof Oregon and 15-20 pp out of RAND, and that\u2019s enough to give us the\nstatistical power to detect an effect in RAND but not Oregon. I can\u2019t prove\nthis is true because of the statistical power issues, it just seems like a\nreasonable explanation for the discrepancy.\n\nOne more point: because of statistical power issues and multiple hypothesis\ntesting, there are a lot of cases here where we can\u2019t say anything either way.\nThese might be places where an effect seems plausible but we can\u2019t prove it,\nor where we find an effect but can\u2019t prove that it isn\u2019t a result of multiple\nhypothesis testing. Here we should go back to the statistical basics and\nremember that this means more or less nothing. We shouldn\u2019t update our priors.\n\nPart of how Robin makes his counterintuitive argument against healthcare is to\nsay that all of these studies found \u201cnull effects\u201d, so now we have to believe\nmedicine is fake. I think instead we should look at the arguments in Section\nII above, start with a strong prior on medicine being real, and then -\nconfronted with studies that sometimes can\u2019t find anything for sure either way\n- continue having that prior.\n\n###\n\nVII. Other, More Positive Studies\n\nSince Robin posted the early versions of his argument, there\u2019s been a newer,\nbigger, RCT-like study on the effects of medicine.\n\nObamacare originally mandated that everyone get health insurance, and punished\nnoncompliance with a fine. In 2017, the IRS fined 4.5 million people for not\nhaving insurance. It originally planned to send these people a letter, saying\n\u201cObamacare mandates you to have insurance, you\u2019re getting fined for failing to\ncomply, please buy insurance through such-and-such a website.\u201d But it ran out\nof budget after sending 3.9 million letters to a randomly selected subset of\nthe insuranceless. The letter must have been at least a little convincing,\nbecause the 3.9 million recipients were 1.3 percentage points more likely to\nget insurance compared to the 0.6 million non-recipients. So the whole event\nturned out as a sort of randomized trial of telling people to get insurance.\n\nGoldin, Lurie, and McCubbin followed up on the results. Because this \u201cstudy\u201d\nwas so big compared to the others (4.5 million participants compared to a\nfive-digit number for RAND, Oregon, and Karnataka), they were able to measure\nmortality directly. They found that:\n\n> The rate of mortality among previously uninsured 45-64 year-olds was lower\n> in the treatment group than in the control by approximately 0.06 percentage\n> points, or one fewer death for every 1,648 individuals in this population\n> who were sent a letter. We found no evidence that the intervention reduced\n> mortality among children or younger adults over our sample period.\n>\n> Using treatment group assignment as an instrument for coverage, we estimate\n> that the average per-month effect of the coverage induced by the\n> intervention on two-year mortality was approximately -0.17 percentage\n> points. We caution, however, that the magnitude of the mortality eect is\n> imprecisely estimated; our condence interval is consistent with both\n> moderate and large eects of coverage on mortality. At the same time, our\n> estimated condence interval is suciently precise to rule out per-month eects\n> smaller in magnitude than -0.03 percentage points, including the estimate\n> from the OLS regression of mortality on coverage across individuals.\n\nThis result was p = 0.01 and robust to various checks.\n\nRobin\u2019s response:\n\n> A 2019 U.S. tax notification experiment did, maybe, see an effect. When 0.6\n> of 4.5 million eligible households were randomly not sent a letter warning\n> of tax penalties, the households warned were 1.1% more likely to buy\n> insurance, and 0.06% less likely to die, over the next two years. Now that\n> last death result was only significant at the 1% level, which is marginal.\n> So there\u2019s a decent chance this study is just noise.\n\nCome on! Thousands of clinical RCTs show that medicine has an effect. Robin\nwants to ignore these in favor of insurance experiments that are underpowered\nto find effects even when they\u2019re there. Then when someone finally does an\ninsurance experiment big and powerful enough to find effects, and it finds the\nsame thing as all the thousands of clinical RCTs, p = 0.01, Robin says maybe\nwe should dismiss it, because p = 0.01 findings are sometimes just \u201cnoise\u201d.\nAaargh!\n\nHere are some other quasi-experimental studies (h/t @agoodmanbacon):\n\nSommers, Baicker, and Epstein: finds that when some states expanded Medicaid\nafter Obamacare, mortality rate in those states (but not comparison states)\nwent down, p = 0.001. Note that Baicker was one of the main people behind the\nOregon experiment.\n\nSommers, Long, and Baicker: same story: after Romneycare, mortality in\nMassachusetts went down compared to comparison states (p = 0.003).\n\nCurrie and Gruber: increased Medicaid availability for children was associated\nwith lower child mortality (they don\u2019t give p-values, but some of the effects\nnoted seem large).\n\nSee more discussion on this thread.\n\n###\n\nVIII: Final Thoughts\n\nThe insurance literature doesn\u2019t do a great job in establishing one way or the\nother whether extra health insurance has detectable health effects on a\npopulation. Gun to my head, I\u2019d say it leans towards showing positive effects.\nBut if Robin wants to fight me on this, I can\u2019t 100% prove him wrong.\n\nBut it\u2019s far less tenable to say - as Robin does - that these studies show\nmedicine doesn\u2019t work. These studies are many steps away from showing that!\n\nFirst, as discussed above, it\u2019s unclear whether insurance studies themselves\nshould be described as having positive or negative results. The best and\nbiggest, like Lurie and Goldin, show detectable and robust effects on\nmortality.\n\nSecond, when insurance studies fail to show certain effects, they\u2019re\npractically always underpowered to say anything about the effects of\nmedication. Often they can\u2019t even find that the better-insured subjects use\nmore medication than the less-insured subjects (eg all negative RAND outcomes,\nall Oregon outcomes except diabetes, everything in Karnataka). When they can\ndetect that better-insured subjects use more medication, they can often\nprecisely quantify whether their study has enough power to test the effect of\nmedication, and explicitly find that it cannot. I can\u2019t think of a single one\nof the experiments Robin cites that finds an increased amount of medication in\nthe experimental group, a power high enough to find medication effects, and a\nlack of medication effects. So these studies shouldn\u2019t be used to make any\nclaims about medication effectiveness.\n\nThird, even if we were to unwisely try to use these studies to assess\nmedication effectiveness, they only measure marginal cases. For example, in\nthe Oregon study, the insured group used about 33% more health care than the\ninsured group - eg the uninsured people had a hospital admission rate per six\nmonths of 20%, compared to the insured group\u2019s 27%; the uninsured group took\nabout 1.8 medications daily, compared to the insured group\u2019s 2.4. Presumably\neveryone is going to the hospital for very serious cases (eg heart attack),\nand the better-insured people are just going for some marginal extra less\nserious things. Even if we could prove with certainty that the insured group\u2019s\nextra medication wasn\u2019t benefiting them at all, this doesn\u2019t say anything\nabout the core 2/3 of medical care that people would get even if they weren\u2019t\ninsured.\n\n(Robin sometimes talks about how it\u2019s hard to distinguish core vs. extra care,\nand I\u2019m not sure how this works on paper, but in practice the poorer patients\nI talk to seem to be able to distinguish it very well - lots of them will go\nto the hospital for \u201creal emergencies\u201d but start worrying about money for\nanything less)\n\nFourth, we have strong direct evidence that medicine works, both in the form\nof randomized controlled trials, and in the form of increasing survival rates\nafter the diagnoses of many severe diseases (and this isn\u2019t just the diseases\nbeing diagnosed better and earlier, see for example here, or the patients\ngetting the diseases younger, see the age-adjusted rates above). Even in the\ncounterfactual where we had unambiguous, well-powered, non-marginal insurance\nstudies suggesting that medication didn\u2019t work, we should at most be confused\nby these conflicting sources. Most likely that confusion would end in us\nsetting the insurance studies aside as suffering from the usual set of\ninexplicable social science confounders, given that they contradict stronger\nand more direct clinical evidence.\n\nI think if Robin wants to do something with these insurance study results, he\nshould follow other economists, including the study authors, and argue about\nwhether the marginal unit of insurance is cost-effective - not about whether\nmedication works at all.\n\n### Subscribe to Astral Codex Ten\n\nBy Scott Alexander\n\nP(A|B) = [P(A)*P(B|A)]/P(B), all the rest is commentary.\n\n9 Likes\n\n9\n\nShare this post\n\n#### Contra Hanson On Medical Effectiveness\n\nwww.astralcodexten.com\n\n38\n\nShare\n\nShare this discussion\n\n#### Contra Hanson On Medical Effectiveness\n\nwww.astralcodexten.com\n\n38 Comments\n\n  * New First\n  * Chronological\n\nShankar SivarajanShankar\u2019s Newsletter54 mins agoAgainst the strongest versions\nof the claim, the obvious smallpox and polio; and antibiotics are good\narguments too.Expand full commentReply (2)Share  \n---  \n  \nScott Alexander50 mins agoAuthorI think he separates vaccination out from\nother medicine. I agree antibiotics are a strong argument.Expand full\ncommentReply (1)Share  \n---  \n  \nJeremiah JohnsonInfinite Scroll27 mins ago\u00b7edited 27 mins agoI am skeptical\nwhether Hanson really believes what he's saying with real confidence.If he has\na significant bacterial infection, would he not take antibiotics? If he\ndevelops a treatable cancer, will he reject modern medicine? I sincerely doubt\nthat would be the case. Revealed preference would be telling in that\nsituation.Expand full commentReplyShare  \n---  \n  \nJayan Amandakone9 mins agoI remember some old emails where Hanson mentioned\nthe Oral polio vaccine AIDS hypothesis, I think he also mentioned W. D.\nHamilton's involvement. Can't remember him mentioning reusing dirty needles in\nhealthcare tho.Expand full commentReplyShare  \n---  \n  \nDaragh ThomasCurious Histories52 mins agoHas Robin ever talked to a doctor or\nbeen ill? I need someone to explain to me why this isn't the stupidest thing\nanyone has ever said. Myself and my girlfriend have both had simple surgeries\nfor life threatening problems, we'd both be dead without medicine.Expand full\ncommentReply (2)Share  \n---  \n  \nScott Alexander50 mins agoAuthorI think his claim is that while medicine\nprobably has some clear victories, it also probably kills some people through\nside effects, so it's hard to say whether it's on net good or bad, and we\ncan't easily distinguish the good parts from the bad parts. See the casino\nquote early in the article.Expand full commentReply (2)Share  \n---  \n  \nTurtle17 mins agoThis seems to me like a galaxy brained take where the galaxy\nwas so dense it collapsed into a supermassive black holeExpand full\ncommentReplyShare  \n---  \n  \nEvan JamesEvan\u2019s Substack7 mins agoThat's still kind of absurd. Yes, there are\nsome treatments of ambiguous value, but there are tons of examples of\nconditions with roughly 100% mortality rates when untreated and nearly 0% when\ntreated promptly: type 1 diabetes, ruptured appendix, adrenal crisis, ectopic\npregnancy, HIV infection...the idea that one somehow can't tell that medicine\nworks to treat these conditions, or that one can't distinguish treatments like\ninsulin and appendectomies from the pool of treatments with more complex cost-\nbenefit equations, is silly.Expand full commentReplyShare  \n---  \n  \nTurtle23 mins agoI came to the comments section to say this tooExpand full\ncommentReplyShare  \n---  \n  \nJ. LashleyJ.\u2019s Substack47 mins ago\u00b7edited 47 mins agoSo I see your point but I\ndo not think you meaningfully interact with what Hanson is saying - in fact it\nseems like what he brings forward does not effect how you respond to him at\nall. Even if we can grant that the maximum application of his thesis is just\nobviously incorrect by no other metric than the successful eradication of\ncertain infectious diseases or things like soft-tissue repair, that does not\ninvalidate everything he has said. That being said, if you are charitable with\nthe person you are responding to, then certainly you should be given pause\nthat for all the praise of modern medicine there are massive problems.The\nchemical-imbalance theory of clinical depression has always been controversial\nand now that the theory is losing support you can only look out into the\naftermath of prescribing people so many of these different anti-depressants to\nsee the problems.How many people were potentially harmed by following the tau\ntheory in Alzheimer's?How many women have been harmed by the overuse of\nC-sections for routine pregnancies?How much medicine has been developed to\ntreat diseases brought about by poor lifestyle choices like obesity or\nmalnourishment from eating processed foods with no nutrients?Medicine in\nAmerica is run like a business, and that has some major problematic\nimplications so your response comes off as being dangerously defensive of what\nmay in fact be indefensible.Expand full commentReply (1)Share  \n---  \n  \nScott Alexander45 mins agoAuthorI think you are doing a mood affiliation thing\nwhere you say there are some things you don't like about medicine, and\ntherefore all anti-medicine claims are correct regardless of their literal\ncontent.I think you may have overupdated on some kind of unsophisticated\ncontrarian attacks on medicine. I'm most qualified to argue your \"chemical\nimbalance\" claim, see my previous writings on this at\nhttps://slatestarcodex.com/2015/04/05/chemical-imbalance/ and\nhttps://slatestarcodex.com/2015/04/18/polemical-imbalance/Expand full\ncommentReply (2)Share  \n---  \n  \nJ. LashleyJ.\u2019s Substack43 mins agoExcept my post didn't say anything close to\nthat at all - there is no need to be defensive if someone points out that you\nare being uncharitable to someone making a point about something by only\nattacking the maximal and almost absurd interpretation of what they are\nsaying. In fact based on how quickly you replied I question if you actually\nread my response or just quickly skimmed over it and made some unfortunate\nassumptions.Expand full commentReplyShare  \n---  \n  \nJ. LashleyJ.\u2019s Substack37 mins agoAlso this is not at all an attack on your\ncontent that you links (and thank you for that) but aren't posts from 9 years\nago somewhat dated? Do you think they accurately reflect what is being\ndiscussed in regards to the chemical imbalance theory in the current\nmoment?Expand full commentReply (1)Share  \n---  \n  \nScott Alexander34 mins agoAuthorI haven't seen any change in the argument in\nthe past nine years that has led me to update that post. Part of the issue\nwith how people present this is that they always talk about \"we've learned\nit's not chemical imbalance!\" as some kind of new discovery or crumbling\northodoxy, whereas in fact people have been talking about the ways \"chemical\nimbalance\" does vs. doesn't describe the territory for as long as anyone has\nused the term, usually with approximately the same arguments.Expand full\ncommentReply (1)Share  \n---  \n  \nJ. LashleyJ.\u2019s Substack31 mins agoAre arguments data? Because certainly in 9\nyears (ages in some sciences) the data has been updated. Also by your\nstatement in those posts you were new to the field - are you telling me in 9\nyears you have gained or seen nothing new?Expand full commentReply (1)Share  \n---  \n  \nScott Alexander27 mins ago\u00b7edited 25 mins agoAuthorYou're talking about the\nchemical imbalance argument, which is a mostly philosophical argument about\nhow to think about depression and its treatments given the facts we know. I\nhope those two articles will explain what I mean by that.I separate that from\nthe empirical arguments about the causes of depression or the effectiveness of\ndepression treatment , which I've written dozens of posts on in the past few\nyears. You can read a few randomly selected ones at :\nhttps://www.astralcodexten.com/p/all-medications-are-insignificant ,\nhttps://www.astralcodexten.com/p/a-look-down-track-b, or\nhttps://www.astralcodexten.com/p/the-precision-of-sensory-evidence, and you\ncan see my overall discussion of depression at\nhttps://lorienpsych.com/2021/06/05/depression/Expand full commentReplyShare  \n---  \n  \nelifland42 mins agoYour Caplan link doesn't work, should be\nhttps://betonit.substack.com/p/reflections-on-goff-and-the-costExpand full\ncommentReplyShare  \n---  \n  \nMatt Levin37 mins agoCancer is a poor place to look for effects - and\nespecially for a $ per QALY metric which a rough steelmanning of Hanson. Which\nobviously is orthogonal to a \u201cmedicine doesn\u2019t work\u201d argument but might\nsupport a \u201cwe spend too much money to help the elderly live a few more poor\nyears\u201d generalized argument.Much better places to look are 1) antibiotics 2)\nemergency medicine 3) pre-natal and maternity care 4) general surgery, for\nstarters - both on a mortality basis and a QALY basis.Expand full commentReply\n(1)Share  \n---  \n  \nScott Alexander33 mins ago\u00b7edited 32 mins agoAuthorIf Hanson wanted to make a\n$ per QALY argument, I would argue against it (or maybe not, I don't really\nobejct to that). I really do want to stress that his real argument is \"maybe\nmedicine doesn't work at all\".Expand full commentReplyShare  \n---  \n  \nStephen Pimentel33 mins agoI hate the way this discussion is framed. Robin\nsays \"medicine doesn't work.\" Scott says \"medicine does work.\" Why is the\nrelevant object \"medicine?\" How does that make any sense? There isn't some one\nbig, monolithic thing called \"medicine.\" There are many different,\nheterogeneous pathologies, and many different, heterogeneous treatments. My\nnull hypothesis would be some of these are great, and some of them suck (even\nworse than doing nothing). And having read the entire post, I still think\nthat's exactly the case.It's easy to believe that modern antibiotics are\nexcellent for treating many bacteria infections. And that some forms surgery,\nperhaps spinal fusion surgery for degenerative disks, can be worse than doing\nnothing. And that medicine is a big mixed bag containing everything in\nbetween. There's no paradox or puzzle here, and it's just dumb to frame this\nas a fight between \"medicine works\" and \"medicine doesn't work.\"Expand full\ncommentReplyShare  \n---  \n  \nMatthew BarnettMatthew Barnett\u2019s Blog28 mins ago> I think if Robin wants to do\nsomething with these insurance study results, he should follow other\neconomists, including the study authors, and argue about whether the marginal\nunit of insurance is cost-effective - not about whether medication works at\nall.As far as I can recall, Robin Hanson generally talks about the marginal\nunit of healthcare, rather than whether medication works \"at all\". For\nexample, in his long paper on medical behavior, he talked about \"A near-zero\nmarginal health-value of medical care\" rather than whether medical care had\nany value \"at all\" (see https://mason.gmu.edu/~rhanson/showcare.pdf). I also\nrecall him being clear to say that he's only talking about marginal\neffectiveness of medicine in his book The Elephant in the Brain.I agree that\nthe way he talks about this topic can be confusing. But ultimately I suspect\nthat, if Hanson ends up replying to this post, he will say that you\nmisunderstood his views on medicine.Expand full commentReplyShare  \n---  \n  \nGregory SchmouseJournal of working-class medici...28 mins agoNone of this\nmeaningfully disproves Hanson. Hanson's (correctly!) credits spontaneously\noccuring secular trends with the increase in life expectancy. Others did so\nbefore him and there are a bunch of other studies basically coming to the same\nconclusion, i.e. finding small to irrelevant effects for medical care. This is\nnot new and not surprising, and anybody practicing medicine with open eyes has\nnoticed that the presentations of new cases of practically all diseases seem\nto ameliorate over time and the clinically large/evident presentations of the\npast are practically absent in todays practice.The error here is the same with\nall the other evidence that has been dragged in to refute this, in that people\ndo not understand that incidence rules health, that comparably large increases\nin survival in lethal disease will not appreciably change the population's\nlife expectancy when incidence is low, and that incidence has always been low\neven for those supposedly common deadly diseases of history. Adjuncts to these\nerrors are the failure to understand that most chronic diseases of aging do\nnot result in death or disability if left alone, most treatment fails to\nmeaningfully alter the course of the disease it pretends to treat and the\nfailure to understand lead-time- and length-time-biases, as demonstrated by\nthe diatribe on cancer survival.I understand the need to believe in medicine\nwhen you are working as a physician, but this is sloppy reasoning.Expand full\ncommentReply (2)Share  \n---  \n  \nJ. LashleyJ.\u2019s Substack23 mins agoHe also said I was 'doing some mood\naffiliation thing' which has nothing to do with the content of my reply at all\nand in fact ignored me when I objected to his radical misreading of what I\nsaid, then links me to some 2015 posts because it is 'mostly philosophy that\nhasnt changed in 9 years\" - I do not think Dr. Alexander is being charitable\nat all.Expand full commentReply (1)Share  \n---  \n  \nTurtle8 mins agoHe spent WAY more time engaging with the arguments than I\nwould have. Props to him.Expand full commentReply (1)Share  \n---  \n  \nJ. LashleyJ.\u2019s Substack6 mins agoI don't appreciate replies with no content so\nplease refrain from interacting with me in this way in the future - I'd be\nvery thankful.Expand full commentReplyShare  \n---  \n  \nTurtle14 mins agoObviously population health trumps specific\nintervention\u201cPrevention is better than cure\u201dThis uhDoesn\u2019t mean cure is\nirrelevantControversial I knowHave you ever been sick?Or had a sick family\nmember?Expand full commentReplyShare  \n---  \n  \ndiddlydiddly links27 mins agoI'm really curious what Robin would say to all\nthe progress on cancer. One might argue that it's a poor use of money, but\nsome of the new cancer treatments have huge effect sizes that would swamp his\ncomplaints for high noise.Expand full commentReplyShare  \n---  \n  \ntailcalledtailcalled27 mins ago\"I\u2019ve spent fifteen years not responding to\nthis argument, because I worry it would be harsh and annoying to use my\nplatform to beat up on one contrarian who nobody else listens to.\"Admittedly I\ndon't have as big of a platform as you do, but one solution I often use for\nthis is to first argue with the contrarian about it behind the scenes, and\nthen only publish the rebuttal if they don't self-correct.The problem with not\ngetting it corrected at all is that \"who nobody else listens to\" is wrong.\nE.g. for a period of time, I found it plausible that Robin Hanson was right,\nbecause I assumed he and others had done their basic statistics to check the\nvalidity of the claims (especially because I saw e.g. Eliezer Yudkowsky\nreference the results too). It's only after getting a better mindset for the\nstatistics (many of the problems you mention here show up in *a lot* of\nstudies) that I started disbelieving.Expand full commentReplyShare  \n---  \n  \nEmil O. W. KirkegaardJust Emil Kirkegaard Things26 mins agoI don't know why\nyou can't find the book. It's here: https://annas-\narchive.org/md5/be2a9bdb7087cc9b26659211f3cf8447Expand full commentReplyShare  \n---  \n  \nNathan El10 mins agoAgreed with this, and I particularly like seeing the\nimprovement in mortality for specific conditions over time like this, it\nstrikes me as a really strong argument for the effectiveness of medicine.What\nI do think remains a valid sort-of anti-medicine point is that treatment is\nvastly less cost-effective than prevention, I recall hearing it being about 50\ntimes less so, and so clearly vast savings could be made through government\ndisease-prevention programs such as dissuasion campaigns against and fees on\nthe externalities of risk factors for disease and especially the broad\ncategory of \"ingested substances\" whether food or recreational drugs and even\nair pollution; the feeing of externalities (\"pigovian taxation\") is of course\nthe least econonomically burdensome and indeed in theory if we could properly\ncalculate the value of the externalities it would be economically optimal,\nsince it doesn't require making any government expenditure and to the contrary\nactually constitutes a source of income for the government and can substitute\nfor an equal amount of economically harmful taxation, so that's what seems to\nme the most obvious major policy to help reduce healthcare costs, though\nfrustratingly it's foolishly opposed by many and ironically generally the most\nso by the \"taxation is theft\" crowd.Expand full commentReply (1)Share  \n---  \n  \nTurtle5 mins agoYeah I actually agree strongly with this. We need much more\nfunding in primary careExpand full commentReplyShare  \n---  \n  \nTurtle9 mins agoSo to look on the positive side, as a physician, I feel like I\nnow understand better the perspective of police officers now in response to\nthe Defund the Police movement.Expand full commentReplyShare  \n---  \n  \nBarry Lam8 mins agoWow, I wish people would either stop using generic\ngeneralizations or read the semantic literature on the variety of incompatible\ninterpretations people make of generics. There is nothing scientifically\nrespectable about summarizing a claim as a generic generalization.Expand full\ncommentReplyShare  \n---  \n  \nSteve Cheung7 mins agoAntibiotics starting with penicillin and moving forward\never since.Insulin.Primary PCI for STEMI.There are many explicit examples\nwhere medicine \u201cworks\u201d. And when a guy is willing to say a P value of 0.01 is\n\u201cnoise\u201d, there\u2019s really not much point engaging with the guy.I agree with your\ndistinction btw secondary prevention and primary prevention. Although I think\nthe fundamental difference is in effect size (and NNT).I think maybe where he\n\u201cmight\u201d have a point (and this is the part that bothers me daily) is in the\nlack of precision medicine. When a certain treatment has an NNT of\n10....that\u2019s a blockbuster....yet in 9 of those people the therapy will\nprovide no benefit, and we have no a priori way of knowing who that 1 lucky\nperson (out of 10) is.Expand full commentReplyShare  \n---  \n  \nJayan Amandakone4 mins agoHaven't spend much time researching this but other\nthan Caplan I think Random Critical Analysis\n(https://randomcriticalanalysis.com/2016/11/06/us-life-expectancy-is-below-\nnaive-expectations-mostly-because-it-economically-outperforms/) and Gwern\n(https://gwern.net/drug-heuristic#sn16) also seem sympathetic to Hanson's\nview.Expand full commentReplyShare  \n---  \n  \nEmil O. W. KirkegaardJust Emil Kirkegaard Things3 mins ago>Come on! Thousands\nof clinical RCTs show that medicine has an effect. Robin wants to ignore these\nin favor of insurance experiments that are underpowered to find effects even\nwhen they\u2019re there. Then when someone finally does an insurance experiment big\nand powerful enough to find effects, and it finds the same thing as all the\nthousands of clinical RCTs, p = 0.01, Robin says maybe we should dismiss it,\nbecause p = 0.01 findings are sometimes just \u201cnoise\u201d. Aaargh!You may want to\nsteelman him here. When analyzing large, complex quasi-experimental data,\nthere are many, many analytic choices to make. The more choices to make, the\nmore opportunity to p-hack. As such, an apparent p value of 0.01 is not\nnecessarily an honest p value of 0.01 because there are many ways to turn\nlarge than 0.01 values into apparent 0.01. How do we know the authors didn't\ncheat here? We don't know that. Would need a specification curve analysis or\nsomething like that.Expand full commentReplyShare  \n---  \n  \nMelvin3 mins agoEach individual treatment has been the subject of a placebo-\ncontrolled double blind trial at some point. It's easy to see how some\nineffective treatments might sneak through, but what are the chances that\nthey're all ineffective? Every single one of them? That absolutely nothing you\ncan possibly do to the human body, even the very obvious things with clear\nmechanisms of action, actually improves health?Expand full commentReplyShare  \n---  \n  \nJay1 min agoHanson's argument really is just absurd. I cannot imagine that he\nreally believes it. Surely this must be the adoption of an extreme position in\norder to get attention.Expand full commentReplyShare  \n---  \n  \nIvermectin: Much More Than You Wanted To Know\n\n...\n\nNov 17, 2021\n\n403\n\nShare this post\n\n#### Ivermectin: Much More Than You Wanted To Know\n\nwww.astralcodexten.com\n\n2,155\n\nStill Alive\n\nYou just keep on trying till you run out of cake\n\nJan 21, 2021\n\n1,198\n\nShare this post\n\n#### Still Alive\n\nwww.astralcodexten.com\n\n512\n\nIn The Long Run, We're All Dad\n\n...\n\nDec 22, 2023\n\n1,045\n\nShare this post\n\n#### In The Long Run, We're All Dad\n\nwww.astralcodexten.com\n\n460\n\nReady for more?\n\n\u00a9 2024 Scott Alexander\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}
