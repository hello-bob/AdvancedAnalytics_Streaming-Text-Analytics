{"aid": "40162183", "title": "Mitigating a token-length side-channel attack in our AI products", "url": "https://blog.cloudflare.com/ai-side-channel-attack-mitigated", "domain": "cloudflare.com", "votes": 3, "user": "rvnx", "posted_at": "2024-04-25 19:51:11", "comments": 0, "source_title": "Mitigating a token-length side-channel attack in our AI products", "source_text": "Mitigating a token-length side-channel attack in our AI products\n\nGet Started Free|Contact Sales\n\n## The Cloudflare Blog\n\nSubscribe to receive notifications of new posts:\n\n# Mitigating a token-length side-channel attack in our AI products\n\n03/14/2024\n\n  * Celso Martinho\n\n  * Michelle Chen\n\n6 min read\n\nThis post is also available in \u7b80\u4f53\u4e2d\u6587, \u7e41\u9ad4\u4e2d\u6587, \ud55c\uad6d\uc5b4, \u65e5\u672c\u8a9e, Espa\u00f1ol and Portugu\u00eas.\n\nSince the discovery of CRIME, BREACH, TIME, LUCKY-13 etc., length-based side-\nchannel attacks have been considered practical. Even though packets were\nencrypted, attackers were able to infer information about the underlying\nplaintext by analyzing metadata like the packet length or timing information.\n\nCloudflare was recently contacted by a group of researchers at Ben Gurion\nUniversity who wrote a paper titled \u201cWhat Was Your Prompt? A Remote Keylogging\nAttack on AI Assistants\u201d that describes \u201ca novel side-channel that can be used\nto read encrypted responses from AI Assistants over the web\u201d.\n\nThe Workers AI and AI Gateway team collaborated closely with these security\nresearchers through our Public Bug Bounty program, discovering and fully\npatching a vulnerability that affects LLM providers. You can read the detailed\nresearch paper here.\n\nSince being notified about this vulnerability, we've implemented a mitigation\nto help secure all Workers AI and AI Gateway customers. As far as we could\nassess, there was no outstanding risk to Workers AI and AI Gateway customers.\n\n### How does the side-channel attack work?\n\nIn the paper, the authors describe a method in which they intercept the stream\nof a chat session with an LLM provider, use the network packet headers to\ninfer the length of each token, extract and segment their sequence, and then\nuse their own dedicated LLMs to infer the response.\n\nThe two main requirements for a successful attack are an AI chat client\nrunning in streaming mode and a malicious actor capable of capturing network\ntraffic between the client and the AI chat service. In streaming mode, the LLM\ntokens are emitted sequentially, introducing a token-length side-channel.\nMalicious actors could eavesdrop on packets via public networks or within an\nISP.\n\nAn example request vulnerable to the side-channel attack looks like this:\n\n    \n    \n    curl -X POST \\ https://api.cloudflare.com/client/v4/accounts/<account-id>/ai/run/@cf/meta/llama-2-7b-chat-int8 \\ -H \"Authorization: Bearer <Token>\" \\ -d '{\"stream\":true,\"prompt\":\"tell me something about portugal\"}'\n\nLet\u2019s use Wireshark to inspect the network packets on the LLM chat session\nwhile streaming:\n\nThe first packet has a length of 95 and corresponds to the token \"Port\" which\nhas a length of four. The second packet has a length of 93 and corresponds to\nthe token \"ug\" which has a length of two, and so on. By removing the likely\ntoken envelope from the network packet length, it is easy to infer how many\ntokens were transmitted and their sequence and individual length just by\nsniffing encrypted network data.\n\nSince the attacker needs the sequence of individual token length, this\nvulnerability only affects text generation models using streaming. This means\nthat AI inference providers that use streaming \u2014 the most common way of\ninteracting with LLMs \u2014 like Workers AI, are potentially vulnerable.\n\nThis method requires that the attacker is on the same network or in a position\nto observe the communication traffic and its accuracy depends on knowing the\ntarget LLM\u2019s writing style. In ideal conditions, the researchers claim that\ntheir system \u201ccan reconstruct 29% of an AI assistant\u2019s responses and\nsuccessfully infer the topic from 55% of them\u201d. It\u2019s also important to note\nthat unlike other side-channel attacks, in this case the attacker has no way\nof evaluating its prediction against the ground truth. That means that we are\nas likely to get a sentence with near perfect accuracy as we are to get one\nwhere only things that match are conjunctions.\n\n### Mitigating LLM side-channel attacks\n\nSince this type of attack relies on the length of tokens being inferred from\nthe packet, it can be just as easily mitigated by obscuring token size. The\nresearchers suggested a few strategies to mitigate these side-channel attacks,\none of which is the simplest: padding the token responses with random length\nnoise to obscure the length of the token so that responses can not be inferred\nfrom the packets. While we immediately added the mitigation to our own\ninference product \u2014 Workers AI, we wanted to help customers secure their LLMs\nregardless of where they are running them by adding it to our AI Gateway.\n\nAs of today, all users of Workers AI and AI Gateway are now automatically\nprotected from this side-channel attack.\n\n### What we did\n\nOnce we got word of this research work and how exploiting the technique could\npotentially impact our AI products, we did what we always do in situations\nlike this: we assembled a team of systems engineers, security engineers, and\nproduct managers and started discussing risk mitigation strategies and next\nsteps. We also had a call with the researchers, who kindly attended, presented\ntheir conclusions, and answered questions from our teams.\n\nThe research team provided a testing notebook that we could use to validate\nthe attack's results. While we were able to reproduce the results for the\nnotebook's examples, we found that the accuracy varied immensely with our\ntests using different prompt responses and different LLMs. Nonetheless, the\npaper has merit, and the risks are not negligible.\n\nWe decided to incorporate the first mitigation suggestion in the paper:\nincluding random padding to each message to hide the actual length of tokens\nin the stream, thereby complicating attempts to infer information based solely\non network packet size.\n\n### Workers AI, our inference product, is now protected\n\nWith our inference-as-a-service product, anyone can use the Workers AI\nplatform and make API calls to our supported AI models. This means that we\noversee the inference requests being made to and from the models. As such, we\nhave a responsibility to ensure that the service is secure and protected from\npotential vulnerabilities. We immediately rolled out a fix once we were\nnotified of the research, and all Workers AI customers are now automatically\nprotected from this side-channel attack. We have not seen any malicious\nattacks exploiting this vulnerability, other than the ethical testing from the\nresearchers.\n\nOur solution for Workers AI is a variation of the mitigation strategy\nsuggested in the research document. Since we stream JSON objects rather than\nthe raw tokens, instead of padding the tokens with whitespace characters, we\nadded a new property, \"p\" (for padding) that has a string value of variable\nrandom length.\n\nExample streaming response using the SSE syntax:\n\n    \n    \n    data: {\"response\":\"portugal\",\"p\":\"abcdefghijklmnopqrstuvwxyz0123456789a\"} data: {\"response\":\" is\",\"p\":\"abcdefghij\"} data: {\"response\":\" a\",\"p\":\"abcdefghijklmnopqrstuvwxyz012\"} data: {\"response\":\" southern\",\"p\":\"ab\"} data: {\"response\":\" European\",\"p\":\"abcdefgh\"} data: {\"response\":\" country\",\"p\":\"abcdefghijklmno\"} data: {\"response\":\" located\",\"p\":\"abcdefghijklmnopqrstuvwxyz012345678\"}\n\nThis has the advantage that no modifications are required in the SDK or the\nclient code, the changes are invisible to the end-users, and no action is\nrequired from our customers. By adding random variable length to the JSON\nobjects, we introduce the same network-level variability, and the attacker\nessentially loses the required input signal. Customers can continue using\nWorkers AI as usual while benefiting from this protection.\n\n### One step further: AI Gateway protects users of any inference provider\n\nWe added protection to our AI inference product, but we also have a product\nthat proxies requests to any provider \u2014 AI Gateway. AI Gateway acts as a proxy\nbetween a user and supported inference providers, helping developers gain\ncontrol, performance, and observability over their AI applications. In line\nwith our mission to help build a better Internet, we wanted to quickly roll\nout a fix that can help all our customers using text generation AIs,\nregardless of which provider they use or if they have mitigations to prevent\nthis attack. To do this, we implemented a similar solution that pads all\nstreaming responses proxied through AI Gateway with random noise of variable\nlength.\n\nOur AI Gateway customers are now automatically protected against this side-\nchannel attack, even if the upstream inference providers have not yet\nmitigated the vulnerability. If you are unsure if your inference provider has\npatched this vulnerability yet, use AI Gateway to proxy your requests and\nensure that you are protected.\n\n### Conclusion\n\nAt Cloudflare, our mission is to help build a better Internet \u2013 that means\nthat we care about all citizens of the Internet, regardless of what their tech\nstack looks like. We are proud to be able to improve the security of our AI\nproducts in a way that is transparent and requires no action from our\ncustomers.\n\nWe are grateful to the researchers who discovered this vulnerability and have\nbeen very collaborative in helping us understand the problem space. If you are\na security researcher who is interested in helping us make our products more\nsecure, check out our Bug Bounty program at hackerone.com/cloudflare.\n\nWe protect entire corporate networks, help customers build Internet-scale\napplications efficiently, accelerate any website or Internet application, ward\noff DDoS attacks, keep hackers at bay, and can help you on your journey to\nZero Trust.\n\nVisit 1.1.1.1 from any device to get started with our free app that makes your\nInternet faster and safer.\n\nTo learn more about our mission to help build a better Internet, start here.\nIf you're looking for a new career direction, check out our open positions.\n\nDiscuss on Hacker News\n\nBug BountyLLMVulnerabilitiesDeveloper PlatformWorkers AIAI GatewaySASE\n\nFollow on X\n\nCelso Martinho|@celso\n\nMichelle Chen|@_mchenco\n\nCloudflare|@cloudflare\n\nRelated posts\n\nFebruary 02, 2023 1:32 PM\n\n## Cloudflare's handling of a bug in interpreting IPv4-mapped IPv6 addresses\n\nRecently, a vulnerability was reported to our bug bounty about a bug in the\nway some of our code interprets IPv4 addresses mapped into IPv6 addresses.\nRead about how Cloudflare addressed this vulnerability and what will prevent\nsimilar exploits in the future....\n\nBy\n\n  * Lucas Ferreira,\n\n  * Aki Shugaeva,\n\n  * Yuchen Wu\n\nSecurity, Bug Bounty, IPv6\n\nMay 06, 2022 1:00 PM\n\n## The Cloudflare Bug Bounty program and Cloudflare Pages\n\nThe Cloudflare Bug Bounty has resulted in numerous security improvements to\nCloudflare Pages...\n\nBy\n\n  * Evan Johnson,\n\n  * Natalie Rogers\n\nBug Bounty, Vulnerabilities, Security\n\nJuly 24, 2021 12:57 PM\n\n## Cloudflare's Handling of an RCE Vulnerability in cdnjs\n\nRecently, a RCE vulnerability in the way cdnjs\u2019 backend is automatically\nkeeping web resources up to date has been disclosed. Read about how Cloudflare\nhandled the security incident and what will prevent similar exploits in the\nfuture....\n\nBy\n\n  * Jonathan Ganz,\n\n  * Thomas Calderon,\n\n  * Sven Sauleau\n\nCDNJS, Security, Bug Bounty\n\n  * Getting Started\n  * Free plans\n  * For enterprises\n  * Compare plans\n  * Get a recommendation\n  * Request a demo\n  * Contact Sales\n\n  * Resources\n  * Learning Center\n  * Analyst reports\n  * Cloudflare Radar\n  * Cloudflare TV\n  * Case Studies\n  * Webinars\n  * White Papers\n  * Developer docs\n  * theNet\n\n  * Solutions\n  * Connectivity cloud\n  * SSE and SASE services\n  * Application services\n  * Network services\n  * Developer services\n\n  * Community\n  * Community Hub\n  * Project Galileo\n  * Athenian Project\n  * Cloudflare for Campaigns\n  * Critical Infrastructure Defense Project\n  * Connect 2024\n\n  * Support\n  * Help center\n  * Cloudflare Status\n  * Compliance\n  * GDPR\n  * Trust & Safety\n\n  * Company\n  * About Cloudflare\n  * Our team\n  * Investor relations\n  * Press\n  * Careers\n  * Diversity, equity & inclusion\n  * Impact/ESG\n  * Network Map\n  * Logos & press kit\n  * Become a partner\n\n\u00a9 2024 Cloudflare, Inc. | Privacy Policy | Terms of Use | Report Security Issues |Cookie Preferences | Trademark\n\n", "frontpage": false}
