{"aid": "40051972", "title": "6th generation x86 CPU Comparisons", "url": "http://www.azillionmonkeys.com/qed/cpuwar.html", "domain": "azillionmonkeys.com", "votes": 3, "user": "luu", "posted_at": "2024-04-16 14:00:31", "comments": 0, "source_title": "Paul Hsieh's 6th generation x86 CPU Comparisons", "source_text": "Paul Hsieh's 6th generation x86 CPU Comparisons\n\n| 6th Generation CPU Comparisons.  \n---  \n  \nby Paul Hsieh\n\nAMD K6| Intel Pentium II| Cyrix 6x86MX| Common features| Closing words|\nGlossary  \n---|---|---|---|---|---  \n  \nUpdate: 09/07/99 I have now started a seventh generation architecture web\npage.\n\nThe following is a comparative text meant to give people a feel for the\ndifferences in the various 6th generation x86 CPUs. For this little ditty,\nI've chosen the Intel P-II (aka Klamath, P6), the AMD K6 (aka NX686), and the\nCyrix 6x86MX (aka M2). These are all MMX capable 6th generation x86 compatible\nCPUs, however I am not going to discuss the MMX capabilities at all beyond\nsaying that they all appear to have similar functionality. (MMX never really\ntook off as the software enabling technology Intel claimed it to be, so its\nnot worth going into any depth on it.)\n\nIn what follows, I am assuming a high level of competence and knowledge on the\npart of the reader (basic 32 bit x86 assembly at least). For many of you, the\ndiscussion will be just slightly over your head. For those, I would recommend\nsitting through the 1 hour online lecture on the Post-RISC architecture by\nCharles Severence to get some more background on the state of modern processor\ntechnology. It is really an excellent lecture, that is well worth the time:\n\n  * Beyond RISC - The Post RISC Architecture (Mark Brehob, Travis Doom, Richard Enbody, William H. Moore, Sherry Q. Moore, Ron Sass, Charles Severance )\n\nMuch of the following information comes from online documentation from Cyrix,\nAMD and Intel. I have played a little with Pentiums and Pentium-II's from\nwork, as well as my AMD-K6 at home. I would also like to thank, Dan Wax, Lance\nSmith and \"Bob Instigator\" from AMD who corrected me on several points about\nthe K6, and both Andreas Kaiser and Lee Powell who also provided insightful\ninformation, and corrections gleened from first hand experiences with these\nCPUs. Also, thanks to Terje Mathisen who pointed out an error, and Brian\nConverse who helped me with my grammar.\n\nComments welcome.\n\nThe AMD K6  \n---  \n  \nThe K6 architecture seems to mix some of the ideas of the P-II and 6x86MX\narchitectures. They made trade offs, and decisions that they believed would\ndeliver the maximal performance over all potential software. They have\nemphasized short latencies (like the 6x86MX) but the K6 translates their x86\ninstructions into RISC operations that are queued in large instruction buffers\nand feed many (7 in all) independent units (like the P-II.) While they don't\nalways have the best single implementation of any specific aspect, this was\nthe result of conscious decisions that they believe helps strike a balance\nthat hits a good performance sweet spot. Versus the P-II, they avoid\nsituations of really deep pipelining which has high penalties when the\npipeline has to be backed out. Versus the Cyrix, the AMD is a fully POST-RISC\narchitecture which is not as susceptible to pipeline stalls which artificially\nback ups other stages.\n\n### General Architecture\n\nThe K6 is an extremely short and elegant pipeline. The AMD-K6 MMX Enhanced\nProcessor x86 Code Optimization Application Note contains the following\ndiagrams:\n\nThis seems remarkably simple considering the features that are claimed for the\nK6. The secret, is that most of these stages do very complicated things. The\nlight blue stages execute in an out of order fashion (and were colored by me,\nnot AMD.)\n\nThe fetch stage, is much like a typical Pentium instruction fetcher, and is\nable to present 16 cache aligned bytes of data per clock. Of course this means\nthat some instructions that straddle 16 byte boundaries will suffer an extra\nclock penalty before reaching the decode stage, much like they do on a\nPentium. (The K6 is a little clever in that if there are partial opcodes from\nwhich the predecoder can determine the instruction length, then the\nprefetching mechanism will fetch the new 16 byte buffer just in time to feed\nthe remaining bytes to the issue stage.)\n\nThe decode stage attempts to simultaneously decode 2 simple, 1 long, and fetch\nfrom 1 ROM x86 instruction(s). If both of the first two fail (usually only on\nrare instructions), the decoder is stalled for a second clock which is\nrequired to completely decode the instruction from the ROM. If the first fails\nbut the second does not (the usual case when involving memory, or an\noverride), then a single instruction or override is decoded. If the first\nsucceeds (the usual case when not involving memory or overrides) then two\nsimple instructions are decoded. The decoded \"OpQuad\" is then entered into the\nscheduler.\n\nThus the K6's execution rate is limited to a maximum of two x86 instructions\nper clock. This decode stage decomposes the x86 instructions into RISC86 ops.\n\nThis last statement has been generally misunderstood in its importance (even\nby me!) Given that the P-II architecture can decode 3 instructions at once, it\nis tempting to conclude that the P-II can execute typically up to 50% faster\nthan a K6. According to \"Bob Instigator\" (a technical marketroid from AMD) and\n\"The Anatomy of a High-Performance Microprocessor A Systems Perspective\" this\njust isn't so. Besides the back-end limitations and scheduler problems that\nclog up the P-II, real world software traces analyzed at Advanced Micro\nDevices indicated that a 3-way decoder would have added almost no benefit\nwhile severely limiting the clock rate ramp of the K6 given its back end\narchitecture.\n\nThat said, in real life decode bandwidth limitation crops up every now and\nthen as a limiting factor, but is rarely egregiously in comparison to ordinary\nexecution limitations.\n\nThe issue stage accepts up to 4 RISC86 instructions from the scheduler. The\nscheduler is basically an OpQuad buffer that can hold up to 6 clocks of\ninstructions (which is up to 12 dual issued x86 instructions.) The K6 issues\ninstructions subject only to execution unit availability using an oldest\nunissued first algorithm at a maximum rate of 4 RISC86 instructions per clock\n(the X and Y ALU pipelines, the load unit, and the store unit.) The\ninstructions are marked as issued, but not removed until retirement.\n\nThe operand fetch stage reads the issued instruction operands without any\nrestriction other than register availability. This is in contrast with the\nP-II which can only read up to two retired register operands per clock (but is\nunrestricted in forwarding (unretired) register accesses.) The K6 uses some\nkind of internal \"register MUX\" which allows arbitrary accesses of internal\nand commited register space. If this stage \"fails\" because of a long data\ndependency, then according to expected availability of the operands the\ninstruction is either held in this stage for an additional clock or unissued\nback into the scheduler, essentially moving the instruction backwards through\nthe pipeline!\n\nThis is an ingenious design that allows the K6 to perform \"late\" data\ndependency determinations without over-complicating the scheduler's issue\nlogic. This clever idea gives a very close approximation of a reservation\nstation architecture's \"greedy algorithm scheduling\".\n\nThe execution stages perform in one or two pipelined stages (with the\nexception of the floating point unit which is not pipelined, or complex\ninstructions which stall those units during execution.) In theory, all units\ncan be executing at once.\n\nRetirement happens as completed instructions are pushed out of the scheduler\n(exactly 6 clocks after they are entered.) If for some reason, the oldest\nOpQuad in the scheduler is not finished, scheduler advancement (which pushes\nout the oldest OpQuad and makes space for a newly decoded OpQuad) is halted\nuntil the OpQuad can be retired.\n\nWhat we see here is the front end starting fairly tight (two instruction) and\nthe back end ending somewhat wider (two integer execution units, one load, one\nstore, and one FPU.) The reason for this seeming mismatch in execution\nbandwidth (as opposed to the Pentium, for example which remains two-wide from\ntop to bottom) is that it will be able to sustain varying execution loads as\nthe dependency states change from clock to clock. This at the very heart of\nwhat an out of order architecture is trying to accomplish, being wider at the\nback-end is a natrual consequence of this kind design.\n\n### Branch Prediction\n\nThe K6 uses a very sophisiticated branch prediction mechanism which delivers\nbetter prediction and fewer stalls than the P-II. There is a 8192 table of two\nbit prediction entries which combine historic prediction information for any\ngiven branch with a heuristic that takes into account the results of nearby\nbranches. Even branches that have somehow left the branch prediction table,\nstill can have the benefit of nearby branch activity data to help their\nprediction. According to published papers which studied these branch\nprediction implementations, this allows them to achieve a 95% prediction rate\nversus the P-II's 90% prediction rate.\n\nAdditional stalls are avoided by using a 16 entry times 16 byte branch target\ncache which allows first instruction decode to occur simultaneously with\ninstruction address computation, rather than requiring (E)IP to be known and\nused to direct the next fetch (as is the case with the P-II.) This removes an\n(E)IP calculation dependency and instruction fetch bubble. (This is a huge\nadvantage in certain algorithms such as computing a GCD; see my examples for\nthe code) The K6 allows up to 7 outstanding unresolved branches (which seems\nlike more than enough since the scheduler only allows up to 6 issued clocks of\npending instructions in the first place.)\n\nThe K6 benefits additionally from the fact that it is only a 6 stage pipeline\n(as opposed to a 12 stage pipeline like the P-II) so even if a branch is\nincorrectly predicted it is only a 4 clock penalty as opposed to the P-II's\n11-15 clock penalty.\n\nOne disadvantage pointed out to me by Andreas Kaiser is that misaligned branch\ntargets still suffer an extra clock penalty and that attempts to align branch\ntargets can lead to branch target cache tag bit aliasing. This is a good\npoint, however it seems to me that you can help this along by hand aligning\nonly your most inner loop branches.\n\nAnother (also pointed out to me by Andreas Kaiser) is that such a prediction\nmechanism does not work for indirect jump predictions (because the\nverification tables only compare a binary jump decision value, not a whole\naddress.) This is a bit of a bummer for virtual C++ functions.\n\n##### Back of envelope calculation\n\nThis all means that the average loop penalty is:\n\n(95% * 0) + (5% * 4) = 0.2 clocks per loop\n\nBut because of the K6's limited decode bandwidth, branch instructions take up\nprecious instruction decode bandwidth. There are no branch execution clocks in\nmost situations, however, branching instructions end up taking a slot where\nthere is essentially no calculations. In that sense K6 branches have a typical\npenalty of about 0.5 clocks. To combat this, the K6 executes the LOOP\ninstruction in a single clock, however this instruction performs so badly on\nIntel CPUs, that no compiler generates it.\n\n### Floating Point\n\nThe common high demand, high performance FPU operations (FADD, FSUB, FMUL) all\nexecute with a throughput and latency of 2 clocks (versus 1 or 2 clock\nthroughput and 3-5 clock latency on the P-II.) Amazingly, this means that it\ncan complete FPU operations faster than the P-II, however is worse on FPU code\nthat is optimally scheduled for the P-II. Like the Pentium, in the P-II Intel\nhas worked hard on fully pipelining the faster FPU operations which works in\ntheir favor. Central to this is FXCH which, in combination with FPU\ninstruction operands allows two new stack registers to be addressed by each\nbinary FPU operation. The P-II allows FXCH to execute in 0 clocks -- the early\nrevs of the K6 took two clocks, while later revs based on the \"CXT core\" can\nexecute them in 0 clocks. Unfortunately, the P-II derives much more benefit\nfrom this since its FPU architecture allows it to decode and execute at a peak\nrate of one new FPU instruction on every clock.\n\nMore complex instructions such as FDIV, FSQRT and so on will stall more of the\nunits on the P-II than on the K6. However since the P-II's scheduler is larger\nit will be able to execute more instructions in parallel with the stalled FPU\ninstruction (21 in all, however the port 0 integer unit is unavailable for the\nduration of the stalled FPU instruction) while the K6 can execute up to 11\nother x86 instructions a full speed before needing to wait for the stalled FPU\ninstruction to complete.\n\nIn a test I wrote (admittedly rigged to favor Intel FPUs) the K6 measured to\nonly perform at about 55% of the P-II's performance. (Update: using the K6-2's\nnew SIMD floating point features, the roles have reversed -- the P-II can only\nexecute at about 70% of a K6-2's speed.)\n\nAn interesting note is that FPU instructions on the K6 will retire before they\ncompletely execute. This is possible because it is only required that they\nwork out whether or not they will generate an exception, and the execution\nstate is reset on a task switch, by the OS's built-in FPU state saving\nmechanism.\n\nThe state of floating point has changed so drastically recently, that its hard\nto make a definitive comment on this without a plethora of caveats. Facts: (1)\nthe pure x87 floating point unit in the K6 does not compare favorably with\nthat of the P-II, (2) this does not tend to always reflect in real life\nsoftware which can be made from bad compilers, (3) the future of floating\npoint clearly lies with SIMD, where AMD has clearly established a leadership\nrole. (4) Intel's advantage was primarily in software that was hand optimized\nby assembly coders -- but that has clearly reversed roles since the\nintroduction of the K6-2.\n\n### Cache\n\nThe K6's L1 cache is 64KB, which is twice as large as the P-II's L1 cache. But\nit is only 2 way set associative (as opposed to the P-II which is 4 way). This\nmakes the replacement algorithm much simpler, but decreases its effectiveness\nin random data accesses. The increased size, however, more than compensates\nfor the extra bit of associativity. For code that works with contiguous data\nsets, the K6 simply offers twice the working set ceiling of the P-II.\n\nLike the P-II, the K6's cache is divided into two fixed caches for separate\ncode and data. I am not as big a fan of split architectures (commonly referred\nto as the Harvard Architecture) because they set an artificial lower limit on\nyour working sets. As pointed out to me by the AMD folk, this keeps them from\nhaving to worry about data accesses kicking out their instruction cache lines.\nBut I would expect this to be dealt with by associativity and don't believe\nthat it is worth the trade off of lower working set sizes.\n\nAmong the design benefits they do derive from a split architecture is that\nthey can add pre-decode bits to just the instruction cache. On the K6, the\npredecode bits are used for determining instruction length boundaries. Their\naddress tags (which appears to work out to 9 bits) point to a sector which\ncontains two 32 byte long cache lines, which (I assume) are selected by\nstandard associativity rules. Each cache line has a standard set of dirty bits\nto indicate accessibility state (obsolete, busy, loaded, etc).\n\nAlthough the K6's cache is non-blocking, (allowing accesses to other lines\neven if a cache line miss is being processed) the K6's load/store unit\narchitecture only allows in-order data access. So this feature cannot be taken\nadvantage of in the K6. (Thanks to Andreas Kaiser for pointing this out to\nme.)\n\nIn addition, like the 6x86MX, the store unit of the K6 actually is buffered by\na store Queue. A neat feature of the store unit architecture is that it has\ntwo operand fetch stages -- the first for the address, and the second for the\ndata which happens one clock later. This allows stores of data that are being\ncomputed in the same clock as the store to occurr without any apparent stall.\nThat is so darn cool!\n\nBut perhaps more fundamentally, as AMD have said themselves, bigger is better,\nand at twice the P-II's size, I'll have to give the nod to AMD (though a\nbigger nod to the 6x86MX; see below.)\n\nThe K6 takes two (fully pipelined) clocks to fetch from its L1 cache from\nwithin its load execution unit. Like the original P55C, the 6x86MX spends\nextra load clocks (i.e., address generation) during earlier stages of their\npipeline. On the other hand this compares favorably with the P-II which takes\nthree (fully pipelined) clocks to fetch from the L1 cache. What this means is\nthat when walking a (cached) linked list (a typical data structure\nmanipulation), the 6x86MX is the fastest, followed by the K6, followed by the\nP-II.\n\nUpdate: AMD has released the K6-3 which, like the Celeron adds a large on die\nL2 cache. The K6-3's L2 cache is 256K which is larger than the Celeron's at\n128K. Unlike Intel, however, AMD has recommended that motherboard continue to\ninclude on board L2 caches creating what AMD calls a \"TriLevel cache\"\narchitecture (I recall that an earler Alpha based system did exactly this same\nthing.) Benchmarks indicate that the K6-3 has increased in performance between\n10% and 15% over similarly clocked K6-2's! (Wow! I think I might have to get\none of these.)\n\n### Other\n\n  * The K6 has bad memory bandwidth. One is an unknown bottleneck in their block move and bursting over their bus (I and others have observed this through testing, though there is no documentation available from AMD that explains this. Update: the K6 did not support pipelined stores which has been corrected in the \"CXT core\".)\n\n  * The K6 has a 2/3 (32 bits ready/64 bits ready) clock integer multiply, which is good counter to the P-II's 1/4 (throughput/latency) clock integer multiply. Programmers usually only use the base 32 bit LSB result of the multiply, and so are likely to achieve realistic 2-clock throughputs. On the other hand the P-II's 4 clock \"hands off\" rule is unlikely to be so easily scheduled, since no contentions in 4 clocks is unlikely. In the real world, I would be very surprised if the P-II actually achieves a 1 or even 2 clock throughput.\n\n  * The K6 does not suffer the same kind of partial register stalls that the P-II does. Register contention is accurate down to the byte sub-register as required. Special clearing of the register is unnecessary. However 16 bit partial register instructions will have instruction decode overrides which will cost an extra clock.\n\n  * The K6 seems to prefer [esi+0] to [esi] memory addressing (for faster pre-decoding.) This is a side effect of the 386 ISA's strange encoding rules for this operand. Basically, the 16 bit mod/rm encodings and 32 bit modrm encodings cause an mode or operand conflict for this situation. Basically, if they made the [esi] decoding fast, numerous 16 bit modrm decodings would be very slow. This trade off was more beneficial to more code at the time.\n\n  * The K6 has a wider riscop instruction window than the P-II. That is to say instructions are entered into and retired from their scheduler at a rate of 4 RISC86 ops per clock, while the P-II enters and retires microops from their reorder buffer at a rate of 3 microops per clock.\n\n  * The K6 has a fast (1 cycle) LOOP instruction. It looks like the Intel CPUs may be the lone wolves with their slow LOOP instruction. If you ask me, this is the most ideal instruction to use for loops.\n\n  * Of course, the K6 has more a sophisticated instruction decode implementation in the sense that they can decode two 7 byte instructions or one 11 byte instruction in a single clock. Like the 6x86MX (though, with an entirely different mechanism) it can only decode a maximum of two instructions per clock versus the P-II's maximum rate of 3 instructions per clock. However, the P-II's decoding is overly optimistic since it balks on any instructions more than 7 bytes long and is also limited by micro-op decode restrictions.\n\nAnyhow, this design is very much in line with AMD's recommendation of using\ncomplicated load and execute instructions which tend to be longer and would\nfavor the K6 over the P-II. In fact, the AMD just seems better suited overall\nfor the CISCy nature of the x86 ISA. For example, the K6 can issue 2 push reg\ninstructions per clock, versus the P-II's 1 push reg per clock.\n\nAccording to AMD, the typical 32 bit decode bandwidth is about the same for\nboth the K6 and the P-II, but 16 bit decode is about 20% faster for the K6.\nUnfortunately for AMD, if software developers and compiler writers heed the\nP-II optimization rules with the same vigor that they did with the Pentium,\nthe typical decode bandwidth will change over time to favor the P-II.\n\n  * The K6's issue to execute scheduling is pretty cool. They use complete logical comparisons between pipeline stages to always find the best path to propagate from issue to operand read to execute. This is particularly effective to divide the work between the two integer units. The scheduler will actually push stalled instructions backwards through the pipeline to simplify and avoid over speculation in multi-clock stalls situations. This also allows other instructions to slip through rather than being caught behind a stalled instruction. This is an effective alternative to the P-II's reservation station which is an optional extra pipeline stage that serves a similar purpose.\n\n6x86MX seems to just let their pipelines accumulate with work moving only in a\nforward direction which makes them more susceptible to being backed up, but\nthey do allow their X and Y pipes to swap contents at one stage.\n\n  * The K6 does not support the new P6 ISA instructions, specifically, the conditional move instructions. It also does not appear to support the set of MSRs that the P6 does (besides the ever important TSC register.) So from a programmer's architecture point of view, the K6 is more like a Pentium than a Pentium-II. Its not clear that this is a real big issue since all the modern compilers still target the 80386 ISA.\n\nUpdate: AMD's new \"CXT Core\" has enabled write combining.\n\nAs I have been contemplating the K6 design, it has really grown on me.\nFundamentally, the big problem with x86 processors versus RISC chips is that\nthey have too few registers and are inherently limited in instruction decode\nbandwidth due to natural instruction complexity. The K6 addresses both of\nthese by maximizing performance of memory based in-cache data accesses to make\nup for the lack of registers, and by streamlining CISC instruction issue to be\noptimally broken down into RISC like sub-instructions.\n\nIt is unfortunate, that compilers are favoring Intel style optimizations.\nBasically there are several instructions and instruction mixes that compilers\navoid due to their poor performance on Intel CPUs, even though the K6 executes\nthem just fine. As an x86 assembly nut, it is not hard to see why I favor the\nK6 design over the Intel design.\n\n### Optimization\n\nAMD realizing that there is a tremendous interest for code optimization for\ncertain high performance applications, decided to write up some Optimization\ndocumentation for the K6 (and now K6-2) processor(s). The documentation is\nfairly good about describing general strategies as well as giving a fairly\ndetailed description for modelling the exact performance of code. This\ndocumentation far exceeed the quality of any of Intel's \"Optimization AP\nnotes\", fundamentally because its accurate and more thorough.\n\nThe reason I have come to this conclusion is that the architecture of the chip\nitself is much more straight forward than, say the P-II, and so there is less\nexplanation necessary. So the volume of documentation is not the only\ndetermining factor to measuring its quality.\n\nIf companies were interested in writing a compiler that optimized for the K6\nI'm sure they could do very well. In my own experiments, I've found that\noptimizing for the K6 is very easy.\n\nRecommendations I know of: (1) Avoid vector decoded instructions including\ncarry flag reading instructions and shld/shrd instructions, (2) Use the loop\ninstruction, (3) Align branch targets and code in general as much as possible,\n(4) Pre-load memory into registers early in your loops to work around the load\nlatency issue.\n\n### Brass Tacks\n\nThe K6 is cheap, supports super socket 7 (with 100Mz Bus), that has\nestablished itself very well in the market place, winning businnes from all\nthe top tier OEMs (with the exception of Dell, which seems to have missed the\nconsumer market shift entirely, and taken a serious step back from challenging\nCompaq's number one position.) AMD really changed the minds of people who\nthought the x86 market was pretty much an Intel deal (including me.)\n\nTheir marketting strategy of selling at a low price while adding features\n(cheaper Super7 infrastructure, SIMD floating point, 256K on chip L2 cache\ncombined with motherboard L2 cache) has paid off in an unheard of level brand\nname recognition outside of Intel. Indeed, 3DNow! is a great counter to Intel\nInside. If nothing else they helped create a real sub-$1000 PC market, and\nhave dictated the price for retail x86 CPUs (Intel has been forced to drop\neven their own prices to unheard of lows for them.)\n\nAMD has struggled more to meet the demand of new speeds as they come online\n(they seem predictably optimistic) but overall have been able to sell a boat\nload of K6's without being stepped on by Intel.\n\nPreviously, in this section I maintained a small chronical of AMD's\nacheivements as the K6 architecture grew, however we've gotten far beyond the\nquestion of \"will the K6 survive?\" (A question only idiots like Ashok Kumar\nstill ask.) From the consumer's point of view, up until now (Aug 99) AMD has\ndone a wonderful job. Eventually, they will need to retire the K6 core -- it\nhas done its tour of duty. However, as long as Intel keeps Celeron in the\nmarket, I'm sure AMD will keep the K6 in the market. AMD has a new core that\nthey have just introduced into the market: the K7. This processor has many\nsignificant advantages over \"6th generation architectures\".\n\nThe real CPU WAR has only just begun ...\n\n### AMD performance documentation links\n\nThe first release of their x86 Optimization guide is what triggered me to\nwrite this page. With it, I had documentation for all three of these 6th\ngeneration x86 CPUs. Unfortunately, they often elect to go with terse\nexplanations that assume the reader is very familiar with CPU architecture and\nterminologies. This lead me to some misunderstandings from my initial reading\nof the documentation (I'm just a software guy.) On the other hand, the\nexamples they give really help clarify the inner workings of the K6.\n\n  * AMD K6-2 specifications\n  * AMD-K6 Optimization Guide\n  * AMD-K6 Processor Data Sheet\n\nUpdate: The IEEE Computer Society has published a book called \"The Anatomy of\na High-Performance Microprocessor A Systems Perspective\" based on the AMD K6-2\nmicroprocessor. It gives inner details of the K6-2 that I have never seen in\nany other documentation on Microprocessors before. These details are a bit\noverwhelming for a mere software developer, however, for a hard core x86\nhacker its a treasure trove of information.\n\n  * The Anatomy of a High-Performance Microprocessor A Systems Perspective\n\nThe Intel P-II  \n---  \n  \nThis was the first processor (I knew of) to have completely documented post-\nRISC features such as dynamic execution, out of order execution and\nretirement. (PA-RISC predated it as far as implementing the technology,\nhowever; I am suspicious that HP told Intel to either work with them on\nMerced, or be sued up the wazoo.) This stuff really blew me away when I first\nread it. The goal is to allow longer latencies in exchange for high throughput\n(single cycle whenever possible.) The various stages would attempt to\nissue/start instructions with the highest possible probability as often as\npossible, working out dependencies, register renaming requirements,\nforwarding, resource contentions, as later parts of the instruction pipe by\nmeans of speculative and out of order execution.\n\nIntel has enjoyed the status of \"defacto standard\" in the x86 world for some\ntime. Their P6/P-II architecture, while not delivering the same performance\nboost of previous generational increments, solidifies their position. Its is\nthe fastest, but it is also the most expensive of the lot.\n\n### General Architecture\n\nThe P-II is a highly pipelined architecture with an out of order execution\nengine in the middle. The Intel Architecture Optimization Manual lists the\nfollowing two diagrams:\n\nThe two sections shown are essentially concatenated, showing 10 stages of in-\norder processing (since retirement must also be in-order) with 3 stages of out\nof order execution (RS, the Ports, and ROB write back colored in light blue by\nme, not Intel.)\n\nIntel's basic idea was to break down the problem of execution into as many\nunits as possible and to peel away every possible stall that was incurred by\ntheir previous Pentium architecture as each instructions marches forward down\ntheir assembly line. In particular, Intel invests 5 pipelined clocks to go\nfrom the instruction cache to a set of ready to execute micro-ops. (RISC\narchitectures have no need for these 5 stages, since their fixed width\ninstructions are generally already specified to make this translation\nimmediate. It is these 5 stages that truly separate the x86 from ordinary RISC\narchitectures, and Intel has essentially solved it with a brute force approach\nwhich costs them dearly in chip area.)\n\nEach of Intel's \"Ports\" is used as a feeding trough for microops to various\ngroupings of units as shown in the above diagram. So, Intel's 5 micro-op\nexecution per clock bandwidth is a little misleading in the sense that two\nports are required for any single storage operation. So, it is more realistic\nto consider this equivalent, to at most 4 K6 RISC86 ops issued per clock.\n\nAs a note of interest, Intel divides the execution and write back stages into\ntwo seperate stages (the K6 does not, and there is really no compelling reason\nfor the P6's method that I can see.)\n\nAlthough it is not as well described, I believe that Intel's reservation\nstation and reorder buffer combinations serves substantially the same purpose\nas the K6's scheduler, and similarly the retire unit acts on instruction\nclusters in exactly the same way as they were issued (CPUs are not otherwise\nknown to have sorting algorithms wired into them.) Thus the micro-op\nthroughput is limited to 3 per clock (compared with 4 RISC86 ops for the K6.)\n\nSo when everything is working well, the P-II can take 3 simple x86\ninstructions and turn them into 3 micro-ops on every clock. But, as can be\nplainly seen in their comments, they have a bizzare problem: they can only\nread two physical input register operands per clock (rename registers are not\nconstrained by this condition.) This means scheduling becomes very\ncomplicated. Registers to be read for multiple purposes will not cost very\nmuch, and data dependencies don't suffer from any more clocks than expected,\nhowever the very typical trick of spreading calculations over several\nregisters (used especially in loop unrolling) will upper bound the pipeline to\ntwo micro-ops per clock because of a physical register read bottleneck.\n\nIn any event, the decoders (which can decode up to 6 micro-ops per clock) are\nclearly out-stripping the later pipeline stages which are bottlenecked both by\nthe 3 micro-op issue and two physical register read operand limit. The front\nend easily outperforms the back end. This helps Intel deal with their branch\nbubble, by making sure the decode bandwidth can stay well ahead of the\nexecution units.\n\nSomething that you cannot see in the pictures above is the fact that the FPU\nis actually divided into two partitioned units. One for addition and\nsubtraction and the other for all the other operations. This is found in the\nPentium Pro documentation and given the above diagram and the fact that this\nis not mentioned anywhere in the P-II documentation I assumed that in fact the\nP-II was different from the PPro in this respect (Intel's misleading\ndocumentation is really unhelpful on this point.) After I made some claims\nabout these differences on USENET some Intel engineer (who must remain\nanonymous since he had a copyright statement insisting that I not copy\nanything he sent me -- and it made no mention of excluding his name) who\nclaims to have worked on the PPro felt it his duty to point out that I was\nmistaken about this. In fact, he says, the PPro and P-II have an identical FPU\narchitecture. So in fact the P-II and PPro really are the same core design\nwith the exception of MMX, segment caching and probably some different glue\nlogic for the local L2 caches.\n\nThis engineer also reiterated Intel's position on not revealing the inner\nworks of their CPU architectures thus rendering it impossible for ordinary\nsoftware engineers to know how to properly optimize for the P-II.\n\n### Branch Prediction\n\nCentral to facilitating the P-II's aggressive fire and forget execution\nstrategy is full branch prediction. The functionality has been documented by\nAgner Fog, and can track very complex patterns of branching. They have\nadvertised a prediction rate of about 90% (based on academic work using the\nsame implementation.) This prediction mechanism was also incorporated into the\nPentium MMX CPUs. Unlike the K6, the branch target buffer contains target\naddresses, not instructions and predictions only for the current branch. This\nmeans an extra clock is required for taken branches to be able to decode their\nbranch target. Branches not in the branch target buffer are predicted\nstatically (backward jumps taken, forward jumps not.) However, this \"extra\nclock\" is generally overlapped with execution clocks, and hence is not a\nfactor except in short loops, or code loops with poorly translated code\nsequences (like compiled sprites.)\n\nIn order to do this in a sound manner, subsequent instructions must be\nexecuted \"speculatively\" under the proviso that any work done by them may have\nto be undone if the prediction turns out to be wrong. This is handled in part\nby renaming target write-back registers to shadow registers in a hidden set of\nextra registers. The K6 and 6x86MX have similar rename and speculation\nmechanisms, but with its longer latencies, it is a more important feature for\nthe P-II. The trade off is that the process of undoing a mispredicted branch\nis slow (since the pipelines must completely flush) costing as much as 15\nclocks (and no less than 11.) These clocks are non-overlappable with\nexecution, of course, since the execution stream cannot be correctly known\nuntil the mispredict is completely processed. This huge penalty offsets the\nperformance of the P-II, especially in code in which no P6/P-II optimizations\nconsiderations have been made.\n\nThe P-II's predictor always deals with addresses (rather than boolean compare\nresults as is done in the K6) and so is applicable to all forms of control\ntransfer such as direct and indirect jumps and calls. This is critical to the\nP-II given that the latency between the ALUs and the instruction fetch is so\nlarge.\n\nIn the event of a conditional branch both addresses are computed in parallel.\nBut this just aids in making the prediction address ready sooner; there is no\nappreciable performance gained from having the mispredicted address ready\nearly given the huge penalty. The addresses are computed in an integer\nexecution port (seperate from the FPU) so branches are considered an ALU\noperation. The prefetch buffer is stalled for one clock until the target\naddress is computed, however since the decode bandwidth out-performs the\nexecution bandwidth by a fair margin, this is not an issue for non-trivial\nloops.\n\n##### Back of envelope calculation\n\nThis all means that the average loop penalty is:\n\n(90% * 0) + (10% * 13) = 1.3 clocks per loop\n\nThis is obviously a lot higher than the K6 penalty. (The zero as the first\npenalty assumes that the loop is sufficiently large to hide the one clock\nbranch bubble.)\n\nFor programmers this means one major thing: Avoid mispredicted branches in\nyour inner loops at all costs (make that 10% closer to 0%). Using tables or\nconditional move instructions are common methods, however since the predictor\nis used even in indirect jumps, there are situations with branching where you\nhave no choice but to suffer from branch prediction penalties.\n\n### Floating Point\n\nIn keeping with their post-RISC architecture, the P-II's have in some cases\nincreased the latency of some of the FPU instructions over the Pentium for\nsake of pipelining at high clock rates and with idea that it hopefully will\nnot matter if the code is properly scheduled. Intel says that FXCH requires no\nexecution cycles, but does not explicitly state whether or not throughput\nbubbles are introduced. Other than latency, the P-II is very similar to the\nPentium in terms of performance characteristics. This is because all FPU\noperations go through port 0 except FXCH's which go to port 1, and the first\nstage of a multiply takes two non-pipelined clocks. This is pretty much\nidentical to the P5 architecture.\n\nThe Intel floating point design has traditionally beat the Cyrix and AMD CPUs\non floating point performance and this still appears to hold true as tests\nwith Quake and 3D Studio have confirmed. (The K6 is also beaten, but not by\nsuch a large margin -- and in the case of Quake II on a K6-2 the roles are\nreversed.)\n\nThe P-II's floating point unit is issued from the same port as one of the ALU\nunits. This means that it cannot issue two integer and 1 floating point\noperation on every clock, and thus is likely to be constrained to an issue\nrate similar to the K6. As Andreas Kaiser points out, this does not\nnecessarily preclude later execution clocks (for slower FPU operations for eg)\nto execute in parallel from all three basic math units (though this same\ncomment applies to the K6).\n\nAs I mentioned above, the P-II's floating point unit is actually two units,\none is a fully pipelined add and subtract unit, and the other is a partially\npipelined complex unit (including multiplies.) In theory this gives greater\nparallelism opportunities over the original Pentium but since the single port\n0 cannot feed the units at a rate greater than 1 instruction per clock, the\nonly value is design simplification. For most code, especially P5 optimized\ncode, the extra multiply latency is likely to be the most telling factor.\n\nUpdate: Intel has introduced the P-!!! which is nothing more than a 500Mhz+ P6\ncore with 3DNow!-like SIMD instructions. These instructions appear to be very\nsimilar in functionality and remarkably similar in performance to the 3DNow!\ninstruction set. There are a lot of misconceptions about the performance of\nSSE versus 3DNow! The best analysis I've seen so far indicate that they are\nnearly identical by virtue of the fact that Intel's \"4-1-1\" issue rate\nrestriction holds back the mostly meaty 2 micro-op SSE instructions.\nFurthermore, there are twice as many subscribers to the SSE units per\ninstruction than 3DNow! which totally nullifies the doubled output width. In\nany event, its almost humorous to see Intel playing catch up to AMD like this.\nThe clear winner: consumers.\n\n### Cache\n\nThe P-II's L1 cache is 32KB divided into two fixed 16KB caches for separate\ncode and data. These caches are 4-way set associative which decreases\nthrashing versus the K6. But relatively speaking, this is quite small and\ninflexible when compared with the 6x86MX's unified cache. I am not a big fan\nof the P-II's smaller, less flexible L1 cache, and it appears as though they\nhave done little to justify it being half the size of their competitors' L1\ncaches.\n\nThe greater associativity helps programs that are written indifferently with\nrespect to data locality, but has no effect on code mindful of data locality\n(i.e., keeping their working sets contiguous and no larger than the L1 cache\nsize.)\n\nThe P-II also has an \"on PCB L2 cache\". What this means is they do not need\nuse the motherboard bus to access their L2 cache. As such the communications\ninterface can (and does) have a much higher frequency. In current P-II's it is\n1/2 the CPU clock rate. This is an advantage over K6, K6-2 and 6x86MX cpus\nwhich access motherboard based L2 caches at only 66Mhz or 100Mhz. (However the\nK6-III's on die L2 cache runs at the CPU clock rate, which is thus twice as\nfast as the P-II's)\n\n### Other\n\n  * The P-II has a partial register stall which is very costly. This occurs when writing to a sub-register within a few clocks of writing to a 32 bit register. That is to say, writing to a ?l or ?h 8 bit register will cause a partial register stall when next reading the corresponding ?x or e?x register. The same is true of writing to a ?x register then reading the corresponding e?x register.\n\nAs described by Agner Fog, the front end is in-order and must assign internal\nregisters before the instruction can be entered into the reservations\nstations. If there is a partial register overlap with a live instruction ahead\nof it, then a disjoint register cannot be assigned until that instruction\nretires. This is a devastating performance stall when it occurs because new\ninstructions cannot even be entered into the reservations stations until this\nstall is resolved. Intel lists this as having roughly a 7 clock cost.\n\nIntel recommends using XOR reg,reg or SUB reg,reg which will somehow mark the\npartial register writes as automatically zero extending. But obviously this\ncan be inappropriate if you need other parts of the register to be non-zero.\nIt is not clear to me whether or not this extends to memory address forwarding\n(it probably does.) I would recommend simply seperating the partial register\nwrite from the dependent register read by as much distance as possible.\n\nThis is not a big issue so long as the execution units are kep busy with\ninstructions leading up to this partial registers stall, but that is a\ndifficult criteria to code towards. One way to accomplish this would be to try\nto schedule this partial register stall as far away from the previous branch\ncontrol transfer as possible (the decoders usually get well ahead of the ALUs\nafter several clocks following a control transfer.)\n\n  * The P-II, like the P6, performs worse on 16 bit code per clock rate than the Pentium. (Significantly worse than the Cyrix 6x86MX, and somewhat worse than the K6.) However, the P-II is not as bad as the P6. In particular, it uses a small 16 bit segment/selector cache which the P6 does not.\n\n  * The P-II's data access actually require an additional address unit for stores. What this means is that memory writes must be broken down into \"address store\" and \"data store\" micro-ops. This increases data write latency (versus the K6.)\n\n  * The P-II can decode instructions to many, many micro-ops, but really only decodes optimally when 2 out of every 3 instructions are decoded to a single micro-op and in a specific \"4-1-1\" sequence (that is for three instructions to decode in parallel the first must decode to no more than 4 micro-ops, and the second and third in no more than 1 micro-op). Instructions must also be 8 bytes or less to allow other instructions to be decoded in the same clock. According to MicroProcessor Report, only one load or store memory operation can be decoded in the first of the at most 3 instructions. If this is true, it certainly detracts from the \"one load or store operations per clock\" claim Intel makes (of course the second of the two store microops might execute at the same time as a load.)\n\nOnly under these circumstances can the P-II achieve its maximum rate of\ndecoding 3 instructions per cycle.\n\nUpdate: I recently tried to hand optimize some code, and found that it is\nactually not all that difficult to achieve the 3 instruction issue per clock,\nbut that certainly no compiler I know of is up to the task. It turns out,\nthough, that such activities are almost certainly a red herring since\ndependency bubbles will end up throttling your performance anyways. My\nrecommendation is to parallelize your calculations as much as possible.\n\n  * Stores are pipelined, but not queued like the 6x86MX or K6. This means cache misses necessarily stalls subsequent store micro-op execution. So the P-II ends up using the reservation station to queue up store commands rather than a dedicated store queue. It is not totally clear to me if this stalls the load unit, but I am guessing not since the cache has been claimed to be non-blocking.\n\n  * The K6 requires in-order writes, while the P-II almost assuredly reorders its writes very aggressively in an attempt to build contiguous memory write streams. The original P6 core has also included write combining (makes clustered byte writes appear as byte enabled dword writes to the PCI bus.) With the introduction of the Pentium Pro, many 3rd party hardware peripheral vendors that used the memory mapping features of PCI found themselves fixing their drivers to, in some cases, work around this \"feature\" of the P6 architecture. However for ordinary applications this just meant higher memory bandwidth performance (more so with the P-II than the P6.)\n\n  * Intel has leveraged its dominance in the market, advanced process and a daring approach to L2 cache usage to introduce their slot 1 cartridge interface to motherboards. The upshot of all of this is that they are able to use a larger heat sink and have better control over a more reliably yielded L2 cache running at reasonable clock rate (half the processor speed.)\n\nAt the same clock rate, this is its biggest advantages over the current K6\nwhose L2 cache is tied to the chipset speed of 66Mhz.\n\n  * Intel's CPUs come with more MSRs which give detailed information about branch prediction and scheduling stalls (by a net counts) and let you mark memory type ranges with respect to cacheability and write combinability. These details, among others, were at the heart of the controversy surrounding \"Appendix H\" a while back with the Pentium CPU.\n\nBut now, after being pressured into publishing information about MSRs, Intel\nhas decided to go one step further and provide a tool to help present the MSR\ninformation in a Windows program. While this tool is very useful in of itself,\nit would be infinitely superior if there were accompanying documentation that\ndescribed the P-II's exact scheduling mechanism.\n\n### Optimization\n\nIntel has been diligent in creating optimization notes and even some\ninteractive tutorials that describe how the P-II microarchitecture works. But\nthe truth is that they serve as much as CPU advertisements as they do for\nserious technical material. We found out with the Pentium CPU, Intel's notes\nwere woefully inadequate to give an accurate characterization for modelling\nits behaviour with respect to performance (this opened the door for people\nlike Michael Abrash and Agner Fog to write up far more detailed descriptions\nbased on observation rather than Intel's anemic documentation.) They contain\negregious omissions, without given a totally clear description of the\narchitecture.\n\nWhile they claim that hand scheduling has little or no effect on performance\nexperiments I and others have conducted have convinced me that this simply is\nnot the case. In the few attempts I've made using ideas I've recently been\nshown and studied myself, I can get between 5% and 30% improvement on very\ninnocent looking loops via some very unintuitive modifications. The problem is\nthat these ideas don't have any well described explanation -- yet.\n\nWith the P-II we find a nice dog and pony show, but again the documentation is\ninadequate to describe essential performance characteristics. They do steer\nyou away from the big performance drains (branch misprediction and partial\nregister stalls.) But in studying the P-II more closely, it is clear that\nthere are lots of things going on under the hood that are not generally well\nunderstood. Here are some examples (1) since the front end out-performs the\nback-end (in most cases) the \"schedule on tie\" situation is extremely\nimportant, but there is not a word about it anywhere in their documentation\n(Lee Powell puts this succinctly by saying that the P-II prefers 3X\nsuperscalar code to 2X superscalar code.) (2) The partial register stall\nappears to, in some cases, totally parallelize with other execution in some\ncases (the stall is less than 7 clocks), while not at all in others (a 7 clock\nstall in addition to ordinary clock expenditures.) (3) Salting execution\nstreams with bogus memory read instructions can improve performance (I\nstrongly suspect this has something to do with (1)).\n\nSo why doesn't Intel tell us these things so we can optimize for their CPU?\nThe theory that they are just telling Microsoft or other compiler vendors\nunder NDA doesn't fly since the kinds of details that are missing are well\nbeyond the capabilities of any conventional compiler to take advantage of (I\ncan still beat the best compilers by hand without even knowing the\noptimization rules, but instead just by guessing at them!) I can only imagine\nthat they are only divulging these rules to certain companies that perform\nperformance critical tasks that Intel has a keen interest in seeing done well\nrunning on their CPUs (soft DVD from Zoran for example; I'd be surprised if\nIntel didn't give them either better optimization documentation or actual code\nto improve their performance.)\n\nIntel has their own compiler that they have periodically advertised on the net\nas a plug in replacement for the Windows NT based version of MSVC++, available\nfor evaluation purposes (it's called Proton if I recall correctly). However,\nit is unclear to me how good it is, or whether anyone is using it (I don't use\nWinNT, so I did not pursue trying to get on the beta list). Update: I have\nbeen told that Microsoft and Imprise (Borland) have licensed Intel's compiler\nsource and has been using it are their compiler base.\n\nRecommendations I know of: (1) Avoid mispredicted branches (using conditional\nmove can be helpful in removing unpredictable branches), (2) Avoid partial\nregister stalls (via the xor/sub reg,reg work arounds, or the movzx/movsx\ncommands or by simply avoiding smaller registers.) (3) Remove artificial\n\"schedule on tie\" stalls by slowing down the front end x86 decoder (i.e.,\nissuing a bogus bypassed load command by rereading out of the same address as\nthe last memory read can often help.) For more information read the discussion\non the sandpile.org discussion forum (4) Align branch target instructions;\nthey are not fed to the second prefetch stage fast enough to automatically\nalign in time.\n\n### Brass Tacks\n\nWhen it comes right down to brass tacks though, the biggest advantage of their\nCPU is the higher clock rates that they have achieved. They have managed to\nstay one or two speed grades ahead of AMD. The chip also enjoys the benefit of\nthe Intel Inside branding. Intel has spent a ton of money in brand name\nrecognition to help lock its success over competitors. Like the Pentium, the\nP-II still requires a lot of specific coding practices to wring the best\nperformance out of them, and its no doubt that many programmers will do this,\nand Intel has gone to some great lengths to write tutorials that explain how\nto do this (regardless of their lack of correctness, they will give\nprogrammers a false sense of empowerment).\n\nDuring 1998, what consumers have been begging for for years, a transition to\nsuper cheap PCs has taken place. This is sometimes called the sub-$1000 PC\nmarket segment. Intel's P-II CPUs are simply too expensive (costing up to $800\nalone) for manufacturers to build compelling sub-$1000 systems with them. As\nsuch, Intel has watched AMD and Cyrix pick up unprecedented market share.\n\nIntel made a late foray into the sub-$1000 PC market. Their whole business\nmodel did not support such an idea. Intel's \"value consumer line\" the Celeron\nstarted out as a L2-cacheless piece of garbage architecture (read: about the\nsame speed as P55Cs at the same clock rates), then switched to an integrated\nL2 cache architecture (stealing the K6-3's thunder). Intel was never really\nable to recover the bad reputation that stuck to the Celeron, but perhaps that\nwas their intent all along. It is now clear that Intel is basically dumping\nCelerons in an effort to wipe out AMD and Cyrix, while trying to maintain\ntheir hefty margins in their Pentium-II line. For the record, there is little\nperformance difference between a Pentium-II and a Celeron, and the clock rates\nfor the Celeron were being made artificially slow so as not to eat into their\nPentium line. This action alone has brought a resurgence into the \"over\nclocking game\" that some adventurous power users like to get into.\n\nBut Intel being Intel has managed to seriously dent what was exclusively an\nAMD and Cyrix market for a while. Nevertheless since the \"value consumer\"\nmarket has been growing so strongly, AMD and Cyrix have nevertheless been able\nto increase their volumes even with Intel's encroachment.\n\nThe P-II architecture is getting long in the tooth, but Intel keeps insisting\non pushing it (demonstrating an uncooled 650Mhz sample in early 1999.) Mum's\nthe word on Intel's seventh generation x86 architecture (the Williamette or\nFoster) probably because that architecture is not scheduled to be ready before\nlate 2000. This old 6th generation part may prove to be easy pickings for\nCyrix Jalapeno and AMD's K7, both of which will be available in the second\nhalf of 1999.\n\n### Intel performance documentation links\n\nWhile Intel does have plenty of documentation on their web site, they quite\nsimply do not sit still with their URLs. It is impossible to keep track of\nthese URLs, and I suspect Intel keeps changing their URLs based on some\nulterior motive. All I can suggest is: slog through their links starting at\nthe top. I have provided a link to Agner Fog's assembly page where his famous\nPentium optimization manual has been updated with a dissection of the P-II.\n\n  * www.intel.com\n  * developer.intel.com\n  * Agner Fog's P5 and P-II optimization manual\n\nThe Cyrix 6x86MX  \n---  \n  \nOriginally codenamed M2, this chip was very eagerly awaited. Cyrix had been\nmaking grand claims about their superior architecture and this was echoed by\nCyrix's small but loyal following. Indeed it did come out, and indeed it is\nvery interesting architecture, but to say the least, it was very late. Both\nAMD and Intel had announced their 6th generation MMX processors and enjoyed a\ncouple months of extra revenue before Cyrix appeared on the scene. But as\nalways, these Cyrix CPUs have hit the street at a substantially lower cost\nthan its rivals, although recent price cuts from AMD may be marginalizing them\nat the high end.\n\nThe primary microarchitecture difference of the 6x86MX CPU versus the K6 and\nP-II CPUs is that it still does native x86 execution rather than translation\nto internal RISC ops.\n\n### General Architecture\n\nThe Cyrix remains a dual piped superscalar architecture, however it has\nsignificant improvements over the Pentium design:\n\nBy being able to swap the instructions, there is no concern about artificial\nstalls due to scheduling of instruction to the wrong pipeline. By introducing\ntwo address generation stages, they eliminate the all too common AGI stall\nthat is seen in the Pentium. The 6x86MX relies entirely on up front dependency\nresolution via register renaming, and data forwarding; it does not buffer\ninstructions in any way. Thus its instruction issue performance becomes\nbottlenecked by dependencies.\n\nThe out of order nature of the execution units are not very well described in\nCyrix's documentation beyond saying that slower instructions will make way for\nfaster instructions. Hence it is not clear what the execution model really\nlooks like.\n\n### Branch Prediction\n\nThe Cyrix CPU uses a 512 entry 2 bit predictor and this does not have a\nprediction rate that rivals either the P-II or K6 designs. However, both sides\nof the branch will have first instruction decoded simultaneously in the same\nclock. In this way, the Cyrix hedges its bets so that it doesn't pay such a\nsevere performance penalty when its prediction goes wrong. Beyond this, it\nappears as though Cyrix has gone full Post-RISC architecture and supports a\nbranch predict and speculative execution model. This fits nicely with their\naggressive register renaming, and data forwarding model from the original 6x86\ndesign. Because of potential FPU exceptions, all FPU instructions are treated\nthe same way as branch prediction. I would expect the same to be true of the\nP-II, but Intel has not documented this, whereas Cyrix has.\n\nThey have a fixed scheme of 4 levels of speculation, that are simply increased\nfor every new speculative instruction issued (this is somewhat lower than the\nP-II and K6 which can have 20 or 24 live instructions at any one given time,\nand somewhat more outstanding branches.)\n\nThe 6x86MX architecture is more lock stepped than the K6, and as such their\nissue follows their latency timings more closely. Specifically their decode,\nissue and address generation stages are executed in lock step, with any stalls\nfrom resource contentions, complex decoding etc, backing up the entire\ninstruction fetch stages. However their design makes it clear that they do\neverything possible to reduce these resource contentions as early as possible.\nThis is to be contrasted with the K6 design which is not lock step at all, but\ndue to its late resource contention resolution, may be in the situation of re-\nissuing instructions after potentially wasting an extra clock that it didn't\nneed to in its operand fetch stage.\n\n### Floating Point\n\nThe 6x86MX has significantly slower floating point. The Cyrix's FADD, FMUL,\nFLD and FXCH instructions all take at least 4 clocks which puts it at one\nquarter of the P-II's peak FPU execution rate. The 6x86MX (and even older\n6x86) tried to make up for it by having an FPU instruction FIFO. This means\nthat most of the FPU clocks can be overlapped with integer clocks, and that a\nhandful of FPU operations can be in flight at the same time, but in general\nrequires hand scheduling and relatively light use of the FPU to maximally\nleverage it. Oddly enough, their FDIV and FSQRT performance is about as good\nif not better than the P-II implementation. This seems like an odd design\ndecision, as optimizing FADD, FLD, FXCH and FMUL, are clearly of much higher\nimportance.\n\nLike AMD, Cyrix designed their 6x86MX floating point around the weak code that\nx86 compilers generate on FPU code. But, personally, I think Cyrix has gone\nway too far in ignoring FPU performance. Compilers only need to get a tiny bit\nbetter for the difference between the Cyrix and Pentium II to be very\nnoticeable on FPU code.\n\n### Cache\n\nThe Cyrix's cache design is unifed at 64KB with a separate extra 256 byte\ninstruction buffer. I prefer this design to the K6's and P-II's split code and\ndata architecture, since it better takes into account the different dynamics\nof code usage versus data usage that you would expect in varied software\ndesigns. As an example, p-code interpreters, or just interpreted languages in\ngeneral, you would expect to benefit more from a larger data cache. The same\nwould apply to multimedia algorithms which would tend to apply simple\ntransformations on large amounts of data (though in truth, your system\nbenefits more from coprocessors for this purpose.) As another example, highly\ncomplex (compiled) applications that weave together the resources of many code\npaths (web browsers, office suite packages, and pre-emptive multitasking OSes\nin general) would prefer to have larger instruction caches. At both extremes,\nthe Cyrix has twice the cache ceiling.\n\nThus the L1 cache becomes a sort of L2 cache for the 256 byte instruction line\nbuffer, which allows the Cyrix design to complicate a much smaller cache\nstructure with predecode bits and so on, and use the unified L1 cache more\nefficiently as described above. Although I don't know details, the prefetch\nunits could try to see a cache miss comming and pre-load the instruction line\ncache in parallel with ordinary execution; this would compensate for the\ninstruction cache's unusually small size, I would expect to the point of\nmaking it a mute point.\n\n### Other\n\n  * In moving to separate unit architectures, the K6 and P-II have sacrificed certain aspects of the Pentium-like fixed architecture. For example, the Pentium is capable of two loads and two stores per cycle to addresses with different cache line offsets. I would expect that the Cyrix has retained this as a side effect of staying with a fixed dual pipeline architecture.\n\n  * Faster selector/segment manipulation instructions than the Pentium. Apparently, the Cyrix has many more TLBs (transfer look aside buffers) that aids this significantly. This helps their 16 bit code significantly over the P-II, and even K6 which explains why their WinStone scores are so much better under Windows 95 than Windows NT.\n\n  * One clock LOOP instructions! This follows the PowerPC design choice of making a high throughput count down branch instruction. Like the PowerPC, they could in fact have implemented this with 100% accurate branch target prediction, however they did not document whether or not they have done this. Unfortunately, programmers have been using these instructions less and less, since starting with the Pentium, Intel has been making this instruction slower.\n\n  * Two barrel shifters (one for each pipe), allowing greater parallelism with shift instructions. This is an advantage over both the P-II and K6 which each have only one unit that can handle shifts.\n\n  * There are no partial register stalls or smaller operand restrictions that I could find documented. Cyrix is clearly committed to retaining high performance of older 16 bit code. This is important for Windows 95, however less so for Windows NT.\n\n  * The Cyrix has a very interesting extension to their general architecture that allows them to use part of the L1 cache as a scratch pad. This presents a very interesting alternative for programmers who have complained about the x86's lack of registers. It is not clear that programmers would be willing to special case the Cyrix to use this feature, but you can bet that the drivers Cyrix writes for their GX platforms uses this feature.\n\nAlthough I have not read about the Cyrix in great detail, it would seem to me\nthat this was motivated by the desire to perform well on multimedia\nalgorithms. The reason is that multimedia tends to use memory in streams,\ninstead of reusing data which conventional caching strategies are designed\nfor. So if the Cyrix's cache line locking mechanism allows redirecting of\ncertain memory loads then this will allow them to keep the rest of their L1\ncache intact for use by tables or other temporary buffers. This would be a\ngood strategy for their next generation MXi processor (an integrated graphics\nand x86 processor.)\n\n### Optimization\n\nCyrix's documentation is not that deep, but I get the feeling that neither are\ntheir CPU's. Nevertheless, they do not describe their out of order mechanism\nin sufficient detail to even evaluate it. Not having tried to optimize for a\nCyrix CPU myself, I don't have enough data points to really evaluate how\nlacking the documentation is. But it does appear that Cyrix is somewhat behind\nboth Intel and AMD here.\n\nIt is my understanding that Cyrix commissioned Green Hills to create a\ncompiler for them, however I have not encountered or even heard of any target\ncode produced by it (that I know of). Perhaps the MediaGX drivers are built\nwith it.\n\nUpdate: I've been recently pointed at Cyrix's Appnotes page, in particular\nnote 106 which describes optimization techniques for the 6x86 and 6x86MX. It\ndoes provide a lot of good suggestions which are in line with what I know\nabout the Cyrix CPUs, but they do not explain everything about how the 6x86MX\nreally works. In particular, I still don't know how their \"out of order\"\nmechanism works.\n\nIt is very much like Intel's documentation which just tells software\ndevelopers what to do without giving complete explanations as to how their CPU\nworks. The difference is that its much shorter and more to the point.\n\nOne thing that surprised me is that the 6x86MX appears to have several\nextended MMX instructions! So in fact, Cyrix had actually beaten AMD to\n(nontrivially) extending the x86 instruction set (with the K6-2), they just\ndidn't do a song and dance about it at the time. I haven't studied them yet,\nbut I suspect that when Cyrix releases their 3DNOW! implementation they should\nbe able to advertise the fact that they will be supplying more total\nextensions to the x86 instruction set with all of them being MMX based.\n\n### Brass Tacks\n\nThe 6x86MX design clearly has the highest instructions processed per clock on\nmost ordinary tasks (read: WinStone.) I have been told various explanations\nfor it (4-way 64K L1 cache, massive TLB cache, very aggressive memory\nstrategies, etc), but without a real part to play with, I have not been able\nto verify this on my own.\n\nWell, whatever it is, Cyrix learned an important lesson the hard way: clock\nrate is more important than architectural performance. Besides keeping Cyrix\nin the \"PR\" labelling game, their clock scalability could not keep up with\neither Intel or AMD. Cyrix did not simply give up however. Faced with a\nquickly dying architecture, a shared market with IBM, as well as an\nunsuccessful first foray into integrated CPUs, Cyrix did the only thing they\ncould do -- drop IBM, get foundry capacity from National Semiconductor and\nsell the 6x86MX for rock bottom prices into the sub-$1000 PC market. Indeed\nhere they remained out of reach of either Intel and AMD, though they were not\nexactly making much money with this strategy.\n\nCyrix's acquisition by National Semiconductor has kept their future processor\ndesigns funded, but Cayenne (a 6x86MX derivative with a faster FPU and 3DNow!\nsupport) has yet to appear. Whatever window of opportunity existed for it has\nalmost surely disappeared if it cannot follow the clock rate curve of Intel\nand AMD. But the real design that we are all waiting for is Jalapeno. National\nSemiconducter is making an very credible effort to ramp up its 0.18 micron\nprocess and may beat both Intel and AMD to it. This will launch Jalapeno at\nspeeds in excess of 600Mhz with the \"PR\" shackels removed, which should allow\nCyrix to become a real player again.\n\nUpdate: National has buckled under the pressure of keeping the Cyrix division\nalive (unable to produce CPUs with high enough clock rate) and has sold it off\nto VIA. How this affects Cyrix' ability to try to reenter the market, and\nrelease next generation products remains to be seen.\n\n### Cyrix performance documentation links\n\n  * 6x86MX Processor Data Book\n  * Software Customization for the 6x86TM Family, Rev 1.5\n  * Cyrix's ISV page\n\nCommon Features  \n---  \n  \nThe P-II and K6 processors require in-order retirement (for the Cyrix,\nretirement has no meaning; it uses 4 levels of speculation to retain order.)\nThis can be reasoned out simply because of x86 architectural constraints.\nSpecifically, in-order execution is required to do proper resource contention.\n\nWithin the scheduler the order of the instructions are maintained. When a\nmicro-op is ready to retire it becomes marked as such. The retire unit then\nwaits for micro-op blocks that correspond to x86 instructions to become\nentirely ready for retirement and removes them from the scheduler\nsimultaneously. (In fact, the K6 retains blocks corresponding to all the\nRISC86 ops scheduled per clock so that one or two x86 instructions might\nretire per clock. The Intel documentation is not as clear about its retirement\nstrategies.) As instructions are retired the non-speculative CS:EIP is\nupdated.\n\nThe speculation aspect is the fact that the branch target of a branch\nprediction is simply fed to the prefetch immediately before the branch is\nresolved. A \"branch verify\" instruction is then queued up in place of the\nbranch instruction and if the verify instruction checks out then it is simply\nretired (with no outputs except possibly to MSRs) like any ordinary\ninstruction, otherwise a branch misprediction exception occurs.\n\nWhenever an exception occurs (including branch mispredicts, page fault, divide\nby zero, non-maskable interrupt, etc) the currently pending instructions have\nto be \"undone\" in a sense before the processor can handle the exception\nsituation. One way to do this is to simply rename all the registers with the\nolder values up until the last retirement which might be available in the\ncurrent physical register file, then send the processor into a kind of \"single\nstep\" mode.\n\nAccording to Agner Fog, the P-II retains fixed architectural registers which\nare not renamable and only updated upon retiring. This would provide a\nconvenient \"undo\" state. This also jells with the documentation which\nindicates that the PII can only read at most two architectural registers per\nclock. The K6, however, does not appear to be similarly stymied, however it\ntoo has fixed architectural registers as well.\n\nThe out of orderedness is limited to execution and register write-back. The\nbenefits of this are mostly in mixing multiple instruction micro-op types so\nthat they can execute in parallel. It is also useful for mixing multi-clock,\nor otherwise high-latency instructions with low-clock instructions. In the\nabsence of these opportunities there are few advantages over previous\ngeneration CPU technologies that aren't taken care of by compilers or hand\nscheduling.\n\nContrary to what has been written about these processors, however, hand tuning\nof code is not unnecessary. In particular, the Intel processors still handle\ncarry flag based computation very well, even though compilers do not; the K6\nhas load latencies, all of these processors still have alignment issues and\nthe K6 and 6x86MX prefer the LOOP instruction which compilers do not generate.\nXCHG is also still the fastest way to swap two integer registers on all these\nprocessors, but compilers continue to avoid that instruction. Many of the\nexceptions (partial register stall, vector decoding, etc.) are also unknown to\nmost modern compilers.\n\nIn the past, penalties for cache misses, instruction misalignment and other\nhidden side-effects were sort of ignored. This is because on older\narchitectures, they hurt you no matter what, with no opportunity for\ninstruction overlap, so the rule of avoiding them as much as possible was more\nimportant than knowing the precise penalty. With these architectures its\nimportant to know how much code can be parallelized with these cache misses.\nIssues such as PCI bus, chip set and memory performance will have to be more\nclosely watched by programmers.\n\nThe K6's documentation was the clearest about its cache design, and indeed it\ndoes appear to have a lot of good features. Their predecode bits are used in a\nvery logical manner (which appears to buy the same thing that the Cyrix's\ninstruction buffer buys them) and they have stuck with the simple to implement\n2-way set associativity. A per-cache line status is kept, allowing independent\naccess to separate lines.\n\nFinal words  \n---  \n  \nWith out of order execution, all these processors appear to promise the\nprogrammer freedom from complicated scheduling and optimization rules of\nprevious generation CPUs. Just write your code in whatever manner pleases you\nand the CPU will take care of making sure it all executes optimally for you.\nAnd depending on who you believe, you can easily be lead to think this.\n\nWhile these architectures are impressive, I don't believe that programmers can\ntake such a relaxed attitude. There are still simple rules of coding that you\nhave to watch out for (partial register stalls, 32 bit coding, for example)\nand there are other hardware limitations (at most 4 levels of speculation, a 4\ndeep FPU FIFO etc.) that still will require care on the part of the programmer\nin search of the highest levels of performance. I also hope that the argument\nthat what these processors are doing is too complicated for programmers to\nmodel dies down as these processors are better understood.\n\nSome programmers may mistakenly believe that the K6 and 6x86MX processors will\nfade away due to market dominance by Intel. I really don't think this is the\ncase, as my sources tell me that AMD and Cyrix are selling every CPU they\nmake, as fast as they can make them. The demand is definately there. 3Q97 PC\npurchases indicated an unusually strong sales for PCs at $1000 or less\n(dominated by Compaq machines powered by the Cyrix CPU), making up about 40%\nof the market.\n\nThe astute reader may notice that there are numerous features that I did not\ndiscuss at all. While its possible that it is an oversight, I have also\nintentionally left out discussion of features that are common to all these\nprocessors (data forwarding, register renaming, call-return prediction stacks,\nand out of order execution for example.) If you are pretty sure I am missing\nsomething that should be told, don't hesitate to send me feedback.\n\nUpdate: Centaur, a subsidiary of IDT, has introduced a CPU called the WinChip\nC6. A brief reading of the documentation on their web site indicates that its\nbasically a single pipe 486 with a 64K split cache dual MMX units, some 3D\ninstruction extensions and generally more RISCified instructions. From a\nperformance point of view their angle seems to be that the simplicity of the\nCPU will allow quick ramp up in clock rate. Their chip has been introduced at\n225 and 240 MHz initially (available in Nov 97) with an intended ramp up to\n266 and 300 Mhz by the second half of 1998. They are also targeting low power\nconsumption, and small die size with an obvious eye towards the laptop market.\n\nUnfortunately, even in the test chosen by them (WinStone; which is limited by\nmemory, graphics and hard disk speed as much as CPU), they appear to score\nonly marginally better than the now obsolete Pentium with MMX, and worse than\nall other CPUs at the same clock rate. These guys will have to pick their\nmarkets carefully and rely on good process technology to deliver the clock\nrates they are planning for.\n\nUpdate: They have since announced the WinChip 2 which is superscalar and they\nexpect to have far superior performance. (They claim that they will be able to\nclock them between 400 and 600 Mhz) We shall see; and we shall see if they\nexplain their architecture to a greater depth.\n\nUpdate: 05/29/98 RISE (a startup Technology Company), has announced that they\ntoo will introduce an x86 CPU, however are keeping a tight lid on their\narchitecture.\n\nGlossary of terms  \n---  \n  \n  * Branch prediction - a mechanism by which the processor guesses the results of a condition decision and thus assumes whether or not a conditional branch is taken.\n  * Data forwarding - the process of copying the contents of a unit output value to an input value for another unit in the same clock.\n  * (Instruction) coloring - a technique for marking speculatively executed instructions to put them into equivalence classes of speculative resolution. The idea is that once a speculative condition has been resolved the corresponding instructions of that color are all deal with in the same way as being either retired or undone.\n  * (Instruction) issue - the first stage of a CPU pipeline where the instruction is first recognized and decoded.\n  * Latency - the total number of clocks required to completely execute an instruction. In maximal resource contention situations, this is usually the maximum number of clocks an instruction can take. (Often manufacturers will abuse the precise definition in their documentation by ignoring clocks that are assumed to (almost) always overlap. For example, most instruction on all fully pipelined processors really take at least 5 clocks from issue to retirement, however under normal circumstances most of those clocks are consistently overlapped by stages of other instructions, and hence are documented to take that many fewer clocks.) The goal of the Post-RISC architecture is to hide latencies to the maximal degree possible via parallelism.\n  * Out of order execution - a feature of the Post-RISC architecture whereby instructions may actual complete their calculation steps in an order different from that in which they were issued in the original program.\n  * Post-RISC architecture - a term coined by Charles Severance referring to the modern trend of CPUs to use techniques not found on traditional RISC processors such as speculative execution and register renaming in conjunction with instruction retirement.\n  * Register contention - a condition where an instruction is trying to use a register whose last write back or read has not yet completed.\n  * Register renaming - retargetting the output of an instruction to an arbitrary internal register that is virtually renamed to be the value of the architectural register. In x86 processors this ordinarily occurs whenever a fld or fxch instruction or a mov with a destination register is encountered.\n  * Resource contention - A condition where a register, alu or pipeline stage is required for an instruction but is currently in use, or scheduled to be used, by a previously unretired instruction.\n  * Retirement - The process by which the CPU knows that an instruction has really completed.\n  * SIMD - Single Instruction Multiple Data. An instruction set which replicates the same operation over multiple operands which are themselves packed into wide registers. MMX (multimedia extensions), 3DNow! (3D no waiting) and SSE (streaming simd extensions) are examples of SIMD instruction sets.\n  * Speculative execution - a processor state in which execution proceeds even if it is not yet known whether such an execution path will actually be taken. Usually occurs after a branch instruction is issued but before it is resolved.\n  * Throughput - the minimal number of clocks that an instruction needs during the flow of a program. In ideal situations this is just the time it takes to issue the instruction, assuming there are no resource contentions with other subsequent or previous instructions.\n\nLinks  \n---  \n  \nJC's PC News'n'Links Ace's Hardware The seventh generation of CPUs\n\nThis page hosted by Pair.com Updated 07/10/99 Copyright \u00a9 1997, 1998, 1999\nPaul Hsieh All Rights Reserved.\n\n", "frontpage": false}
