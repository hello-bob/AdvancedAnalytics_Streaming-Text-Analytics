{"aid": "40188186", "title": "Governments use facial recognition for protest surveillance", "url": "https://restofworld.org/2024/facial-recognition-government-protest-surveillance/", "domain": "restofworld.org", "votes": 2, "user": "Anon84", "posted_at": "2024-04-28 12:44:29", "comments": 0, "source_title": "How governments are using facial recognition to crack down on protesters", "source_text": "How governments use facial recognition for protest surveillance - Rest of\nWorld\n\nSkip to content\n\nReporting Global Tech Stories\n\nGlobalPoliticsThe changing face of protest\n\nOur Impact\n\n##### Features\n\n# The changing face of protest\n\n### Mass protests used to offer a degree of safety in numbers. Facial\nrecognition technology changes the equation.\n\n  * Intro: An end to privacy\n  * Russia: The rise of pre-crime\n  * India: Targeting minorities\n  * Iran: Phantom technology\n  * End: Policing emotion\n\nFrom the Arab Spring to the Umbrella Revolution, mass protests have shaken\ngovernments around the world.\n\nFrom the Arab Spring to the Umbrella Revolution, mass protests have shaken\ngovernments around the world.\n\nBut over the past decade, facial recognition technology has increased the\nrisks around expressing dissent.\n\nBut over the past decade, facial recognition technology has increased the\nrisks around expressing dissent.\n\nDemonstrators can be picked out of a crowd, arrested, or even preemptively\ndetained.\n\nDemonstrators can be picked out of a crowd, arrested, or even preemptively\ndetained.\n\nIllustrations by Matt Huynh for Rest of World\n\nBy Darren Loucaides\n\n27 March 2024\n\nEspa\u00f1olPortugu\u00eas\u4e2d\u6587 (\u7b80\u4f53\u5b57)DeutschFran\u00e7ais\n\n  * Intro: An end to privacy\n  * Russia: The rise of pre-crime\n  * India: Targeting minorities\n  * Iran: Phantom technology\n  * End: Policing emotion\n\n## Facial Recognition\n\n  * Intro: An end to privacy\n  * Russia: The rise of pre-crime\n  * India: Targeting minorities\n  * Iran: Phantom technology\n  * End: Policing emotion\n\n##### Intro\n\n## An end to privacy\n\nOn March 13, 2022, 34-year-old English teacher Yulia Zhivtsova left her Moscow\napartment to meet her friends at the mall. Bundled up against the freezing\ncold, she entered the metro at the CSKA station on the Bolshaya Koltsevaya\nline, passing through station barriers that let travelers pay by scanning\ntheir faces.\n\nBut when she went down to the platform, two police officers plucked her out of\nthe crowd.\n\n\u201cHey!\u201d said one, and then addressed her by her full name, including the\nRussian patronymic. \u201cYulia Maksimovna. Come with us.\u201d\n\nThe officers looked back and forth between Zhivtsova and an image on their\nsmartphones. They seemed unsure if they had the right person. Catching a\nglimpse of the screen, Zhivtsova recognized a photo of herself taken the month\nbefore, when she was detained for protesting Russia\u2019s war in Ukraine. Her hair\nlooked different: In the photo it was faded blue, but that day it was back to\na gleaming teal. \u201cI do tend to change my hair color a lot,\u201d Zhivtsova told\nRest of World.\n\nAfter a while, the officers decided to trust the image on their smartphones.\nAnother anti-war demonstration was taking place in Moscow that day, and even\nthough Zhivtsova didn\u2019t plan to attend, they detained her preventively,\nholding her for a few hours.\n\n### The changing face of protest\n\nMass protests used to offer a degree of safety in numbers. Facial recognition\ntechnology changes the equation.\n\nThis story explores how thanks to new facial recognition technology,\nprotesters\u2019 safety in numbers is becoming a thing of the past. We take a look\nat three case studies \u2014 in Russia, India, and Iran \u2014 to show the proliferation\nof facial recognition as a tool to control and curtail protest.\n\nWritten by Darren Loucaides. Narrated by Jane Seidel.\n\nOriginal story: https://restofworld.org/2024/facial-recognition-government-\nprotest-surveillance/\n\n0:00/33:10\n\nLong Reads by\n\nExplore more episodes >>\n\nOver the past decade, there has been a steep rise globally in law enforcement\nusing facial recognition technology. Data gathered by Steven Feldstein, a\nresearcher with the Carnegie Endowment for International Peace, found that\ngovernment agencies in 78 countries now use public facial recognition systems.\n\nThe public is often supportive of the use of such tech: 59% of U.K. adults\ntold a survey they \u201csomewhat\u201d or \u201cstrongly\u201d support police use of facial\nrecognition technology in public spaces, and a Pew Research study found 46% of\nU.S. adults said they thought it was a good idea for society. In China, one\nstudy found that 51% of respondents approved of facial recognition tech in the\npublic sphere, while in India, 69% of people said in a 2023 report that they\nsupported its use by the police.\n\nBut while authorities generally pitch facial recognition as a tool to capture\nterrorists or wanted murderers, the technology has also emerged as a critical\ninstrument in a very particular context: punishing protesters.\n\nThe last 20 years have shown that mass demonstrations can have real impacts.\nStarting in 2010, a wave of protests across the Middle East and North Africa,\nknown as the Arab Spring, toppled regimes in Tunisia, Libya, Egypt, and Yemen,\nand spurred revolts in many other countries. In 2014, protesters in Hong Kong\ntook to the streets for universal suffrage, sometimes called the Umbrella\nRevolution owing to protesters\u2019 use of umbrellas to shield against pepper\nspray. While authorities did not make any concessions at the time, the\nprotests drew global attention, and when Hong Kongers took to the streets with\nnew demands in 2019, the government withdrew a controversial bill that would\nhave allowed suspects to be extradited to mainland China. In 2020, the\n#EndSARS movement against police brutality in Nigeria resulted in the\ndisbanding of the Special Anti-Robbery Squad, the police force at the center\nof the controversy, while mass protests in Chile led to a cabinet reshuffle\nand a referendum to rewrite the country\u2019s constitution. So far, 2024 has been\nmarked by several large-scale protest events, including farmers\u2019 protests in\nIndia and Europe, and protests in many countries against the war in Gaza.\n\nIn countries where demonstrating can come with physical or political risk,\nlarge-scale protests have historically offered a degree of anonymity, and,\nwith it, a level of protection. Mass protests are a way for citizens to\nexpress dissent as a collective \u2014 often under the assumption that \u201cthey can\u2019t\narrest us all.\u201d\n\nBut in the last decade, the spread of facial recognition technology has\nchanged that equation: A lone face in a crowd is no longer anonymous; facial\nrecognition allows authorities to capture people\u2019s identities en masse.\n\nIt\u2019s no coincidence that the widespread adoption of the technology has evolved\nin parallel with increasingly draconian laws against protest. As part of its\n\u201cProtect the Protest\u201d project, Amnesty International tracks repressive\nlegislation that imposes illegitimate restrictions on protests, with examples\nacross five regions. Facial recognition tech helps enable this repression by\noffering a way to enforce such regulation on a sweeping scale.\n\nIn the U.S., law enforcement used facial recognition at Black Lives Matter\nprotests in 2020, resulting in at least one activist being targeted at their\nhome. In the U.K., the London Metropolitan Police admitted to using facial\nrecognition technology on tens of thousands of people attending King Charles\nIII\u2019s coronation in May 2023.\n\nOften, facial recognition is used to disproportionately target people\nbelonging to a racial, ethnic, or religious minority. \u201cAgain and again we see\nthat it\u2019s people who are already targeted by police or subject to severe\nmovement restrictions, or have already been subject within their communities\nto police brutality, that are most targeted by these tools,\u201d Matt Mahmoudi, a\nresearcher at Amnesty International who specializes in facial recognition,\ntold Rest of World.\n\nMass demonstrations have become opportunities for authorities to net thousands\nof faces via CCTV, van-mounted cameras, and police mobile devices, which can\nthen be added to facial recognition databases. In the past month, Indian\nauthorities used the technology to identify people who participated in\nfarmers\u2019 protests, threatening to cancel their passports. A Russian civil\nsociety group believes Moscow police used the technology to track down people\nwho attended opposition leader Alexei Navalny\u2019s funeral.\n\nLaw enforcement walk past crowds gathered for the funeral service of Alexei\nNavalny in Moscow, Russia, on March 1, 2024. Alexander Nemenov/AFP/Getty\nImages\n\nThe result is a fundamental shift in the power balance between authorities and\nthe general public that is changing the nature of protest. The most obvious\noutcome is a chilling effect: Facial recognition technology puts demonstrators\nat greater risk of persecution, often stymieing efforts to protest before they\neven occur.\n\nMeanwhile, those still brave enough to take to the streets are finding ways to\ntry to mitigate the threat. Protests in Chile and Argentina saw people donning\nface masks and balaclavas. Activists in London have painted their faces with\nso-called dazzle makeup, developed by artist Adam Harvey and designed to\nconfuse algorithms (although experts warn that this may not be effective\nagainst newer facial recognition systems). In Hong Kong, during the pro-\ndemocracy protests that started in 2019, demonstrators again employed\numbrellas, which helped conceal their faces from police surveillance, fired\nlasers to blind cameras, and felled surveillance towers. In mainland China,\nprotesters demonstrated against the government in November 2022 by holding\nblank pieces of paper in the air and in front of their masked faces.\n\nAuthorities are often secretive about their use of facial recognition at\nprotests. Often, the people arrested are not told whether the technology has\nplayed a role in their detention, even if they suspect it. Over six months,\nRest of World spoke to researchers, activists, and people targeted by facial\nrecognition systems around the world to track how this technology is upending\nprotest as we know it. We found evidence of facial recognition tools being\nused at major protests worldwide, often in a way that clashes with civil\nliberties. The context may vary by location, but the overall outcome is\nshared: Facial recognition technology is making the act of protest riskier\nthan ever, putting demonstrators at greater risk of persecution, exacerbating\nthe targeting of minority groups, and changing the way people express dissent.\n\nCombined with a rise in authoritarianism in many countries, some activists and\ncivil groups even fear that the increased use of facial recognition could mean\nan end to protest as we know it. \u201cI don\u2019t see [almost] any protest anywhere,\u201d\nShivangi Narayan, a sociologist in India who studies digital policing, told\nRest of World. \u201cEven a person like me who\u2019s working on government surveillance\nand policing \u2014 I\u2019m wary of who I\u2019m talking to.\u201d\n\nNow, if she knows there will be CCTV surveillance at a particular location,\nNarayan avoids the area, or covers her face.\n\n##### Russia\n\n## The rise of pre-crime\n\nSix months after being detained at CSKA station, Yulia Zhivtsova was back on\nthe Moscow Metro. It was September 30, 2022, and the government was holding a\nconcert rally next to the red-brick walls surrounding the Kremlin to celebrate\nthe \u201cnew territories\u201d annexed from Ukraine. Zhivtsova hadn\u2019t attended protests\nsince her last detention; she was heading home from a dance class.\n\nBut when she entered the metro at Tverskaya station, two officers stopped her.\nAgain, they took a while to compare the image on their screens with the woman\nin front of them \u2014 who now had shorter hair \u2014 before taking her in.\n\nZhivtsova expected to be detained for a couple of hours and let go like last\ntime. But at the police station, officers noticed a tattoo on her hand. After\nher previous detention, she\u2019d gotten the words \u201cNo to war\u201d inked. The officers\ncharged Zhivtsova with \u201cdiscrediting the military\u201d under draconian new\nlegislation that carries a possible five-year prison sentence.\n\nYulia Zhivtsova was charged with \u201cdiscrediting the military\u201d for a tattoo on\nher hand that reads \u201cNo to war.\u201d Yulia Zhivtsova\n\nIn August 2023, she was convicted and fined 50,000 rubles ($540). Shortly\nafter, she left Russia, fearful that she would be sent to prison if she were\ncaught with the tattoo again. Zhivtsova now lives in Montenegro. \u201cI\u2019m not\ngoing back anytime soon,\u201d she said.\n\nOther anti-war protesters in Russia have similar stories. After the invasion\nof Ukraine, Andrei Markov put up anti-war posters in public spaces. He also\nwrote snippets of anti-war graffiti on the Moscow Metro. One Thursday\nafternoon in July, he boarded a quiet carriage and scrawled the words \u201cno war\u201d\non the corner of a subway map in permanent marker.\n\nThe following Sunday, police knocked at his apartment. \u201cThat was a bad\nsurprise,\u201d he told Rest of World. \u201cI didn\u2019t open the door.\u201d But when he\nentered the metro for his commute on Monday morning, police stopped him.\n\nMarkov asked to be identified by a pseudonym because he currently lives in\nRussia and fears authorities could target him further for speaking out. He\nsaid he spent 40 hours in a 3-square-meter cell between interviews. \u201cIt was a\nvery bad experience. I could not call relatives, lawyers or anybody else, and\nit made me really nervous. They even did not give any drink or food,\u201d Markov\nsaid. Finally, officers told him he was accused of discrediting the military.\nThey showed him a video of him writing the graffiti. They also told him that\nhe had appeared in Sfera, a facial recognition system used in Moscow\u2019s metro.\nHe was released with a fine.\n\nBut the next time Markov went to take the metro, a police officer immediately\nstopped him. Markov explained he\u2019d already been arrested and paid the fine.\nThe officer shrugged. \u201cThis is not my problem,\u201d he said.\n\nMarkov doesn\u2019t take the metro any more, and has changed his apartment and\nphone number. \u201cBut I\u2019m sure they can still find me very easily,\u201d he said. \u201cNot\njust me, but everybody. They\u2019re using modern systems that are really good to\nfind any person.\u201d\n\nRest Of World spoke to five Russians who had attended protests in the past and\nwere later tracked down by law enforcement using facial recognition\ntechnology. OVD-Info, a Russian human rights and media group dedicated to\nfighting political persecution, has documented 595 cases in which facial\nrecognition technology was used against dissenters since 2021. Of those, 141\nwere cases of activists being detained preventively on the metro \u2014 all since\nthe invasion of Ukraine. OVD-Info defines preventive detentions and arrests as\nstopping people who have not been charged with anything, as a way of\npreventing them from attending political protests.\n\nProtesters march in support of Alexei Navalny in Moscow on January 23, 2021.\nKirill Kudryavtsev/AFP/Getty Images\n\nBut while many detainees report police officers verbally stating that they\nhave been caught by facial recognition technology, or even showing them the\nSfera system on their devices, the tech rarely appears in court documents.\n\n\u201cThe authorities are still hiding the facts,\u201d Stanislav Seleznev, a lawyer\nworking for Net Freedoms Project, which defends Russian digital rights, told\nRest of World.\n\nRussia\u2019s use of facial recognition has coincided with a general clampdown on\nprotest following mass demonstrations in December 2011 around elections to the\nState Duma, the lower house of Russia\u2019s parliament. The next year, authorities\ninstalled 60,000 new cameras in Moscow alone. In subsequent years, several\nRussian companies emerged offering facial recognition tech to the authorities.\n\nIn 2017, the Moscow Department of Information Technologies announced that\n3,000 of the city\u2019s now 160,000 cameras were being connected to a facial\nrecognition system by software company NtechLab. Authorities also started to\nregularly deploy the tech at protests, rallies, and private events. In 2018,\nit was connected to the Moscow Metro; in 2019, the Ministry of Internal\nAffairs claimed it had identified 90 wanted persons using the tech. NtechLab\ndid not respond to a request for comment from Rest of World.\n\nThe full potential of facial recognition technology as a tool against protest\nbecame clear in April 2021 at a march in support of Navalny. The opposition\nleader had just returned to Russia after being treated in Germany for\npoisoning, and had been imprisoned. Few people were detained at the protest,\nbut OVD-Info\u2019s lawyers soon realized that facial recognition had been deployed\nat the event when police started showing up at the homes and workplaces of\nmany attendees.\n\nA. A., who asked to be identified only by his initials out of fear of\nreceiving more unwanted attention from the authorities, attended a protest in\nsupport of Navalny in January 2021. A week after the march, he opened his door\nto the police, who showed surveillance photos of him at the protest and warned\nhim against attending \u201cunauthorized events.\u201d He was arrested and spent the\nbetter part of a weekend in detention. Eventually, he went to court and\nreceived a fine.\n\nThanks in part to its existing database of dissenters, the Kremlin was in an\neven stronger position to clamp down on protests following Russia\u2019s invasion\nof Ukraine. According to OVD-Info\u2019s data, protests against the invasion peaked\nin 2022, when there were more than 20,000 political arrests; in 2023, protests\ndwindled, though close to 800 people across the country faced criminal charges\nfor \u201canti-war\u201d views. While Moscow is the clear leader in use of facial\nrecognition technology, it\u2019s spreading fast across Russia: Some 62 regions now\nuse the tech today, up from just five in 2021.\n\n> \u201cAfter spring 2022, mass protests practically disappeared.\u201d\n\nSeleznev suggests facial recognition technology, alongside increasingly\nrepressive laws, has had a chilling effect on protest movements. \u201cAfter spring\n2022, mass protests practically disappeared,\u201d he said. According to him, anti-\nwar protests are not mass events any longer, but \u201cindividual in nature\u201d \u2014 like\nZhivtsova\u2019s tattoo and Markov\u2019s graffiti.\n\n\u201cI think many may be frightened by facial recognition, as punishment becomes\nmore and more inevitable,\u201d said A. A. \u201cI think this is one of the main reasons\nwhy protests do not occur in Moscow and, to a lesser extent, in other cities.\u201d\n\nEven those who still wish to protest may struggle to do so because of\npreventive detentions. Maria Nemova, a lawyer at OVD-Info, has encountered\nmany such cases where people were stopped in Moscow\u2019s metro. \u201cPeople were\ndetained not for a specific action, but simply because they were considered\ndangerous,\u201d she told Rest of World.\n\nNemova said she knows of several people who decided to leave Russia after\nbeing preventively detained via facial recognition technology on the metro.\n\u201cThese individuals explained their decision by a sense of vulnerability and\nlack of protection: The state no longer needs a reason, such as participation\nin a protest, to detain you, and it can track you almost anywhere.\u201d\n\n##### India\n\n## Targeting minorities\n\nWhen India\u2019s government passed the Citizenship Amendment Act (CAA) in December\n2019, it triggered some of the biggest protests the country had seen in years.\nThe law, which was proposed by the ruling Bharatiya Janata Party (BJP) and its\nHindu nationalist prime minister, Narendra Modi, streamlined the path to\ncitizenship for migrants from neighboring countries, while excluding Muslims.\nCritics argued that, combined with the National Register of Citizens and its\nstrict requirements for birth and identity documents, the new law could make\nmany Muslims in India effectively stateless.\n\nShivangi Narayan, a 39-year-old sociologist who lives in a New Delhi suburb,\nrecalled noticing many people she wasn\u2019t used to seeing at demonstrations,\nincluding more women, ethnic minorities, and students. The issue had clearly\nstruck a nerve. \u201cThe protests became national. And there were women at the\nforefront,\u201d Narayan told Rest of World. \u201cAnybody who wanted democracy and\nfreedom of speech and expression \u2014 and who wanted a lively diverse culture in\nIndia \u2014 was loving it.\u201d\n\nNarayan, who specializes in researching high-tech solutions to policing, did\nnot fail to notice that law enforcement was using surveillance at the\nprotests: videoing the crowds, approaching demonstrators to ask their names\nand affiliations, and deploying drones. \u201cI think nobody really thought much\nabout it,\u201d she said. \u201cI know a couple of people who were active in protests\nwho were like, so what? Take my picture, it doesn\u2019t really matter.\u201d\n\n\u201cA lot of students we did not know by name or face before that,\u201d Radhika\nGanesh, a prominent political youth organizer, told Rest of World. \u201cThey\u2019re\nnot activists. They\u2019re not people who have an agenda. They\u2019re not people who\nhave a network or the support systems that some of us do. They didn\u2019t think of\nhiring lawyers, or what their paper trail was going to be. These were really\nunassuming young people who found their agency.\u201d\n\nLike Narayan, Ganesh was used to being surveilled. Soon, however, she and\nother veteran activists noticed a shift in who was being targeted and how.\n\u201cYou could be an absolute no-one, just a random student in the middle of the\ncrowd surrounded by a sea of people,\u201d she said. Participants like these were\nbeing picked up before and after protests. Given the omnipresence of\nsurveillance cameras at the protests, and the fact that it would be almost\nimpossible to manually identify so many random individuals lacking any public\nprofile, activists believed facial recognition was in use.\n\nA large protest against the Citizenship Amendment Act in New Delhi, India, on\nDecember 20, 2019. Sanchit Khanna/Hindustan Times/Getty Images\n\nAs the protests rolled on, police began to aggressively target student\nactivists from Jamia Millia Islamia university, which has a strong Muslim\nhistory. \u201cYoung hijabi women were being arrested and picked up,\u201d Ganesh said.\n\u201cAll of a sudden you hear of parents running into the protest sites and\nsaying, \u2018Oh my daughter has been taken away \u2014 I can\u2019t figure out which police\nstation they\u2019ve been taken to.\u2019\u201d\n\nThings got worse when rioting related to the citizenship law broke out in\nnortheast Delhi in February 2020. More than 50 people died in the riots \u2014 the\nmajority of them Muslim. Evidence collected by the Delhi Minorities Commission\nsuggested that the police deliberately stoked violence against Muslims \u2014\nattacking them in at least one case. After the riots, video footage was used\nto arrest hundreds of people. The Delhi police commissioner told local press a\nyear later that 755 people were arrested in connection with the riots across\nDelhi, 231 of whom were traced using CCTV or other video footage. Of these,\n137 were identified using facial recognition.\n\nSurveillance in India began to increase after the BJP came to power in 2014,\nwith cameras increasingly common in cities. But the CAA protests were a\nwatershed. Anushka Jain, formerly of India\u2019s Internet Freedom Foundation,\ndocumented facial recognition via a website called Project Panoptic. Jain told\nRest of World the CAA protests were the first time her organization had heard\nof facial recognition being used against protesters. Since then, the use of\nthe technology has quickly ramped up.\n\nA key concern is the disproportionate use of facial recognition against\nminorities, and particularly Muslims. A study by the Vidhi Centre for Legal\nPolicy, an Indian think tank, found that the tech would almost inevitably\ndisproportionately impact Delhi\u2019s Muslim community \u2014 a consequence of both\npolice prejudice and the over-surveillance of Muslim-populated areas.\n\nThere has been a rise in anti-Muslim sentiment in India, which has been\nreflected in policing. Data from the National Crime Records Bureau shows that\nmore than 30% of those detained in Indian prisons in 2021 were Muslim (Muslims\nform around 14% of the country\u2019s population). A study in 2019 found anti-\nMuslim prejudice was rife among India\u2019s police. In this context, facial\nrecognition can be employed to specifically target Muslims for arrest.\n\n> \u201cA lot of the use of this technology is under wraps.\u201d\n\nThis prejudice can also take a more passive form. In May 2021, during the\nsecond wave of Covid-19 in India, social activist S.Q Masood was heading to\nhis home in Hyderabad. With 83 cameras per 1,000 people, the southern Indian\ncity has the densest CCTV network outside of China, according to the consumer\nresearch site Comparitech. Masood was stopped by a dozen police officers who\nhad set up a picket near a Muslim-dominant area. Two officers, who were\ncarrying tablet-sized phones, asked him to remove his face mask. Given that\nnot wearing a face mask carried a penalty, Masood refused. The police\nphotographed him anyway.\n\nAfterwards, Masood heard that the state police were using facial recognition\ntechnology to compare photographs of people to images in India\u2019s nationwide\nCrime and Criminal Tracking Network and Systems (CCTNS) database.\n\n\u201cI was worried, being a Muslim in the current political scenario where every\nday the minority community is targeted,\u201d Masood told Rest of World. Concerned\nabout his photo potentially being in the authorities\u2019 database, he contacted\nlawyers and activists. With the support of the Internet Freedom Foundation,\nMasood took Telangana state \u2014 of which Hyderabad is the capital \u2014 to court,\nclaiming that the use of facial recognition technology was illegal and\nunconstitutional. \u201cThere is no law in the state and central government that\nempowers law enforcement agencies to use facial recognition,\u201d Masood said.\n\nThe matter is still pending. Masood does not expect the authorities to stop\nusing facial recognition, but hopes to force greater transparency around how\nthey use it.\n\nThe potential for the technology to be weaponized as a tool for targeting\nminorities was again seen in India in 2021 with the widespread farmers\u2019\ndemonstrations, which resulted in a police clampdown that disproportionately\ntargeted the Sikh community \u2014 in part through the use of facial recognition.\n\nAs a result, while facial recognition technology may have a chilling effect on\nprotest generally, this effect is felt particularly keenly by communities that\nare already marginalized.\n\nSrinivas Kodali, an independent digital researcher based in Hyderabad, told\nRest of World that facial recognition is proving a powerful deterrent against\npublic demonstrations. \u201cIt stops you from coming to a protest, because you\nknow the police are going to recognize you,\u201d he said. Protests in Hyderabad\nhave become very rare, Kodali said, in part due to the use of facial\nrecognition alongside other police tactics. \u201cPolice arrest people before they\neven come to the protest site,\u201d he said.\n\n##### Iran\n\n## Phantom technology\n\nOn a mild spring evening in 2023, Maryam, who is in her late 30s, was sitting\nin the courtyard of a Tehran coffee shop. Maryam \u2014 who asked to use a\npseudonym to protect her safety while living in Iran \u2014 was not wearing a\nhijab, although it is required by the country\u2019s law. Since the protests that\nfollowed the death of 22-year-old Mahsa Amini in September 2022, who died in\npolice custody after being arrested for not wearing a \u201cproper\u201d hijab, Maryam\nsometimes kept her hair uncovered in public \u2014 an act of personal defiance. \u201cI\nprefer to show in public that we want to have the right to choose,\u201d she told\nRest of World in an interview in November 2023.\n\nSeveral months after her coffee outing, Maryam was summoned to court for\nfailing to wear a hijab. She planned to say that they had the wrong person,\nbut then she was shown a photo of herself at the cafe. \u201cI was shocked and\ncouldn\u2019t say that [it wasn\u2019t me],\u201d Maryam said.\n\nThere were several other women in court with Maryam that day for clothing-\nrelated charges. Maryam watched them being questioned by the judge and signing\ndocuments about how to behave. One woman complained the photographer had acted\n\u201cunjustly\u201d because her headscarf had only fallen for a moment. \u201cThe\nphotographers are paid for this job and they are just doing their job,\u201d Maryam\nrecalled the judge responding. \u201cIt is not unjust.\u201d\n\n> \u201cThere was no other way to recognize me.\u201d\n\nMaryam stayed quiet. The judge gave her a document that stated she, too, had\nunintentionally let her headscarf fall \u2014 even though she knew full well that\nshe had not been wearing the hijab at all. She signed the confession anyway,\nand received a fine.\n\nMaryam doesn\u2019t know how her picture was taken \u2014 she didn\u2019t see anyone taking\nphotographs at the cafe \u2014 but she firmly believes she was identified through\nfacial recognition. \u201cThere was no other way to recognize me,\u201d she said.\n\nA few weeks before the anti-hijab protests following Amini\u2019s death, the\nIranian government had announced that it was planning to use facial\nrecognition to identify women not wearing the hijab on public transport. This\ncame shortly after a new decree signed by the hard-line president, Ebrahim\nRaisi, restricting women\u2019s clothing, after women posted videos of themselves\non social media with their heads uncovered. The secretary of Iran\u2019s\nHeadquarters for Promoting Virtue and Preventing Vice, Mohammad Saleh Hashemi\nGolpayegani, said that images would be compared with the national database for\ncitizens\u2019 ID cards.\n\nIn the wake of the protests, authorities reiterated that facial recognition\nwould be used to identify offenders. \u201cPeople who remove their hijab in public\nplaces will be warned first and presented to the courts as a next step,\u201d said\nIran\u2019s police chief in an interview on state television last April. A police\nstatement said the authorities would \u201ctake action to identify norm-breaking\npeople by using tools and smart cameras in public places and thoroughfares.\u201d\nIn June 2023, a video released by a news agency linked with the Islamic\nRevolutionary Guard Corps showed supposed facial recognition technology being\nused.\n\nProtesters against the killing of Mahsa Amini in Bukan, Iran, on September 16,\n2022. MEI/Redux\n\nIt remains unclear to what extent the Iranian authorities are actually using\nfacial recognition technology. The government could be exaggerating its\ncapabilities in order to induce fear, Azin Mohajerin, deputy director at human\nrights organization Miaan Group, told Rest of World. Mohajerin has separately\nworked with a group of volunteers to document detainees from last year\u2019s\nprotests.\n\nMohajerin and her fellow volunteers found cases where people were arrested at\nhome after a protest. But there are several ways to identify individuals in a\ncrowd: Authorities often post pictures of suspects on websites and Telegram\nchannels, and invite members of the public to report their neighbors. In\nrecent years, the authorities have also launched an app called Nazer that\nencourages the public to report individuals who are not properly clothed.\n\u201cThey were using various techniques to identify the protestors,\u201d said\nMohajerin. Facial recognition could be among these methods, \u201cbut we couldn\u2019t\nhave any proof of that,\u201d she said.\n\nA research project by the Miaan Group, called Filterwatch, analyzed a trove of\nhacked prosecutorial emails. It found that two Iranian companies working on\nfacial recognition for commercial purposes had been collaborating with the\nauthorities since 2015. Iran is also known to have acquired smart cameras from\nChinese firm Tiandy Technologies.\n\nThere were also recent reports from the city of Mashhad about commuters\nentering the metro and passing in front of CCTV cameras, after which their\nphotos, names, and genders \u2014 seemingly taken from the national ID database \u2014\nappeared on a screen, suggesting facial recognition was being implemented.\nAfter backlash over the violation of citizens\u2019 right to privacy, the\nauthorities confirmed the tech\u2019s use. A spokesperson for the city council said\nit would only be used to catch \u201cenemies of the regime.\u201d\n\nFor now, activists cannot tell the extent to which Iranian law enforcement is\nactually using facial recognition, and how much it is invoking the idea of the\ntechnology to scare people into not attending protests or participating in\nother forms of dissent.\n\n\u201cCurrently it seems the authorities are leveraging the use of these\ntechnologies more as a tool for intimidation,\u201d Azam Jangravi, a researcher at\nCitizen Lab, told Rest of World. \u201cBased on my analysis, they have not achieved\nthe capability to conduct facial recognition on a widespread scale.\u201d\n\nTo some degree, the result is the same. In the context of the strict hijab\nlaw, just the threat of an all-seeing eye could be all the government needs,\neven if the system isn\u2019t very advanced or widespread. \u201cIt doesn\u2019t necessarily\nneed to be in place in order to disincentivize women to come out and protest,\u201d\nsaid Amnesty International\u2019s Mahmoudi. \u201cUltimately, the fear that it generates\nis the same.\u201d\n\nMaryam has continued with her personal protest of not wearing the hijab,\nthough she is on high alert for anyone around her who might be trying to\nphotograph her. She does not feel aggrieved for being summoned to court. \u201cIt\nis somehow like we pay for our freedom,\u201d she said. \u201cI was satisfied with a\nfine.\u201d\n\nShe is concerned, however, about what might result from a repeat offense if\nshe is caught again. \u201cWhat is the fine for the next time? Is it the same or\nwill something worse happen?\u201d she said.\n\n##### End\n\n## Policing emotion\n\nAs the adoption of facial recognition at protests spreads, digital rights\ngroups are mobilizing to try to force legislation to protect civil liberties\nfrom the technology. But Access Now\u2019s Daniel Leufer worries that, as the\nworld\u2019s de facto leading regulator on tech, the EU has set a very low bar. Its\nrecent legislation on the use of artificial intelligence and facial\nrecognition has \u201cproblematic loopholes and exceptions,\u201d Leufer told Rest of\nWorld.\n\nFacial recognition systems are also outpacing any legislative efforts. Leufer\npoints to emerging technology that claims to offer emotion detection, which he\nsaid could be adapted for use against protestors. EU funds have supported\nresearch into surveillance tech that can predict the level of potential\nviolence at large public events. NtechLab is developing features including\naggression and violence detection, according to reports.\n\n\u201cIf a crowd goes above an aggressivity threshold, then the system could alert\nthe authorities,\u201d Leufer said. Experts question the technology\u2019s accuracy in\npredicting human emotion based on facial expressions. Baked-in biases play a\npart here, too: One study, using 400 images of NBA players, showed how two\nfacial recognition systems consistently rated Black players as more \u201cangry\u201d\nthan white players.\n\n\u201cBut also, more fundamentally \u2014 is anger at protests not acceptable?\u201d Leufer\nsaid. \u201cThe criminalization of emotions is going down a very dark road.\u201d\n\nEnjoyed this story? Support our award-winning journalism by making a donation.\n\nDarren Loucaides is a writer from the U.K. based in Barcelona.\n\nIllustrations in this article are representative of scenes and not the\nindividuals described.\n\nContributing reporting: Rakshitha Narasimhan\n\nDesign: Joanne Lee\n\nDevelopment: Anna Rasshivkina\n\nStory editing: Victoria Turk\n\nArt direction: Cengiz Yar\n\nData Visualization: Connor Rothschild/Moksha Data Studio\n\nRead more stories\n\nEV Revolution\n\nSingapore\u2019s EV challenge: High prices and high-rises\n\nThe country\u2019s new EV push is clashing with long-standing policies to\ndiscourage car ownership in general.\n\nBy Nicholas Yong\n\n3 Minutes With\n\nWhat it takes to raise a $300 million VC fund for Africa\n\nTidjane Deme talks about convincing investors to back Africa-focused tech\nfunds amid a global funding slump.\n\nBy David I. Adeleke\n\nLabor\n\nWhy IBM employees in Brazil are suing to be classified as tech workers\n\nUnions in two Brazilian states are suing IBM in an effort to be recognized as\ntech employees, giving them access to better wages, benefits, and profit\nparticipation.\n\nBy La\u00eds Martins\n\n  * About us\n  * Jobs\n  * Privacy Policy\n  * Platforms\n  * Newsletters\n  * Donate\n  * Contact us\n\n\u00a9 2024 Rest of World\n\n", "frontpage": false}
