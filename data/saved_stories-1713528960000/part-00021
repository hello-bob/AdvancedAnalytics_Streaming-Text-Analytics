{"aid": "40083139", "title": "Uncovering Reasons Behind a Mysterious Performance Regression (In LuaJIT)", "url": "https://konghq.com/blog/engineering/mysterious-performance-regression", "domain": "konghq.com", "votes": 3, "user": "dndx", "posted_at": "2024-04-19 03:18:27", "comments": 0, "source_title": "Down the Rabbit Hole: Uncovering the Reasons Behind a Mysterious Performance Regression", "source_text": "Down the Rabbit Hole: Uncovering the Reasons Behind a Mysterious Performance Regression | Kong Inc.\n\nAnnouncing the GA of Kong Konnect Dedicated Cloud Gateways\n\nLearn More\n\nBlog\n\n  * Engineering\n  * Enterprise\n  * Kong News\n  * Product Releases\n\n  *     * API Gateway\n    * Service Mesh\n    * Insomnia\n    * Kubernetes\n    * API Security\n    * Tutorial\n\n  * Home\n  * Blog\n  * Engineering\n  * Down the Rabbit Hole: Uncovering the Reasons Behind a Mysterious Performance Regression\n\nEngineering\n\nApril 15, 2024\n\n8 min read\n\n# Down the Rabbit Hole: Uncovering the Reasons Behind a Mysterious Performance\nRegression\n\nQiqi Zhang\n\n### How does Kong Engineering approach Gateway performance benchmarks?\n\nAt Kong, we take the robustness and performance of our gateway product\nseriously, dedicating ourselves to maintaining high standards through a robust\ninternal benchmark framework and infrastructure. Our setup includes a\ndedicated bare metal cluster for running performance tests, seamlessly\nintegrated into our CI/CD process. Moreover, we conduct extensive performance\ntesting for each major, minor, and patch release candidate. While this\nthorough approach aims to prevent significant performance regressions, we\nremain agile, ready to address and optimize potential regressions in\nperformance as they arise in upcoming releases.\n\nBelow is a simplified overview of our benchmarking infrastructure:\n\nLet's use the nightly benchmark as a case study to illustrate a segment of our\nbenchmarking workflow.\n\nA scheduled cron job activates the nightly test suites and initiates the bare\nmetal cluster. For each suite, we obtain a small sample size nightly and\ncompare it against a larger sample size from the latest release. Statistical\nhypothesis testing is then applied to these results to identify potential\nperformance regression.\n\n## Performance regression before the release\n\nIn a recent release cycle, we detected a regression of approximately 10% in\nRequests Per Second (RPS) within the development branch. Initial quick\nbenchmarks confirmed this regression. Furthermore, the performance regression\ncan be reproduced even under the simplest configuration which suggests it is\ncaused by changes in fundamental performance characteristics to our core proxy\npath.\n\nSubsequently, we executed a series of rapid benchmarks, employing binary\nsearch on a range of commits to identify the problematic one. This led us to\npinpoint the slow commit, which involved refactoring the algorithm for\ngenerating cache keys in the router.\n\n## How does the Kong Gateway router work?\n\nThe router, a central component of the Kong Gateway, is configured by\ncustomers using a specific format. This configuration directs how the Kong\nGateway matches each incoming request with pre-established routes, services,\nand plugins. Starting with Kong Gateway 3.0, we've redesigned a clean sheet\nimplementation of our router in Rust, achieving greater CPU and memory\nefficiency as well as enhanced flexibility. More descriptions of how our new\nrouter works can be found inside our router documentation.\n\n## Why refactor the cache key algorithm?\n\nRouter matching represents one of the most resource-intensive operations\nwithin our core proxy path. To mitigate the computational costs associated\nwith evaluating thousands of routes each time when a request comes in, we've\nimplemented a caching mechanism. This allows us, in certain cases, to bypass\nthe router-matching process entirely.\n\n    \n    \n    local cache_key = (req_method or \"\") .. \"|\" .. (req_uri or \"\") .. \"|\" .. (req_host or \"\") .. \"|\" .. (sni or \"\") .. \"|\" .. (headers_key or \"\") .. \"|\" .. (queries_key or \"\")\n\nThe previous algorithm consolidated all conditions into a single cache key.\nWhile accurate, this approach is not as efficient as it could be as not all\ncustomers utilize every condition simultaneously. Suppose the operator only\nconfigured routes that match against the incoming request path, the above\ncaching algorithm will not be able to utilize cached results for requests that\nhave the same path but different header values.\n\nSo in the 3.6 development cycle, we decided to refactor the algorithm to make\nit more efficient utilizing the knowledge of used fields from our new router,\nnow it only uses the configured conditions to generate the cache key.\n\nFor instance, consider two routes configured by customers using the following\nexpression:\n\n    \n    \n    http.path == /example && http.headers.x_foo == \"foo\"\n    \n    \n    http.host == \u201cexample.com\u201d\n\nThe resulting cache key would appear as follows (where the value gets\ndynamically filled with actual values from the incoming request):\n\n    \n    \n    http.path:<value>|http.headers.x_foo:<value>|http.host:<value>\n\nThanks to the new Rust-based router's awareness of all conditions utilized\nacross routes, it achieves more efficient cache key generating and higher hit\nratio in the router cache which (should) translate to higher RPS and less\nresource usage.\n\nWith the cache key rework commit identified and the rationale behind it\nunderstood, we then performed some profiling on this specific codepath.\n\n## Profiling\n\nWe produced flamegraphs before and after the identified slow commit using\nprofilers, including our proprietary built-in LuaJIT profiler.\n\n### timer-based flamegraph\n\nThe timer-based flamegraph is generated by the handler of a repeatable timer,\nit collects stacktraces of code being executed at short intervals, and the\nresult represents a probabilistic view into the percent of time LuaJIT spent\non executing each codepath.\n\nBefore the cache key algorithm rework\n\nAfter the cache key algorithm rework\n\nWe searched for the keyword 'route' and found no matching span in the first\nflamegraph, yet it accounted for 13.3% of the second graph (highlighted\nsamples in the second graph).\n\n### Instruction-based flamegraph\n\nThis flamegraph is produced through a counter mechanism. With each instruction\nexecuted by the LuaJIT interpreter, the counter increments by one. Once\nreaching a specified threshold, it captures the stack trace of the currently\nexecuting code. This method is instrumental in identifying code paths burdened\nby excessive instructions.\n\nBefore the cache key algorithm rework\n\nAfter the cache key algorithm rework\n\nWe searched the keyword 'route,' yielding results akin to those from the time-\nbased flamegraphs.\n\nHaving reaffirmed that the new cache key algorithm is indeed the reason behind\nthe performance regression, yet finding no slow code upon a thorough review,\nwe resolved to proceed with micro-benchmarking.\n\n## Micro-benchmarking\n\nWe isolated the router code for direct invocation in our micro-benchmarks. The\ncode, noted for its simplicity, is structured as follows:\n\n    \n    \n    for _i = 1, N do assert(router.match(request) is not false) end\n\nSurprisingly, our comparison revealed no noticeable performance difference\nbetween the old and new cache key algorithms.\n\n## Going back to flamegraphs\n\nIt's puzzling \u2014 both timer-based and instruction-based flamegraphs indicate\nthe router as a slow point, yet this isn't replicable in micro-benchmarking.\nConsequently, we went deeper into the flamegraphs to unearth more clues.\n\nAn important detail to note is that this regression persists even when testing\na single route, resulting in a 100% cache hit rate. This piqued our interest\nin the LRU cache's role, as depicted in the flamegraphs.\n\nAfter the cache key algorithm rework (timer-based)\n\nAfter cache key algorithm rework (instruction-based)\n\nWe searched for 'lru,' finding it accounted for 2.6% of CPU time but was\nassociated with only 0.1% of instructions\u2014specifically, LuaJIT bytecode.\nTypically, if a code path executes around 10% bytecode, it should consume\napproximately 10% of CPU time. While the number does not always match exactly\ndue to different bytecodes having different costs, the discrepancy shouldn't\nbe as vast.\n\nAdditionally, flamegraphs prior to the algorithm rework commit show no spans\nof 'lru,' despite a 100% cache hit rate, indicating it wasn't a significant\nperformance factor before the change However, after the cache key algorithm\nrefactor it suddenly started showing up in the profiling result. The LRU cache\ncode has not seen any change for a long time, what could have caused this\nseemingly mysterious change in its performance?\n\n## JIT debugging\n\n### What is LuaJIT doing behind the scenes?\n\nWhen dealing with complex dynamic language runtimes like LuaJIT, performance\ncharacteristics of the runtime are often affected by subtle codepath changes\nthat are easily missed by human eyes. This is especially true with LuaJIT\nwhich performs a \u201chigh risk, high reward\u201d JIT compilation of the bytecode at\nruntime to achieve faster execution for hot codepaths. Being able to JIT a\ncodepath often results in many times of performance improvement while failing\nto do so can often lead to noticeable performance loss.\n\nLuaJIT operates as a trace-based JIT (Just-In-Time) compiler, mapping the\nexecution flow of bytecodes in real time. It creates a 'trace', a data\nstructure encompassing both the sequence of bytecodes and their runtime\ncontext, and then compiles this trace into machine code.\n\n### Looking inside the LuaJIT\n\nLuaJIT gives us some interfaces for debugging the JIT compiler.\n\n    \n    \n    local dump = require(\"jit.dump\") dump.on(nil, \"/path/to/jit.log\")\n\nAfter enabling the JIT log, we identified a suspicious trace abort within the\nhot execution path of the cache key algorithm.\n\n    \n    \n    ---- TRACE 1545 start fields.lua:258 0001 UGET 3 0 ; str_buf (fields.lua:259) 0002 MOV 5 3 (fields.lua:259) 0003 TGETS 3 3 0 ; \"reset\" (fields.lua:259) 0004 CALL 3 1 2 (fields.lua:259) 0000 . FUNCC ; buffer.method.reset 0005 UGET 3 1 ; fields_visitor (fields.lua:262) 0006 MOV 5 0 (fields.lua:262) 0007 MOV 6 1 (fields.lua:262) 0008 MOV 7 2 (fields.lua:262) 0009 FNEW 8 1 ; fields.lua:262 (fields.lua:295) ---- TRACE 1545 abort fields.lua:295 -- NYI: bytecode 51(FNEW)\n\nTo be more specific, here is the line of code that was causing the trace abort\nduring the execution:\nhttps://github.com/Kong/kong/blob/c9fd6c127a9576da09d9af4fa4ba1139b30b3509/kong/router/fields.lua#L295\n\n    \n    \n    fields_visitor(fields, params, nil, function(field, value) ... end)\n\nThis segment of code, situated in the critical execution path, is responsible\nfor appending routable fields to the router to facilitate subsequent matching.\nThe issue arises from generating a new closure for each request (the FNEW\nbytecode), a process that leads to a trace abort since LuaJIT is currently\nunable to compile this operation yet.\n\n### What is the trace abort?\n\nA trace abort occurs when LuaJIT encounters a scenario it cannot, or chooses\nnot to, compile, resulting in the decision to halt the trace and refrain from\ncompiling that particular execution flow.\n\nFor example, LuaJIT can not JIT compile the standard function error. This\nmakes sense, this function is used for raising a Lua error (which is similar\nto the concept exception in languages like C++/Java and should not be in the\nhot path). Implementing JIT compilation on it would result in little\nperformance benefit.\n\nHere is an example list that shows a few functions LuaJIT cannot or chooses\nnot to compile:\n\ndebug.* \u2014 Never compile\n\ngetfenv \u2014 Only compile getfenv(0)\n\nstring.dump \u2014 Never compile\n\n### How does the trace abort affect performance?\n\nLuaJIT bytecode flow tracing and JIT compilation incur more overhead in\naddition to the cost of interpreter execution, therefore, it is only triggered\nwhen a hot code path has been identified at runtime. In the event of a trace\nabort, the trace workflow will be terminated immediately until the next\nhotspot is found. Consequently, this may sometimes affect the opportunity to\ncompile subsequent code segments and cause them to run in the slower\ninterpreted mode as well.\n\n## Fixing and result\n\nResolving this issue is straightforward: replacing the closure with a local\nfunction eliminates the need to generate it for every request.\n\n    \n    \n    local function foo() ... end ... fields_visitor(fields, params, nil, foo)\n\nWe subsequently conducted another performance comparison involving three\nversions:\n\nFrom left to right, the previous release, the version with the fix, and the\nupcoming release candidate (RC).\n\nCurrently, we observe only a 2.6% regression in RPS, which falls within the\nmargin of error of our performance measurement. Fortunately, enhancements in\nthe router cache hit rate promise additional performance gains for our\ncustomers. The conclusive benchmark confirms the absence of significant\nregression in RPS.\n\n## More findings\n\nSince NYI has such a significant impact on performance, so we did more\nprofiling after the release and found a few NYIs on the hot path, a quick\nbenchmark produced another 7% in RPS improvements.\n\n## What\u2019s next?\n\nThe LuaJIT is highly complex, making it difficult to expect every engineer to\nunderstand its implementation details. Therefore, we plan to enhance the\ndebuggability of LuaJIT by providing sketches of key performance indicators\nsuch as the occurrence of NYIs in the hot path and trace aborts. This will\nhelp us detect any code that is not compatible with JIT compilation.\nSubsequently, we aim to incorporate this monitoring into our internal CI/CD\nworkflow, enabling us to identify and address these issues at an early stage.\nAll of these work together to achieve one goal \u2014 to provide a robust and\nperformance platform that our customers can rely on.\n\nInterested in this kind of low-level troubleshooting and performance\noptimization? Check out Kong's job openings on our Gateway Performance\nEngineering team.\n\nTags:Life at Kong\n\n|\n\nKong Gateway\n\nPowering the API world\n\nIncrease developer productivity, security, and performance at scale with the\nunified platform for API management, service mesh, and ingress controller.\n\nSign up for Kong newsletter\n\nProducts\n\nKong KonnectKong Gateway EnterpriseKong GatewayKong MeshKong Ingress\nControllerKong InsomniaProduct UpdatesGet Started\n\nExplore More\n\nAPI First DevelopmentAPI Gateway: Build vs BuyAWS and Kong TogetherKong vs\nMulesoftKong vs ApigeeAccelerate APIOpsCloud API Modernization\n\nDocumentation\n\nKong Konnect DocsKong Gateway DocsKong Gateway Enterprise DocsKong Mesh\nDocsKong Insomnia DocsKong Konnect Plugin Hub\n\nOpen Source\n\nKong GatewayKumaInsomniaKong Community\n\nCompany\n\nAbout KongCustomersCareersPressEventsContact\n\n  * Terms\u2022\n  * Privacy\u2022\n  * Trust and Compliance\n\n  * \u00a9 Kong Inc. 2024\n\nBy clicking \u201cAccept All Cookies\u201d, you agree to the storing of cookies on your\ndevice to enhance site navigation, analyze site usage, and assist in our\nmarketing efforts.\n\n## Privacy Preference Center\n\nWhen you visit any website, it may store or retrieve information on your\nbrowser, mostly in the form of cookies. This information might be about you,\nyour preferences or your device and is mostly used to make the site work as\nyou expect it to. The information does not usually directly identify you, but\nit can give you a more personalized web experience. Because we respect your\nright to privacy, you can choose not to allow some types of cookies. Click on\nthe different category headings to find out more and change our default\nsettings. However, blocking some types of cookies may impact your experience\nof the site and the services we are able to offer.\n\n### Manage Consent Preferences\n\n### Cookie List\n\nlabel\n\nConsent Leg.Interest\n\nlabel\n\nlabel\n\nlabel\n\n", "frontpage": false}
