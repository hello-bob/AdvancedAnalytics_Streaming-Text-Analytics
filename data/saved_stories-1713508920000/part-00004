{"aid": "40080660", "title": "Meta Llama 3 Available on Cloudflare Workers AI", "url": "https://blog.cloudflare.com/meta-llama-3-available-on-cloudflare-workers-ai", "domain": "cloudflare.com", "votes": 6, "user": "gregorymichael", "posted_at": "2024-04-18 21:01:05", "comments": 0, "source_title": "Meta Llama 3 available on Cloudflare Workers AI", "source_text": "Meta Llama 3 available on Cloudflare Workers AI\n\nGet Started Free|Contact Sales\n\n## The Cloudflare Blog\n\nSubscribe to receive notifications of new posts:\n\n# Meta Llama 3 available on Cloudflare Workers AI\n\n04/18/2024\n\n  * Michelle Chen\n\n  * Davina Zamanzadeh\n\n  * Isaac Rehg\n\n  * Nikhil Kothari\n\n3 min read\n\nWe are thrilled to give developers around the world the ability to build AI\napplications with Meta Llama 3 using Workers AI. We are proud to be a launch\npartner with Meta for their newest 8B Llama 3 model, and excited to continue\nour partnership to bring the best of open-source models to our inference\nplatform.\n\n## Workers AI\n\nWorkers AI\u2019s initial launch in beta included support for Llama 2, as it was\none of the most requested open source models from the developer community.\nSince that initial launch, we\u2019ve seen developers build all kinds of innovative\napplications including knowledge sharing chatbots, creative content\ngeneration, and automation for various workflows.\n\nAt Cloudflare, we know developers want simplicity and flexibility, with the\nability to build with multiple AI models while optimizing for accuracy,\nperformance, and cost, among other factors. Our goal is to make it as easy as\npossible for developers to use their models of choice without having to worry\nabout the complexities of hosting or deploying models.\n\nAs soon as we learned about the development of Llama 3 from our partners at\nMeta, we knew developers would want to start building with it as quickly as\npossible. Workers AI\u2019s serverless inference platform makes it extremely easy\nand cost effective to start using the latest large language models (LLMs).\nMeta\u2019s commitment to developing and growing an open AI-ecosystem makes it\npossible for customers of all sizes to use AI at scale in production. All it\ntakes is a few lines of code to run inference to Llama 3:\n\n    \n    \n    export interface Env { // If you set another name in wrangler.toml as the value for 'binding', // replace \"AI\" with the variable name you defined. AI: any; } export default { async fetch(request: Request, env: Env) { const response = await env.AI.run('@cf/meta/llama-3-8b-instruct', { messages: [ {role: \"user\", content: \"What is the origin of the phrase Hello, World?\"} ] } ); return new Response(JSON.stringify(response)); }, };\n\n## Built with Meta Llama 3\n\nLlama 3 offers leading performance on a wide range of industry benchmarks. You\ncan learn more about the architecture and improvements on Meta\u2019s blog post.\nCloudflare Workers AI supports Llama 3 8B, including the instruction fine-\ntuned model.\n\nMeta\u2019s testing shows that Llama 3 is the most advanced open LLM today on\nevaluation benchmarks such as MMLU, GPQA, HumanEval, GSM-8K, and MATH. Llama 3\nwas trained on an increased number of training tokens (15T), allowing the\nmodel to have a better grasp on language intricacies. Larger context windows\ndoubles the capacity of Llama 2, and allows the model to better understand\nlengthy passages with rich contextual data. Although the model supports a\ncontext window of 8k, we currently only support 2.8k but are looking to\nsupport 8k context windows through quantized models soon. As well, the new\nmodel introduces an efficient new tiktoken-based tokenizer with a vocabulary\nof 128k tokens, encoding more characters per token, and achieving better\nperformance on English and multilingual benchmarks. This means that there are\n4 times as many parameters in the embedding and output layers, making the\nmodel larger than the previous Llama 2 generation of models.\n\nUnder the hood, Llama 3 uses grouped-query attention (GQA), which improves\ninference efficiency for longer sequences and also renders their 8B model\narchitecturally equivalent to Mistral-7B. For tokenization, it uses byte-level\nbyte-pair encoding (BPE), similar to OpenAI\u2019s GPT tokenizers. This allows\ntokens to represent any arbitrary byte sequence \u2014 even those without a valid\nutf-8 encoding. This makes the end-to-end model much more flexible in its\nrepresentation of language, and leads to improved performance.\n\nAlong with the base Llama 3 models, Meta has released a suite of offerings\nwith tools such as Llama Guard 2, Code Shield, and CyberSec Eval 2, which we\nare hoping to release on our Workers AI platform shortly.\n\n## Try it out now\n\nMeta Llama 3 8B is available in the Workers AI Model Catalog today! Check out\nthe documentation here and as always if you want to share your experiences or\nlearn more, join us in the Developer Discord.\n\nWe protect entire corporate networks, help customers build Internet-scale\napplications efficiently, accelerate any website or Internet application, ward\noff DDoS attacks, keep hackers at bay, and can help you on your journey to\nZero Trust.\n\nVisit 1.1.1.1 from any device to get started with our free app that makes your\nInternet faster and safer.\n\nTo learn more about our mission to help build a better Internet, start here.\nIf you're looking for a new career direction, check out our open positions.\n\nDiscuss on Hacker News\n\nLlamaDevelopersDeveloper PlatformWorkers AICloudflare WorkersProduct News\n\nFollow on X\n\nMichelle Chen|@_mchenco\n\nDavina Zamanzadeh|@davzaman\n\nCloudflare|@cloudflare\n\n  * Getting Started\n  * Free plans\n  * For enterprises\n  * Compare plans\n  * Get a recommendation\n  * Request a demo\n  * Contact Sales\n\n  * Resources\n  * Learning Center\n  * Analyst reports\n  * Cloudflare Radar\n  * Cloudflare TV\n  * Case Studies\n  * Webinars\n  * White Papers\n  * Developer docs\n  * theNet\n\n  * Solutions\n  * Connectivity cloud\n  * SSE and SASE services\n  * Application services\n  * Network services\n  * Developer services\n\n  * Community\n  * Community Hub\n  * Project Galileo\n  * Athenian Project\n  * Cloudflare for Campaigns\n  * Critical Infrastructure Defense Project\n  * Connect 2024\n\n  * Support\n  * Help center\n  * Cloudflare Status\n  * Compliance\n  * GDPR\n  * Trust & Safety\n\n  * Company\n  * About Cloudflare\n  * Our team\n  * Investor relations\n  * Press\n  * Careers\n  * Diversity, equity & inclusion\n  * Impact/ESG\n  * Network Map\n  * Logos & press kit\n  * Become a partner\n\n\u00a9 2024 Cloudflare, Inc. | Privacy Policy | Terms of Use | Report Security Issues |Cookie Preferences| Trademark\n\n## Our site uses cookies\n\nLike most websites, we use cookies to make our site work the way you expect it\nto, improve your experience on our site, analyze site usage, and assist in our\nmarketing efforts. By choosing \"Accept All Cookies\", you agree to the storing\nof all categories of cookies on your device. If you wish to accept or reject\nsome categories of cookies, please click \u201cCookie Preferences.\u201d\n\n## Your Cookie Options\n\nCloudflare uses four types of cookies as described below. You can decide which\ncategories of cookies you wish to accept to improve your experience on our\nwebsite. To learn more about the cookies we use on our site, please read our\nCookie Policy. Cloudflare's Cookie Policy\n\n### Manage Consent Preferences\n\n#### Strictly Necessary Cookies\n\nAlways Active\n\nStrictly Necessary cookies are essential to our website functioning as\nexpected. You cannot turn off Strictly Necessary cookies because they are\nrequired to deliver security, enable core site functionality, and help you use\nour site's features and services as you would expect (including remembering\nyour cookie consent preferences). Cloudflare does not use these cookies to\ntrack individuals across websites.\n\n#### Functional Cookies\n\nFunctional cookies allow us to remember choices you make about the kind of\nexperience you want on our site and to provide you with a more personalized\nexperience. For example, a functional cookie is required to remember which\nlanguage you prefer.\n\n#### Performance Cookies\n\nPerformance cookies help us learn how you use our website to help improve its\nperformance and design. These cookies provide us with aggregated statistical\ninformation such as number of page visits, page load speeds, how long a user\nspends on a particular page, and the types of browsers or devices used to\naccess our site.\n\n#### Targeting Cookies\n\nWe use Targeting cookies to deliver advertisements relevant to you and your\ninterests when you visit other websites that host advertisements.\n\n### Cookie List\n\nlabel\n\nConsent Leg.Interest\n\nlabel\n\nlabel\n\nlabel\n\n", "frontpage": false}
