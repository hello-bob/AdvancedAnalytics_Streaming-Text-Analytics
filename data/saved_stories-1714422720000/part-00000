{"aid": "40198766", "title": "SB-1047 will stifle open-source AI and decrease safety", "url": "https://www.answer.ai/posts/2024-04-29-sb1047.html", "domain": "answer.ai", "votes": 20, "user": "kmdupree", "posted_at": "2024-04-29 14:29:13", "comments": 0, "source_title": "SB-1047 will stifle open-source AI and decrease safety", "source_text": "Answer.AI - SB-1047 will stifle open-source AI and decrease safety\n\n# SB-1047 will stifle open-source AI and decrease safety\n\nBy imposing the restrictions on open-source AI, SB-1047 could reduce AI\nsafety, through reducing transparency, collaboration, diversity, and\nresilience.\n\nAuthor\n\nJeremy Howard\n\nPublished\n\nApril 29, 2024\n\n> Note from Jeremy: This is my personal submission to the authors of bill\n> SB-1047. It\u2019s not an official Answer.AI statement.\n\nThis is a comment from Jeremy Howard regarding SB-1047. I am an AI researcher\nand entrepreneur. I am the CEO of Answer.AI, an AI R&D lab registered to do\nbusiness in California. I am the author of popular AI software including the\nfastai library, a widely used AI training system. I am the co-author of Deep\nLearning for Coders with Fastai and PyTorch: AI Applications Without a PhD, a\nwidely-praised book with a 4.7 rating on Amazon based on nearly 500 reviews,\nand am the creator of the Practical Deep Learning series of free courses, the\nlongest-running deep learning course in the world, with over 5 million views.\nI co-authored the paper Universal Language Model Fine-tuning for Text\nClassification, which created the 3-stage language model pre-training and\nfine-tuning approach on which all of today\u2019s language models (including\nChatGPT and Gemini) are based.\n\nWhile the intent of SB-1047 to ensure the safe and secure development of AI is\ncommendable, certain provisions within the bill raise serious concerns\nregarding their potential impact on open-source developers, small businesses,\nand overall innovation within the AI sector. This response aims to highlight\nthese concerns and suggest alternative approaches that could achieve the\ndesired safety goals without stifling the dynamism of the AI ecosystem.\n\nIronically, by imposing these restrictions on open-source development, SB-1047\ncould actually reduce overall safety within the AI ecosystem, in particular\nthrough reducing:\n\n  * Transparency and Collaboration: Open-source development fosters transparency and collaboration, allowing a wider range of experts to identify and address potential safety concerns. Restricting this open development model limits the ability of the broader community to contribute to safety solutions.\n  * Diversity and Resilience: Open-source projects contribute to a more diverse and resilient AI landscape. Concentrating control within a few large entities creates single points of failure and increases the potential for systemic risks.\n\n## Concerns Regarding Open-Source Development\n\nOpen source has been a key enabler of the success of the US software industry,\nand has allowed many Americans to access critical software tools which would\notherwise be unavailable to them. Open source has, in particular, provided\nmany of the fundamental building blocks for modern artificial intelligence,\nand is the basis on which nearly all academic research (including safety and\nsecurity research) is done. Harming open source will harm developers,\nconsumers, academics, and obstruct the development of new startups. The bill\nwould cause harm in a number of ways:\n\n  * Overly Broad Definitions: The definition of \u201ccovered model\u201d within the bill is extremely broad, potentially encompassing a wide range of open-source models that pose minimal risk. This could inadvertently criminalize the activities of well-intentioned developers working on beneficial AI projects.\n  * Dual use: An AI model is a general purpose piece of software that runs on a computer, much like a word processor, calculator, or web browser. The creator of a model can not ensure that a model is never used to do something harmful \u2013 any more so that the developer of a web browser, calculator, or word processor could. Placing liability on the creators of general purpose tools like these mean that, in practice, such tools can not be created at all, except by big businesses with well funded legal teams.\n  * Restrictive Requirements: The bill imposes significant burdens on developers, including mandatory shutdowns, extensive reporting, and compliance with potentially ambiguous \u201ccovered guidance.\u201d These requirements could disproportionately impact open-source developers who often lack the resources of larger corporations to navigate complex regulatory processes.\n  * Disincentivizing Openness: The fear of legal repercussions and bureaucratic hurdles could discourage open-source development, hindering the collaborative spirit that has been instrumental in driving AI advancements. This reduction in transparency could also make it more difficult to identify and address potential safety concerns.\n\n## Impact on Small Businesses and Innovation\n\nThe proposed regulations create significant barriers to entry for small\nbusinesses and startups looking to innovate in the AI space. The costs\nassociated with compliance, coupled with the legal risks, could deter\nentrepreneurs and limit competition. This would ultimately stifle innovation\nand concentrate power within established corporations.\n\n  * Barrier to Entry: The substantial costs associated with compliance, including fees, audits, and legal counsel, could create a significant barrier to entry for small businesses and startups. This would limit competition and concentrate power within established corporations, ultimately hindering innovation.\n  * Chilling Effect on Research: The fear of inadvertently triggering the bill\u2019s provisions could lead researchers and developers to self-censor or avoid exploring promising avenues of AI research. This would stifle scientific progress and limit the potential of AI to address societal challenges.\n  * Loss of Talent: The restrictive environment created by the bill could drive talented AI researchers and developers out of California, harming the state\u2019s economy and weakening its position as a leader in AI innovation.\n\nCalifornia plays a critical role in driving US innovation, particularly in the\ntechnology sector. By placing undue burdens on AI development, SB-1047 risks\nhindering the state\u2019s leadership in this crucial field. This could have ripple\neffects throughout the US, slowing down overall progress in AI research and\ndevelopment.\n\n## Alternative Approaches\n\nInstead of focusing on regulating AI model development, I urge you to consider\nalternative approaches that address the actual risks associated with AI\napplications.\n\n  * Support Open-Source Development: Encourage and facilitate the open-source development of AI models to foster collaboration, transparency, and a more diverse and resilient AI ecosystem.\n  * Focus on Usage, Not Development: Instead of regulating the development of AI models, the focus should be on regulating their applications, particularly those that pose high risks to public safety and security. Regulate the use of AI in high-risk areas such as healthcare, criminal justice, and critical infrastructure, where the potential for harm is greatest, would ensure accountability for harmful use, whilst allowing for the continued advancement of AI technology.\n  * Promote Transparency and Collaboration: Encourage the development and adoption of best practices for responsible AI development through collaboration between industry, academia, and government. This could involve creating industry standards, fostering open-source development, and investing in AI safety research.\n  * Invest in AI Expertise: Provide resources to government agencies to develop expertise in AI and build capacity to effectively monitor and address potential risks. This would enable a more informed and nuanced approach to AI regulation that balances safety with innovation.\n\n## Conclusion\n\nCalifornia has a unique opportunity to lead the way in responsible AI\ndevelopment. However, SB-1047, in its current form, risks stifling innovation\nand undermining the state\u2019s leadership in AI. By adopting alternative\napproaches that prioritize accountability for harmful use while fostering a\nvibrant and open AI ecosystem, California can ensure the safe and beneficial\nadvancement of this transformative technology.\n\n## Specific Sections of Concern\n\n  * Section 22602 (f): The definition of \u201ccovered model\u201d is overly broad and could encompass a wide range of open-source models.\n  * Section 22603 (b): The requirements for developers are overly burdensome and could discourage open-source development.\n  * Section 22606 (a): The potential for civil penalties could have a chilling effect on research and innovation.\n  * Section 11547.6 (c)(11): The ability to levy fees could create a barrier to entry for small businesses.\n\n", "frontpage": true}
