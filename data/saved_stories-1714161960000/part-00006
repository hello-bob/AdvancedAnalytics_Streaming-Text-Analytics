{"aid": "40167461", "title": "Show HN: OpenLIT \u2013 Open-Source LLM Observability with OpenTelemetry", "url": "https://github.com/openlit/openlit", "domain": "github.com/openlit", "votes": 1, "user": "aman_041", "posted_at": "2024-04-26 09:45:26", "comments": 0, "source_title": "GitHub - openlit/openlit: OpenLIT is an open-source GenAI and LLM observability platform native to OpenTelemetry with traces and metrics in a single application \ud83d\udd25 \ud83d\udda5 . \ud83d\udc49 Open source GenAI and LLM Application Performance Monitoring (APM) & Observability tool", "source_text": "GitHub - openlit/openlit: OpenLIT is an open-source GenAI and LLM\nobservability platform native to OpenTelemetry with traces and metrics in a\nsingle application \ud83d\udd25 \ud83d\udda5 . \ud83d\udc49 Open source GenAI and LLM Application Performance\nMonitoring (APM) & Observability tool\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nopenlit / openlit Public\n\n  * Notifications\n  * Fork 7\n  * Star 66\n\nOpenLIT is an open-source GenAI and LLM observability platform native to\nOpenTelemetry with traces and metrics in a single application \ud83d\udd25 \ud83d\udda5 . \ud83d\udc49 Open\nsource GenAI and LLM Application Performance Monitoring (APM) & Observability\ntool\n\ndocs.openlit.io\n\n### License\n\nApache-2.0 license\n\n66 stars 7 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# openlit/openlit\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n5 Branches\n\n16 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\ndependabot[bot]andpatcher9build(deps): bump sigstore/cosign-installer from\n3.4.0 to 3.5.0 (#181)Apr 25, 2024b4fd361 \u00b7 Apr 25, 2024Apr 25, 2024\n\n## History\n\n175 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| build(deps): bump sigstore/cosign-installer from 3.4.0 to 3.5.0 (#181)| Apr\n25, 2024  \n  \n### assets\n\n|\n\n### assets\n\n| update docker compose| Apr 21, 2024  \n  \n### docs\n\n|\n\n### docs\n\n| Update mint.json| Apr 25, 2024  \n  \n### sdk/python\n\n|\n\n### sdk/python\n\n| update python version| Apr 23, 2024  \n  \n### src\n\n|\n\n### src\n\n| Replace doku with openlit| Apr 23, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| add meta image (#189)| Apr 18, 2024  \n  \n### CODEOWNERS\n\n|\n\n### CODEOWNERS\n\n| feat: updated theme for the dashboard, migrated to openlit db, suppor...|\nApr 23, 2024  \n  \n### CODE_OF_CONDUCT.md\n\n|\n\n### CODE_OF_CONDUCT.md\n\n| Initial Commit| Jan 23, 2024  \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n| add meta image (#189)| Apr 18, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Update LICENSE| Jan 23, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| update readme and docs (#199)| Apr 25, 2024  \n  \n### SECURITY.md\n\n|\n\n### SECURITY.md\n\n| add meta image (#189)| Apr 18, 2024  \n  \n### docker-compose.yml\n\n|\n\n### docker-compose.yml\n\n| Update DockerCompose| Apr 23, 2024  \n  \n### package-lock.json\n\n|\n\n### package-lock.json\n\n| Replace doku with openlit| Apr 23, 2024  \n  \n## Repository files navigation\n\n# OpenTelemetry-native LLM Application Observability\n\nDocumentation | Quickstart | Python SDK\n\nOpenLIT is an OpenTelemetry-native GenAI and LLM Application Observability\ntool. It's designed to make the integration process of observability into\nGenAI projects as easy as pie \u2013 literally, with just a single line of code.\nWhether you're working with popular LLM Libraries such as OpenAI and\nHuggingFace or leveraging vector databases like ChromaDB, OpenLIT ensures your\napplications are monitored seamlessly, providing critical insights to improve\nperformance and reliability.\n\nThis project proudly follows the Semantic Conventions of the OpenTelemetry\ncommunity, consistently updating to align with the latest standards in\nobservability.\n\n## What is LIT?\n\nLIT stands for Learning Interpretability Tool. It refers to a visual,\ninteractive model-understanding and data visualization tool ad a term\nintroduced by Google.\n\n## \u26a1 Features\n\n  * OpenTelemetry-native: Native support ensures that integrating OpenLIT into your projects feels more like a natural extension rather than an additional layer of complexity.\n  * Granular Usage Insights of your LLM Applications: Assess your LLM's performance and costs with fine-grained control, breaking down metrics by environment (such as staging or production) or application, to optimize for efficiency and scalability.\n  * Vendor-Neutral SDKs: In the spirit of OpenTelemetry, OpenLIT's SDKs are agnostic of the backend vendors. This means you can confidently use OpenLIT with various telemetry backends, like Grafana Tempo, without worrying about compatibility issues.\n\n## \ud83d\ude80 Getting Started\n\n## Step 1: Deploy OpenLIT\n\nFrom the root directory of the this Repo, Run the below command:\n\n    \n    \n    docker-compose up -d\n\n## Step 2: Install OpenLIT SDK\n\n    \n    \n    pip install openlit\n\n### Step 2: Instrument your Application\n\nIntegrating the OpenLIT into LLM applications is straightforward. Start\nmonitoring for your LLM Application with just one line of code:\n\n    \n    \n    import openlit openlit.init(otlp_endpoint=\"http://127.0.0.1:4318\")\n\nTo forward telemetry data to an HTTP OTLP endpoint, such as the OpenTelemetry\nCollector, set the otlp_endpoint parameter with the desired endpoint.\nAlternatively, you can configure the endpoint by setting the\nOTEL_EXPORTER_OTLP_ENDPOINT environment variable as recommended in the\nOpenTelemetry documentation.\n\n> \ud83d\udca1 Info: If you dont provide otlp_endpoint function argument or set the\n> OTEL_EXPORTER_OTLP_ENDPOINT environment variable, The SDK directs the trace\n> directly to your console, which can be useful during development.\n\nTo send telemetry to OpenTelemetry backends requiring authentication, set the\notlp_headers parameter with its desired value. Alternatively, you can\nconfigure the endpoint by setting the OTEL_EXPORTER_OTLP_HEADERS environment\nvariable as recommended in the OpenTelemetry documentation.\n\n#### Example\n\nHere is how you can send telemetry from OpenLIT to Grafana Cloud\n\n    \n    \n    openlit.init( otlp_endpoint=\"https://otlp-gateway-prod-us-east-0.grafana.net/otlp\", otlp_headers=\"Authorization=Basic%20<base64 encoded Instance ID and API Token>\" )\n\nAlternatively, You can also choose to set these values using\nOTEL_EXPORTER_OTLP_ENDPOINT and OTEL_EXPORTER_OTLP_HEADERS environment\nvariables\n\n    \n    \n    openlit.init()\n    \n    \n    export OTEL_EXPORTER_OTLP_ENDPOINT = \"https://otlp-gateway-prod-us-east-0.grafana.net/otlp\" export OTEL_EXPORTER_OTLP_HEADERS = \"Authorization=Basic%20<base64 encoded Instance ID and API Token>\"\n\n### Step 3: Visualize and Optimize!\n\nWith the LLM Observability data now being collected and sent to OpenLIT, the\nnext step is to visualize and analyze this data to get insights into your LLM\napplication's performance, behavior, and identify areas of improvement.\n\nJust head over to OpenLIT UI at 127.0.0.1:3000 on your browser to start\nexploring.\n\n## \ud83c\udf31 Contributing\n\nWhether it's big or small, we love contributions \ud83d\udc9a. Check out our Contribution\nguide to get started\n\nUnsure where to start? Here are a few ways to get involved:\n\n  * Join our Slack channel to discuss ideas, share feedback, and connect with both our team and the wider OpenLIT community.\n\nYour input helps us grow and improve, and we're here to support you every step\nof the way.\n\n## \ud83d\udc9a Community & Support\n\nConnect with the OpenLIT community and maintainers for support, discussions,\nand updates:\n\n  * \ud83c\udf1f If you like it, Leave a star on our GitHub\n  * \ud83c\udf0d Join our Slack Community for live interactions and questions.\n  * \ud83d\udc1e Report bugs on our GitHub Issues to help us improve OpenLIT.\n  * X Follow us on X for the latest updates and news.\n\n## License\n\nOpenLIT is available under the Apache-2.0 license.\n\n## Visualize! Analyze! Optimize!\n\nJoin us on this voyage to reshape the future of AI Observability. Share your\nthoughts, suggest features, and explore contributions. Engage with us on\nGitHub and be part of OpenLIT's community-led innovation.\n\n## About\n\nOpenLIT is an open-source GenAI and LLM observability platform native to\nOpenTelemetry with traces and metrics in a single application \ud83d\udd25 \ud83d\udda5 . \ud83d\udc49 Open\nsource GenAI and LLM Application Performance Monitoring (APM) & Observability\ntool\n\ndocs.openlit.io\n\n### Topics\n\npython open-source metrics clickhouse grafana tracing openai observability\ndistributed-tracing typescipt monitoring-tool otel opentelemetry otlp ai-\nobservability llms langchain llmops anthropic genai\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\n### Code of conduct\n\nCode of conduct\n\n### Security policy\n\nSecurity policy\n\nActivity\n\nCustom properties\n\n### Stars\n\n66 stars\n\n### Watchers\n\n2 watching\n\n### Forks\n\n7 forks\n\nReport repository\n\n## Releases 15\n\nopenlit-1.0.0 Latest\n\nApr 26, 2024\n\n\\+ 14 releases\n\n## Packages 3\n\n  * doku-ingester\n  * doku-client\n  * openlit\n\n## Contributors 5\n\n## Languages\n\n  * Python 66.8%\n  * TypeScript 32.4%\n  * Other 0.8%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
