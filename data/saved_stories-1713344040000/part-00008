{"aid": "40057183", "title": "Harnessing the Power of Large Language Models for Insightful Review Analysis", "url": "https://techblog.holidaycheck.com/post/2024/03/31/review-topic-sentiment-overview", "domain": "holidaycheck.com", "votes": 1, "user": "kkm", "posted_at": "2024-04-16 21:03:25", "comments": 0, "source_title": "Harnessing the Power of Large Language Models for Insightful Review Analysis", "source_text": "The HolidayCheck Tech Blog | Harnessing the Power of Large Language Models for Insightful Review Analysis\n\n  * Home\n  * Events\n  * Jobs\n  * Imprint\n  * About\n  * Twitter\n  * Source\n\n# Harnessing the Power of Large Language Models for Insightful Review Analysis\n\nMateusz Jancy, Richard Knoche, Timon Blauensteiner, Thomas Mayer in Machine\nlearning 8 minutes read March 31, 2024\n\nIn our latest efforts towards enhancing user experience and offering more\nprofound insights into our expansive collection of travel reviews,\nHolidayCheck Group is thrilled to unveil a cutting-edge feature powered by\nLarge Language Models (LLMs). This innovative tool transcends traditional\nreview analysis by extracting topics and their corresponding sentiments from\nour platform\u2019s treasure chest of reviews. It signifies a leap in our\ntechnological dedication to put AI to good use. It demonstrates our commitment\nto understanding and catering to the nuanced preferences of our diverse user\nbase. By leveraging the advanced capabilities of LLMs, we can now dissect the\nvast ocean of user-generated content, distilling it into actionable insights\nand transparent feedback for our users.\n\n## Motivation\n\nAt HolidayCheck Group, we believe in the importance of accurately capturing\nthe voice of our users. While summarizing reviews using LLMs could offer a\nquick snapshot, we\u2019ve decided to take a more nuanced route. Recognizing the\ncomplexity and depth of user reviews, we aim to first dissect these into their\ncore topics and associated sentiments. This method allows us to construct a\nmore representative and comprehensive overview of user opinions, ensuring that\nno critical detail is overlooked or \u2013 even worse \u2013 sentiments about a specific\ntopic are misrepresented. Our initial step in sharing these insights is to\ncluster reviews by topic, providing our users with precise statistics on\nsentiments. This feature is designed to enhance transparency and trust, giving\nboth new and seasoned travelers an informed glimpse into the experiences of\nothers. We want to provide full transparency to the hotel owners and our users\nalike on how these overall summaries can be reconstructed from the review\nsources. For us, this also entails to be able to filter for the reviews where\nthe specific topics are mentioned.\n\nExample sentiment analysis for a review (red indicates negative sentiments,\ngreen positive sentiments, grey represents a neutral sentiment.\n\nThe screenshot shows the feature for a particular hotel with all topics\nexpanded and the topic \u201cSchlafqualit\u00e4t\u201d selected. Topics are shown in pills\nwhere a green thumb indicates that most sentiments for this topic are\npositive. Behind the topic name we show the number of times the specific topic\nwas mentioned in the most frequent reviews. If a specific topic is selected\n(as in the screenshot), more detailed information is provided below the pills.\nWe show the percentages and absolute numbers for the three categories of\npositive, neutral and negative sentiments. In addition, for the reviews the\nsame topic filter is applied (see the blue pill at the very bottom) so that\nonly reviews containing the specific topic are shown to the user. Snippets\nwithin the review that mention the topic are also highlighted to the user for\neasier reference.\n\nCurrently, we gradually roll out the feature for our top hotels and for their\nmost recent reviews. For a live example, go here.\n\n## Topic extraction and sentiment classification\n\nBoth topic extraction and sentiment classification are provided with the help\nof an LLM. To this end, we devised a specific prompt that takes as input a\ngiven review and extracts the relevant topics. The prompt features relevant\nexamples in a few-shot learning approach (https://arxiv.org/abs/2005.14165).\nThe extracted topics are then simultaneously classified for their sentiment\n(see https://techblog.holidaycheck.com/post/2023/08/24/sentiment-analysis-llms\nfor more information on sentiment analysis with LLMs).\n\nThe LLM then generates the output in JSON format. With the help of the\nLangChain library (https://www.langchain.com/), we provide the expected schema\nfor the output format and pipe the prompt through the respective chain to\ngenerate the response. From a cost and quality trade-off, we currently use GPT\n3.5 Turbo as our preferred LLM, but we also investigate other options to\nprovide even better quality (at lower costs) to our users. We focused also on\navoiding reprocessing in case of errors happening in mid of batch processing\n(so if a review was processed successfully, it won\u2019t be reprocessed after the\nrestart again). Similary, we also experimented in finding the optimal number\nof parallel requests that would still satisfy our OpenAI quota restrictions\nfor a specific region.\n\nThe results of our processing are meticulously logged in our Data Lake. We not\nonly track the raw output of the LLM but also potential error messages from\nOpenAI. The logging enables us to keep a full overview of the whole processing\nsteps afterwards.\n\n## Making it accessible to the frontend\n\nThe extracted topics, along with their associated sentiment analyses and\nquotes, are added to our Elasticsearch database. This addition enables the\nexecution of quick aggregations for searches and displaying aggregated data on\nthe frontend. Combined with our current pagination logic, it permits filtering\nby topics and incorporating other filters, such as sun ratings, while at the\nsame time maintaining system performance.\n\nThe integration of Elasticsearch into our topic analysis significantly\nsimplified the frontend development in React. By leveraging Elasticsearch\u2019s\npowerful aggregation capabilities, we can easily showcase the required data\naggregations on our pages. This allows for a seamless user experience; when a\nuser selects a topic filter, we promptly display a detailed breakdown for that\nspecific topic. Additionally, we utilize these aggregations to efficiently\nquery and present the most relevant reviews, complete with quotations,\nhighlighting key insights.\n\n## Challenges\n\nUsing LLMs to extract review topics and sentiments also has some challenges. A\nnotable hurdle is the model\u2019s inclination to \u201ccorrect\u201d the UGC text, altering\nverbatim snippets in ways that makes it harder for us to detect the snippet in\nthe original review. Additionally, navigating OpenAI\u2019s content filtering poses\nits own set of challenges. At times, certain reviews are filtered out for\nreasons that are not immediately apparent. While there might be some\nunderlying sexual connotations in some reviews that are filtered, with others\nit is entirely weird why this input should be filtered out. For example, the\nfollowing review does not pass OpenAI\u2019s content filter:\n\n\u201cSehr sch\u00f6nes Hotel mit freundlichen Personal, sehr Hilfsbereit und sehr\nfreundlich und sehr Sauber sch\u00f6ner Pool. Sehr sch\u00f6n Zimmer.\u201d (translation:\nVery nice hotel with friendly staff, very helpful and very friendly and very\nclean, beautiful pool. Very nice room.)\n\nWhen it comes to our choice for which language models we use, there are a\nnumber of criteria at stake that need to be considered. Our choice in using\nGPT 3.5 was determined by a trade-off between quality of results (esp. with\nGerman language extraction) and budget. At the same time, we\u2019re exploring\ndifferent avenues to use (fine-tuned) open source models as a replacement. Our\nexperience in this respect has mostly shown two challenges: First, we still\nlack the same quality in the results for sentiment and topic extraction with\nthe German language when using OSS models. Second, we also experience\ndifficulties in achieving the same level of reliability for generating\nstructured output in JSON format. Nevertheless, we are very confident that we\nwill soon overcome these obstacles and use self-hosted models for these\npurposes.\n\nThese challenges underscore the complexities of leveraging advanced AI\ntechnologies in a way that respects the authenticity and diversity of user\nexperiences.\n\n## Evaluation\n\nWe invite you to read our tech blog post\n(https://techblog.holidaycheck.com/post/2023/08/24/sentiment-analysis-llms)\nwhere we outline how we test our sentiment analysis approaches. Manual checks\n(even though they might sound dull) are still a cornerstone of our teams\u2019\nevaluation process, providing a hands-on approach to refining and enhancing\nour models. We are committed to continuous improvement, relying on these\nmeticulous reviews to polish our algorithms. Moreover, the feature\u2019s\nintroduction to our users follows a strategic, gradual roll-out. This phased\napproach allows us to monitor the quality closely, make adjustments, and\nensure that our insights are accurate and representative of the original\nreview.\n\n## Conclusion\n\nBy leveraging LLMs to extract and analyze topics and sentiments from user\nreviews, HolidayCheck Group is enhancing the travel planning experience and\nfostering a deeper connection within our community. This is a testament to our\ncommitment to leveraging cutting-edge technology to truly understand and meet\nthe needs of travellers worldwide.\n\nPublished Mar 31, 2024\n\nMateusz Jancy, Richard Knoche, Timon Blauensteiner, Thomas Mayer in Machine\nlearning\n\n### Also found in\n\n  * Machine learning\n\nShare this article\n\n  * Home\n  * Events\n  * Jobs\n  * Imprint\n  * About\n  * Twitter\n  * Source\n\n", "frontpage": false}
