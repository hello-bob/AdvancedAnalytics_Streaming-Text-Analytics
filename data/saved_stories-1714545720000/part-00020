{"aid": "40215212", "title": "Dean Ball on the new California AI bill", "url": "https://marginalrevolution.com/marginalrevolution/2024/04/dean-ball-on-the-new-california-ai-bill-from-my-email.html", "domain": "marginalrevolution.com", "votes": 9, "user": "paulbaumgart", "posted_at": "2024-04-30 19:29:13", "comments": 2, "source_title": "Dean Ball on the new California AI bill (from my email)", "source_text": "Dean Ball on the new California AI bill (from my email) - Marginal REVOLUTION\n\nThank-you! You've been successfully added to the Marginal Revolution email\nsubscription list.\n\n# Dean Ball on the new California AI bill (from my email)\n\nby Tyler Cowen April 30, 2024 at 1:06 am in\n\n  * Law\n  * Web/Tech\n\n> SB 1047 was written, near as I can tell, to satisfy the concerns of a small\n> group of people who believe widespread diffusion of AI constitutes an\n> existential risk to humanity. It contains references to hypothetical models\n> that autonomously engage in illegal activity causing tens of millions in\n> damage and model weights that \u201cescape\u201d from data centers\u2014the stuff of\n> science fiction, codified in law.\n>\n> The bill\u2019s basic mechanism is to require developers to guarantee, with\n> extensive documentation and under penalty of perjury, that their models do\n> not have a \u201chazardous capability,\u201d either autonomously or at the behest of\n> humans. The problem is that it is very hard to guarantee that a general-\n> purpose tool won\u2019t be used for nefarious purposes, especially because it\u2019s\n> hard to define what \u201cused\u201d means in this context. If I use GPT-4 to write a\n> phishing email against an urban wastewater treatment plan, does that count?\n> Under this bill, quite possibly so.\n>\n> If, back in the 70s, Steve Jobs and Steve Wozniak had to guarantee that\n> their computers would not be used for serious crimes, would they have been\n> willing to sign with potential jail time on the line? Would they have even\n> bothered to found Apple?\n>\n> Finally, because of its requirements (or very strong incentives) for\n> developers to monitor and have the means to shut off a user\u2019s access, the\n> bill could make it nearly impossible to open-source models at the current AI\n> frontier\u2014much less the frontiers of tomorrow.\n\nAnd here is Dean\u2019s Substack on emerging technology (including AI) and the\nfuture of governance.\n\n  * 35 Comments\n\n  * Facebook\n  * Twitter\n  * RSS Feed\n\n  * print\n\n## Comments\n\n### blue jay\n\n2024-04-30 02:15:33\n\n256| 10  \n---|---  \n  \nHide Replies\n\n#\n\nWe can only wonder how governments in CA, WA, SF, SEA, LA etc get elected.\nThey give a sort of defacto credence to the idea of rigged elections.\n\nRespond\n\n### DF\n\n2024-04-30 06:18:00\n\n9| 0  \n---|---  \n  \n#\n\nIt's not rigged, the population loves the politicians who hate on tech.\nProphets are hated in their hometowns, or something like that. These residents\ndon't see how much they benefit from their tech industry, they just see the\ncosts in terms of higher rents, change in culture, gentrification, and\ngeopolitical issues like the surveillance state and think techies need to be\nknocked down a peg.\n\nRespond\n\n### rayward\n\n2024-04-30 05:03:05\n\n251| 6  \n---|---  \n  \nHide Replies\n\n#\n\n\"AI systems covered by the Act (SB-1047): Not all AI systems are scrutinized\nequally under the Act. The Act defines \u201cartificial intelligence models\u201d as\nmachine-based systems that can make predictions, recommendations, or decisions\ninfluencing real or virtual environments and which can formulate options for\ninformation or action. However, the Act does not emphasize AI models generally\n\u2013 rather, it focuses specifically on AI models that it defines as a \u201ccovered\nAI model.\u201d These covered models are those that meet one or both of the\nfollowing requirements: (1) the model was trained using a quantity of\ncomputing power greater than 10^26 integer or floating-point operations or (2)\nthe model has similar performance to that of a state-of-the-art foundation\nmodel.\"\n\n\"Safety assessment requirement: Under the Act, developers would be required to\nassess safety before training a \u201ccovered AI model,\u201d ensuring that the models\nare safe and do not pose a risk to public safety or welfare. This involves\nmaking a positive safety determination that the model does not have the\ncapability to enable certain harms, such as the creation of chemical or\nbiological weapons that would result in mass casualties or a cyberattack on\ncritical infrastructure resulting in $500 million or more in damage.\"\n\n\"Third-party model testing: Developers of covered AI models are required to\nimplement a written safety and security protocol which provides sufficient\ndetail for third parties to test the safety of the models they develop.\"\n\n\"Shutdown capability: Under the Act, developers are required to implement a\nshutdown capability for AI models when such models have not obtained a\npositive safety determination. This means that developers must be able to\ndeactivate or restrict the AI model's functionalities until they are able to\nobtain such a determination.\"\n\nThat's from a summary of SB-1047 prepared by the international firm DLA Piper.\nAs one can see, the proposed Act isn't nearly as broad as the alarmists are\nindicating. What's going on here is the industry, having grown accustomed to\nits immunity from liability pursuant to Section 230 of the Communications\nDecency Act, recoiling from an effort to prevent the industry from evading\nliability for damages caused by a limited number of A.I. systems. Indeed, the\nAct proposed in California is limited, distinguishing A.I. systems that have\nthe capability to enable the kind of harm the Act covers. The \"nefarious\"\nactor scenario described in the blog post is a red herring.\n\nRespond\n\n### Terry richards\n\n2024-04-30 05:25:19\n\n17| 5  \n---|---  \n  \nHide Replies\n\n#\n\nWhy not just move AI development to Texas and let Cali continue to commit\nsuicide. Isn\u2019t that the whole point of the bill, to continue the\ncivilizational breakdown?\n\nI mean for god sakes In and Out is shutting down stores in No Cal and many\nretail outlets have put bike locks on the tooth paste.\n\nRespond\n\n### jayson\n\n2024-04-30 06:42:50\n\n8| 3  \n---|---  \n  \nHide Replies\n\n#\n\nThis comment is against the law in the state of California.\n\nRespond\n\n### JWatts\n\n2024-04-30 09:33:12\n\n1| 0  \n---|---  \n  \n#\n\nIt does seem like a lot of Californians are in denial and believe that other\nstates are \"almost\" as bad.\n\nRespond\n\n### Bill Allen\n\n2024-04-30 08:01:29\n\n7| 0  \n---|---  \n  \nHide Replies\n\n#\n\nSB-1047 would essentially shut down the development of open-source AI models\nto the exclusive benefit of large corporations that can afford teams of\nlawyers to deal with the affects of the law. That's actually the biggest\nissue.\n\nRespond\n\n### Marie\n\n2024-04-30 11:35:59\n\n2| 3  \n---|---  \n  \n#\n\nIn practice, this isn't really an issue. The financial costs of the computing\nresources (massive hardware and huge amounts of electrical power) needed to\ntrain a large AI model are absolutely enormous. Any organization that has that\nkind of money has plenty to cover the additional cost of lawyers.\n\nAnd unlike coding labor cannot be substituted by volunteer effort.\n\nRespond\n\n### Kevin\n\n2024-04-30 12:51:49\n\n1| 0  \n---|---  \n  \n#\n\nThat's extremely broad! Chips keep getting better over time. When you set the\nbar to \"10^26 integer operations\", okay it might cost millions of dollars\ntoday, but eventually that sort of power will go into everything.\n\nRespond\n\n### Adam\n\n2024-04-30 06:55:45\n\n219| 2  \n---|---  \n  \n#\n\nTechno narcissism is becoming tiring. Companies aren't using AI. I'm sure\nOpenAI can make a lot of money from creatives but probably far less than what\nthey are expecting with their world domination wet dreams. No smarter than an\noctopus.\n\nRespond\n\n### Marie\n\n2024-04-30 10:42:08\n\n133| 0  \n---|---  \n  \nHide Replies\n\n#\n\nThe problem with the current trend in AI regulation is that it keeps trying to\nregulate \"AI\", rather than what people *do* with AI.\n\nIn most cases, either minor tweaks to existing laws and regulations or\ntransparency requirements would seem to handle most of the cases that are\nconcerning, while still allowing for interesting uses.\n\nE.g. make sure that \"deep fakes\" are properly covered under existing fraud /\nlibel / revenge-porn laws. We already have (pretty good, not perfect)\nmechanisms for dealing with tension between art, free speech, libel, marketing\n... do these really need more than some fine-tuning for the AI case?\n\nE.g. For AI in employment, promotion, admissions, insurance, criminal justice\netc. it is probably sufficient to require transparency with respect to inputs\nand outputs and allow anyone to verify and test the models.\n\nThere are plenty of organizations that will be happy, even eager, to test for\ndiscrimination, stupidity or bugs (if only to discredit rival products..\n\nE.g. for many applications, clarifying ordinary liability should be reasonable\n(e.g. medical decision making).\n\nRespond\n\n### Rajni\n\n2024-04-30 12:35:44\n\n81| 2  \n---|---  \n  \n#\n\n\"The problem with the current trend in AI regulation is that it keeps trying\nto regulate \"AI\", rather than what people *do* with AI. \"\n\nThat's a feature, not a bug. People like you and Dean Ball keep repeating\nwords like 'autonomous' without ever, apparently, understanding what they\nmean. You can't regulate what people \"do\" with dangerous AI because 'people'\nwon't necessarily do anything. The AIs will do things. That's the point!\nThat's the whole point of aiming for A*G*I in the first place! It's not like\n'electricity' and it's not like a 1970s Mac (which couldn't even be hooked up\nto a computer network), because none of those *think for themselves*. Saying\n\"let's just regulate what people will do with AI to prevent harms\" is like\nsaying \"let's just prevent pandemics by holding people liable for each person\nthey infect, that should be reasonable\". You are not living in the real world\nif you think that is either possible or a solution.\n\nRespond\n\n### Vulcidian\n\n2024-04-30 08:05:56\n\n50| 0  \n---|---  \n  \n#\n\nWe've known since feudal days that it's much easier for the government to work\nits power if it grants a monopoly in exchange for a share of the rent. We seem\nto be relying more and more on that and I agree it is a worrying trend.\nJustice would seem to dictate that we allow them the freedom to invent and\nthen punish the bad actors, but that's a lot harder.\n\nTo Tyler's Apple example: Of course no one would found Apple if they were held\nfully responsible for every money-laundering scheme conducted on an Apple\ncomputer (that's basically what's happening with Pornhub and Craigslist).\nHowever, if the government had offered to certify Apple as a monopoly and only\nasked for a percentage of the fraud conducted on their devices as a payment\nthey might have jumped at it.\n\nRespond\n\n### Christopher Johnson\n\n2024-04-30 01:38:49\n\n24| 3  \n---|---  \n  \nHide Replies\n\n#\n\nLooks like typical regulatory capture to me. Basically, the bill requires that\nyou can't just build and release an ML model yourself, you have to have a\nwhole team of lawyers, designers, etc that come up with this \"documentation\"\nto show the system isn't harmful. Read: only big tech and rubber-stamped\nstartups backed by mega-VCs are allowed to develop new models.\n\nIf I had to guess, that flowery language about \"escaping the data center\" is\nlikely just some fluff thrown in to try to convince the non-technical people\nto support the bill.\n\nNearly certain that big tech companies are the driving forces behind this bill\nand the AI doomsayers are simply the useful idiots.\n\nRespond\n\n### OldCurmudgeon\n\n2024-04-30 09:59:22\n\n154| 0  \n---|---  \n  \nHide Replies\n\n#\n\nIDK. I wouldn't worry so much about documentation; open-source communities are\nsurprisingly capable there. The bigger issue is whether any of the CA\nrequirements are inconsistent with the typical open-source licenses (e.g.,\nrequire a warrantee against harm) and/or the LLAMA license. Even a minor\nchange can be a huge PITA in open-source land due to the distributed copyright\nownership.\n\nRespond\n\n### Marie\n\n2024-04-30 11:29:29\n\n2| 0  \n---|---  \n  \n#\n\nNope. Big difference between 'voluntarily providing (hopefully) useful and\naccurate documentation' and 'providing legal binding assurance that\ndocumentation meets complex regulatory standards'.\n\nBut also irrelevant - since any substantial open-source AI would fail to meet\nregulations. Essentially all open-source licenses have a 'no warranty, no\nliability whatsoever, use at your own risk' clause.\n\nWithout that protection, an individual would be stupidly irresponsible\ncontributing to an open-source project (this has historically been an issue\nwrt to open-source implementation of security protocols).\n\nRespond\n\n### ABC\n\n2024-04-30 02:21:36\n\n7| 2  \n---|---  \n  \n#\n\nMuch like how the \u201chigh-speed\u201d rail project is really a jobs program for\nenvironmental and regulatory lawyers shrouded in Central Valley working class\nroll-up-your-bootstraps photo ops and press releases. It\u2019s surprising how\nimpotent big tech is in lobbying and lawyering, given how much they have to\nlose if Sacramento makes it impossible to build the future for the sake of\n\u201cprogress.\u201d\n\nRespond\n\n### Ricardo\n\n2024-04-30 05:55:42\n\n9| 5  \n---|---  \n  \nHide Replies\n\n#\n\nProbably but the issue of algorithms \"escaping\" the data center can be\nreframed to account for the simple fact that once you allow LLMs to call APIs,\ninitiate any sort of internet connection with a third party, or really just\n\"do\" anything aside from send text responses to a user, the risks obviously\ngrow.\n\nWe were stupid about email security and how everyone is getting phishing\nemails or emails with malicious attachments. We were stupid about smartphone\nsecurity and now we have smartphone viruses, malicious apps, and security\nholes. If we are stupid about AI once it goes beyond the realm of chatbots, we\nwill be on the backfoot on a whole other set of security problems.\n\nRespond\n\n### mento\n\n2024-04-30 10:41:36\n\n5| 1  \n---|---  \n  \n#\n\nThese pale against the benefits of the technologies you mention and they\u2019re\nbeing addressed. There will always be crime and malfeasance. Let\u2019s not be\nafraid to cross the street\n\nRespond\n\n### This sounds like it could set a really bad precedent\n\n2024-04-30 01:46:39\n\n11| 2  \n---|---  \n  \nHide Replies\n\n#\n\nFirearms manufacturer are a dynamic and growing part of the American economy,\nbut recently, a couple was sentenced to jail for how they were involved with\ntheir son's school mass murder. Making firearms manufacturers liable for\nillegal deaths would be a horrible idea that is likely completely\nunenforceable.\n\nJust like Boeing cannot guarantee that their airplanes won't crash, there is\nno way that someone creating AI for use in warfare cannot guarantee that it\nwon't end up killing innocent aid workers, or women and children. Why should\nthey be penalized?\n\nAs observed by Andreesen - \u201cOur enemy is the Precautionary Principle.\u201d Normal\npeople define that as the imperative of seeking to prevent and contain certain\npotentially civilization-ending potentialities like nuclear holocaust and\npandemic. Andreessen, conversely, calls precaution \u201cperhaps the most\ncatastrophic mistake in Western society in my lifetime ... deeply immoral, and\nwe must jettison it with extreme prejudice.\u201d\n\nRespond\n\n### Mike in Va\n\n2024-04-30 06:22:07\n\n4| 0  \n---|---  \n  \n#\n\nIf there was not the law the shields gun manufacturers for illegal use of guns\nby the end user, I have no doubt that California would try to pass a law like\nthis requiring gun manufacturers to certify that no nefarious use of guns\nwould occur in California.\n\nRespond\n\n### mento\n\n2024-04-30 02:40:02\n\n7| 7  \n---|---  \n  \n#\n\nAll such bills should have a cost benefit analysis.but this is never done.\nThis reminds me of climate change legislation. where they list catastrophic\nrisks to humanity on one side of the ledger , in order to make appear trivial\nin comparison the economic costs of the legislation.\n\nRespond\n\n### dearieme\n\n2024-04-30 06:30:31\n\n0| 4  \n---|---  \n  \nHide Replies\n\n#\n\n\"Normal people define that as the imperative ...\"\n\nNormal people with common sense dismiss the expression \"the Precautionary\nPrinciple\" as mere windbaggery. There is not and cannot be any general\nPrecautionary Principle.\n\nFor a start, introducing a Precautionary Principle to the world would violate\nthe Precautionary Principle.\n\nRespond\n\n### Mere windbaggery indeed\n\n2024-04-30 06:45:20\n\n1| 1  \n---|---  \n  \n#\n\nWell run laboratories are probably the largest devotees of the precautionary\nprinciple on Earth.\n\nThe hold my beer crowd, on the other hand ....\n\nRespond\n\n### Todd K\n\n2024-04-30 01:52:55\n\n15| 6  \n---|---  \n  \n#\n\nDean Ball has a BA in history. He might have insights into AI but unlikely not\nmore than those who think of AI like Irish historian Tyler Cowen.\n\nRespond\n\n### Famulus\n\n2024-04-30 01:37:39\n\n19| 13  \n---|---  \n  \nHide Replies\n\n#\n\nThis \"small group of people who believe widespread diffusion of AI constitutes\nan existential risk to humanity\" includes the godfathers of Deep Learning\nGeoff Hinton and Yoshua Bengio, Deepmind founder Demis Hassabis, Anthropic\nfounder Dario Amodei, and many other luminaries.\n\nThe last time such a large percentage of the leaders of a field were warning\nabout their tech destroying the world, the threat was nuclear bombs. Sure the\nabsolute numbers are small, but the percentage is what is relevant here.\n\nRespond\n\n### jayson\n\n2024-04-30 06:50:20\n\n9| 2  \n---|---  \n  \nHide Replies\n\n#\n\nRemember when nuclear bombs destroyed the world? That was a bad day.\n\nRespond\n\n### Zach M.\n\n2024-04-30 14:02:46\n\n0| 0  \n---|---  \n  \n#\n\nExactly. Any regulation designed to limit the proliferation of nuclear weapons\nis simply a big-government attempt to strangle small business.\n\nWhy not let nuclear weapons go where the market decides?\n\nRespond\n\n### mento\n\n2024-04-30 02:01:59\n\n8| 11  \n---|---  \n  \nHide Replies\n\n#\n\nI saw an interview with Yoshua Bengio and the AI risks he was worried about\nwere disinformation, troll farms, deep fakes, dangerous cyber attacks ,dark\nweb LLMs tuned for fraud, biological weapons ( new biological compounds found\nby LLMs) and chemical weapons.\n\nIt seems exaggerated to me. At any rate other governments or even terrorists\ncould have these LLMs so the best policy is to counter AI threats if they\nexist with AI, rather than hamstringing ourselves and falling behind, thinking\nthat if our version of AI is bridled, others will be too.\n\nRespond\n\n### Ricardo\n\n2024-04-30 02:45:06\n\n10| 4  \n---|---  \n  \nHide Replies\n\n#\n\nTroll farms, deep fakes, and scams will grow worse with LLMs. Just as we talk\nabout LLMs being used to automate back-office and admin tasks within\nlegitimate companies, they can be used to increase the scale of AI-generated\nspam and scam content.\n\nI expect an arms race with AI-powered scam- and spam-detection tools being\nused to shut these sorts of activities down but then AI-powered tools on the\nother side will seek to circumvent these counter-measures. And, at this point,\nwe need to distinguish LLMs from true AI or AGI. Anything that is intelligent\nby human standards will be able to make itself indistinguishable from a human\nuser and the only countermeasure left will be some sort of (probably real-\nlife) Know Your Customer process for certain platforms that excludes bots\nentirely and also forbids anonymity.\n\nRespond\n\n### Alan\n\n2024-04-30 06:34:24\n\n0| 1  \n---|---  \n  \n#\n\nThus, the Musk style \"need a cc\" requirement for blue checks. Anyone know how\nthat's working re bot elimination? (Genuine question)\n\nRespond\n\n### Eric Auld\n\n2024-04-30 01:22:21\n\n1| 0  \n---|---  \n  \n#\n\nStrong agree.\n\nRespond\n\n### Brian Chau\n\n2024-04-30 13:19:38\n\n1| 0  \n---|---  \n  \n#\n\nConcerning ...\n\nRespond\n\n### Edward Burke\n\n2024-04-30 05:21:37\n\n0| 0  \n---|---  \n  \n#\n\nApplied technology giveth and applied technology taketh away: blessed be the\nname of Applied Technology.\n\nRespond\n\n### patwater\n\n2024-04-30 14:10:24\n\n0| 0  \n---|---  \n  \n#\n\nCommittee votes are bipartisan and overwhelmingly in favor:\n\nSen Governmental Organization Ayes Count 11 Noes Count 0 NVR Count 5\n\nSen Judiciary Ayes Count 9 Noes Count 0 NVR Count 2\n\nRespond\n\nRespond\n\n### Marginal Revolution University\n\nSee Courses\n\n### Learn more about Mercatus Center Fellowships\n\nLearn More\n\n### Subscribe via Email\n\n  * RSS Feed\n\n## Contact Us\n\nAlex Tabarrok Email Alex Follow @atabarrok\n\nTyler Cowen Email Tyler Follow @tylercowen\n\nWebmaster Report an issue\n\n  * Blogs We Like\n  * Interesting People & Sites\n\n## Our Web Pages\n\n  * Alex Tabarrok's Home Page\n  * Alex's TED talk, how ideas trump crises\n  * Conversations with Tyler\n  * FDAReview.org\n  * Tyler Cowen's Personal Web Page\n  * Tyler's ethnic dining guide\n  * Apply to Emergent Ventures\n\n## Books\n\n### Modern Principles of Economics\n\nTyler Cowen & Alexander Tabarrok\n\nMarginal Revolution 2024\n\n  * About Marginal Revolution\n  * Categories\n  * Date Archives\n  * Our Books\n  * Our Textbook: Modern Principles of Economics\n  * Marginal Revolution University\n  *     * Facebook\n    * Twitter\n    * RSS Feed\n  * ### Marginal Revolution University\n\nSee Courses\n\nPrivacy Policy Marginal Revolution 2024\n\n", "frontpage": true}
