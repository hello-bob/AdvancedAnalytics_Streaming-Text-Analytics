{"aid": "40252569", "title": "Show HN: I built a free in-browser Llama 3 chatbot powered by WebGPU", "url": "https://github.com/abi/secret-llama", "domain": "github.com/abi", "votes": 8, "user": "abi", "posted_at": "2024-05-03 21:26:46", "comments": 0, "source_title": "GitHub - abi/secret-llama: Fully private LLM chatbot that runs entirely with a browser with no server needed. Supports Mistral and LLama 3.", "source_text": "GitHub - abi/secret-llama: Fully private LLM chatbot that runs entirely with a\nbrowser with no server needed. Supports Mistral and LLama 3.\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nabi / secret-llama Public\n\n  * Notifications\n  * Fork 0\n  * Star 4\n\nFully private LLM chatbot that runs entirely with a browser with no server\nneeded. Supports Mistral and LLama 3.\n\nsecretllama.com\n\n### License\n\nApache-2.0 license\n\n4 stars 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# abi/secret-llama\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nabiUpdate README.mdMay 3, 20248dc8e1a \u00b7 May 3, 2024May 3, 2024\n\n## History\n\n51 Commits  \n  \n### src\n\n|\n\n### src\n\n| update name| May 3, 2024  \n  \n### .eslintrc.cjs\n\n|\n\n### .eslintrc.cjs\n\n| basic webllm set up and working| May 1, 2024  \n  \n### .gitattributes\n\n|\n\n### .gitattributes\n\n| Initial commit| Apr 30, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| basic webllm set up and working| May 1, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Update LICENSE| May 3, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| Update README.md| May 3, 2024  \n  \n### components.json\n\n|\n\n### components.json\n\n| add shadcn and basic UI to send messages| May 1, 2024  \n  \n### index.html\n\n|\n\n### index.html\n\n| update name| May 3, 2024  \n  \n### package.json\n\n|\n\n### package.json\n\n| add display names and icons for every model| May 3, 2024  \n  \n### postcss.config.js\n\n|\n\n### postcss.config.js\n\n| basic webllm set up and working| May 1, 2024  \n  \n### tailwind.config.js\n\n|\n\n### tailwind.config.js\n\n| render markdown properly| May 2, 2024  \n  \n### tsconfig.json\n\n|\n\n### tsconfig.json\n\n| add shadcn and basic UI to send messages| May 1, 2024  \n  \n### tsconfig.node.json\n\n|\n\n### tsconfig.node.json\n\n| basic webllm set up and working| May 1, 2024  \n  \n### vite.config.ts\n\n|\n\n### vite.config.ts\n\n| add shadcn and basic UI to send messages| May 1, 2024  \n  \n### yarn.lock\n\n|\n\n### yarn.lock\n\n| add display names and icons for every model| May 3, 2024  \n  \n## Repository files navigation\n\n# Secret Llama\n\nEntirely-in-browser, fully private LLM chatbot supporting Llama 3, Mistral and\nother open source models.\n\n  * Fully private = No conversation data ever leaves your computer\n  * Runs in the browser = No server needed and no install needed!\n  * Works offline\n  * Easy-to-use interface on par with ChatGPT, but for open source LLMs\n\nBig thanks to the inference engine provided by webllm.\n\n## System Requirements\n\nTo run this, you need a modern browser with support for WebGPU. According to\ncaniuse, WebGPU is supported on:\n\n  * Google Chrome\n  * Microsoft Edge\n\nIt's also available in Firefox, but it needs to be enabled manually through\nthe dom.webgpu.enabled flag. Safari on MacOS also has experimental support for\nWebGPU which can be enabled through the WebGPU experimental feature.\n\nIn addition to WebGPU support, various models might have specific RAM\nrequirements.\n\n## Try it out\n\nYou can try it here.\n\nTo compile the React code yourself, download the repo and then, run\n\n    \n    \n    yarn yarn build-and-preview\n\nIf you're looking to make changes, run the development environment with live\nreload:\n\n    \n    \n    yarn yarn dev\n\n## Supported models\n\nModel| Model Size  \n---|---  \nTinyLlama-1.1B-Chat-v0.4-q4f32_1-1k| 600MB  \nLlama-3-8B-Instruct-q4f16_1 \u2b50| 4.3GB  \nPhi1.5-q4f16_1-1k| 1.2GB  \nMistral-7B-Instruct-v0.2-q4f16_1 \u2b50| 4GB  \n  \n## Looking for contributors\n\nWe would love contributions to improve the interface, support more models,\nspeed up initial model loading time and fix bugs.\n\n## Other Projects\n\nCheck out screenshot to code and Pico - AI-powered app builder\n\n## About\n\nFully private LLM chatbot that runs entirely with a browser with no server\nneeded. Supports Mistral and LLama 3.\n\nsecretllama.com\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\nActivity\n\n### Stars\n\n4 stars\n\n### Watchers\n\n1 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * TypeScript 84.4%\n  * JavaScript 9.0%\n  * CSS 5.6%\n  * HTML 1.0%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": true}
