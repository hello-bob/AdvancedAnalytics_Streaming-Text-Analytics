{"aid": "40142190", "title": "AI Software Should Be More Like Plain Old Software", "url": "https://www.sigarch.org/ai-software-should-be-more-like-plain-old-software/", "domain": "sigarch.org", "votes": 1, "user": "lbeurerkellner", "posted_at": "2024-04-24 09:12:42", "comments": 0, "source_title": "AI Software Should be More Like Plain Old Software", "source_text": "AI Software Should be More Like Plain Old Software | SIGARCH\n\n  * Home\n  * Join\n  * About\n\n    * Bylaws\n    * Officers\n    * Committees\n    * Reports\n    * Logo\n  * Contact\n\nSelect Page\n\n  * Benefit\n\n    * Awards and Honors\n    * Conferences\n\n      * Sponsored Conferences\n\n        * Guidelines for Sponsorship\n        * List of Sponsored Conferences\n      * Guidelines for Organizers\n\n        * General Chairs\u2019 Packet\n        * Program Chairs\u2019 Packet\n        * Best Practices for PC Chairs\n      * Best Practices for Reviewing Process\n      * PC Database\n    * Grants and Support Programs\n  * Contribute\n\n    * Submit a Call for Contributions\n    * Submit a Call for Participation\n    * Submit an Announcement\n    * Propose a Blog Post Topic\n\n      * Author Guidelines and Policies\n    * Visioning Workshop Proposals\n    * FAQ\n  * Discover\n\n    * Calls for Contributions\n    * Calls for Participation\n    * Announcements\n    * Social Media\n  * CARES\n  * WICARCH\n  * CASA\n  * Blog\n  * Home\n  * Join\n  * About\n\n    * Bylaws\n    * Officers\n    * Committees\n    * Reports\n    * Logo\n  * Contact\n\n# Computer Architecture Today\n\nInforming the broad computing community about current activities, advances and\nfuture directions in computer architecture.\n\n# AI Software Should be More Like Plain Old Software\n\nby Emery Berger and Ben Zorn on Apr 23, 2024 | Tags: Computer Systems, deep neural networks, Machine Learning, Programming\n\nLarge Language Models (LLMs) and other foundation models have revolutionized\nwhat is possible to implement in software. On a regular basis, new AI models\nwith ever greater capabilities, such as converting text to video, are rolled\nout. This disruption is so striking that new terminology is needed. We refer\nto traditional software \u2013 the kind that does not call LLMs at runtime \u2013 as\nPlain Old Software (POSW). We call software that exploits LLMs during\nexecution as AI Software (AISW).\n\nOne key reason we distinguish these two types is that, even though AISW\ngreatly expands the kind of software that is possible to implement, AISW\nrelinquishes the guarantees we have become accustomed to with POSW. Systems\nresearchers have invested decades of effort into ensuring that POSW has\nrobustness, privacy, security, and other guarantees that are implemented\nthroughout the system stack. For example, hardware supports a separation of\ncode and data with an \u201cexecute bit\u201d that can successfully prevent many code\nexploit attacks. But AISW is susceptible to analogous attacks. AISWs are\ndriven by prompts. If a prompt includes both a task description (\u201csummarize\nthis document\u201d) and data (the document itself), AISWs can suffer from a\n\u201cprompt injection\u201d attack because they cannot easily determine if the document\nalso contains additional potentially adversarial commands.\n\nCarrying over the guarantees of POSW to AISW will require engagement and\ninnovation from the research community and other disciplines across computer\nscience including HCI, AI, etc. Only through a deep collaboration between\nthese communities can these challenges be overcome. We outline here some of\nthe implications of the shift from POSW to AISW to inform researchers on the\nneeds and challenges of building a robust AISW infrastructure going forward.\n\nWe believe the familiar system stack that hasn\u2019t changed dramatically in many\ndecades must be reinvented with AISW in mind:\n\nThe parts of this new stack are analogous with the old stack, but also\ndifferent in important ways. The LLM inference engine interfaces the LLM to\nthe stack above it via an interface that includes the prompt context and a\n\u201cgenerate next token\u201d instruction. In traditional hardware, think of the\nprompt context as defining the location of the program counter and the\n\u201cgenerate token\u201d action as executing the next instruction. The AI controller\nmanages what \u201cinstructions\u201d can be executed by explicitly limiting what tokens\nthe LLM is allowed to generate, much as an OS can prevent certain instructions\nin privileged mode. The prompt runtime is a set of services that are used to\ncreate the final prompt sent to the LLM and parse the resulting generation.\nRetrieval Augmented Generation (RAG), where additional content from external\nsources (like documents or the web) is added to the prompt, is an important\npart of every prompt runtime. Validating generations for correctness, when\npossible, is another important element of the prompt runtime.\n\nTo understand how this new stack differs from the old one, consider this\nsimple AISW application that can be implemented in single sentence: \u201cGiven\nthis research paper <attach the paper.pdf> and an organization <name a\nuniversity, program committee, etc.>, give me 5 individuals in that\norganization that would be interested in reading this paper.\u201d\n\nThis \u201cprogram\u201d can be implemented in ChatGPT or other existing LLMs with an\ninteractive chat dialog. Having the user in the loop (who understands the\nstandard disclaimers about hallucinations, etc.) provides a level of\nrobustness to the program making it usable. But such a level of review and\nhuman intervention defeats the purpose of automating such tasks and is only\nnecessary because the infrastructure supporting robust AISW is only starting\nto emerge. Right now, it is not obvious how one would transform this chat\nsession application into a robust service. Our goal is a world where, from the\nperspective of a user, AISW \u201cjust works\u201d like POSW.\n\nTwo key approaches that existing systems use to solve this problem are\nspecification/verification and standardization. Let\u2019s consider each issue in\nturn.\n\nFirst, how do we specify and verify the output of an LLM? Several approaches\nto specifying both the syntax and semantics of LLM generations have been\nproposed and implemented. Constraining the output of an LLM to a particular\nwell-formed syntax has clear value when generations are expected to be in JSON\nformat, for example; this approach is supported by libraries like Pydantic\nValidators. Newly proposed languages like LMQL and Guidance provide \u201cprompt-\nas-programs\u201d approaches that specify constraints over LLM output as well as\nconditional execution paths in prompts, depending on the results produced by a\nprevious round of prompting the LLM. These approaches constitute the evolution\nof the Prompt/Prompt Runtime and AI Controller parts of System Stack 2.0 shown\nabove.\n\nSyntax validation is only a small part of the deeper challenge of specifying\nand verifying constraints on LLM outputs that are not expressible using\nexisting mathematics. How do you measure whether an LLM summary is faithful to\nthe original content, or that an individual would truly be interested in\nreading your paper? These are not new questions and ideas for solutions pre-\ndate the rise of LLMs. More than 10 years ago, the Automan project considered\nhow to leverage crowdsourcing to implement functions that could not be\ncomputed with POSW. The solution acknowledged that the source of information\n(humans in the crowd) was inconsistent and potentially unreliable, much as\nLLMs are today. We believe that increasing the reliability of LLM generations\nwill also involve some of the statistical techniques explored in Automan as\nwell as leveraging potentially many different AI models focusing on different\naspects of correctness. Techniques to go beyond ensuring syntactic constraints\nhave also recently been explored, including the concept of Monitor-Guided\nDecoding (MGD) which uses static analysis to impose semantic constraints on\ngenerations.\n\nStandardization in different layers of a stack allows innovation above and\nbelow the interfaces. We are familiar with existing HW instruction set\narchitectures, like ARM and x86. These standard interfaces have existed and\nsupported incredible changes in the technology both above and below them for\nover 40 years. What are the new standard interfaces for AISW? We believe one\npossible layer in System Stack 2.0 is a token-by-token interface between the\nprompt language runtime and the LLM. While at the level of ChatGPT, we see an\nentire prompt and response from the LLM, the interaction could instead happen\na token at a time. Each time a token is generated, the calling program would\nhave the opportunity to constrain what the LLM can generate.\n\nControlling the LLM at this level in a standard way is the focus of the\nrecently released AI Controller Interface project. For example, using a\ncontroller like AICI, a prompt can specify that the output must be\nsyntactically correct JSON (or any other language specified in a context-free\ngrammar) and guarantee that it is. Similarly, the prompt can request the model\nto extract an exact quote from a document and guarantee that the LLM response\ndoes not hallucinate the output.\n\nWe believe that the co-development of emerging prompt-as-programming\nlanguages, like LMQL; standard interfaces, like AICI; and open source\nimplementations of the underlying AI inference stack (such as the Berkeley\nvLLM project) are emerging technologies that are beginning to define what\nSystem Stack 2.0 will be.\n\nThis is a call to action for the systems community to embrace the importance\nof AISW on the future of systems and to focus effort across the community on\nensuring that we incorporate state-of-the-art design and implementation as\nquickly as possible into these systems. The explosive growth of ChatGPT usage\nillustrates how quickly new AI technology can be invented and deployed. We\nanticipate rapid advances in the AI state-of-the-art going forward, which\nhighlights the need for the systems research community to continue defining\nstrong, durable abstractions around such systems that can form a basis for\nensuring their security, robustness, etc. independently as the models evolve.\n\nAISW will evolve and embed itself increasingly in many aspects of society and,\nas a discipline, the systems research community has a once-in-a-lifetime\nopportunity to ensure that future AISW is even more robust, secure, and safe\nthan our existing POSW.\n\nAbout the Authors: Ben Zorn is a Partner Researcher at Microsoft Research in\nRedmond, Washington working in (and previously having managed) the Research in\nSoftware Engineering (RiSE) group. His research interests include programming\nlanguage design and implementation, end-user programing, and empowering\nindividuals with responsible uses of artificial intelligence. Emery Berger is\na Professor of Computer Science at the University of Massachusetts Amherst and\nan Amazon Scholar. His research interests center around building advanced\nsoftware development tools, and is currently working on harnessing large\nlanguage models to radically improve these tools, including profilers,\ndebuggers, and compilers.\n\nDisclaimer: These posts are written by individual contributors to share their\nthoughts on the Computer Architecture Today blog for the benefit of the\ncommunity. Any views or opinions represented in this blog are personal, belong\nsolely to the blog author and do not represent those of ACM SIGARCH or its\nparent organization, ACM.\n\n### Share this:\n\n  * Facebook\n  * Twitter\n  * LinkedIn\n\n#### Contribute\n\nEditor: Brandon Lucia Associate Editor: Christina Delimitrou\n\nContribute to Computer Architecture Today\n\n#### Recent Blog Posts\n\n  * AI Software Should be More Like Plain Old Software\n  * Building Community: WICARCH In-Person Meetups\n  * The Brain-Computer Interfacing Landscape for Computer Architects\n  * Extending Dataflow Techniques from Dense to Sparse Accelerators\n  * Architecture 2.0 Workshop: How Machine Learning Will Redefine Computer Architecture and Systems\n\n#### Archives\n\n  * April 2024 (2)\n  * January 2024 (1)\n  * December 2023 (3)\n  * November 2023 (2)\n  * October 2023 (2)\n  * September 2023 (2)\n  * August 2023 (4)\n  * July 2023 (3)\n  * June 2023 (5)\n  * May 2023 (3)\n  * March 2023 (1)\n  * January 2023 (3)\n  * December 2022 (2)\n  * November 2022 (1)\n  * October 2022 (2)\n  * September 2022 (4)\n  * August 2022 (8)\n  * July 2022 (5)\n  * June 2022 (2)\n  * May 2022 (7)\n  * April 2022 (5)\n  * March 2022 (1)\n  * February 2022 (2)\n  * January 2022 (4)\n  * December 2021 (1)\n  * November 2021 (2)\n  * October 2021 (2)\n  * September 2021 (5)\n  * August 2021 (4)\n  * July 2021 (4)\n  * June 2021 (8)\n  * May 2021 (4)\n  * April 2021 (4)\n  * March 2021 (1)\n  * February 2021 (8)\n  * January 2021 (2)\n  * December 2020 (5)\n  * November 2020 (5)\n  * October 2020 (6)\n  * September 2020 (3)\n  * August 2020 (2)\n  * July 2020 (4)\n  * June 2020 (5)\n  * May 2020 (6)\n  * April 2020 (4)\n  * March 2020 (6)\n  * February 2020 (2)\n  * January 2020 (2)\n  * December 2019 (3)\n  * November 2019 (6)\n  * October 2019 (3)\n  * September 2019 (5)\n  * August 2019 (6)\n  * July 2019 (5)\n  * June 2019 (4)\n  * May 2019 (5)\n  * April 2019 (5)\n  * March 2019 (4)\n  * February 2019 (5)\n  * January 2019 (4)\n  * December 2018 (3)\n  * November 2018 (3)\n  * October 2018 (4)\n  * September 2018 (4)\n  * August 2018 (4)\n  * July 2018 (6)\n  * June 2018 (4)\n  * May 2018 (7)\n  * April 2018 (7)\n  * March 2018 (6)\n  * February 2018 (4)\n  * January 2018 (7)\n  * December 2017 (4)\n  * November 2017 (4)\n  * October 2017 (6)\n  * September 2017 (6)\n  * August 2017 (2)\n  * July 2017 (4)\n  * June 2017 (6)\n  * May 2017 (6)\n  * April 2017 (4)\n  * March 2017 (2)\n\n#### Tags\n\nAcademia Accelerators ACM SIGARCH Advice Architecture ASPLOS Benchmarks Cloud\ncomputing Conference Conferences Databases Datacenters Distributed Systems\nDiversity Emerging Technology Hardware Industry Interview ISCA Machine\nLearning Measurements Memory Mentoring Methodology Mobile Networking non-\nvolatile Operating Systems Opinion Performance Persistent Policy\nProgrammability Quantum Computing Research Review Reviewing Security\nSpecialization Storage Systems Travel Virtual Meetings Vision Workshop\n\n#### Subscribe\n\n#### Join Us\n\nKeep up-to-date with the latest technical developments, network with\ncolleagues outside your workplace and get cutting-edge information, focused\nresources and unparalleled forums for discussions. Learn more...\n\n#### ACM SIGARCH\n\nSIGARCH serves a unique community of computer professionals working on the\nforefront of computer design in both industry and academia. It is ACM\u2019s\nprimary forum to interchange ideas about tomorrow\u2019s hardware and its\ninteractions with software.\n\n#### ACM SIGARCH\n\nSIGARCH serves a unique community of computer professionals working on the\nforefront of computer design in both industry and academia. It is ACM\u2019s\nprimary forum to interchange ideas about tomorrow\u2019s hardware and its\ninteractions with software.\n\n#### About the Site\n\nThis site is maintained by volunteers working in many programs of ACM SIGARCH.\nWe thank you for visiting! If you have questions about the site, please send a\nnote to our content editor.\n\n", "frontpage": false}
