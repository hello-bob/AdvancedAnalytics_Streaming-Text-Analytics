{"aid": "40050193", "title": "SiLLM \u2013 Silicon LLM Training and Inference Toolkit", "url": "https://github.com/armbues/SiLLM", "domain": "github.com/armbues", "votes": 1, "user": "tosh", "posted_at": "2024-04-16 10:02:01", "comments": 0, "source_title": "GitHub - armbues/SiLLM", "source_text": "GitHub - armbues/SiLLM\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\narmbues / SiLLM Public\n\n  * Notifications\n  * Fork 5\n  * Star 70\n\n### License\n\nMIT license\n\n70 stars 5 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# armbues/SiLLM\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\narmbuesFix support for Command-R+6569b50 \u00b7\n\n## History\n\n252 Commits  \n  \n### app\n\n|\n\n### app\n\n| Add model name and rename step  \n  \n### examples\n\n|\n\n### examples\n\n| Adjusted learning rate  \n  \n### sillm\n\n|\n\n### sillm\n\n| Fix support for Command-R+  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Updating .gitignore  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Initial commit  \n  \n### PUBLISH.md\n\n|\n\n### PUBLISH.md\n\n| Remove files  \n  \n### README.md\n\n|\n\n### README.md\n\n| Update Readme  \n  \n### requirements-server.txt\n\n|\n\n### requirements-server.txt\n\n| Add server requirement  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| Remove files  \n  \n### setup.py\n\n|\n\n### setup.py\n\n| Fix version and name  \n  \n## Repository files navigation\n\n# SiLLM - Silicon LLM Training & Inference Toolkit\n\nSiLLM simplifies the process of training and running Large Language Models\n(LLMs) on Apple Silicon by leveraging the MLX framework. Building upon the\nfoundation provided by MLX Examples, this project introduces additional\nfeatures specifically designed to enhance LLM operations with MLX in a\nstreamlined package.\n\n  * LLM Loading: load LLMs for chat and training in different formats (Huggingface, Torch, GGUF, MLX)\n  * LoRA Training: train LLMs using Low-rank Adaptation\n  * DPO Training: train LLMs with Direct Preference Optimization\n\n## Features\n\n  * Web app for a seamless chat experience running on local hardware\n  * API server with OpenAI compatible chat endpoints\n  * Model architectures: Llama, Mistral, Mixtral, Phi-2, Gemma, Qwen2, Starcoder2, DBRX, Cohere Command-R\n  * Conversation templates: llama-2, chatml, alpaca, vicuna, gemma, phi, openchat\n  * Loss functions for DPO: sigmoid, hinge, IPO, DPOP\n  * Training loss plots using matplotlib\n  * Perplexity calculation\n\n## Installation\n\nUsing pip:\n\n    \n    \n    pip install sillm-mlx\n\n## Usage\n\n### Chat web application\n\nThe web app uses Chainlit to provide a frontend for conversational AI running\nlocally on Apple Silicon hardware.\n\nTo start the web app, clone the repository and start the app using chainlit:\n\n    \n    \n    git clone https://github.com/armbues/SiLLM.git cd SiLLM/app python -m chainlit run app.py -w\n\nSet the environment variables SILLM_MODEL_DIR and SILLM_ADAPTER_DIR to load\nlocal models/adapters.\n\n### Command-line interface (CLI) scripts\n\nRun the CLI scripts with the argument -h to see a print-out of all available\narguments.\n\n#### Chat:\n\nSimple CLI interface for chatting with an LLM in the terminal.\n\n    \n    \n    python -m sillm.chat /path/to/model\n\nRunning sillm.chat in the terminal with Gemma-2B-it on a MacBook Air M2 with\n16GB memory:\n\n#### Server:\n\nRun an API server with basic functionality compatible with OpenAI compatible\nchat endpoints.\n\n    \n    \n    python -m sillm.server /path/to/model --port 8000\n\n#### LoRA Fine-tuning:\n\nFine-tune a model with low-rank adaptation (LoRA).\n\n    \n    \n    python -m sillm.lora /path/to/model -d /path/to/dataset -o /output/adapters\n\n#### DPO Fine-tuning:\n\nFine-tune a model with LoRA and direct preference optimization (DPO).\n\n    \n    \n    python -m sillm.dpo /path/to/model -d /path/to/dataset -o /output/adapters\n\n#### Conversion\n\nConvert a model while merging adapters or quantizing the weights.\n\nExample of merging an adapter into a model:\n\n    \n    \n    python -m sillm.convert /path/to/input/model /path/to/output/model -a /path/to/adapters\n\n#### Quantization\n\nQuantize a model serially (without loading it entirely into memory):\n\n    \n    \n    python -m sillm.quantize /path/to/input/model /path/to/output/model --bits 4\n\n### Python\n\nMinimal example of loading a model with SiLLM and generating a text\ncompletion:\n\n    \n    \n    import sillm model = sillm.load(\"/path/to/model\") for s, _ in model.generate(\"On a beautiful Sunday morning,\"): print(s, flush=True, end=\"\")\n\n### Examples\n\n#### LoRA Fine-tuning\n\nLoRA training Mistral-7B-Instruct-v0.2 with the Nvidia HelpSteer dataset.\n\n#### DPO Fine-tuning\n\nDPO training Qwen1.5-7B-Chat with the DPO Mix 7K dataset. The training\nconsists of a supervised fine tuning (SFT) followed by direct preference\noptimization (DPO).\n\n#### MMLU Benchmark\n\nImplementation of the \"Massive Multitask Language Understanding\" benchmark\nusing the MMLU dataset.\n\n#### Perplexity\n\nCalculating perplexity scores for a sample dataset of entry paragraphs from\nWikipedia articles.\n\n## Model Support\n\nSiLLM generally supports loading LLMs of the following model\narchitectures/families: Llama 2, Mistral, Mixtral, Gemma, Phi, Qwen 2,\nStarCoder2.\n\nHere is a list of models that were successfully tested with SiLLM:\n\nModel Family| Models/Sizes (HF)| Models/Sizes (GGUF)| Models/Sizes (MLX)  \n---|---|---|---  \nLlama-2| 7b-chat.Q8_0, 13b-chat.Q8_0| 7b, 7b-chat  \nMistral v0.2| 7b-instruct-v0.2| 7b-instruct-v0.2.Q8_0  \nMixtral v0.1| 8x7B-Instruct  \nGemma| 2b, 2b-it, 7b, 7b-it  \nPhi-2| 2.7b  \nQwen 1.5| 7b-chat, 14b-chat  \nStarCoder2| 3b, 7b, 15b  \nCodeLlama| 70b-instruct.Q4_0, Phind-34b-v2.Q4_0  \nDBRX| (currently not supported)| dbrx-instruct-4bit  \nCohere| Command-R  \n  \n## Roadmap\n\n  * Repetition penalty for inference\n  * Learning rate schedulers for training\n  * Merging models\n  * Saving models to GGUF\n  * Fine tuning with ORPO\n\n## License\n\nThis project uses the MIT License.\n\n## Acknowledgments\n\nBig thanks to the Apple MLX team for implementing and maintaining the MLX\nframework that makes it possible to unlock the power of Apple Silicon and\nrun/train LLMs on MacBooks and other Apple devices. Thank you to all the\ncontributors of the MLX Examples project and developers sharing model\nimplementations online. Last but not least, thank you to the larger community\nsharing open weights models, fine tunes, and datasets - without you all the\ngen AI progress would happen behind locked doors!\n\n## About\n\nNo description, website, or topics provided.\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\nActivity\n\n### Stars\n\n70 stars\n\n### Watchers\n\n2 watching\n\n### Forks\n\n5 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * Python 96.7%\n  * Jinja 3.3%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
