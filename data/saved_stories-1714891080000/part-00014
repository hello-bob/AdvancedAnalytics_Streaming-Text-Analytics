{"aid": "40261139", "title": "Concurrent Burgers", "url": "https://fastapi.tiangolo.com/pl/async/#concurrent-burgers", "domain": "tiangolo.com", "votes": 1, "user": "rrr_oh_man", "posted_at": "2024-05-04 23:30:08", "comments": 0, "source_title": "Concurrency and async / await - FastAPI", "source_text": "Concurrency and async / await - FastAPI\n\nPrzejd\u017a do tre\u015bci\n\nFollow @fastapi on Twitter to stay updated\n\nSubscribe to the FastAPI and friends newsletter \ud83c\udf89\n\nYou can now sponsor FastAPI \ud83c\udf70\n\nsponsor\n\nsponsor\n\nsponsor\n\nsponsor\n\nsponsor\n\nsponsor\n\nsponsor\n\nsponsor\n\nsponsor\n\n# Concurrency and async / await\u00b6\n\nWarning\n\nThe current page still doesn't have a translation for this language.\n\nBut you can help translating it: Contributing.\n\nDetails about the async def syntax for path operation functions and some\nbackground about asynchronous code, concurrency, and parallelism.\n\n## In a hurry?\u00b6\n\nTL;DR:\n\nIf you are using third party libraries that tell you to call them with await,\nlike:\n\n    \n    \n    results = await some_library()\n\nThen, declare your path operation functions with async def like:\n\n    \n    \n    @app.get('/') async def read_results(): results = await some_library() return results\n\nNote\n\nYou can only use await inside of functions created with async def.\n\nIf you are using a third party library that communicates with something (a\ndatabase, an API, the file system, etc.) and doesn't have support for using\nawait, (this is currently the case for most database libraries), then declare\nyour path operation functions as normally, with just def, like:\n\n    \n    \n    @app.get('/') def results(): results = some_library() return results\n\nIf your application (somehow) doesn't have to communicate with anything else\nand wait for it to respond, use async def.\n\nIf you just don't know, use normal def.\n\nNote: You can mix def and async def in your path operation functions as much\nas you need and define each one using the best option for you. FastAPI will do\nthe right thing with them.\n\nAnyway, in any of the cases above, FastAPI will still work asynchronously and\nbe extremely fast.\n\nBut by following the steps above, it will be able to do some performance\noptimizations.\n\n## Technical Details\u00b6\n\nModern versions of Python have support for \"asynchronous code\" using something\ncalled \"coroutines\", with async and await syntax.\n\nLet's see that phrase by parts in the sections below:\n\n  * Asynchronous Code\n  * async and await\n  * Coroutines\n\n## Asynchronous Code\u00b6\n\nAsynchronous code just means that the language \ud83d\udcac has a way to tell the\ncomputer / program \ud83e\udd16 that at some point in the code, it \ud83e\udd16 will have to wait\nfor something else to finish somewhere else. Let's say that something else is\ncalled \"slow-file\" \ud83d\udcdd.\n\nSo, during that time, the computer can go and do some other work, while \"slow-\nfile\" \ud83d\udcdd finishes.\n\nThen the computer / program \ud83e\udd16 will come back every time it has a chance\nbecause it's waiting again, or whenever it \ud83e\udd16 finished all the work it had at\nthat point. And it \ud83e\udd16 will see if any of the tasks it was waiting for have\nalready finished, doing whatever it had to do.\n\nNext, it \ud83e\udd16 takes the first task to finish (let's say, our \"slow-file\" \ud83d\udcdd) and\ncontinues whatever it had to do with it.\n\nThat \"wait for something else\" normally refers to I/O operations that are\nrelatively \"slow\" (compared to the speed of the processor and the RAM memory),\nlike waiting for:\n\n  * the data from the client to be sent through the network\n  * the data sent by your program to be received by the client through the network\n  * the contents of a file in the disk to be read by the system and given to your program\n  * the contents your program gave to the system to be written to disk\n  * a remote API operation\n  * a database operation to finish\n  * a database query to return the results\n  * etc.\n\nAs the execution time is consumed mostly by waiting for I/O operations, they\ncall them \"I/O bound\" operations.\n\nIt's called \"asynchronous\" because the computer / program doesn't have to be\n\"synchronized\" with the slow task, waiting for the exact moment that the task\nfinishes, while doing nothing, to be able to take the task result and continue\nthe work.\n\nInstead of that, by being an \"asynchronous\" system, once finished, the task\ncan wait in line a little bit (some microseconds) for the computer / program\nto finish whatever it went to do, and then come back to take the results and\ncontinue working with them.\n\nFor \"synchronous\" (contrary to \"asynchronous\") they commonly also use the term\n\"sequential\", because the computer / program follows all the steps in sequence\nbefore switching to a different task, even if those steps involve waiting.\n\n### Concurrency and Burgers\u00b6\n\nThis idea of asynchronous code described above is also sometimes called\n\"concurrency\". It is different from \"parallelism\".\n\nConcurrency and parallelism both relate to \"different things happening more or\nless at the same time\".\n\nBut the details between concurrency and parallelism are quite different.\n\nTo see the difference, imagine the following story about burgers:\n\n### Concurrent Burgers\u00b6\n\nYou go with your crush to get fast food, you stand in line while the cashier\ntakes the orders from the people in front of you. \ud83d\ude0d\n\nThen it's your turn, you place your order of 2 very fancy burgers for your\ncrush and you. \ud83c\udf54\ud83c\udf54\n\nThe cashier says something to the cook in the kitchen so they know they have\nto prepare your burgers (even though they are currently preparing the ones for\nthe previous clients).\n\nYou pay. \ud83d\udcb8\n\nThe cashier gives you the number of your turn.\n\nWhile you are waiting, you go with your crush and pick a table, you sit and\ntalk with your crush for a long time (as your burgers are very fancy and take\nsome time to prepare).\n\nAs you are sitting at the table with your crush, while you wait for the\nburgers, you can spend that time admiring how awesome, cute and smart your\ncrush is \u2728\ud83d\ude0d\u2728.\n\nWhile waiting and talking to your crush, from time to time, you check the\nnumber displayed on the counter to see if it's your turn already.\n\nThen at some point, it finally is your turn. You go to the counter, get your\nburgers and come back to the table.\n\nYou and your crush eat the burgers and have a nice time. \u2728\n\nInfo\n\nBeautiful illustrations by Ketrina Thompson. \ud83c\udfa8\n\nImagine you are the computer / program \ud83e\udd16 in that story.\n\nWhile you are at the line, you are just idle \ud83d\ude34, waiting for your turn, not\ndoing anything very \"productive\". But the line is fast because the cashier is\nonly taking the orders (not preparing them), so that's fine.\n\nThen, when it's your turn, you do actual \"productive\" work, you process the\nmenu, decide what you want, get your crush's choice, pay, check that you give\nthe correct bill or card, check that you are charged correctly, check that the\norder has the correct items, etc.\n\nBut then, even though you still don't have your burgers, your work with the\ncashier is \"on pause\" \u23f8, because you have to wait \ud83d\udd59 for your burgers to be\nready.\n\nBut as you go away from the counter and sit at the table with a number for\nyour turn, you can switch \ud83d\udd00 your attention to your crush, and \"work\" \u23ef \ud83e\udd13 on\nthat. Then you are again doing something very \"productive\" as is flirting with\nyour crush \ud83d\ude0d.\n\nThen the cashier \ud83d\udc81 says \"I'm finished with doing the burgers\" by putting your\nnumber on the counter's display, but you don't jump like crazy immediately\nwhen the displayed number changes to your turn number. You know no one will\nsteal your burgers because you have the number of your turn, and they have\ntheirs.\n\nSo you wait for your crush to finish the story (finish the current work \u23ef /\ntask being processed \ud83e\udd13), smile gently and say that you are going for the\nburgers \u23f8.\n\nThen you go to the counter \ud83d\udd00, to the initial task that is now finished \u23ef, pick\nthe burgers, say thanks and take them to the table. That finishes that step /\ntask of interaction with the counter \u23f9. That in turn, creates a new task, of\n\"eating burgers\" \ud83d\udd00 \u23ef, but the previous one of \"getting burgers\" is finished \u23f9.\n\n### Parallel Burgers\u00b6\n\nNow let's imagine these aren't \"Concurrent Burgers\", but \"Parallel Burgers\".\n\nYou go with your crush to get parallel fast food.\n\nYou stand in line while several (let's say 8) cashiers that at the same time\nare cooks take the orders from the people in front of you.\n\nEveryone before you is waiting for their burgers to be ready before leaving\nthe counter because each of the 8 cashiers goes and prepares the burger right\naway before getting the next order.\n\nThen it's finally your turn, you place your order of 2 very fancy burgers for\nyour crush and you.\n\nYou pay \ud83d\udcb8.\n\nThe cashier goes to the kitchen.\n\nYou wait, standing in front of the counter \ud83d\udd59, so that no one else takes your\nburgers before you do, as there are no numbers for turns.\n\nAs you and your crush are busy not letting anyone get in front of you and take\nyour burgers whenever they arrive, you cannot pay attention to your crush. \ud83d\ude1e\n\nThis is \"synchronous\" work, you are \"synchronized\" with the cashier/cook \ud83d\udc68\ud83c\udf73.\nYou have to wait \ud83d\udd59 and be there at the exact moment that the cashier/cook \ud83d\udc68\ud83c\udf73\nfinishes the burgers and gives them to you, or otherwise, someone else might\ntake them.\n\nThen your cashier/cook \ud83d\udc68\ud83c\udf73 finally comes back with your burgers, after a long\ntime waiting \ud83d\udd59 there in front of the counter.\n\nYou take your burgers and go to the table with your crush.\n\nYou just eat them, and you are done. \u23f9\n\nThere was not much talk or flirting as most of the time was spent waiting \ud83d\udd59 in\nfront of the counter. \ud83d\ude1e\n\nInfo\n\nBeautiful illustrations by Ketrina Thompson. \ud83c\udfa8\n\nIn this scenario of the parallel burgers, you are a computer / program \ud83e\udd16 with\ntwo processors (you and your crush), both waiting \ud83d\udd59 and dedicating their\nattention \u23ef to be \"waiting on the counter\" \ud83d\udd59 for a long time.\n\nThe fast food store has 8 processors (cashiers/cooks). While the concurrent\nburgers store might have had only 2 (one cashier and one cook).\n\nBut still, the final experience is not the best. \ud83d\ude1e\n\nThis would be the parallel equivalent story for burgers. \ud83c\udf54\n\nFor a more \"real life\" example of this, imagine a bank.\n\nUp to recently, most of the banks had multiple cashiers \ud83d\udc68\ud83d\udcbc\ud83d\udc68\ud83d\udcbc\ud83d\udc68\ud83d\udcbc\ud83d\udc68\ud83d\udcbc and a big\nline \ud83d\udd59\ud83d\udd59\ud83d\udd59\ud83d\udd59\ud83d\udd59\ud83d\udd59\ud83d\udd59\ud83d\udd59.\n\nAll of the cashiers doing all the work with one client after the other \ud83d\udc68\ud83d\udcbc\u23ef.\n\nAnd you have to wait \ud83d\udd59 in the line for a long time or you lose your turn.\n\nYou probably wouldn't want to take your crush \ud83d\ude0d with you to do errands at the\nbank \ud83c\udfe6.\n\n### Burger Conclusion\u00b6\n\nIn this scenario of \"fast food burgers with your crush\", as there is a lot of\nwaiting \ud83d\udd59, it makes a lot more sense to have a concurrent system \u23f8\ud83d\udd00\u23ef.\n\nThis is the case for most of the web applications.\n\nMany, many users, but your server is waiting \ud83d\udd59 for their not-so-good\nconnection to send their requests.\n\nAnd then waiting \ud83d\udd59 again for the responses to come back.\n\nThis \"waiting\" \ud83d\udd59 is measured in microseconds, but still, summing it all, it's\na lot of waiting in the end.\n\nThat's why it makes a lot of sense to use asynchronous \u23f8\ud83d\udd00\u23ef code for web APIs.\n\nThis kind of asynchronicity is what made NodeJS popular (even though NodeJS is\nnot parallel) and that's the strength of Go as a programming language.\n\nAnd that's the same level of performance you get with FastAPI.\n\nAnd as you can have parallelism and asynchronicity at the same time, you get\nhigher performance than most of the tested NodeJS frameworks and on par with\nGo, which is a compiled language closer to C (all thanks to Starlette).\n\n### Is concurrency better than parallelism?\u00b6\n\nNope! That's not the moral of the story.\n\nConcurrency is different than parallelism. And it is better on specific\nscenarios that involve a lot of waiting. Because of that, it generally is a\nlot better than parallelism for web application development. But not for\neverything.\n\nSo, to balance that out, imagine the following short story:\n\n> You have to clean a big, dirty house.\n\nYep, that's the whole story.\n\nThere's no waiting \ud83d\udd59 anywhere, just a lot of work to be done, on multiple\nplaces of the house.\n\nYou could have turns as in the burgers example, first the living room, then\nthe kitchen, but as you are not waiting \ud83d\udd59 for anything, just cleaning and\ncleaning, the turns wouldn't affect anything.\n\nIt would take the same amount of time to finish with or without turns\n(concurrency) and you would have done the same amount of work.\n\nBut in this case, if you could bring the 8 ex-cashier/cooks/now-cleaners, and\neach one of them (plus you) could take a zone of the house to clean it, you\ncould do all the work in parallel, with the extra help, and finish much\nsooner.\n\nIn this scenario, each one of the cleaners (including you) would be a\nprocessor, doing their part of the job.\n\nAnd as most of the execution time is taken by actual work (instead of\nwaiting), and the work in a computer is done by a CPU, they call these\nproblems \"CPU bound\".\n\nCommon examples of CPU bound operations are things that require complex math\nprocessing.\n\nFor example:\n\n  * Audio or image processing.\n  * Computer vision: an image is composed of millions of pixels, each pixel has 3 values / colors, processing that normally requires computing something on those pixels, all at the same time.\n  * Machine Learning: it normally requires lots of \"matrix\" and \"vector\" multiplications. Think of a huge spreadsheet with numbers and multiplying all of them together at the same time.\n  * Deep Learning: this is a sub-field of Machine Learning, so, the same applies. It's just that there is not a single spreadsheet of numbers to multiply, but a huge set of them, and in many cases, you use a special processor to build and / or use those models.\n\n### Concurrency + Parallelism: Web + Machine Learning\u00b6\n\nWith FastAPI you can take the advantage of concurrency that is very common for\nweb development (the same main attraction of NodeJS).\n\nBut you can also exploit the benefits of parallelism and multiprocessing\n(having multiple processes running in parallel) for CPU bound workloads like\nthose in Machine Learning systems.\n\nThat, plus the simple fact that Python is the main language for Data Science,\nMachine Learning and especially Deep Learning, make FastAPI a very good match\nfor Data Science / Machine Learning web APIs and applications (among many\nothers).\n\nTo see how to achieve this parallelism in production see the section about\nDeployment.\n\n## async and await\u00b6\n\nModern versions of Python have a very intuitive way to define asynchronous\ncode. This makes it look just like normal \"sequential\" code and do the\n\"awaiting\" for you at the right moments.\n\nWhen there is an operation that will require waiting before giving the results\nand has support for these new Python features, you can code it like:\n\n    \n    \n    burgers = await get_burgers(2)\n\nThe key here is the await. It tells Python that it has to wait \u23f8 for\nget_burgers(2) to finish doing its thing \ud83d\udd59 before storing the results in\nburgers. With that, Python will know that it can go and do something else \ud83d\udd00 \u23ef\nin the meanwhile (like receiving another request).\n\nFor await to work, it has to be inside a function that supports this\nasynchronicity. To do that, you just declare it with async def:\n\n    \n    \n    async def get_burgers(number: int): # Do some asynchronous stuff to create the burgers return burgers\n\n...instead of def:\n\n    \n    \n    # This is not asynchronous def get_sequential_burgers(number: int): # Do some sequential stuff to create the burgers return burgers\n\nWith async def, Python knows that, inside that function, it has to be aware of\nawait expressions, and that it can \"pause\" \u23f8 the execution of that function\nand go do something else \ud83d\udd00 before coming back.\n\nWhen you want to call an async def function, you have to \"await\" it. So, this\nwon't work:\n\n    \n    \n    # This won't work, because get_burgers was defined with: async def burgers = get_burgers(2)\n\nSo, if you are using a library that tells you that you can call it with await,\nyou need to create the path operation functions that uses it with async def,\nlike in:\n\n    \n    \n    @app.get('/burgers') async def read_burgers(): burgers = await get_burgers(2) return burgers\n\n### More technical details\u00b6\n\nYou might have noticed that await can only be used inside of functions defined\nwith async def.\n\nBut at the same time, functions defined with async def have to be \"awaited\".\nSo, functions with async def can only be called inside of functions defined\nwith async def too.\n\nSo, about the egg and the chicken, how do you call the first async function?\n\nIf you are working with FastAPI you don't have to worry about that, because\nthat \"first\" function will be your path operation function, and FastAPI will\nknow how to do the right thing.\n\nBut if you want to use async / await without FastAPI, you can do it as well.\n\n### Write your own async code\u00b6\n\nStarlette (and FastAPI) are based on AnyIO, which makes it compatible with\nboth Python's standard library asyncio and Trio.\n\nIn particular, you can directly use AnyIO for your advanced concurrency use\ncases that require more advanced patterns in your own code.\n\nAnd even if you were not using FastAPI, you could also write your own async\napplications with AnyIO to be highly compatible and get its benefits (e.g.\nstructured concurrency).\n\n### Other forms of asynchronous code\u00b6\n\nThis style of using async and await is relatively new in the language.\n\nBut it makes working with asynchronous code a lot easier.\n\nThis same syntax (or almost identical) was also included recently in modern\nversions of JavaScript (in Browser and NodeJS).\n\nBut before that, handling asynchronous code was quite more complex and\ndifficult.\n\nIn previous versions of Python, you could have used threads or Gevent. But the\ncode is way more complex to understand, debug, and think about.\n\nIn previous versions of NodeJS / Browser JavaScript, you would have used\n\"callbacks\". Which leads to callback hell.\n\n## Coroutines\u00b6\n\nCoroutine is just the very fancy term for the thing returned by an async def\nfunction. Python knows that it is something like a function that it can start\nand that it will end at some point, but that it might be paused \u23f8 internally\ntoo, whenever there is an await inside of it.\n\nBut all this functionality of using asynchronous code with async and await is\nmany times summarized as using \"coroutines\". It is comparable to the main key\nfeature of Go, the \"Goroutines\".\n\n## Conclusion\u00b6\n\nLet's see the same phrase from above:\n\n> Modern versions of Python have support for \"asynchronous code\" using\n> something called \"coroutines\", with async and await syntax.\n\nThat should make more sense now. \u2728\n\nAll that is what powers FastAPI (through Starlette) and what makes it have\nsuch an impressive performance.\n\n## Very Technical Details\u00b6\n\nWarning\n\nYou can probably skip this.\n\nThese are very technical details of how FastAPI works underneath.\n\nIf you have quite some technical knowledge (coroutines, threads, blocking,\netc.) and are curious about how FastAPI handles async def vs normal def, go\nahead.\n\n### Path operation functions\u00b6\n\nWhen you declare a path operation function with normal def instead of async\ndef, it is run in an external threadpool that is then awaited, instead of\nbeing called directly (as it would block the server).\n\nIf you are coming from another async framework that does not work in the way\ndescribed above and you are used to defining trivial compute-only path\noperation functions with plain def for a tiny performance gain (about 100\nnanoseconds), please note that in FastAPI the effect would be quite opposite.\nIn these cases, it's better to use async def unless your path operation\nfunctions use code that performs blocking I/O.\n\nStill, in both situations, chances are that FastAPI will still be faster than\n(or at least comparable to) your previous framework.\n\n### Dependencies\u00b6\n\nThe same applies for dependencies. If a dependency is a standard def function\ninstead of async def, it is run in the external threadpool.\n\n### Sub-dependencies\u00b6\n\nYou can have multiple dependencies and sub-dependencies requiring each other\n(as parameters of the function definitions), some of them might be created\nwith async def and some with normal def. It would still work, and the ones\ncreated with normal def would be called on an external thread (from the\nthreadpool) instead of being \"awaited\".\n\n### Other utility functions\u00b6\n\nAny other utility function that you call directly can be created with normal\ndef or async def and FastAPI won't affect the way you call it.\n\nThis is in contrast to the functions that FastAPI calls for you: path\noperation functions and dependencies.\n\nIf your utility function is a normal function with def, it will be called\ndirectly (as you write it in your code), not in a threadpool, if the function\nis created with async def then you should await for that function when you\ncall it in your code.\n\nAgain, these are very technical details that would probably be useful if you\ncame searching for them.\n\nOtherwise, you should be good with the guidelines from the section above: In a\nhurry?.\n\nThe FastAPI trademark is owned by @tiangolo and is registered in the US and\nacross other regions\n\nMade with Material for MkDocs\n\n", "frontpage": false}
