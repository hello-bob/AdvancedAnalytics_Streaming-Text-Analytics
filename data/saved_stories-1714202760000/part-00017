{"aid": "40173377", "title": "OpenELM's LLM", "url": "https://github.com/CarperAI/OpenELM", "domain": "github.com/carperai", "votes": 3, "user": "kristianpaul", "posted_at": "2024-04-26 19:48:15", "comments": 2, "source_title": "GitHub - CarperAI/OpenELM: Evolution Through Large Models", "source_text": "GitHub - CarperAI/OpenELM: Evolution Through Large Models\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nCarperAI / OpenELM Public\n\n  * Notifications\n  * Fork 62\n  * Star 528\n\nEvolution Through Large Models\n\n### License\n\nMIT license\n\n528 stars 62 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# CarperAI/OpenELM\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n10 Branches\n\n9 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\ndaia99update readme qdaif (#74)Oct 21, 2023c844e14 \u00b7 Oct 21, 2023Oct 21, 2023\n\n## History\n\n124 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| Remove paper and fix github actions (#67)| Jul 10, 2023  \n  \n### docs\n\n|\n\n### docs\n\n| v0.2.0 (#36)| Feb 17, 2023  \n  \n### src/openelm\n\n|\n\n### src/openelm\n\n| enabled load_in_4/8bit with hf models (#73)| Aug 9, 2023  \n  \n### tests\n\n|\n\n### tests\n\n| 0.9 Release (#66)| Jul 10, 2023  \n  \n### trlx_example\n\n|\n\n### trlx_example\n\n| 0.1.5 release (#32)| Dec 23, 2022  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Release/0.2.1 (#45)| Mar 8, 2023  \n  \n### .pre-commit-config.yaml\n\n|\n\n### .pre-commit-config.yaml\n\n| v0.2.0 (#36)| Feb 17, 2023  \n  \n### .readthedocs.yml\n\n|\n\n### .readthedocs.yml\n\n| v0.2.0 (#36)| Feb 17, 2023  \n  \n### CITATION.cff\n\n|\n\n### CITATION.cff\n\n| v0.2.0 (#36)| Feb 17, 2023  \n  \n### CODE_OF_CONDUCT.md\n\n|\n\n### CODE_OF_CONDUCT.md\n\n| Create CODE_OF_CONDUCT.md| Nov 20, 2022  \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n| 0.1.5 release (#32)| Dec 23, 2022  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Add MIT License| Oct 5, 2022  \n  \n### README.md\n\n|\n\n### README.md\n\n| update readme qdaif (#74)| Oct 21, 2023  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| Requirements fix| Jul 10, 2023  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| Requirements fix| Jul 10, 2023  \n  \n### run_elm.py\n\n|\n\n### run_elm.py\n\n| 0.9 Release (#66)| Jul 10, 2023  \n  \n### run_p3.py\n\n|\n\n### run_p3.py\n\n| 0.9 Release (#66)| Jul 10, 2023  \n  \n## Repository files navigation\n\n# OpenELM\n\nOpenELM is an open-source library by CarperAI, designed to enable evolutionary\nsearch with language models in both code and natural language.\n\nThe OpenELM project has the following goals:\n\n  1. Release an open-source version of ELM with its associated diff models.\n  2. Integrate with both open-source language models (run locally or on Colab) and with closed models via paid APIs, such as the OpenAI API. We want to support users with many different compute profiles!\n  3. Provide a simple interface to a range of example environments for evolutionary search, to let users adapt these easily for their domain.\n  4. Demonstrate the potential of evolution with LLMs.\n\nFor QDAIF: poetry domain currently implemented in main, and other experiment\ncode with few-shot LMX domains currently in experimental branch\n\n# Install\n\npip install openelm\n\nTo use the sodarace environment, you must first pip install swig.\n\nThen:\n\npip install openelm[sodaracer]\n\nSee the pyproject.toml for further install options.\n\n# Features\n\n### LLM integration with evolutionary algorithms\n\nOpenELM supports the quality-diversity algorithms MAP-Elites, CVT-MAP-Elites,\nand Deep Grid MAP-Elites, as well as a simple genetic algorithm baseline.\n\n### Evolutionary operators\n\nOpenELM supports:\n\n  1. Prompt-based mutation with instruct models\n  2. Diff models (specialised for code)\n  3. Crossover with language models\n\n### LLM support, efficiency, and safety\n\nOpenELM\u2019s language models are instantiated as Langchain classes by default,\nwhich means that OpenELM can support practically any existing LLM API, as well\nas models run on your local GPU via HuggingFace Transformers.\n\nWe also provide optional Nvidia Triton Inference Server support, intended for\nuse cases where low latency on 8 or more GPUs is important. Finally, for code\ngeneration domains, we provide a sandbox environment, consisting of a\ncontainer server backed with gVisor (a container runtime that introduces an\nadditional barrier between the host and the container) as well as a heuristic-\nbased safety guard.\n\n### Baseline environments\n\n  1. Sodarace. A 2D physics-based simulation of robots moving across a variety of terrains. These robots are created by Python programs generated from an LLM.\n  2. Image Generation. OpenELM can evolve over generated images by generating code that returns NumPy arrays containing the images. This serves as a simple test environment for code generation\n  3. Programming Puzzles. OpenELM can be used to generate diverse solutions to programming puzzles. This environment supports co-evolution of both the problem and the solution at the same time.\n  4. Prompts. OpenELM contains a generic environment suitable for evolving prompts for language models, customizable with Langchain templates to the desired domain.\n  5. We also include a poetry environment, demonstrating the use of LLMs to evaluate both the quality and diversity of generated creative writing text, as described in a recent CarperAI blog post on Quality-Diversity with AI Feedback (QDAIF).\n\n## Architecture\n\nRoughly, ELM consists of a pipeline of different components:\n\n  1. The Environment class. This class defines the mechanics of how to initialize members of the population, mutate them with the desired operator, and how to measure the fitness (and diversity) of individuals.\n  2. The MAPElites class. This class describes how the evolutionary algorithm works, and can be viewed as a wrapper around the environment defining the selection algorithm for generated individuals.\n  3. The MutationModel class, which is responsible for running the LLM to actually generate new individuals. This functions as a wrapper around the LangChain API. The environment is expected to call the MutationModel when a new individual is needed.\n  4. The ELM class calls the MAPElites algorithm class and runs the search.\n\nAll options for these classes are defined in configs.py, via dataclasses which\nare registered as a hydra config, and can be overriden via the command line\nwhen running one of the example scripts such as run_elm.py.\n\n## Running ELM\n\npython run_elm.py will start an ELM evolutionary search using the defaults\nlisted in configs.py. These can be overriden via the command line. For\nexample, you can use run_elm.py env=image_evolution to run the Image Evolution\nenvironment.\n\n## Sandbox\n\nTo use the code execution sandbox, see the sandboxing readme for instructions\nto set it up in a Docker container with the gVisor runtime.\n\n## Triton\n\nWe also have code available to run models in Nvidia's Triton Inference Server.\nSee the Triton Readme to get started\n\n# Contributing\n\nIf you'd like to contribute or have questions, go to the #openelm channel on\nthe CarperAI discord!\n\n## About\n\nEvolution Through Large Models\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\n### Code of conduct\n\nCode of conduct\n\n### Citation\n\nActivity\n\nCustom properties\n\n### Stars\n\n528 stars\n\n### Watchers\n\n23 watching\n\n### Forks\n\n62 forks\n\nReport repository\n\n## Releases 6\n\nv0.2.1 Latest\n\nMar 8, 2023\n\n\\+ 5 releases\n\n## Contributors 16\n\n\\+ 2 contributors\n\n## Languages\n\n  * Python 99.8%\n  * Other 0.2%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
