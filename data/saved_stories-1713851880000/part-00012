{"aid": "40117007", "title": "Runhouse", "url": "https://github.com/run-house/runhouse", "domain": "github.com/run-house", "votes": 1, "user": "fzliu", "posted_at": "2024-04-22 18:09:09", "comments": 0, "source_title": "GitHub - run-house/runhouse: The fastest way to iterate and deploy AI workloads on your own infra. Unobtrusive, debuggable, PyTorch-like APIs.", "source_text": "GitHub - run-house/runhouse: The fastest way to iterate and deploy AI\nworkloads on your own infra. Unobtrusive, debuggable, PyTorch-like APIs.\n\n## Navigation Menu\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nrun-house / runhouse Public\n\n  * Notifications\n  * Fork 32\n  * Star 708\n\nThe fastest way to iterate and deploy AI workloads on your own infra.\nUnobtrusive, debuggable, PyTorch-like APIs.\n\nrun.house\n\n### License\n\nApache-2.0 license\n\n708 stars 32 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# run-house/runhouse\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n71 Branches\n\n23 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nrohinb2Add logging statement when there is a None actor. (#740)Apr 19,\n2024b1d2bf0 \u00b7 Apr 19, 2024Apr 19, 2024\n\n## History\n\n1,328 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| Dynamically set API_SERVER_URL (#708)| Apr 12, 2024  \n  \n### docker\n\n|\n\n### docker\n\n| Change Caddy installation to download from Github. (#702)| Apr 4, 2024  \n  \n### docs\n\n|\n\n### docs\n\n| support for saving resources on behalf of an org (#676)| Apr 16, 2024  \n  \n### examples\n\n|\n\n### examples\n\n| Llama3 README update. (#744)| Apr 18, 2024  \n  \n### runhouse\n\n|\n\n### runhouse\n\n| Add logging statement when there is a None actor. (#740)| Apr 19, 2024  \n  \n### scripts\n\n|\n\n### scripts\n\n| Remove notebooks and reorganize rst folders (#510)| Feb 23, 2024  \n  \n### tests\n\n|\n\n### tests\n\n| Make env_servlets cache an instance field instead of global. (#736)| Apr 16,\n2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Update the Docker test setup (#122)| Oct 18, 2023  \n  \n### .pre-commit-config.yaml\n\n|\n\n### .pre-commit-config.yaml\n\n| Move ruff config to pyproject.toml. (#558)| Mar 5, 2024  \n  \n### .readthedocs.yaml\n\n|\n\n### .readthedocs.yaml\n\n| update docs build| Jun 7, 2023  \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n| Update contributing for notebook files (#513)| Feb 23, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| A new start| Dec 9, 2022  \n  \n### MANIFEST.in\n\n|\n\n### MANIFEST.in\n\n| Move scripts and docker out of source folder (#360)| Jan 23, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| Fix emoji (#580)| Mar 7, 2024  \n  \n### collect_env.py\n\n|\n\n### collect_env.py\n\n| Remove sshtunnel from package dependencies, keep in [aws] for sagem...| Mar\n21, 2024  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| Make asyncio event loop session-scoped for tests. (#696)| Apr 2, 2024  \n  \n### pytest.ini\n\n|\n\n### pytest.ini\n\n| Split up envtest to improve parallelism in CI further. (#488)| Feb 14, 2024  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| Remove sshtunnel from package dependencies, keep in [aws] for sagem...| Mar\n21, 2024  \n  \n### setup.py\n\n|\n\n### setup.py\n\n| Add native async support client side. (#690)| Apr 9, 2024  \n  \n## Repository files navigation\n\n# \ud83c\udfc3\u2640\ufe0fRunhouse\ud83c\udfe0\n\n## \ud83d\udc75 Welcome Home!\n\nRunhouse is the fastest way to build, run, and deploy production-quality AI\napps and workflows on your own compute. Leverage simple, powerful APIs for the\nfull lifecycle of AI development, through\nresearch\u2192evaluation\u2192production\u2192updates\u2192scaling\u2192management, and across any\ninfra.\n\nBy automatically packaging your apps into scalable, secure, and observable\nservices, Runhouse can also turn otherwise redundant AI activities into common\nreusable components across your team or company, which improves cost,\nvelocity, and reproducibility.\n\nHighlights:\n\n  * \ud83d\udc69\ud83d\udd2c Dispatch Python functions, classes, and data to remote infra (clusters, cloud VMs, etc.) instantly. No need to reach for a workflow orchestrator to run different chunks of code on various beefy boxes.\n  * \ud83d\udc77\u2640\ufe0f Deploy Python functions or classes as production-quality services instantly, including HTTPS, auth, observability, scaling, custom domains, secrets, versioning, and more. No research-to-production gap.\n  * \ud83d\udc0d No DSL, decorators, yaml, CLI incantations, or boilerplate. Just your own Python.\n  * \ud83d\udc69\ud83c\udf93 Extensive support for Ray, Kubernetes, AWS, GCP, Azure, local, on-prem, and more. When you want to shift or scale, just send your app to more powerful infra.\n  * \ud83d\udc69\ud83d\ude80 Extreme reusability and portability. A single succinct script can stand up your app, dependencies, and infra.\n  * \ud83d\udc69\ud83c\udf73 Arbitrarily nest applications to create complex workflows and services. Apps are decoupled so you can change, move, or scale any component without affecting the rest of your system.\n\nThe Runhouse API is dead simple. Send your apps (functions and classes) into\nenvironments on compute infra, like this:\n\n    \n    \n    import runhouse as rh from diffusers import StableDiffusionPipeline def sd_generate(prompt, **inference_kwargs): model = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-base\").to(\"cuda\") return model(prompt, **inference_kwargs).images if __name__ == \"__main__\": gpu = rh.cluster(name=\"rh-a10x\", instance_type=\"A10G:1\", provider=\"aws\") sd_env = rh.env(reqs=[\"torch\", \"transformers\", \"diffusers\"], name=\"sd_generate\", working_dir=\"./\") # Deploy the function and environment (syncing over local code changes and installing dependencies) remote_sd_generate = rh.function(sd_generate).to(gpu, env=sd_env) # This call is actually an HTTP request to the app running on the remote server imgs = remote_sd_generate(\"A hot dog made out of matcha.\") imgs[0].show() # You can also call it over HTTP directly, e.g. from other machines or languages print(remote_sd_generate.endpoint())\n\nWith the above simple structure you can run, deploy, and share:\n\n  * \ud83d\udee0\ufe0f AI primitives: Preprocessing, training, fine-tuning, evaluation, inference\n  * \ud83d\ude80 Higher-order services: Multi-stage inference (e.g. RAG), e2e workflows\n  * \ud83e\uddba Controls and safety: PII obfuscation, content moderation, drift detection\n  * \ud83d\udcca Data services: ETL, caching, data augmentation, data validation\n\n## \ud83d\udecb\ufe0f Share Apps and Resources with Runhouse Den\n\nYou can unlock unique portability and sharing features by creating a Runhouse\nDen account. Log in from anywhere to save, share, and load resources:\n\n    \n    \n    runhouse login\n\nor from Python:\n\n    \n    \n    import runhouse as rh rh.login()\n\nExtending the example above to share and load our app via Den:\n\n    \n    \n    remote_sd_generate.share([\"my_pal@email.com\"]) # The service stub can now be reloaded from anywhere, always at yours and your collaborators' fingertips # Notice this code doesn't need to change if you update, move, or scale the service remote_sd_generate = rh.function(\"/your_username/sd_generate\") imgs = remote_sd_generate(\"More matcha hotdogs.\") imgs[0].show()\n\n## \ud83c\udfd7\ufe0f Supported Compute Infra\n\nPlease reach out (first name at run.house) if you don't see your favorite\ncompute here.\n\n  * Local - Supported\n  * Single box - Supported\n  * Ray cluster - Supported\n  * Kubernetes (K8S) - Supported\n  * Amazon Web Services (AWS)\n\n    * EC2 - Supported\n    * EKS - Supported\n    * SageMaker - Supported\n    * Lambda - Alpha\n  * Google Cloud Platform (GCP)\n\n    * GCE - Supported\n    * GKE - Supported\n  * Microsoft Azure\n\n    * VMs - Supported\n    * AKS - Supported\n  * Lambda Labs - Supported\n  * Modal Labs - Planned\n  * Slurm - Exploratory\n\n## \ud83d\udc68\ud83c\udfeb Learn More\n\n\ud83d\udc23 Getting Started: Installation, setup, and a quick walkthrough.\n\n\ud83d\udcd6 Docs: Detailed API references, basic API examples and walkthroughs, end-to-\nend tutorials, and high-level architecture overview.\n\n\ud83c\udfaa Funhouse: Standalone ML apps and examples to try with Runhouse, like image\ngeneration models, LLMs, launching Gradio spaces, and more!\n\n\ud83d\udc69\ud83d\udcbb Blog: Deep dives into Runhouse features, use cases, and the future of AI\ninfra.\n\n\ud83d\udc7e Discord: Join our community to ask questions, share ideas, and get help.\n\nX Twitter: Follow us for updates and announcements.\n\n## \ud83d\ude4b\u2642\ufe0f Getting Help\n\nMessage us on Discord, email us (first name at run.house), or create an issue.\n\n## \ud83d\udc77\u2640\ufe0f Contributing\n\nWe welcome contributions! Please check out contributing if you're interested.\n\n## About\n\nThe fastest way to iterate and deploy AI workloads on your own infra.\nUnobtrusive, debuggable, PyTorch-like APIs.\n\nrun.house\n\n### Topics\n\npython api infrastructure aws middleware data-science machine-learning\ndeployment serverless azure gcp collaboration pytorch distributed artificial-\nintelligence ray observability sagemaker fastapi\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\nActivity\n\nCustom properties\n\n### Stars\n\n708 stars\n\n### Watchers\n\n7 watching\n\n### Forks\n\n32 forks\n\nReport repository\n\n## Releases 23\n\nv0.0.25 Latest\n\nApr 16, 2024\n\n\\+ 22 releases\n\n## Packages 0\n\nNo packages published\n\n## Contributors 12\n\n## Languages\n\n  * Python 97.9%\n  * Other 2.1%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
