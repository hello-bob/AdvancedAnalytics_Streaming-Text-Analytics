{"aid": "40178754", "title": "Large language models (e.g., ChatGPT) as research assistants", "url": "https://lemire.me/blog/2024/04/27/large-language-models-e-g-chatgpt-as-research-assistants/", "domain": "lemire.me", "votes": 3, "user": "leononame", "posted_at": "2024-04-27 10:01:03", "comments": 0, "source_title": "Large language models (e.g., ChatGPT) as research assistants", "source_text": "Large language models (e.g., ChatGPT) as research assistants \u2013 Daniel Lemire's\nblog\n\nSkip to content\n\nDaniel Lemire's blog\n\nDaniel Lemire is a computer science professor at the Data Science Laboratory\nof the Universit\u00e9 du Qu\u00e9bec (T\u00c9LUQ) in Montreal. His research is focused on\nsoftware performance.\n\n## Support my work!\n\nI do not accept any advertisement. However, you can you can sponsor my open-\nsource work on GitHub.\n\nJoin over 12,500 email subscribers:\n\nYou can follow this blog on telegram. You can find me on twitter as @lemire or\non Mastodon.\n\n## Recent Posts\n\n## Recent Comments\n\n## Pages\n\n## Archives\n\n## Boring stuff\n\n# Large language models (e.g., ChatGPT) as research assistants\n\nSoftware can beat human beings at most games... from Chess to Go, and even\npoker. Large language models like GPT-4 offered through services such as\nChatGPT allow us to solve a new breed of problems. GPT-4 can beat 90% of human\nbeings at the bar exam. Artificial intelligence can match math Olympians.\n\nThe primary skills of academics are language-related: synthesis, analogy,\nextrapolation, etc. Academics analyze the literature, identify gaps, and\nformulate research questions. They review and synthesize existing research.\nThey write research papers, grant proposals, and reports. Being able to\nproduce well-structured and grammatically correct prose is a vital skill for\nacademics.\n\nUnsurprisingly, software and artificial intelligence can help academics, and\nmaybe replace them in some cases. Liang et al. found that an increasing number\nof research papers are written with tools like GPT-4 (up to 18% in some\nfields). It is quite certain that in the near future, a majority of all\nresearch papers will be written with the help of artificial intelligence. I\nsuspect that they will be reviewed with artificial intelligence as well. We\nmight soon face a closed loop where software writes papers while other\nsoftware reviews it.\n\nI encourage scholars to apply artificial intelligence immediately for tasks\nsuch as...\n\n  1. Querying a document. A tool like BingChat from Microsoft allows you to open a PDF document and query it. You may ask \u201cwhat are the main findings of this study?\u201d or \u201care there any practical applications for this work?\u201d.\n  2. Improve text. Many academics, like myself, use English as a second language. Of course, large language models can translate, but they can also improve your wording. It is more than a mere grammar checker: it can rewrite part of your text, correcting bad usages as it goes.\n  3. Idea generation. I used to spend a lot of time chatting with colleagues about a vague idea I had. \u201cHow could we check whether X is true?\u201d A tool like ChatGPT can help you get started. If you ask how to design an experiment to check a given hypothesis, it can often do a surprisingly good job.\n  4. Grant applications. You can use tools like ChatGTP to help you with grant applications. Ask it to make up short-term and long-term objectives, sketch a methodology and discuss the impact of your work... it will come up with something credible right away. It is likely that thousands of grant applications have been written with artificial intelligence.\n  5. Writing code. You are not much of a programmer, but you want an R script that will load data from your Excel spreadsheet and do some statistical analysis? ChatGPT will do it for you.\n  6. Find reviewers and journals. Sometimes you have done some work and you would like help picking the right journal, a tool like ChatGPT can help. If a student of yours finished their thesis, ChatGPT can help you identify prospective referees.\n\nI suspect that much academic work will soon greatly benefit from artificial\nintelligence to the point where a few academics will be able to do the work\nthat required an entire research institute in the past.\n\nAnd this new technology should mediocre academics even less useful, relatively\nspeaking. If artificial intelligence can write credible papers and grant\napplications, what is the worth of someone who can barely do these things?\n\nYou would think that these technological advances should accelerate progress.\nBut, as argued by Patrick Collison and Michael Nielsen, science productivity\nhas been falling despite all our technological progress. Physics is not\nadvancing faster today than it did in the first half of the XXth century. It\nmay even be stagnant in relative terms. I do not think that we should hastily\nconclude that ChatGPT will somehow accelerate the rate of progress in Physics.\nAs Clusmann et al. point out: it may simply ease scientific misconduct. We\ncould soon be drowning in a sea of automatically generated documents. Messeri\nand Crockett put it elegantly:\n\n> AI tools in science risks introducing a phase of scientific enquiry in which\n> we produce more but understand less\n\nYet there are reasons to be optimistic. By allowing a small group of\nresearchers to be highly productive, by freeing them to explore further with\nless funding, we could be on the verge of entering into a new era of\nscientific progress. However, it may not be directly measurable using our\nconventional tools. It may not appear as more highly cited papers or through\nlarge grants. A good illustration is Hugging Face, a site where thousands of\nengineers from all over the world explore new artificial-intelligence models.\nThis type of work is undeniably scientific research: we have metrics,\nhypotheses, testing, reproducibility, etc. However, it does not look like\n\u2018academic work\u2019.\n\nIn any case, conventional academics will be increasingly challenged.\nIronically, plumbers and electricians won\u2019t be so easily replaced, a fact\nsometimes attributed to the Moravec paradox. Steven Pinker wrote in 1994 that\ncooks and gardeners are secured in their jobs for decades to come, unlike\nstock market analysis and engineers. But I suspect that the principle even\nextends within the academy: some work, like conducting actual experiments, is\nharder to automate than producing and running models. The theoretical work is\nlikely more impacted by intelligence artificial than more applied, concrete\nwork.\n\nNote: This blog post was not written with artificial intelligence. Expect\ntypos and grammatical mistakes.\n\nDaniel Lemire, \"Large language models (e.g., ChatGPT) as research assistants,\"\nin Daniel Lemire's blog, April 27, 2024.\n\n## Published by\n\n### Daniel Lemire\n\nA computer science professor at the University of Quebec (TELUQ). View all\nposts by Daniel Lemire\n\nPosted on April 27, 2024April 27, 2024Author Daniel LemireCategories\n\n### Leave a Reply Cancel reply\n\nYou may subscribe to this blog by email.\n\nTerms of use Proudly powered by WordPress\n\n", "frontpage": true}
