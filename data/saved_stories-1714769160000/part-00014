{"aid": "40247993", "title": "Paramount is an OSS package for LLM regression testing using expert feedback", "url": "https://github.com/ask-fini/paramount", "domain": "github.com/ask-fini", "votes": 2, "user": "hakimk", "posted_at": "2024-05-03 14:22:37", "comments": 0, "source_title": "GitHub - ask-fini/paramount: Agent accuracy measurements for LLMs", "source_text": "GitHub - ask-fini/paramount: Agent accuracy measurements for LLMs\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nask-fini / paramount Public\n\n  * Notifications\n  * Fork 0\n  * Star 42\n\nAgent accuracy measurements for LLMs\n\n### License\n\nView license\n\n42 stars 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# ask-fini/paramount\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n2 Branches\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nhakimkhalafiREADME updateMay 3, 20249e9a4ce \u00b7 May 3, 2024May 3, 2024\n\n## History\n\n173 Commits  \n  \n### paramount\n\n|\n\n### paramount\n\n| add builds| Apr 22, 2024  \n  \n### .dockerignore\n\n|\n\n### .dockerignore\n\n| adjust Dockerfiles & let flask serves the static files of the client| Mar\n13, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| include dist| Mar 15, 2024  \n  \n### Dockerfile.client\n\n|\n\n### Dockerfile.client\n\n| adjust Dockerfiles & let flask serves the static files of the client| Mar\n13, 2024  \n  \n### Dockerfile.server\n\n|\n\n### Dockerfile.server\n\n| adjust Dockerfiles & let flask serves the static files of the client| Mar\n13, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Update LICENSE| Mar 13, 2024  \n  \n### MANIFEST.in\n\n|\n\n### MANIFEST.in\n\n| fix CLI| Mar 15, 2024  \n  \n### Makefile\n\n|\n\n### Makefile\n\n| adjust Dockerfiles & let flask serves the static files of the client| Mar\n13, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| README update| May 3, 2024  \n  \n### example.py\n\n|\n\n### example.py\n\n| put example| Apr 17, 2024  \n  \n### paramount.toml.example\n\n|\n\n### paramount.toml.example\n\n| Fix allow empty chat| Apr 11, 2024  \n  \n### setup.py\n\n|\n\n### setup.py\n\n| 0.4.0| Apr 22, 2024  \n  \n### usage.gif\n\n|\n\n### usage.gif\n\n| README update| May 3, 2024  \n  \n## Repository files navigation\n\n## paramount\n\nParamount lets your expert agents evaluate AI chats, enabling:\n\n  * quality assurance\n  * ground truth capturing\n  * automated regression testing\n\n### Usage\n\n### Getting Started\n\n  1. Install the package:\n\n    \n    \n    pip install paramount\n\n  2. Decorate your AI function:\n\n    \n    \n    @paramount.record() def my_ai_function(message_history, new_question): # Inputs # <LLM invocations happen here> new_message = {'role': 'user', 'content': new_question} updated_history = message_history + [new_message] return updated_history # Outputs.\n\n  3. After my_ai_function(...) has run several times, launch the Paramount UI to evaluate results:\n\n    \n    \n    paramount\n\nYour SMEs can now evaluate recordings and track accuracy improvements over\ntime.\n\nParamount runs completely offline in your private environment.\n\n### Usage\n\nAfter installation, run python example.py for a minimal working example.\n\n### Configuration\n\nIn order to set up successfully, define which input and output parameters\nrepresent the chat list used in the LLM.\n\nThis is done via the paramount.toml configuration file that you add in your\nproject root dir.\n\nIt will be autogenerated for you with defaults if it doesn't already exist on\nfirst run.\n\n    \n    \n    [record] enabled = true function_url = \"http://localhost:9000\" # The url to your LLM API flask app, for replay [db] type = \"csv\" # postgres also available [db.postgres] connection_string = \"\" [api] endpoint = \"http://localhost\" # url and port for paramount UI/API port = 9001 split_by_id = false # In case you have several bots and want to split them by ID identifier_colname = \"\" [ui] # These are display elements for the UI # For the table display - define which columns should be shown meta_cols = ['recorded_at'] input_cols = ['args__message_history', 'args__new_question'] # Matches my_ai_function() example output_cols = ['1', '2'] # 1 and 2 are indexes for llm_answer and llm_references in example above # For the chat display - describe how your chat structure is set up. This example uses OpenAI format. chat_list = \"output__1\" # Matches output updated_history. Must be a list of dicts to display chat format chat_list_role_param = \"role\" # Key in list of dicts describing the role in the chat chat_list_content_param = \"content\" # Key in list of dicts describing the content\n\nIt is also possible to describe references via config but is not shown here\nfor simplicity.\n\nSee paramount.toml.example for more info.\n\n#### For Developers\n\nThe deeper configuration instructions about the client & server can be seen\nhere.\n\n### Docker\n\nBy using Dockerfile.server, you can containerize and deploy the whole package\n(including the client).\n\nWith Docker, you will need to mount the paramount.toml file dynamically into\nthe container for it to work.\n\n    \n    \n    docker build -t paramount-server -f Dockerfile.server . # or make docker-build-server docker run -dp 9001:9001 paramount-server # or make docker-run-server\n\n### License\n\nThis project is under GPL License for individuals. Companies with >1000\ninvocations per month or >100 employees require a commercial license.\n\n## About\n\nAgent accuracy measurements for LLMs\n\n### Resources\n\nReadme\n\n### License\n\nView license\n\nActivity\n\nCustom properties\n\n### Stars\n\n42 stars\n\n### Watchers\n\n1 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Contributors 2\n\n  * hakimkhalafi\n  * mrcn04 \u00d6m\u00fcrcan Cengiz\n\n## Languages\n\n  * TypeScript 63.2%\n  * Python 32.8%\n  * CSS 2.0%\n  * JavaScript 1.2%\n  * Other 0.8%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
