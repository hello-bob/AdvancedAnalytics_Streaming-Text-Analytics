{"aid": "40062791", "title": "Seeking faster video rendering with HTMLVideoElement", "url": "https://re.video/blog/seeking", "domain": "re.video", "votes": 1, "user": "justusm", "posted_at": "2024-04-17 10:45:26", "comments": 0, "source_title": "Revideo", "source_text": "Revideo\n\nEngineering\n\nSeeking faster video rendering with HTMLVideoElement\n\nHow we got rid of the bottleneck in our video rendering pipeline.\n\n\ud83d\udca1\n\nRevideo is a typescript framework to create videos with code. People use\nRevideo to create Tiktoks/ Youtube Shorts, ads or demo videos\nprogrammatically. Revideo is MIT licensed and will stay that way. We plan to\nmonetize it down the line by building additional tooling around the open-\nsource framework.\n\nWe\u2019re building Revideo on top of Motion Canvas, an animation library, which in\nturn wraps the canvas API of the browser. This gives us a strong foundation to\nbuild on top of but also comes with its downsides. While the canvas API is a\nvery powerful way to compose different elements into a scene, there are some\nthings that canvas is not meant for, which we need to work around.\n\nWhen making videos with Revideo, a common use-case is to take an already\nexisting video file, and lay it down as part of a scene. The way this works is\nthrough an HTMLVideoElement which can then fairly easily be projected onto the\ncanvas. This is highly optimized and works great for normal playback, which we\nuse when previewing a scene. When rendering the final videos, however, we\nnoticed an increasing render-time per frame as the render progressed. Few\nseconds into the render we went from 30ms per frame all the way up to 700ms!\n\nCharting the time taken per frame we can see just how regular the increase in\ntime per frame is over time. This is the render-time per frame for a video\nthat is 30s long in which we show a Minecraft jump-and-run video without any\nadditional objects inside the scene.\n\nTo understand where this lag comes from, we dove into the code to identify\nwhat we\u2019re spending all this time on. Looking at the flame chart of the render\nprocess, we can see that Javascript is not actually doing that much between\nframes. This told us that what we\u2019re looking for is an IO process which taking\nall this time to wrap up, so JS can go back to work.\n\nDigging deeper into the call stack, we identified the culprit. Unlike playback\ninside the web-preview, we don\u2019t just play the video back when rendering to an\nmp4. Some frames might take longer to process than others, and for simple\nscenes without video-in-video, the process usually even surpasses real-time.\nIn order to keep the video lined up with the rest of the scene, we instead set\nthe current time of the HTMLVideo tag for each frame. An operation that is\nincredibly slow as it seeks through the entire mp4 file for every (!!!) frame,\nmaking it more and more costly as the video goes on. Bingo!\n\nAfter trying different settings for our video tag, we were left stumped. The\nbrowser seems to discard all of its prior decoding work every time the\ncurrentTime value is reassigned. This obviously doesn\u2019t need to be the case.\nAfter all, stepping through a video frame by frame is what video encodings are\noptimized for.\n\nWe needed a fix to speed things up. For this we came up with two options:\n\n  * We could try to find a way to seek through the video faster.\n  * Or we could try to find a way to render the video without seeking.\n\nWe were a little scared of the first option as we didn\u2019t want to introduce the\nadditional complexity and stack into our project. We much preferred running\nwith something we know well already.\n\nThe solution we landed on was a lot simpler. From our vite-nodejs-backend, we\nspawn an ffmpeg child process (ffmpeg is already a dependency of the project\nanyway), and pipe all the frames we need, at the appropriate framerate, back\ninto the node-process. From there, we send it through a web-socket connection\nto the client, populate image tags with the data, and then project those\nimages onto the canvas.\n\nThe biggest downside to this approach is that we don\u2019t know how many frames of\nthe video we will need ahead of rendering, leading to some frames being\nprocessed unnecessarily. The way we deal with this is by only spawning an\nffmpeg process for 10s of video at a time (or less if the source video ends).\nThis still means that we need to re-seek every time we spawn a new ffmpeg\nprocess every 10s, but this is already streets ahead of anything we had\nbefore. Benchmarking this approach against the old version shows just how much\nwe\u2019ve sped up the process.\n\nIn these 30s of video, we can clearly see the two spikes when the ffmpeg\nprocess needs to restart. Not perfect but it\u2019ll do for now. Rendering this\nparticular video went from 6 min, down to real-time, 30 seconds! We were happy\nwith our result and called it a day.\n\nIf you have a better idea for how to solve this problem, we would love to hear\nit!\n\nIf you\u2019re interested in the code, feel free to check out our Github repository\nhttps://github.com/redotvideo/revideo and consider giving it a \u2b50\ufe0f!\n\nLast modified: Tue 16. Apr 2024\n\nImprintContact Us\n\nLinkedInTwitter\n\n", "frontpage": false}
