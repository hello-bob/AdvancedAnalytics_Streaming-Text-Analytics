{"aid": "40286166", "title": "Red Hat Unveils InstructLab: A Simplified Path to AI Adoption and LLM Creation", "url": "https://www.redhat.com/en/topics/ai/what-is-instructlab", "domain": "redhat.com", "votes": 10, "user": "mikehollinger", "posted_at": "2024-05-07 14:46:31", "comments": 0, "source_title": "What is InstructLab?", "source_text": "What is InstructLab?\n\nSkip to content\n\n### Platform products\n\n  * Red Hat Enterprise LinuxA flexible, stable operating system to support hybrid cloud innovation.\n  * Red Hat OpenShiftA container platform to build, modernize, and deploy applications at scale.\n  * Red Hat Ansible Automation PlatformA foundation for implementing enterprise-wide automation.\n\n### Try & buy\n\n  * Start a trialAssess a product with a no-cost trial.\n  * Buy onlineBuy select products and services in the Red Hat Store.\n  * Integrate with major cloud providersBuy Red Hat solutions using committed spend from providers, including:\n\n### Featured\n\n  * Red Hat Enterprise Linux AI\n  * Red Hat OpenShift AI\n  * Red Hat OpenShift Virtualization\n  * Red Hat OpenShift Service on AWS\n  * Microsoft Azure Red Hat OpenShift\n\nSee all products\n\n### By category\n\n  * Application platform\n  * Artificial intelligence\n  * Edge computing\n  * IT automation\n  * Linux standardization\n\n### By organization type\n\n  * Automotive\n  * Financial services\n  * Healthcare\n  * Industrial sector\n  * Media and entertainment\n  * Public sector\n  * Telecommunications\n\n### By customer\n\n  * British Army\n  * Edenor\n  * HCA Healthcare\n  * Macquarie Bank\n  * Tata Consultancy Services\n  * UPS\n  * Search all success stories\n\nExplore solutions\n\n### Services\n\n  * Consulting\n  * Open Innovation Labs\n  * Technical Account Management\n\n### Training & certification\n\n  * All courses and exams\n  * All certifications\n  * Verify a certification\n  * Skills assessment\n  * Learning subscription\n  * Learning community\n  * Red Hat Academy\n  * FAQs\n  * Connect with learning experts\n\n### Featured\n\n  * Red Hat System Administration I (RH124)\n  * Red Hat OpenShift Administration II (DO280)\n  * Red Hat Certified Engineer (RHCE)\n\nExplore services\n\n### Topics\n\n  * AI\n  * Application modernization\n  * Automation\n  * Cloud computing\n  * Cloud-native applications\n  * Containers\n  * DevOps\n  * Edge computing\n  * Linux\n  * Virtualization\n  * See all topics\n\n### Articles\n\n  * What is InstructLab?\n  * What are cloud services?\n  * What is edge computing?\n  * What is hybrid cloud?\n  * Why build a Red Hat cloud?\n  * Cloud vs. edge\n  * Red Hat OpenShift vs. Kubernetes\n  * Learning Ansible basics\n  * What is Linux?\n\n### More to explore\n\n  * Blog\n  * Customer success stories\n  * Events and webinars\n  * Newsroom\n  * Podcasts and video series\n  * Resource library\n  * Training and certification\n\nExplore resources\n\n### For customers\n\n  * Our partners\n  * Red Hat Ecosystem Catalog\n  * Find a partner\n\n### For partners\n\n  * Partner Connect\n  * Become a partner\n  * Training\n  * Support\n  * Access the partner portal\n\n### About us\n\n  * Our company\n  * How we work\n  * Our social impact\n  * Development model\n  * Subscription model\n  * Product support\n\n### Open source\n\n  * Open source commitments\n  * How we contribute\n  * Red Hat on GitHub\n\n### Company details\n\n  * Analyst relations\n  * Blog\n  * Locations\n  * Newsroom\n\n### Communities\n\n  * Ansible\n  * For system administrators\n  * For architects\n  * Customer advocacy\n\nExplore Red Hat\n\nContact us\n\nFor customers\n\n  * Customer support\n  * Documentation\n  * Support cases\n  * Subscription management\n  * Red Hat Ecosystem Catalog\n  * Find a partner\n\nFor partners\n\n  * Partner portal\n  * Partner support\n  * Become a partner\n\nTry, buy, & sell\n\n  * Red Hat Marketplace\n  * Red Hat Store\n  * Contact sales\n  * Start a trial\n\nLearning resources\n\n  * Training and certification\n  * For developers\n  * Hybrid cloud learning hub\n  * Interactive labs\n  * Learning community\n  * Red Hat TV\n\nOpen source communities\n\n  * Ansible\n  * For system administrators\n  * For architects\n\n### Recommendations\n\nAs you browse redhat.com, we'll recommend resources you may like. For now, try\nthese.\n\n  * All Red Hat products\n  * Tech topics\n  * Red Hat resources\n\nRed Hat SummitSupportConsoleDevelopersStart a trialContact\n\nContact us\n\n### Select a language\n\n  * \u7b80\u4f53\u4e2d\u6587\n  * English\n  * Fran\u00e7ais\n  * Deutsch\n  * Italiano\n  * \u65e5\u672c\u8a9e\n  * \ud55c\uad6d\uc5b4\n  * Portugu\u00eas\n  * Espa\u00f1ol\n\n  * Products\n  * Solutions\n  * Training & services\n  * Resources\n  * Partners\n  * About\n  * Contact us\n\n### Select a language\n\n  * \u7b80\u4f53\u4e2d\u6587\n  * English\n  * Fran\u00e7ais\n  * Deutsch\n  * Italiano\n  * \u65e5\u672c\u8a9e\n  * \ud55c\uad6d\uc5b4\n  * Portugu\u00eas\n  * Espa\u00f1ol\n\n  * Topics\n  * Understanding AI\n  * What is InstructLab?\n\n# What is InstructLab?\n\nUpdated May 7, 2024 \u2022%t-minute read\n\nCopy URL\n\n  * Overview\n  * What does InstructLab do?\n  * How does InstructLab work?\n  * How is InstructLab different?\n  * InstructLab components\n  * Red Hat Enterprise Linux AI\n\n## Overview\n\nInstructLab is an open source project for enhancing large language models\n(LLMs) used in generative artificial intelligence (gen AI) applications.\nCreated by IBM and Red Hat, the InstructLab community project provides a cost-\neffective solution for improving the alignment of LLMs and opens the doors for\nthose with minimal machine learning experience to contribute.\n\nJoin the InstructLab community\n\n## What does InstructLab do?\n\nLLMs can power a range of useful applications like chatbots and coding\nassistants. These LLMs can be proprietary (such as OpenAI\u2019s GPT models and\nAnthropic\u2019s Claude models) or offer varying degrees of openness around\npretraining data and usage restrictions (such as Meta\u2019s Llama models, Mistral\nAI\u2019s Mistral models, and IBM\u2019s Granite models).\n\nAI practitioners often need to adapt a pretrained LLM to suit a particular\nbusiness purpose. But there are limits to the ways you can modify an LLM:\n\n  * Fine-tuning an LLM to understand a specific area of knowledge or skills typically involves forking an existing open model, then running expensive, resource-intensive training.\n  * There\u2019s no way to incorporate improvements back to the upstream project, and thus no way for models to continuously improve from community contributions.\n  * LLM refinements have typically required large amounts of human-generated data, which can be time-consuming and expensive to get.\n\nInstructLab follows an approach that punches through those limitations. It can\nenhance an LLM using far less human-generated information and far fewer\ncomputing resources than are typically used to retrain a model. And it makes\nit possible for upstream contributions to continuously make the model better.\n\nInstructLab is named after and based on IBM Research\u2019s work on Large-scale\nAlignment for chatBots, abbreviated as LAB. The LAB method is described in a\n2024 research paper by members of the MIT-IBM Watson AI Lab and IBM Research.\n\nInstructLab is not model-specific. It can provide supplemental skills and\nknowledge fine-tuning to an LLM of your choice. This \u201ctree of skills and\nknowledge\u201d improves continuously from community contributions and can be\napplied to support regular builds of an enhanced LLM. InstructLab maintains an\nenhanced version of IBM Granite. Two other lab-enhanced models released by IBM\ninclude Labradorite, which is derived from Llama 2, and Merlinite, which is\nderived from Mistral. The InstructLab project prioritizes fast iteration and\nintends to retrain models on a regular basis. Organizations can also use the\nInstructLab model alignment tools to train their own private LLMs with their\nown proprietary skills and knowledge.\n\n## How does InstructLab work?\n\nThe LAB method consists of 3 components:\n\n  * Taxonomy-driven data curation. Taxonomy is a set of diverse training data curated by humans as examples of new knowledge and skills for the model.\n  * Large-scale synthetic data generation. The model is then used to generate new examples based on the seed training data. Recognizing that synthetic data can vary in quality, the LAB method adds an automated step to refine the example answers, making sure they\u2019re grounded and safe.\n  * Iterative, large-scale alignment tuning. Finally, the model is retrained based on the set of synthetic data. The LAB method includes 2 tuning phases: knowledge tuning, followed by skill tuning.\n\nThe contributions of data from the community can lead to regular iterative\nbuilds of enhanced LLMs, each made better by the tree of skills generated from\ncommunity contributions.\n\n## How is InstructLab different from other methods of training an LLM?\n\nLet\u2019s compare InstructLab to the other steps in creating and improving an LLM.\n\n### Pretraining\n\nDuring pretraining, an LLM is trained to predict the next token using\ntrillions of tokens of unlabeled data. This gets really expensive, sometimes\nrequiring thousands of GPUs and months of time. Pretraining a highly capable\nLLM is only possible for organizations with significant resources.\n\n### Alignment tuning\n\nAfter pretraining, LLMs undergo alignment tuning to make the model\u2019s answers\nas accurate and useful as possible. The 1st step in alignment tuning is\ntypically instruction tuning, in which a model is trained directly on specific\ntasks of interest. Next is preference tuning, which can include reinforcement\nlearning from human feedback (RLHF). In this step, humans test the model and\nrate its output, noting if the model\u2019s answers are preferred or unpreferred.\nAn RLHF process may include multiple rounds of feedback and refinement to\noptimize a model.\n\nResearchers have found that the amount of feedback at this alignment tuning\nstage can be much smaller than the initial set of training data\u2015tens of\nthousands of human annotations, compared to the trillions of tokens of data\nrequired for pretraining\u2015and still unlock latent capabilities of the model.\n\n### InstructLab\n\nThe LAB method emerged from the idea that it should be possible to realize the\nbenefits of model alignment from an even smaller set of human-generated data.\nAn AI model can use a handful of human examples to generate a large amount of\nsynthetic data\u2015then refine that list for quality\u2015and use that high-quality\nsynthetic data set for further tuning and training. In contrast to instruction\ntuning, which typically need thousands of examples of human feedback, LAB can\nmake a model significantly better using relatively few examples provided by\nhumans.\n\n### How is InstructLab different from retrieval-augmented generation (RAG)?\n\nThe short answer is InstructLab and RAG solve different problems.\n\nRAG is a cost-efficient method for supplementing an LLM with domain-specific\nknowledge that wasn\u2019t part of its pretraining. RAG makes it possible for a\nchatbot to accurately answer questions related to a specific field or business\nwithout retraining the model. Knowledge documents are stored in a vector\ndatabase, then retrieved in chunks and sent to the model as part of user\nqueries. This is helpful for anyone who wants to add proprietary data to an\nLLM without giving up control of their information, or who needs an LLM to\naccess timely information.\n\nThis is in contrast to the InstructLab method, which sources end-user\ncontributions to support regular builds of an enhanced version of an LLM.\nInstructLab helps add knowledge and unlock new skills of an LLM.\n\nIt\u2019s possible to \"supercharge\" a RAG process by using the RAG technique on an\nInstructLab-tuned model.\n\n## What are the components of the InstructLab project?\n\nInstructLab is composed of several projects.\n\n### Taxonomy\n\nInstructLab is driven by taxonomies, which are largely created manually and\nwith care. InstructLab contains a taxonomy tree that lets users create models\ntuned with human-provided data, which is then enhanced with synthetic data\ngeneration.\n\n### Command-line interface (CLI)\n\nThe InstructLab CLI lets contributors test their contributions using their\nlaptop or workstation. Community members can use the InstructLab technique to\ngenerate a low-fidelity approximation of synthetic data generation and model-\ninstruction tuning without access to specialized hardware.\n\n### Model training infrastructure\n\nFinally, there\u2019s the process of creating the enhanced LLMs. It takes GPU-\nintensive infrastructure to regularly retrain models based on new\ncontributions from the community. IBM donates and maintains the infrastructure\nnecessary to frequently retrain the InstructLab project\u2019s enhanced models.\n\n## Discover Red Hat Enterprise Linux AI\n\nWhen you\u2019re ready to bring AI to the enterprise, Red Hat\u00ae Enterprise Linux\u00ae AI\nbrings together the Granite family of open source-licensed LLMs, InstructLab\nmodel alignment tools, a bootable image of Red Hat Enterprise Linux,\nenterprise-grade technical support, and model intellectual property\nindemnification.\n\nRed Hat Enterprise Linux is the world\u2019s leading enterprise Linux platform,\ncertified on hundreds of clouds and with thousands of hardware and software\nvendors. With the technological foundation of Linux, containers, and\nautomation, Red Hat\u2019s open hybrid cloud strategy gives you the flexibility to\nrun your AI applications anywhere you need them.\n\nRed Hat Enterprise Linux AI and the InstructLab project further deliver on\nthis vision, breaking down the cost and resource barriers to experimenting\nwith and building AI models while providing the tools, data, and concepts\nneeded to fuel the next wave of intelligent workloads.\n\nExplore Red Hat Enterprise Linux AI\n\n## Keep reading\n\nArticle\n\n### What is generative AI?\n\nGenerative AI relies on deep learning models trained on large data sets to\ncreate new content.\n\nLearn more\n\nArticle\n\n### What is machine learning?\n\nMachine learning is the technique of training a computer to find patterns,\nmake predictions, and learn from experience without being explicitly\nprogrammed.\n\nLearn more\n\nArticle\n\n### What are foundation models?\n\nA foundation model is a type of machine learning (ML) model that is pre-\ntrained to perform a range of tasks.\n\nLearn more\n\n### More about AI/ML\n\n#### Products\n\nNew\n\nA foundation model platform used to seamlessly develop, test, and run Granite\nfamily LLMs for enterprise applications.\n\nLearn more\n\nAn AI-focused portfolio that provides tools to train, tune, serve, monitor,\nand manage AI/ML experiments and models on Red Hat OpenShift.\n\nLearn more\n\nAn enterprise application platform with a unified set of tested services for\nbringing apps to market on your choice of infrastructure.\n\nLearn more\n\nRed Hat Ansible Lightspeed with IBM watsonx Code Assistant is a generative AI\nservice designed by and for Ansible automators, operators, and developers.\n\nLearn more\n\n#### Related articles\n\n  * What is generative AI?\n  * What is deep learning?\n  * What are large language models?\n  * What are foundation models?\n  * AI infrastructure explained\n  * Understanding AI\n  * What is an AI platform?\n  * What is LLMOps?\n  * AI in banking\n\n  * What is MLOps?\n  * What is machine learning?\n  * Understanding AI/ML use cases\n  * What is AI in healthcare?\n  * AI/ML on Red Hat OpenShift\n  * What is edge AI?\n  * AI infrastructure explained\n  * What is AIOps?\n\n#### Resources\n\ne-book\n\nTop considerations for building a production-ready AI/ML environment\n\nRead it\n\nAnalyst Material\n\nThe Total Economic ImpactTM Of Red Hat Hybrid Cloud Platform For MLOps\n\nLearn more\n\nWebinar\n\nGetting the most out of AI with open source and Kubernetes\n\nWatch it on demand\n\n### Keep exploring\n\nPORTFOLIO\n\nAI from Red Hat\n\nE-BOOK\n\nAdvance your business with AI and ML\n\nBLOG\n\nWhat is AI/ML and why does it matter to your business?\n\nPARTNERS\n\nExplore Red Hat\u2019s AI partner ecosystem\n\nSUCCESS STORY\n\nBanco Galicia speeds new customer onboarding\n\nLinkedInYouTubeFacebookTwitter\n\n### Products\n\n  * Red Hat Enterprise Linux\n  * Red Hat OpenShift\n  * Red Hat Ansible Automation Platform\n  * Cloud services\n  * See all products\n\n### Tools\n\n  * Training and certification\n  * My account\n  * Developer resources\n  * Customer support\n  * Red Hat value calculator\n  * Red Hat Ecosystem Catalog\n  * Find a partner\n\n### Try, buy, & sell\n\n  * Product trial center\n  * Red Hat Marketplace\n  * Red Hat Store\n  * Buy online (Japan)\n  * Console\n\n### Communicate\n\n  * Contact sales\n  * Contact customer service\n  * Contact training\n  * Social\n\n### About Red Hat\n\nWe\u2019re the world\u2019s leading provider of enterprise open source\nsolutions\u2014including Linux, cloud, container, and Kubernetes. We deliver\nhardened solutions that make it easier for enterprises to work across\nplatforms and environments, from the core datacenter to the network edge.\n\n### Select a language\n\n  * \u7b80\u4f53\u4e2d\u6587\n  * English\n  * Fran\u00e7ais\n  * Deutsch\n  * Italiano\n  * \u65e5\u672c\u8a9e\n  * \ud55c\uad6d\uc5b4\n  * Portugu\u00eas\n  * Espa\u00f1ol\n\n### Red Hat legal and privacy links\n\n  * About Red Hat\n  * Jobs\n  * Events\n  * Locations\n  * Contact Red Hat\n  * Red Hat Blog\n  * Diversity, equity, and inclusion\n  * Cool Stuff Store\n  * Red Hat Summit\n\n### Red Hat legal and privacy links\n\n  * Privacy statement\n  * Terms of use\n  * All policies and guidelines\n  * Digital accessibility\n  * Cookie preferences\n\n", "frontpage": false}
