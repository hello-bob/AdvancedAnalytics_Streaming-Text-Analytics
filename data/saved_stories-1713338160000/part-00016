{"aid": "40057032", "title": "Solving the minimum cut problem for undirected graphs", "url": "https://research.google/blog/solving-the-minimum-cut-problem-for-undirected-graphs/", "domain": "research.google", "votes": 2, "user": "skottenborg", "posted_at": "2024-04-16 20:51:57", "comments": 0, "source_title": "Solving the minimum cut problem for undirected graphs", "source_text": "Solving the minimum cut problem for undirected graphs\n\nresearch.google uses cookies from Google to deliver and enhance the quality of\nits services and to analyze traffic. Learn more.\n\nJump to Content\n\nResearch\n\nResearch\n\n# Solving the minimum cut problem for undirected graphs\n\nApril 16, 2024\n\nDi Wang, Research Scientist, Google Research\n\nWe discuss a recent (best-paper award) publication at ACM-SIAM Symposium on\nDiscrete Algorithms (SODA24) which gives a near-linear running time\ndeterministic algorithm for the fundamental optimization problem of finding a\nminimum cut in weighted graphs.\n\n## Quick links\n\n  * Paper\n  *     * \u00d7\n\nA graph is a ubiquitous data structure used in computer science that consists\nof nodes (or vertices) and edges between pairs of nodes to capture objects and\ntheir relations. The minimum cut problem (often referred to as \u201cmin-cut\u201d) is a\nbasic structural question about the connectivity of a graph that asks: what is\nthe least expensive way to disconnect a network? More formally, given an input\ngraph where edges have no orientation (i.e., the graph is undirected) and are\nassociated with positive weights quantifying the importance of the edges\n(e.g., capacity of a road, or strength of a relationship, level of similarity\nbetween the endpoints, etc.), a cut is a partition of the nodes into two\nsides. The size of a cut is the total weight of edges connecting nodes on\ndifferent sides of the cut, and the min-cut problem is to find a cut of the\nminimum size.\n\nSolving it efficiently has been one of the most fundamental problems in\nalgorithmic graph theory. Moreover, min-cut has diverse applications in\npractice such as image restoration, stereo and segmentation in computer\nvision, and network resilience analysis (such as for roads or power grids). It\nis also generally very useful when the underlying graph data is too large and\nneeds to be partitioned into smaller components to be processed in a divide-\nand-conquer manner.\n\nIn the theory of algorithm design, the asymptotic complexity for any problem\nthat requires reading the entire input (which is the case for min-cut) is at\nleast linear in the size of the input (since that is the time needed to read\nthe input). A nearly-linear time algorithm essentially achieves this lower-\nbound, and thus is canonically viewed as the optimal result one can achieve.\nFor the min-cut problem, existing nearly-linear time algorithms are either\nrandomized (which may output an incorrect answer with some probability) or\nonly work for the special case when the graph is simple (which cannot model\nmany real-world applications), so its optimal complexity remains an open\nproblem.\n\nIn \u201cDeterministic Near-Linear Time Minimum Cut in Weighted Graphs\u201d, which co-\nwon the best paper award at the ACM-SIAM Symposium on Discrete Algorithms\n(SODA2024), we design the first nearly-linear algorithm for the min-cut\nproblem that is deterministic (i.e., always finds the correct answer) and that\nalso works for general graphs, thus settling the optimal complexity for the\nmin-cut problem.\n\n## Technical insights\n\nOur result is the culmination of a long line of research, and algorithmic\nadvances on this problem (including ours) are usually motivated by structural\ndiscoveries of graph connectivity. In particular, a seminal result by Karger\nin 1996 gave a nearly-linear time randomized algorithm that finds a min-cut\nwith high probability, and a critical insight from that work was the existence\nof a much smaller graph that largely preserves all cuts\u2019 size. This is useful\nsince one can afford to run a slower algorithm with the smaller graph as\ninput, and the slower running time (in terms of the size of the smaller graph)\ncan still be nearly-linear in the size of the original (larger) graph. Indeed,\nmany of the structural discoveries on the min-cut problem are along this\ndirection, and the high-level idea of reducing problem size while preserving\nstructures of interest has been widely impactful in algorithm design.\n\n## Cut-preserving graph sparsification\n\nWe start by discussing the structural insight used by Karger in more detail.\nStarting with a graph G with n nodes, the cut-preserving sparsification by\nBenzur and Karger established the existence of a sparse weighted graph G\u2019 on\nthe same set of nodes with a smaller number of edges such that with high\nprobability, every cut S\u2019s size in G\u2019 is roughly the same as its size in G.\nThis idea is illustrated below, where the original graph consists of two\ncomplete graphs connected by a single edge (i.e., the dumbbell graph), and the\nsparsified graph has fewer, but larger weight, edges, while all the cut sizes\nare approximately preserved.\n\nplay silent looping video pause silent looping video\n\nIllustration of the cut preserving graph sparsification.\n\nTo algorithmically construct such a sparser graph, Benzur and Karger used the\napproach of sampling edges independently, where each edge in G is included in\nG\u2019 with some probability, and its weight in G\u2019 is scaled up by the reciprocal\nof the sampling probability (e.g., an edge of original weight 1 in G would\nhave a weight of 10 in G\u2019 if it\u2019s included with a 10% chance). It turns out\nthat with high probability, this remarkably simple (and nearly-linear time)\nmethod can successfully construct a cut-preserving graph sparsification.\n\nThe cut-preserving graph sparsification, along with several other creative\nalgorithmic ideas, yielded Karger's breakthrough result. However, Karger\u2019s\nalgorithm is a Monte Carlo algorithm, i.e., the output may be incorrect with\n(small) probability, and there is no known way to tell if the output is\ncorrect other than comparing it with an actual known min-cut. Since then,\nresearchers have been on the quest to resolve the open question of a nearly-\nlinear time deterministic algorithm. In particular, the construction of the\ncut-preserving graph sparsification is the only component in Karger\u2019s\nalgorithm that is randomized, and an apparent recipe is to find a\ndeterministic construction (a.k.a. derandomization) of the sparsification in\nnearly-linear time.\n\nIn 2015, Kawarabayashi and Thorup achieved a major milestone with such a\ndeterministic nearly-linear time algorithm for simple graphs, i.e., graphs\nthat have at most one edge between every pair of nodes and all edge weights\nequal to 1. The key observation in that work is a connection between min-cut\nand another important graph structure known as a low-conductance cut\n(explained below). This connection also turned out to be critical in later\nefforts to derandomize Karger\u2019s algorithm on graphs of general edge weights,\nwhich eventually culminated in our result.\n\n## Alignment of min-cut and low-conductance cut\n\nThe conductance of a cut S is defined as the ratio of the cut size of S over\nthe volume of S (assuming S is the smaller volume side of the cut and is non-\nempty), where the volume of S is the sum of the degree of the nodes in S. A\ncut S of low conductance intuitively captures a bottleneck in a network, as\nthere is only a small number of edges (relative to its volume) connecting S to\nthe rest of the graph. The conductance of a graph is defined as the min\nconductance of any cut in the graph, and a graph of large conductance (a.k.a.\nan expander graph) is considered well-connected as there is no bottleneck\ninside.\n\nKawayabarashi and Thorup made the observation that any non-trivial (i.e., both\nsides have at least two nodes) min-cut must have low conductance in a simple\ngraph where the min node degree is large. Following this observation, if one\ncan partition the graph into well-connected clusters, the partitioning must be\nconsistent with every non-trivial min-cut in the sense that each cluster must\nlie entirely on one side of every such cut. One can then contract each cluster\ninto a single node, and work on the smaller graph where all non-trivial min-\ncuts of the original graph are intact.\n\nHowever, for weighted graphs the same observation no longer holds, and the\nsame partitioning used in the simple graph case may not be exactly consistent\nwith non-trivial min-cuts. Nonetheless, Li 2021 observed that such a\npartitioning is still approximately consistent with non-trivial min-cuts as\nillustrated in the figure below. In particular, for a non-trivial min-cut S,\nthere exists a cut S\u2019 that is not too different from S such that S\u2019 is\nconsistent with the clusters. Li further observed that this property of the\npartitioning can be exploited to efficiently derandomize the construction of\ncut-preserving graph sparsification.\n\nplay silent looping video pause silent looping video\n\nA partitioning of the graph that is approximately consistent with near-minimum\ncuts.\n\nIn our new result, we devise an algorithm to construct such a partitioning\ntailored to our use case of finding min-cut. Compared to the more generic off-\nthe-shelf method used by Li in the previous work, our tailored construction is\nmuch more precise, so that the original min-cut S and its corresponding\ncluster-consistent cut S\u2019 (in the figure above) are guaranteed to have more\nsimilar cut sizes. Moreover, our algorithm is faster than off-the-shelf\nmethods, which comes by improving previous clustering techniques developed\nsolely for simple graphs (by Henzinger, Rao and Wang in 2017) to work more\nbroadly on weighted graphs. The stronger precision and running time guarantees\nachieved by the new construction ultimately lead to our nearly-linear time\ndeterministic algorithm for the min-cut problem.\n\n## Acknowledgements\n\nWe are grateful to our co-authors Monika Henzinger, Jason Li, and Satish Rao.\nWe would also like to extend special thanks to John Guilyard for creating the\nanimation used in this post.\n\nLabels:\n\n  * Algorithms & Theory\n\n## Quick links\n\n  * Paper\n  *     * \u00d7\n\n### Other posts of interest\n\n  * April 10, 2024\n\nSOAR: New algorithms for even faster vector search with ScaNN\n\n    * Algorithms & Theory \u00b7\n    * Conferences & Events \u00b7\n    * Data Mining & Modeling\n\n  * March 28, 2024\n\nAutoBNN: Probabilistic time series forecasting with compositional bayesian\nneural networks\n\n    * Algorithms & Theory \u00b7\n    * Machine Intelligence \u00b7\n    * Open Source Models & Datasets\n\n  * March 12, 2024\n\nTalk like a graph: Encoding graphs for large language models\n\n    * Algorithms & Theory \u00b7\n    * Generative AI \u00b7\n    * Machine Intelligence\n\nFollow us\n\n", "frontpage": false}
