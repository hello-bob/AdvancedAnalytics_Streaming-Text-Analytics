{"aid": "40174138", "title": "MapReader: Computer vision pipeline for exploring and analyzing images at scale", "url": "https://living-with-machines.github.io/MapReader/", "domain": "living-with-machines.github.io", "votes": 1, "user": "benbreen", "posted_at": "2024-04-26 20:52:04", "comments": 0, "source_title": "MapReader", "source_text": "MapReader | A computer vision pipeline for exploring and analyzing images at scale\n\n# MapReader\n\nA computer vision pipeline for exploring and analyzing images at scale\n\nView the Project on GitHub Living-with-machines/MapReader\n\n# MapReader\n\n## A computer vision pipeline for exploring and analyzing images at scale\n\n## What is MapReader?\n\nMapReader is an end-to-end computer vision (CV) pipeline for exploring and\nanalyzing images at scale.\n\nMapReader was developed in the Living with Machines project to analyze large\ncollections of historical maps but is a generalizable computer vision pipeline\nwhich can be applied to any images in a wide variety of domains.\n\n## Overview\n\nMapReader is a groundbreaking interdisciplinary tool that emerged from a\nspecific set of geospatial historical research questions. It was inspired by\nmethods in biomedical imaging and geographic information science, which were\nadapted for use by historians, for example in our Journal of Victorian Culture\nand Geospatial Humanities 2022 SIGSPATIAL workshop papers. The success of the\ntool subsequently generated interest from plant phenotype researchers working\nwith large image datasets, and so MapReader is an example of cross-pollination\nbetween the humanities and the sciences made possible by reproducible data\nscience.\n\n### MapReader pipeline\n\nThe MapReader pipeline consists of a linear sequence of tasks which, together,\ncan be used to train a computer vision (CV) classifier to recognize visual\nfeatures within maps and identify patches containing these features across\nentire map collections.\n\nSee our About MapReader page to learn more.\n\n## Documentation\n\nThe MapReader documentation can be found at\nhttps://mapreader.readthedocs.io/en/latest/index.html.\n\nNew users should refer to the Installation instructions and Input guidance for\nhelp with the initial set up of MapReader.\n\nAll users should refer to our User Guide for guidance on how to use MapReader.\nThis contains end-to-end instructions on how to use the MapReader pipeline,\nplus a number of worked examples illustrating use cases such as:\n\n  * Geospatial images (i.e. maps)\n  * Non-geospatial images\n\nDevelopers and contributors may also want to refer to the API documentation\nand Contribution guide for guidance on how to contribute to the MapReader\npackage.\n\nJoin our Slack workspace! Please fill out this form to receive an invitation\nto the Slack workspace.\n\n## What is included in this repo?\n\nThe MapReader package provides a set of tools to:\n\n  * Download images/maps and metadata stored on web-servers (e.g. tileservers which can be used to retrieve maps from OpenStreetMap (OSM), the National Library of Scotland (NLS), or elsewhere).\n  * Load images/maps and metadata stored locally.\n  * Pre-process images/maps:\n\n    * patchify (create patches from a parent image),\n    * resample (use image transformations to alter pixel-dimensions/resolution/orientation/etc.),\n    * remove borders outside the neatline,\n    * reproject between coordinate reference systems (CRS).\n  * Annotate images/maps (or their patches) using an interactive annotation tool.\n  * Train or fine-tune Computer Vision (CV) models and use these to predict labels (i.e. model inference) on large sets of images/maps.\n\nVarious plotting and analysis functionalities are also included (based on\npackages such as matplotlib, cartopy, Google Earth, and kepler.gl).\n\n## How to cite MapReader\n\nIf you use MapReader in your work, please cite both the MapReader repo and our\nSIGSPATIAL paper:\n\n  * Kasra Hosseini, Daniel C. S. Wilson, Kaspar Beelen, and Katherine McDonough. 2022. MapReader: a computer vision pipeline for the semantic exploration of maps at scale. In Proceedings of the 6th ACM SIGSPATIAL International Workshop on Geospatial Humanities (GeoHumanities '22). Association for Computing Machinery, New York, NY, USA, 8\u201319. https://doi.org/10.1145/3557919.3565812\n  * Kasra Hosseini, Rosie Wood, Andy Smith, Katie McDonough, Daniel C.S. Wilson, Christina Last, Kalle Westerling, and Evangeline Mae Corcoran. \u201cLiving-with-machines/mapreader: End of Lwm\u201d. Zenodo, July 27, 2023. https://doi.org/10.5281/zenodo.8189653.\n\n## Acknowledgements\n\nThis work was supported by Living with Machines (AHRC grant AH/S01179X/1) and\nThe Alan Turing Institute (EPSRC grant EP/N510129/1).\n\nLiving with Machines, funded by the UK Research and Innovation (UKRI)\nStrategic Priority Fund, is a multidisciplinary collaboration delivered by the\nArts and Humanities Research Council (AHRC), with The Alan Turing Institute,\nthe British Library and the Universities of Cambridge, East Anglia, Exeter,\nand Queen Mary University of London.\n\nMaps above reproduced with the permission of the National Library of Scotland\nhttps://maps.nls.uk/index.html\n\n## Contributors\n\n_Katie McDonough \ud83d\udd2c \ud83e\udd14 \ud83d\udcd6 \ud83d\udccb \ud83d\udcc6 \ud83d\udc40 \ud83d\udce2 \u2705| _Daniel C.S. Wilson \ud83d\udd2c \ud83e\udd14 \ud83d\udce2 \ud83d\udcd6 \ud83d\udccb| _Kasra\nHosseini \ud83d\udcbb \ud83e\udd14 \ud83d\udd2c \ud83d\udc40 \ud83d\udce2| _Rosie Wood \ud83d\udcbb \ud83d\udcd6 \ud83e\udd14 \ud83d\udce2 \u2705 \ud83d\udc40 \ud83d\udea7 \ud83d\udd2c| _Kalle Westerling \ud83d\udcbb \ud83d\udcd6 \ud83d\udea7 \ud83d\udc40 \ud83d\udce2|\n_Chris Fleet \ud83d\udd23| _Kaspar Beelen \ud83e\udd14 \ud83d\udc40 \ud83d\udd2c  \n---|---|---|---|---|---|---  \n_Andy Smith \ud83d\udcbb \ud83d\udcd6 \ud83e\uddd1\ud83c\udfeb \ud83d\udc40  \n  \nThis project is maintained by Living-with-machines\n\nHosted on GitHub Pages \u2014 Theme by orderedlist\n\n", "frontpage": false}
