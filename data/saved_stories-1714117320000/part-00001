{"aid": "40163104", "title": "A Logic Language for Distributed SQL Queries", "url": "https://www.osohq.com/post/logic-language-distributed-sql-queries", "domain": "osohq.com", "votes": 5, "user": "mpweiher", "posted_at": "2024-04-25 21:13:52", "comments": 0, "source_title": "A Logic Language for Distributed SQL Queries", "source_text": "A Logic Language for Distributed SQL Queries\n\nTry Oso\n\nMeet an Eng\n\nInternals\n\nApril 25, 2024\n\n# A Logic Language for Distributed SQL Queries\n\nSam Scott\n\nIf you\u2019ve worked with microservices, you know how hard it is to solve for\nshared capabilities. Authorization is one such capability. Most services will\nneed some kind of authorization, and so you want a clean authorization\nimplementation that every service can reuse. But authorization as a domain is\nmessy. Authorization logic blurs with domain-specific information, and data\nneeded to evaluate authorization decisions heavily overlaps with application\ndata.\n\nThis means that when trying to extract authorization out into its own service,\nit ends up being challenging to draw a clean separation.\n\nAuthorization as a domain blurs lines between multiple applications, making it\nhard to extract into a service\n\nOur ideal version of authorization as a shared capability sharpens these\nlines, so you can integrate it with minimal overhead to any given application.\nA key consideration is that you shouldn\u2019t need to synchronize data to a\ndifferent service, just to evaluate authorization logic that could have all\nbeen handled locally.\n\nTo this end, we built a logic language for expressing authorization called\nPolar. It\u2019s built to allow multiple teams to build an authorization model\nexpressing both shared and domain-specific logic.\n\nAnd then we made it possible to run Polar over multiple data stores, so that\nit can do authorization using shared data stored centrally, and application\ndata stored alongside the application.\n\nIn Distributed Authorization, we extract as much authorization as possible\ninto a shared service, but let each service manage some of it on its own\n\nWe call the resulting architecture Distributed Authorization. Here\u2019s how we\nbuilt it.\n\n### Scenario: Service-Oriented GitHub\n\nImagine you\u2019re building an application like GitHub, but with a service-\noriented architecture. It\u2019s common that application-specific functionality\nlike \u201crepository issues\u201d would be decoupled from authorization and permission\ncontrols like \u201cmanaging organizations and user roles\u201d.\n\nSo let\u2019s say you have two services: AuthzService and IssuesService\n\nDiagram showing our two services, their databases, and a list of the data they\nmanage\n\nThe AuthzService knows everything authorization-related about Organizations:\nwho belongs to those organizations, what roles they have, what custom roles\nthey\u2019ve created. It also manages authorization data on Repositories, like\nwhich organization owns the Repository, who the members are, and what roles\nthey have.\n\nMeanwhile, the IssuesService deals with everything issue-related: who created\nthe issue, what repository it belongs to, and so on.\n\nLet\u2019s take as an example: the user Alice wants to close issue #42 on\nrepository acme/anvil. The IssuesService wants to know if Alice is allowed to\ndo this, and will make an API request to the AuthzService to find out.\n\nThis is a simple question, but in a mature application like GitHub, the logic\ngets complex. For example, GitHub has organization roles, customizable default\nrepository roles, custom roles, issue creators, and public/private\nrepositories. All of these impact the authorization logic:\n\nRoles, relationships, and attributes impacting whether Alice can close issue\n#42\n\nAnd authorization goes beyond simple yes/no questions like this. As put really\nnicely by wkirby on Hacker News:\n\n> Permissions have three moving parts, who wants to do it, what do they want\n> to do, and on what object. Any good permission system has to be able to\n> efficiently answer any permutation of those variables. Given this person and\n> this object, what can they do? Given this object and this action, who can do\n> it? Given this person and this action, which objects can they act upon?\n\nwhich acts a force multiplier on all of the above complexity.\n\nGiven all this, a shared authorization capability for this application has to\nbe able to:\n\n  1. express the above logic, which spans the Authz and Issues domains\n  2. use data stored in both the AuthzService and IssuesService\n  3. support yes/no questions as well as more flexible \u201clist\u201d questions\n\nLet's start with the logic. From there, we'll explain how our approach to\nlogic let us solve some tricky data problems. We\u2019ll demonstrate the concepts\nwith examples that apply them to both yes/no and list questions.\n\n## Polar: A prolog-inspired language that transpiles to SQL\n\nPolar is our declarative approach to authorization logic that spans multiple\nservices. Polar is inspired by logic programming languages like Prolog,\nDatalog, and miniKanren. Under the hood, Polar transpiles to SQL over a custom\ndata model, which does the heavy lifting of query planning and fast data\naccess.\n\nHere\u2019s a fairly minimal example of a Polar policy:\n\n    \n    \n    allow(user: User, \"read\", org: Organization) if has_role(user, \"member\", org); has_role(User{\"alice\"}, \"member\", Organization{\"acme\"});\n\nThere\u2019s an allow \u201drule\u201d that says:\n\n  1. a user (of type User ) is allowed to read an org (of type Organization)\n  2. if the user has the role member on that org\n\nThere\u2019s also a solitary has_role rule with no if and no conditions. These are\ncalled facts \u2014 unconditionally true information. In this case, the fact is\nasserting that the user with id: alice is a member of the organization with\nid: acme.\n\nThis Polar policy expresses:\n\n  1. a simple piece of role-based access control logic: org members can read that organization\n  2. a small piece of factual data assigning the member role to alice.\n\nTo use this policy, you can query it. The theoretical foundations of this come\nfrom logic programming and first order logic. For a deeper dive, I\u2019d recommend\nchecking out The Power of Prolog.\n\nFor today, there are two main facets of logic programming that you\u2019ll want to\nwrap your head around:\n\n  1. Inference logic (how Polar evaluate rules)\n  2. Unification (the core \u201cpattern-matching algorithm\u201d of Polar)\n\n### Interlude: Logic Programming\n\nRules express logical properties about the world: \u201cthis statement is true if\nthese other things are also true\u201d. The syntax of rules makes them look a\nlittle like functions, but they resolve logically/declaratively rather than\nimperatively. It can still be helpful though to think in terms of \u201ccalling\u201d\nrules.\n\nInference says that \u201cGiven a user alice who has the member role on the acme\norganization, it follows that allow(alice, \"read\", acme) is true. That is, we\ninfer that the allow rule is true based on the fact that the has_role\ncondition is satisfied.\n\nUnification is effectively a fancy pattern matching algorithm that combines\nvariable assignment + comparisons into one operator.\n\nFor example, the following are all examples of simple unification:\n\n    \n    \n    1 = 1 # two concrete values, behaves like comparison true 1 = 2 # false x = 1 # behaves like assignment, the variable `x` now has value 1 x = 1 # `x` is now 1 y = x # true, the variable `y` is equal to 1 y = x # true, the variable `y` is equal to variable `x` x = 1 # true, `x` is now 1, `y` is also 1\n\nUnification is a process for helping you solve those equations. Given x=1 and\ny=x what is y? Well, obviously it\u2019s 1 . That\u2019s what unification is doing.\n\n### Logic Programming in Polar\n\nPutting the two together \u2014 rule inference and unification \u2014 you end up with a\nlogic engine that can make simple deductions:\n\nLogical steps taken to evaluate a query against a Polar policy\n\n### Querying a Polar policy\n\nHere\u2019s an example of how you query a policy using the oso-cloud CLI:\n\n    \n    \n    > tee -a intro.polar <<EOF allow(user: User, \"read\", org: Organization) if has_role(user, \"member\", org); has_role(User{\"alice\"}, \"member\", Organization{\"acme\"}); EOF > oso-cloud policy intro.polar Policy successfully loaded. > oso-cloud query allow User:alice read Organization:_ allow(User:alice, String:read, Organization:acme)\n\nThe output of oso-cloud query is showing the result of logical deductions: it\n\u201cfilled in\u201d the missing argument of Organization:acme.\n\nAnd you can extend this:\n\n    \n    \n    > tee intro.polar <<EOF allow(user: User, \"read\", org: Organization) if has_role(user, \"member\", org); has_role(User{\"alice\"}, \"member\", Organization{\"acme\"}); has_role(User{\"bob\"}, \"member\", Organization{\"megacorp\"}); EOF > oso-cloud policy intro.polar && oso-cloud query allow User:_ _ Organization:_ Policy successfully loaded. allow(User:alice, String:read, Organization:acme) allow(User:bob, String:read, Organization:megacorp)\n\nThis time there\u2019s an additional fact \u2014 user bob is a member of megacorp.\n\nAnd the query is even more generic \u2014 what are all the users, with any\npermission, on any organization. Using the same deduction process as above,\nOso Cloud determines that alice can read acme and bob can read megacorp.\n\nThere\u2019s a particularly nice element of logic languages on display here: you\nuse the exact same declarative configuration to answer \u201ccan Alice read\nOrganization:acme\u201d as well as \u201cwhat are all the organizations Alice can\naccess\u201d. Which is exactly what you need for common authorization use cases.\n\n### Using Inference to Remove Redundancy\n\nNow suppose you introduce more roles and more permissions by defining a member\nwith the following permissions:\n\n    \n    \n    allow(user: User, \"read\", org: Organization) if has_role(user, \"member\", org); allow(user: User, \"create_repository\", org: Organization) if has_role(user, \"member\", org);\n\nAnd an admin with a slightly increased set of permissions:\n\n    \n    \n    allow(user: User, \"read\", org: Organization) if has_role(user, \"admin\", org); allow(user: User, \"create_repository\", org: Organization) if has_role(user, \"admin\", org); allow(user: User, \"invite_users\", org: Organization) if has_role(user, \"admin\", org);\n\nYou can see that it starts to get a little repetitive. And so you can write\nlogic wherever it makes sense to remove redundancy. In the above case, admins\ncan do whatever members can do, so for the admin permissions you can write:\n\n    \n    \n    - allow(user: User, \"read\", org: Organization) if - has_role(user, \"admin\", org); - - allow(user: User, \"create_repository\", org: Organization) if - has_role(user, \"admin\", org); + has_role(user: User, \"member\", org: Organization) if + has_role(user, \"admin\", org); allow(user: User, \"invite_users\", org: Organization) if has_role(user, \"admin\", org);\n\nThat is, you use inference logic to say that a user has the \u201cmember\u201d role at\nan organization if they have the \u201cadmin\u201d role. Rule inference logic is\nrecursive. By adding that one rule, you now know that any rule that relies on\na user being a member of an organization will also work for a user who is an\nadmin of the organization. This saves you from needing to repeat all the\nmember permissions on the admin \u2013 and from needing to remember to do that\nevery time you add a new permission to members.\n\nIncidentally, the above use case is so common that Polar has some built-in\nprimitives to express it. You would write it as:\n\n    \n    \n    actor User { } resource Organization { roles = [\"admin\", \"member\"]; permissions = [\"read\", \"create_repository\", \"invite_users\"]; \"read\" if \"member\"; \"create_repository\" if \"member\"; \"member\" if \"admin\"; \"invite_users\" if \"admin\"; }\n\nwhich is a little less noisy, while also baking in validation logic to prevent\ntypos of names.\n\nUnder the hood those \"read\" if \"member\" rules expand to the same thing you\nwrote earlier\n\n    \n    \n    # \"read\" if # \\/ has_permission(user: User, \"read\", organization: Organization) if # \"member\" ; # \\/ has_role(user, \"member\", organization);\n\nit\u2019s purely syntactic sugar.\n\n### Pulling it all Together\n\nComing back to the GitHub example, the full logic from earlier would look\nsomething like:\n\n    \n    \n    actor User {} resource Organization { roles = [\"member\", \"admin\"]; } resource Repository { roles = [\"reader\", \"triage\", \"admin\"]; permissions = [\"close_issues\"]; relations = { parent: Organization, }; \"admin\" if \"admin\" on \"parent\"; \"close_issues\" if \"triage\"; \"triage\" if \"admin\"; } has_role(user: User, role: String, repository: Repository) if org matches Organization and has_relation(repository, \"parent\", org) and has_role(user, \"member\", org) and default_repository_role(org, role); resource Issue { permissions = [\"read\", \"close\"]; relations = { parent: Repository, creator: User, }; \"close\" if \"creator\" and \"read\" on \"parent\"; \"close\" if \"close_issues\" on \"parent\"; } has_permission(user: User, \"close_issues\", repository: Repository) if org matches Organization and has_relation(repository, \"parent\", org) and role matches CustomRole and has_relation(role, \"parent\", org) and has_role(user, role, repository) and grants_permission(role, \"Repository\", \"close_issues\"); grants_permission(role: Role, resource_type: String, permission: String) if inherited_role matches String and inherits_role(role, inherited_role) and grants_permission(inherited_role, resource_type, permission);\n\nIn this policy there are effectively five different ways (not counting the\ncombinatorial explosions of all of them) that a user might get permission to\nclose an issue:\n\n  1. They are the issue creator, and they have read-access on the repository\n  2. They directly have an appropriate role (e.g. \u201ctriage\u201d) on the repository it belongs to\n  3. They directly have a custom role on the repository, and the organization configured that role to have \u201cclose_issues\u201d permission on repositories\n  4. They are a member of the organization, and the organization configures members to have at least \u201ctriage\u201d level access on all repositories\n  5. They are an organization admin which grants them admin-level access on all repositories.\n\nPhew!\n\nWhat makes logic programming a powerful paradigm for authorization is the\nability to implement this kind of branching conditional logic, which you\ntypically see in authorization systems, with reusable logical predicates\n(i.e., more rules). Polar\u2019s logic programming foundations let it represent\nthis logic clearly and concisely.\n\nWhat\u2019s more, by pulling the authorization logic out of the individual services\nand into a common location, multiple teams can collaborate on the policy.\nBecause the policy language is declarative, the rules are easy to read and the\nlogic is easy to understand, further facilitating collaboration.\n\nFor example, to extend the prior policy to make \u201cclosing locked issues\u201d a\ndistinct permission, you can make a small policy change:\n\n    \n    \n    resource Issue { permissions = [\"read\", \"close\"]; relations = { parent: Repository, creator: User, }; - \"close\" if \"creator\" and \"read\" on \"parent\"; - \"close\" if \"close_issues\" on \"parent\"; + \"close\" if \"creator\" and \"read\" on \"parent\" and is_locked(resource, false); + \"close\" if \"close_issues\" on \"parent\" and is_locked(resource, false); + \"close\" if \"close_locked_issues\" on \"parent\"; }\n\n### From Logic to Data: Facts as SQL\n\nExpressing authorization logic in a language like Polar is half the battle.\nWhat it gives you is a consistent approach to writing reusable authorization\nlogic that multiple teams can collaborate on building.\n\nHowever, we\u2019ve been deliberately skipping over data: where it comes from and\nhow it affects performance.\n\nEarlier, we showed how you can add data by writing facts directly in the\npolicy:\n\n    \n    \n    has_role(User{\"alice\"}, \"member\", Organization{\"acme\"});\n\nFrom the logic programming standpoint, there\u2019s nothing inherently wrong with\nthis. There\u2019s no real need to make a distinction between rules and facts \u2014\nremember, a fact is just an unconditionally true rule. It\u2019s down to the\nimplementation to provide convenient APIs for modifying the state of our\nsystem by adding/removing new facts, and to implement an efficient way to\nstore/index/lookup facts.\n\n### Storing facts\n\nDatalog illustrates this nicely. Datalog is a logic programming language that\ndistinguishes rules from facts as a fundamental element of its design. One way\nthat different implementations of Datalog are distinguished from one another\nis the strategies they use for evaluating rules and facts together in optimal\nways: https://en.wikipedia.org/wiki/Datalog#Evaluation.\n\nIn fact, we could have used Datalog to achieve our data goals \u2014 but that would\nmean we have to build our own Datalog implementation, backing data store, etc.\nWe don\u2019t want to do that.\n\nWe want to leverage existing tried and true technology \u2014 like SQL. And more\nspecifically, SQLite.\n\nAnd so what we decided was: we should have a custom data model purpose-built\nfor Polar and backed by SQL. We\u2019ve been through a few iterations of said data\nmodel, and landed on a painfully simple one: we store facts as rows in SQL\ntables.\n\nInitially we put all facts with the same arity (number of arguments) in one\ntable together. But we realized that with SQLite we would be better served by\ndynamically creating tables for a given fact type, which we defined as the\nfact name (e.g. \u201chas_role\u201d) and argument types.\n\nIn Polar, values are either raw primitives (strings, integers, booleans), or\ntype + ID pairs, like { type: \"Organization\", id: \"acme\" }. And we can\nrepresent primitives in that format too (e.g. { type: \u201cString\u201d, id:\n\u201cmember\u201d}).\n\nWhere this leaves us - for a fact like:\n\n    \n    \n    has_role(User{\"alice\"}, \"member\", Organization{\"acme\"});\n\nwe create an entry in a fact index, which maps an incrementing ID to the fact\ntype, e.g.\n\n    \n    \n    1 -> has_role, [User, String, Organization]\n\nand then store the id: portions of the fact value (i.e. the quoted parts) in\nthe fact_1 table:\n\n    \n    \n    arg0 | arg1 | arg2 --------------------- alice | member | acme\n\n### Retrieving Facts\n\nSo now the question becomes: how should Polar access this data? There are two\noptions worth considering:\n\n  1. Make it possible to access the backing datastore as part of query evaluation.\n  2. Split evaluation into two phases: query evaluation, and data lookups\n\nWe ultimately opted for (2) because we knew when we started that we were\nheading towards something that could support data split across multiple\nservices, so we would need those two steps to be separated.\n\nHow this works is: when Polar evaluates a query like allow User:alice read\nOrganization:_, it works mostly like a regular logic programming language. It\nperforms unification and applies inference logic to find all possibilities of\nwhat the input variables could be \u2013 with one important difference.\n\nWhen Polar sees a condition like:\n\n    \n    \n    has_role(user, \"member\", organization)\n\nIt considers two distinct possibilities:\n\n  1. The condition is satisfied by some other rule, and so should find matching rules and evaluate those\n  2. The condition is satisfied by a concrete fact that is stored in the underlying database. In which case, track this in its internal state as something to be resolved later.\n\nAnd so instead of Polar returning concrete results like before, Polar is\nactually returning an intermediate representation of all the ways the query\ncould be satisfied using facts in the database.\n\nFor the above example rule of \u201cusers can close issues if they have the\n\u2018triage\u2019 role on the repository it belongs to\u201d, asking the query \u201cwhich issues\ncan Alice close\u201d results in the intermediate representation:\n\n    \n    \n    Outputs: issue: f0.arg0 Facts: f0: has_relation(Issue, String, Repository) f1: has_role(User, String, Repository) Conditions: f0.arg2 = f1.arg2 f0.arg1 = \"parent\" f1.arg1 = \"triage\" f1.arg0 = User{\"alice\"}\n\nIt\u2019s no coincidence that this looks a lot like SQL\u2019s SELECT ... FROM ... WHERE\nsyntax. The final step in this process is to turn the above into SQL, and\nquery our embedded SQLite database.\n\nFor the facts, indexed f0 and f1 , we look up the corresponding fact tables\nvia the index. For simplicity, I\u2019ll assume those tables are fact_0 and fact_1\n. The SQL output is:\n\n    \n    \n    SELECT f0.arg0 FROM fact_0 f0, fact_1 f1 WHERE f0.arg2 = f1.arg2 and f0.arg1 = 'parent' and f1.arg1 = 'triage' and f1.arg0 = 'alice';\n\n### Interlude: Performance\n\nGiven that one of the motivations for using SQL was performance, how well does\nthis perform?\n\nBecause our facts are in SQL tables, we can generate a bunch of indexes for\nthose tables using simple heuristics:\n\n    \n    \n    CREATE UNIQUE INDEX fact_0_idx_0 on fact_0 ( arg0, arg2, arg1 ); CREATE UNIQUE INDEX fact_0_idx_1 on fact_0 ( arg2, arg0, arg1 ); CREATE UNIQUE INDEX fact_1_idx_0 on fact_1 ( arg0, arg2, arg1 ); CREATE UNIQUE INDEX fact_1_idx_1 on fact_1 ( arg2, arg0, arg1 );\n\nOur SQL queries end up being a number of joins, and simple filters on these\nindexed columns. This makes the SQLite query planner very happy:\n\n    \n    \n    QUERY PLAN |--SEARCH f0 USING COVERING INDEX fact_0_idx_0 (arg0=?) `--SEARCH f1 USING COVERING INDEX fact_1_idx_1 (arg2=?)\n\nIt does exactly what you would expect: it finds all of the repositories that\nalice is has the \u201ctriage\u201d role for, and then gets all of the issues belonging\nto those repositories.\n\nAnd in the case where we ask if alice can close a specific issue? The SQLite\nquery planner is smart enough to realize that issues belong to strictly one\nrepository, whereas users might have roles on many repositories and reverses\nthe ordering of the joins:\n\n    \n    \n    QUERY PLAN |--SEARCH f1 USING COVERING INDEX fact_1_idx_0 (arg0=?) `--SEARCH f0 USING COVERING INDEX fact_0_idx_0 (arg0=?)\n\n### Polar + Facts: An Ideal Combination\n\nAt this point I\u2019m basically just explaining to you why SQL is cool...But it\u2019s\nhard to overstate how nice it is for us to be able to focus purely on\nproviding good inputs to a battle-tested SQL engine like SQLite rather than\nattempt to build this. We get to spend our innovation tokens elsewhere.\n\nWe\u2019ve also drawn a relatively clear line in the sand. Polar supports:\n\n  1. Common authorization data: roles, relationships, attributes\n  2. Custom data types expressed as facts\n  3. Arbitrary combinations of facts expressed via and and or\n  4. A handful of comparisons like integer comparisons, and time-based checks (for expiration).\n  5. Recursive data lookups (e.g. files and folders hierarchies a la Google Drive).\n\nWe think this the ideal combination: flexible enough to represent almost\nanything, while being structured enough for us to write a robust querying\nlayer using SQLite to do the underlying query planning and data lookups.\n\nLooking back, it\u2019s unsurprising that SQL works so well in a Datalog-like logic\nprogramming language. SQL was itself inspired by logic programming, and\nDatalog is frequently described as a stepping stone between logic programming\nand relational algebra. Everything starts blurring together the more you look\nat it.\n\n## Distributing Queries\n\nWith Polar we have a declarative way to express authorization logic. And we\u2019ve\nseen that we can use Polar with a custom data model in SQL to evaluate queries\nfast. We use that to build our central authorization system (Oso Cloud).\n\nReturning to our IssuesService example: if we want to use that central\nauthorization system to decide \u201ccan Alice close issue #42\u201d, we\u2019ll need to give\nit access to the data it needs somehow.\n\nTypically, centralized authorization systems \u2013 including Oso Cloud \u2013 have\nachieved this by requiring that any necessary data exist in the authorization\nsystem at the time the decision is made. This means either:\n\n  1. Duplicating authorization-relevant data between the application and the authorization service\n  2. Moving to event sourcing\n\nBoth of those sound like a lot of extra work just to answer some authorization\nquestions. In the case of duplicating the data, you\u2019re either building a\nreplication process or you\u2019re passing extra data over the wire for every\nauthorization request. If you move to event sourcing, then you\u2019re taking on a\nmajor application refactor.\n\nHowever you choose to get the data into the service, some operations will also\nreturn a long list of data back out of it. Think back to the case where we\nasked for all the issues that Alice can close. If Alice has access to hundreds\nof issues, then the response will include all of them, increasing latency.\n\nThis led us to consider a different option: distribute the authorization. We\ncan centralize anything that\u2019s shared across multiple services and leave\neverything else in the application.\n\nFor example, in the GitHub example most of a user\u2019s permissions on an issue\ncome from the repository roles, and so one path to implement it would be:\n\n    \n    \n    // issuesService/controller/closeIssue.ts async function closeIssue(currentUser: User, issueData: IssueData) { // Note: we should still check for read permission on the repo // even if the user is the creator -- you cannot // close issues for repositories you don't have access to if (!canRead) { throw new PermissionDeniedError(); } if (!canClose) { // Implement issue-level authorization logic directly in the issue service. // // unless you have the repository-level canClose permission, // you need to be the issue creator const issueCreator = await db .selectFrom(\"issue\") .select(\"creator_id\") .where(\"id\", \"=\", issueData.id) .execute(); if (issueCreator[0] !== currentUser.id) { throw new PermissionDeniedError(); } } // close the issue }\n\nWhich, to be frank, is not too bad at all. Most of GitHub runs off of what\norganization/repository permissions a user has, so you manage that logic and\ndata in the shared authorization service. But you implement domain-specific\nauthorization logic, like \u201cissue creators can close their own issues\u201d, within\nthe service (i.e. IssueService) and use the application data you already have.\n\nBut we can do better. The above code has one big downside: a significant\namount of authorization logic has bled into the IssuesService.\n\nThat\u2019s bad because it creates a coupling between the AuthzService and the\nIssuesService.\n\nSuppose you want to modify your authorization logic to differentiate between\nwhich users can close locked issues. That might look something like:\n\n  1. Add code to IssuesService for checking if the user has \"close_locked_issues\" permission. Deploy these changes behind a feature flag.\n  2. Add the new permission to roles in the AuthzService, redeploy these changes.\n  3. Toggle the feature flag for IssuesService to enable the new feature.\n\nSmall changes in one service require coordinating code changes across multiple\nservices (and therefore teams).\n\nAt the same time, by deferring domain-specific authorization to the associated\nservices, each team is left to \u201cdraw the rest of the owl\u201d in their\napplication. For example, it\u2019s fortunate that when implementing \u201ccreators can\nclose issues\u201d, the Issues team remembered to check the issue creator still has\nread-level access to the repository (employees who left the company shouldn\u2019t\nbe able to close their old issues). But this logic is outside the\nAuthzService, so you\u2019ve lost most of your tools to make sure that this line is\nimplemented correctly, and tested.\n\n### Cleaning up the Mess\n\nAs we said at the beginning: authorization is messy.\n\nTo decide who can do what to which resources, you need knowledge about what\nthose resources are and how they relate to other resources. But you don\u2019t want\nauthorization logic to leak into your application, and you don\u2019t want to\nduplicate application data in your authorization service. That means you need\na way to distribute authorization decisions across both the AuthzService and\nIssueService.\n\nThe code sample above got us close, but a solution that eliminates the leaked\nauthorization logic while maintaining encapsulation of the domain-specific\ndata would be more resilient to changes in logic or data on either end.\nPractically, this means:\n\n  1. Centralizing all authorization logic in the authorization service\n  2. Centralizing shared authorization data (e.g. organization and repository roles) in the authorization service\n  3. Keeping domain specific authorization data in the appropriate application database\n\n### Evaluating Polar against an Application DB\n\nWe achieve this by bringing the power of Polar to data stored across multiple\ndata stores. And importantly, to data stored outside of Oso Cloud.\n\nWe have prior experience turning Polar into SQL that runs inside an\napplication. However, previously we relied on ORMs to do the query building.\nWe returned an intermediate representation inspired by relational algebra, and\nused the ORM to turn this into SQL.\n\nBut given that we are already working with an intermediate representation we\nknow is flexible enough to convert to SQL, we looked at what we already had\nwhen thinking about this problem again.\n\nWe need to do two things:\n\n  1. Turn our intermediate representation into SQL to run it against an application database.\n  2. Split the intermediate representation into an Oso part that runs centrally and a local part that runs in the application.\n\nOne way to do (1) which is relatively naive, but close to what we need, is to\nuse CTEs to make the application database \u201clook like\u201d our own internal schema,\ne.g. in the previous query replace fact_0 and fact_1 with a CTE describing how\nto get that data:\n\n    \n    \n    WITH fact_0(arg0, arg1, arg2) as ( SELECT id, 'parent', repository_id FROM issues ), fact_1(arg0, arg1, arg2) as ) SELECT user_id, \"role\", repository_id FROM repository_roles ) SELECT f0.arg0 FROM fact_0 f0, fact_1 f1 WHERE f0.arg2 = f1.arg2 and f0.arg1 = 'parent' and f1.arg1 = 'triage' and f1.arg0 = 'alice';\n\nTo get this, we just need a configuration file that maps between the Oso data\nschema and SQL tables, e.g.\n\n    \n    \n    facts: has_relation(Issue:_, String:_, Repository:_): query: |- SELECT id, 'parent', repository_id FROM issues has_role(User:_, String:_, Repository:_): query: |- SELECT user_id, \"role\", repository_id FROM repository_roles\n\nHaving a simple mapping from an application DB to Oso facts was no accident.\nWe have a simple rule of thumb for mapping data to Oso:\n\n  1. Roles: many-to-many or one-to-many tables which relate two tables/primary keys and have an additional \u201crole\u201d attribute.\n  2. Relationships: a primary key + a foreign key\n  3. Attributes: a primary key + a column value\n\nWe tell our customers to use this simple mapping for sending Oso data, and so\nall of our common patterns for authorization rules are expressed in terms of\nthis data.\n\nThe \u201cissue\u201d table has a primary key, foreign keys for the parent repository\nand issue creator, and a column for if its locked. Combinations of these map\nto relationship and attribute data in Oso.\n\nThe mapping that we create is a \u201cvirtual\u201d mapping. We don\u2019t actually need to\nmodify the database in any way, nor persist any data. But if we were to\nconvert the data into how Polar sees it, or to expand out the CTEs that we\ngenerate into actual tables, it would look something like this:\n\nEach row in the \u201cissue\u201d table maps to many facts.\n\nAnd just like that* we have a policy language that can run over an application\ndatabase with minimal configuration.\n\n*Note: I would like to clarify that the intent here is to say that it\u2019s that easy for Oso users, and not diminish the effort of the Oso team who implemented this feature \ud83d\udc3b\n\n### Splitting the lookup across two services\n\nWe now have (1) \u2014 a way to run SQL against an application database.\n\nLets move on to (2) \u2014 split the intermediate representation into an Oso part\nand a local part.\n\nOnce we had figured out the configuration and how that would compile to SQL,\ndeciding on how to \u201csplit\u201d the intermediate state was clear.\n\nWe partition the facts we\u2019re searching for into Oso parts and local parts, and\ncreate dummy variables to bridge the two, e.g. we know the issuesService\nmanages issue data, and therefore the has_relation facts between issues and\nrepositories, whereas Oso manages roles\n\nBefore splitting:\n\n    \n    \n    Outputs: issue: f0.arg0 Facts: f0: has_relation(Issue, String, Repository) f1: has_role(User, String, Repository) Conditions: f0.arg2 = f1.arg2 f0.arg1 = \"parent\" f1.arg1 = \"triage\" f1.arg0 = User{\"alice\"}\n\nAfter splitting:\n\n    \n    \n    ### Oso part: Outputs: var0: f1.arg2 Facts: f1: has_role(User, String, Repository) Conditions: f1.arg1 = \"triage\" f1.arg0 = User{\"alice\"} ### Local part Outputs: issue: f0.arg0 Facts: f0: has_relation(Issue, String, Repository) Conditions: f0.arg2 = inputs.var0 f0.arg1 = \"parent\"\n\nOn Oso\u2019s side, we evaluate the Oso part in an identical way to before: we\ncompile it to SQL, run the SQL, and get back a set of results.\n\nTo resolve the rest of the authorization result within the application, we\u2019ll\nneed to take:\n\n  1. The other half of the intermediate representation\n  2. The schema mapping configuration\n  3. The partially evaluated results from Oso\n\nAnd turn them into a SQL query we can run.\n\nThat is, we combine:\n\nthe required lookups:\n\n    \n    \n    Outputs: issue: f0.arg0 Facts: f0: has_relation(Issue, String, Repository) Conditions: f0.arg2 = inputs.var0 f0.arg1 = \"parent\"\n\nplus the configuration:\n\n    \n    \n    has_relation(Issue:_, String:_, Repository:_): query: | select id, repository_id from issues\n\nand the inputs from Oso:\n\n    \n    \n    inputs: ('anvil', ...)\n\nto compute the SQL to perform \u201cthe rest of the authorization\u201d:\n\n    \n    \n    WITH fact_0(arg0, arg1, arg2) as ( SELECT id, 'parent', repository_id FROM issues ) SELECT f0.arg0 FROM fact_0 f0 WHERE f0.arg2 in ('anvil', ...);\n\nThe IssueService can run this SQL against its own database to check\nauthorization of a single entity:\n\n    \n    \n    // get \"Local Part\" from Oso Cloud const authorizeSql = await oso.authorizeLocal(user, \"close\", issue); const { allowed } = ( // evaluate \"Local Part\" against application database await sql.raw<{ allowed: boolean }>(authorizeSql).execute(db) ).rows[0];\n\nBy converting the intermediate polar representation to SQL that the\nIssueService can run, we have built a way to access authorization data that is\ndistributed across multiple services.\n\nWith all this in place, the closeIssue method gets a whole lot shorter:\n\n    \n    \n    async function closeIssue(issueData: IssueData) { // get \"Local Part\" from Oso Cloud const authorizeSql = await oso.authorizeLocal(user, \"close\", issue); const { allowed } = ( // evaluate \"Local Part\" against application database await sql.raw<{ allowed: boolean }>(authorizeSql).execute(db) ).rows[0]; if (!allowed) { throw new PermissionDeniedError(); } // close the issue }\n\nYou can also use this approach to generate lists of authorized issues. For\nexample, to return all the issues that the current user can close:\n\n    \n    \n    // get \"Local Part\" from Oso Cloud const listSql = await await oso.listLocal(user, \"close\", \"Issue\", \"id\") // evaluate \"Local Part\" against application database const results = await db .selectFrom(\"issues\") .where(sql.raw<boolean>(listSql)) .selectAll() .execute();\n\nBecause you\u2019re creating the list against the local database, it\u2019s easy to sort\nand paginate the results.\n\n    \n    \n    // get \"Local Part\" from Oso Cloud const listSql = await await oso.listLocal(user, \"close\", \"Issue\", \"id\") // evaluate \"Local Part\" against application database const results = await db .selectFrom(\"issues\") .where(sql.raw<boolean>(listSql)) .orderBy(\"created_at\") .offset(50) .limit(25) .selectAll() .execute();\n\n### Conclusion\n\nReferring back to our initial criteria:\n\na shared authorization capability must provide mechanisms for:\n\n  1. expressing the above logic, which spans the Authz and Issues domains\n  2. using data stored in both the AuthzService and IssuesService\n  3. supporting yes/no questions as well as more flexible \u201clist\u201d questions\n\nWe achieved all three of these! We have Polar to express declarative logic\ndecoupled from any one service. We distribute Polar across services to avoid\nneeding to sync data anywhere, and our approach of compiling Polar to SQL\nmakes it possible to ask any kind of question without needing to rewrite any\nlogic.\n\nTry it out here: https://www.osohq.com/docs/guides/integrate/filter-\nlists#list-filtering-with-decentralized-data\n\n##### Want us to remind you?\n\nGreat decision!\n\nOops! That's...not a valid email :-/\n\nWe'll email you before the event with a friendly reminder.\n\n##### Implement authorization with Oso\n\nLearn about Oso\n\n### Write your first policy\n\nTry Oso Cloud\n\nRead the docs\n\n###### Product\n\nDocumentationUse casesPricingSecurityChangelogStatusPrivacy Policy\n\n###### Learn\n\nAuthorization AcademyWhat is Google Zanzibar?What is Open Policy Agent\n(OPA)?Authorization as a ServiceAuthorization FAQWhat is Attribute Based\nAccess Control (ABAC)?\n\n###### How-to\n\nRole-Based Access Control in PythonRole-Based Access Control in Node.jsRole-\nBased Access Control in GoDebugTestPolar Syntax\n\n\u00a9 2024 Oso Security, Inc.\n\n", "frontpage": true}
