{"aid": "40144044", "title": "Custom Dashboard for Great Expectations", "url": "https://blog.datachef.co/custom-dashboard-for-great-expectations", "domain": "datachef.co", "votes": 1, "user": "shahinism", "posted_at": "2024-04-24 13:18:34", "comments": 0, "source_title": "Custom dashboard for Great Expectations", "source_text": "Custom dashboard for Great Expectations\n\n# Custom dashboard for Great Expectations\n\n## Enable advanced dashboarding on Great Expectation results using metrics\n\nShahin\n\n\u00b7Apr 24, 2024\u00b7\n\n3 min read\n\n## Introduction\n\nNowadays, Great Expectations is a very viable option for most of the\norganizations to introduce data quality solution for their data platform.\nSimplicity, being easily customizable and relying on the toolbox that is\nmostly known to modern data engineers, are the common factors which help with\nlowering the adaption barrier.\n\nHowever, there is one part of Great Expectation, which I hoped to see\nsignificant improvement some day. The static dashboards! They are:\n\n  1. Static! And not much customizable.\n\n  2. Lack governance and require extra effort to manage users.\n\n  3. Lack features like a search bar, or historical or any other kind of specialized reports.\n\n  4. Lack direct access to logs.\n\nIn one of our recent projects at DataChef, we found ourselves, faced with\nthese limitations, and thought it's time to build on top of the flexibility\nwhich Great Expectation already provides. The idea was simple. When running\nthe suits, we wanted to generate metrics based on the findings, so we can use\nany modern dashboarding tool, to visualize the reports. For us, the following\nwere the main pros of this approach:\n\n  1. Customizability of the dashboards.\n\n  2. Relying on existing monitoring dashboards, and providing a holistic view over the whole life cycle of the data products (not just data quality).\n\n  3. Less maintenance and user management requirements.\n\n## How to do it?\n\nThe main part of the process, to extract metrics, remains the same as usual.\nThe interesting part happens, after running the checkpoint. This is where you\nhave something like the following:\n\n    \n    \n    checkpoint = context.get_validator( app_id, context, validator=validator ).run()\n\nThe result of this piece, is a very nested object containing the report of the\nexpectation suit, which unfortunately is not very well documented. However,\nthe concept is simple, which helps us to extract valuable metrics from the\nresult. We need to:\n\n  1. Find the validation identifier.\n\n  2. Get the corresponding result object.\n\n  3. For each column in the result set, publish related metrics, if it applies.\n\nThis is how it looks like in code:\n\n    \n    \n    def get_columns(result_object: list[dict], delimiter: str = '_') -> str | None: \"\"\"Given the result object, extract the column name. The column name might be a list, in that case, make a string, using delimiter. Args: result_object (list[dict]): Great Expectation's result object. delimiter (str): Delimiter to use for list columns. Returns: column name if exists. \"\"\" kwargs = result[\"expectation_config\"][\"kwargs\"] column = kwargs.get(\"column\") columns = kwargs.get(\"columns\") column_list = kwargs.get(\"column_list\") if column: return column elif columns: return \"_\".join(columns) elif column_list: return \"_\".join(column_list) def process_checkpoint(checkpoint: list[dict], target_table: str) -> None: \"\"\"Process Great Expectation checkpoint object, and invoke `publish_metrics` method. Args: checkpoint (list[dict]): The great expectation checkpoint object. target_table (str): Name of the target table used by GX. \"\"\" run_results = checkpoint.get(\"run_results\") if not run_results: raise Exception(\"Couldn't find run_result. Make sure you are using correct GX API\") run_id = next(iter(run_results)) results = run_results[run_id][\"validation_result\"][\"result\"] for result in results: columns = get_columns(result) rule = result[\"expectation_config\"][\"expectation_type\"] element_count = result[\"result\"][\"element_count\"] success = 1 if result[\"success\"] else 0 error = 1 if result[\"exception_info\"][\"raised_exception\"] else 0 failure_rate = result[\"result\"][\"unexpected_percent\"] publish_metrics( target_table=target_table, element_count=element_count, success=success, error=error failure_rate=failure_rate ) def publish_metrics(): ...\n\nAnd with that, all you need to do, is define the publish_metrics method,\ntargeting your desired system. We used AWS CloudWatch for it, but in theory,\nany other system can be used.\n\nFor visualizations, you can use any system too. We used Grafana, which was\nvery useful for our needs, especially since our organization's observability\nalready depended on it.\n\n## Conclusion\n\nI think Great Expectation is already doing an impressive job, on the\nvalidation side of the data quality. It would've been nice, if the project,\nwas expanding its flexibility of choice, to the dashboarding part as well.\n\nWe covered how simple this can be extracted in this blog post. The only\npossible bottleneck would be the change of the APIs used for metrics, which\nare not guaranteed to remain the same.\n\ngreat-expectationsGrafanadata-quality#CloudWatch\n\n### Written by\n\n# Shahin\n\n\ud83e\uddd1\ud83c\udf73 Cooking data as a chef de partie at DataChef.co by day! \ud83e\ude84 Avid coder\ninventing magic by night!\n\n\ud83e\uddd1\ud83c\udf73 Cooking data as a chef de partie at DataChef.co by day! \ud83e\ude84 Avid coder\ninventing magic by night!\n\n### Published on\n\n# DataChef's Blog\n\nShare this\n\n### More articles\n\nBram Elfrink\n\n# Navigating Data Platforms: Principles for Success\n\nWelcome to the first part of our series on data platforms! In this series, we\nare going to dive into...\n\nAli Yazdizadeh\n\n# FP-Growth Algorithm and How to Avoid Its Dark Side!\n\nContext A few weeks ago we were contacted by FrieslandCampina to help them\nwith a problem they faced...\n\nZambo\n\n# Speed up dbt workflow with Task\n\nDo you remember the last time you opened your laptop and thought: \"I can't\nwait to spend half my day...\n\n\u00a92024 DataChef's Blog\n\nArchive\u00b7Privacy policy\u00b7Terms\n\n", "frontpage": false}
