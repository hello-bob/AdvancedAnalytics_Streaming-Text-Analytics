{"aid": "40280485", "title": "How to rewrite a C++ codebase successfully", "url": "https://gaultier.github.io/blog/how_to_rewrite_a_cpp_codebase_successfully.html", "domain": "gaultier.github.io", "votes": 1, "user": "heinrich5991", "posted_at": "2024-05-06 23:03:01", "comments": 0, "source_title": "How to rewrite a C++ codebase successfully", "source_text": "How to rewrite a C++ codebase successfully\n\nPhilippe Gaultier\n\n  * Body of work\n  * Resume\n  * LinkedIn\n  * Github\n  * Feed\n\nPublished on 2024-05-03.\n\n# How to rewrite a C++ codebase successfully\n\nNot your typical \u2018Rewrite it in Rust\u2019 article.\n\nI recently wrote about inheriting a legacy C++ codebase. At some point,\nalthough I cannot pinpoint exactly when, a few things became clear to me:\n\n  * No one in the team but me is able - or feels confident enough - to make a change in this codebase\n  * This is a crucial project for the company and will live for years if not decades\n  * The code is pretty bad on all the criteria we care about: correctness, maintainability, security, you name it. I don\u2019t blame the original developers, they were understaffed and it was written as a prototype (the famous case of the prototype which becomes the production code).\n  * No hiring of C++ developers is planned or at least in the current budget (also because that\u2019s the only C++ project we have and we have many other projects to maintain and extend)\n\nSo it was apparent to me that sticking with C++ was a dead end. It\u2019s simply a\nconflict of values and priorities: C++ values many things that are not that\nimportant in this project, such as performance above all; and it does not give\nany guarantees about things that are crucial to us, such as memory and\ntemporal safety (special mention to integer under/overflows. Have fun\nreviewing every single instance of arithmetic operations to check if it can\nunder/overflow).\n\nWe bought a race car but what we needed was a family-friendly 5 seater, that\u2019s\nour mistake.\n\nThe only solution would be to train everyone in the team on C++ and dedicate a\nsignificant amount of time rewriting the most problematic parts of the\ncodebase to perhaps reach a good enough state, and even then, we\u2019d have little\nconfidence our code is robust against nation-state attacks.\n\nIt\u2019s a judgment call in the end, but that seemed to be more effort than\n\u2018simply\u2019 introducing a new language and doing a rewrite.\n\nI don\u2019t actually like the term \u2018rewrite\u2019. Folks on the internet will eagerly\nrepeat that rewrites are a bad idea, will undoubtedly fail, and are a sign of\nhubris and naivety. I have experienced such rewrites, from scratch, and yes\nthat does not end well.\n\nHowever, I claim, because I\u2019ve done it, and many others before me, that an\nincremental rewrite can be successful, and is absolutely worth it. It\u2019s all\nabout how it is being done, so here\u2019s how I proceeded and I hope it can be\napplied in other cases, and people find it useful.\n\nI think it\u2019s a good case study because whilst not a big codebase, it is a\ncomplex codebase, and it\u2019s used in production on 10+ different operating\nsystems and architectures, including by external customers. This is not a toy.\n\nSo join me on this journey, here\u2019s the guide to rewrite a C++ codebase\nsuccessfully. And also what not do!\n\nTable of Contents\n\n  * The project\n  * Improve the existing codebase\n  * Get buy-in\n  * Keeping buy-in\n  * Preparations to introduce the new language\n  * Incremental rewrite\n  * Fuzzing\n  * Pure Rust vs interop (FFI)\n\n    * C FFI in Rust is cumbersome and error-prone\n    * An example of a real bug at the FFI boundary\n    * Another example of a real bug at the FFI boundary\n  * Cross-compilation\n  * Conclusion\n\n## The project\n\nThis project is a library that exposes a C API but the implementation is C++,\nand it vendors C libraries (e.g. mbedtls) which we build from source. The\nfinal artifacts are a libfoo.a static library and a libfoo.h C header. It is\nused to talk to applets on a smart card like your credit card, ID, passport or\ndriving license (yes, smart cards are nowadays everywhere - you probably carry\nseveral on you right now), since they use a bizzarre interesting communication\nprotocol. The library also implements a home-grown protocol on top of the\nwell-specified smart card protocol, encryption, and business logic.\n\nIt is meant to be part of an user-facing application running on smartphones\nand Point of Sales terminals, as well as in servers running in a datacenter or\nin the cloud.\n\nThis library is used in:\n\n  * Android applications, through JNI\n  * Go back-end services running in Kubernetes, through CGO\n  * iOS applications, through Swift FFI\n  * C and C++ applications running on very small 32 bits ARM boards similar to the first Raspberry Pi\n\nAdditionally, developers are using macOS (x64 and arm64) and Linux so the\nlibrary needs to build and run on these platforms.\n\nSince external customers also integrate their applications with our library\nand we do not control these environments, and because some developer machines\nand servers use glibc and others musl, we also need to work with either the\nglibc and the musl C libraries, as well as clang and gcc, and expose a C89-ish\nAPI, to maximize compatibility.\n\nAlright, now that the stage is set, let\u2019s go through the steps of rewriting\nthis project.\n\n## Improve the existing codebase\n\nThat\u2019s basically all the steps in Inheriting a legacy C++ codebase. We need to\nstart the rewrite with a codebase that builds and runs on every platform we\nsupport, with tests passing, and a clear README explaining how to setup the\nproject locally. This is a small investment (a few days to a few weeks\ndepending on the scale of the codebase) that will pay massive dividends in the\nfuture.\n\nBut I think the most important point is to trim all the unused code which is\ntypically the majority of the codebase! No one wants to spend time and effort\non rewriting completely unused code.\n\nAdditionally, if you fail to convince your team and the stakeholders to do the\nrewrite, you at least have improved the codebase you are now stuck with. So\nit\u2019s time well spent either way.\n\n## Get buy-in\n\nSame as in my previous article: Buy-in from teammates and stakeholders is\nprobably the most important thing to get, and maintain.\n\nIt\u2019s a big investment in time and thus money we are talking about, it can only\nwork with everyone on board.\n\nHere I think the way to go is showing the naked truth and staying very\nfactual, in terms managers and non-technical people can understand. This is\nroughly what I presented:\n\n  * The bus factor for this project is 1 (me)\n  * Tool X shows that there are memory leaks at the rate of Y MiB/hour which means the application using our library will be OOM killed after around Z minutes/hours.\n  * Quick and dirty fuzzing manages to make the library crash 133 times in 10 seconds\n  * Linter X detects hundreds of real issues we need to fix\n  * All of these points make it really likely a hacker can exploit our library to gain Remote Code Execution (RCE) or steal secrets\n\nEssentially, it\u2019s a matter of genuinely presenting the alternative of\nrewriting being cheaper in terms of time and effort compared to improving the\nproject with pure C++. If your teammates and boss are reality-based, it should\nbe a straightforward decision.\n\nWe use at my day job basically a RFC process to introduce a major change.\nThat\u2019s great because it forces the person pushing for a change to document the\ncurrent issues, the possible solutions, and allowing for a rational discussion\nto take place in the team. And documenting the whole process in a shared\ndocument (that allows comments) is very valuable because when people ask about\nit months later, you can just share the link to it.\n\nAfter the problematic situation has been presented, I think at least 3\ndifferent solutions should be presented and compared (including sticking with\npure C++), and seriously consider each option. I find it important here to be\nas little emotionally invested as possible even if one option is your\nfavorite, and to be ready to work for possibly months on your least favorite\noption, if it happens to be chosen by the collective.\n\nIdeally, if time permits, a small prototype for the preferred solution should\nbe done, to confirm or infirm early that it can work, and to eliminate doubts.\nIt\u2019s a much more compelling argument to say: \u201cOf course it will work, here is\nprototype I made, let\u2019s look at it together!\u201d compared to \u201cI hope it will\nwork, but who knows, oh well I guess we\u2019ll see 3 months in...\u201d.\n\nAfter much debate, we settled on Rust as the new programming language being\nintroduced into the codebase. It\u2019s important to note that I am not a Rust die\nhard fan. I appreciate the language but it\u2019s not perfect (see the FFI section\nlater), it has issues, it\u2019s just that it solves all the issues we have in this\nproject, especially considering the big focus on security (since we deal with\npayments), the relative similarity with the company tech stack (Go), and the\nwillingness of the team to learn it and review code in it.\n\nAfter all, the goal is also to gain additional developers, and stop being the\nonly person who can even touch this code.\n\nI also seriously considered Go, but after doing a prototype, I was doubtful\nthe many limitations of CGO would allow us to achieve the rewrite. Other\nteammates also had concerns on how the performance and battery usage would\nlook like on low-end Android and Linux devices, especially 32 bits, having\nessentially two garbage collectors running concurrently, the JVM one and the\nGo one.\n\n## Keeping buy-in\n\nKeeping buy-in after initially getting it is not a given, since software\nalways takes longer than expected and unexpected hurdles happen all the time.\nHere, showing the progress through regular demos (weekly or biweekly is a good\nfrequency) is great for stakeholders especially non-technical ones. And it can\npotentially motivate fellow developers to also learn the new language and help\nyou out.\n\nAdditionally, showing how long-standing issues in the old code get\nautomatically solved by the new code, e.g. memory leaks, or fuzzing crashes in\none function, are a great sign for stakeholders of the quality improving and\nthe value of the on-going effort.\n\nBe prepared to repeat many many times the decision process that led to the\nrewrite to your boss, your boss\u2019s boss, the odd product manager who\u2019s not\ntechnical, the salesperson supporting the external customers, etc. It\u2019s\nimportant to nail the elevator\u2019s pitch.\n\nThat applies also to teammates, who might be unsure the new programming\nlanguage \u2018carries its weight\u2019. It helps to regularly ask them how they feel\nabout the language, the on-going-effort, the roadmap, etc. Also, pairing with\nthem, so that ideally, everyone in the team feels confident working on this\nproject alone.\n\n## Preparations to introduce the new language\n\nBefore adding the first line of code in the new language, I created a Git tag\nlast-before-rust. The commit right after introduced some code in Rust.\n\nThis proved invaluable, because when rewriting the legacy code, I found tens\nof bugs lying around, and I think that\u2019s very typical. Also, this rewriting\neffort requires time, during which other team members or external customers\nmay report bugs they just found.\n\nEvery time such a bug appeared, I switched to this Git tag, and tried to\nreproduce the bug. Almost every time, the bug was already present before the\nrewrite. That\u2019s a very important information (for me, it was a relief!) for\nsolving the bug, and also for stakeholders. That\u2019s the difference in their eye\nbetween: We are improving the product by fixing long existing bugs; or: we are\nintroducing new bugs with our risky changes and we should maybe stop the\neffort completely because it\u2019s harming the product.\n\nFurthermore, I think the first commit introducing the new code should add\ndummy code and focus on making the build system and CI work seamlessly on\nevery supported platform. This is not appealing work but it\u2019s necessary. Also,\nhaving instructions in the README explaining a bit what each tool does (cargo,\nrustup, clippy, etc) is very valuable and will ease beginners into\ncontributing in the new language.\n\n## Incremental rewrite\n\nAlong with stakeholder buy-in, the most important point in the article is that\nonly an incremental rewrite can succeed, in my opinion. Rewriting from scratch\nis bound to fail, I think. At least I have never seen it succeed, and have\nseen it fail many times.\n\nWhat does it mean, very pragmatically? Well it\u2019s just a few rules of thumb:\n\n  * A small component is picked to be rewritten, the smallest, the better. Ideally it is as small as one function, or one class.\n  * The new implementation is written in the same Git (or whatever CVS you use) repository as the existing code, alongside it. It\u2019s a \u2018bug for bug\u2019 implementation which means it does the exact same thing as the old implementation, even if the old seems sometimes non-sensical. In some cases, what the old code tries to do is so broken and insecure, that we have to do something different in the new code, but that should be rare.\n  * Tests for the new implementation are written and pass (so that we know the new implementation is likely correct)\n  * Each site calling the function/class is switched to using the new implementation. After each replacement, the test suite is run and passes (so that we know that nothing broke at the scale of the project; a kind of regression testing). The change is committed. That way is something breaks, we know exactly which change is the culprit.\n  * A small PR is opened, reviewed and merged. Since our changes are anyways incremental, it\u2019s up to us to decide that the current diff is of the right size for a PR. We can make the PR as big or small as we want. We can even make a PR with only the new implementation that\u2019s not yet used at all.\n  * Once the old function/class is not used anymore by any code, it can be \u2018garbage-collected\u2019 i.e. safely removed. This can even be its own PR depending on the size.\n  * Rinse and repeat until all of the old code has been replaced\n\nThere are of course thornier cases, but that\u2019s the gist of it. What\u2019s crucial\nis that each commit on the main branch builds and runs fine. At not point the\ncodebase is ever broken, does not build, or is in an unknown state.\n\nIt\u2019s actually not much different from the way I do a refactor in a codebase\nwith just one programming language.\n\nWhat\u2019s very important to avoid are big PRs that are thousands lines long and\nnobody wants to review them, or long running branches that effectively create\na multiverse inside the codebase. It\u2019s the same as regular software\ndevelopment, really.\n\nHere are a few additional tips I recommend doing:\n\n  * Starting from the leaves of the call graph is much easier than from the root. For example, if foo calls bar which calls baz, first rewriting baz then bar then foo is straightforward, but the reverse is usually not true.\n  * Thus, mapping out at the start from a high-level what are the existing components and which component calls out to which other component is invaluable in that regard, but also for establishing a rough roadmap for the rewrite, and reporting on the progress (\u201c3 components have been rewritten, 2 left to do!\u201d).\n  * Port the code comments from the old code to the new code if they make sense and add value. In my experience, a few are knowledge gems and should be kept, and most are completely useless noise.\n  * If you can use automated tools (search and replace, or tools operating at the AST level) to change every call site to use the new implementation, it\u2019ll make your reviewers very happy, and save you hours and hours of debugging because of a copy-paste mistake\n  * Since Rust and C++ can basically only communicate through a C API (I am aware of experimental projects to make them talk directly but we did not use those - we ultimately want 100% Rust code exposing a C API, just like the old C++ did), it means that each Rust function must be accompanied by a corresponding C function signature, so that C++ can call it as a C function. I recommend automating this process with cbindgen. I have encountered some limitations with it but it\u2019s very useful, especially to keep the implementation (in Rust) and the API (in C) in sync, or if your teammates are not comfortable with C.\n  * Automate when you can, for example I added the cbindgen code generation step to CMake so that rebuilding the C++ project would automatically run cbindgen as well as cargo build for the right target in the right mode (debug or release) for the right platforms (--target=...). DevUX matters!\n  * When rewriting a function/class, port the tests for this function/class to the new implementation to avoid reducing the code coverage each time\n  * Make the old and the new test suites fast so that the iteration time is short\n  * When a divergence is detected (a difference in output or side effects between the old and the new implementation), observe with tests or within the debugger the output of the old implementation (that\u2019s where the initial Git tag comes handy, and working with small commits) in detail so that you can correct the new implementation. Some people even develop big test suites verifying that the output of the old and the new implementation are exactly the same.\n  * Since it\u2019s a bug-for-bug rewrite, what the new implementation does may seem weird or unnecessarily convoluted but shall be kept (at least as a first pass). However, how it does it in the new code should be up to the best software engineering standards, that means tests, fuzzing, documentation, etc.\n  * Thread lightly, what can tank the project is being too bold when rewriting code and by doing so, introducing bugs or subtly changing the behavior which will cause breakage down the line. It\u2019s better to be conservative here.\n  * Pick a prefix for all structs and functions in the C API exposed by the Rust code, even if it\u2019s just RUST_xxx, so that they are immediately identifiable and greppable. Just like libcurl has the prefix curl_xxx.\n\nFinally, there is one hidden advantage of doing an incremental rewrite. A\nfrom-scratch rewrite is all or nothing, if it does not fully complete and\nreplace the old implementation, it\u2019s useless and wasteful. However, an\nincremental rewrite is immediately useful, may be paused and continued a\nnumber of times, and even if the funding gets cut short and it never fully\ncompletes, it\u2019s still a clear improvement over the starting point.\n\n## Fuzzing\n\nI am a fan a fuzzing, it\u2019s great. Almost every time I fuzz some code, I find\nan corner case I did not think about, especially when doing parsing.\n\nI added fuzzing to the project so that every new Rust function is fuzzed. I\ninitially used AFL but then turned to cargo-fuzz, and I\u2019ll explain why.\n\nFuzzing is only useful if code coverage is high. The worst that can happen is\nto dedicate serious time to setup fuzzing, to only discover at the end that\nthe same few branches are always taken during fuzzing.\n\nCoverage can only be improved if developers can easily see exactly which\nbranches are being executed during fuzzing. And I could not find an easy way\nwith AFL to get a hold on that data.\n\nUsing cargo-fuzz and various LLVM tools, I wrote a small shell script to\nvisualize exactly which branches are taken during fuzzing as well as the code\ncoverage in percents for each file and for the project as a whole (right now\nit\u2019s at around 90%).\n\nTo get to a high coverage, the quality of the corpus data is paramount, since\nfuzzing works by doing small mutations of this corpus and observing which\nbranches are taken as a result.\n\nI realized that the existing tests in C++ had lots of useful data in them,\ne.g.:\n\n    \n    \n    const std::vector<char> input = {0x32, 0x01, 0x49, ...}; // <= This is the interesting data. assert(foo(input) == ...);\n\nSo I had the idea of extracting all the input = ... data from the tests to\nbuild a good fuzzing corpus. My first go at it was a hand-written quick and\ndirty C++ lexer in Rust. It worked but it was clunky. Right after I finished\nit, I thought: why don\u2019t I use tree-sitter to properly parse C++ in Rust?\n\nAnd so I did, and it turned out great, just 300 lines of Rust walking through\neach TestXXX.cpp file in the repository and using tree-sitter to extract each\npattern. I used the query language of tree-sitter to do so:\n\n    \n    \n    let query = tree_sitter::Query::new( tree_sitter_cpp::language(), \"(initializer_list (number_literal)+) @capture\", )\n\nThe tree-sitter website thankfully has a playground where I could experiment\nand tweak the query and see the results live.\n\nAs time went on and more and more C++ tests were migrated to Rust tests, it\nwas very easy to extend this small Rust program that builds the corpus data,\nto also scan the Rust tests!\n\nA typical Rust test would look like this:\n\n    \n    \n    const INPUT: [u8; 4] = [0x01, 0x02, 0x03, 0x04]; // <= This is the interesting data. assert_eq!(foo(&INPUT), ...);\n\nAnd the query to extract the interesting data would be:\n\n    \n    \n    let query = tree_sitter::Query::new( tree_sitter_rust::language(), // TODO: Maybe make this query more specific with: // `(let_declaration value: (array_expression (integer_literal)+)) @capture`. // But in a few cases, the byte array is defined with `const`, not `let`. \"(array_expression (integer_literal)+) @capture\", )\n\nHowever I discovered that not all data was successfully extracted. What about\nthis code:\n\n    \n    \n    const BAR : u8 = 0x42; const INPUT: [u8; 4] = [BAR, 0x02, 0x03, 0x04]; // <= This is the interesting data. assert_eq!(foo(&INPUT), ...);\n\nWe have a constant BAR which trips up tree-sitter, because it only see a\nliteral (i.e. 3 letters: \u2018B\u2019, \u2018A\u2019 and \u2018R\u2019) and does not know its value.\n\nThe way I solved this issue was to do two passes: once to collect all\nconstants along with their values in a map, and then a second pass to find all\narrays in tests:\n\n    \n    \n    let query = tree_sitter::Query::new( tree_sitter_rust::language(), \"(const_item value: (integer_literal)) @capture \", )\n\nSo that we can then resolve the literals to their numeric value.\n\nThat\u2019s how I implemented a compiler for the Kotlin programming language in the\npast and it worked great. Maybe there are more advanced approaches but this\none is dead-simple and fast so it\u2019s good enough for us.\n\nI am pretty happy with how this turned out, scanning all C++ and Rust files to\nfind interesting test data in them to build the corpus. I think this was key\nto move from the initial 20% code coverage with fuzzing (using a few hard-\ncoded corpus files) to 90%. It\u2019s fast too.\n\nAlso, it means the corpus gets better each time we had a test (be it in C++ or\nRust), for free.\n\nDoes it mean that the corpus will grow to an extreme size? Well, worry not,\nbecause LLVM comes with a fuzzing corpus minimizer:\n\n    \n    \n    # Minimize the fuzzing corpus (in place). cargo +nightly fuzz cmin [...]\n\nFor each file in the corpus, it feeds it as input to our code, observes which\nbranches are taken, and if a new set of branches is taken, this file remains\n(or perhaps gets minimized even more, not sure how smart this tool is).\nOtherwise it is deemed a duplicate and is trimmed.\n\nSo:\n\n  1. We generate the corpus with our program\n  2. Minimize it\n  3. Run the fuzzing for however long we wish. It runs in CI for every commit and developers can also run it locally.\n  4. When fuzzing is complete, we print the code coverage statistics\n\nFinally, we still have the option to add manually crafted files to this corpus\nif we wish. For example after hitting a bug in the wild, and fixing it, we can\nadd a reproducer file to the corpus as a kind of regression test.\n\n## Pure Rust vs interop (FFI)\n\nWriting Rust has been a joy, even for more junior developers in the team. Pure\nRust code was pretty much 100% correct on the first try.\n\nHowever we had to use unsafe {} blocks in the FFI layer. We segregated all the\nFFI code to one file, and converted the C FFI structs to Rust idiomatic\nstructs as soon as possible, so that the bulk of the Rust code can be\nidiomatic and safe.\n\nBut that means this FFI code is the most likely part of the Rust code to have\nbugs. To get some confidence in its correctness, we write Rust tests using the\nC FFI functions (as if we were a C consumer of the library) running under Miri\nwhich acts as valgrind essentially, simulating a CPU and checking that our\ncode is memory safe. Tests run perhaps 5 to 10 times as slow as without Miri\nbut this has proven invaluable since it detected many bugs ranging from\nalignment issues to memory leaks and use-after-free issues.\n\nWe run tests under Miri in CI to make sure each commit is reasonably safe.\n\nSo beware: introducing Rust to a C or C++ codebase may actually introduce new\nmemory safety issues, usually all located in the FFI code.\n\nThankfully that\u2019s a better situation to be in than to have to inspect all of\nthe codebase when a memory issue is detected.\n\n### C FFI in Rust is cumbersome and error-prone\n\nThe root cause for all these issues is that the C API that C++ and Rust use to\ncall each other is very limited in its expressiveness w.r.t ownership, as well\nas many Rust types not being marked #[repr(C)], even types you would expect\nto, such as Option, Vec or &[u8]. That means that you have to define your own\nequivalent types:\n\n    \n    \n    #[repr(C)] // An option type that can be used from C pub struct OptionC<T> { pub has_value: bool, pub value: T, } #[repr(C)] // Akin to `&[u8]`, for C. pub struct ByteSliceView { pub ptr: *const u8, pub len: usize, } /// Owning Array i.e. `Vec<T>` in Rust or `std::vector<T>` in C++. #[repr(C)] pub struct OwningArrayC<T> { pub data: *mut T, pub len: usize, pub cap: usize, } /// # Safety /// Only call from C. #[no_mangle] pub extern \"C\" fn make_owning_array_u8(len: usize) -> OwningArrayC<u8> { vec![0; len].into() }\n\nApparently, Rust developers do not want to commit to a particular ABI for\nthese types, to avoid missing out on some future optimizations. So it means\nthat every Rust struct now needs the equivalent \u201cFFI friendly\u201d struct along\nwith conversion functions (usually implemented as .into() for convenience):\n\n    \n    \n    struct Foo<'a> { x: Option<usize>, y: &'a [u8], z: Vec<u8>, } #[repr(C)] struct FooC { x: OptionC<usize>, y: ByteSliceView, z: OwningArrayC<u8>, }\n\nWhich is cumbersome but still fine, especially since Rust has powerful macros\n(which I investigated using but did not eventually). However, since Rust also\ndoes not have great idiomatic support for custom allocators, we stuck with the\nstandard memory allocator, which meant that each struct with heap-allocated\nfields has to have a deallocation function:\n\n    \n    \n    #[no_mangle] pub extern \"C\" fn foo_free(foo: &FooC) { ... }\n\nAnd the C or C++ calling code would have to do:\n\n    \n    \n    FooC foo{}; if (foo_parse(&foo, bytes) == SUCCESS) { // do something with foo... ... foo_free(foo); }\n\nTo simplify this, I introduced a defer construct to C++ (thanks Gingerbill!):\n\n    \n    \n    FooC foo{}; defer({foo_free(foo);}); if (foo_parse(&foo, bytes) == SUCCESS) { // do something with foo... ... }\n\nWhich feels right at home for Go developers, and is an improvement over the\nstyle in use in the old C++ code where it was fully manual calls to\nnew/delete.\n\nStill, it\u2019s more work than what you\u2019d have to do in pure idiomatic Rust or C++\ncode (or even C code with arenas for that matter).\n\nIn Zig or Odin, I would probably have used arenas to avoid that, or a general\nallocator with defer.\n\n### An example of a real bug at the FFI boundary\n\nMore perniciously, it\u2019s easy to introduce memory unsafety at the FFI boundary.\nHere is a real bug I introduced, can you spot it? I elided all the error\nhandling to make it easier to spot:\n\n    \n    \n    #[repr(C)] struct BarC { x: ByteSliceView, } #[no_mangle] unsafe extern \"C\" fn bar_parse(input: *const u8, input_len: usize, bar_c: &mut BarC) { let input: &[u8] = unsafe { std::slice::from_raw_parts(input, input_len) }; let bar: Bar = Bar { x: [input[0], input[1]], }; *bar_c = BarC { x: ByteSliceView { ptr: bar.x.as_ptr(), len: bar.x.len(), }, }; }\n\nclippy did not notice anything. address-sanitizer did not notice anything.\nHowever, both miri and valgrind did, and fuzzing crashed (which was not easy\nto troubleshoot but at least pinpointed to a problem).\n\nSo...found it? Still nothing? Well, let\u2019s be good developers and add a test\nfor it:\n\n    \n    \n    #[test] fn bar() { // This mimicks how C/C++ code would call our function. let mut bar_c = MaybeUninit::<BarC>::uninit(); let input = [0, 1, 2]; unsafe { bar_parse( input.as_ptr(), input.len(), bar_c.as_mut_ptr().as_mut().unwrap(), ); } let bar_c = unsafe { bar_c.assume_init_ref() }; let x: &[u8] = (&bar_c.x).into(); assert_eq!(x, [0, 1].as_slice()); }\n\nIf you\u2019re lucky, cargo test would fail at the last assertion saying that the\nvalue is not what we expected, but in my case it passed every time, and so the\nbug stayed undetected for a while. That\u2019s because we unknowingly introduced\nundefined behavior, and as such, how or if it manifests is impossible to tell.\n\nLet\u2019s run the test with Miri:\n\n    \n    \n    running 1 test test api::tests::bar ... error: Undefined Behavior: out-of-bounds pointer use: alloc195648 has been freed, so this pointer is dangling --> src/tlv.rs:321:18 | 321 | unsafe { &*core::ptr::slice_from_raw_parts(item.ptr, item.len) } | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ out-of-bounds pointer use: alloc195648 has been freed, so this pointer is dangling | = help: this indicates a bug in the program: it performed an invalid operation, and caused Undefined Behavior = help: see https://doc.rust-lang.org/nightly/reference/behavior-considered-undefined.html for further information help: alloc195648 was allocated here: --> src/api.rs:1396:9 | 1396 | let bar: Bar = Bar { | ^^^ help: alloc195648 was deallocated here: --> src/api.rs:1406:1 | 1406 | }\n\nMiri is great, I tell you.\n\nThe issue here is that we essentially return a pointer to local variable (x)\nfrom inside the function, so the pointer is dangling.\n\nAlternatively we can call our function from C/C++ and run that under valgrind:\n\n    \n    \n    int main() { BarC bar{}; const uint8_t input[] = {0, 1, 2, 3}; bar_parse(input, sizeof(input), &bar); assert(bar.x.ptr[0] == 0); assert(bar.x.ptr[1] == 1); }\n\nAnd I get:\n\n    \n    \n    ==805913== Conditional jump or move depends on uninitialised value(s) ==805913== at 0x127C34: main (src/example.cpp:13) ==805913== ==805913== Conditional jump or move depends on uninitialised value(s) ==805913== at 0x127C69: main (src/example.cpp:14)\n\nWhich is not very informative, but better than nothing. Miri\u2019s output is much\nmore actionable.\n\nSo in conclusion, Rust\u2019s FFI capabilities work but are tedious are error-prone\nin my opinion, and so require extra care and testing with Miri/fuzzing, with\nhigh code coverage of the FFI functions. It\u2019s not enough to only test the pure\n(non FFI) Rust code.\n\n### Another example of a real bug at the FFI boundary\n\nWhen I started this rewrite, I was under the impression that the Rust standard\nlibrary uses the C memory allocator (basically, malloc) under the covers when\nit needs to allocate some memory.\n\nHowever, I quickly discovered that it is not (anymore?) the case, Rust uses\nits own allocator - at least on Linux where there is no C library shipping\nwith the kernel. Miri again is the MVP here since it detected the issue of\nmixing the C and Rust allocations which prompted this section.\n\nAs Bryan Cantrill once said: \u201cglibc on Linux, it\u2019s just, like, your opinion\ndude\u201d. Meaning, glibc is just one option, among many, since Linux is just the\nkernel and does not ship with a libC. So the Rust standard library cannot\nexpect a given C library on every Linux system, like it would be on macOS or\nthe BSDs or Illumos. All of that to say: Rust implements its own memory\nallocator.\n\nThe consequence of this, is that allocating memory on the C/C++ side, and\nfreeing it on the Rust side, is undefined behavior: it amounts to freeing a\npointer that was never allocated by this allocator. And vice-versa, allocating\na pointer from Rust and freeing it from C.\n\nThat has dire consequences since most memory allocators do not detect this in\nrelease mode. You might free completely unrelated memory leading to use-after-\nfree later, or corrupt the memory allocator structures. It\u2019s bad.\n\nHere\u2019s a simplified example of code that triggered this issue:\n\n    \n    \n    #[repr(C)] pub struct FooC { foo: u8, bar: *mut usize, } #[no_mangle] pub extern \"C\" fn parse_foo(in_bytes: *const u8, in_bytes_len: usize, foo: &mut FooC) { let in_bytes: &[u8] = unsafe { &*core::ptr::slice_from_raw_parts(in_bytes, in_bytes_len) }; // Parse `foo` from `in_bytes` but `bar` is sometimes not present in the payload. // In that case it is set manually by the calling code. *foo = FooC { foo: in_bytes[0], bar: if in_bytes_len == 1 { core::ptr::null_mut() } else { let x = Box::new(in_bytes[1] as usize); Box::into_raw(x) }, } } #[no_mangle] pub extern \"C\" fn free_foo(foo: &mut FooC) { if !foo.bar.is_null() { unsafe { let _ = Box::from_raw(foo.bar); } } }\n\nAnd the calling code:\n\n    \n    \n    FooC foo{}; const uint8_t data[] = { 1 }; parse_foo(data, sizeof(data), &foo); if (foo.bar == nullptr) { foo.bar = new size_t{99999}; } free_foo(&foo);\n\nThis is undefined behavior if the array is of size 1, since in that case the\nRust allocator will free a pointer allocated by the C allocator, and address\nsanitizer catches it:\n\n    \n    \n    SUMMARY: AddressSanitizer: alloc-dealloc-mismatch /home/runner/work/llvm-project/llvm-project/final/llvm-project/compiler-rt/lib/asan/asan_malloc_linux.cpp:52:3 in free\n\nHowever, it is only detected with sanitizers on and if a test (or fuzzing)\ntriggers this case. Or by Miri if a Rust test covers this function.\n\nSo I recommend sticking to one \u2018side\u2019, be it C/C++ or Rust, of the FFI\nboundary, to allocate and free all the memory using in FFI structures. Rust\nhas an edge here since the long-term goal is to have 100% of Rust so it will\nhave to allocate all the memory anyway in the end.\n\nDepending on the existing code style, it might be hard to ensure that the\nC/C++ allocator is not used at all for structures used in FFI, due to\nabstractions and hidden memory allocations.\n\nOne possible solution (which I did not implement but considered) is making FFI\nstructures a simple opaque pointer (or \u2018handle\u2019) so that the caller has to use\nFFI functions to allocate and free this structure. That also means\nimplementing getter/setters for certain fields since the structures are now\nopaque. It maximizes the ABI compatibility, since the caller cannot rely on a\ngiven struct size, alignment, or fields.\n\nHowever that entails more work and more functions in the API.\n\nlibcurl is an example of such an approach, libuv is an example of a library\nwhich did not do this initially, but plans to move to this approach in future\nversions, which would be a breaking change for clients.\n\nSo to summarize, Miri is so essential that I don\u2019t know whether it\u2019s viable to\nwrite Rust code with lots of FFI (and thus lots of unsafe blocks) without it.\nIf Miri did not exist, I would seriously consider using only arenas or\nreconsider the use of Rust.\n\n## Cross-compilation\n\nRust has great cross-compilation support; C++ not so much. Nonetheless I\nmanaged to coerced CMake into cross-compiling to every platform we support\nfrom my Linux laptop. After using Docker for more than 10 years I am firmly\nagainst using Docker for that, it\u2019s just clunky and slow and not a good fit.\nAlso we already have to cross-compile to the mobile platforms anyway so why\nnot make that work for all platforms?\n\nThat way, I can even cross-compile tests and example programs in C or C++\nusing the library and run them inside qemu to make sure all platforms work as\nexpected.\n\nI took inspiration from the CMake code in the Android project, which has to\ncross-compile for many architectures. Did you know that Android supports x86\n(which is 32 bits), x86_64, arm (which is 32 bits), aarch64 (sometimes called\narm64), and more?\n\nIn short, you instruct CMake to cross-compile by supplying on the command-line\nthe variables CMAKE_SYSTEM_PROCESSOR and CMAKE_SYSTEM_NAME, which are the\nequivalent of GOARCH and GOOS if you are familiar with Go. E.g.:\n\n    \n    \n    $ cmake -B .build -S src -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ -DCMAKE_SYSTEM_NAME=Linux -DCMAKE_SYSTEM_PROCESSOR=arm\n\nOn the Rust side, you tell cargo to cross-compile by supplying the --target\ncommand-line argument, e.g.: --target=x86_64-unknown-linux-musl. This works by\nvirtue of installing the pre-compiled toolchain for this platform with rustup\nfirst:\n\n    \n    \n    $ rustup target add x86_64-unknown-linux-musl\n\nSo now we have to convert in CMake CMAKE_SYSTEM_ARCHITECTURE and\nCMAKE_SYSTEM_NAME into a target triple that clang and cargo can understand. Of\ncourse you have to do all the hard work yourself. This is complicated by lots\nof factors like Apple using the architecture name arm64 instead of aarch64,\niOS peculiarities, soft vs hard float, arm having multiple variants (v6, v7,\nv8, etc), and so on. Your mileage may vary. We opt-in into using musl with a\nCMake command line option, on Linux.\n\nHere it is in all its glory:\n\n    \n    \n    # We need to craft the target triple to make it work when cross-compiling. # NOTE: If an architecture supports both soft-float and hard-float, we pick hard-float (`hf`). # since we do not target any real hardware with soft-float. # Linux has two main libcs, glibc (the default) and musl (opt-in with `FMW_LIBC_MUSL=1`), useful for Alpine. if (CMAKE_SYSTEM_NAME STREQUAL \"Linux\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"x86_64\" AND NOT DEFINED FMW_LIBC_MUSL) set(TARGET_TRIPLE \"x86_64-unknown-linux-gnu\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Linux\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"x86_64\" AND \"${FMW_LIBC_MUSL}\" EQUAL 1) set(TARGET_TRIPLE \"x86_64-unknown-linux-musl\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Linux\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"arm\" AND NOT DEFINED FMW_LIBC_MUSL) set(TARGET_TRIPLE \"arm-unknown-linux-gnueabihf\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Linux\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"arm\" AND \"${FMW_LIBC_MUSL}\" EQUAL 1) set(TARGET_TRIPLE \"arm-unknown-linux-musleabihf\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Linux\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\" AND NOT DEFINED FMW_LIBC_MUSL) set(TARGET_TRIPLE \"aarch64-unknown-linux-gnu\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Linux\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\" AND \"${FMW_LIBC_MUSL}\" EQUAL 1) set(TARGET_TRIPLE \"aarch64-unknown-linux-musl\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Linux\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"armv7\") set(TARGET_TRIPLE \"armv7-unknown-linux-gnueabihf\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Darwin\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\") set(TARGET_TRIPLE \"aarch64-apple-darwin\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Darwin\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"arm64\") set(TARGET_TRIPLE \"aarch64-apple-darwin\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Darwin\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"x86_64\") set(TARGET_TRIPLE \"x86_64-apple-darwin\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"iOS\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"x86_64\") set(TARGET_TRIPLE \"x86_64-apple-ios\") execute_process(COMMAND xcrun --sdk iphonesimulator --show-sdk-path OUTPUT_VARIABLE CMAKE_OSX_SYSROOT) string(REPLACE \"\\n\" \"\" CMAKE_OSX_SYSROOT ${CMAKE_OSX_SYSROOT}) elseif (CMAKE_SYSTEM_NAME STREQUAL \"iOS\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\") set(TARGET_TRIPLE \"aarch64-apple-ios\") execute_process(COMMAND xcrun --sdk iphoneos --show-sdk-path OUTPUT_VARIABLE CMAKE_OSX_SYSROOT) string(REPLACE \"\\n\" \"\" CMAKE_OSX_SYSROOT ${CMAKE_OSX_SYSROOT}) elseif (CMAKE_SYSTEM_NAME STREQUAL \"iOS\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"arm64\") set(TARGET_TRIPLE \"aarch64-apple-ios\") execute_process(COMMAND xcrun --sdk iphoneos --show-sdk-path OUTPUT_VARIABLE CMAKE_OSX_SYSROOT) string(REPLACE \"\\n\" \"\" CMAKE_OSX_SYSROOT ${CMAKE_OSX_SYSROOT}) elseif (CMAKE_SYSTEM_NAME STREQUAL \"Android\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"arm\") set(TARGET_TRIPLE \"arm-linux-androideabi\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Android\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"armv7\") set(TARGET_TRIPLE \"armv7-linux-androideabi\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Android\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"armv7-a\") set(TARGET_TRIPLE \"armv7-linux-androideabi\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Android\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"aarch64\") set(TARGET_TRIPLE \"aarch64-linux-android\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Android\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"i686\") set(TARGET_TRIPLE \"i686-linux-android\") elseif (CMAKE_SYSTEM_NAME STREQUAL \"Android\" AND CMAKE_SYSTEM_PROCESSOR STREQUAL \"x86_64\") set(TARGET_TRIPLE \"x86_64-linux-android\") else() message(FATAL_ERROR \"Invalid OS/Architecture, not supported: CMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME} CMAKE_SYSTEM_PROCESSOR=${CMAKE_SYSTEM_PROCESSOR}\") endif() message(STATUS \"Target triple: ${TARGET_TRIPLE}\") # If we are cross compiling manually (e.g to Linux arm), `CMAKE_C_COMPILER_TARGET` and `CMAKE_CXX_COMPILER_TARGET` are unset and we need to set them manually. # But if we are cross compiling through a separate build system e.g. to Android or iOS, they will set these variables and we should not override them. if ( NOT DEFINED CMAKE_C_COMPILER_TARGET ) set(CMAKE_C_COMPILER_TARGET ${TARGET_TRIPLE}) endif() if ( NOT DEFINED CMAKE_CXX_COMPILER_TARGET ) set(CMAKE_CXX_COMPILER_TARGET ${TARGET_TRIPLE}) endif()\n\nThere was a lot of trial and error as you can guess.\n\nAlso, gcc is not directly supported for cross-compilation in this approach\nbecause gcc does not support a --target option like clang does, since it\u2019s not\na cross-compiler. You have to download the variant you need e.g.\ngcc-9-i686-linux-gnu to compile for x86, and set CMAKE_C_COMPILER and\nCMAKE_CXX_COMPILER to gcc-9-i686-linux-gnu. However, in that case you are not\nsetting CMAKE_SYSTEM_NAME and CMAKE_SYSTEM_PROCESSOR since it\u2019s in theory not\ncross-compiling, so cargo will not have its --target option filled, so it\nwon\u2019t work for the Rust code. I advise sticking with clang in this setup.\nStill, when not cross-compiling, gcc works fine.\n\nFinally, I wrote a Lua script to cross-compile for every platform we support\nto make sure I did not break anything. I resorted to using the Zig toolchain\n(not the language) to be able to statically link with musl or cross-compile\nfrom Linux to iOS which I could not achieve with pure clang. However this is\nonly my local setup, we do not use the Zig toolchain when building the\nproduction artifacts (e.g. the iOS build is done in a macOS virtual machine,\nnot from a Linux machine).\n\nThis is very useful also if you have several compile-time feature flags and\nwant to build in different configurations for all platforms, e.g.\nenable/disable logs at compile time:\n\n    \n    \n    local android_sdk = arg[1] if android_sdk == nil or android_sdk == \"\" then print(\"Missing Android SDK as argv[1] e.g. '~/Android/Sdk/ndk/21.4.7075529'.\") os.exit(1) end local build_root = arg[2] if build_root == nil then build_root = \"/tmp/\" end local rustup_targets = { \"aarch64-apple-darwin\", \"aarch64-linux-android\", \"aarch64-unknown-linux-gnu\", \"aarch64-unknown-linux-musl\", \"arm-linux-androideabi\", \"arm-unknown-linux-gnueabihf\", \"arm-unknown-linux-musleabihf\", \"armv7-linux-androideabi\", \"armv7-unknown-linux-gnueabi\", \"armv7-unknown-linux-gnueabihf\", \"armv7-unknown-linux-musleabi\", \"armv7-unknown-linux-musleabihf\", \"i686-linux-android\", \"x86_64-apple-darwin\", \"x86_64-linux-android\", \"x86_64-unknown-linux-gnu\", \"x86_64-unknown-linux-musl\", } for i = 1,#rustup_targets do local target = rustup_targets[i] os.execute(\"rustup target install \" .. target) end local targets = { {os=\"Linux\", arch=\"x86_64\", cc=\"clang\", cxx=\"clang++\", cmakeArgs=\"\"}, {os=\"Linux\", arch=\"aarch64\", cc=\"clang\", cxx=\"clang++\", cmakeArgs=\"\"}, {os=\"Linux\", arch=\"arm\", cc=\"clang\", cxx=\"clang++\", cmakeArgs=\"\"}, {os=\"Linux\", arch=\"armv7\", cc=\"clang\", cxx=\"clang++\", cmakeArgs=\"\"}, {os=\"Linux\", arch=\"arm\", cc=\"zig\", cxx=\"zig\", cmakeArgs=\"-DCMAKE_C_COMPILER_ARG1=cc -DCMAKE_CXX_COMPILER_ARG1=c++ -DFMW_LIBC_MUSL=1 -DCMAKE_C_COMPILER_TARGET=arm-linux-musleabihf -DCMAKE_CXX_COMPILER_TARGET=arm-linux-musleabihf\"}, {os=\"Linux\", arch=\"aarch64\", cc=\"zig\", cxx=\"zig\", cmakeArgs=\"-DCMAKE_C_COMPILER_ARG1=cc -DCMAKE_CXX_COMPILER_ARG1=c++ -DFMW_LIBC_MUSL=1 -DCMAKE_C_COMPILER_TARGET=aarch64-linux-musl -DCMAKE_CXX_COMPILER_TARGET=aarch64-linux-musl\"}, {os=\"Linux\", arch=\"x86_64\", cc=\"zig\", cxx=\"zig\", cmakeArgs=\"-DCMAKE_C_COMPILER_ARG1=cc -DCMAKE_CXX_COMPILER_ARG1=c++ -DFMW_LIBC_MUSL=1 -DCMAKE_C_COMPILER_TARGET=x86_64-linux-musl -DCMAKE_CXX_COMPILER_TARGET=x86_64-linux-musl\"}, {os=\"Darwin\", arch=\"x86_64\", cc=\"zig\", cxx=\"zig\", cmakeArgs=\"-DCMAKE_C_COMPILER_ARG1=cc -DCMAKE_CXX_COMPILER_ARG1=c++ -DFMW_LIBC_MUSL=1 -DCMAKE_C_COMPILER_TARGET=x86_64-macos-none -DCMAKE_CXX_COMPILER_TARGET=x86_64-macos-none\"}, {os=\"Darwin\", arch=\"arm64\", cc=\"zig\", cxx=\"zig\", cmakeArgs=\"-DCMAKE_C_COMPILER_ARG1=cc -DCMAKE_CXX_COMPILER_ARG1=c++ -DFMW_LIBC_MUSL=1 -DCMAKE_C_COMPILER_TARGET=aarch64-macos-none -DCMAKE_CXX_COMPILER_TARGET=aarch64-macos-none\"}, {os=\"Android\", arch=\"armv7-a\", cc=\"clang\", cxx=\"clang++\", cmakeArgs=\"-DCMAKE_ANDROID_NDK='\" .. android_sdk .. \"'\"}, {os=\"Android\", arch=\"aarch64\", cc=\"clang\", cxx=\"clang++\", cmakeArgs=\"-DCMAKE_ANDROID_NDK='\" .. android_sdk .. \"'\"}, {os=\"Android\", arch=\"i686\", cc=\"clang\", cxx=\"clang++\", cmakeArgs=\"-DCMAKE_ANDROID_NDK='\" .. android_sdk .. \"'\"}, {os=\"Android\", arch=\"x86_64\", cc=\"clang\", cxx=\"clang++\", cmakeArgs=\"-DCMAKE_ANDROID_NDK='\" .. android_sdk .. \"'\"}, } for i = 1,#targets do local target = targets[i] local build_dir = \".build-\" .. target.os .. \"-\" .. target.arch .. \"-\" .. target.cc .. \"-\" .. target.cxx .. \"-\" .. target.cmakeArgs build_dir = string.gsub(build_dir, \"%s+\", \"_\") build_dir = string.gsub(build_dir, \"^./+\", \"_\") build_dir = build_root .. \"/\" .. build_dir print(build_dir) local cmd_handle = io.popen(\"command -v llvm-ar\") local llvm_ar = cmd_handle:read('*a') cmd_handle:close() llvm_ar = string.gsub(llvm_ar, \"%s+$\", \"\") local cmd_handle = io.popen(\"command -v llvm-ranlib\") local llvm_ranlib = cmd_handle:read('*a') cmd_handle:close() llvm_ranlib = string.gsub(llvm_ranlib, \"%s+$\", \"\") local build_cmd = \"cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo -B '\" .. build_dir .. \"' -DCMAKE_AR=\" .. llvm_ar .. \" -DCMAKE_RANLIB=\" .. llvm_ranlib .. \" -DCMAKE_SYSTEM_NAME=\" .. target.os .. \" -DCMAKE_SYSTEM_PROCESSOR=\" .. target.arch .. \" -DCMAKE_C_COMPILER=\" .. target.cc .. \" -DCMAKE_CXX_COMPILER=\" .. target.cxx .. \" \" .. target.cmakeArgs .. \" -S src/. -G Ninja\" print(build_cmd) os.execute(build_cmd) -- Work-around for getting rid of mbedtls linker flags specific to Apple's LLVM fork that are actually not needed. if target.os == \"Darwin\" then os.execute(\"sed -i '\" .. build_dir .. \"/CMakeFiles/rules.ninja' -e 's/ -no_warning_for_no_symbols -c//g'\") end os.execute(\"ninja -C '\" .. build_dir .. \"'\") end\n\nI look forward to only having Rust code and deleting all of this convoluted\nstuff.\n\nThat\u2019s something that people do not mention often when saying that modern C++\nis good enough and secure enough. Well, first I disagree with this statement,\nbut more broadly, the C++ toolchain to cross-compile sucks. You only have\nclang that can cross-compile in theory but in practice you have to resort to\nthe Zig toolchain to automate cross-compiling the standard library etc.\n\nAlso, developers not deeply familiar with either C or C++ do not want to touch\nall this CMake/Autotools with a ten-foot pole. And I understand them.\nStockholm syndrome notwithstanding, these are pretty slow, convoluted, niche\nprogramming languages and no one wants to actively learn and use them unless\nthey have to.\n\nOnce you are used to simply typing go build or cargo build, you really start\nto ask yourself if those weird things are worth anyone\u2019s time.\n\n## Conclusion\n\nThe rewrite is not yet fully done, but we have already more Rust code than C++\ncode, and it\u2019s moving along nicely, at our own pace (it\u2019s not by far the only\nproject we have on our lap). Once all C++ code is removed, we will do a final\npass to remove the CMake stuff and build directly via cargo. We\u2019ll see if that\nworks when integrating with other build systems e.g. Bazel for Android or\nXcode for iOS.\n\nDevelopers who learned Rust are overall very happy with it and did not have\ntoo many fights with the borrow checker, with one notable exception of trying\nto migrate a C struct that used an intrusive linked list (ah, the dreaded\nlinked list v. borrow checker!). My suggestion was to simply use a Vec in Rust\nsince the linked list was not really justified here, and the problem was\nsolved.\n\nAdding unit tests was trivial in Rust compared to C++ and as a result people\nwould write a lot more of them. Built-in support for tests is expected in 2024\nby developers. I don\u2019t think one single C++ test was written during this\nrewrite, now that I think of it.\n\nEveryone was really satisfied with the tooling, even though having to first do\nrustup target add ... before cross-compiling tripped up a few people, since in\nGo that\u2019s done automatically behind the scenes (I think one difference is that\nGo compiles everything from source and so does not need to download pre-\ncompiled blobs?).\n\nEveryone also had an easy time with their text editor/IDE, Rust is ubiquitous\nenough now that every editor will have support for it.\n\nAll the tooling we needed to scan dependencies for vulnerabilities, linting,\netc was present and polished. Shootout to osv-scanner from Google, which\nallowed us to scan both the Rust and C++ dependencies in the same project (and\nit evens supports Go).\n\nAs expected, developers migrating C++ code to Rust code had a breeze with the\nRust code and almost every time asked for assistance when dealing with the C++\ncode. C++ is just too complex a language for most developers, especially\ncompared to its alternatives.\n\nCMake/Make/Ninja proved surprisingly difficult for developers not accustomed\nto them, but I mentioned that already. I think half of my time during this\nrewrite was actually spent coercing all the various build systems\n(Bazel/Xcode/CMake/cargo/Go) on the various platforms into working well\ntogether. If there is no one in the team who\u2019s really familiar with build\nsystems, I think this is going to be a real challenge.\n\nSo, I hope this article alleviated your concerns about rewriting your C++\ncodebase. It can absolutely be done, just pick the right programming language\nfor you and your context, do it incrementally, don\u2019t overpromise, establish a\nrough roadmap with milestones, regularly show progress to stakeholders (even\nif it\u2019s just you, it helps staying motivated!), and make sure the team is on-\nboard and enjoying the process.\n\nYou know, like any other software project, really!\n\n> If you liked this article and you want to support me, and can afford it:\n> Donate\n\n", "frontpage": false}
