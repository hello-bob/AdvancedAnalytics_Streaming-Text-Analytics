{"aid": "40236079", "title": "Shifting Winter Storms Bring More Flooding to India", "url": "https://eos.org/articles/shifting-winter-storms-bring-more-flooding-to-india", "domain": "eos.org", "votes": 1, "user": "Brajeshwar", "posted_at": "2024-05-02 13:35:20", "comments": 0, "source_title": "Shifting Winter Storms Bring More Flooding to India", "source_text": "Shifting Winter Storms Bring More Flooding to India - Eos\n\nThis website uses cookies to ensure you get the best experience on our\nwebsite. Learn more\n\nAccept\n\n  * About\n  * Sections\n  * Topics\n\n    * Climate\n    * Earth Science\n    * Oceans\n    * Space & Planets\n    * Health & Ecosystems\n    * Culture & Policy\n    * Education & Careers\n    * Opinions\n  * Projects\n\n    * Eos Election Coverage\n    * ENGAGE\n    * Editors\u2019 Highlights\n    * Editors\u2019 Vox\n    * The Landslide Blog\n    * Eos en Espa\u00f1ol\n    * Eos \u7b80\u4f53\u4e2d\u6587\u7248\n    * Print Archive\n  * Newsletter\n  * Submit to Eos\n\nSkip to content\n\nEos\n\nScience News by AGU\n\nSign Up for Newsletter\n\nPosted inNews\n\n# Shifting Winter Storms Bring More Flooding to India\n\nWestern disturbances are hanging out over India for longer, adversely\naffecting water security in the country.\n\nby Rishika Pardikar 1 May 20242 May 2024\n\n### Share this:\n\n  * Click to print (Opens in new window)\n  * Click to email a link to a friend (Opens in new window)\n  * Click to share on Twitter (Opens in new window)\n  * Click to share on Facebook (Opens in new window)\n  * Click to share on LinkedIn (Opens in new window)\n\nRecent research illustrates the lengthening pattern of western disturbances,\nstorms (like this one in February 2013) that primarily affect northern India\nduring the winter months. Credit: NASA/Wikimedia Commons\n\nWestern disturbances describe a system of winds that bring snow and rainfall\nto northern India during winter months. They originate west of the Hindu Kush\nand the Himalaya mountains, sometimes as far away as the Mediterranean Sea,\nand are vital for ensuring water security across states in northern India.\n\nA new study published in the journal Weather and Climate Dynamics found a\nseasonal shift in western disturbances: They are now occurring more frequently\nin summer months, when they were once rare. Western disturbances have become\ntwice as common in June in the past 20 years than during the previous 50\nyears.\n\nTypically, western disturbances occur between December and March. That timing\nbenefits farmers and boosts water security, because the heavy precipitation\nrecharges mountain glaciers and snowpack that lose mass in the warmer summer\nmonths.\n\n## This newsletter rocks.\n\nGet the most fascinating science news stories of the week in your inbox every\nFriday.\n\nSign up now\n\n\u201cWinter precipitation is important for livelihoods [in northern Indian\nHimalayan states] because it ensures water availability in the subsequent\nspring season,\u201d said A. P. Dimri, a climate scientist at Jawaharlal Nehru\nUniversity who was not affiliated with the study.\n\n> \u201cWe had anecdotal evidence of western disturbances interacting with the\n> monsoon, but now we have been able to show the trend.\u201d\n\nThe snow and ice associated with western disturbances melt in the spring,\nmaking up a large proportion of runoff in the Indus-Ganges river system\u2014an\nartery that provides water for irrigation, hydropower, and household use for\nthe roughly half a billion people living in its plains.\n\nBut 70 years of storm track data from a climate hindcast (European Centre for\nMedium-Range Weather Forecasts Reanalysis version 5; ERA5) show that the\nwestern disturbance season has gotten longer. It now stretches into May, June,\nand July, when the weather pattern can sometimes interact with the summer\nmonsoon, which begins in June. The result is worse flooding.\n\n\u201cIn the winter, the atmosphere is drier because it\u2019s colder. So western\ndisturbances have to draw their own water from the Arabian Sea, and typically,\nthey do not cause floods,\u201d said Kieran Hunt, the author of the study and a\nmeteorologist at the University of Reading. A lot of the precipitation falls\nas snow, which melts slowly through the spring. But an overlap between western\ndisturbances and monsoons\u2014which carry about 6\u20137 times more moisture\u2014can be\ncatastrophic.\n\n\u201cWe had anecdotal evidence of western disturbances interacting with the\nmonsoon, but now we have been able to show the trend [in shifting patterns]\nmore clearly,\u201d Hunt said. Flash floods in 2013 in the Himalayan state of\nUttarakhand claimed around 6,000 lives. They happened in June, when western\ndisturbances struck during the summer monsoon. The same happened in July 2023,\nleading to floods in many northern Indian states, including in the capital,\nNew Delhi.\n\nThe changing pattern of western disturbances is \u201cvery concerning,\u201d especially\nbecause it has the potential to result in weather extremes, said Rajib\nChattopadhyay, a meteorologist at the Indian Institute of Tropical\nMeteorology.\n\n### The Climate Link\n\nWestern disturbances are steered by the subtropical jet stream, a high-\naltitude air current.\n\nClimate change has altered the jet stream\u2019s movement: Polar regions have\nbecome warmer, reducing the temperature gradient between them and the tropical\nregions to the south. The force that used to draw the jet stream northward\nbefore the monsoon season is therefore weaker, extending the time storms pass\nover India.\n\n> \u201cWe need to give more attention to western disturbance forecasts.\u201d\n\nThe weakening temperature gradient also means that the jet stream is more\nsusceptible to local factors. One dominant local factor, according to Hunt, is\nthe rapid warming of the Tibetan Plateau. Studies have previously shown that\nthe region is warming at rates almost twice the global average. This makes the\nplateau warmer than surrounding regions, resulting in a temperature gradient\nthat strengthens the jet stream, intensifying western disturbances and making\nthem more frequent.\n\nAnother local factor, according to Hunt, may be the reduction in aerosols over\nnorthern India due to air pollution control measures, which has made the local\natmosphere warmer and the temperature gradient stronger, also strengthening\nthe jet stream.\n\n\u201cWe need to give more attention to western disturbance forecasts,\u201d\nChattopadhyay said, adding that \u201cit is useful to get some first-order outlook\non impending disasters of flash flood, cloudbursts, etc., during monsoon and\ncold wave or snowfall during other seasons.\u201d\n\n\u2014Rishika Pardikar (@rishpardikar), Science Writer\n\n2 May 2024: This article was updated to clarify water use in the basin.\n\n##### Citation: Pardikar, R. (2024), Shifting winter storms bring more\nflooding to India, Eos, 105, https://doi.org/10.1029/2024EO240192. Published\non 1 May 2024.\n\n###### Text \u00a9 2024. The authors. CC BY-NC-ND 3.0 Except where otherwise noted,\nimages are subject to copyright. Any reuse without express permission from the\ncopyright owner is prohibited.\n\n### Related\n\nTagged: climate, Climate Change, extreme weather, floods, Ganges River, India,\nmonsoons, seasonal variability, snow\n\n#### Features from AGU Publications\n\nResearch Spotlights\n\n## How Mantle Movements Shape Earth\u2019s Surface\n\n2 May 20242 May 2024\n\nEditors' Highlights\n\n## Discounting Carbon Gain to Prevent Water Loss Today\n\n29 April 202429 April 2024\n\nEditors' Vox\n\n## Challenges in Evaluating Climate Sensitivity from Climate Models\n\n1 May 20241 May 2024\n\nAbout Eos ENGAGE Awards Contact\n\nAdvertise Submit Career Center Sitemap\n\n\u00a9 2024 American Geophysical Union. All rights reserved. Powered by Newspack\n\n", "frontpage": false}
{"aid": "40236081", "title": "DARPA's Manta Ray robotic sub hits the sea", "url": "https://newatlas.com/military/darpa-manta-ray-robotic-sub/", "domain": "newatlas.com", "votes": 1, "user": "Brajeshwar", "posted_at": "2024-05-02 13:35:27", "comments": 0, "source_title": "DARPA\u2019s massive Manta Ray robotic sub hits the sea", "source_text": "DARPA\u2019s massive Manta Ray robotic sub hits the sea\n\n\u00a9 2024 New Atlas\n\nMilitary\n\n# DARPA\u2019s massive Manta Ray robotic sub hits the sea\n\nBy David Szondy\n\nMay 01, 2024\n\n  * Facebook\n  * Twitter\n  * Flipboard\n  * LinkedIn\n\nDARPA\u2019s massive Manta Ray robotic sub hits the sea\n\nThe Manta ray dwarfs a a small work boat behind it\n\nNorthrop Grumman\n\nView 3 Images\n\n1/3\n\nThe Manta ray dwarfs a a small work boat behind it\n\nNorthrop Grumman\n\n2/3\n\nThe Manta Ray on the surface\n\nNorthrop Grumman\n\n3/3\n\nDARPA program manager Dr. Kyle Woerner (right) talks with a member of the\nNorthrop Grumman team while standing atop the Manta Ray vehicle\n\nNorthrop Grumman\n\nView gallery - 3 images\n\nDARPA has finally unveiled more of its mysterious Manta Ray robotic sub, with\nimpressive new images of the prototype Uncrewed Underwater Vehicle (UUV)\nundergoing its first sea trials off the coast of Southern California.\n\nLooking like a cross between a B-21 Raider bomber and a refugee from a '60s\nsci-fi television series, the Manta Ray is about as enigmatic. While DARPA has\nbeen happy to release some details about the sub, the agency has been a bit\ncoy about very basic information about specifications and performance.\n\nMore Stories\n\nTechnology\n\nAI voice analysis gives suicide hotline workers an emotional dashboard\n\nThe Manta Ray is set to play a lead role in a new class of UUVs that are long\nrange and long duration, as well as capable of handling a wide variety of\npayloads. It can also be shipped in sections in standard containers and\nassembled where needed, without taking up space at piers or naval facilities.\nIn this way, it can be quickly deployed without wasting time and wear in\ntransit.\n\nThe Manta Ray on the surface\n\nNorthrop Grumman\n\nFrom the presence of people and a small boat in the images, we can see that\nthe Manta Ray isn't small. It also has a stern that seems to have shrouded\npropulsors and perhaps thrusters for maneuvering. Along with this, there are\nprotuberances that are likely some sort of antenna, water inlets, and a\ngeneral shape that indicates that it's designed to glide through the water in\nthe most energy efficient way.\n\nIn other words, more is going into endurance than speed.\n\nAccording to primary contractor Northrop Grumman, the Manta Ray has a modular\nconstruction and energy-saving systems that include the ability to anchor\nitself on the sea floor and go into hibernation mode. There are low-power\nundersea propulsion systems, new sensors for underwater detection and\nclassification of threats and hazards, high-efficiency navigation and command\nand control systems, and cutting-edge anti-biofouling and material degradation\napproaches.\n\nDARPA program manager Dr. Kyle Woerner (right) talks with a member of the\nNorthrop Grumman team while standing atop the Manta Ray vehicle\n\nNorthrop Grumman\n\nThis first test period, which took place in February and March, focused on the\nManta Ray's hydrodynamic performance while submerged, and the operation of the\npropulsion, steering, buoyancy, propellers, and control surfaces. The tests\nalso included the portability of the sub as Manta Ray was disassembled and\npacked in five standard shipping containers before being sent from Northrop\nGrumman's Maryland facility to California.\n\n\"Our successful, full-scale Manta Ray testing validates the vehicle\u2019s\nreadiness to advance toward real-world operations after being rapidly\nassembled in the field from modular subsections,\" said Dr. Kyle Woerner, DARPA\nprogram manager for Manta Ray. \"The combination of cross-country modular\ntransportation, in-field assembly, and subsequent deployment demonstrates a\nfirst-of-kind capability for an extra-large UUV.\n\n\"Shipping the vehicle directly to its intended area of operation conserves\nenergy that the vehicle would otherwise expend during transit,\" he added.\n\"Once deployed, the vehicle uses efficient, buoyancy-driven gliding to move\nthrough the water.The craft is designed with several payload bays of multiple\nsizes and types to enable a wide variety of naval mission sets.\"\n\nSource: DARPA\n\nView gallery - 3 images\n\n## Tags\n\nMilitaryDARPANorthrop GrummanUnderwater dronesNaval\nWarfareSubmarineRoboticsWarfare\n\n  * Facebook\n  * Twitter\n  * Flipboard\n  * LinkedIn\n\nNo comments\n\nDavid Szondy\n\nDavid Szondy is a playwright, author and journalist based in Seattle,\nWashington. A retired field archaeologist and university lecturer, he has a\nbackground in the history of science, technology, and medicine with a\nparticular emphasis on aerospace, military, and cybernetic subjects. In\naddition, he is the author of four award-winning plays, a novel, reviews, and\na plethora of scholarly works ranging from industrial archaeology to law.\nDavid has worked as a feature writer for many international magazines and has\nbeen a feature writer for New Atlas since 2011.\n\n## Most Viewed\n\n  * Energy\n\n### Advanced 'high-density waterless hydro' energy plant gets green light\n\n  * Medical\n\n### Only half of atrial fibrillation patients survive 10 years after treatment\n\n  * Automotive\n\n### 1,200-horsepower, 250-mph, V12 quad bike seeks world's fastest farmer\n\nLoad More\n\nby Taboolaby Taboola\n\nSponsored LinksSponsored Links\n\nPromoted LinksPromoted Links\n\nYou May Like\n\nHausnotruf-Heute\n\nSenioren-Sturzgefahr: F\u00fcr diese Uhr zahlt die Kasse!Hausnotruf-Heute\n\nTreppenlift-Vergleich\n\nRentner in Riesa: So kosten Treppenlifte fast nichtsTreppenlift-Vergleich\n\nApotheke Regional\n\n\u00c4rzte ratlos: 62-J\u00e4hrige sieht fast 20 Jahre j\u00fcnger aus dank diesem einfachen\nTrick!Apotheke Regional\n\nApotheken Magazin\n\nPrivatversicherte \u00fcber 55 Jahren k\u00f6nnen bis zu 70% sparenApotheken Magazin\n\n0 comments\n\nSign in to post a comment. Please keep comments to less than 150 words. No\nabusive material or spam will be published.\n\nThere are no comments. Be the first!\n\n## GET OUR NEWSLETTER\n\nOver 220,000 people receive our email newsletter. Get your daily dose of\nextraordinary ideas!\n\nRegister\n\nFollow Us\n\n  * twitter\n  * instagram\n  * pinterest\n  * flipboard\n  * facebook\n  * linkedin\n\n\u00a9 2024 New Atlas\n\n# Notice\n\nWe and selected third parties use cookies or similar technologies for\ntechnical purposes and, with your consent, for functionality, experience,\nmeasurement and marketing (personalized ads) as specified in the cookie\npolicy.\n\nWith respect to advertising, we and 851 selected , may use precise geolocation\ndata, and identification through device scanning in order to store and/or\naccess information on a device and process personal data like your usage data\nfor the following : personalised advertising and content, advertising and\ncontent measurement, audience research and services development.\n\nYou can freely give, deny, or withdraw your consent at any time by accessing\nthe preferences panel. If you give consent, it will be valid only in this\ndomain. Denying consent may make related features unavailable.\n\nUse the \u201cAccept\u201d button to consent. Use the \u201cReject\u201d button to continue\nwithout accepting.\n\nPress again to continue 0/2\n\n", "frontpage": false}
{"aid": "40236100", "title": "Remote machine learning on Windows with Docker and WSL2 from anywhere", "url": "https://tailscale.com/blog/remote-gpus-docker-wsl2-immich", "domain": "tailscale.com", "votes": 1, "user": "yarapavan", "posted_at": "2024-05-02 13:37:05", "comments": 0, "source_title": "Remote machine learning on Windows with Docker and WSL2 from anywhere", "source_text": "Remote machine learning on Windows with Docker and WSL2 from anywhere\n\nDownloadLog in\n\nGet started\n\nProduct\n\nMeet Tailscale\n\n  * How it works\n\n  * Why Tailscale\n\n  * WireGuard\u00ae for Enterprises\n\n  * Bring Tailscale to Work\n\nExplore\n\n  * Integrations\n\n  * Features\n\n  * Compare Tailscale\n\nSolutions\n\nBy use-case\n\n  * Remote Access\n\n  * Kubernetes Networking\n\n  * Edge & IoT Deployments\n\n  * Zero Trust Networking\n\n  * AI Workloads\n\n  * Secure SaaS\n\n  * Business VPN\n\n  * Homelab\n\nBy role\n\n  * DevOps\n\n  * IT\n\n  * Security\n\nEnterprise\n\nCustomers\n\nDocs\n\nBlog\n\nPricing\n\nDownload\n\nGet started\n\nLogin\n\nWireGuard is a registered trademark of Jason A. Donenfeld.\n\nTerms of ServicePrivacy Policy\n\n\u00a9 2024 Tailscale Inc. All rights reserved. Tailscale is a registered trademark\nof Tailscale Inc.\n\nGo back\n\nBlog\n\nRemote machine learning on Windows with Docker and WSL2 from anywhere\n\n# Remote machine learning on Windows with Docker and WSL2 from anywhere\n\nApril 24 2024\n\nAlex Kretzschmar\n\nShare Article\n\nAs a computer nerd, I am what you might call in the \u201cpro utilization\u201d camp for\nmy hardware. In other words, that graphics card which is sitting there doing\npractically nothing all day in my gaming PC could be put to work, couldn\u2019t it?\n\nLately, we\u2019ve been on a bit of a mission to help folks looking to bring hosted\nservices in-house. Today\u2019s target is photos, using Immich \u2014 a self-hosted\nphoto and video management solution. Think Google Photos, only it runs on your\nhardware and the data it harvests remains yours.\n\nThe obvious downside to hosting these things yourself is that you can\u2019t\noutsource the facial recognition or smart search object detection to someone\nelse. Instead, it\u2019s up to you. In today\u2019s video I walk you through the process\nof hooking up Immich\u2019s machine learning components to a Windows 11 system,\nprimarily used as my personal gaming rig, running on WSL2, inside of a docker\ncontainer with Nvidia hardware acceleration support. And of course, we\u2019ll\ndiscuss how to do this on any GPU that is in your tailnet (even a friend's\nremote GPU!).\n\nThis video builds upon concepts we\u2019ve been exploring on the channel lately,\nsuch as running Tailscale in a docker container to add individual services to\nyour tailnet.\n\nCentral to our mission here at Tailscale is to help you create small, trusted\nnetworks with your friends, family and coworkers. Are you using Tailscale to\nthis end? Let us know with a post in our subreddit, in the Fediverse, or on X\n(formerly Twitter). Until next time, I\u2019ve been Alex from Tailscale.\n\n## Subscribe to Tailscale\u2019s blog\n\nWe have a deep commitment to keeping your data safe.\n\nToo much email?RSSX\n\n## More articles\n\nMay 01, 2024\n\n#### Tailscale and CrowdStrike Falcon for enhanced device posture management\n\nTinku Thomas, Anton Tolchanov, Paul Scott, Kristoffer Dalby, James Sanderson &\nRoss Zurowski\n\nApr 19, 2024\n\n#### April Tailscale newsletter\n\nParker Higgins\n\nApr 18, 2024\n\n#### SSO tax, cut\n\nCharlotte Brandhorst-Satzkorn\n\n## Try Tailscale for free\n\nGet started\n\nSchedule a demo\n\nContact sales\n\nProduct\n\nHow it worksPricingIntegrationsFeaturesCompare Tailscale\n\nUse Cases\n\nBusiness VPNRemote AccessSite-to-Site NetworkingHomelabEnterprise\n\nResources\n\nBlogEvents & Webinars\n\nCompany\n\nCompanyCareersPress\n\nHelp & Support\n\nSupportSalesSecurityLegalOpen SourceChangelog\n\nLearn\n\nSSH keysDocker SSHDevSecOpsMulticloudNAT TraversalMagicDNSPAMPoLPAll articles\n\nTerms of ServicePrivacy Policy\n\nWireGuard is a registered trademark of Jason A. Donenfeld.\n\n\u00a9 2024 Tailscale Inc. All rights reserved. Tailscale is a registered trademark\nof Tailscale Inc.\n\n", "frontpage": false}
{"aid": "40236104", "title": "Learning Geometry-Guided Semantics for Exploring Unconstrained Photo Collections", "url": "https://tau-vailab.github.io/HaLo-NeRF/", "domain": "tau-vailab.github.io", "votes": 1, "user": "PaulHoule", "posted_at": "2024-05-02 13:37:23", "comments": 0, "source_title": "HaLo-NeRF: Learning Geometry-Guided Semantics for Exploring Unconstrained Photo Collections", "source_text": "HaLo-NeRF: Learning Geometry-Guided Semantics for Exploring Unconstrained\nPhoto Collections\n\nHaLo-NeRF: Learning Geometry-Guided Semantics for Exploring Unconstrained\nPhoto Collections\n\n# HaLo-NeRF\ud83d\ude07 Learning Geometry-Guided Semantics for Exploring Unconstrained\nPhoto Collections\n\n## Eurographics 2024\n\nChen Dudai*^1\n\nMorris Alper*^1\n\nHana Bezalel^1\n\nRana Hanocka^2\n\nItai Lang^2\n\nHadar Averbuch-Elor^1\n\n^* Denotes equal contribution\n\n^1Tel Aviv University ^2University of Chicago\n\nPaper Code Supplementary Data\n\n## TL;DR We learn a semantic localization field for textual descriptions over\ncollections of in-the-wild images depicting a large-scale scene.\n\nAs illustrated for St. Paul's Cathedral above, our approach enables generating\nnovel views with controlled appearances of these semantic regions of interest.\n\n## Abstract\n\nInternet image collections containing photos captured by crowds of\nphotographers show promise for enabling digital exploration of large-scale\ntourist landmarks. However, prior works focus primarily on geometric\nreconstruction and visualization, neglecting the key role of language in\nproviding a semantic interface for navigation and fine-grained understanding.\nIn more constrained 3D domains, recent methods have leveraged modern vision-\nand-language models as a strong prior of 2D visual semantics. While these\nmodels display an excellent understanding of broad visual semantics, they\nstruggle with unconstrained photo collections depicting such tourist\nlandmarks, as they lack expert knowledge of the architectural domain and fail\nto exploit the geometric consistency of images capturing multiple views of\nsuch scenes. In this work, we present a localization system that connects\nneural representations of scenes depicting large-scale landmarks with text\ndescribing a semantic region within the scene, by harnessing the power of SOTA\nvision-and-language models with adaptations for understanding landmark scene\nsemantics. To bolster such models with fine-grained knowledge, we leverage\nlarge-scale Internet data containing images of similar landmarks along with\nweakly-related textual information. Our approach is built upon the premise\nthat images physically grounded in space can provide a powerful supervision\nsignal for localizing new concepts, whose semantics may be unlocked from\nInternet textual metadata with large language models. We use correspondences\nbetween views of scenes to bootstrap spatial understanding of these semantics,\nproviding guidance for 3D-compatible segmentation that ultimately lifts to a\nvolumetric scene representation. To evaluate our method, we present a new\nbenchmark dataset containing large-scale scenes with ground-truth\nsegmentations for multiple semantic concepts. Our results show that HaLo-NeRF\ncan accurately localize a variety of semantic concepts related to\narchitectural landmarks, surpassing the results of other 3D models as well as\nstrong 2D segmentation baselines.\n\n## Neural 3D Localization Results of our Method\n\nWe demonstrate sample results from our HolyScenes benchmark (depicting Milan\nCathedral on top and Badshahi Mosque on bottom), visualizing segmentation maps\nover input images from test landmarks. As illustrated above, HaLo-NeRF\nsuccessfully segments regions corresponding to a given text input. Moreover,\nour method can differentiate between concepts with similar semantic\ndescriptions, such as Portal and Window\n\n## Method\n\nOur goal is to perform text-driven neural 3D localization for landmark scenes\ncaptured by collections of Internet photos. In other words, given this\ncollection of images and a text prompt describing a semantic concept in the\nscene, we would like to know where it is located in 3D space. These images are\nin the wild, meaning that they may be taken in different seasons, time of day,\nviewpoints, and distances from the landmark, and may include transient\nocclusions.\n\nIn order to localize unique architectural features landmarks in 3D space, we\nleverage the power modern foundation models for visual and textual\nunderstanding. Despite progress in general multimodal understanding, modern\nVLMs struggle to localize fine-grained semantic concepts on architectural\nlandmarks, as we show extensively in our results. The architectural domain\nuses a specialized vocabulary, with terms being rare in general usage.\n\nTo address these challenges, we design a three-stage system: (a) We extract\nsemantic pseudo-labels from noisy Internet image metadata using a large\nlanguage model (LLM). (b) We use these pseudo-labels and correspondences\nbetween scene views to learn image-level and pixel-level semantics. In\nparticular, we fine-tune an image segmentation model (CLIPSegFT) using multi-\nview supervision\u2014where zoomed-in views and their associated pseudo-labels\n(such as image on the left associated with the term \u201ctympanum\u201d) provide a\nsupervision signal for zoomed-out views. (c) We then lift this semantic\nunderstanding to learn volumetric probabilities over new, unseen landmarks\n(such as the St. Paul\u2019s Cathedral depicted on the right), allowing for\nrendering views of the segmented scene with controlled viewpoints and\nillumination settings.\n\n## Visualizations\n\nIn addition, we show below visualizations, comparing HaLo-NeRF (left) with the\nBaseline model (right), which uses the CLIPSeg model without finetuning. Both\nvideos show the same temporal sequence of RGB renderings, varying only in the\nprobabilities depicted (taken either from our model or the baseline). Note\nthat once zoomed-in, we turn off the probabilities for both models, allowing\nto better view the target semantic region. The target text prompt is written\nabove each video, with the name of the landmark on the right. As illustrated\nbelow, our model yields significantly cleaner probabilities that better\nlocalize the semantic regions, particularly for unique concepts that are less\ncommon outside of the domain of architectural landmarks. We also visualize the\nzoomed-in region with multiple appearance (for our model, keeping the\nappearance of the baseline model fixed). Results over additional prompts and\nlandmarks from the HolyScenes benchmark are illustrated in the main paper.\n\n#### \"Portals\" (a grand entrance to a cathedral), Notre-Dame Cathedral\n\nHaLo-NeRF Baseline\n\n\u276e \u276f\n\n## Citation\n\n    \n    \n    @InProceedings{dudai2024halonerf, author = {Dudai, Chen and Alper, Morris and Bezalel, Hana and Hanocka, Rana and Lang, Itai and Averbuch-Elor, Hadar}, title = {HaLo-NeRF: Learning Geometry-Guided Semantics for Exploring Unconstrained Photo Collections}, booktitle = {Proceedings of the Eurographics Conference (EG)}, year = {2024} }\n\n", "frontpage": false}
