{"aid": "40083807", "title": "Supabase Storage: now supports the S3 protocol", "url": "https://supabase.com/blog/s3-compatible-storage", "domain": "supabase.com", "votes": 17, "user": "inian", "posted_at": "2024-04-19 05:51:32", "comments": 2, "source_title": "Supabase Storage: now supports the S3 protocol", "source_text": "Supabase Storage: now supports the S3 protocol\n\nGeneral Availability Week: Day 4\n\nLearn more\n\nBack\n\nBlog\n\n# Supabase Storage: now supports the S3 protocol\n\n2024-04-18\n\n\u2022\n\n5 minute read\n\nFabrizio FenoglioEngineering\n\nSupabase Storage is now officially an S3-Compatible Storage Provider. This is\none of the most-requested features and is available today in public alpha.\nResumable Uploads are also transitioning from Beta to Generally Available.\n\nThe Supabase Storage Engine is fully open source and is one of the few storage\nsolutions that offer 3 interoperable protocols to manage your files:\n\n  * Standard uploads: simple to get started\n  * Resumable uploads: for resumable uploads with large uploads\n  * S3 uploads: for compatibility across a plethora of tools\n\n## S3 compatibility#\n\nWe always strive to adopt industry standards at Supabase. Supporting standards\nmakes workloads portable, a key product principle. The S3 API is undoubtedly a\nstorage standard, and we're making it accessible to developers of various\nexperience-levels.\n\nThe S3 protocol is backwards compatible with our other APIs. If you are\nalready using Storage via our REST or TUS APIs, today you can use any S3\nclient to interact with your buckets and files: upload with TUS, serve them\nwith REST, and manage them with the S3 protocol.\n\nThe protocol works on the cloud, local development, and self-hosting. Check\nout the API compatibility in our docs\n\n### Authenticating with Supabase S3#\n\nTo authenticate with Supabase S3 you have 2 options:\n\n  1. The standard access_key and secret_key credentials. You can generate these from the storage settings page. This authentication method is widely compatible with tools supporting the S3 protocol. It is also meant to be used exclusively serverside since it provides full access to your Storage resources.\n\nWe will add scoped access key credentials in the near future which can have\naccess to specific buckets.\n\n  2. User-scoped credentials with RLS. This takes advantage of a well-adopted concept across all Supabase services, Row Level Security. It allows you to interact with the S3 protocol by scoping storage operations to a particular authenticated user or role, respecting your existing RLS policies. This method is made possible by using the Session token header which the S3 protocol supports. You can find more information on how to use the Session token mechanism in the doc.\n\n### S3-compatible Integrations#\n\nWith the support of the S3 protocol, you can now connect Supabase Storage to\nmany 3rd-party tools and services by providing a pair of credentials which can\nbe revoked at any time.\n\nYou can use popular tools for backups and migrations, such as:\n\n  * AWS CLI: The official AWS CLI\n  * rclone: a command-line program to manage files on cloud storage.\n  * Cyberduck: a cloud storage browser for Mac and Windows.\n  * and any other s3-compatible tool ...\n\nCheck out our Cyberduck guide here.\n\n### S3 for Data Engineers#\n\nS3 compatibility provides a nice primitive for Data Engineers. You can use it\nwith many popular tools:\n\n  * Data Warehouses like ClickHouse\n  * Query engines like DuckDB, Spark, Trino, & Snowflake External Table\n  * Data Loaders like Fivetran & Airbyte\n\nIn this example our incredible data analyst, Tyler, demonstrates how to store\nParquet files in Supabase Storage and query them directly using DuckDB:\n\n### Multipart Uploads in S3#\n\nIn addition to the standard uploads and resumable uploads, we now support\nmultipart uploads via the S3 protocol. This allows you to maximize upload\nthroughput by uploading chunks in parallel, which are then concatenated at the\nend.\n\n# Resumable uploads is Generally Available#\n\nAlong with the platform GA announcement, we are also thrilled to announce that\nresumable uploads are also generally available.\n\nResumable uploads are powered by the TUS protocol. The journey to get here was\nimmensely rewarding, working closely with the TUS team. A big shoutout to the\nmaintainers of the TUS protocol, @murderlon and @acconut, for their\ncollaborative approach to open source.\n\nSupabase contributed some advanced features from the Node implementation of\nTUS Spec including distributed locks, max file size, expiration extension and\nnumerous bug fixes:\n\nThese features were essential for Supabase, and since the TUS node server is\nopen source, they are also available for you to use. This is another core\nprinciple: wherever possible, we use and support existing tools rather than\ndeveloping from scratch.\n\n  * Cross-bucket transfers: We have added the availability to copy and move objects across buckets, where previously you could do these operations only within the same Supabase bucket.\n  * Standardized error codes: Error codes have now been standardized across the Storage server and now will be much easier to branch logic on specific errors. You can find the list of error codes here.\n  * Multi-tenant migrations: We made significant improvements to the running migrations across all our tenants. This has reduced migration errors across the fleet and enables us to run long running migrations in an asynchronous manner. Stay tuned for a separate blog post with more details.\n  * Decoupled dependencies: Storage is fully decoupled from other Supabase products, which means you can run Storage as a standalone service. Get started with this docker-compose file.\n\n# Getting started#\n\n  * Check out the S3 API compatibility in our docs\n  * Learn about S3 Authentication\n  * Try S3 with Cyberduck: follow our integration guide\n  * Try S3 with DuckDB: follow the guide on YouTube\n\nWeek\n\n15-19 April\n\nDay 1 -Supabase is officially launching into General AvailabilityDay 2\n-Supabase Functions now supports AI modelsDay 3 -Supabase Auth now supports\nAnonymous sign-insDay 4 -Supabase Storage: now supports the S3 protocol\n\nBuild Stage\n\n01 -PostgreSQL Index Advisor02 -Branching now Publicly Available03 -Oriole\njoins Supabase04 -Supabase on AWS Marketplace05 -Supabase Bootstrap06\n-Supabase SwiftOpen Source Hackathon 2024Community Meetups\n\nShare this article\n\nNext post\n\n#### Supabase Auth now supports Anonymous Sign-ins\n\n17 April 2024\n\nlaunch-week\n\nstorage\n\nOn this page\n\n  * S3 compatibility\n\n    * Authenticating with Supabase S3\n    * S3-compatible Integrations\n    * S3 for Data Engineers\n    * Multipart Uploads in S3\n\n  * Resumable uploads is Generally Available\n  * Getting started\n\nShare this article\n\n## Build in a weekend, scale to millions\n\n## Footer\n\nWe protect your data.More on Security\n\n  * SOC2 Type 2 Certified\n  * HIPAA Compliant\n\nTwitter\n\nGitHub\n\nDiscord\n\nYoutube\n\n###### Product\n\n  * Database\n\n  * Auth\n\n  * Functions\n\n  * Realtime\n\n  * Storage\n\n  * Vector\n\n  * Pricing\n\n  * GA Week\n\n###### Resources\n\n  * Support\n\n  * System Status\n\n  * Become a Partner\n\n  * Integrations\n\n  * Experts\n\n  * Brand Assets / Logos\n\n  * Security and Compliance\n\n  * DPA\n\n  * SOC2\n\n  * HIPAA\n\n###### Developers\n\n  * Documentation\n\n  * Changelog\n\n  * Contributing\n\n  * Open Source\n\n  * SupaSquad\n\n  * DevTo\n\n  * RSS\n\n###### Company\n\n  * Blog\n\n  * Customer Stories\n\n  * Careers\n\n  * Company\n\n  * Terms of Service\n\n  * Privacy Policy\n\n  * Acceptable Use Policy\n\n  * Support Policy\n\n  * Service Level Agreement\n\n  * Humans.txt\n\n  * Lawyers.txt\n\n  * Security.txt\n\n\u00a9 Supabase Inc\n\nWe only collect analytics essential to ensuring smooth operation of our\nservices. Learn more\n\nLearn more\n\n", "frontpage": true}
