{"aid": "40049105", "title": "Healthy Code Reviews", "url": "https://vadimkravcenko.com/shorts/code-reviews/", "domain": "vadimkravcenko.com", "votes": 2, "user": "bndr", "posted_at": "2024-04-16 07:03:51", "comments": 0, "source_title": "Healthy Code Reviews", "source_text": "Healthy Code Reviews\n\nVadim Kravcenko\n\n\ud83d\udd25 Newsletter\n\n\ud83d\udd25 Roast my Resume\n\n# Healthy Code Reviews\n\n14 January 2024 \u00b7 33,889 views \u00b7 Updated 22 March 2024\n\ndevelopment newsletter startups teams\n\n## Table of Contents\n\nI worked with a client in the early days of my career building social media\nsentiment analysis platform when Twitter was still called Twitter. We were a\nteam of seven and I was a junior-level developer back then. We were young and\nenthusiastic and full of ourselves. \"We're agile, we move fast, we break\nthings!\u201d was our motto, patting ourselves on the back for our speed. Code\nreviews? Please. We thought they were a bureaucratic relic from the corporate\nworld.\n\nFast forward many months, and our codebase had turned into a minefield. Bugs\nwere the least of our worries, though there were many. The real problem was\nthat no one could understand what the hell anyone else had written; we had\nduplicate logic in many places and different code styles in our modules. It\nwas really bad\n\nThat's when it hit us: we need to get this thing under control. Code reviews\nare actually helpful and help you keep your code readable, maintainable, and\nscalable.\n\nSo, to put it simply: if you're not doing code reviews, or if you're doing\nthem just to tick a box, you're setting yourself up for a world of pain, not\nnow, maybe, but eventually. It's like building a house on a foundation of\nsand. Sure, it might stand up for a while, but it's only a matter of time\nbefore it all comes crashing down. And in the startup world, you might not get\na second chance.\n\nSo now that we\u2019re all aligned that code reviews are good. There have been\nhundreds of articles that prove time and time again that doing code reviews\nbrings more value than the time spent doing them. Many articles have also\ndiscussed how best to do them, and yes, I\u2019ve decided to write my own because\nwhy not? I have a lot of opinions on a lot of stuff, and code reviews are one\nof those things where everyone is doing it differently, and there\u2019s no \u201csingle\nway\u201d of doing them.\n\nSo I suggest you read the article, take the bits you like, and ignore the\nrest. Ultimately, your code review process will most likely differ from the\none I\u2019m used to, and that\u2019s fine.\n\nBefore we start, let\u2019s reiterate why code reviews are a must from the\nperspective of a software engineer:\n\n  1. Two pairs of eyes are better than one. We, developers, tend to overestimate how good our code is \u2014 so a second pair of eyes shatters that overconfidence a bit and makes the code objectively better. The higher the number of reviewers who look at the code, the more \u201cobjectively\u201d better the code becomes. But usually, a single reviewer is enough to get to the point where it becomes good enough.\n  2. The reviewer is the first person who reads the code as an outside developer and can also assess if the code is maintainable. You must\u2019ve heard the saying: write code as if you will forget about it for five years and then return to maintain it. If the reviewer has difficulty grasping what the hell is happening in all the intertwined functions \u2014 then the code is unmaintainable and needs to be rewritten for clarity.\n  3. We\u2019re all human and are not always diligent in following the guidelines. Code reviews help keep us on our feet and ensure we\u2019re not pushing code that a) does not conform to the company-wide guidelines and b) has unintended side effects. I mean by the side effects, e.g., null pointer exceptions, segfaults, and race conditions. There are many \u201ccommon\u201d ones, depending on what kind of software you\u2019re writing. We\u2019re going to discuss a few of them below.\n\nNow, let\u2019s talk about you as the author of a new feature or a bug fix that\nwill need to be reviewed.\n\nOne of the biggest issues I have seen is that people get too attached to the\ncode they\u2019re writing. They view it as an extension of their self-worth. So if\nthe code is bad = they are bad. That\u2019s not true. First of all, you are not\nperfect, and you are not your code. The code is a collaborative document that\nwill be refined by hundreds of software engineers, and with your help, it will\nimprove over time. You\u2019re not going to remember what you\u2019ve written today five\nyears from now, so why should you have so much emotional attachment to\nsomething that will undergo so many changes over time? Hell, I barely remember\nwhat I coded two years ago, but that might be just me.\n\nThe second biggest issue is the US vs. THEM mentality. That\u2019s the worst thing\nyou can do: assume you\u2019re on different sides of the barricades. There are code\nproducers, and there are reviewers. No, you\u2019re both engineers who are building\na product. Eventually, you will be someone\u2019s reviewer, ensuring the new code\nmoves the software forward, not backward.\n\n## Before the review\n\nSo there are at least two things you and your team need to do before any\nreviews happen:\n\n  1. Defining what Done means.\n  2. Coding Standards.\n\nDefinition of Done The last thing you want is someone submitting something for\nreview that is not done to the level that everyone is comfortable with. And if\nyou multiply this by a hundred, you get half-baked software. You need a\nconcrete, black-and-white definition that everyone on your team understands\nand agrees with.\n\nThink about it. If 'done' means the code is written but not tested, you're\nsetting yourself up for a disaster. If 'done' means it's been tested but not\ndocumented, you're just passing the buck to the next poor soul who has to\nfigure out what the hell you were thinking. As a rule of thumb, \u2018Done' should\nmean it's written, tested, documented, and ready to be deployed without\ncausing the whole cluster to break down in the server room. Should be easy\nright? Again, your mileage may vary; you should sit down with your team and\nagree on acceptable terms.\n\nEnjoyed the read? Join a growing community of more than 2,500 (\ud83e\udd2f) future CTOs.\n\nCoding Standards Same thing here - coding standards are important not to the\nengineer writing code but to all the other developers who will be reading it.\n\nYour coding standards should cover everything from variable naming and spacing\nto how you handle error messages and logging. The goal is that any developer\nfrom any team should be able to see the code and be immediately familiar with\nthe coding patterns, variable naming, spacing, etc. It should feel like home,\nespecially during the review.\n\nGet at least these two things right, and you're laying the foundation for a\ngood code review process that's efficient, effective, and much less painful\nfor everyone involved.\n\n## Standardizing everything\n\nOnce you've got the foundation for your code reviews, you\u2019re free to focus on\nthe standardization \u2014 checklists & tools & CI.\n\nStart with a clear checklist. There are quite a few good examples here.\nBasically, your checklist should cover the essentials: code functionality,\nreadability, adherence to coding standards, and security checks, to name a\nfew. For example, check if the code does what it's supposed to, has any\nobvious logic errors, or is reinventing the wheel with existing functions.\n\nFrom the github repo above\n\nYou might ask why you need a checklist; it\u2019s straightforward, and you can\nremember it all. Wrong. Even airplane pilots, after tens of thousands of\nflights, rely on checklists during take-off and landing. No matter how expert\nyou may be, well-designed checklists can improve outcomes and lower the risk\nof getting bad code into production.\n\nAfter you have published your checklist, it\u2019s time to set up some tools. These\nare your best friends who will do the heavy lifting \u2014 linters, static code\nanalysis, and vulnerability scanners. For example, there\u2019s a whole plethora of\npre-commit hooks that will make sure that the code that\u2019s committed can be\ntrusted:\n\nPre-commit hooks helps maintain quality before hitting the repository.\n\nThis topic is quite controversial; there are several camps here. Some people\nenjoy the pre-commit hooks; some think the CI should validate your code, and\nothers rely on IDE Plugins. It\u2019s your choice which way to go; I prefer a mix\nof all of those \u2014 for example, I have a few pre-commit hooks set up to lint\nthe Python code, there are tools attached to the CI to validate the types, AND\nthere are auto-formatting in the JetBrains IDE. So if something goes wrong, I\neither cannot merge the code or get an email notification from the CI, or my\nIDE tells me I\u2019m an idiot.\n\n## Common things to look out for\n\nHere\u2019s my list of things I focus on when doing code reviews. Again, skim\nthrough, take what you like, and discard the rest; I\u2019m pretty sure there\u2019s no\nright and wrong here as long as the code that gets merged adheres to your\nsubjective quality standards.\n\nSo, the first thing I look at is the size of the Pull Request. The bigger the\nPR, the heavier the metal load, and the more likely I will get tired. Big PRs\nare overwhelming; when people are overwhelmed, they miss stuff. Important\nstuff. So, if I see a massive PR, I will probably comment that it needs to be\nbroken down into smaller ones that can be stacked upon each other.\n\nI will be checking the code for guard clauses. There are pros and cons to\nthese. Some people say a function should have a single point of exit, but I\ndisagree. For me, guard clauses are what keep the function understandable. And\nI hate the nesting IF statements. When I see a guard, I think, \u201cThis is not\ntrue, so we exit early or raise an exception or return.\u201d I have already\nlowered the mental load for the following lines because I no longer care about\nthat case. Easy.\n\nGuard Clauses. Source\n\nDead code or commented-out code. I will quickly skim the code to see if\nanything is irrelevant to the feature being submitted. Every line should serve\na purpose; if it\u2019s there for no reason, why are you trying to squeeze it into\nproduction?\n\nI will be checking the variable names and the parameters. I\u2019m a fan of\nexplicit parameters and making it clear from the start what it does. I don\u2019t\nwant to figure out what the code does from reading the function; I want to see\nit immediately. There\u2019s a massive difference between having an input parameter\nnamed data and sumEmployees. That\u2019s a whole different level of information.\n\nI will also check if the developer did premature optimization or over-\nengineering. I know we developers tend to tinker with stuff, and sometimes,\nthe urge to build it in a complicated way is stronger than just keeping it\nsimple. Over-architecting is probably one of the most common pitfalls I\u2019ve\nseen (alongside bad variable naming). This is when software engineers create a\nlabyrinth of interfaces, factories, and abstract classes for problems that\ncould\u2019ve been a single function. They were asked to build a toaster, and they\nbuilt a toaster factory. I usually approach this with a question: Is this\ncomplexity really necessary? What was the underlying motivation when building\nit that way? The reviewer is not always correct, so there might be a reason\nfor this complexity. So, I usually just ask.\n\nIf you\u2019re reviewing a PR for a huge codebase, chances are a lot of utility\nfunctionality is already built. Sometimes, people are unaware that they\u2019re\nreinventing the wheel, and having several modules in a system that do similar\nthings is not the best idea. So, I will also check if the developer missed\nsomething in terms of \u201cre-inventing the wheel\u201d and not reusing the existing\nmodules properly. It\u2019s usually just a minor oversight, but it keeps everything\ntidy.\n\nSometimes, developers get carried away when developing their features and end\nup refactoring parts of code they were not supposed to. I think refactoring\ncode should always be a separate Pull Request, and the initial authors should\nbe tagged to take a look. This helps avoid situations where multiple\ndevelopers are working on different features that rely on some module, and one\nof them refactors that module and breaks something for the other developer.\nBetter no surprises.\n\nWhile I do agree that well-written code should be self-explanatory, there are\ntimes when comments are necessary. When looking at code, it should be clear\nWHAT it does; when looking at comments, it should be clear WHY it does it. So,\nI will check if the comments explain the underlying ideas behind the function.\nComments are where you explain the business complexity and decisions that\naren't immediately obvious. It helps future maintainers (we\u2019re talking a year+\nin the future) understand the rationale behind your choices. You don\u2019t want to\nend up in a situation a year from now, \u201cWHAT DOES THIS ALL MEAN?\u201d when you\nread your own code.\n\nI\u2019m also highly skeptical of Pull Requests that introduce new dependencies.\nThere\u2019s a whole dance around understanding if it can be used based on its\nlicense, security implications, and if the technology makes sense. So, I\nusually ask many questions if I see some new tech added.\n\nIf any endpoints were developed, I would check if they followed our guidelines\non how to write an endpoint. We usually follow REST, so it needs to adhere to\nthose standards. I will also check if the endpoint is protected enough in\nterms of\n\n  1. Returning data only that is relevant and which is appropriately filtered\n  2. I verify the session handling if the endpoint is behind authorization.\n  3. Headers\n  4. Race Conditions / Idempotence\n\nI think the things above should be enough to give you a rough idea of what I\nfocus on during code reviews. Of course, there are many more things you can\ncheck. Let me give you a few references for things to focus on when doing the\nreview:\n\n  * Code Health\n  * Code Review Guidelines\n  * Another guidelines\n\nThese pitfalls are common but avoidable. Over time, you get into a habit of\navoiding them. I think it\u2019s just a matter of experience - the more code you\nwrite, the more code reviews you pass \u2014 the less you \u201cactively\u201d focus on\nmaking the code good, and the more it happens subconsciously. As mentioned\nabove, having checklists is still important. Remember, the goal of a code\nreview is not just to find mistakes but to learn from them and improve both\nthe code and you, the coder.\n\n## Great, you found issues, how to communicate\n\nImagine you found the issues. How do you make sure the developer doesn\u2019t hate\nyou after you give him the feedback? I\u2019ve seen quite a few times when the\ndevelopers were demotivated for weeks after a bad review. And that\u2019s not how\nit should go.\n\nI\u2019m a strong believer in Nonviolent Code Review. Basically, the NVC\nmethodology is applied to the Code Reviews. The key principles include:\n\n  * Everyone's code, including yours, can be better. Someone wanting to change things in your code is not a personal attack on you.\n  * We're talking about the code, not the coder.\n  * No personal feelings. Avoid thoughts \u201c... as we have always done it that way,\u201d \u201cI spent a lot of time on this,\u201d \u201cI\u2019m not stupid, you are,\u201d \u201cMy code is better,\u201d etc. Smile, forgive yourself, shake your head, and move on.\n  * Make all of your comments positive and oriented to improving the code. Be kind to the coder, not to the code.\n\nGreat example of what not to do. Source Toxic Code Reviews\n\nSometimes, what bugs you is just a matter of personal taste, not an objective\nflaw in the code. We\u2019re all software developers, and we have gathered our\nshare of subjective opinions over the years. Learn to distinguish between your\ntaste and objective flaws. Be pragmatic. The goal is better code, not winning\nan argument.\n\n    \n    \n    \u274c Bad: \u201cYou are writing code that I can\u2019t understand.\u201d \u274c Bad: \u201cYour code is so bad/unclear/ \u201d \u2705 Good: \u201cI\u2019m having a hard time understanding the code.\u201d \u2705 Good: \u201cI have a feeling the code lacks clarity in this module.\u201d \u2705 Good: \u201cI\u2019m struggling to understand the complexity, how can we make it more clear?\u201d\n\nUse I-messages. Instead of saying, \"You write code like a toddler,\u201d try, \"I'm\nfinding it hard to understand what's happening here.\" See the difference?\nOne's a personal attack, the other's constructive feedback.\n\nAs part of the Non-Violent-Communication \u2014 ask questions as an equal instead\nof making declarations from on high. Instead of \"Rename this variable to\n\u2018sumOfBalances\u2019 now,\" try \"What do you think about naming this variable\n\u2018sumOfBalances\u2019?\" It's not just about being polite; it's about opening a\ndialogue, not shutting it down.\n\n    \n    \n    \u274c Bad: \u201cWe\u2019ve done it like this all the time!\u201d \u274c Bad: \u201cI don\u2019t like how you named your variables\u201d \u274c Bad: \u201cYou\u2019ve chosen a bad framework, should\u2019ve stuck to X.\u201d \u2705Good: \u201cYour solution is fine, but I know a few alternatives to how this can be done if you\u2019re interested.\u201d \u2705Good: \u201cAre you sure the variables are named according to our coding standards?\u201d \u2705Good: \u201cI have my personal opinion about this framework; maybe we should discuss it?\n\nRemember, you're reviewing code, not personality traits. Don't label someone\nas sloppy/bad/tardy just because they missed a couple of tests. Point out the\ncode, not the person. \u201cI think focusing more on test coverage at this function\nwould be beneficial. What do you think?\u201d It goes down a lot smoother than \"You\nalways miss some test cases!\u201d\n\nNobody sits down at their computer and thinks, \"Today, I'm going to write the\nworst code the world has ever seen.\" They're doing their best. Remember that.\nAnd compliment them when you don\u2019t find anything or something is done well.\n\n## Code Reviews FAQ\n\nHere are some common questions that I've encountered to guide you through this\ncritical process.\n\n  1. What if code reviews are slowing down our development process?\n\nA popular question from the business perspective. Why do code reviews at all\nwhen you can just push to the main branch? Speed vs. Quality: a classic trade-\noff. Remember, the goal of code reviews is not just to maintain code quality\ntoday but also to prevent future issues that can slow you down significantly.\nIf you allow ANY code into your main branch over time, the code smells will\npile on, and you\u2019ll end up with a codebase that is unmaintainable. If reviews\nare taking too long, consider streamlining your process with checklists,\nautomated tools, and clear guidelines.\n\n  2. Should we review everything, or can some things be skipped?\n\nWhile it's tempting to review every single line of code, it's not always\npractical or necessary. Set a threshold for what requires review - for\ninstance, major features, bug fixes, and code that affects critical parts of\nthe application. Use your best judgment and trust your team for smaller, less\ncritical changes, e.g., typos or documentation updates don\u2019t require a review.\n\n  3. Can we rely purely on automated tools for code reviews?\n\nAutomated tools are valuable, but they're not a complete substitute for human\nreviews. They're great for catching syntactical errors, code style violations,\nand obvious bugs. However, they can't assess the WHY behind a function, the\nlogic, architecture, or whether the code meets specific business requirements.\n\n  4. How do we handle code reviews in a remote or distributed team?\n\nEasy: Asynchronously. I know some people prefer both parties to be online\nwhile doing the review as it lessens the communication time, but I\u2019m a strong\nproponent of asynchronous communication. You do your review, ask questions,\nand continue with your work until the developer comes online and responds to\nthe feedback/refactors the code, etc. For remote or distributed teams,\ntransparent communication and the right tools are key.\n\n  5. What's the largest size for a pull request that should be reviewed?\n\nIt's best to keep PRs manageable. A good upper limit is a PR that can be\nthoroughly reviewed in 30 to 60 minutes. If a PR is too large, it becomes\ndifficult to review effectively, increasing the chances of missing critical\nissues. If your PRs are consistently large, consider breaking them into\nsmaller, more focused units.\n\n  6. How do we handle urgent hotfixes in terms of code reviews?\n\nUrgent hotfixes often require a different approach. While they still need to\nbe reviewed, the process might be expedited. In such cases, it's crucial to\nhave a post-mortem review after the fix is deployed to ensure any missed\nissues are caught and to learn from the incident.\n\nAs always, my comment section is open if you have any thoughts and opinions of\nyour own. Cheers.\n\nOther Newsletter Issues:\n\n  * Habits of great software engineers\n  * Networking as an introvert CTO\n  * Database Migrations\n  * Proper Documentation\n\n### Reactions\n\nHot! The last couple of years I've been writing about CTO / Tech lead job.\nI've compiled all my knowledge into a printable PDF. I called it \"256 Pages of\nNo Bullshit Guide for CTOs\". So if you're interested, take a look.\n\nHot! If you're a software engineer looking for a job, I started a Roast my\nResume service, where I record a personalized video of me \"roasting\" your CV,\nwhich basically means taking a hard look at your resume as a CTO and\ncommenting on all the good and the bad parts.\n\nNew! \ud83d\ude80 15% OFF for HackerNews Visitors for No Bullshit Guide for CTOs. Give it\na click if you like.\n\nCancel\n\n  * Liam Stone\n\nFebruary 27, 2024 at 11:34 pm\n\nOnce, in a sprint to meet an insane deadline, my team decided to skip code\nreviews, thinking we\u2019d save precious time. What followed was a chaotic\nscenario where merging to the main branch felt like diffusing a bomb, unsure\nif our new features would implode the app. After facing the aftermath, I\u2019ve\nbecome a huge advocate for regular, thorough reviews, regardless of time\nconstraints.\n\nReply\n\n  * Thijs\n\nFebruary 15, 2024 at 2:20 am\n\nCode reviews are super important, man. They catch mistakes but really, they\nmake the team work better together. It\u2019s all about getting better together,\nnot just pointing out what\u2019s wrong. Gotta keep an open mind and not get all\ndefensive. Tools help, but nothing beats a real person looking at the code.\nWe\u2019re all here to make the code better, not to blame. You think adding more\nautomated tools in the review process is a good idea?\n\nReply\n\n  * Jhonattan\n\nJanuary 18, 2024 at 4:53 pm\n\nGreat article, by working on a software develpment we already know most of the\narticle parts, but for sure we do not follow, it\u2019s allways good to have things\nwell explain and refresh like this article. On the other side I believe that\nsome kind of guide should be created among the \u201cagile world\u201d I mean scrum,\nkamban and so on ... I believe that time to market makes also bad code to be\ndeployed, since there is so much pression over there to approve almost\nanything just to acomplish some high goals for the teams. I\u2019ve seen a big\ndifference bettewen in home projects for a product vs working as a external\nvendor, the first one is in a rush of presenting new features no matter the\nrisk (we can do QA latter), let\u2019s go to production first. The second one might\nbe more detail, but since no all \u201ccode review beheavorals are followed\u201d you\ncan be easily overhamed about your code, there are a lot of product owners and\ncode owners out there that just want the code to be as they wanted to be.\n\nReply\n\n  * Anonymous\n\nJanuary 16, 2024 at 4:54 pm\n\nWow! Its article make me think about the really purpose behind code review.\nTks!\n\nReply\n\n  * Anonymous\n\nJanuary 16, 2024 at 12:59 pm\n\nCode review is a very laborious, fickle, opinionated process. Once someone\nreviews my PR, I just make their changes. I care more about getting the PR\nthrough, so I become their yes-man.\n\nGoing back and forth bickering about what style of code is \u201ccleaner\u201d will just\nwaste my time, when at work I really only care about optimizing for stuff like\nperformance reviews.\n\nReply\n\n  * Anonymous\n\nJanuary 15, 2024 at 4:23 pm\n\n> Remember, you\u2019re reviewing code, not personality traits. Don\u2019t label someone\n> as sloppy/bad/tardy just because they missed a couple of tests. Point out\n> the code, not the person. \u201cI think focusing more on test coverage at this\n> function would be beneficial. What do you think?\u201d It goes down a lot\n> smoother than \u201cYou always miss some test cases!\u201d\n\nHow do you suggest, as a code reviewer, how to handle multiple code reviews\nwhere the same sloppy code is consistently part of the code? I am running into\nthis currently, and it gets exhausting repeating the same reasons why they\nshould make changes....and now they (the coder) just think i\u2019m being a\nrepeating a**hole because I\u2019m saying the same things over, and it\u2019s just\nemotionally exhausting cuz I gotta go through this every PR?....genuinely\nlooking for help, thanks\n\nReply\n\n    1. TKeezy\n\nJanuary 15, 2024 at 4:24 pm\n\nPS: Loved the article, btw\n\n-TKeezy\n\nReply\n\n    2. Mickus\n\nJanuary 16, 2024 at 5:08 pm\n\nI worked in a Scrum team whose product was late to market (released a full\nyear behind their competitor!) and the name of the game was fast, cheap, and\npoor quality. I did not enjoy it, and had to stem the tide of rookie devs\nusing questionable data structures. My favorite response was \u201cHey, are you\nsure you want to skim testing on this? This will cause problems X, Y, and Z\nlater.\u201d The response was always some form of \u201cBut it works and it\u2019s fast\u201d, to\nwhich I said \u201cOK, but be warned, the rest of the team will make sure all\nfuture X, Y, and Z work on this item goes to you\u201d. Passing the work by saying\n\u201cDo you want this?\u201d and making sure they answer the question, \u201cBut you didn\u2019t\nanswer my question... do you want this extra responsibility?\u201d, seemed to cut\ndown on ~30% of repeat issues, and I was able to convince at least 1 of 4 new\ndevs on how it should be done.\n\nReply\n\n  * Danilo\n\nJanuary 15, 2024 at 10:41 am\n\nA good overview of why code reviews are important!\n\nI feel a bit bad about other commenters here (Alex, first Anonymous) having\nexperienced bad teams as much to have the opinions they do (\u201ctoo often\u201d and\n\u201cwhatever your lead dev\u201d...).\n\nI had the fortune to start my career on a project requiring 2 code reviews,\nbut everyone was approachable and kind, and I kept learning as if on a speed\nrun.\n\nReply\n\n  * Alex Lee\n\nJanuary 15, 2024 at 9:45 am\n\nWell said. Constructive critique of code can be very valuable but too often\ndevolve into turf wars and ideology.\n\nReply\n\n    1. Anonymous\n\nJanuary 16, 2024 at 1:12 pm\n\nA. N\n\nReply\n\n  * Anonymous\n\nJanuary 15, 2024 at 8:39 am\n\nYou might be interested in my blog post about coffee reviews, as it has other\nvery useful information, backed by research:\nhttps://blog.pplupo.com/2021-12-14-Code-Review-Guidelines-Beyond-the-what/\n\nReply\n\n    1. Vadim Kravcenko\n\nJanuary 15, 2024 at 3:57 pm\n\nThanks for sharing that, it has a lot of scientific papers, will take a look\nat them more in-depth\n\nReply\n\n  * Anonymous\n\nJanuary 15, 2024 at 8:38 am\n\nBad code is whatever your lead dev perceives it to be...\n\nReply\n\n    1. Vadim Kravcenko\n\nJanuary 15, 2024 at 3:55 pm\n\nSo this sounds a bit sad. Sure, the lead dev\u2019s opinion carries weight, but\nit\u2019s not the be-all and end-all.\n\nNow, don\u2019t get me wrong. Your lead dev\u2019s feedback is crucial. They\u2019ve been\ndoing this for a longer amount of time and probably have seen a lot of\nspaghetti code, so take the feedback seriously.\n\nAnd hey, sometimes you gotta stand your ground. If you think your code adheres\nto all the best practices and this is the way to go you\u2019ve got solid reasoning\nbehind it, make your case. Just be ready to back it up with more than just \u201cit\nworks on my machine.\u201d\n\nReply\n\n  * 1\\. Preface\n  * 2\\. Before the review\n  * 3\\. Standardizing everything\n  * 4\\. Common things to look out for\n  * 5\\. Great, you found issues, how to communicate\n  * 6\\. Code Reviews FAQ\n\n#### Popular Issues\n\n  * \ud83d\udd52 Rules of Thumb for Software Development Estimations\n\n  * \ud83d\udcdc Contracts you should never sign\n\n  * \ud83e\udd77 Things they didn\u2019t teach you about Software Engineering\n\n  * \ud83e\udd39\u2642\ufe0f Habits of great software engineers\n\n  * \ud83e\udd2b Falsehoods Junior Developers believe about becoming Senior\n\n  * \ud83c\udfad Managing difficult software engineers\n\nNew!\ud83d\udd75\ufe0f\u2642\ufe0f Roast My Resume Hot!\ud83e\udd16 No-Bullshit CTO Guide \ud83d\udd25 Watch Youtube \ud83d\udcda\nDeveloper Q&A\n\n89+ people joined this week\n\n### Get insights from a CTO into your inbox every two weeks.\n\nYou've probably read a few of my articles already, that's the kind of content\nyou should expect in the newsletter. I share my thoughts as a CTO. Some of the\ntopics that I like writing about: building SaaS products, growing teams,\nscaling technology and in general being a good founder and a decent person.\n\nNo spam, unsubscribe at any time\n\n## Developer Q&A Latest\n\n  * How can you tell if you\u2019re a good developer?\n  * I\u2019m finishing university, scared about future career prospects\n  * I have a very poor work-life balance. How can I escape the grind?\n  * What is your unethical CS career\u2019s advice?\n  * My coworker rewrote all my code, what should I do?\n  * How do you know when to use which programming language?\n  * How to get programming experience when you can\u2019t find a job?\n  * Do some people just not have the talent for Software Engineering?\n\n## Popular Issues\n\n  * \ud83d\udd52 Rules of Thumb for Software Development Estimations\n  * \ud83d\udcdc Contracts you should never sign\n  * \ud83e\udd77 Things they didn\u2019t teach you about Software Engineering\n  * \ud83e\udd39\u2642\ufe0f Habits of great software engineers\n  * \ud83e\udd2b Falsehoods Junior Developers believe about becoming Senior\n  * \ud83c\udfad Managing difficult software engineers\n  * \ud83d\udce2 The silent majority\n  * \ud83d\udd10 Security at Startup\n  * \ud83d\udcda The Surprising Power of Documentation\n\n## Popular Tags\n\n  * Engineering Growth\n  * Management Tips\n  * Development\n  * Startups\n\n## Work with me\n\n  * CTO-as-a-Service\n  * Fractional CTO\n  * Consulting\n\n\u00a9 2024 Vadim Kravcenko. Built with \u2665 in Zurich. All opinions are my own. I use\nPlausible to track certain anonymous events. Some links are affiliate links\nwhere I earn a commission. Contact me at hi@vadimkravcenko.com\n\n", "frontpage": false}
