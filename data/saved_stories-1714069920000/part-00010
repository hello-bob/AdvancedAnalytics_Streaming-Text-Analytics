{"aid": "40155743", "title": "FastText Repo Archived", "url": "https://github.com/facebookresearch/fastText", "domain": "github.com/facebookresearch", "votes": 1, "user": "polm23", "posted_at": "2024-04-25 10:37:52", "comments": 0, "source_title": "GitHub - facebookresearch/fastText: Library for fast text representation and classification.", "source_text": "GitHub - facebookresearch/fastText: Library for fast text representation and\nclassification.\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nThis repository has been archived by the owner on Mar 19, 2024. It is now\nread-only.\n\nfacebookresearch / fastText Public archive\n\n  * Notifications\n  * Fork 4.7k\n  * Star 25.6k\n\nLibrary for fast text representation and classification.\n\nfasttext.cc/\n\n### License\n\nMIT license\n\n25.6k stars 4.7k forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# facebookresearch/fastText\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n6 Branches\n\n5 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nbigfootjonandfacebook-github-botDelete .circleci directory (#1366)Mar 13,\n20241142dc4 \u00b7 Mar 13, 2024Mar 13, 2024\n\n## History\n\n391 Commits  \n  \n### alignment\n\n|\n\n### alignment\n\n| Add unsupervised multilingual alignement| Sep 6, 2019  \n  \n### crawl\n\n|\n\n### crawl\n\n| Corrected URL for lid models in the scripts to process CC.| Feb 22, 2019  \n  \n### docs\n\n|\n\n### docs\n\n| Add documentation about Hugging Face integration (#1335)| Jun 7, 2023  \n  \n### python\n\n|\n\n### python\n\n| deeplearning/fastText 2/2| Feb 20, 2024  \n  \n### scripts\n\n|\n\n### scripts\n\n| Re-licensing fasttext to MIT| Dec 18, 2018  \n  \n### src\n\n|\n\n### src\n\n| Predict 1.9-4.2x faster (#1341)| Jan 9, 2024  \n  \n### tests\n\n|\n\n### tests\n\n| Replace outdated url in the scripts| Apr 17, 2023  \n  \n### webassembly\n\n|\n\n### webassembly\n\n| wasm compilation issue fix| May 27, 2020  \n  \n### website\n\n|\n\n### website\n\n| Adding social banner (#1257)| Mar 4, 2022  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| WebAssembly| Apr 10, 2020  \n  \n### CMakeLists.txt\n\n|\n\n### CMakeLists.txt\n\n| Predict 1.9-4.2x faster (#1341)| Jan 9, 2024  \n  \n### CODE_OF_CONDUCT.md\n\n|\n\n### CODE_OF_CONDUCT.md\n\n| Adopt Contributor Covenant| Aug 30, 2019  \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n| Re-licensing fasttext to MIT| Dec 18, 2018  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Re-licensing fasttext to MIT| Dec 18, 2018  \n  \n### MANIFEST.in\n\n|\n\n### MANIFEST.in\n\n| setup.py to support packaging and replace throw with exit| Nov 28, 2017  \n  \n### Makefile\n\n|\n\n### Makefile\n\n| Predict 1.9-4.2x faster (#1341)| Jan 9, 2024  \n  \n### PACKAGE\n\n|\n\n### PACKAGE\n\n| Migrate \"deeplearning/fastText\" from LLVM-12 to LLVM-15| Jun 21, 2023  \n  \n### README.md\n\n|\n\n### README.md\n\n| release 0.9.2| Apr 28, 2020  \n  \n### classification-example.sh\n\n|\n\n### classification-example.sh\n\n| Replace outdated url in the scripts| Apr 17, 2023  \n  \n### classification-results.sh\n\n|\n\n### classification-results.sh\n\n| Re-licensing fasttext to MIT| Dec 18, 2018  \n  \n### download_model.py\n\n|\n\n### download_model.py\n\n| scripts to download word vector models and reduce their size| Jan 3, 2020  \n  \n### eval.py\n\n|\n\n### eval.py\n\n| Re-licensing fasttext to MIT| Dec 18, 2018  \n  \n### fasttext.pc.in\n\n|\n\n### fasttext.pc.in\n\n| cmake: generate fasttext.pc for pkg-config (#916)| Apr 28, 2020  \n  \n### get-wikimedia.sh\n\n|\n\n### get-wikimedia.sh\n\n| Re-licensing fasttext to MIT| Dec 18, 2018  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| Add pyproject.toml to comply with PEP-518 (#1292)| Nov 27, 2023  \n  \n### quantization-example.sh\n\n|\n\n### quantization-example.sh\n\n| Replace outdated url in the scripts| Apr 17, 2023  \n  \n### reduce_model.py\n\n|\n\n### reduce_model.py\n\n| scripts to download word vector models and reduce their size| Jan 3, 2020  \n  \n### runtests.py\n\n|\n\n### runtests.py\n\n| New release of python module| Jun 25, 2019  \n  \n### setup.cfg\n\n|\n\n### setup.cfg\n\n| setup.py to support packaging and replace throw with exit| Nov 28, 2017  \n  \n### setup.py\n\n|\n\n### setup.py\n\n| deeplearning/fastText 2/2| Feb 20, 2024  \n  \n### wikifil.pl\n\n|\n\n### wikifil.pl\n\n| Corrected brace escaping in perl script| Mar 13, 2017  \n  \n### word-vector-example.sh\n\n|\n\n### word-vector-example.sh\n\n| Re-licensing fasttext to MIT| Dec 18, 2018  \n  \n## Repository files navigation\n\n# fastText\n\nfastText is a library for efficient learning of word representations and\nsentence classification.\n\n## Table of contents\n\n  * Resources\n\n    * Models\n    * Supplementary data\n    * FAQ\n    * Cheatsheet\n  * Requirements\n  * Building fastText\n\n    * Getting the source code\n    * Building fastText using make (preferred)\n    * Building fastText using cmake\n    * Building fastText for Python\n  * Example use cases\n\n    * Word representation learning\n    * Obtaining word vectors for out-of-vocabulary words\n    * Text classification\n  * Full documentation\n  * References\n\n    * Enriching Word Vectors with Subword Information\n    * Bag of Tricks for Efficient Text Classification\n    * FastText.zip: Compressing text classification models\n  * Join the fastText community\n  * License\n\n## Resources\n\n### Models\n\n  * Recent state-of-the-art English word vectors.\n  * Word vectors for 157 languages trained on Wikipedia and Crawl.\n  * Models for language identification and various supervised tasks.\n\n### Supplementary data\n\n  * The preprocessed YFCC100M data used in [2].\n\n### FAQ\n\nYou can find answers to frequently asked questions on our website.\n\n### Cheatsheet\n\nWe also provide a cheatsheet full of useful one-liners.\n\n## Requirements\n\nWe are continuously building and testing our library, CLI and Python bindings\nunder various docker images using circleci.\n\nGenerally, fastText builds on modern Mac OS and Linux distributions. Since it\nuses some C++11 features, it requires a compiler with good C++11 support.\nThese include :\n\n  * (g++-4.7.2 or newer) or (clang-3.3 or newer)\n\nCompilation is carried out using a Makefile, so you will need to have a\nworking make. If you want to use cmake you need at least version 2.8.9.\n\nOne of the oldest distributions we successfully built and tested the CLI under\nis Debian jessie.\n\nFor the word-similarity evaluation script you will need:\n\n  * Python 2.6 or newer\n  * NumPy & SciPy\n\nFor the python bindings (see the subdirectory python) you will need:\n\n  * Python version 2.7 or >=3.4\n  * NumPy & SciPy\n  * pybind11\n\nOne of the oldest distributions we successfully built and tested the Python\nbindings under is Debian jessie.\n\nIf these requirements make it impossible for you to use fastText, please open\nan issue and we will try to accommodate you.\n\n## Building fastText\n\nWe discuss building the latest stable version of fastText.\n\n### Getting the source code\n\nYou can find our latest stable release in the usual place.\n\nThere is also the master branch that contains all of our most recent work, but\ncomes along with all the usual caveats of an unstable branch. You might want\nto use this if you are a developer or power-user.\n\n### Building fastText using make (preferred)\n\n    \n    \n    $ wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip $ unzip v0.9.2.zip $ cd fastText-0.9.2 $ make\n\nThis will produce object files for all the classes as well as the main binary\nfasttext. If you do not plan on using the default system-wide compiler, update\nthe two macros defined at the beginning of the Makefile (CC and INCLUDES).\n\n### Building fastText using cmake\n\nFor now this is not part of a release, so you will need to clone the master\nbranch.\n\n    \n    \n    $ git clone https://github.com/facebookresearch/fastText.git $ cd fastText $ mkdir build && cd build && cmake .. $ make && make install\n\nThis will create the fasttext binary and also all relevant libraries (shared,\nstatic, PIC).\n\n### Building fastText for Python\n\nFor now this is not part of a release, so you will need to clone the master\nbranch.\n\n    \n    \n    $ git clone https://github.com/facebookresearch/fastText.git $ cd fastText $ pip install .\n\nFor further information and introduction see python/README.md\n\n## Example use cases\n\nThis library has two main use cases: word representation learning and text\nclassification. These were described in the two papers 1 and 2.\n\n### Word representation learning\n\nIn order to learn word vectors, as described in 1, do:\n\n    \n    \n    $ ./fasttext skipgram -input data.txt -output model\n\nwhere data.txt is a training file containing UTF-8 encoded text. By default\nthe word vectors will take into account character n-grams from 3 to 6\ncharacters. At the end of optimization the program will save two files:\nmodel.bin and model.vec. model.vec is a text file containing the word vectors,\none per line. model.bin is a binary file containing the parameters of the\nmodel along with the dictionary and all hyper parameters. The binary file can\nbe used later to compute word vectors or to restart the optimization.\n\n### Obtaining word vectors for out-of-vocabulary words\n\nThe previously trained model can be used to compute word vectors for out-of-\nvocabulary words. Provided you have a text file queries.txt containing words\nfor which you want to compute vectors, use the following command:\n\n    \n    \n    $ ./fasttext print-word-vectors model.bin < queries.txt\n\nThis will output word vectors to the standard output, one vector per line.\nThis can also be used with pipes:\n\n    \n    \n    $ cat queries.txt | ./fasttext print-word-vectors model.bin\n\nSee the provided scripts for an example. For instance, running:\n\n    \n    \n    $ ./word-vector-example.sh\n\nwill compile the code, download data, compute word vectors and evaluate them\non the rare words similarity dataset RW [Thang et al. 2013].\n\n### Text classification\n\nThis library can also be used to train supervised text classifiers, for\ninstance for sentiment analysis. In order to train a text classifier using the\nmethod described in 2, use:\n\n    \n    \n    $ ./fasttext supervised -input train.txt -output model\n\nwhere train.txt is a text file containing a training sentence per line along\nwith the labels. By default, we assume that labels are words that are prefixed\nby the string __label__. This will output two files: model.bin and model.vec.\nOnce the model was trained, you can evaluate it by computing the precision and\nrecall at k (P@k and R@k) on a test set using:\n\n    \n    \n    $ ./fasttext test model.bin test.txt k\n\nThe argument k is optional, and is equal to 1 by default.\n\nIn order to obtain the k most likely labels for a piece of text, use:\n\n    \n    \n    $ ./fasttext predict model.bin test.txt k\n\nor use predict-prob to also get the probability for each label\n\n    \n    \n    $ ./fasttext predict-prob model.bin test.txt k\n\nwhere test.txt contains a piece of text to classify per line. Doing so will\nprint to the standard output the k most likely labels for each line. The\nargument k is optional, and equal to 1 by default. See classification-\nexample.sh for an example use case. In order to reproduce results from the\npaper 2, run classification-results.sh, this will download all the datasets\nand reproduce the results from Table 1.\n\nIf you want to compute vector representations of sentences or paragraphs,\nplease use:\n\n    \n    \n    $ ./fasttext print-sentence-vectors model.bin < text.txt\n\nThis assumes that the text.txt file contains the paragraphs that you want to\nget vectors for. The program will output one vector representation per line in\nthe file.\n\nYou can also quantize a supervised model to reduce its memory usage with the\nfollowing command:\n\n    \n    \n    $ ./fasttext quantize -output model\n\nThis will create a .ftz file with a smaller memory footprint. All the standard\nfunctionality, like test or predict work the same way on the quantized models:\n\n    \n    \n    $ ./fasttext test model.ftz test.txt\n\nThe quantization procedure follows the steps described in 3. You can run the\nscript quantization-example.sh for an example.\n\n## Full documentation\n\nInvoke a command without arguments to list available arguments and their\ndefault values:\n\n    \n    \n    $ ./fasttext supervised Empty input or output path. The following arguments are mandatory: -input training file path -output output file path The following arguments are optional: -verbose verbosity level [2] The following arguments for the dictionary are optional: -minCount minimal number of word occurrences [1] -minCountLabel minimal number of label occurrences [0] -wordNgrams max length of word ngram [1] -bucket number of buckets [2000000] -minn min length of char ngram [0] -maxn max length of char ngram [0] -t sampling threshold [0.0001] -label labels prefix [__label__] The following arguments for training are optional: -lr learning rate [0.1] -lrUpdateRate change the rate of updates for the learning rate [100] -dim size of word vectors [100] -ws size of the context window [5] -epoch number of epochs [5] -neg number of negatives sampled [5] -loss loss function {ns, hs, softmax} [softmax] -thread number of threads [12] -pretrainedVectors pretrained word vectors for supervised learning [] -saveOutput whether output params should be saved [0] The following arguments for quantization are optional: -cutoff number of words and ngrams to retain [0] -retrain finetune embeddings if a cutoff is applied [0] -qnorm quantizing the norm separately [0] -qout quantizing the classifier [0] -dsub size of each sub-vector [2]\n\nDefaults may vary by mode. (Word-representation modes skipgram and cbow use a\ndefault -minCount of 5.)\n\n## References\n\nPlease cite 1 if using this code for learning word representations or 2 if\nusing for text classification.\n\n### Enriching Word Vectors with Subword Information\n\n[1] P. Bojanowski*, E. Grave*, A. Joulin, T. Mikolov, Enriching Word Vectors\nwith Subword Information\n\n    \n    \n    @article{bojanowski2017enriching, title={Enriching Word Vectors with Subword Information}, author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas}, journal={Transactions of the Association for Computational Linguistics}, volume={5}, year={2017}, issn={2307-387X}, pages={135--146} }\n\n### Bag of Tricks for Efficient Text Classification\n\n[2] A. Joulin, E. Grave, P. Bojanowski, T. Mikolov, Bag of Tricks for\nEfficient Text Classification\n\n    \n    \n    @InProceedings{joulin2017bag, title={Bag of Tricks for Efficient Text Classification}, author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas}, booktitle={Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers}, month={April}, year={2017}, publisher={Association for Computational Linguistics}, pages={427--431}, }\n\n### FastText.zip: Compressing text classification models\n\n[3] A. Joulin, E. Grave, P. Bojanowski, M. Douze, H. J\u00e9gou, T. Mikolov,\nFastText.zip: Compressing text classification models\n\n    \n    \n    @article{joulin2016fasttext, title={FastText.zip: Compressing text classification models}, author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Douze, Matthijs and J{\\'e}gou, H{\\'e}rve and Mikolov, Tomas}, journal={arXiv preprint arXiv:1612.03651}, year={2016} }\n\n(* These authors contributed equally.)\n\n## Join the fastText community\n\n  * Facebook page: https://www.facebook.com/groups/1174547215919768\n  * Google group: https://groups.google.com/forum/#!forum/fasttext-library\n  * Contact: egrave@fb.com, bojanowski@fb.com, ajoulin@fb.com, tmikolov@fb.com\n\nSee the CONTRIBUTING file for information about how to help out.\n\n## License\n\nfastText is MIT-licensed.\n\n## About\n\nLibrary for fast text representation and classification.\n\nfasttext.cc/\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\n### Code of conduct\n\nCode of conduct\n\n### Security policy\n\nSecurity policy\n\nActivity\n\nCustom properties\n\n### Stars\n\n25.6k stars\n\n### Watchers\n\n845 watching\n\n### Forks\n\n4.7k forks\n\nReport repository\n\n## Releases 4\n\nv0.9.2 Latest\n\nApr 28, 2020\n\n\\+ 3 releases\n\n## Packages 0\n\nNo packages published\n\n## Used by 5.7k\n\n\\+ 5,679\n\n## Contributors 56\n\n\\+ 42 contributors\n\n## Languages\n\n  * HTML 68.4%\n  * C++ 10.9%\n  * JavaScript 10.2%\n  * Python 6.4%\n  * CSS 2.0%\n  * Shell 1.7%\n  * Other 0.4%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
