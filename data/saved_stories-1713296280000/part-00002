{"aid": "40051690", "title": "Is there enough text to feed the AI beast?", "url": "https://www.semafor.com/article/04/15/2024/is-there-enough-text-to-feed-the-ai-beast", "domain": "semafor.com", "votes": 1, "user": "marban", "posted_at": "2024-04-16 13:37:21", "comments": 0, "source_title": "Is there enough text to feed the AI beast? | Semafor", "source_text": "Is there enough text to feed the AI beast? | Semafor\n\nEventsNewsletters\n\n  * Home\n  * politics\n  * business\n  * technology\n  * net zero\n  * africa\n  * security\n  * media\n  * Global Elections\n\n  * TikTokTwitterFacebook\n  * AboutCareers\n\nPrivacy\u00a9 2024 Semafor Inc.\n\n  * D.C.\n  * BXL\n  * Lagos\n  * Dubai\n  * Beijing\n  * SG\n\n  * D.C.\n  * BXL\n  * Lagos\n\n  * Dubai\n  * Beijing\n  * SG\n\nEventsNewsletters\n\nIntelligentTransparentGlobal\n\nKatyanna Quach\n\nApr 16, 2024, 8:25am EDT\n\ntech\n\n# Is there enough text to feed the AI beast?\n\nDenis Balibouse/File Photo/Reuters\n\nPostEmailWhatsapp\n\nIn this article:\n\n### The Scoop\n\n### Know More\n\n### Katyanna\u2019s view\n\n### Room for Disagreement\n\n### Notable\n\n### The Scoop\n\nA Stanford study made headlines this week with the prediction that the largest\nAI models could run out of new text to scrape by the end of this year \u2014 but\nthe study\u2019s leader said he believes AI companies won\u2019t really feel the crunch\nuntil at least the end of the decade.\n\nEpoch, an AI forecasting research institute, projected the amount of data\nrequired to train models as they continue to scale in size, and compared this\nto how much data is expected to be published online in the future. Its results\nappear in the AI Index Report published by the Stanford Institute for Human-\nCentered AI this week.\n\nThe amount of data on the internet is growing at a pace of about 7% per year,\nEpoch\u2019s director, Jaime Sevilla, said, while the amount of data AI is being\ntrained on is increasing at 200% per year. If the biggest models have ingested\nmost of the content already, there won\u2019t be much new information for them to\nlearn from.\n\nAD\n\nBut while the Stanford study says AI companies could run out of text within\nmonths, Epoch has adjusted its predictions and is planning to publish a new\nresearch paper with updating its estimates, and believes that there will still\nbe enough public data left to train AI models \u201cfive or six years from now,\u201d he\nsaid.\n\nThe shift comes because analysts initially only considered the high-quality\ntext from reputable sources that have been edited by people for accuracy like\nnews articles and Wikipedia pages.\n\n\u201cWe\u2019re less sure about how important it\u2019s going to be to train only on high-\nquality data. We think that broader kinds of data might still be useful,\nperhaps not to the same degree, but they might still be enough to continue the\npace of scaling so we have become a bit more optimistic,\u201d Sevilla said.\n\nAD\n\nIn this article:\n\n### The Scoop\n\n### Know More\n\n### Katyanna\u2019s view\n\n### Room for Disagreement\n\n### Notable\n\n### Know More\n\nTech companies will have to find new sources of data if they run out of\ninformation to scrape from the internet to train increasingly large AI models.\nWell-funded AI giants will probably find a way around this shortage. OpenAI\u2019s\nCEO Sam Altman has said that it won\u2019t be too much of a problem if AI can\ngenerate useful synthetic data.\n\nTraining on AI-generated outputs, however, is risky and unreliable. Models are\nprone to spewing false facts, and these errors are carried forward if they\u2019re\ntrained on the text they produce, degrading their performance over time. Last\nyear, computer scientists showed how a language model, released by Meta in\n2022, got worse when it was repeatedly trained on synthetic data.\n\nIn one example, a conversation about the architecture of an old church quickly\nmorphed into a list of jackrabbits with different coloured tails. The text\nproduced by AI is often bland and repetitive, and nudging models to write more\ncreatively comes at the cost of sacrificing accuracy.\n\nAD\n\nFiguring out how to generate good synthetic data is an active area of\nresearch. Microsoft has been exploring methods to produce text that\u2019s both\ndiverse and accurate. Meanwhile, Anthropic may have found a decent way around\nthese issues since it trained its latest language model on some synthetic\ntext.\n\nThere is another way to get more data too: Paying humans to create it. Several\ntech companies work with data labeling services to look for people with\nwriting skills or expert knowledge to produce content to train AI. Those with\ndeep pockets, like OpenAI and Google, have negotiated content licensing deals\nwith platforms and publishers worth millions of dollars per year.\n\n### Katyanna\u2019s view\n\nOne immediate consequence of the text shortage may be a widening gap between\nthe performance of open source AI and private commercial technologies.\n\nCompanies will have to pay for new sources of data, both by synthetically\ngenerating it themselves and paying people to create it. Taking text produced\nby one commercial model to train a competing system is typically against the\nterms and conditions of usage (although this is difficult to stop in\npractice), and those that can\u2019t afford to pay creators for content could\nstruggle to compete.\n\n### Room for Disagreement\n\nData shortages may not matter so much if computer scientists can develop new\ntechniques or architectures that make models learn more efficiently on less\ninformation. There\u2019s a push to make small models more effective by training\nthem on other sources of text that are cleaner and more specialized, like\ntextbooks, instead of general information scraped from the web.\n\n### Notable\n\n  * Stanford HAI also found that private investment in AI has decreased overall, but there are more startups than ever and spending on generative AI has octupled to $25.2 billion.\n  * To find more text, OpenAI reportedly used its AI speech-to-text tool, Whisper, to automatically transcribe audio from YouTube videos, according to the New York Times.\n  * AI startups are training their own models on synthetic data generated by top systems like GPT-4 to copy its behavior, The Information reported.\n\nAD\n\n", "frontpage": false}
