{"aid": "40051576", "title": "SQLite on Rails: The how and why of optimal performance", "url": "https://fractaledmind.github.io/2024/04/15/sqlite-on-rails-the-how-and-why-of-optimal-performance/", "domain": "fractaledmind.github.io", "votes": 2, "user": "stadeschuldt", "posted_at": "2024-04-16 13:24:53", "comments": 0, "source_title": "SQLite on Rails | Fractaled Mind", "source_text": "SQLite on Rails | Fractaled Mind\n\nApril 15, 2024 \u00b7 Stephen Margheim \u00b7 code, ruby, rails, sqlite\n\n# SQLite on Rails: The how and why of optimal performance\n\nOver the last year or so, I have found myself on a journey to deeply\nunderstand how to run Rails applications backed by SQLite performantly and\nresiliently. In that time, I have learned various lessons that I want to share\nwith you all now. I want to walk through where the problems lie, why they\nexist, and how to resolve them.\n\nAnd to start, we have to start with the reality that...\n\nUnfortunately, running SQLite on Rails out-of-the-box isn\u2019t viable today. But,\nwith a bit of tweaking and fine-tuning, you can ship a very performant,\nresilient Rails application with SQLite. And my personal goal for Rails 8 is\nto make the out-of-the-box experience fully production-ready.\n\nAnd so, I have spent the last year digging into the details to uncover what\nthe issues are with SQLite on Rails applications as they exist today and how\nto resolve those issues. So, let me show you everything you need to build a\nproduction-ready SQLite-driven Rails application today...\n\n... Yeah, not too bad, huh? These three commands will set your app up for\nproduction success. You will get massive performance improvements, additional\nSQL features, and point-in-time backups. This is how you build a production-\nready SQLite on Rails application today.\n\n... And that\u2019s all you need. Thank you. And I could genuinely stop the talk\nhere. You know how and why to run SQLite in production with Rails. Those two\ngems truly are the headline, and if you take-away only 1 thing from this talk,\nlet it be that slide.\n\nBut, given that this is a space for diving deep into complex topics, I want to\nwalk through the exact problems and solutions that these gems package up.\n\nTo keep this journey practical and concrete, we will be working on a demo app\ncalled \u201cLorem News\u201d. It is a basic Hacker News clone with posts and comments\nmade by users but all of the content is Lorem Ipsum. This codebase will be the\nfoundation for all of our examples and benchmarks.\n\nLet\u2019s observe how our demo application performs. We can use the oha load\ntesting CLI and the benchmarking routes built into the app to simulate user\nactivity in our app. Let\u2019s start with a simple test where we sent 1 request\nafter another for 5 seconds to our post#create endpoint.\n\nNot bad. We see solid RPS and every request is successful. The slowest request\nis many times slower than the average, which isn\u2019t great, but even that\nrequest isn\u2019t above 1 second. I\u2019ve certainly seen worse. Maybe I was wrong to\nsay that the out-of-the-box experience with Rails and SQLite isn\u2019t production-\nready as of today.\n\nLet\u2019s try the same load test but send 4 concurrent requests in waves for 5\nseconds.\n\nAll of a sudden things aren\u2019t looking as good any more. We see a percentage of\nour requests are returning 500 error code responses.\n\nIf we look at our logs, we will see the first major problem that SQLite on\nRails applications need to tackle ...\n\n... the SQLITE_BUSY exception.\n\nIn order to ensure only one write operation occurs at a time, SQLite uses a\nwrite lock on the database. Only one connection can hold the write lock at a\ntime. If you have multiple connections open to the database, this is the\nexception that is thrown when one connection attempts to acquire the write\nlock but another connection still holds it. Without any configuration, a web\napp with a connection pool to a SQLite database will have numerous errors in\ntrying to respond to requests.\n\nAs your Rails application is put under more and more concurrent load, you will\nsee a steady increase in the percentage of requests that error with the\nSQLITE_BUSY exception. What we need is a way to allow write queries to queue\nup and resolve linearly without immediately throwing an exception.\n\nEnter immediate transactions. Because of the global write lock, SQLite needs\ndifferent transaction modes for different possible behaviors.\n\nLet\u2019s consider this transaction.\n\nBy default, SQLite uses a deferred transaction mode. This means that SQLite\nwill not acquire the lock until a write operation is made inside the\ntransaction. For this transaction, this means that the write lock won\u2019t\nattempt to be acquired until ...\n\n... this line here, the third operation within the transaction.\n\nIn a context where you only have one connection or you have a large amount of\ntransactions that only do read operations, this is great for performance,\nbecause it means that SQLite doesn\u2019t have to acquire a lock on the database\nfor every transaction, only for transactions that actually write to the\ndatabase. The problem is that this is not the context Rails apps are in.\n\nIn a production Rails application, not only will you have multiple connections\nto the database from multiple threads, Rails will only wrap database queries\nthat write to the database in a transaction. And, when we write our own\nexplicit transactions, it is essentially a guarantee that we will include a\nwrite operation. So, in a production Rails application, SQLite will be working\nwith multiple connections and every transaction will include a write\noperation. This is the opposite of the context that SQLite\u2019s default deferred\ntransaction mode is optimized for.\n\nOur SQLITE_BUSY exceptions are arising from the fact that when SQLite attempts\nto acquire the write lock in the middle of a transaction and there is another\nconnection holding the lock, SQLite cannot safely retry that transaction-bound\nquery. Retrying in the middle of a transaction could break the serializable\nisolation that SQLite guarantees. Thus, when SQLite hits a busy exception when\ntrying to upgrade a transaction, it can\u2019t queue that query to retry acquiring\nthe write lock later; it immediately throws the error and halts that\ntransaction.\n\nIf we instead begin the transaction by explicitly declaring this an immediate\ntransaction, SQLite will be able to queue this query to retry acquiring the\nwrite lock again later. This gives SQLite the ability to serialize the\nconcurrent queries coming in by relying on a basic queuing system, even when\nsome of those queries are wrapped in transactions.\n\nSo, how do we ensure that our Rails application makes all transactions\nimmediate? ...\n\n... As of version 1.6.9, the sqlite3-ruby gem allows you to configure the\ndefault transaction mode. Since Rails passes any top-level keys in your\ndatabase.yml configuration directly to the sqlite3-ruby database initializer,\nyou can easily ensure that Rails\u2019 SQLite transactions are all run in IMMEDIATE\nmode.\n\nLet\u2019s make this change in our demo app and re-run our simple load test.\n\nWith one simple configuration change, our Rails app now handle concurrent load\nwithout throwing nearly any 500 errors! Though we do see some errors start to\ncreep in at 16 concurrent requests. This is a signal that something is still\namiss.\n\nIf we look now at the latency results from our load tests, we will see that\nthis new problem quickly jumps out.\n\nAs the number of concurrent requests approaches and then surpasses the number\nof Puma workers our application has, our p99 latency skyrockets. But,\ninterestingly, the actual request time stays stable, even under 3 times the\nconcurrent load of our Puma workers. We will also see that once we start\ngetting some requests taking approximately 5 seconds, we also start getting\nsome 500 SQLITE_BUSY responses as well.\n\nIf that 5 seconds is ringing a bell, it is because that is precisely what our\ntimeout is set to. It seems that as our application is put under more\nconcurrent load than the number of Puma workers it has, more and more database\nqueries are timing out. This is our next problem to solve.\n\nThis timeout option in our database.yml configuration file will be mapped to\none of SQLite\u2019s configuration pragmas...\n\nSQLite\u2019s busy_timeout configuration option. Instead of throwing the BUSY\nexception immediately, you can tell SQLite to wait up to the timeout number of\nmilliseconds. SQLite will attempt to re-acquire the write lock using a kind of\nexponential backoff, and if it cannot acquire the write lock within the\ntimeout window, then and only then will the BUSY exception be thrown. This\nallows a web application to use a connection pool, with multiple connections\nopen to the database, but not need to resolve the order of write operations\nitself. You can simply push queries to SQLite and allow SQLite to determine\nthe linear order that write operations will occur in. The process will look\nsomething like this:\n\nImagine our application sends 4 write queries to the database at the same\nmoment.\n\nOne of those four will acquire the write lock first and run. The other three\nwill be queued, running the backoff re-acquire logic. Once the first write\nquery completes, ...\n\n... one of the queued queries will attempt to re-acquire the lock and\nsuccessfully acquire the lock and start running. The other two queries will\ncontinue to stay queued and keep running the backoff re-acquire logic. Again,\nwhen the second write query completes, ...\n\n... another query will have its backoff re-acquire logic succeed and will\nstart running. Our last query is still queued and still running its backoff\nre-acquire logic.\n\nOnce the third query completes, our final query can acquire the write lock and\nrun. So long as no query is forced to wait for longer than the timeout\nduration, SQLite will resolve the linear order of write operations on its own.\nThis queuing mechanism is essential to avoiding SQLITE_BUSY exceptions. But,\nthere is a major performance bottleneck lurking in the details of this feature\nfor Rails applications.\n\nBecause SQLite is embedded within your Ruby process and the thread that spawns\nit, care must be taken to release Ruby\u2019s global VM lock (GVL) when the Ruby-\nto-SQLite bindings execute SQLite\u2019s C code. By design, the sqlite3-ruby gem\ndoes not release the GVL when calling SQLite. For the most part, this is a\nreasonable decision, but for the busy_timeout, it greatly hampers throughput.\n\nInstead of allowing another Puma worker to acquire Ruby\u2019s GVL while one Puma\nworker is waiting for the database query to return, that first Puma worker\nwill continue to hold the GVL even while the Ruby operations are completely\nidle waiting for the database query to resolve and run. This means that\nconcurrent Puma workers won\u2019t even be able to send concurrent write queries to\nthe SQLite database and SQLite\u2019s linear writes will force our Rails app to\nprocess web requests somewhat linearly as well. This radically slows down the\nthroughput of our Rails app.\n\nWhat we want is to allow our Puma workers to be able to process requests\nconcurrently, passing the GVL amongst themselves as they wait on I/O. So, for\nRails app using SQLite, this means that we need to unlock the GVL whenever a\nwrite query gets queued and is waiting to acquire the SQLite write lock.\n\nLuckily, in addition to the busy_timeout, SQLite also provides the lower-level\nbusy_handler hook. The busy_timeout is nothing more than a specific\nbusy_handler implementation provided by SQLite. Any application using SQLite\ncan provide its own custom busy_handler. The sqlite3-ruby gem is a SQLite\ndriver, meaning that it provides Ruby bindings for the C API that SQLite\nexposes. Since it provides a binding for the sqlite3_busy_handler C function,\nwe can write a Ruby callback that will be called whenever a query is queued.\n\nHere is a Ruby implementation of the logic you will find in SQLite\u2019s C source\nfor its busy_timeout. Every time this callback is called, it is passed the\ncount of the number of times this query has called this callback. That count\nis used to determine how long this query should wait to try again to acquire\nthe write lock and how long it has already waited. By using Ruby\u2019s sleep, we\ncan ensure that the GVL is released while a query is waiting to retry\nacquiring the lock.\n\nBy ensuring that the GVL is released while queries wait to retry acquiring the\nlock, we have massively improved our p99 latency even when under concurrent\nload.\n\nBut, there are still some outliers. If we look instead at the p99.99 latency,\nwe will find another steadily increasing graph.\n\nOur slowest queries get steadily slower the more concurrent load our\napplication is under. This is another growth curve that we would like to\nflatten. But, in order to flatten it, we must understand why it is occurring.\n\nThe issue is that our Ruby re-implementation of SQLite\u2019s busy_timeout logic\npenalizes \u201colder queries\u201d. This is going to kill our long-tail performance, as\nresponses will get naturally segmented into the batch that had \u201cyoung\u201d queries\nand those that had \u201cold\u201d queries, because SQLite will naturally segment\nqueries into such batches. To explain more clearly what I mean, let\u2019s step\nthrough our Ruby busy_timeout logic a couple times.\n\nThe first time a query is queued and calls this timeout callback, the count is\nzero.\n\nAnd since 0 is less than 12, we enter the if block.\n\nWe get the zero-th element in the delays array as our delay, which is 1.\n\nWe then take the first 0 elements of the delays array, which is an empty\narray, and sum those numbers together, which in this case sums to 0. This is\nhow long the query has been delayed for already,\n\nWith our timeout as 5000, 0 + 1 is not greater than 5000, so we fall through\nto the else block.\n\nAnd we sleep for 1 millisecond before this callback is called again.\n\nThe tenth time this query calls this timeout callback, the count is, well, 10.\n\n10 is still less than 12, so we enter the if block.\n\nWe get the tenth element in the delays array as our delay, which is 50.\n\nWe then take the first 10 elements of the delays array, that is the everything\nin the array up to but not including the tenth element, and sum those numbers\ntogether, which in this case sums to 178. This is how long the query has been\ndelayed for already.\n\n50 + 178 is still not greater than 5000, so we fall through to the else block.\n\nAnd now we sleep for 50 milliseconds before this callback is called again.\n\nLet\u2019s consider the 58th time this query calls this timeout callback.\n\n58 is greater than 12, so we fall through to the else block.\n\nOnce we are past the 12th call to this callback, we will always delay 100\nmilliseconds.\n\nIn order to calculate how long this query has already been delayed, we get the\nsum of the entire delays array and add the 100 milliseconds times however many\ntimes beyond 12 the query has retried. In this case, the sum of the entire\ndelays array is 328, 58 minus 12 is 46 and 46 times 100 is 4600. So 4600 plus\n328 is 4928. Up to this point, our query has been delayed for 4928\nmilliseconds.\n\n100 + 4928 is 5028, which is indeed greater than 5000, so we enter the if\nblock.\n\nAnd finally we raise the exception.\n\nI know that stepping through this code might be a bit tedious, but we all need\nto be on the same page understanding how SQLite\u2019s busy_timeout mechanism\nhandles queued queries. When I say it penalizes old queries, I mean that it\nmakes them much more likely to become timed out queries under consistent load.\nTo understand why, let\u2019s go back to our queued queries...\n\nLet\u2019s track how many retries each query makes from our simple example above.\n\nOur three remaining queries have retried once...\n\n... and now the remaining two queries are, at best, on their second retry.\n\nAnd our third query is, again at best, on its third retry. On the third retry,\nthe delay is already 10 milliseconds. Let\u2019s imagine that at this moment a new\nwrite query is sent to the database.\n\nThis new query immediately attempts to acquire the write lock, is denied and\nmakes its zeroth call to the busy_timeout callback. It will be told to wait 1\nmillisecond. Our original query is waiting for 10 milliseconds, so this new\nquery will get to retry again before our older query.\n\nWhile the write lock is still held, our new query is only asked to wait 2\nmilliseconds next.\n\nEven when the count is 2, it is only asked to wait 5 milliseconds. This new\nquery will be allowed to retry to acquire the write lock three times before\nthe original query is allowed to retry once.\n\nThese increasing backoffs greatly penalize older queries, such that any query\nthat has to wait even just 3 retries is now much more likely to never acquire\nthe write lock if there is a steady stream of write queries coming in.\n\nSo, what if instead of incrementally backing off our retries, we simply had\nevery query retry at the same frequency, regardless of age? Doing so would\nalso mean that we could do away with our delays array and re-think our\nbusy_handler function altogether.\n\nAnd that is precisely what we have done in the main branch of the sqlite3-ruby\ngem. Unfortunately, as of today, this feature is not in a tagged release of\nthe gem, but it should be released relatively soon. This Ruby callback\nreleases the GVL while waiting for a connection using the sleep operation and\nalways sleeps 1 millisecond. These 10 lines of code make a massive difference\nin the performance of your SQLite on Rails application.\n\nLet\u2019s re-run our benchmarking scripts and see how our p99.99 latency looks\nnow...\n\nVoila! We have flattened out the curve. There is still a jump with currency\nmore than half the number of Puma workers we have, but after that jump our\nlong-tail latency flatlines at around half a second.\n\nSo, when it comes to performance, there are 4 keys that you need to ensure are\ntrue of your next SQLite on Rails application...\n\nWe have covered the first three, but not the last. The write-ahead-log allows\nSQLite to support multiple concurrent readers. The default rollback journal\nmode only allows for one query at a time, regardless of whether it is a read\nor a write. WAL mode allows for concurrent readers but only one writer at a\ntime.\n\nLuckily, starting with Rails 7.1, Rails applies a better default configuration\nfor your SQLite database. These changes are central to making SQLite work well\nin the context of a web application. If you\u2019d like to learn more about what\neach of these configuration options are, why we use the values we do, and how\nthis specific collection of configuration details improve things, I have a\nblog post that digs into these details.\n\nNow, while this isn\u2019t a requirement, there is a fifth lever we can pull to\nimprove the performance of our application. Since we know that SQLite in WAL\nmode supports multiple concurrent reading connections but only one writing\nconnection at a time, we can recognize that it is possible for the Active\nRecord connection pool to be saturated with writing connections and thus block\nconcurrent reading operations.\n\nIf your connection pool only has 3 connections, and you receive 5 concurrent\nqueries, what happens if the 3 connections get picked up by three write\nqueries?\n\nThe remaining read queries have to wait until one of the write queries\nreleases a connection. Ideally, since we are using SQLite in WAL mode, read\nqueries should never need to wait on write queries. In order to ensure this,\nwe will need to create two distinct connection pools\u2014one for reading operation\nand one for writing operations.\n\nWe can leverage Rails\u2019 support for multiple databases to achieve this result.\nInstead of pointing the reader and writer database configurations to separate\ndatabases, we point them at the same single database, and thus simply create\ntwo distinct and isolated connection pools with distinct connection\nconfigurations.\n\nThe reader connection pool will only consist of readonly connections...\n\nAnd the writer connection pool will only have one connection.\n\nWe can then configure our Active Records models to connect to the appropriate\nconnection pool depending on the role.\n\nWhat we want, conceptually, is for our requests to behave essentially like\nSQLite deferred transactions. Every request should default to using the reader\nconnection pool, but whenever we need to write to the database, we switch to\nusing the writer pool for just that operation. To set that up, we will use\nRails\u2019 automatic role switching feature.\n\nBy putting this code in an initializer, we will force Rails to set the default\ndatabase connection for all web requests to be the reading connection pool. We\nalso tweak the delay configuration since we aren\u2019t actually using separate\ndatabases, only separate connections, we don\u2019t need to ensure that requests\n\u201cread your own writes\u201d with a delay.\n\nWe can then patch the transaction method of the ActiveRecord adapter to force\nit to connection to the writing database.\n\nTaken together, these changes enable our \u201cdeferred requests\u201d utilizing\nisolated connection pools. And when testing against the comment create\nendpoint, we do see a performance improvement when looking at simple requests\nper second.\n\nSo, these are the 5 levels of performance improvement that you should make to\nyour SQLite on Rails application.\n\nBut, you don\u2019t need to walk through all of these enhancements in your Rails\napp. As I said at the beginning, you can simply install the enhanced adapter\ngem.\n\nAnd if you want to use the isolated connection pools, you can simply add this\nconfiguration to your application. This is a newer experimental feature, which\nis why you have to opt into it.\n\nAnd, after all that, we are now done with how to make your SQLite on Rails\napplication performant.\n\nIn the end, I hope that this exploration of the tools, techniques, and\ndefaults for SQLite on Rails applications has shown you how powerful,\nperformant, and flexible this approach is. Rails is legitimately the best web\napplication framework for working with SQLite today. The community\u2019s growing\necosystem of tools and gems is unparalleled. And today is absolutely the right\ntime to start a SQLite on Rails application and explore these things for\nyourself.\n\nI hope that you now feel confident in the hows (and whys) of optimal\nperformance when running SQLite in production with Rails.\n\nThank you.\n\nMore to come.\n\nYou can read it here now, or later with the RSS feed .\n\n\u2190 Back one page \u2191 Back to top\n\n\u2193 Connect with me\n\nEmail Twitter GitHub Mastodon LinkedIn\n\n\u00a9 2015\u20132024 Stephen Margheim\n\n", "frontpage": false}
