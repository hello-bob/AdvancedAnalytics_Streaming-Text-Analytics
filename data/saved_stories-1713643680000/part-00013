{"aid": "40096669", "title": "Trillion-Parameter Sequential Transducers for Generative Recommendations", "url": "https://arxiv.org/abs/2402.17152", "domain": "arxiv.org", "votes": 1, "user": "jonbaer", "posted_at": "2024-04-20 11:55:28", "comments": 0, "source_title": "Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations", "source_text": "[2402.17152] Actions Speak Louder than Words: Trillion-Parameter Sequential\nTransducers for Generative Recommendations\n\nSkip to main content\n\nWe gratefully acknowledge support from the Simons Foundation, member\ninstitutions, and all contributors. Donate\n\n> cs > arXiv:2402.17152\n\n# Computer Science > Machine Learning\n\narXiv:2402.17152 (cs)\n\n[Submitted on 27 Feb 2024 (v1), last revised 18 Apr 2024 (this version, v2)]\n\n# Title:Actions Speak Louder than Words: Trillion-Parameter Sequential\nTransducers for Generative Recommendations\n\nAuthors:Jiaqi Zhai, Lucy Liao, Xing Liu, Yueming Wang, Rui Li, Xuan Cao, Leon\nGao, Zhaojie Gong, Fangda Gu, Michael He, Yinghai Lu, Yu Shi\n\nView a PDF of the paper titled Actions Speak Louder than Words: Trillion-\nParameter Sequential Transducers for Generative Recommendations, by Jiaqi Zhai\nand 11 other authors\n\nView PDF HTML (experimental)\n\n> Abstract:Large-scale recommendation systems are characterized by their\n> reliance on high cardinality, heterogeneous features and the need to handle\n> tens of billions of user actions on a daily basis. Despite being trained on\n> huge volume of data with thousands of features, most Deep Learning\n> Recommendation Models (DLRMs) in industry fail to scale with compute.\n> Inspired by success achieved by Transformers in language and vision domains,\n> we revisit fundamental design choices in recommendation systems. We\n> reformulate recommendation problems as sequential transduction tasks within\n> a generative modeling framework (``Generative Recommenders''), and propose a\n> new architecture, HSTU, designed for high cardinality, non-stationary\n> streaming recommendation data. HSTU outperforms baselines over synthetic and\n> public datasets by up to 65.8\\% in NDCG, and is 5.3x to 15.2x faster than\n> FlashAttention2-based Transformers on 8192 length sequences. HSTU-based\n> Generative Recommenders, with 1.5 trillion parameters, improve metrics in\n> online A/B tests by 12.4\\% and have been deployed on multiple surfaces of a\n> large internet platform with billions of users. More importantly, the model\n> quality of Generative Recommenders empirically scales as a power-law of\n> training compute across three orders of magnitude, up to GPT-3/LLaMa-2\n> scale, which reduces carbon footprint needed for future model developments,\n> and further paves the way for the first foundational models in\n> recommendations.\n\nComments:| 26 pages, 13 figures. this https URL. Full technical report to\nfollow  \n---|---  \nSubjects:| Machine Learning (cs.LG); Information Retrieval (cs.IR)  \nCite as:| arXiv:2402.17152 [cs.LG]  \n(or arXiv:2402.17152v2 [cs.LG] for this version)  \nhttps://doi.org/10.48550/arXiv.2402.17152arXiv-issued DOI via DataCite  \n  \n## Submission history\n\nFrom: Jiaqi Zhai [view email] [v1] Tue, 27 Feb 2024 02:37:37 UTC (1,966 KB)\n[v2] Thu, 18 Apr 2024 03:38:55 UTC (1,768 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Actions Speak Louder than Words: Trillion-\nParameter Sequential Transducers for Generative Recommendations, by Jiaqi Zhai\nand 11 other authors\n\n  * View PDF\n  * HTML (experimental)\n  * TeX Source\n  * Other Formats\n\nview license\n\nCurrent browse context:\n\ncs.LG\n\n< prev | next >\n\nnew | recent | 2402\n\nChange to browse by:\n\ncs cs.IR\n\n### References & Citations\n\n  * NASA ADS\n  * Google Scholar\n  * Semantic Scholar\n\na export BibTeX citation Loading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer (What is the Explorer?)\n\nLitmaps (What is Litmaps?)\n\nscite Smart Citations (What are Smart Citations?)\n\n# Code, Data and Media Associated with this Article\n\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\n\nDagsHub (What is DagsHub?)\n\nGotit.pub (What is GotitPub?)\n\nPapers with Code (What is Papers with Code?)\n\nScienceCast (What is ScienceCast?)\n\n# Demos\n\nReplicate (What is Replicate?)\n\nHugging Face Spaces (What is Spaces?)\n\nTXYZ.AI (What is TXYZ.AI?)\n\n# Recommenders and Search Tools\n\nInfluence Flower (What are Influence Flowers?)\n\nConnected Papers (What is Connected Papers?)\n\nCORE Recommender (What is CORE?)\n\nIArxiv Recommender (What is IArxiv?)\n\n  * Author\n  * Venue\n  * Institution\n  * Topic\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new\narXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and\naccepted our values of openness, community, excellence, and user data privacy.\narXiv is committed to these values and only works with partners that adhere to\nthem.\n\nHave an idea for a project that will add value for arXiv's community? Learn\nmore about arXivLabs.\n\nWhich authors of this paper are endorsers? | Disable MathJax (What is MathJax?)\n\n  * About\n  * Help\n\n  * Contact\n  * Subscribe\n\n  * Copyright\n  * Privacy Policy\n\n  * Web Accessibility Assistance\n  * arXiv Operational Status Get status notifications via email or slack\n\n", "frontpage": false}
