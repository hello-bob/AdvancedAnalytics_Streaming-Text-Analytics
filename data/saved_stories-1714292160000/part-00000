{"aid": "40184677", "title": "C++17 Parallel Algorithms and Hipstdpar", "url": "https://rocm.blogs.amd.com/software-tools-optimization/hipstdpar/README.html", "domain": "amd.com", "votes": 2, "user": "mathiasgredal", "posted_at": "2024-04-27 23:52:48", "comments": 0, "source_title": "C++17 parallel algorithms and HIPSTDPAR \u2014 ROCm Blogs", "source_text": "C++17 parallel algorithms and HIPSTDPAR \u2014 ROCm Blogs\n\nSkip to main content\n\nROCm blogs\n\n## 18 April 2024\n\n  * Alessandro Fanfarillo, Alex Voicu\n  * English\n  * Software tools & optimizations\n  * HPC Compiler Performance C++ Memory\n\n### Recent Posts\n\n  * Table Question-Answering with TaPas\n  * Multimodal (Visual and Language) understanding with LLaVA-NeXT\n  * Application portability with HIP\n  * Unlocking Vision-Text Dual-Encoding: Multi-GPU Training of a CLIP-Like Model\n  * Transforming Words into Motion: A Guide to Video Generation with AMD GPU\n\n### Tags\n\n  * AAC\n  * AI/ML\n  * AMD GPU\n  * ASR\n  * Automatic Mixed Precision\n  * BERT\n  * C++\n  * CIFAR10\n  * Compiler\n  * Computer Vision\n  * DQN\n  * Deep Learning\n  * Deep Q-Network\n  * Fine-tune\n  * GEMM\n  * GPGPU\n  * GPU Programming\n  * GenAI\n  * HPC\n  * Image Classification\n  * Images\n  * Inference\n  * Installation\n  * Julia\n  * Kernel\n  * LLM\n  * Llama\n  * LoRA\n  * MONAI\n  * MPI\n  * Memory\n  * Mixed Precision\n  * Multimodal\n  * NUMA\n  * NeRF\n  * OpenMP\n  * Optimization\n  * PEFT\n  * Performance\n  * Physics\n  * Profiling\n  * PyTorch\n  * QLora\n  * RAG\n  * Reinforcement Learning\n  * ResNet\n  * Scientific computing\n  * Segmentation\n  * Serving\n  * Sparse\n  * Speech to Text\n  * Stable Diffusion\n  * TensorFlow\n  * Triton\n  * Tuning\n  * Video Generation\n  * Videos\n  * Vision-Text\n  * Whisper\n  * custom cpp extension\n  * vLLM\n\n### Categories\n\n  * Applications & models (46)\n  * Software tools & optimizations (12)\n\n### Archives\n\n  * 2024 (45)\n  * 2023 (11)\n  * 2022 (2)\n\nv: latest\n\nDownloads\n\n    HTML\n\nOn GitHub\n\n    View\n    Edit\n\nDocumentation hosted by Read the Docs\n\n# C++17 parallel algorithms and HIPSTDPAR\n\n## Contents\n\n# C++17 parallel algorithms and HIPSTDPAR#\n\nThe C++17 standard added the concept of parallel algorithms to the pre-\nexisting C++ Standard Library. The parallel version of algorithms like\nstd::transform maintain the same signature as the regular serial version,\nexcept for the addition of an extra parameter specifying the execution policy\nto use. This flexibility allows users that are already using the C++ Standard\nLibrary algorithms to take advantage of multi-core architectures by just\nintroducing minimal changes to their code.\n\nStarting with ROCm 6.1, the parallel algorithms seamlessly offload to AMD\naccelerators via HIPSTDPAR, as long as the user is willing to add an extra\ncompiler flag or two.\n\nWhilst the functionality introduced by HIPSTDPAR is available for all AMD GPUs\n(including consumer cards), this blog post focuses on the AMD CDNA2TM and\nCDNA3TM architectures (MI200 and MI300 series cards, respectively) using ROCm\n6.1. As a code example, we focus on the Travelling Salesman Problem (TSP)\nsolver available here.\n\n## The travelling salesman problem#\n\nThe travelling salesman problem tries to answer the following question: \u201cGiven\na list of cities and the distances between each pair of cities, what is the\nshortest possible route that visits each city exactly once and returns to the\norigin city?\u201d. This problem is particularly hard to solve (NP-hard) due to\nexponential complexity; adding an extra city to the list causes an exponential\ngrowth in the number of combinations to check. Solving this problem by just\nenumerating all possible combinations and checking each one of them is\ncomputationally prohibitive for problems with more than 17 or 18 cities. For\nreal world applications, advanced methods are used (cutting planes and branch\nand bound techniques) but for the purposes of this blog we focus on a\nembarrassingly parallel implementation of the brute-force approach.\n\nThe TSP solver we look at relies on the following function to check the\nvarious permutations of cities and pick the one with the lowest cost/distance.\nHere is a detailed implementation that does not make use of any parallelism:\n\n    \n    \n    template<int N> route_cost find_best_route(int const* distances) { return std::transform_reduce( counting_iterator(0), counting_iterator(factorial(N)), route_cost(), [](route_cost x, route_cost y) { return x.cost < y.cost ? x : y; }, [=](int64_t i) { int cost = 0; route_iterator<N> it(i); // first city visited int from = it.first(); // visited all other cities in the chosen route // and compute cost while (!it.done()) { int to = it.next(); cost += distances[to + N*from]; from = to; } // update best_route -> reduction return route_cost(i, cost); }); }\n\nThe std::transform_reduce algorithm performs two operations:\n\n  1. a transformation (equivalent to a map operation) implemented by the lambda function passed as final argument;\n\n  2. a reduction operation, expressed as lambda function as fourth argument.\n\nThe function above runs through all elements from 0 to N!, each of which\nexpresses a particular permutation of all cities, computes the cost of the\nparticular path, and returns an instance of route_cost object that includes\nthe id of the particular path and the cost associated with it. At the end, a\nreduction is performed by comparing the cost of the various paths and\nselecting the one with lowest cost.\n\nOn an AMD Zen4 processor, this serial code takes about 11.52 seconds to\ncompute the best path for a TSP instance involving twelve cities. The same\ncode takes about 156 seconds for a TSP instance involving thirteen cities.\nThis is a normal consequence of the exponential growth of the search space\nimposed by the TSP.\n\n## Execution policies and HIPSTDPAR#\n\nSince each of the N! paths are independent, computing their individual cost is\nan embarrassingly parallel operation. C++17 allows developers to easily\nparallelize the previous code by just passing an execution policy as the first\nargument of the algorithm invocation. The C++17 standard defines three\npossible execution policies:\n\n  * std::execution::sequenced_policy and the corresponding policy object to pass as argument std::execution::seq\n\n  * std::execution::parallel_policy and the corresponding policy object to pass as argument std::execution::par\n\n  * std::execution::parallel_unsequenced_policy and the corresponding policy object to pass as argument std::execution::par_unseq\n\nExecution policies allow the user to convey information to the implementation\nabout the invariants that user code shall enforce / maintain, thus allowing\nthe latter to possibly adopt more favourable / performant execution.\n\n### std::execution::sequenced_policy#\n\nThe sequenced policy constrains the implementation to perform all operations\non the thread that invoked the algorithm, inhibiting possible parallel\nexecution. All operations are indeterminately sequenced within the caller\nthread, which implies subsequent invocations of the same algorithm, within the\nsame thread, can have their operations sequenced differently.\n\n### std::execution::parallel_policy#\n\nThe parallel policy allows the implementation to employ parallel execution.\nOperations may be performed on the thread that invoked the algorithm or on\nthreads created by the standard library implementation. All operations are\nindeterminately sequenced within a thread, for all threads used to perform the\ncomputation described by the algorithm invocation. Furthermore, there are no\nordering guarantees provided for the element access function invocations\nthemselves. Compared to the sequenced policy, additional constraints are\nimposed on the various components used by the algorithm. In particular,\noperations on iterators, values, and callable objects, as well as their\ntransitive closure, must be data race free.\n\nIn the previous example, it is possible to parallelize the find_best_route\nfunction by passing as first extra argument the std::execution:par policy as\nfollows:\n\n    \n    \n    return std::transform_reduce( std::execution::par, // THE SIMPLE CHANGE counting_iterator(0), counting_iterator(factorial(N)), route_cost(), [](route_cost x, route_cost y) { return x.cost < y.cost ? x : y; }, [=](int64_t i)\n\nBy making this simple change, the code will now run on all CPU cores\navailable. On the CPU portion of a MI300A, equipped with 48 Zen4 logical\ncores, solving an instance of TSP with 12 cities takes about 0.34 seconds.\nThis parallel run is almost 34x faster compared to the 11.52 seconds needed by\nthe serial version! For an instance of TSP with thirteen cities the parallel\nversion takes about 5 seconds. Finally, for a bigger problem involving\nfourteen cites, the 48 Zen4 logical cores take about 77 seconds.\n\n### std::execution::parallel_unsequenced_policy#\n\nThis policy guarantees the most restrictive requirements are met by user\nprovided code. An algorithm invoked with this policy may perform the steps in\nunordered and unsequenced ways with respect to one another. This means that\nthe various operations can be interleaved with each other on the same thread.\nAlso any given operation may start on a thread and end on a different thread.\nWhen specifying the parallel unsequenced policy, the user guarantees that no\noperations that entail calling a function that synchronizes-with another\nfunction are employed. In practice, this means that user code does not do any\nmemory allocation / deallocation, only relies on lock-free specializations of\nstd::atomic, and does not rely on synchronization primitives such as\nstd::mutex.\n\nThis policy is currently the only one that can be chosen to offload\nparallelism to AMD accelerators. To trigger the GPU offload of all parallel\nalgorithms invoked with the parallel unsequenced policy, the --hipstdpar flag\nmust be passed at compile time. Furthermore, for GPU targets other than the\ncurrent default (gfx906), the user must also pass --offload-arch= specifying\nwhich GPU is being used.\n\nOn MI300A, by simply switching policy and recompiling with the aforementioned\nflags, the execution time for an instance of TSP with thirteen cities goes\ndown to 0.5 seconds. When using fourteen cities, the use of the GPU portion of\nMI300A brings down the execution time to 4.8 seconds from the 77 seconds\nneeded by the parallel version running on 48 Zen4 logical cores. And because\neverybody loves a good table, let us conclude this section by summarising the\nprogression from sequenced execution on the CPU to parallel unsequenced\nexecution offloaded to the accelerator:\n\n14-city TSP| Timing (s)  \n---|---  \nseq| 2337  \npar| 77  \npar_unseq on CPU| 75  \npar_unseq on GPU| 4.8  \n  \n## TeaLeaf#\n\nA more complex example showing the use and performance of HIPSTDPAR is\nTeaLeaf. The code is a C++ implementation of the TeaLeaf heat conduction mini-\napp from the University of Bristol, UK. Multiple implementations illustrate\nvarious parallel programming paradigms, including HIP and parallelised\nstandard algorithms. This allows us to make a fair performance comparison\nbetween an optimized, HIP-based implementation and a HIPSTDPAR one. For the\npurpose of this test, we selected the tea_bm_5.in benchmark, comprising of a\n2D grid of 4000x4000 cells and 10 time steps.\n\nFor the HIPSTDPAR version, on a MI300A card, the following output is obtained:\n\n    \n    \n    Timestep 10 CG: 3679 iterations Wallclock: 40.884s Avg. time per cell: 2.555271e-06 Error: 9.805532e-31 Checking results... Expected 9.546235158221428e+01 Actual 9.546235158231138e+01 This run PASSED (Difference is within 0.00000000%)\n\nAs for the HIP version, it performs as follows:\n\n    \n    \n    Timestep 10 CG: 3679 iterations Wallclock: 34.286s Avg. time per cell: 2.142853e-06 Error: 9.962546e-31 Checking results... Expected 9.546235158221428e+01 Actual 9.546235158231144e+01 This run PASSED (Difference is within 0.00000000%)\n\nThe performance difference in-between the two versions stems from the overhead\nassociated with handling the initial page-in of non-resident memory. To \u201ceven\nthings out\u201d, the HIP version can be adjusted to use hipMallocManaged() as\nwell, instead of hipMalloc(). This particular configuration is already\navailable in the HIP version of TeaLeaf and it can be enabled by passing a\nsimple flag at compile time. The following is the output for the HIP version\nof TeaLeaf when using hipMallocManaged() and XNACK for all GPU allocations.\n\n    \n    \n    Timestep 10 CG: 3679 iterations Wallclock: 39.573s Avg. time per cell: 2.473331e-06 Error: 9.962546e-31 Checking results... Expected 9.546235158221428e+01 Actual 9.546235158231144e+01 This run PASSED (Difference is within 0.00000000%)\n\nAs expected, the performance of the HIP version when introducing\nhipMallocManaged() is comparable with the one observed for the HIPSTDPAR\nversion. In closing, we will note that ongoing work is expected to reduce the\noverhead, thus bringing the offloaded version closer to the HIP one.\n\n## Nuts and bolts of HIPSTDPAR#\n\nThe ability to offload C++ Standard Parallel algorithm execution to the GPU\nrelies on the interaction between the LLVM compiler, HIPSTDPAR, and rocThrust.\nStarting from ROCm 6.1, the LLVM compiler used to compile regular HIP codes\nwill be able to forward invocations of standard algorithms which take the\nparallel_unsequenced_policy execution policy to the HIPSTDPAR header-only\nlibrary when the --hipstdpar flag is passed. The header-only library is in\ncharge of mapping the parallel algorithms used by C++ Standard Library into\nthe equivalent rocThrust algorithm invocation. This very simple design allows\nfor a low overhead implementation of the offloading for parallel standard\nalgorithms. A natural question to ask at this point is: \u201ccomputation is nice\nbut what about the memory it operates on?\u201d. By default, HIPSTDPAR assumes that\nthe underlying system is HMM (Heterogeneous Memory Management)-enabled, and\nthat page migration is possible via the handling of retry-able page-faults\nimplemented atop XNACK (e.g., export HSA_XNACK=1). This particular mode is\nreferred to as HMM Mode.\n\nWhen these two requirements are satisfied, code offloaded to the GPU\n(implemented via rocThrust) triggers the page migration mechanism and data\nwill automatically migrate from host to device. On MI300A, although physical\nmigration is neither needed nor useful, handling page faults via XNACK is\nstill necessary. For more details about page migration please refer to the\nfollowing blog post.\n\nOn systems without HMM / XNACK we can still use HIPSTDPAR by passing an extra\ncompilation flag: --hipstdpar-interpose-alloc. This flag will instruct the\ncompiler to replace all dynamic memory allocations with compatible\nhipManagedMemory allocations implemented in the HIPSTDPAR header-only library.\nFor example, if the application being compiled, or one of its transitive\ninclusions, allocates free store memory via operator new, that call will be\nreplaced with a call to __hipstdpar_operator_new. By looking at the\nimplementation of that function in the HIPSTDPAR library we see that the\nactual allocation is performed via the hipMallocManaged() function. By doing\nso on a non HMM-enabled system, host memory is pinned and directly accessible\nby the GPU without requiring any page-fault driven migration to the GPU\nmemory. This particular mode is referred to as Interposition Mode.\n\n### Restrictions#\n\nFor both HMM and Interposition modes, the following restrictions apply:\n\n  1. Pointers to function, and all associated features, such as e.g. dynamic polymorphism, cannot be used (directly or transitively) by the user provided callable passed to an algorithm invocation;\n\n  2. Global / namespace scope / static / thread storage duration variables cannot be used (directly or transitively) in name by the user provided callable;\n\n     * When executing in HMM Mode they can be used in address e.g.:\n        \n                namespace { int foo = 42; } bool never(const vector<int>& v) { return any_of(execution::par_unseq, cbegin(v), cend(v), [](auto&& x) { return x == foo; }); } bool only_in_hmm_mode(const vector<int>& v) { return any_of(execution::par_unseq, cbegin(v), cend(v), [p = &foo](auto&& x) { return x == *p; }); }\n\n  3. Only algorithms that are invoked with the parallel_unsequenced_policy are candidates for offload;\n\n  4. Only algorithms that are invoked with iterator arguments that model random_access_iterator are candidates for offload;\n\n  5. Exceptions cannot be used by the user provided callable;\n\n  6. Dynamic memory allocation (e.g. operator new) cannot be used by the user provided callable;\n\n  7. Selective offload is not possible i.e. it is not possible to indicate that only some algorithms invoked with the parallel_unsequenced_policy are to be executed on the accelerator.\n\nIn addition to the above, using Interposition Mode imposes the following\nadditional restrictions:\n\n  1. All code that is expected to interoperate has to be recompiled with the --hipstdpar-interpose-alloc flag i.e. it is not safe to compose libraries that have been independently compiled;\n\n  2. automatic storage duration (i.e. stack allocated) variables cannot be used (directly or transitively) by the user provided callable e.g.\n    \n        bool never(const vector<int>& v, int n) { return any_of(execution::par_unseq, cbegin(v), cend(v), [p = &n](auto&& x) { return x == *p; }); }\n\n## But why?#\n\nAfter what has been something of a whirlwind tour, it is not unreasonable to\nask \u201cbut how does this benefit me, the C++ developer?\u201d. The goal of HIPSTDPAR\nis to allow any C++ developer that is employing standard algorithms to\nleverage GPU acceleration with no cognitive overload. The application\ndeveloper can remain firmly planted in the Standard C++ world, without having\nto step into the brave new world of GPU specific languages such as e.g. HIP or\nSYCL. Fortunately for us, our particular example allows for some limited,\nquantitative insight into just how close we got to this goal. The Tealeaf\nauthor has implemented the solver via multiple programming interfaces which\nmeans that we can use the cloc tool to count the lines of code needed by the\ntsp.cpp implementation:\n\nProgramming Interface| LoC  \n---|---  \nKokkos| 145  \nOpenACC| 142  \nOpenMP| 116  \nStandard C++ Serial| 112  \nStandard C++ Parallel Algorithms| 107  \nSYCL| 169  \n  \nIt is apparent that using compiler flag driven offload, as enabled by\nHIPSTDPAR, saves on a considerable amount or typing - up to 57% versus SYCL,\nfor example. This enables a more natural journey towards GPU accelerated\nexecution. As a result, the programmer can focus on the algorithm / problem\nsolving, at least initially, and discover generic algorithmic optimisations\nthat are profitable for the GPU, without having to dive head-first into GPU\n\u201carcana\u201d.\n\n## TL;DR, just tell me how to go fast#\n\nInitially, HIPSTDPAR is officially supported on Linux, with Windows support\nforthcoming at a future date. Starting from an environment that has been set\nup for ROCm, using the package manager to install the hipstdpar package will,\nin general, bring in all the required goodness. Additionally, at the time of\nwriting, a dependency on TBB exists, as a consequence of standard library\nimplementation details (see e.g. Note 3). Therefore, it is necessary to\ninstall the system\u2019s TBB package (e.g. libtbb-dev on Ubuntu). Armed thusly,\nand assuming that we have a main.cpp file which uses some standard algorithms\nto solve a given problem, the compiler driver invocation:\n\n    \n    \n    clang++ --hipstdpar main.cpp -o main\n\ntransparently offloads all algorithm invocations that use the\nstd::execution::parallel_unsequenced_policy execution policy, if we are\ntargeting a GPU compatible with the gfx906 ISA (i.e. Vega20). Otherwise, we\nalso have to specify the target for offload:\n\n    \n    \n    clang++ --hipstdpar --offload-arch=gfx90a main.cpp -o main\n\n## Conclusion#\n\nIn this post, we provided a high level overview of the ROCm support for\noffloading C++ Standard Parallel Algorithms, aiming to show how existing C++\ndevelopers can leverage GPU acceleration without having to adopt any new, GPU\nspecific, language (e.g., HIP) or directives (e.g., OpenMP).\n\nWe believe that this standard, extremely accessible, way of exploiting\nhardware parallelism will be particularly beneficial for applications\ntargeting MI300A accelerators, where the CPU and the GPU share the same pool\nof HBM. Although not demonstrated today, the combination of the APU\narchitecture and HIPSTDPAR can enable fine-grained cooperation between CPU and\nGPU, which become true peers, accessible via a uniform programming interface.\n\nFor an in-depth look at the compiler side of HIPSTDPAR support, the interested\nreader should peruse the associated AMD-LLVM documentation.\n\nThe authors would like to thank Bob Robey and Justin Chang for their helpful\nreviews. If you have any questions please reach out to us on GitHub\nDiscussions.\n\nInferencing with AI2\u2019s OLMo model on AMD GPU Transforming Words into Motion: A\nGuide to Video Generation with AMD GPU\n\nContents\n\n  * Terms and Conditions\n  * Privacy\n  * Trademarks\n  * Statement on Forced Labor\n  * Fair and Open Competition\n  * UK Tax Strategy\n  * Cookie Policy\n  * Cookies Settings\n\n\u00a9 2023 Advanced Micro Devices, Inc\n\nThis site uses cookies from us and our partners to make your browsing\nexperience more efficient, relevant, convenient and personal. In some cases,\nthey are essential to making the site work properly. Using the buttons below,\nyou can accept cookies, refuse cookies, or change your settings at any time by\nclicking on the Cookie Settings link. For more information, refer to AMD's\nprivacy policy and cookie policy.\n\n## Cookie Settings\n\nWhen you visit any website, it may store or retrieve information on your\nbrowser, mostly in the form of cookies. This information might be about you,\nyour preferences or your device and is mostly used to make the site work as\nyou expect it to. The information does not usually directly identify you, but\nit can give you a more personalized web experience. Because we respect your\nright to privacy, you can choose not to allow some types of cookies. Click on\nthe different category headings to find out more and change our default\nsettings. However, blocking some types of cookies may impact your experience\nof the site and the services we are able to offer. More information\n\n### Manage Consent Preferences\n\n#### Performance Cookies\n\nThese cookies allow us to recognize and count the number of visitors and to\nsee how visitors move around the Sites when they use them. This helps us to\nunderstand what areas of the Sites are of interest to you and to improve the\nway the Sites work, for example, by helping you find what you are looking for\neasily. We may use third party web analytics providers to help us analyze the\nuse of the Sites, email, and newsletters. These cookies store data such as\nonline identifiers (including IP address and device identifiers), information\nabout your web browser and operating system, website usage activity\ninformation (including the frequency of your visits, your actions on the Sites\nand, if you arrived at any of the Sites from another website, i.e. the URL of\nthat website), and content-related activity (including the email and\nnewsletter content you view and click on).\n\n#### Targeting Cookies\n\nThese cookies record online identifiers (including IP address and device\nidentifiers), information about your web browser and operating system, website\nusage activity information (such as information about your visit to the Sites,\nthe pages you have visited, content you have viewed, and the links you have\nfollowed), and content-related activity (including the email and newsletter\ncontent you view and click on). The information is used to try to make the\nSites, emails, and newsletters, and the advertising displayed on them and\nother websites more relevant to your interests. For instance, when you visit\nthe Sites, these targeting cookies are used by third party providers for\nremarketing purposes to allow them to show you advertisements for our products\nwhen you visit other websites on the internet. Our third party providers may\ncollect and combine information collected through the Sites, emails, and\nnewsletters with other information about your visits to other websites and\napps over time, if those websites and apps also use the same providers.\n\n#### Functionality Cookies\n\nThese cookies are used to recognize you when you return to the Sites. This\nenables us to remember your preferences (for example, your choice of language\nor region) or when you register on areas of the Sites, such as our web\nprograms or extranets. These cookies store data such as online identifiers\n(including IP address and device identifiers) along with the information used\nto provide the function.\n\n#### Strictly Necessary Cookies\n\nAlways Active\n\nThese are cookies that are technically required for the operation of the\nSites. They are usually only set in response to actions made by you which\namount to a request for services, such as setting your privacy preferences,\nlogging into secure areas of the Sites or filling in forms. These cookies\nstore data such as online identifiers (including IP address and device\nidentifiers) along with the information used to operate the Sites. We may\nestimate your geographic location based on your IP address to help us display\nthe content available in your location and adjust the operation of the Sites.\n\n### Cookie List\n\nlabel\n\nConsent Leg.Interest\n\nlabel\n\nlabel\n\nlabel\n\n", "frontpage": false}
