{"aid": "40169348", "title": "Nightly Postgres Backups via GitHub Actions", "url": "https://joshstrange.com/2024/04/26/nightly-postgres-backups-via-github-actions/", "domain": "joshstrange.com", "votes": 1, "user": "joshstrange", "posted_at": "2024-04-26 13:47:06", "comments": 0, "source_title": "Nightly Postgres Backups via GitHub Actions", "source_text": "Nightly Postgres Backups via GitHub Actions \u2013 Josh Strange\n\nSkip to content\n\nJosh Strange\n\n  * Mastodon\n  * Mail\n\n# Nightly Postgres Backups via GitHub Actions\n\nApr 26, 2024\n\nRecently I wanted to set up nightly backups of my Postgres databases hosted on\nNeon.tech. Yes, they have backups and PITR but I knew I\u2019d feel better if I had\nbackups just in case. My business runs on AWS and so S3 was the obvious\ndestination. I took this as an opportunity to look into what Amazon wants you\nto use for authenticating instead of having to click the shameful \u201cOther\u201d\nbutton (aka \u201cPlease just give my access id and secret that I\u2019ve been using for\nover a decade\u201d).\n\nAWS appears to discourage the continued use of this method.\n\nNOTE: Before I get started I want to say I\u2019m sure nothing is this blog post is\nnew or groundbreaking. I just wanted to document how I solved it in case it\nhelps someone in the future.\n\n## AWS Setup\n\nFirst you\u2019ll need to create an S3 Bucket, this is incredibly straightforward\nand I left all the defaults as-is except I turned on versioning. I don\u2019t plan\nto ever upload a file to an existing key but there isn\u2019t a way to easily\nrestrict to add-only (no overwrite) so I figure versions are a safe thing to\nturn on that might save me one day. Hopefully they are never needed.\n\nOnce you have your S3 bucket let\u2019s go over to the \u201cManagement\u201d tab and click\non \u201cCreate lifecycle rule\u201d. This isn\u2019t strictly necessary but I wanted to move\nolder backups to cheaper S3 storage after a certain amount of time.\n\nHere is the rule that I created. I wanted files to move to IA after 30 days\nand Glacier Instant Retrieval after 60. Also I moved any noncurrent versions\nto Glacier Instant Retrieval after 30 days.\n\nOnce that\u2019s done head over to IAM to add an Identity Provider. This is so that\nGitHub can assume the role without having to add in any access key/secret to\nyour GitHub Actions Secrets. Go to \u201cIdentity Providers\u201d then click \u201cAdd\nprovider\u201d and fill in the following:\n\n  * Select \u201cOpenID Connect\u201d\n  * Provider Url: https://token.actions.githubusercontent.com\n  * Audience: sts.amazonaws.com\n\nNow that we have that configured we are going to create a new role with a\n\u201cCustom trust policy\u201d. Edit the one below to match your account and GitHub\nuser/repo.\n\n    \n    \n    { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Federated\": \"arn:aws:iam::YOUR_AWS_ACCOUNT_ID:oidc-provider/token.actions.githubusercontent.com\" }, \"Action\": \"sts:AssumeRoleWithWebIdentity\", \"Condition\": { \"StringEquals\": { \"token.actions.githubusercontent.com:aud\": \"sts.amazonaws.com\", \"token.actions.githubusercontent.com:sub\": \"repo:USERNAME/REPO_NAME:ref:refs/heads/main\" } } } ] }\n\nOnce the role is created you\u2019ll want to attach an inline policy, here is the\none I used:\n\n    \n    \n    { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"s3:GetObject\", \"s3:PutObject\", \"s3:AbortMultipartUpload\", \"s3:ListMultipartUploadParts\", \"s3:ListBucket\", \"s3:ListBucketMultipartUploads\", \"s3:ListMultiRegionAccessPoints\" ], \"Resource\": [ \"arn:aws:s3:::YOUR_S3_BUCKET/*\", \"arn:aws:s3:::YOUR_S3_BUCKET/\" ] } ] }\n\nNow that you have your role and identity provider in place we can move on to\nGitHub.\n\n## GitHub Setup\n\nOnce all your AWS stuff is done we can setup our GitHub workflow. Copy the\nfollowing file into the root of your repo at .github/workflows/backup.yml\n\n    \n    \n    name: Database Backup and Upload on: schedule: - cron: '33 8 * * *' # Run at 8:33am UTC every day (Will be the middle of the night in the US) workflow_dispatch: # Allows manual triggering from GitHub UI permissions: id-token: write contents: read jobs: backup-and-upload: runs-on: ubuntu-latest strategy: matrix: include: - prefix: PREFIX_1 # I had multiple databases I wanted backed up and each had a secret like: - prefix: PREFIX_2 # \"PREFIX_2_BACKUP_DB_CONNECTION\". If you only have 1 DB you don't need this steps: - name: Checkout code uses: actions/checkout@v3 - name: Install PostgreSQL client run: | sudo apt install -y postgresql-common yes '' | sudo /usr/share/postgresql-common/pgdg/apt.postgresql.org.sh sudo apt-get install -y postgresql-client-16 - name: Set Timestamp run: echo \"TIMESTAMP=$(date -u +'%Y-%m-%d-%H-%M-%S')\" >> $GITHUB_ENV - name: Dump database run: | /usr/lib/postgresql/16/bin/pg_dump ${{ secrets[format('{0}_BACKUP_DB_CONNECTION', matrix.prefix)] }} | gzip > \"${TIMESTAMP}.sql.gz\" - name: Configure AWS credentials from Action OIDC uses: aws-actions/configure-aws-credentials@v1 with: aws-region: us-east-1 role-to-assume: arn:aws:iam::AWS_ACCOUNT_ID:role/ROLE_YOU_CREATED_ABOVE role-session-name: GitHubActionSession - name: Upload backup to S3 run: | YEAR_MONTH=$(date -u +\"%Y/%m\") aws s3 cp \"${TIMESTAMP}.sql.gz\" s3://YOUR_S3_BUCKET_NAME/${{ matrix.prefix }}/database/${YEAR_MONTH}/\n\nThis will run at 8:33am UTC every day and backup each of my databases to S3 in\na folder named after the \u201cprefix\u201d. As I explain above, I have a secret per DB\nand the prefix is used to build the secret name here:\n\n1| ${{ secrets[format('{0}_BACKUP_DB_CONNECTION', matrix.prefix)] }}  \n---|---  \n  \nIf you just have 1 database you can hardcode the secret there and remove all\nthe prefix/matrix logic and pass your secret connection string to pg_dump\ndirectly. Just a note, you cannot use a secret value as a matrix value, it\nwill throw an error. My way around this was just specify my \u201cprefix\u201d and then\nbuild the secret name later.\n\nWhy \u201c8:33\u201d? Well GitHub says that Action schedules might be delayed if there\nare a lot of jobs running at that time so choosing to run \u201con the hour\u201d is\nprobably a contentious time, you could pick any time or have it run on the\nhour and deal with delays.\n\n### That\u2019s it!\n\nLike I said at the top, this isn\u2019t rocket science or anything that hasn\u2019t been\ndone before, I just wanted to document how I accomplished it. I hope you found\nit useful!\n\n### Share this:\n\n  * Mastodon\n  * Email\n  * Reddit\n  * Twitter\n  * Facebook\n\nLike Loading...\n\nAWS Github Github Actions Neon.tech Postgres\n\nJosh Strange\n\nMy Personal Blog\n\n## Social\n\nBlog at WordPress.com.\n\nLoading Comments...\n\n  * Reblog\n  * Subscribe Subscribed\n\n    * Josh Strange\n    * Already have a WordPress.com account? Log in now.\n\n  * Privacy\n  *     * Josh Strange\n    * Edit Site\n    * Subscribe Subscribed\n    * Sign up\n    * Log in\n    * Copy shortlink\n    * Report this content\n    * View post in Reader\n    * Manage subscriptions\n    * Collapse this bar\n\n%d\n\n", "frontpage": false}
