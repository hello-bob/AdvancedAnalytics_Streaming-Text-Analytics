{"aid": "40081314", "title": "The Rust Calling Convention We Deserve", "url": "https://mcyoung.xyz/2024/04/17/calling-convention/", "domain": "mcyoung.xyz", "votes": 28, "user": "matt_d", "posted_at": "2024-04-18 22:13:13", "comments": 0, "source_title": "The Rust Calling Convention We Deserve \u00b7 mcyoung", "source_text": "The Rust Calling Convention We Deserve \u00b7 mcyoung\n\n# mcyoung\n\nI'm Miguel. I write about compilers, performance, and silly computer things. I\nalso draw Pok\u00e9mon.\n\nCC BY-SA \u2022 Site Analytics \u00a9 2024 Miguel Young de la Sota\n\n2024-04-17 \u2022 3689 words \u2022 20 minutes \u2022 #dark-arts \u2022 #assembly \u2022 #rust\n\n# The Rust Calling Convention We Deserve\n\nI will often say that the so-called \u201cC ABI\u201d is a very bad one, and a\nrelatively unimaginative one when it comes to passing complicated types\neffectively. A lot of people ask me \u201cok, what would you use instead\u201d, and I\njust point them to the Go register ABI, but it seems most people have trouble\nfilling in the gaps of what I mean. This article explains what I mean in\ndetail.\n\nI have discussed calling conventions in the past, but as a reminder: the\ncalling convention is the part of the ABI that concerns itself with how to\npass arguments to and from a function, and how to actually call a function.\nThis includes which registers arguments go in, which registers values are\nreturned out of, what function prologues/epilogues look like, how unwinding\nworks, etc.\n\nThis particular post is primarily about x86, but I intend to be reasonably\ngeneric (so that what I\u2019ve written applies just as well to ARM, RISC-V, etc).\nI will assume a general familiarity with x86 assembly, LLVM IR, and Rust (but\nnot rustc\u2019s internals).\n\n## The Problem\n\nToday, like many other natively compiled languages, Rust defines an\nunspecified0- calling convention that lets it call functions however it likes.\nIn practice, Rust lowers to LLVM\u2019s built-in C calling convention, which LLVM\u2019s\nprologue/epilogue codegen generates calls for.\n\nRust is fairly conservative: it tries to generate LLVM function signatures\nthat Clang could have plausibly generated. This has two significant benefits:\n\n  1. Good probability debuggers won\u2019t choke on it. This is not a concern on Linux, though, because DWARF is very general and does not bake-in the Linux C ABI. We will concern ourselves only with ELF-based systems and assume that debuggability is a nonissue.\n\n  2. It is less likely to tickle LLVM bugs due to using ABI codegen that Clang does not exercise. I think that if Rust tickles LLVM bugs, we should actually fix them (a very small number of rustc contributors do in fact do this).\n\nHowever, we are too conservative. We get terrible codegen for simple\nfunctions:\n\n    \n    \n    fn extract(arr: [i32; 3]) -> i32 { arr[1] }\n\nRust\n\n    \n    \n    extract: mov eax, dword ptr [rdi + 4] ret\n\nx86 Assembly\n\narr is 12 bytes wide, so you\u2019d think it would be passed in registers, but no!\nIt is passed by pointer! Rust is actually more conservative than what the\nLinux C ABI mandates, because it actually passes the [i32; 3] in registers\nwhen extern \"C\" is requested.\n\n    \n    \n    extern \"C\" fn extract(arr: [i32; 3]) -> i32 { arr[1] }\n\nRust\n\n    \n    \n    extract: mov rax, rdi shr rax, 32 ret\n\nx86 Assembly\n\nThe array is passed in rdi and rsi, with the i32s packed into registers. The\nfunction moves rdi into rax, the output register, and shifts the upper half\ndown.\n\nNot only does clang produce patently bad code for passing things by value, but\nit also knows how to do it better, if you request a standard calling\nconvention! We could be generating way better code than Clang, but we don\u2019t!\n\nHereforth, I will describe how to do it.\n\n### -Zcallconv\n\nLet\u2019s suppose that we keep the current calling convention for extern \"Rust\"^1,\nbut we add a flag -Zcallconv that sets the calling convention for extern\n\"Rust\" when compiling a crate. The supported values will be -Zcallconv=legacy\nfor the current one, and -Zcallconv=fast for the one we\u2019re going to design. We\ncould even let -O set -Zcallconv=fast automatically.\n\nWhy keep the old calling convention? Although I did sweep debugability under\nthe rug, one nice property -Zcallconv=fast will not have is that it does not\nplace arguments in the C ABI order, which means that a reader replying on the\n\u201cDiana\u2019s silk dress cost $89\u201d mnemonic on x86 will get fairly confused.\n\nI am also assuming we may not even support -Zcallconv=fast for some targets,\nlike WASM, where there is no concept of \u201cregisters\u201d and \u201cspilling\u201d. It may not\neven make sense to enable it for for debug builds, because it will produce\nmuch worse code with optimizations turned off.\n\nThere is also a mild wrinkle with function pointers, and extern \"Rust\" {}\nblocks. Because this flag is per-crate, even though functions can advertise\nwhich version of extern \"Rust\" they use, function pointers have no such\nluxury. However, calling through a function pointer is slow and rare, so we\ncan simply force them to use -Zcallconv=legacy. We can generate a shim to\ntranslate calling conventions as needed.\n\nSimilarly, we can, in principle, call any Rust function like this:\n\n    \n    \n    fn secret_call() -> i32 { extern \"Rust\" { fn my_func() -> i32; } unsafe { my_func() } }\n\nRust\n\nHowever, this mechanism can only be used to call unmangled symbols. Thus, we\ncan simply force #[no_mangle] symbols to use the legacy calling convention.\n\n## Bending LLVM to Our Will\n\nIn an ideal world, LLVM would provide a way for us to specify the calling\nconvention directly. E.g., this argument goes in that register, this return\ngoes in that one, etc. Unfortunately, adding a calling convention to LLVM\nrequires writing a bunch of C++.\n\nHowever, we can get away with specifying our own calling convention by\nfollowing the following procedure.\n\n  1. First, determine, for a given target triple, the maximum number of values that can be passed \u201cby register\u201d. I will explain how to do this below.\n\n  2. Decide how to pass the return value. It will either fit in the output registers, or it will need to be returned \u201cby reference\u201d, in which case we pass an extra ptr argument to the function (tagged with the sret attribute) and the actual return value of the function is that pointer.\n\n  3. Decide which arguments that have been passed by value need to be demoted to being passed by reference. This will be a heuristic, but generally will be approximately \u201carguments larger than the by-register space\u201d. For example, on x86, this comes out to 176 bytes.\n\n  4. Decide which arguments get passed by register, so as to maximize register space usage. This problem is NP-hard (it\u2019s the knapsack problem) so it will require a heuristic. All other arguments are passed on the stack.\n\n  5. Generate the function signature in LLVM IR. This will be all of the arguments that are passed by register encoded as various non-aggregates, such as i64, ptr, double, and <2 x i64>. What valid choices are for said non-aggregates depends on the target, but the above are what you will generally get on a 64-bit architecture. Arguments passed on the stack will follow the \u201cregister inputs\u201d.\n\n  6. Generate a function prologue. This is code to decode each Rust-level argument from the register inputs, so that there are %ssa values corresponding to those that would be present when using -Zcallconv=legacy. This allows us to generate the same code for the body of the function regardless of calling convention. Redundant decoding code will be eliminated by DCE passes.\n\n  7. Generate a function exit block. This is a block that contains a single phi instruction for the return type as it would be for -Zcallconv=legacy. This block will encode it into the requisite output format and then ret as appropriate. All exit paths through the function should br to this block instead of ret-ing.\n\n  8. If a non-polymorphic, non-inline function may have its address taken (as a function pointer), either because it is exported out of the crate or the crate takes a function pointer to it, generate a shim that uses -Zcallconv=legacy and immediately tail-calls the real implementation. This is necessary to preserve function pointer equality.\n\nThe main upshot here is that we need to cook up heuristics for figuring out\nwhat goes in registers (since we allow reordering arguments to get better\nthroughput). This is equivalent to the knapsack problem; knapsack heuristics\nare beyond the scope of this article. This should happen early enough that\nthis information can be stuffed into rmeta to avoid needing to recompute it.\nWe may want to use different, faster heuristics depending on -Copt-level. Note\nthat correctness requires that we forbid linking code generated by multiple\ndifferent Rust compilers, which is already the case, since Rust breaks ABI\nfrom release to release.\n\n### What Is LLVM Willing to Do?\n\nAssuming we do that, how do we actually get LLVM to pass things in the way we\nwant it to? We need to determine what the largest \u201cby register\u201d passing LLVM\nwill permit is. The following LLVM program is useful for determining this on a\nparticular version of LLVM:\n\n    \n    \n    %InputI = type [6 x i64] %InputF = type [0 x double] %InputV = type [8 x <2 x i64>] %OutputI = type [3 x i64] %OutputF = type [0 x double] %OutputV = type [4 x <2 x i64>] define void @inputs({ %InputI, %InputF, %InputV }) { %p = alloca [4096 x i8] store volatile { %InputI, %InputF, %InputV } %0, ptr %p ret void } %Output = { %OutputI, %OutputF, %OutputV } @gOutput = constant %Output zeroinitializer define %Output @outputs() { %1 = load %Output, ptr @gOutput ret %Output %1 }\n\nLLVM IR\n\nWhen you pass an aggregate by-value to an LLVM function, LLVM will attempt to\n\u201cexplode\u201d that aggregate into as many registers as possible. There are\ndistinct register classes on different systems. For example, on both x86 and\nARM, floats and vectors share the same register class (kind of^2).\n\nThe above values are for x86^3. LLVM will pass six integers and eight SSE\nvectors by register, and return half as many (3 and 4) by register. Increasing\nany of the values generates extra loads and stores that indicate LLVM gave up\nand passed arguments on the stack.\n\nThe values for aarch64-unknown-linux are 8 integers and 8 vectors for both\ninputs and outputs, respectively.\n\nThis is the maximum number of registers we get to play with for each class.\nAnything extra gets passed on the stack.\n\nI recommend that every function have the same number of by-register arguments.\nSo on x86, EVERY -Zcallconv=fast function\u2019s signature should look like this:\n\n    \n    \n    declare {[3 x i64], [4 x <2 x i64>]} @my_func( i64 %rdi, i64 %rsi, i64 %rdx, i64 %rcx, i64 %r8, i64 %r9, <2 x i64> %xmm0, <2 x i64> %xmm1, <2 x i64> %xmm2, <2 x i64> %xmm3, <2 x i64> %xmm4, <2 x i64> %xmm5, <2 x i64> %xmm6, <2 x i64> %xmm7, ; other args... )\n\nLLVM IR\n\nWhen passing pointers, the appropriate i64s should be replaced by ptr, and\nwhen passing doubles, they replace <2 x i64>s.\n\nBut you\u2019re probably saying, \u201cMiguel, that\u2019s crazy! Most functions don\u2019t pass\n176 bytes!\u201d And you\u2019d be right, if not for the magic of LLVM\u2019s very well-\nspecified poison semantics.\n\nWe can get away with not doing extra work if every argument we do not use is\npassed poison. Because poison is equal to \u201cthe most convenient possible value\nat the present moment\u201d, when LLVM sees poison passed into a function via\nregister, it decides that the most convenient value is \u201cwhatever happens to be\nin the register already\u201d, and so it doesn\u2019t have to touch that register!\n\nFor example, if we wanted to pass a pointer via rcx, we would generate the\nfollowing code.\n\n    \n    \n    ; This is a -Zcallconv=fast-style function. %Out = type {[3 x i64], [4 x <2 x i64>]} define %Out @load_rcx( i64 %rdi, i64 %rsi, i64 %rdx, ptr %rcx, i64 %r8, i64 %r9, <2 x i64> %xmm0, <2 x i64> %xmm1, <2 x i64> %xmm2, <2 x i64> %xmm3, <2 x i64> %xmm4, <2 x i64> %xmm5, <2 x i64> %xmm6, <2 x i64> %xmm7 ) { %load = load i64, ptr %rcx %out = insertvalue %Out poison, i64 %load, 0, 0 ret %Out %out } declare ptr @malloc(i64) define i64 @make_the_call() { %1 = call ptr @malloc(i64 8) store i64 42, ptr %1 %2 = call %Out @by_rcx( i64 poison, i64 poison, i64 poison, ptr %1, i64 poison, i64 poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison) %3 = extractvalue %Out %2, 0, 0 %4 = add i64 %3, 42 ret i64 %4 }\n\nLLVM IR\n\n    \n    \n    by_rcx: mov rax, qword ptr [rcx] ret make_the_call: push rax mov edi, 8 call malloc mov qword ptr [rax], 42 mov rcx, rax call load_rcx add rax, 42 pop rcx ret\n\nx86 Assembly\n\nIt is perfectly legal to pass poison to a function, if it does not interact\nwith the poisoned argument in any proscribed way. And as we see, load_rcx()\nreceives its pointer argument in rcx, whereas make_the_call() takes no penalty\nin setting up the call: loading poison into the other thirteen registers\ncompiles down to nothing^4, so it only needs to load the pointer returned by\nmalloc into rcx.\n\nThis gives us almost total control over argument passing; unfortunately, it is\nnot total. In an ideal world, the same registers are used for input and\noutput, to allow easier pipelining of calls without introducing extra register\ntraffic. This is true on ARM and RISC-V, but not x86. However, because\nregister ordering is merely a suggestion for us, we can choose to allocate the\nreturn registers in whatever order we want. For example, we can pretend the\norder registers should be allocated in is rdx, rcx, rdi, rsi, r8, r9 for\ninputs, and rdx, rcx, rax for outputs.\n\n    \n    \n    %Out = type {[3 x i64], [4 x <2 x i64>]} define %Out @square( i64 %rdi, i64 %rsi, i64 %rdx, ptr %rcx, i64 %r8, i64 %r9, <2 x i64> %xmm0, <2 x i64> %xmm1, <2 x i64> %xmm2, <2 x i64> %xmm3, <2 x i64> %xmm4, <2 x i64> %xmm5, <2 x i64> %xmm6, <2 x i64> %xmm7 ) { %sq = mul i64 %rdx, %rdx %out = insertvalue %Out poison, i64 %sq, 0, 1 ret %Out %out } define i64 @make_the_call(i64) { %2 = call %Out @square( i64 poison, i64 poison, i64 %0, i64 poison, i64 poison, i64 poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison) %3 = extractvalue %Out %2, 0, 1 %4 = call %Out @square( i64 poison, i64 poison, i64 %3, i64 poison, i64 poison, i64 poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison) %5 = extractvalue %Out %4, 0, 1 ret i64 %5 }\n\nLLVM IR\n\n    \n    \n    square: imul rdx, rdx ret make_the_call: push rax mov rdx, rdi call square call square mov rax, rdx pop rcx ret\n\nx86 Assembly\n\nsquare generates extremely simple code: the input and output register is rdi,\nso no extra register traffic needs to be generated. Similarly, when we\neffectively do @square(@square(%0)), there is no setup between the functions.\nThis is similar to code seen on aarch64, which uses the same register sequence\nfor input and output. We can see that the \u201cnaive\u201d version of this IR produces\nthe exact same code on aarch64 for this reason.\n\n    \n    \n    define i64 @square(i64) { %2 = mul i64 %0, %0 ret i64 %2 } define i64 @make_the_call(i64) { %2 = call i64 @square(i64 %0) %3 = call i64 @square(i64 %2) ret i64 %3 }\n\nLLVM IR\n\n    \n    \n    square: mul x0, x0, x0 ret make_the_call: str x30, [sp, #-16]! bl square ldr x30, [sp], #16 b square // Tail call.\n\nARM Assembly\n\n### Rust Structs and Unions\n\nNow that we\u2019ve established total control on how registers are assigned, we can\nturn towards maximizing use of these registers in Rust.\n\nFor simplicity, we can assume that rustc has already processed the users\u2019s\ntypes into basic aggregates and unions; no enums here! We then have to make\nsome decisions about which portions of the arguments to allocate to registers.\n\nFirst, return values. This is relatively straightforward, since there is only\none value to pass. The amount of data we need to return is not the size of the\nstruct. For example, [(u64, u32); 2] measures 32 bytes wide. However, eight of\nthose bytes are padding! We do not need to preserve padding when returning by\nvalue, so we can flatten the struct into (u64, u32, u64, u32) and sort by size\ninto (u64, u64, u32, u32). This has no padding and is 24 bytes wide, which\nfits into the three return registers LLVM gives us on x86. We define the\neffective size of a type to be the number of non-undef bits it occupies. For\n[(u64, u32); 2], this is 192 bits, since it excludes the padding. For bool,\nthis is one. For char this is technically 21, but it\u2019s simpler to treat char\nas an alias for u32.\n\nThe reason for counting bits this way is that it permits significant\ncompaction. For example, returning a struct full of bools can simply bit-pack\nthe bools into a single register.\n\nSo, a return value is converted to a by-ref return if its effective size is\nsmaller than the output register space (on x86, this is three integer\nregisters and four SSE registers, so we get 88 bytes total, or 704 bits).\n\nArgument registers are much harder, because we hit the knapsack problem, which\nis NP-hard. The following relatively naive heuristic is where I would start,\nbut it can be made infinitely smarter over time.\n\nFirst, demote to by-ref any argument whose effective size is larget than the\ntotal by-register input space (on x86, 176 bytes or 1408 bits). This means we\nget a pointer argument instead. This is beneficial to do first, since a single\npointer might pack better than the huge struct.\n\nEnums should be replaced by the appropriate discriminant-union pair. For\nexample, Option<i32> is, internally, (union { i32, () }, i1), while\nOption<Option<i32>> is (union { i32, (), () }, i2). Using a small non-power-\nof-two integer improves our ability to pack things, since enum discriminants\nare often quite tiny.\n\nNext, we need to handle unions. Because mucking about with unions\u2019\nuninitialized bits behind our backs is allowed, we need to either pass it as\nan array of u8, unless it only has a single non-empty variant, in which case\nit is replaced with that variant^5.\n\nNow, we can proceed to flatten everything. All of the converted arguments are\nflattened into their most primitive components: pointers, integers, floats,\nand bools. Every field should be no larger than the smallest argument\nregister; this may require splitting large types such as u128 or f64.\n\nThis big list of primitives is next sorted by effective size, from smallest to\nlargest. We take the largest prefix of this that will fit in the available\nregister space; everything else goes on the stack.\n\nIf part of a Rust-level input is sent to the stack in this way, and that part\nis larger than a small multiple of the pointer size (e.g., 2x), it is demoted\nto being passed by pointer-on-the-stack, to minimize memory traffic.\nEverything else is passed directly on the stack in the order those inputs were\nbefore the sort. This helps keep regions that need to be copied relatively\ncontiguous, to minimize calls to memcpy.\n\nThe things we choose to pass in registers are allocated to registers in\nreverse size order, so e.g. first 64-bit things, then 32-bit things, etc. This\nis the same layout algorithm that repr(Rust) structs use to move all the\npadding into the tail. Once we get to the bools, those are bit-packed, 64 to a\nregister.\n\nHere\u2019s a relatively complicated example. My Rust function is as follows:\n\n    \n    \n    struct Options { colorize: bool, verbose_debug: bool, allow_spurious_failure: bool, retries: u32, } trait Context { fn check(&self, n: usize, colorize: bool); } fn do_thing<'a>(op_count: Option<usize>, context: &dyn Context, name: &'a str, code: [char; 6], options: Options, ) -> &'a str { if let Some(op_count) = op_count { context.check(op_count, options.colorize); } for c in code { if let Some((_, suf)) = name.split_once(c) { return suf; } } \"idk\" }\n\nRust\n\nThe codegen for this function is quite complex, so I\u2019ll only cover the\nprologue and epilogue. After sorting and flattening, our raw argument LLVM\ntypes are something like this:\n\n    \n    \n    gprs: i64, ptr, ptr, ptr, i64, i32, i32 xmm0: i32, i32, i32, i32 xmm1: i32, i1, i1, i1, i1\n\nLLVM IR\n\nEverything fits in registers! So, what does the LLVM function look like on\nx86?\n\n    \n    \n    %Out = type {[3 x i64], [4 x <2 x i64>]} define %Out @do_thing( i64 %rdi, ptr %rsi, ptr %rdx, ptr %rcx, i64 %r8, i64 %r9, <4 x i32> %xmm0, <4 x i32> %xmm1, ; Unused. <2 x i64> %xmm2, <2 x i64> %xmm3, <2 x i64> %xmm4, <2 x i64> %xmm5, <2 x i64> %xmm6, <2 x i64> %xmm7 ) { ; First, unpack all the primitives. %r9.0 = trunc i64 %r9 to i32 %r9.1.i64 = lshr i64 %r9, 32 %r9.1 = trunc i64 %r9.1.i64 to i32 %xmm0.0 = extractelement <4 x i32> %xmm0, i32 0 %xmm0.1 = extractelement <4 x i32> %xmm0, i32 1 %xmm0.2 = extractelement <4 x i32> %xmm0, i32 2 %xmm0.3 = extractelement <4 x i32> %xmm0, i32 3 %xmm1.0 = extractelement <4 x i32> %xmm1, i32 0 %xmm1.1 = extractelement <4 x i32> %xmm1, i32 1 %xmm1.1.0 = trunc i32 %xmm1.1 to i1 %xmm1.1.1.i32 = lshr i32 %xmm1.1, 1 %xmm1.1.1 = trunc i32 %xmm1.1.1.i32 to i1 %xmm1.1.2.i32 = lshr i32 %xmm1.1, 2 %xmm1.1.2 = trunc i32 %xmm1.1.2.i32 to i1 %xmm1.1.3.i32 = lshr i32 %xmm1.1, 3 %xmm1.1.3 = trunc i32 %xmm1.1.3.i32 to i1 ; Next, reassemble them into concrete values as needed. %op_count.0 = insertvalue { i64, i1 } poison, i64 %rdi, 0 %op_count = insertvalue { i64, i1 } %op_count.0, i1 %xmm1.1.0, 1 %context.0 = insertvalue { ptr, ptr } poison, ptr %rsi, 0 %context = insertvalue { ptr, ptr } %context.0, ptr %rdx, 1 %name.0 = insertvalue { ptr, i64 } poison, ptr %rcx, 0 %name = insertvalue { ptr, i64 } %name.0, i64 %r8, 1 %code.0 = insertvalue [6 x i32] poison, i32 %r9.0, 0 %code.1 = insertvalue [6 x i32] %code.0, i32 %r9.1, 1 %code.2 = insertvalue [6 x i32] %code.1, i32 %xmm0.0, 2 %code.3 = insertvalue [6 x i32] %code.2, i32 %xmm0.1, 3 %code.4 = insertvalue [6 x i32] %code.3, i32 %xmm0.2, 4 %code = insertvalue [6 x i32] %code.4, i32 %xmm0.3, 5 %options.0 = insertvalue { i32, i1, i1, i1 } poison, i32 %xmm1.0, 0 %options.1 = insertvalue { i32, i1, i1, i1 } %options.0, i1 %xmm1.1.1, 1 %options.2 = insertvalue { i32, i1, i1, i1 } %options.1, i1 %xmm1.1.2, 2 %options = insertvalue { i32, i1, i1, i1 } %options.2, i1 %xmm1.1.3, 3 ; Codegen as usual. ; ... }\n\nLLVM IR\n\nAbove, !dbg metadata for the argument values should be attached to the\ninstruction that actually materializes it. This ensures that gdb does\nsomething halfway intelligent when you ask it to print argument values.\n\nOn the other hand, in current rustc, it gives LLVM eight pointer-sized\nparameters, so it winds up spending all six integer registers, plus two values\npassed on the stack. Not great!\n\nThis is not a complete description of what a completely over-engineered\ncalling convention could entail: in some cases we might know that we have\nadditional registers available (such as AVX registers on x86). There are cases\nwhere we might want to split a struct across registers and the stack.\n\nThis also isn\u2019t even getting into what returns could look like. Results are\noften passed through several layers of functions via ?, which can result in a\nlot of redundant register moves. Often, a Result is large enough that it\ndoesn\u2019t fit in registers, so each call in the ? stack has to inspect an ok bit\nby loading it from memory. Instead, a Result return might be implemented as an\nout-parameter pointer for the error, with the ok variant\u2019s payload, and the is\nok bit, returned as an Option<T>. There are some fussy details with Into calls\nvia ?, but the idea is implementable.\n\n### Optimization-Dependent ABI\n\nNow, because we\u2019re Rust, we\u2019ve also got a trick up our sleeve that C doesn\u2019t\n(but Go does)! When we\u2019re generating the ABI that all callers will see (for\n-Zcallconv=fast), we can look at the function body. This means that a crate\ncan advertise the precise ABI (in terms of register-passing) of its functions.\n\nThis opens the door to a more extreme optimization-based ABIs. We can start by\nsimply throwing out unused arguments: if the function never does anything with\na parameter, don\u2019t bother spending registers on it.\n\nAnother example: suppose that we know that an &T argument is not retained (a\nquestion the borrow checker can answer at this point in the compiler) and is\nnever converted to a raw pointer (or written to memory a raw pointer is taken\nof, etc). We also know that T is fairly small, and T: Freeze. Then, we can\nreplace the reference with the pointee directly, passed by value.\n\nThe most obvious candidates for this is APIs like HashMap::get(). If the key\nis something like an i32, we need to spill that integer to the stack and pass\na pointer to it! This results in unnecessary, avoidable memory traffic.\n\nProfile-guided ABI is a step further. We might know that some arguments are\nhotter than others, which might cause them to be prioritized in the register\nallocation order.\n\nYou could even imagine a case where a function takes a very large struct by\nreference, but three i64 fields are very hot, so the caller can preload those\nfields, passing them both by register and via the pointer to the large struct.\nThe callee does not see additional cost: it had to issue those loads anyway.\nHowever, the caller probably has those values in registers already, which\navoids some memory traffic.\n\nInstrumentation profiles may even indicate that it makes sense to duplicate\nwhole functions, which are identical except for their ABIs. Maybe they take\ndifferent arguments by register to avoid costly spills.\n\n## Conclusion\n\nThis is a bit more advanced (and ranty) than my usual writing, but this is an\naspect of Rust that I find really frustrating. We could be doing so much\nbetter than C++ ever can (because of their ABI constraints). None of this is\nnew ideas; this is literally how Go does it!\n\nSo why don\u2019t we? Part of the reason is that ABI codegen is complex, and as I\ndescribed above, LLVM gives us very few useful knobs. It\u2019s not a friendly part\nof rustc, and doing things wrong can have nasty consequences for usability.\nThe other part is a lack of expertise. As of writing, only a handful of people\ncontributing to rustc have the necessary grasp of LLVM\u2019s semantics (and mood\nswings) to emit the Right Code such that we get good codegen and don\u2019t crash\nLLVM.\n\nAnother reason is compilation time. The more complicated the function\nsignatures, the more prologue/epilogue code we have to generate that LLVM has\nto chew on. But -Zcallconv is intended to only be used with optimizations\nturned on, so I don\u2019t think this is a meaningful complaint. Nor do I think the\nproject\u2019s Goodhartization of compilation time as a metric is healthy... but I\ndo not think this is ultimately a relevant drawback.\n\nI, unfortunately, do not have the spare time to dive into fixing rustc\u2019s ABI\ncode, but I do know LLVM really well, and I know that this is a place where\nRust has a low bus factor. For that reason, I am happy to provide the Rust\ncompiler team expert knowledge on getting LLVM to do the right thing in\nservice of making optimized code faster.\n\n  1. Or just switch it to the codepath for extern \"C\" or extern \"fastcall\" since those are clearly better. We will always need to know how to generate code for the non-extern \"Rust\" calling conventions. \u21a9\n\n  2. It\u2019s Complicated. Passing a double burns a whole <2 x i64> slot. This seems bad, but it can be beneficial since keeping a double in vector registers reduces register traffic, since usually, fp instructions use the vector registers (or the fp registers shadow the vector registers, like on ARM). \u21a9\n\n  3. On the one hand, you might say this \u201cextended calling convention\u201d isn\u2019t an explicitly supported part of LLVM\u2019s ccc calling convention. On the other hand, Hyrum\u2019s Law cuts both ways: Rust is big enough of an LLVM user that LLVM cannot simply miscompile all Rust programs at this point, and the IR I propose Rust emits is extremely reasonable.\n\nIf Rust causes LLVM to misbehave, that\u2019s an LLVM bug, and we should fix LLVM\nbugs, not work around them. \u21a9\n\n  4. Only on -O1 or higher, bizarrely. At -O0, LLVM decides that all of the poisons must have the same value, so it copies a bunch of registers around needlessly. This seems like a bug? \u21a9\n\n  5. There are other cases where we might want to replace a union with one of its variants: for example, there\u2019s a lot of cases where Result<&T, Error> is secretly a union { ptr, u32 }, in which case it should be replaced with a single ptr. \u21a9\n\n## Related Posts\n\n  * 2023-11-27 /\n\n###### Designing a SIMD Algorithm from Scratch\n\n  * 2023-09-29 /\n\n###### What is a Matrix? A Miserable Pile of Coefficients!\n\n  * 2023-08-09 /\n\n###### I Wrote A String Type\n\n2024-04-17 \u2022 3689 words \u2022 20 minutes \u2022 #dark-arts \u2022 #assembly \u2022 #rust\n\n# The Rust Calling Convention We Deserve\n\nI will often say that the so-called \u201cC ABI\u201d is a very bad one, and a\nrelatively unimaginative one when it comes to passing complicated types\neffectively. A lot of people ask me \u201cok, what would you use instead\u201d, and I\njust point them to the Go register ABI, but it seems most people have trouble\nfilling in the gaps of what I mean. This article explains what I mean in\ndetail.\n\nI have discussed calling conventions in the past, but as a reminder: the\ncalling convention is the part of the ABI that concerns itself with how to\npass arguments to and from a function, and how to actually call a function.\nThis includes which registers arguments go in, which registers values are\nreturned out of, what function prologues/epilogues look like, how unwinding\nworks, etc.\n\nThis particular post is primarily about x86, but I intend to be reasonably\ngeneric (so that what I\u2019ve written applies just as well to ARM, RISC-V, etc).\nI will assume a general familiarity with x86 assembly, LLVM IR, and Rust (but\nnot rustc\u2019s internals).\n\n## The Problem\n\nToday, like many other natively compiled languages, Rust defines an\nunspecified0- calling convention that lets it call functions however it likes.\nIn practice, Rust lowers to LLVM\u2019s built-in C calling convention, which LLVM\u2019s\nprologue/epilogue codegen generates calls for.\n\nRust is fairly conservative: it tries to generate LLVM function signatures\nthat Clang could have plausibly generated. This has two significant benefits:\n\n  1. Good probability debuggers won\u2019t choke on it. This is not a concern on Linux, though, because DWARF is very general and does not bake-in the Linux C ABI. We will concern ourselves only with ELF-based systems and assume that debuggability is a nonissue.\n\n  2. It is less likely to tickle LLVM bugs due to using ABI codegen that Clang does not exercise. I think that if Rust tickles LLVM bugs, we should actually fix them (a very small number of rustc contributors do in fact do this).\n\nHowever, we are too conservative. We get terrible codegen for simple\nfunctions:\n\n    \n    \n    fn extract(arr: [i32; 3]) -> i32 { arr[1] }\n\nRust\n\n    \n    \n    extract: mov eax, dword ptr [rdi + 4] ret\n\nx86 Assembly\n\narr is 12 bytes wide, so you\u2019d think it would be passed in registers, but no!\nIt is passed by pointer! Rust is actually more conservative than what the\nLinux C ABI mandates, because it actually passes the [i32; 3] in registers\nwhen extern \"C\" is requested.\n\n    \n    \n    extern \"C\" fn extract(arr: [i32; 3]) -> i32 { arr[1] }\n\nRust\n\n    \n    \n    extract: mov rax, rdi shr rax, 32 ret\n\nx86 Assembly\n\nThe array is passed in rdi and rsi, with the i32s packed into registers. The\nfunction moves rdi into rax, the output register, and shifts the upper half\ndown.\n\nNot only does clang produce patently bad code for passing things by value, but\nit also knows how to do it better, if you request a standard calling\nconvention! We could be generating way better code than Clang, but we don\u2019t!\n\nHereforth, I will describe how to do it.\n\n### -Zcallconv\n\nLet\u2019s suppose that we keep the current calling convention for extern \"Rust\"^1,\nbut we add a flag -Zcallconv that sets the calling convention for extern\n\"Rust\" when compiling a crate. The supported values will be -Zcallconv=legacy\nfor the current one, and -Zcallconv=fast for the one we\u2019re going to design. We\ncould even let -O set -Zcallconv=fast automatically.\n\nWhy keep the old calling convention? Although I did sweep debugability under\nthe rug, one nice property -Zcallconv=fast will not have is that it does not\nplace arguments in the C ABI order, which means that a reader replying on the\n\u201cDiana\u2019s silk dress cost $89\u201d mnemonic on x86 will get fairly confused.\n\nI am also assuming we may not even support -Zcallconv=fast for some targets,\nlike WASM, where there is no concept of \u201cregisters\u201d and \u201cspilling\u201d. It may not\neven make sense to enable it for for debug builds, because it will produce\nmuch worse code with optimizations turned off.\n\nThere is also a mild wrinkle with function pointers, and extern \"Rust\" {}\nblocks. Because this flag is per-crate, even though functions can advertise\nwhich version of extern \"Rust\" they use, function pointers have no such\nluxury. However, calling through a function pointer is slow and rare, so we\ncan simply force them to use -Zcallconv=legacy. We can generate a shim to\ntranslate calling conventions as needed.\n\nSimilarly, we can, in principle, call any Rust function like this:\n\n    \n    \n    fn secret_call() -> i32 { extern \"Rust\" { fn my_func() -> i32; } unsafe { my_func() } }\n\nRust\n\nHowever, this mechanism can only be used to call unmangled symbols. Thus, we\ncan simply force #[no_mangle] symbols to use the legacy calling convention.\n\n## Bending LLVM to Our Will\n\nIn an ideal world, LLVM would provide a way for us to specify the calling\nconvention directly. E.g., this argument goes in that register, this return\ngoes in that one, etc. Unfortunately, adding a calling convention to LLVM\nrequires writing a bunch of C++.\n\nHowever, we can get away with specifying our own calling convention by\nfollowing the following procedure.\n\n  1. First, determine, for a given target triple, the maximum number of values that can be passed \u201cby register\u201d. I will explain how to do this below.\n\n  2. Decide how to pass the return value. It will either fit in the output registers, or it will need to be returned \u201cby reference\u201d, in which case we pass an extra ptr argument to the function (tagged with the sret attribute) and the actual return value of the function is that pointer.\n\n  3. Decide which arguments that have been passed by value need to be demoted to being passed by reference. This will be a heuristic, but generally will be approximately \u201carguments larger than the by-register space\u201d. For example, on x86, this comes out to 176 bytes.\n\n  4. Decide which arguments get passed by register, so as to maximize register space usage. This problem is NP-hard (it\u2019s the knapsack problem) so it will require a heuristic. All other arguments are passed on the stack.\n\n  5. Generate the function signature in LLVM IR. This will be all of the arguments that are passed by register encoded as various non-aggregates, such as i64, ptr, double, and <2 x i64>. What valid choices are for said non-aggregates depends on the target, but the above are what you will generally get on a 64-bit architecture. Arguments passed on the stack will follow the \u201cregister inputs\u201d.\n\n  6. Generate a function prologue. This is code to decode each Rust-level argument from the register inputs, so that there are %ssa values corresponding to those that would be present when using -Zcallconv=legacy. This allows us to generate the same code for the body of the function regardless of calling convention. Redundant decoding code will be eliminated by DCE passes.\n\n  7. Generate a function exit block. This is a block that contains a single phi instruction for the return type as it would be for -Zcallconv=legacy. This block will encode it into the requisite output format and then ret as appropriate. All exit paths through the function should br to this block instead of ret-ing.\n\n  8. If a non-polymorphic, non-inline function may have its address taken (as a function pointer), either because it is exported out of the crate or the crate takes a function pointer to it, generate a shim that uses -Zcallconv=legacy and immediately tail-calls the real implementation. This is necessary to preserve function pointer equality.\n\nThe main upshot here is that we need to cook up heuristics for figuring out\nwhat goes in registers (since we allow reordering arguments to get better\nthroughput). This is equivalent to the knapsack problem; knapsack heuristics\nare beyond the scope of this article. This should happen early enough that\nthis information can be stuffed into rmeta to avoid needing to recompute it.\nWe may want to use different, faster heuristics depending on -Copt-level. Note\nthat correctness requires that we forbid linking code generated by multiple\ndifferent Rust compilers, which is already the case, since Rust breaks ABI\nfrom release to release.\n\n### What Is LLVM Willing to Do?\n\nAssuming we do that, how do we actually get LLVM to pass things in the way we\nwant it to? We need to determine what the largest \u201cby register\u201d passing LLVM\nwill permit is. The following LLVM program is useful for determining this on a\nparticular version of LLVM:\n\n    \n    \n    %InputI = type [6 x i64] %InputF = type [0 x double] %InputV = type [8 x <2 x i64>] %OutputI = type [3 x i64] %OutputF = type [0 x double] %OutputV = type [4 x <2 x i64>] define void @inputs({ %InputI, %InputF, %InputV }) { %p = alloca [4096 x i8] store volatile { %InputI, %InputF, %InputV } %0, ptr %p ret void } %Output = { %OutputI, %OutputF, %OutputV } @gOutput = constant %Output zeroinitializer define %Output @outputs() { %1 = load %Output, ptr @gOutput ret %Output %1 }\n\nLLVM IR\n\nWhen you pass an aggregate by-value to an LLVM function, LLVM will attempt to\n\u201cexplode\u201d that aggregate into as many registers as possible. There are\ndistinct register classes on different systems. For example, on both x86 and\nARM, floats and vectors share the same register class (kind of^2).\n\nThe above values are for x86^3. LLVM will pass six integers and eight SSE\nvectors by register, and return half as many (3 and 4) by register. Increasing\nany of the values generates extra loads and stores that indicate LLVM gave up\nand passed arguments on the stack.\n\nThe values for aarch64-unknown-linux are 8 integers and 8 vectors for both\ninputs and outputs, respectively.\n\nThis is the maximum number of registers we get to play with for each class.\nAnything extra gets passed on the stack.\n\nI recommend that every function have the same number of by-register arguments.\nSo on x86, EVERY -Zcallconv=fast function\u2019s signature should look like this:\n\n    \n    \n    declare {[3 x i64], [4 x <2 x i64>]} @my_func( i64 %rdi, i64 %rsi, i64 %rdx, i64 %rcx, i64 %r8, i64 %r9, <2 x i64> %xmm0, <2 x i64> %xmm1, <2 x i64> %xmm2, <2 x i64> %xmm3, <2 x i64> %xmm4, <2 x i64> %xmm5, <2 x i64> %xmm6, <2 x i64> %xmm7, ; other args... )\n\nLLVM IR\n\nWhen passing pointers, the appropriate i64s should be replaced by ptr, and\nwhen passing doubles, they replace <2 x i64>s.\n\nBut you\u2019re probably saying, \u201cMiguel, that\u2019s crazy! Most functions don\u2019t pass\n176 bytes!\u201d And you\u2019d be right, if not for the magic of LLVM\u2019s very well-\nspecified poison semantics.\n\nWe can get away with not doing extra work if every argument we do not use is\npassed poison. Because poison is equal to \u201cthe most convenient possible value\nat the present moment\u201d, when LLVM sees poison passed into a function via\nregister, it decides that the most convenient value is \u201cwhatever happens to be\nin the register already\u201d, and so it doesn\u2019t have to touch that register!\n\nFor example, if we wanted to pass a pointer via rcx, we would generate the\nfollowing code.\n\n    \n    \n    ; This is a -Zcallconv=fast-style function. %Out = type {[3 x i64], [4 x <2 x i64>]} define %Out @load_rcx( i64 %rdi, i64 %rsi, i64 %rdx, ptr %rcx, i64 %r8, i64 %r9, <2 x i64> %xmm0, <2 x i64> %xmm1, <2 x i64> %xmm2, <2 x i64> %xmm3, <2 x i64> %xmm4, <2 x i64> %xmm5, <2 x i64> %xmm6, <2 x i64> %xmm7 ) { %load = load i64, ptr %rcx %out = insertvalue %Out poison, i64 %load, 0, 0 ret %Out %out } declare ptr @malloc(i64) define i64 @make_the_call() { %1 = call ptr @malloc(i64 8) store i64 42, ptr %1 %2 = call %Out @by_rcx( i64 poison, i64 poison, i64 poison, ptr %1, i64 poison, i64 poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison) %3 = extractvalue %Out %2, 0, 0 %4 = add i64 %3, 42 ret i64 %4 }\n\nLLVM IR\n\n    \n    \n    by_rcx: mov rax, qword ptr [rcx] ret make_the_call: push rax mov edi, 8 call malloc mov qword ptr [rax], 42 mov rcx, rax call load_rcx add rax, 42 pop rcx ret\n\nx86 Assembly\n\nIt is perfectly legal to pass poison to a function, if it does not interact\nwith the poisoned argument in any proscribed way. And as we see, load_rcx()\nreceives its pointer argument in rcx, whereas make_the_call() takes no penalty\nin setting up the call: loading poison into the other thirteen registers\ncompiles down to nothing^4, so it only needs to load the pointer returned by\nmalloc into rcx.\n\nThis gives us almost total control over argument passing; unfortunately, it is\nnot total. In an ideal world, the same registers are used for input and\noutput, to allow easier pipelining of calls without introducing extra register\ntraffic. This is true on ARM and RISC-V, but not x86. However, because\nregister ordering is merely a suggestion for us, we can choose to allocate the\nreturn registers in whatever order we want. For example, we can pretend the\norder registers should be allocated in is rdx, rcx, rdi, rsi, r8, r9 for\ninputs, and rdx, rcx, rax for outputs.\n\n    \n    \n    %Out = type {[3 x i64], [4 x <2 x i64>]} define %Out @square( i64 %rdi, i64 %rsi, i64 %rdx, ptr %rcx, i64 %r8, i64 %r9, <2 x i64> %xmm0, <2 x i64> %xmm1, <2 x i64> %xmm2, <2 x i64> %xmm3, <2 x i64> %xmm4, <2 x i64> %xmm5, <2 x i64> %xmm6, <2 x i64> %xmm7 ) { %sq = mul i64 %rdx, %rdx %out = insertvalue %Out poison, i64 %sq, 0, 1 ret %Out %out } define i64 @make_the_call(i64) { %2 = call %Out @square( i64 poison, i64 poison, i64 %0, i64 poison, i64 poison, i64 poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison) %3 = extractvalue %Out %2, 0, 1 %4 = call %Out @square( i64 poison, i64 poison, i64 %3, i64 poison, i64 poison, i64 poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison, <2 x i64> poison) %5 = extractvalue %Out %4, 0, 1 ret i64 %5 }\n\nLLVM IR\n\n    \n    \n    square: imul rdx, rdx ret make_the_call: push rax mov rdx, rdi call square call square mov rax, rdx pop rcx ret\n\nx86 Assembly\n\nsquare generates extremely simple code: the input and output register is rdi,\nso no extra register traffic needs to be generated. Similarly, when we\neffectively do @square(@square(%0)), there is no setup between the functions.\nThis is similar to code seen on aarch64, which uses the same register sequence\nfor input and output. We can see that the \u201cnaive\u201d version of this IR produces\nthe exact same code on aarch64 for this reason.\n\n    \n    \n    define i64 @square(i64) { %2 = mul i64 %0, %0 ret i64 %2 } define i64 @make_the_call(i64) { %2 = call i64 @square(i64 %0) %3 = call i64 @square(i64 %2) ret i64 %3 }\n\nLLVM IR\n\n    \n    \n    square: mul x0, x0, x0 ret make_the_call: str x30, [sp, #-16]! bl square ldr x30, [sp], #16 b square // Tail call.\n\nARM Assembly\n\n### Rust Structs and Unions\n\nNow that we\u2019ve established total control on how registers are assigned, we can\nturn towards maximizing use of these registers in Rust.\n\nFor simplicity, we can assume that rustc has already processed the users\u2019s\ntypes into basic aggregates and unions; no enums here! We then have to make\nsome decisions about which portions of the arguments to allocate to registers.\n\nFirst, return values. This is relatively straightforward, since there is only\none value to pass. The amount of data we need to return is not the size of the\nstruct. For example, [(u64, u32); 2] measures 32 bytes wide. However, eight of\nthose bytes are padding! We do not need to preserve padding when returning by\nvalue, so we can flatten the struct into (u64, u32, u64, u32) and sort by size\ninto (u64, u64, u32, u32). This has no padding and is 24 bytes wide, which\nfits into the three return registers LLVM gives us on x86. We define the\neffective size of a type to be the number of non-undef bits it occupies. For\n[(u64, u32); 2], this is 192 bits, since it excludes the padding. For bool,\nthis is one. For char this is technically 21, but it\u2019s simpler to treat char\nas an alias for u32.\n\nThe reason for counting bits this way is that it permits significant\ncompaction. For example, returning a struct full of bools can simply bit-pack\nthe bools into a single register.\n\nSo, a return value is converted to a by-ref return if its effective size is\nsmaller than the output register space (on x86, this is three integer\nregisters and four SSE registers, so we get 88 bytes total, or 704 bits).\n\nArgument registers are much harder, because we hit the knapsack problem, which\nis NP-hard. The following relatively naive heuristic is where I would start,\nbut it can be made infinitely smarter over time.\n\nFirst, demote to by-ref any argument whose effective size is larget than the\ntotal by-register input space (on x86, 176 bytes or 1408 bits). This means we\nget a pointer argument instead. This is beneficial to do first, since a single\npointer might pack better than the huge struct.\n\nEnums should be replaced by the appropriate discriminant-union pair. For\nexample, Option<i32> is, internally, (union { i32, () }, i1), while\nOption<Option<i32>> is (union { i32, (), () }, i2). Using a small non-power-\nof-two integer improves our ability to pack things, since enum discriminants\nare often quite tiny.\n\nNext, we need to handle unions. Because mucking about with unions\u2019\nuninitialized bits behind our backs is allowed, we need to either pass it as\nan array of u8, unless it only has a single non-empty variant, in which case\nit is replaced with that variant^5.\n\nNow, we can proceed to flatten everything. All of the converted arguments are\nflattened into their most primitive components: pointers, integers, floats,\nand bools. Every field should be no larger than the smallest argument\nregister; this may require splitting large types such as u128 or f64.\n\nThis big list of primitives is next sorted by effective size, from smallest to\nlargest. We take the largest prefix of this that will fit in the available\nregister space; everything else goes on the stack.\n\nIf part of a Rust-level input is sent to the stack in this way, and that part\nis larger than a small multiple of the pointer size (e.g., 2x), it is demoted\nto being passed by pointer-on-the-stack, to minimize memory traffic.\nEverything else is passed directly on the stack in the order those inputs were\nbefore the sort. This helps keep regions that need to be copied relatively\ncontiguous, to minimize calls to memcpy.\n\nThe things we choose to pass in registers are allocated to registers in\nreverse size order, so e.g. first 64-bit things, then 32-bit things, etc. This\nis the same layout algorithm that repr(Rust) structs use to move all the\npadding into the tail. Once we get to the bools, those are bit-packed, 64 to a\nregister.\n\nHere\u2019s a relatively complicated example. My Rust function is as follows:\n\n    \n    \n    struct Options { colorize: bool, verbose_debug: bool, allow_spurious_failure: bool, retries: u32, } trait Context { fn check(&self, n: usize, colorize: bool); } fn do_thing<'a>(op_count: Option<usize>, context: &dyn Context, name: &'a str, code: [char; 6], options: Options, ) -> &'a str { if let Some(op_count) = op_count { context.check(op_count, options.colorize); } for c in code { if let Some((_, suf)) = name.split_once(c) { return suf; } } \"idk\" }\n\nRust\n\nThe codegen for this function is quite complex, so I\u2019ll only cover the\nprologue and epilogue. After sorting and flattening, our raw argument LLVM\ntypes are something like this:\n\n    \n    \n    gprs: i64, ptr, ptr, ptr, i64, i32, i32 xmm0: i32, i32, i32, i32 xmm1: i32, i1, i1, i1, i1\n\nLLVM IR\n\nEverything fits in registers! So, what does the LLVM function look like on\nx86?\n\n    \n    \n    %Out = type {[3 x i64], [4 x <2 x i64>]} define %Out @do_thing( i64 %rdi, ptr %rsi, ptr %rdx, ptr %rcx, i64 %r8, i64 %r9, <4 x i32> %xmm0, <4 x i32> %xmm1, ; Unused. <2 x i64> %xmm2, <2 x i64> %xmm3, <2 x i64> %xmm4, <2 x i64> %xmm5, <2 x i64> %xmm6, <2 x i64> %xmm7 ) { ; First, unpack all the primitives. %r9.0 = trunc i64 %r9 to i32 %r9.1.i64 = lshr i64 %r9, 32 %r9.1 = trunc i64 %r9.1.i64 to i32 %xmm0.0 = extractelement <4 x i32> %xmm0, i32 0 %xmm0.1 = extractelement <4 x i32> %xmm0, i32 1 %xmm0.2 = extractelement <4 x i32> %xmm0, i32 2 %xmm0.3 = extractelement <4 x i32> %xmm0, i32 3 %xmm1.0 = extractelement <4 x i32> %xmm1, i32 0 %xmm1.1 = extractelement <4 x i32> %xmm1, i32 1 %xmm1.1.0 = trunc i32 %xmm1.1 to i1 %xmm1.1.1.i32 = lshr i32 %xmm1.1, 1 %xmm1.1.1 = trunc i32 %xmm1.1.1.i32 to i1 %xmm1.1.2.i32 = lshr i32 %xmm1.1, 2 %xmm1.1.2 = trunc i32 %xmm1.1.2.i32 to i1 %xmm1.1.3.i32 = lshr i32 %xmm1.1, 3 %xmm1.1.3 = trunc i32 %xmm1.1.3.i32 to i1 ; Next, reassemble them into concrete values as needed. %op_count.0 = insertvalue { i64, i1 } poison, i64 %rdi, 0 %op_count = insertvalue { i64, i1 } %op_count.0, i1 %xmm1.1.0, 1 %context.0 = insertvalue { ptr, ptr } poison, ptr %rsi, 0 %context = insertvalue { ptr, ptr } %context.0, ptr %rdx, 1 %name.0 = insertvalue { ptr, i64 } poison, ptr %rcx, 0 %name = insertvalue { ptr, i64 } %name.0, i64 %r8, 1 %code.0 = insertvalue [6 x i32] poison, i32 %r9.0, 0 %code.1 = insertvalue [6 x i32] %code.0, i32 %r9.1, 1 %code.2 = insertvalue [6 x i32] %code.1, i32 %xmm0.0, 2 %code.3 = insertvalue [6 x i32] %code.2, i32 %xmm0.1, 3 %code.4 = insertvalue [6 x i32] %code.3, i32 %xmm0.2, 4 %code = insertvalue [6 x i32] %code.4, i32 %xmm0.3, 5 %options.0 = insertvalue { i32, i1, i1, i1 } poison, i32 %xmm1.0, 0 %options.1 = insertvalue { i32, i1, i1, i1 } %options.0, i1 %xmm1.1.1, 1 %options.2 = insertvalue { i32, i1, i1, i1 } %options.1, i1 %xmm1.1.2, 2 %options = insertvalue { i32, i1, i1, i1 } %options.2, i1 %xmm1.1.3, 3 ; Codegen as usual. ; ... }\n\nLLVM IR\n\nAbove, !dbg metadata for the argument values should be attached to the\ninstruction that actually materializes it. This ensures that gdb does\nsomething halfway intelligent when you ask it to print argument values.\n\nOn the other hand, in current rustc, it gives LLVM eight pointer-sized\nparameters, so it winds up spending all six integer registers, plus two values\npassed on the stack. Not great!\n\nThis is not a complete description of what a completely over-engineered\ncalling convention could entail: in some cases we might know that we have\nadditional registers available (such as AVX registers on x86). There are cases\nwhere we might want to split a struct across registers and the stack.\n\nThis also isn\u2019t even getting into what returns could look like. Results are\noften passed through several layers of functions via ?, which can result in a\nlot of redundant register moves. Often, a Result is large enough that it\ndoesn\u2019t fit in registers, so each call in the ? stack has to inspect an ok bit\nby loading it from memory. Instead, a Result return might be implemented as an\nout-parameter pointer for the error, with the ok variant\u2019s payload, and the is\nok bit, returned as an Option<T>. There are some fussy details with Into calls\nvia ?, but the idea is implementable.\n\n### Optimization-Dependent ABI\n\nNow, because we\u2019re Rust, we\u2019ve also got a trick up our sleeve that C doesn\u2019t\n(but Go does)! When we\u2019re generating the ABI that all callers will see (for\n-Zcallconv=fast), we can look at the function body. This means that a crate\ncan advertise the precise ABI (in terms of register-passing) of its functions.\n\nThis opens the door to a more extreme optimization-based ABIs. We can start by\nsimply throwing out unused arguments: if the function never does anything with\na parameter, don\u2019t bother spending registers on it.\n\nAnother example: suppose that we know that an &T argument is not retained (a\nquestion the borrow checker can answer at this point in the compiler) and is\nnever converted to a raw pointer (or written to memory a raw pointer is taken\nof, etc). We also know that T is fairly small, and T: Freeze. Then, we can\nreplace the reference with the pointee directly, passed by value.\n\nThe most obvious candidates for this is APIs like HashMap::get(). If the key\nis something like an i32, we need to spill that integer to the stack and pass\na pointer to it! This results in unnecessary, avoidable memory traffic.\n\nProfile-guided ABI is a step further. We might know that some arguments are\nhotter than others, which might cause them to be prioritized in the register\nallocation order.\n\nYou could even imagine a case where a function takes a very large struct by\nreference, but three i64 fields are very hot, so the caller can preload those\nfields, passing them both by register and via the pointer to the large struct.\nThe callee does not see additional cost: it had to issue those loads anyway.\nHowever, the caller probably has those values in registers already, which\navoids some memory traffic.\n\nInstrumentation profiles may even indicate that it makes sense to duplicate\nwhole functions, which are identical except for their ABIs. Maybe they take\ndifferent arguments by register to avoid costly spills.\n\n## Conclusion\n\nThis is a bit more advanced (and ranty) than my usual writing, but this is an\naspect of Rust that I find really frustrating. We could be doing so much\nbetter than C++ ever can (because of their ABI constraints). None of this is\nnew ideas; this is literally how Go does it!\n\nSo why don\u2019t we? Part of the reason is that ABI codegen is complex, and as I\ndescribed above, LLVM gives us very few useful knobs. It\u2019s not a friendly part\nof rustc, and doing things wrong can have nasty consequences for usability.\nThe other part is a lack of expertise. As of writing, only a handful of people\ncontributing to rustc have the necessary grasp of LLVM\u2019s semantics (and mood\nswings) to emit the Right Code such that we get good codegen and don\u2019t crash\nLLVM.\n\nAnother reason is compilation time. The more complicated the function\nsignatures, the more prologue/epilogue code we have to generate that LLVM has\nto chew on. But -Zcallconv is intended to only be used with optimizations\nturned on, so I don\u2019t think this is a meaningful complaint. Nor do I think the\nproject\u2019s Goodhartization of compilation time as a metric is healthy... but I\ndo not think this is ultimately a relevant drawback.\n\nI, unfortunately, do not have the spare time to dive into fixing rustc\u2019s ABI\ncode, but I do know LLVM really well, and I know that this is a place where\nRust has a low bus factor. For that reason, I am happy to provide the Rust\ncompiler team expert knowledge on getting LLVM to do the right thing in\nservice of making optimized code faster.\n\n  1. Or just switch it to the codepath for extern \"C\" or extern \"fastcall\" since those are clearly better. We will always need to know how to generate code for the non-extern \"Rust\" calling conventions. \u21a9\n\n  2. It\u2019s Complicated. Passing a double burns a whole <2 x i64> slot. This seems bad, but it can be beneficial since keeping a double in vector registers reduces register traffic, since usually, fp instructions use the vector registers (or the fp registers shadow the vector registers, like on ARM). \u21a9\n\n  3. On the one hand, you might say this \u201cextended calling convention\u201d isn\u2019t an explicitly supported part of LLVM\u2019s ccc calling convention. On the other hand, Hyrum\u2019s Law cuts both ways: Rust is big enough of an LLVM user that LLVM cannot simply miscompile all Rust programs at this point, and the IR I propose Rust emits is extremely reasonable.\n\nIf Rust causes LLVM to misbehave, that\u2019s an LLVM bug, and we should fix LLVM\nbugs, not work around them. \u21a9\n\n  4. Only on -O1 or higher, bizarrely. At -O0, LLVM decides that all of the poisons must have the same value, so it copies a bunch of registers around needlessly. This seems like a bug? \u21a9\n\n  5. There are other cases where we might want to replace a union with one of its variants: for example, there\u2019s a lot of cases where Result<&T, Error> is secretly a union { ptr, u32 }, in which case it should be replaced with a single ptr. \u21a9\n\n## Related Posts\n\n  * 2023-11-27 /\n\n###### Designing a SIMD Algorithm from Scratch\n\n  * 2023-09-29 /\n\n###### What is a Matrix? A Miserable Pile of Coefficients!\n\n  * 2023-08-09 /\n\n###### I Wrote A String Type\n\nCC BY-SA \u2022 Site Analytics \u00a9 2024 Miguel Young de la Sota\n\n", "frontpage": true}
