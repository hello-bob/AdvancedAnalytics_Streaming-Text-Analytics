{"aid": "40272045", "title": "LeRobot: Machine Learning for Real-World Robotics in PyTorch", "url": "https://github.com/huggingface/lerobot", "domain": "github.com/huggingface", "votes": 14, "user": "AdilZtn", "posted_at": "2024-05-06 07:17:59", "comments": 0, "source_title": "GitHub - huggingface/lerobot: \ud83e\udd17 LeRobot: State-of-the-art Machine Learning for Real-World Robotics in Pytorch", "source_text": "GitHub - huggingface/lerobot: \ud83e\udd17 LeRobot: State-of-the-art Machine Learning for\nReal-World Robotics in Pytorch\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nhuggingface / lerobot Public\n\n  * Notifications\n  * Fork 3\n  * Star 112\n\n\ud83e\udd17 LeRobot: State-of-the-art Machine Learning for Real-World Robotics in\nPytorch\n\n### License\n\nApache-2.0 license\n\n112 stars 3 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# huggingface/lerobot\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n26 Branches\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nalexander-soareRemove loss masking from diffusion policy (#135)May 6,\n2024a8e245f \u00b7 May 6, 2024May 6, 2024\n\n## History\n\n502 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| Release cleanup (#132)| May 6, 2024  \n  \n### docker\n\n|\n\n### docker\n\n| Add test-docker-build workflow (#109)| Apr 27, 2024  \n  \n### examples\n\n|\n\n### examples\n\n| Release cleanup (#132)| May 6, 2024  \n  \n### lerobot\n\n|\n\n### lerobot\n\n| Remove loss masking from diffusion policy (#135)| May 6, 2024  \n  \n### media\n\n|\n\n### media\n\n| Release cleanup (#132)| May 6, 2024  \n  \n### tests\n\n|\n\n### tests\n\n| Remove loss masking from diffusion policy (#135)| May 6, 2024  \n  \n### .dockerignore\n\n|\n\n### .dockerignore\n\n| CI nightlies cpu/gpu & cleanup (#75)| Apr 25, 2024  \n  \n### .gitattributes\n\n|\n\n### .gitattributes\n\n| WIP Upgrading simxam from mujoco-py to mujoco python bindings| Mar 25, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Remove update method from the policy (#99)| Apr 29, 2024  \n  \n### .pre-commit-config.yaml\n\n|\n\n### .pre-commit-config.yaml\n\n| More CI cleanup, add style workflow (#107)| Apr 27, 2024  \n  \n### CODE_OF_CONDUCT.md\n\n|\n\n### CODE_OF_CONDUCT.md\n\n| Add COC| Apr 16, 2024  \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n| Update readme & remove example 1 (#108)| Apr 27, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Add simxarm license| Mar 25, 2024  \n  \n### Makefile\n\n|\n\n### Makefile\n\n| Refactor eval.py (#127)| May 3, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| Release cleanup (#132)| May 6, 2024  \n  \n### poetry.lock\n\n|\n\n### poetry.lock\n\n| Remove EMA model from Diffusion Policy (#134)| May 5, 2024  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| Release cleanup (#132)| May 6, 2024  \n  \n## Repository files navigation\n\n###\n\nState-of-the-art Machine Learning for real-world robotics\n\n\ud83e\udd17 LeRobot aims to provide models, datasets, and tools for real-world robotics\nin PyTorch. The goal is to lower the barrier to entry to robotics so that\neveryone can contribute and benefit from sharing datasets and pretrained\nmodels.\n\n\ud83e\udd17 LeRobot contains state-of-the-art approaches that have been shown to\ntransfer to the real-world with a focus on imitation learning and\nreinforcement learning.\n\n\ud83e\udd17 LeRobot already provides a set of pretrained models, datasets with human\ncollected demonstrations, and simulation environments to get started without\nassembling a robot. In the coming weeks, the plan is to add more and more\nsupport for real-world robotics on the most affordable and capable robots out\nthere.\n\n\ud83e\udd17 LeRobot hosts pretrained models and datasets on this Hugging Face community\npage: huggingface.co/lerobot\n\n#### Examples of pretrained models on simulation environments\n\nACT policy on ALOHA env| TDMPC policy on SimXArm env| Diffusion policy on\nPushT env  \n---|---|---  \n  \n### Acknowledgment\n\n  * Thanks to Tony Zaho, Zipeng Fu and colleagues for open sourcing ACT policy, ALOHA environments and datasets. Ours are adapted from ALOHA and Mobile ALOHA.\n  * Thanks to Cheng Chi, Zhenjia Xu and colleagues for open sourcing Diffusion policy, Pusht environment and datasets, as well as UMI datasets. Ours are adapted from Diffusion Policy and UMI Gripper.\n  * Thanks to Nicklas Hansen, Yunhai Feng and colleagues for open sourcing TDMPC policy, Simxarm environments and datasets. Ours are adapted from TDMPC and FOWM.\n  * Thanks to Vincent Moens and colleagues for open sourcing TorchRL. It allowed for quick experimentations on the design of LeRobot.\n  * Thanks to Antonio Loquercio and Ashish Kumar for their early support.\n\n## Installation\n\nDownload our source code:\n\n    \n    \n    git clone https://github.com/huggingface/lerobot.git && cd lerobot\n\nCreate a virtual environment with Python 3.10 and activate it, e.g. with\nminiconda:\n\n    \n    \n    conda create -y -n lerobot python=3.10 && conda activate lerobot\n\nInstall \ud83e\udd17 LeRobot:\n\n    \n    \n    pip install .\n\nFor simulations, \ud83e\udd17 LeRobot comes with gymnasium environments that can be\ninstalled as extras:\n\n  * aloha\n  * xarm\n  * pusht\n\nFor instance, to install \ud83e\udd17 LeRobot with aloha and pusht, use:\n\n    \n    \n    pip install \".[aloha, pusht]\"\n\nTo use Weights and Biases for experiment tracking, log in with\n\n    \n    \n    wandb login\n\n## Walkthrough\n\n    \n    \n    . \u251c\u2500\u2500 examples # contains demonstration examples, start here to learn about LeRobot \u251c\u2500\u2500 lerobot | \u251c\u2500\u2500 configs # contains hydra yaml files with all options that you can override in the command line | | \u251c\u2500\u2500 default.yaml # selected by default, it loads pusht environment and diffusion policy | | \u251c\u2500\u2500 env # various sim environments and their datasets: aloha.yaml, pusht.yaml, xarm.yaml | | \u2514\u2500\u2500 policy # various policies: act.yaml, diffusion.yaml, tdmpc.yaml | \u251c\u2500\u2500 common # contains classes and utilities | | \u251c\u2500\u2500 datasets # various datasets of human demonstrations: aloha, pusht, xarm | | \u251c\u2500\u2500 envs # various sim environments: aloha, pusht, xarm | | \u251c\u2500\u2500 policies # various policies: act, diffusion, tdmpc | | \u2514\u2500\u2500 utils # various utilities | \u2514\u2500\u2500 scripts # contains functions to execute via command line | \u251c\u2500\u2500 eval.py # load policy and evaluate it on an environment | \u251c\u2500\u2500 train.py # train a policy via imitation learning and/or reinforcement learning | \u251c\u2500\u2500 push_dataset_to_hub.py # convert your dataset into LeRobot dataset format and upload it to the Hugging Face hub | \u2514\u2500\u2500 visualize_dataset.py # load a dataset and render its demonstrations \u251c\u2500\u2500 outputs # contains results of scripts execution: logs, videos, model checkpoints \u2514\u2500\u2500 tests # contains pytest utilities for continuous integration\n\n### Visualize datasets\n\nCheck out example 1 that illustrates how to use our dataset class which\nautomatically download data from the Hugging Face hub.\n\nYou can also locally visualize episodes from a dataset by executing our script\nfrom the command line:\n\n    \n    \n    python lerobot/scripts/visualize_dataset.py \\ --repo-id lerobot/pusht \\ --episode-index 0\n\nIt will open rerun.io and display the camera streams, robot states and\nactions, like this:\n\nOur script can also visualize datasets stored on a distant server. See python\nlerobot/scripts/visualize_dataset.py --help for more instructions.\n\n### Evaluate a pretrained policy\n\nCheck out example 2 that illustrates how to download a pretrained policy from\nHugging Face hub, and run an evaluation on its corresponding environment.\n\nWe also provide a more capable script to parallelize the evaluation over\nmultiple environments during the same rollout. Here is an example with a\npretrained model hosted on lerobot/diffusion_pusht:\n\n    \n    \n    python lerobot/scripts/eval.py \\ -p lerobot/diffusion_pusht \\ eval.n_episodes=10 \\ eval.batch_size=10\n\nNote: After training your own policy, you can re-evaluate the checkpoints\nwith:\n\n    \n    \n    python lerobot/scripts/eval.py \\ -p PATH/TO/TRAIN/OUTPUT/FOLDER\n\nSee python lerobot/scripts/eval.py --help for more instructions.\n\n### Train your own policy\n\nCheck out example 3 that illustrates how to start training a model.\n\nIn general, you can use our training script to easily train any policy. To use\nwandb for logging training and evaluation curves, make sure you ran wandb\nlogin. Here is an example of training the ACT policy on trajectories collected\nby humans on the Aloha simulation environment for the insertion task:\n\n    \n    \n    python lerobot/scripts/train.py \\ policy=act \\ env=aloha \\ env.task=AlohaInsertion-v0 \\ dataset_repo_id=lerobot/aloha_sim_insertion_human\n\nThe experiment directory is automatically generated and will show up in yellow\nin your terminal. It looks like\noutputs/train/2024-05-05/20-21-12_aloha_act_default. You can manually specify\nan experiment directory by adding this argument to the train.py python\ncommand:\n\n    \n    \n    hydra.run.dir=your/new/experiment/dir\n\nA link to the wandb logs for the run will also show up in yellow in your\nterminal. Here is an example of logs from wandb:\n\nYou can deactivate wandb by adding these arguments to the train.py python\ncommand:\n\n    \n    \n    wandb.disable_artifact=true \\ wandb.enable=false\n\nNote: For efficiency, during training every checkpoint is evaluated on a low\nnumber of episodes. After training, you may want to re-evaluate your best\ncheckpoints on more episodes or change the evaluation settings. See python\nlerobot/scripts/eval.py --help for more instructions.\n\n## Contribute\n\nIf you would like to contribute to \ud83e\udd17 LeRobot, please check out our\ncontribution guide.\n\n### Add a new dataset\n\nTo add a dataset to the hub, you need to login using a write-access token,\nwhich can be generated from the Hugging Face settings:\n\n    \n    \n    huggingface-cli login --token ${HUGGINGFACE_TOKEN} --add-to-git-credential\n\nThen move your dataset folder in data directory (e.g. data/aloha_ping_pong),\nand push your dataset to the hub with:\n\n    \n    \n    python lerobot/scripts/push_dataset_to_hub.py \\ --data-dir data \\ --dataset-id aloha_ping_ping \\ --raw-format aloha_hdf5 \\ --community-id lerobot\n\nSee python lerobot/scripts/push_dataset_to_hub.py --help for more\ninstructions.\n\nIf your dataset format is not supported, implement your own in\nlerobot/common/datasets/push_dataset_to_hub/${raw_format}_format.py by copying\nexamples like pusht_zarr, umi_zarr, aloha_hdf5, or xarm_pkl.\n\n### Add a pretrained policy\n\nOnce you have trained a policy you may upload it to the Hugging Face hub using\na hub id that looks like ${hf_user}/${repo_name} (e.g.\nlerobot/diffusion_pusht).\n\nYou first need to find the checkpoint located inside your experiment directory\n(e.g. outputs/train/2024-05-05/20-21-12_aloha_act_default/checkpoints/002500).\nIt should contain:\n\n  * config.json: A serialized version of the policy configuration (following the policy's dataclass config).\n  * model.safetensors: A set of torch.nn.Module parameters, saved in Hugging Face Safetensors format.\n  * config.yaml: A consolidated Hydra training configuration containing the policy, environment, and dataset configs. The policy configuration should match config.json exactly. The environment config is useful for anyone who wants to evaluate your policy. The dataset config just serves as a paper trail for reproducibility.\n\nTo upload these to the hub, run the following:\n\n    \n    \n    huggingface-cli upload ${hf_user}/${repo_name} path/to/checkpoint/dir\n\nSee eval.py for an example of how other people may use your policy.\n\n### Improve your code with profiling\n\nAn example of a code snippet to profile the evaluation of a policy:\n\n    \n    \n    from torch.profiler import profile, record_function, ProfilerActivity def trace_handler(prof): prof.export_chrome_trace(f\"tmp/trace_schedule_{prof.step_num}.json\") with profile( activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], schedule=torch.profiler.schedule( wait=2, warmup=2, active=3, ), on_trace_ready=trace_handler ) as prof: with record_function(\"eval_policy\"): for i in range(num_episodes): prof.step() # insert code to profile, potentially whole body of eval_policy function\n\n## Citation\n\nIf you want, you can cite this work with:\n\n    \n    \n    @misc{cadene2024lerobot, author = {Cadene, Remi and Alibert, Simon and Soare, Alexander and Gallouedec, Quentin and Zouitine, Adil and Wolf, Thomas}, title = {LeRobot: State-of-the-art Machine Learning for Real-World Robotics in Pytorch}, howpublished = \"\\url{https://github.com/huggingface/lerobot}\", year = {2024} }\n\n## About\n\n\ud83e\udd17 LeRobot: State-of-the-art Machine Learning for Real-World Robotics in\nPytorch\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\n### Code of conduct\n\nCode of conduct\n\nActivity\n\nCustom properties\n\n### Stars\n\n112 stars\n\n### Watchers\n\n15 watching\n\n### Forks\n\n3 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Contributors 6\n\n## Languages\n\n  * Python 98.7%\n  * Other 1.3%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": true}
