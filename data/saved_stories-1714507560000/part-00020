{"aid": "40208834", "title": "Ace Zero \u2013 Posing of Image Collections via Incremental Learning of a Relocalizer", "url": "https://nianticlabs.github.io/acezero/", "domain": "nianticlabs.github.io", "votes": 1, "user": "zadamzen", "posted_at": "2024-04-30 09:17:29", "comments": 0, "source_title": "Scene Coordinate Reconstruction: Posing of Image Collections via Incremental Learning of a Relocalizer", "source_text": "ACE Zero\n\n# Scene Coordinate Reconstruction\n\n### Posing of Image Collections via Incremental Learning of a Relocalizer\n\n###### Eric Brachmann^1 Jamie Wynn^1 Shuai Chen^2 Tommaso Cavallari^1 \u00c1ron\nMonszpart^1 Daniyar Turmukhambetov^1 Victor Adrian Prisacariu^1,2\n\n^1Niantic ^2University of Oxford\n\narXiv Video Code (soon) BibTeX\n\n### Abstract\n\nWe address the task of estimating camera parameters from a set of images\ndepicting a scene. Popular feature-based structure-from-motion (SfM) tools\nsolve this task by incremental reconstruction: they repeat triangulation of\nsparse 3D points and registration of more camera views to the sparse point\ncloud. We re-interpret incremental structure-from-motion as an iterated\napplication and refinement of a visual relocalizer, that is, of a method that\nregisters new views to the current state of the reconstruction. This\nperspective allows us to investigate alternative visual relocalizers that are\nnot rooted in local feature matching. We show that scene coordinate\nregression, a learning-based relocalization approach, allows us to build\nimplicit, neural scene representations from unposed images. Different from\nother learning-based reconstruction methods, we do not require pose priors nor\nsequential inputs, and we optimize efficiently over thousands of images. Our\nmethod, ACE0 (ACE Zero), estimates camera poses to an accuracy comparable to\nfeature-based SfM, as demonstrated by novel view synthesis.\n\n### Watch a 3-minute overview video\n\n### Watch ACE Zero reconstruct some scenes\n\nWe visualize the reconstruction process of ACE Zero for some of the scenes\nform our experiments. During each reconstruction, we show the point cloud\nextracted from the current implicit scene model. At the end of each\nreconstruction, we switch to a point cloud extracted from a Nerfacto model\ntrained on top of the ACE Zero camera poses. Use the controls to switch\nbetween scenes.\n\n##### Mip-NeRF 360 - Garden\n\n##### 7-Scenes - Fire\n\n##### Tanks and Temples - Ignatius\n\n##### Mip-NeRF 360 - Bonsai\n\n##### 7-Scenes - Pumpkin\n\n##### Tanks and Temples - Truck\n\n##### Mip-NeRF 360 - Counter\n\n##### 7-Scenes - Chess\n\n##### Tanks and Temples - Family\n\n##### Mip-NeRF 360 - Kitchen\n\n### How does ACE Zero work?\n\nTop left: We loop between learning a reconstruction from the current set of\nimages and poses (\"neural mapping\"), and estimating poses of more images\n(\"relocalization\"). Top right During the mapping stage, we train an ACE scene\ncoordinate regression network as our scene representation. Camera poses of the\nlast relocalization round and camera calibration parameters are refined during\nthis process. We visualize scene coordinates by mapping XYZ to the RGB cube.\nBottom: In the relocalization stage, we re-estimate poses of images using the\nscene coordinate regression network, including images that were previously not\nregistered to the reconstruction. If the registration of an image succeeds, it\nwill be used in the next iteration of the mapping stage; otherwise it will\nnot.\n\n### ACE Zero poses allow for novel view synthesis\n\nWe showcase the robustness of ACE Zero, and the accuracy of its estimated\nposes, via novel view synthesis. In particular, we reconstruct a scene using\nACE Zero, and then train a Nerfacto model on top of the final camera pose\nestimates. Novel view synthesis is also the foundation of the quantitative\nbenchmark in our paper.\n\n### ACE Zero compares favourably to previous SfM approaches\n\nWe compare ACE Zero to previous learning-based SfM approaches via novel view\nsynthesis. NoPe-NeRF needs a long time to converge. We run it on 200 images\nper scene which still takes two days per scene. DUSt3R quickly runs out of GPU\nmemory. We were able to run it with 50 frames per scene on a A100 GPU (40GB).\nACE Zero can process multiple thousand images per scene efficiently, in terms\nof time and memory.\n\nACE Zero estimates poses very similar to COLMAP. We show COLMAP poses (for\nTanks & Temples and Mip-NeRF 360) and KinectFusion (for 7-Scenes) in orange\nand ACE Zero poses in green.\n\nACE Zero offers attractive running times while enabling view synthesis quality\ncomparable to COLMAP.\n\n### Please consider citing our paper\n\n    \n    \n    @inproceedings{brachmann2024acezero, title={Scene Coordinate Reconstruction: Posing of Image Collections via Incremental Learning of a Relocalizer}, author={Brachmann, Eric and Wynn, Jamie and Chen, Shuai and Cavallari, Tommaso and Monszpart, {\\'{A}}ron and Turmukhambetov, Daniyar and Prisacariu, Victor Adrian}, booktitle={arXiv}, year={2024}, }\n\n", "frontpage": false}
