{"aid": "40092687", "title": "Dynamic Typography: Bringing Text to Life via Video Diffusion Prior", "url": "https://animate-your-word.github.io/demo/", "domain": "animate-your-word.github.io", "votes": 7, "user": "GaggiX", "posted_at": "2024-04-19 22:36:53", "comments": 0, "source_title": "\ud83e\ude84 animate your word!", "source_text": "\ud83e\ude84 animate your word!\n\n# Dynamic Typography: Bringing Text to Life via Video Diffusion Prior\n\nZichen Liu^*,1,\n\nYihao Meng^*,1,\n\nHao Ouyang^1,\n\nYue Yu^1,\n\nBolin Zhao^1,\n\nDaniel Cohen-Or^2,\n\nHuamin Qu^1\n\n^1 Hong Kong University of Science and Technology, ^2 Tel-Aviv University\n\n^* indicates equal contribution\n\npapercode\n\n\ud83c\udfb5 We recommend watching the video with sound on \ud83c\udfb5\n\n## Abstract\n\nText animation serves as an expressive medium, transforming static\ncommunication into dynamic experiences by infusing words with motion to evoke\nemotions, emphasize meanings, and construct compelling narratives. Crafting\nanimations that are semantically aware poses significant challenges, demanding\nexpertise in graphic design and animation. We present an automated text\nanimation scheme, termed \u201cDynamic Typography,\u201d which combines two challenging\ntasks. It deforms letters to convey semantic meaning and infuses them with\nvibrant movements based on user prompts. Our technique harnesses vector\ngraphics representations and an end-to-end optimization-based framework. This\nframework employs neural displacement fields to convert letters into base\nshapes and applies per-frame motion, encouraging coherence with the intended\ntextual concept. Shape preservation techniques and perceptual loss\nregularization are employed to maintain legibility and structural integrity\nthroughout the animation process. We demonstrate the generalizability of our\napproach across various text-to-video models and highlight the superiority of\nour end-to-end methodology over baseline methods, which might comprise\nseparate tasks. Through quantitative and qualitative evaluations, we\ndemonstrate the effectiveness of our framework in generating coherent text\nanimations that faithfully interpret user prompts while maintaining\nreadability.\n\n## Gallery\n\n* Click to play the gif\n\nROMANTIC\n\nA couple is walking hand in hand, with the girl following the boy\n\nPASSION\n\nTwo people kiss each other, one holding the others chin with his hand\n\nFIRE\n\nTwo soldiers are firing their guns, one standing and one crouching\n\nCAMEL\n\nA camel walks steadily across the desert\n\nTELESCOPE\n\nA hand holding a monocular telescope turns towards the camera\n\nKNIGHT\n\nA knight draws his sword, pointing it forward, ready for battle\n\nBUTTERFLY\n\nA butterfly is flying sideways and waves its two wings\n\nDANGEROUS\n\nA dangerous monster opens its mouth, ready to swallow someone\n\nfather\n\nA tall father walks along the road, holding his little son with his hand\n\nSWAN\n\nA fat swan is swimming elegantly and stretching its neck on the water\n\nHARMONY\n\nTwo men shaking hands with each other in a friendly manner\n\nGYM\n\nA man doing exercise by lifting two dumbbells in both hands\n\nLOVE\n\nA large and a small hand together make a heart shape\n\nJET\n\nThree jet planes are flying in formation side by side.\n\nLIFT\n\nA man doing Dumbbell Lateral Raise\n\nhide\n\nA child playing hide and seek peeks their head out from the side of a wall\n\nQUERY\n\nA hand holding a magnifying glass is searching around\n\nVICTORY\n\nA man raises his arm and shouts in celebration of victory\n\nLEG\n\nA leg standing on the ground\n\nJAZZ\n\nA pair of hands is playing the saxophone\n\n## Why SVG?\n\nSVG is resolution-independent, allowing for clear scaling at any resolution.\nIt is easily editable, enabling dynamic changes to graphic attributes like\nline colors, widths, and styles, enhancing interactivity and personalization.\n\n\ud83d\udd0d Get closer - zoom infinitely into this SVG\n\n## Playground\n\nFill\n\nFill Color - start\n\n#FFB600\n\nFill Color - end\n\n#FF9E00\n\nStroke\n\nStroke Color\n\n#000000\n\nStroke Width\n\nStroke Dashed\n\n\ud83e\ude84 You can freely adjust the SVG to create your own animation!\n\n## How does it work?\n\nThe original input letter is initialized as a set of connected cubic B\u00e9zier\ncurves, represented by a set of control points. Our method predicts a\ndisplacement for each control point at each frame.\n\nA overview of the model architecture. Given a letter represented as a set of\ncontrol points, the Base Field deforms it to the shared base shape, setting\nthe stage to add per-frame displacement. Then we duplicate the base shape\nacross k frames and utilize the Motion Field to predict displacements for each\ncontrol point at each frame, infusing movement to the base shape. Every frame\nis then rendered by the differentiable rasterizer R and concatenated as the\noutput video. The base and motion field are jointly optimized by the video\nprior (L_SDS ) from frozen pre-trained video foundation model using Score\nDistillation Sampling, under regularization on legibility L_legibility and\nstructure preservation L_structure.\n\n## Comparison\n\nWe compare our method with three baseline models: two pixel-based models( t2v\nmodel Gen-2, i2v model DynamiCrafter) and one vector-based animation\nmodel(LiveSketch). For text-to-video generation, we append the prompt with\n\u201cwhich looks like a letter \u00a7,\u201d where \u00a7 represents the specific letter to be\nanimated. In the image-to-video case, we use the stylized letter generated by\nthe word-as-image as the conditioning image. Within the vector-based scenario,\nwe utilize LiveSketch as a framework to animate vector images. To ensure a\nfair comparison, we condition the animation on the stylized letter generated\nby the word-as-image as well\n\nA hand holding a monocular telescope turns towards the camera\n\ninput\n\nGen-2\n\nDynamiCrafter\n\nLiveSketch\n\nOurs\n\nA camel walks steadily across the desert\n\ninput\n\nGen-2\n\nDynamiCrafter\n\nLiveSketch\n\nOurs\n\nA man doing exercise by lifting two dumbbells in both hands\n\ninput\n\nGen-2\n\nDynamiCrafter\n\nLiveSketch\n\nOurs\n\nTwo people kiss each other, one holding the others chin with his hand\n\ninput\n\nGen-2\n\nDynamiCrafter\n\nLiveSketch\n\nOurs\n\nA fat swan is swimming elegantly and stretching its neck on the water\n\ninput\n\nGen-2\n\nDynamiCrafter\n\nLiveSketch\n\nOurs\n\nA hand holding a monocular telescope turns towards the camera\n\ninput\n\nGen-2\n\nDynamiCrafter\n\nLiveSketch\n\nOurs\n\nA camel walks steadily across the desert\n\ninput\n\nGen-2\n\nDynamiCrafter\n\nLiveSketch\n\nOurs\n\nA man doing exercise by lifting two dumbbells in both hands\n\ninput\n\nGen-2\n\nDynamiCrafter\n\nLiveSketch\n\nOurs\n\nTwo people kiss each other, one holding the others chin with his hand\n\ninput\n\nGen-2\n\nDynamiCrafter\n\nLiveSketch\n\nOurs\n\nA fat swan is swimming elegantly and stretching its neck on the water\n\ninput\n\nGen-2\n\nDynamiCrafter\n\nLiveSketch\n\nOurs\n\nA hand holding a monocular telescope turns towards the camera\n\ninput\n\nGen-2\n\nDynamiCrafter\n\nLiveSketch\n\nOurs\n\n## Bibtex\n\n    \n    \n    @article{liu2024dynamic, title={Dynamic Typography: Bringing Text to Life via Video Diffusion Prior}, author={Zichen Liu and Yihao Meng and Hao Ouyang and Yue Yu and Bolin Zhao and Daniel Cohen-Or and Huamin Qu}, year={2024}, eprint={2404.11614}, archivePrefix={arXiv}, primaryClass={cs.CV}}\n\nThis website is licensed under a Creative Commons Attribution-ShareAlike 4.0\nInternational License.\n\nYou are welcome to use the source code of this website, but we kindly request\nthat you provide a link back to this page in the footer. Please remember to\nremove any analytics code from the header that you do not wish to include on\nyour own website.\n\n", "frontpage": true}
