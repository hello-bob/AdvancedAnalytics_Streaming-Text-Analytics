{"aid": "40070515", "title": "Feds appoint \"AI doomer\" to run US AI safety institute", "url": "https://arstechnica.com/tech-policy/2024/04/feds-appoint-ai-doomer-to-run-us-ai-safety-institute/", "domain": "arstechnica.com", "votes": 7, "user": "notamy", "posted_at": "2024-04-17 22:00:25", "comments": 0, "source_title": "Feds appoint \u201cAI doomer\u201d to run US AI safety institute", "source_text": "Feds appoint \u201cAI doomer\u201d to run US AI safety institute | Ars Technica\n\nSkip to main content\n\nSubscribe\n\nClose\n\n### Navigate\n\n  * Store\n  * Subscribe\n  * Videos\n  * Features\n  * Reviews\n\n  * RSS Feeds\n  * Mobile Site\n\n  * About Ars\n  * Staff Directory\n  * Contact Us\n\n  * Advertise with Ars\n  * Reprints\n\n### Filter by topic\n\n  * Biz & IT\n  * Tech\n  * Science\n  * Policy\n  * Cars\n  * Gaming & Culture\n  * Store\n  * Forums\n\n### Settings\n\nFront page layout\n\nGrid\n\nList\n\nSite theme\n\nlight\n\ndark\n\nSign in\n\n#### Confronting doom \u2014\n\n# Feds appoint \u201cAI doomer\u201d to run US AI safety institute\n\n## Former OpenAI researcher once predicted a 50 percent chance of AI killing\nall of us.\n\nAshley Belanger - 4/17/2024, 8:30 PM\n\nEnlarge\n\nBill Oxford | iStock / Getty Images Plus\n\n#### reader comments\n\n39\n\nThe US AI Safety Institute\u2014part of the National Institute of Standards and\nTechnology (NIST)\u2014has finally announced its leadership team after much\nspeculation.\n\nAppointed as head of AI safety is Paul Christiano, a former OpenAI researcher\nwho pioneered a foundational AI safety technique called reinforcement learning\nfrom human feedback (RLHF), but is also known for predicting that \"there's a\n50 percent chance AI development could end in 'doom.'\" While Christiano's\nresearch background is impressive, some fear that by appointing a so-called\n\"AI doomer,\" NIST may be risking encouraging non-scientific thinking that many\ncritics view as sheer speculation.\n\nThere have been rumors that NIST staffers oppose the hiring. A controversial\nVentureBeat report last month cited two anonymous sources claiming that,\nseemingly because of Christiano's so-called \"AI doomer\" views, NIST staffers\nwere \"revolting.\" Some staff members and scientists allegedly threatened to\nresign, VentureBeat reported, fearing \"that Christiano\u2019s association\" with\neffective altruism and \"longtermism could compromise the institute\u2019s\nobjectivity and integrity.\"\n\nNIST's mission is rooted in advancing science by working to \"promote US\ninnovation and industrial competitiveness by advancing measurement science,\nstandards, and technology in ways that enhance economic security and improve\nour quality of life.\" Effective altruists believe in \"using evidence and\nreason to figure out how to benefit others as much as possible\u201d and\nlongtermists that \"we should be doing much more to protect future\ngenerations,\" both of which are more subjective and opinion-based.\n\nOn the Bankless podcast, Christiano shared his opinions last year that\n\"there's something like a 10\u201320 percent chance of AI takeover\" that results in\nhumans dying, and \"overall, maybe you're getting more up to a 50-50 chance of\ndoom shortly after you have AI systems that are human level.\"\n\nAdvertisement\n\n\"The most likely way we die involves\u2014not AI comes out of the blue and kills\neveryone\u2014but involves we have deployed a lot of AI everywhere... [And] if for\nsome reason, God forbid, all these AI systems were trying to kill us, they\nwould definitely kill us,\u201d Christiano said.\n\nCritics of so-called \"AI doomers\" have warned that focusing on any potentially\noverblown talk of hypothetical killer AI systems or existential AI risks may\nstop humanity from focusing on current perceived harms from AI, including\nenvironmental, privacy, ethics, and bias issues. Emily Bender, a University of\nWashington professor of computation linguistics who has warned about AI\ndoomers thwarting important ethical work in the field, told Ars that because\n\"weird AI doomer discourse\" was included in Joe Biden's AI executive order,\n\"NIST has been directed to worry about these fantasy scenarios\" and \"that's\nthe underlying problem\" leading to Christiano's appointment.\n\n\"I think that NIST probably had the opportunity to take it a different\ndirection,\" Bender told Ars. \"And it's unfortunate that they didn't.\"\n\nAs head of AI safety, Christiano will seemingly have to monitor for current\nand potential risks. He will \"design and conduct tests of frontier AI models,\nfocusing on model evaluations for capabilities of national security concern,\"\nsteer processes for evaluations, and implement \"risk mitigations to enhance\nfrontier model safety and security,\" the Department of Commerce's press\nrelease said.\n\nChristiano has experience mitigating AI risks. He left OpenAI to found the\nAlignment Research Center (ARC), which the Commerce Department described as \"a\nnonprofit research organization that seeks to align future machine learning\nsystems with human interests by furthering theoretical research.\" Part of\nARC's mission is to test if AI systems are evolving to manipulate or deceive\nhumans, ARC's website said. ARC also conducts research to help AI systems\nscale \"gracefully.\"\n\nAdvertisement\n\nBecause of Christiano's research background, some people think he is a good\nchoice to helm the safety institute, such as Divyansh Kaushik, an associate\ndirector for emerging technologies and national security at the Federation of\nAmerican Scientists. On X (formerly Twitter), Kaushik wrote that the safety\ninstitute is designed to mitigate chemical, biological, radiological, and\nnuclear risks from AI, and Christiano is \u201cextremely qualified\u201d for testing\nthose AI models. Kaushik cautioned, however, that \"if there\u2019s truth to NIST\nscientists threatening to quit\" over Christiano's appointment, \"obviously that\nwould be serious if true.\"\n\nThe Commerce Department does not comment on its staffing, so it's unclear if\nanyone actually resigned or plans to resign over Christiano's appointment.\nSince the announcement was made, Ars was not able to find any public\nannouncements from NIST staffers suggesting that they might be considering\nstepping down.\n\nIn addition to Christiano, the safety institute's leadership team will include\nMara Quintero Campbell, a Commerce Department official who led projects on\nCOVID response and CHIPS Act implementation, as acting chief operating officer\nand chief of staff. Adam Russell, an expert focused on human-AI teaming,\nforecasting, and collective intelligence, will serve as chief vision officer.\nRob Reich, a human-centered AI expert on leave from Stanford University, will\nbe a senior advisor. And Mark Latonero, a former White House global AI policy\nexpert who helped draft Biden's AI executive order, will be head of\ninternational engagement.\n\n\"To safeguard our global leadership on responsible AI and ensure we\u2019re\nequipped to fulfill our mission to mitigate the risks of AI and harness its\nbenefits, we need the top talent our nation has to offer,\" Gina Raimondo, US\nSecretary of Commerce, said in the press release. \"That is precisely why we\u2019ve\nselected these individuals, who are the best in their fields, to join the US\nAI Safety Institute executive leadership team.\"\n\nVentureBeat's report claimed that Raimondo directly appointed Christiano.\n\nBender told Ars that there's no advantage to NIST including \"doomsday\nscenarios\" in its research on \"how government and non-government agencies are\nusing automation.\"\n\n\"The fundamental problem with the AI safety narrative is that it takes people\nout of the picture,\" Bender told Ars. \"But the things we need to be worrying\nabout are what people do with technology, not what technology autonomously\ndoes.\"\n\n### Ars Video\n\n### How Lighting Design In The Callisto Protocol Elevates The Horror\n\n#### reader comments\n\n39\n\nAshley Belanger Ashley is a senior policy reporter for Ars Technica, dedicated\nto tracking social impacts of emerging policies and new technologies. She is a\nChicago-based journalist with 20 years of experience.\n\nAdvertisement\n\n### Channel Ars Technica\n\n#### SITREP: F-16 replacement search a signal of F-35 fail?\n\nFootage courtesy of Dvids, Boeing, and The United States Navy.\n\n  * ##### SITREP: F-16 replacement search a signal of F-35 fail?\n\n  * ##### Sitrep: Boeing 707\n\n  * ##### The F-35's next tech upgrade\n\n  * ##### US Navy Gets an Italian Accent\n\n  * ##### SITREP: DOD Resets Ballistic Missile Interceptor program\n\n  * ##### SITREP: DOD's New Long-Range Air-to-Air Missile Aims to \"Outstick\" China\n\n  * ##### Army's New Pistol Has Had Some Misfires\n\n  * ##### Army's Next (Vertical) Lift En Route\n\n  * ##### SITREP: President Trump's Missile Defense Strategy\n\n  * ##### Hybrid Options for US's Next Top Fighter\n\n  * ##### The Air Force\u2019s Senior Citizen Chopper Can\u2019t Retire Yet\n\n  * ##### Ars Live #23: The History and Future of Tech Law\n\n  * ##### Police re-creation of body camera evidence - Pueblo, CO | Ars Technica\n\n  * ##### Visual Labs body camera software with the Dos Palos PD | Ars Technica\n\n  * ##### He knew his rights; he got tased anyway\n\nMore videos\n\n\u2190 Previous story Next story \u2192\n\n### Related Stories\n\n### Today on Ars\n\nCNMN Collection WIRED Media Group \u00a9 2024 Cond\u00e9 Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 1/1/20) and Privacy Policy and Cookie Statement (updated 1/1/20) and Ars Technica Addendum (effective 8/21/2018). Ars may earn compensation on sales from links on this site. Read our affiliate link policy. Your California Privacy Rights | Manage Preferences The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond\u00e9 Nast. Ad Choices\n\n## We Care About Your Privacy\n\nWe and our 167 partners store and/or access information on a device, such as\nunique IDs in cookies to process personal data. You may accept or manage your\nchoices by clicking below or at any time in the privacy policy page. These\nchoices will be signaled to our partners and will not affect browsing\ndata.More information about your privacy\n\n### We and our partners process data to provide:\n\nUse precise geolocation data. Actively scan device characteristics for\nidentification. Store and/or access information on a device. Personalised\nadvertising and content, advertising and content measurement, audience\nresearch and services development.\n\n", "frontpage": true}
