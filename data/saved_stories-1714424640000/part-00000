{"aid": "40199220", "title": "A Quick Guide to the AIpocalypse", "url": "https://beabytes.com/guide-aipocalypse/", "domain": "beabytes.com", "votes": 1, "user": "beabytes", "posted_at": "2024-04-29 15:02:08", "comments": 0, "source_title": "A Quick Guide to the AIpocalypse", "source_text": "A Quick Guide to the AIpocalypse\n\nB\u00e9atrice Moissinac, PhD Hello, world! \ud83d\udc4b Welcome to BeaBytes. My goal is to\nhelp you understand AI and equip you with enough conceptual (but not\ntechnical) fluency to fight off the snake oil merchants. I reserve the right\nto change my mind at any time.\n\ncontact -at- beabytes -dot- com\n\n  * Blog\n  * About\n  * Talks\n\n\u00a9 2013-2024 B\u00e9atrice Moissinac, all rights reserved. Any opinions, findings,\nand conclusions or recommendations expressed in this material are those of the\nauthor(s) and do not necessarily reflect the views of my employer or sponsors.\n\n# A Quick Guide to the AIpocalypse\n\nArtificial Intelligence (AI) is now ubiquitous in our daily life, and we have\nbecome - willingly or unwillingly - guinea pigs \ud83d\udc39. In the future, the\nAIpocalypse may yet be an action-packed fight against the Terminator, but for\nnow, it is something closer to a boring dystopia \u00e0 la 1984.\n\n\ud83e\udd16 \ud83d\udc80\n\nIn this article, I introduce the notions of AI risk, AI harm, and AI threat,\nand present recent examples of harmful AI. I also point at a few resources to\nkeep you informed and safe \ud83d\udc40.\n\n# The Risk, The Harm, and the ugly Threat\n\n## AI Risk\n\nAn AI risk is everything that can go wrong - knowingly or unknowingly - about\nor because of a model, at any point in the designing/training/production\npipeline of an AI system. IBM has heavily invested in AI Governance, and\ncreated this wonderfully terrifying AI Risk Atlas. This is similar to the\nMitre CVE classification, which catalogs cybersecurity vulnerabilities.\nCataloging risks is a crucial step in alleviating and mitigating risks. \u201cKnow\nThy Enemy\u201d.\n\n## AI Harm\n\nAn AI harm is an harmful or near harmful consequence of the deployment and\nusage of an AI system. The collection and cataloging of harms is a well-\nestablished (and legally required) practice in aviation all around the world.\n\n> A common saying in aviation: Regulations are written in blood. \u2708\ufe0f \ud83e\ude78\n\nFortunately, lack of AI regulations has not stopped open-source efforts from\ncoalescing. For instance, the AI incident Database is actively cataloging\nincidents, but their reach is limited to what is publicly published. Looking\nback on what the history of the aviation industry taught us, UL Digital Safety\nResearch Institute\u2019s Director, Dr. Sean McGregor is advocating for more open\ndigital safety standards:\n\n> Failing to share insights with competitors for how to save lives is a moral\n> failing and not possible in modern aviation.\n\nCybersecurity has CVE, aviation has agencies like the american FAA or the\nFrench BEA. We need the same for AI before too much blood is spilled.\n\n## AI Threat\n\nAn AI threat is a threat caused by the malicious use of AI. AI threats have\nexponentially exploded with generativeAI, by lowering the barrier of access,\nand the cost of cyber attacks. OWASP, a leading open-source cybersecurity\ncommunity which - among other things -focuses on identifying top threats, has\nidentified 10 possible threats for LLMs models. Gone are the days where you\ncould spot phishing by looking for typos and weird English. Now, attackers are\nusing LLM-backed ChatBots to phish and spear phish. Furthermore, Deep Fakes\npose a real danger to consumers, citizens, and public institutions.\n\n# The Boring AI Dystopia\n\n## Unfair Justice System\n\nThe now famous ProPublica study on Machine Bias is one of the most notable\nwork on harmful AI of recent years and should be required reading for any\ndata-related course, as it clearly demonstrates that an AI is only as\nimpartial as its data. It describes how the justice system uses data and\nalgorithms to calculate recidivism risk, and determine sentences. In the USA,\ninstitutional racism defines the ensemble of laws, systems, practices,\npolicies, etc. that perpetrates and perpetuates discrimination toward a\nminoritized group. Thus, the data collected from this system will \u201chave\u201d\ninstitutional racism in it.\n\n> An algorithm can never be \u201cbetter\u201d than the data you feed it, it cannot\n> transcend it. I wrote an in-depth explanation of how AI \u201cthink\u201d over here.\n\nAI perpetuates the worst in our society, automatically, at scale.\n\n## Automatic Dystopia\n\nThe problem does not stop with crime statistics. Facial recognition is being\nextensively used by the US State Department, culminating to a database of 117\nmillions Americans as of 2016. I recently went through passport control\nwithout having to show my passport. This was both amazing and terrifying. Why\nterrifying? Because we are all very likely to have doppelgangers, and some of\nthem will cause you trouble. The invasion of privacy is a legitimate concerns,\nespecially in countries that have laws regarding undue search.\n\n## Algorithm Addiction\n\nSocial media algorithms, which control your social media feed, are designed to\nincrease attention and retention. Intended or not, those algorithms causes\naddictions. Compulsion, addiction, whatever you want to call it, the science\nis narrowing down on the negative effects to children, teens, and adults.\n\n## Propaganda & Misinformation\n\nThis article is written in 2024, an election year in the United States. These\nwill be interesting times. On one hand, we have social media algorithms\naddicting your attention, and perpetuating (or even favoring) misinformation.\nOn the other, we have easy access to unregulated tools that are very good at\nproducing propaganda, automatically, at scale. Researchers have raised alarms\nabout this dangerous cocktail, but public action has been limited.\n\n# The environmental cost of this blog\u2019s banner\n\nDuring the 2021-2022 winter, violent demonstrations shook Kazakhstan. These\ndemonstrations were catalyzed by the skyrocketing electricity prices. These\nprices were driven up by crypto-miners. You read that right. People mining\nBitcoin and other crypto currencies, used data centers in Kazakhstan that used\nso much electricity it caused a near-revolution.\n\nNow, consider that training a GPT model requires an estimated 10 Gigawatt-\nhours (10 millions kilowatt-hours), and that ChatGPT\u2019s daily usage is also\nestimated at 1 Gigawatt-hours. The average US household consumes 0.010\ngigawatt-hours per year.\n\nIn addition of the societal risks imposed on poorer countries with unregulated\nelectricity grids, the carbon-cost of generative AI is indecent. How can we\njustify this, in a century where temperatures are expected to rise 2 to 4\ndegree Celsius and displace 3 *billion people.\n\nI really like this article -> Is it worth it?.\n\nAI technology has contribution to make, especially in fighting climate change.\nThis is not unsolvable. Innovations on reducing computational needs pre-date\ngenerative AI, and regulations would help.\n\n# Terminator\n\nIn 2017, I attended the inaugural speech of Dr. Dietterich as President of the\nAssociation for the Advancement of Artificial Intelligence (AAAI). AAAI is one\nof the main scientific society to research, develop, and promote AI. In his\nspeech, Dr. Dietterich said:\n\n> The final high-stakes application that I wish to discuss is autonomous\n> weaponry. Unlike all of the other applications I\u2019ve discussed, offensive\n> autonomous weapons are designed to inflict damage and kill people. These\n> systems have the potential to transform military tactics by greatly speeding\n> up the tempo of the battlefield. [...] My view is that until we can provide\n> strong robustness guarantees for the combined human-robot system, we should\n> not deploy autonomous weapons systems on the battlefield. I believe that a\n> treaty banning such weapons would be a safer course for humanity to follow.\n\nWeaponized AI exists, and is well on its way to be integrated in our daily\nlives. It will seem innocuous at first, but it is advancing even if\n\u201chypothetically\u201d.\n\n\ud83e\udd16 \ud83d\udc80\n\n", "frontpage": false}
