{"aid": "40129915", "title": "Metrics for bias in machine learning datasets", "url": "https://github.com/irisdominguez/Dataset_Bias_Metrics", "domain": "github.com/irisdominguez", "votes": 1, "user": "iris_dominguez", "posted_at": "2024-04-23 08:56:10", "comments": 0, "source_title": "GitHub - irisdominguez/Dataset_Bias_Metrics: Python package with a collection dataset demographic bias metrics", "source_text": "GitHub - irisdominguez/Dataset_Bias_Metrics: Python package with a collection\ndataset demographic bias metrics\n\n## Navigation Menu\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nirisdominguez / Dataset_Bias_Metrics Public\n\n  * Notifications\n  * Fork 0\n  * Star 1\n\nPython package with a collection dataset demographic bias metrics\n\n### License\n\nMIT license\n\n1 star 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# irisdominguez/Dataset_Bias_Metrics\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n1 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nirisdominguezWhite background on readme imagesApr 23, 2024a70bdc2 \u00b7 Apr 23,\n2024Apr 23, 2024\n\n## History\n\n5 Commits  \n  \n### dataset_bias_metrics\n\n|\n\n### dataset_bias_metrics\n\n| Initial commit| Feb 21, 2023  \n  \n### docs\n\n|\n\n### docs\n\n| Initial commit| Feb 21, 2023  \n  \n### example_data\n\n|\n\n### example_data\n\n| Initial commit| Feb 21, 2023  \n  \n### images\n\n|\n\n### images\n\n| White background on readme images| Apr 23, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Initial commit| Feb 21, 2023  \n  \n### LICENSE.txt\n\n|\n\n### LICENSE.txt\n\n| Initial commit| Feb 21, 2023  \n  \n### more_examples.ipynb\n\n|\n\n### more_examples.ipynb\n\n| Initial commit| Feb 21, 2023  \n  \n### readme.ipynb\n\n|\n\n### readme.ipynb\n\n| Initial commit| Feb 21, 2023  \n  \n### readme.md\n\n|\n\n### readme.md\n\n| Update link to paper in readme.md| Apr 23, 2024  \n  \n### setup.cfg\n\n|\n\n### setup.cfg\n\n| Update setup.cfg| Mar 28, 2023  \n  \n### setup.py\n\n|\n\n### setup.py\n\n| Initial commit| Feb 21, 2023  \n  \n## Repository files navigation\n\n# Dataset demographic bias metrics\n\nThis package implements several metrics for dataset demographic bias. The\nmetrics are organized as follows:\n\n  * Representational bias metrics (dataset_bias_metrics.representational)\n  * Stereotypical bias metrics at the global level (dataset_bias_metrics.stereotypical)\n  * Stereotypical bias metrics at the local level (dataset_bias_metrics.local_stereotypical)\n  * Some visualization tools (dataset_bias_metrics.visualization)\n\nFor the details on the bias metrics included, please see our paper \"Metrics\nfor Dataset Demographic Bias: A Case Study on Facial Expression Recognition\",\navailable in the IEEE Transactions on Pattern Analysis and Machine\nIntelligence.\n\n## Installation\n\nBinary installers for the latest released version are available at the Python\nPackage Index (PyPI).\n\npip install dataset-bias-metrics\n\n## Usage\n\n### Including the libraries\n\n    \n    \n    import pandas as pd import os import dataset_bias_metrics as dbm\n\n### Loading example datasets\n\nThe .csv files available in example_data correspond to the datasets analyzed\nin the paper. Only the demographic data with no identifying information is\nprovided, and the rows are scrambled to avoid the identification of specific\nsamples.\n\n    \n    \n    datasets = {} for filename in os.listdir('example_data'): if filename.endswith(\".csv\"): ds = pd.read_csv(os.path.join('example_data', filename)) datasets[filename.split('.')[0]] = ds display(datasets['raf-db2'])\n\nage| race| gender| label  \n---|---|---|---  \n0| 20-29| Indian| Male| disgust  \n1| 20-29| White| Male| disgust  \n2| 30-39| White| Male| angry  \n3| 60-69| Southeast Asian| Female| happy  \n4| 40-49| East Asian| Male| neutral  \n...| ...| ...| ...| ...  \n15121| 30-39| White| Male| sad  \n15122| 30-39| East Asian| Male| happy  \n15123| 20-29| Black| Male| fear  \n15124| 30-39| White| Female| happy  \n15125| 20-29| White| Female| neutral  \n  \n15126 rows \u00d7 4 columns\n\n### Representational bias\n\nThe following is an example of the application of the representational bias\nmetrics:\n\n    \n    \n    # Application of a single metric dbm.representational.ens(datasets['adfes'], 'race')\n    \n    \n    2.478206948646503\n    \n    \n    # It also supports combined components dbm.representational.ens(datasets['adfes'], ['age', 'race'])\n    \n    \n    3.0404964294246533\n    \n    \n    # Comparative analysis across datasets, with visualization component = 'race' repbias = pd.DataFrame(0, index=datasets.keys(), columns=dbm.representational.metrics.keys()) for dsname, ds in datasets.items(): for metricname, m in dbm.representational.metrics.items(): repbias.loc[dsname, metricname] = m(ds, component) display(f'{component.capitalize()} component') dbm.visualization.plotTable(repbias.T, normalizeAxis=1, sort=None)\n    \n    \n    'Race component'\n\n### Stereotypical bias (global)\n\nThe following is an example of the application of the global stereotypical\nbias metrics:\n\n    \n    \n    # Application of a single metric dbm.stereotypical.cramersv(datasets['expw'], 'race', 'label')\n    \n    \n    0.04104288518527493\n    \n    \n    # Comparative analysis across datasets, with visualization c1, c2 = ('race', 'label') stereobias = pd.DataFrame(0, index=datasets.keys(), columns=dbm.stereotypical.metrics.keys()) for dsname, ds in datasets.items(): for metricname, m in dbm.stereotypical.metrics.items(): stereobias.loc[dsname, metricname] = m(ds, c1, c2) display(f'{c1.capitalize()}-{c2.capitalize()} components') dbm.visualization.plotTable(stereobias.T, normalizeAxis=1)\n    \n    \n    'Race-Label components'\n\n### Stereotypical bias (local)\n\nThe following is an example of the application of the local stereotypical bias\nmetrics:\n\n    \n    \n    # Single metric application with visualization ds = datasets['expw'] c1, c2 = ('race', 'label') matrix = dbm.local_stereotypical.duchersz(ds, c1, c2) display(f'{c1.capitalize()}-{c2.capitalize()} components, {metricname}') dbm.visualization.plotMatrix(matrix)\n    \n    \n    'Race-Label components, NMI'\n\n## About\n\nPython package with a collection dataset demographic bias metrics\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\nActivity\n\n### Stars\n\n1 star\n\n### Watchers\n\n2 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Releases 1\n\nv0.1 Latest\n\nMar 28, 2023\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * Jupyter Notebook 97.9%\n  * Python 2.1%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
