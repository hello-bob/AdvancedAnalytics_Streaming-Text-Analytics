{"aid": "40178652", "title": "The Server Chose Violence", "url": "https://cliffle.com/blog/hubris-reply-fault/", "domain": "cliffle.com", "votes": 4, "user": "lukastyrychtr", "posted_at": "2024-04-27 09:37:28", "comments": 0, "source_title": "The server chose violence", "source_text": "The server chose violence - Cliffle\n\n# Cliffle\n\nFortuna Eruditis Favet\n\n  * About Me\n  * Blog\n  * Projects\n  * Papers\n  * Food\n  * Colophon\n\nCopyright \u00a92011-2024 Cliff L. Biffle Contact \u2014 RSS\n\n# The server chose violence\n\nHubris's oddest syscall\n\n2024-04-08\n\n  * A brief overview of Hubris IPC\n  * New and exciting failure modes\n  * None of this happens in normal, correct programs\n  * The kernel is not having any of your nonsense.\n  * The server isn\u2019t having any of your nonsense, either.\n  * The joy of panicking other programs\n\nI\u2019m continuing to reflect on the past four years with Hubris \u2014 April Fool\u2019s\nDay was, appropriately enough, the fourth anniversary of the first Hubris user\nprogram, and today is the fourth anniversary of the first kernel code. (I\nwrote the user program first to help me understand what the kernel\u2019s API\nwanted to look like.)\n\nOf all of Hubris\u2019s design decisions, there\u2019s one that gets a \u201cwait what\u201d\nresponse more often than any other. It\u2019s also proving to be a critical part of\nthe system\u2019s overall robustness. In this post, I\u2019ll take a look at our 13th\nand oddest syscall, REPLY_FAULT.\n\n## A brief overview of Hubris IPC\n\nHubris uses a small, application-independent kernel, and puts most of the code\n\u2014 drivers, application logic, network stack, etc. \u2014 in separately compiled\nisolated tasks. These tasks can communicate with each other using a cross-task\nmessaging system (inter-process communication, or IPC). (This section will do\na sort of \u201cHubris in a nutshell\u201d \u2014 if you\u2019d like to learn more I recommend the\nReference Manual.)\n\nIPC in Hubris consists of three core operations, implemented in the kernel,\nwhich tasks can request using syscalls:\n\n  * RECV collects the highest priority incoming message, or blocks until one arrives.\n  * SEND stops the caller and transfers a message \u2014 and control! \u2014 to the receiving task. The caller is parked until it gets a response.\n  * REPLY delivers a response to a task that had previously used SEND, allowing it to continue.\n\nThe Hubris IPC scheme is deliberately designed to work a lot like a function\ncall, at least from the perspective of the client.\n\nWe often talk about \u201cclients\u201d and \u201cservers\u201d in Hubris, and it\u2019s worth noting\nthat these are roles tasks play. A client is just a task using SEND, and a\nserver is a task using RECV and REPLY \u2013 but they\u2019re not mutually exclusive. A\ntask may be a server to some other tasks, and simultaneously a client to\ndifferent tasks. For instance, an \u201cLED Blinker\u201d task may call (client) into a\n\u201cGPIO driver\u201d task (server), which itself may call (client) into a supervisory\ntask (server).\n\nTo underscore this point, here\u2019s a graph of the IPC flow (green arrows)\nbetween tasks (rectangles) in Oxide\u2019s production server firmware. Notice that\nalmost all tasks have arrows both coming out (client) and coming in (server).\n\n## New and exciting failure modes\n\nWhen writing a function or procedure in almost any programming language, you\nmake some assumptions about your callers\u2019 behavior. This creates preconditions\nfor calling the function. Depending on the language, some are explicit, and\nsome are implicit. In Rust, for instance, if your function takes an argument\nof type String, it\u2019s reasonable to assume your caller passes in a String and\nnot a bool.\n\nYour function has the backing of the compiler here: the caller has to pass a\ncompatible type for all arguments, or the compiler won\u2019t let them attempt to\ncall the function. It\u2019s possible to subvert this if you work at it, of course,\nbut it\u2019s hard to subvert it by accident.\n\nThe compiler and linker conspire behind the scenes to make sure that your\nprogram calls the function you intended. This ensures that you won\u2019t be\nsurprised by code that attempts to call pet_cat and winds up calling\nfire_missiles instead, except in very rare circumstances.\n\nBecause IPC crosses task boundaries, and tasks in Hubris are separately\ncompiled programs, you have to be careful making these same assumptions with\nIPC. If a client is compiled against the wrong interface, or confuses one task\nfor another, the compiler won\u2019t have any idea, since it sees only a single\nprogram at a time. In this respect, IPC acts more like communication over a\nnetwork.\n\nEvery task on Hubris that acts as an IPC server has to deal with the following\npotential errors:\n\n  * Getting a message with an operation code that isn\u2019t even appropriate for your interface, like \u201coperation number 48\u201d in a two-operation interface.\n  * Receiving an uninterpretable bag of bytes instead of the message type you were expecting \u2014 or a message that is much too short or long.\n  * Not getting the sort of loaned memory you require (e.g. you need it writable but you receive it read-only, or don\u2019t receive it at all).\n\nBut I describe those as potential errors because, in practice...\n\n## None of this happens in normal, correct programs\n\nIn a normal Hubris program, none of these things happen.\n\nTasks are connected to each other by configuration in the build system, so\nit\u2019s hard to confuse one for the other. Clients use generated Rust code to\nconstruct and send IPCs to servers, which use different generated Rust code to\nhandle the result. This lets us squint and pretend that the type system works\nacross task boundaries \u2014 it doesn\u2019t, really, but our tools produce a pretty\ngood illusion.\n\nI always hate to penalize the \u201cgood\u201d programs for error cases that they can\u2019t\nactually hit. All of the obvious ways of handling the potential but unlikely\nerrors (described above) hurt good programs.\n\nFor example: making all IPC operations return a Result<T, IpcError> where the\ngood programs can\u2019t actually hit any case in IpcError means that, in practice,\nthey\u2019ll just unwrap() it. That\u2019s a fairly large operation in terms of code\nsize \u2014 especially when we know the code will never be used! \u2014 and costs time\nat runtime to check for errors that won\u2019t happen.\n\nTo keep every client from needing to unwrap() a bazillion errors, we could put\nthe unwrap() (or more generally a panic!) into the generated code. This might\nreduce the code size impact (by centralizing the panic! in one location) but\nwon\u2019t reduce the cost at runtime.\n\nThere\u2019s also a different kind of cost: a design cost. To be able to return a\nuniversal error from any operation, and have it be understood by a caller\nattempting any other operation, we have to make rules about the message\nencoding. Every operation must be capable of returning an error, every\noperation must have a way of encoding this particular error, and the encoding\nof this error by all operations must be identical.\n\nThis means you can\u2019t express an operation that can\u2019t fail, which is\nparticularly annoying: as we\u2019ve built our firmware infrastructure on Hubris,\nwe keep finding operations that really can\u2019t fail. Setting a GPIO pin, for\nexample.\n\nSo we dearly needed an alternative to this \u201cuniversal error code\u201d approach. I\ndrew inspiration from a weird design decision I made in the Hubris kernel API:\nthe Hubris kernel is unusually aggressive.\n\n## The kernel is not having any of your nonsense.\n\nIn most operating systems, if you violate the preconditions for a system call,\nyou get a polite error code back from the kernel \u2014 or, at worst, an exception\nhandler or signal handler gets triggered. You have an opportunity to recover.\n\nTake Unix for example. If you call close on a file descriptor you never\nopened, you get an error code back. If you call open and hand it a null\npointer instead of a pathname? You get an error code back. Both of these are\nviolations of a system call\u2019s preconditions, and both are handled through the\nsame error mechanism that handles \u201cfile not found\u201d and other cases that can\nhappen in a correct program.\n\nOn Hubris, if you break a system call\u2019s preconditions, your task is\nimmediately destroyed with no opportunity to do anything else.^1\n\n^1\n\nThe application can choose to do something about it, because when any task\ntakes a fault, the application\u2019s supervisor task is notified. Typically the\nsupervisor responds by wiping the task and restarting it. But the task has no\nopportunity to do anything else.\n\nMore specifically, the kernel delivers a synthetic fault. This is very similar\nto the hardware faults that a task receives if it, say, dereferences a null\npointer, or divides by zero. Those are produced by the CPU for breaking the\nprocessor architecture\u2019s rules. Synthetic faults, on the other hand, are\nproduced by the kernel for breaking the kernel\u2019s rules.\n\nFor example, when a task calls SEND, it passes the kernel the index of the\nintended recipient task, and a pointer to some memory containing the message.\nIf the recipient task index is out of range for the application? Synthetic\nfault. If the message pointer points to memory the task doesn\u2019t actually have\naccess to? Synthetic fault.\n\nEarly in the system\u2019s design, I decided not to permit recoverable/resumable\nfaults. That is, when a program takes a fault \u2014 whether it\u2019s hardware or\nsynthetic \u2014 the task is dead. It can run no further instructions. There is no\nway to \u201cfix\u201d the problem and resume the task. This was a conscious choice to\navoid some subtle failure modes and simplify reasoning about the system.^2\n\n^2\n\nAs I mentioned in the previous footnote, the application supervisor task can\ndecide to leave the task dead, or to wipe it and restart it. I also decided to\nsupport one supervisor, not a supervisor tree like Erlang\u2019s. This prevents a\nmalicious pair of tasks from cooperating to reset one another by making one\nsupervise the other. If you want the supervisor to participate in your scheme,\nyou\u2019ll have to exploit the central well-tested supervisor task.\n\nBut combined with the kernel\u2019s habit of faulting any task that looks at it\nfunny, this makes the system\u2019s behavior very unusual compared to most\noperating systems.\n\nAnd it\u2019s been great.\n\nInitially I was concerned that I\u2019d made the kernel too aggressive, but in\npractice, this has meant that errors are caught very early in development. A\nfault is hard to miss, and literally cannot be ignored the way an error code\nmight be. Humility (our debugger) happily prints a detailed description of any\nfault it finds; in fact, one made an appearance in my last Hubris-related\npost, although in that case it was being reported in error:\n\n    \n    \n    mem fault (precise: 0x801bffd) in syscall (was: wait: reply from i2c_driver/gen0)\n\nThis is a synthetic fault that a task receives for handing the kernel a\npointer to some memory (at address 0x801bffd in this case) that the task can\u2019t\nactually access.\n\nThis behavior was so nice to use in practice, in fact, that it suggested a way\nto fix our IPC error reporting woes: generalize the same mechanism.\n\n## The server isn\u2019t having any of your nonsense, either.\n\nOnce I realized that our unusually strict kernel was actually helping\ndevelopers instead of hindering them, I was inspired to implement Hubris\u2019s\n13th and oddest syscall: REPLY_FAULT.\n\nI mentioned REPLY earlier, the mechanism servers use to respond to their\nclients. More specifically,\n\n  * When a client uses SEND the kernel marks the client\u2019s task as \u201cwaiting to send\u201d to the recipient task.\n\n  * When the recipient uses RECV, one client task \u201cwaiting to send\u201d to it is updated to \u201cwaiting for reply.\u201d The client task will remain in that state until something changes \u2014 usually, the server using REPLY.\n\n  * REPLY only works on a task marked as \u201cwaiting for reply\u201d from the specific server task that is attempting to reply. It switches the client task back into a \u201crunnable\u201d state.\n\nREPLY_FAULT is basically the same thing, except instead of delivering a\nmessage and making the task runnable, it delivers a fault and makes the task\ndead. With REPLY_FAULT, we can avoid having unnecessary error handling on IPC\noperations, because correct programs will just go on as if the problem can\u2019t\noccur \u2014 and incorrect programs won\u2019t get to handle the error at all!\n\nLike REPLY, a server can only REPLY_FAULT a task that is waiting for its\nreply. You can\u2019t use REPLY_FAULT to kill random tasks, only the set of tasks\nfrom which you have RECV\u2019d a message and not yet REPLY\u2019d.\n\nOur system now uses REPLY_FAULT to handle the three cases I mentioned earlier:\na bogus operation code; or a corrupt, truncated, or otherwise nonsensical\nmessage; or if the client doesn\u2019t send the right kind of loaned memory.\n\nBut REPLY_FAULT also provides a way to define and implement new kinds of\nerrors \u2014 application-specific errors \u2014 such as access control rules. For\ninstance, the Hubris IP stack assigns IP ports to tasks statically. If a task\ntries to mess with another task\u2019s IP port, the IP stack faults them. This gets\nus the same sort of \u201cfail fast\u201d developer experience, with the smaller and\nsimpler code that results from not handling \u201ctheoretical\u201d errors that can\u2019t\noccur in practice.\n\nLike the kernel\u2019s aggressive handling of errors in system calls, I was\ninitially concerned that REPLY_FAULT would be too extreme. After I had the\nidea, I delayed several months before starting implementation, basically\ntrying to talk myself out of it.\n\nI was being too careful. REPLY_FAULT has been great. A new developer on the\nsystem recently cited it as one of the more surprising and pleasant parts of\ndeveloping on Hubris, which is what inspired me to write this post.\n\n## The joy of panicking other programs\n\nI mentioned earlier that Hubris IPC was explicitly designed to behave like a\nRust function call from the perspective of the client.\n\nWell, if you violate the preconditions on a Rust function call, the function\nwill normally respond with a panic!.\n\nREPLY_FAULT essentially provides a way for servers to generate cross-process\npanic! in their clients, without requiring clients to contain code to do it \u2014\nor, perhaps more importantly, without requiring clients to cooperate in the\nprocess at all.\n\nOverall, this combines with some other system features to make Hubris\n\u201caggressively hostile to malicious programs,\u201d as Eliza Weissman recently\ndescribed it. Since attempts at exploitation often manifest first as errors or\nmisuse of APIs, a system that responds to any misbehavior by wiping the state\nof the misbehaving component ought to be harder to exploit. (This hypothesis\nhas yet to be tested! Please reach out to me if you\u2019re interested in trying to\nexploit Hubris. I will help!)\n\nIn practice, the only downside I\u2019ve observed from these decisions is that the\nsystem is really difficult to fuzz test. Because I like chaos engineering,\nI\u2019ve implemented a small \u201cchaos\u201d task that generates random IPCs and system\ncalls to test other components for bugs, and almost anything it does causes it\nto get immediately reset. To be useful, it has to base all of its decisions\noff the one piece of state that is observably different each time it starts:\nthe system uptime counter. (However, REPLY_FAULT does provide a way for\nservers to force chaos upon their clients by randomly killing them, an option\nI haven\u2019t fully evaluated.)\n\nBut normal Hubris tasks don\u2019t dynamically generate IPC messages, particularly\nones that are deliberately bogus. In practice, they can carry on without\nrealizing REPLY_FAULT even exists \u2014 because unless they do something really\nunusual, they will never see the business end of it anyway.\n\n#api-design #dayjob #embedded #rust #security\n\n", "frontpage": true}
