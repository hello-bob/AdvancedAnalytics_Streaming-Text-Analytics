{"aid": "40188640", "title": "Architecting ML Pipelines on Snowflake", "url": "https://www.modelbit.com/blog/a-technical-guide-to-architecting-large-ml-pipelines-on-snowflake-warehouses", "domain": "modelbit.com", "votes": 1, "user": "tadkar", "posted_at": "2024-04-28 13:58:43", "comments": 0, "source_title": "A technical guide to architecting large ML pipelines on Snowflake warehouses | The Modelbit Machine Learning Blog | Modelbit", "source_text": "A technical guide to architecting large ML pipelines on Snowflake warehouses | The Modelbit Machine Learning Blog | Modelbit\n\nSign In\n\nGet a DemoTry It Free\n\nApril 24, 2024\n\n# A technical guide to architecting large ML pipelines on Snowflake warehouses\n\nBy\n\nTom O'Neill, Co-Founder & CTO\n\nTable of Contents\n\nExpectations for our ML pipelineIn the beginning there were only External\nFunctionsThen came External AccessRunning your ML pipeline inside Snowflake\nSnowparkThe future is nighWrapping up\n\nSuggested Reads\n\nAnnouncing MLOps for Snowpark - Deploy ML Models Into Snowpark and Manage Them\nIn Production\n\nAmazon SageMaker vs Modelbit: In-depth Comparison with Code Samples\n\n9 Important Questions to Answer Before Hosting Your ML Model\n\nThank you! Your submission has been received!\n\nOops! Something went wrong while submitting the form.\n\nThere are several kinds of machine learning pipelines. Each requires different\narchitectural choices because of different expectations around latency, volume\nand environment capabilities. The constraints for serving models used in real-\ntime threat detection in video feeds are very different from those for batch\ninformation extraction across hundreds of millions of documents.\n\nThis post focuses on the latter: Large-scale batch inferences utilizing\nSnowflake. At Modelbit we\u2019ve helped many customers perform inferences on the\ndata in their Snowflake warehouses, and we\u2019ve learned a lot along the way. If\nyou\u2019re thinking about building your own ML pipeline on Snowflake, then this\npost is for you!\n\nBelow we\u2019ll share hard-learned lessons and recommendations for how you should\n(and shouldn\u2019t) build your own ML pipeline on Snowflake. And at the end we\u2019ll\nshare some predictions for where we think this technology is going and what\nthe future holds.\n\n## Expectations for our ML pipeline\n\nWhen we\u2019re talking about an ML pipeline in Snowflake, we\u2019re talking about\nsomething dbt could orchestrate. Such a pipeline would process hundreds of\nmillions of rows through dozens or more different ML models to create a\ncollection of tables containing the inference results.\n\nWhen we refer to a model, we\u2019re referring to thousands of lines of Python code\nspread across many source files, pickled artifacts, Python packages, binary\nweights and checkpoint files. It\u2019s everything you need to process the raw data\ninto an inference.\n\nFinally, the pipeline needs to be able to support GPUs. While your models\ntoday might not need them, the future of machine learning will include many\nmore use cases where GPUs are effective. Adding support for GPUs should be a\ncheckbox, not a whole second architecture.\n\nWith those expectations set, let\u2019s dive into ML pipelines in Snowflake!\n\n## In the beginning there were only External Functions\n\nRunning an ML model means running a complex Python program. Each model has\ncode and assets that are often sensitive to even small changes in the Python\nenvironment. And each model has its own set of libraries and versions it\ndepends on, often including the system packages that vary from one flavor of\nLinux to another. Containerization is the solution to this set of problems.\n\nUntil recently it wasn\u2019t reasonable to run complex Python programs, like ML\nmodels, within Snowflake. (More on that later.) The only reasonable way to run\none model, let alone dozens, was to call out from Snowflake to an ML service\nyou create and manage, like an EC2 that hosts and runs your models.\n\nSnowflake created a feature called External Functions to enable this scenario.\n\n### The ideal external function\n\nExternal functions allow you to define a SQL function that sends its arguments\nout to a service you control. Your service processes the list of rows it gets\nand returns a list of results which Snowflake consumes as if it were the\nresults of any other SQL function. You make a REST API for your ML model and\nuse external functions to call it. Simple!\n\nUnfortunately, this is a lie. External functions cannot call an arbitrary\nendpoint. They can only call authenticated AWS API Gateways (or the Azure/GCP\nequivalent) via an API integration. Calling an API Gateway from Snowflake\nmeans you also need to configure a bunch of IAM permissions and network\nplumbing. The API Gateway also needs to call something that can rapidly scale\nand respond or else it\u2019ll error. So in reality Snowflake calls an API Gateway,\nwhich then calls an AWS Lambda function, and finally the Lambda function can\ncall your ML service:\n\nWith the above setup you can call your ML service with data from Snowflake and\nget the inferences materialized into Snowflake tables.\n\n> Lesson\n\n> Data size matters. Snowflake has a limit of 16MB per cell. AWS Lambda\n> functions have a body limit of 6MB. This means it\u2019s possible there\u2019s data in\n> your warehouse that cannot be sent externally because the Lambda cannot\n> receive it. If you\u2019re trying to process 10MB documents then external\n> functions cannot support you. (So skip to the next section!)\n\n> This size limit works in reverse too. If your ML service generates a\n> response for a batch of rows that\u2019s larger than 6MB you won\u2019t be able to\n> send it back to the Lambda to send to Snowflake.\n\nIf you\u2019re still reading, you\u2019ll be disappointed to learn that this diagram is\nalso a lie! While it will work for a prototype, it will not scale to large\ndatasets. And large datasets are why we\u2019re here.\n\n### Scaling issues with external functions\n\nSnowflake offers two API modes with their external functions. The default is a\nsynchronous API that\u2019s easy to work with: When a request comes in, your\nservice processes it and returns the response like any REST API. However there\nare two big problems with the synchronous API.\n\nThe first is timeouts. The Snowflake query calling the external function can\nrun as long as you\u2019d like, but the API Gateway has a timeout of 30 seconds\nthat cannot be changed. If your model runs in 30s, you may think you\u2019re out of\nthe woods. You are not, because of the second wrinkle: concurrency.\n\nThe Snowflake warehouse chooses the concurrency of the batches of rows it\nsends to your service. We\u2019ve seen it start by sending as few as 8 concurrent\nbatches, each containing a few dozen rows. We\u2019ve also seen it choose to send\nas many as 1000 concurrent batches, each with thousands of rows.\n\nThe number of concurrent batches and the batch sizes are not predictable,\nthough in general it does send more when using a larger warehouse. And since\nwe\u2019re working with hundreds of millions of rows in this pipeline, we\u2019re using\npretty large warehouses.\n\n> Lesson\n\n> You don\u2019t control the concurrency with which Snowflake calls your service.\n> How Snowflake chooses the level of concurrency is a black box and is not\n> configurable. Building a service that can efficiently handle rapidly\n> changing levels of concurrency is a challenge.\n\nThe combination of a low timeout with high concurrency means reliably\nresponding to all traffic from an external function within 30 seconds is quite\nproblematic. Thankfully, Snowflake\u2019s external functions have an asynchronous\nAPI that is a better fit for large workloads like ours.\n\n### Using the async API\n\nWhen your service responds to the synchronous API it returns a HTTP 200 with\nthe inference results. Snowflake sees the HTTP 200 as meaning the request is\ncomplete. However, your service can respond with other HTTP codes to trigger\nother behavior.\n\nIf you respond with a HTTP 202, Snowflake will take that to mean your service\nhas accepted the batch. For the next 10 minutes Snowflake will poll, asking\nfor the results of that batch. When the results are ready, just respond with\nthe results and a HTTP 200 and you\u2019re all set.\n\nSo the async API looks like a better fit for large batches of inferences!\nUnfortunately, it\u2019s limited by a 10-minute timeout for processing each batch.\n\n> Lesson\n\n> The async API only polls for 10 minutes, not for the duration of the query\n> in the warehouse. If your service takes longer than 10 minutes to complete\n> any single batch, Snowflake will error the query and fail this step of the\n> pipeline. The 10-minute limit is not configurable.\n\nYour architecture for using the async API will need a queue so that your\nservice can have a pending list of batches for the model to run, and a\ncompleted set of results that Snowflake can poll for and fetch. Due to the\n10-minute timeout, it\u2019s important to work on batches in-order.\n\nThat 10-minute async API limit is often not enough when the Snowflake\nwarehouse sends a (metric) gazillion batches all at once. To buy a little more\ntime to scale up your ML service and process all the batches, your service can\nrespond with an HTTP 429. The 429 tells Snowflake that the service is busy and\nit\u2019ll slow down the rate of sending new batches to your service. You\u2019ll still\nhave only 10 minutes to respond to in-flight requests.\n\n> Lesson\n\n> Always work on batches in-order. If you process batches in random order it\u2019s\n> possible for early batches to wait more than 10 minutes and cause Snowflake\n> to error the entire query. This becomes very challenging when also\n> responding with 429 since you won\u2019t have those batches in the queue.\n\nHowever, you can only respond with HTTP 429 for about 12 minutes. If you\u2019re\nstill 429\u2019ing after 12 minutes, Snowflake will again error and fail this step\nof the pipeline.\n\n> Lesson\n\n> Responding with 429s doesn\u2019t affect the initial concurrency volume. If the\n> Snowflake warehouse decides to send a zillion requests all at once at the\n> start of the query, your service has to complete them all within the time\n> limit. There isn\u2019t a way to tell the warehouse \u201cstart slow and ramp up\u201d.\n\n### We can do better!\n\nExternal functions with the async API work pretty well, and until a few months\nago were the only option for workloads like this.\n\nRecently Snowflake added External Access to User-Defined Functions (UDFs).\nThis makes real-world ML pipelines possible with Snowflake compute for the\nfirst time!\n\n## Then came External Access\n\nTwo years ago Snowflake launched Snowpark for Python and allowed running\narbitrary Python code within the warehouse as UDFs. These Python UDFs had\nseveral limitations, the chief of which was no network access. Without network\naccess Snowpark simply wasn\u2019t viable for complex ML scenarios like ours.\n\nThat changed in the last few months when Snowflake launched External Access.\nWith additional configuration it\u2019s now possible to call out to the internet\nfrom Python UDFs. This means the architecture above can be greatly simplified\nwhile also allowing more control.\n\n### Houston, do you read me?\n\nNow we\u2019re in a world where Python code that\u2019s running in Snowflake can call\nout to Python code running in your service. Sounds a bit like microservices,\nright? Yes it does. Developing here is better and easier than developing with\nExternal Functions, and is our recommended approach for making external API\ncalls.\n\nNo lies this time, the architecture can really look like this:\n\nThe simplicity of the Python UDF with External Access is a welcome change from\nExternal Functions!\n\n### Communication is the answer\n\nYour Python UDF is responsible for how it communicates with your service. By\ndefault, the UDF isn\u2019t allowed to communicate with any external service. To\nenable external access you need to create a network rule to allow traffic to\nleave Snowflake. The network rule requires you to specify every domain and\nsubdomain your Python UDF is allowed to communicate with.\n\n> Lesson\n\n> Frustratingly, the network rule does not support wildcards, so you need to\n> specify every subdomain. That can be a lot of subdomains when you\u2019re talking\n> to AWS services. Set your log-level to DEBUG, run your UDF, and let \"boto3\"\n> fail to connect. Then wait 10 minutes and check your events table for\n> \"boto3\u2019\"s error logs, showing which hosts it couldn\u2019t reach. Update your\n> network rule, rinse, repeat.\n\nYour Python UDF must also handle authentication. Previously the External\nFunction used IAM permissions to authenticate to your API Gateway. With\nExternal Access you own your own authentication. Snowflake has a set of\nfeatures around secrets that\u2019ll give you access to your own API keys or auth\ntokens within your Python UDF.\n\nFinally, in order to connect the network rule and secret to your Python UDF,\nyou must create an access integration. With these three pieces you can create\na Python UDF that can talk to (some of) the internet by setting the\n\"external_access_integrations\" field in your UDF definition:\n\n    \n    \n    create or replace function my_schema.my_udf(...) returns ... language python runtime_version = 3.10 HANDLER = 'handler' external_access_integrations = (my_access_integration) packages = ('snowflake-snowpark-python', 'requests') secrets = ('authToken' = my_secret ) AS $$ import _snowflake, requests, os, pandas os.environ[\"AUTH_TOKEN\"] = _snowflake.get_generic_secret_string('authToken') @_snowflake.vectorized(input=pandas.DataFrame) def handler(inputDf): # your code to call the REST API of your ML service return requests.post(\"https://your-domain.com/api/run_model\", headers={\"x-auth-token\": os.environ[\"AUTH_TOKEN\"]}, data=json.dumps(inputDf.to_dict(orient=\"records\")).json() $$;\n\nAlong with authentication, your UDF code is also responsible for retries and\nthrottling. If your service isn\u2019t ready for the next batch of inferences, your\nPython UDF can simply \"sleep\" a few seconds and try again. Like before, there\nis a 10-minute timeout. Unlike before, this timeout is configurable.\n\n> Lesson\n\n> To change the timeout of your Python UDF, contact Snowflake Support. The\n> setting exists but it\u2019s not customer-facing. Raise it to an hour so you\u2019re\n> never worried about a Python UDF killing a long-running SQL job because one\n> batch unluckily took 10.1 minutes to complete.\n\nThe simplicity of this UDF is its strength. You can call whatever API you\u2019d\nlike, however you\u2019d like, with a dozen lines of Python inside your Snowflake\nwarehouse.\n\n### Mostly rainbows and unicorns\n\nPython UDFs with External Access check a lot of boxes for making it easy to\nbuild an ML pipeline on top of Snowflake. And since your ML inferences are\nrunning on your EC2s it\u2019s possible to have any shape hardware you need to run\nyour model.\n\nHaving a capable Python environment within the Snowflake warehouse raises the\nobvious question: Can the ML models just run within Snowpark? I\u2019m glad you\nasked!\n\n## Running your ML pipeline inside Snowflake Snowpark\n\nIf (and that\u2019s a big IF) your ML models can run within Snowflake, then you\nshould probably just run them there! The architecture will be simpler than\nanything that relies on models running on EC2s. And scaling up/down model\nconcurrency happens in lockstep with your warehouse size.\n\nWe\u2019ve seen 4XL warehouses process inferences for half a billion rows in 10\nminutes, while a decent cluster of EC2s would take close to an hour. Part of\nthis is due to the serialization and networking overhead of moving a lot of\ndata out of Snowflake and through EC2s and back. And part of this is because\nlarge Snowflake warehouses are just fast!\n\n### ML models in Snowpark\n\nRunning your models with Snowflake Snowpark is very similar to the Python UDFs\ndiscussed earlier. You define a Python UDF with the code and packages needed,\nand pass the inputted DataFrame to your model.\n\nHowever, the developer ergonomics of Snowpark are quite poor for complex ML\nmodels. Remember, our models are \u201cthousands of lines of Python code spread\nacross many source files, pickled artifacts, installed Python packages, binary\nweights and checkpoint files\u201d. Effectively writing (and testing!) Python\nembedded within a SQL function becomes a challenge after just a couple dozen\nlines of code.\n\nAlternatively you could put all your code in a Stage. But that means for every\nchange during development you must (1) package your code into a \"whl\", (2)\nupload it to a stage, (3) recreate your UDF to use the new code and files,\nthen finally (4) call the UDF to see if your code change works. This is not\nrealistic for real-world development, and if you\u2019re selling this as a service\nto real customers for real dollars, I do not recommend bringing this idea up\non a sales call.\n\n> Lesson\n\n> Avoid using Stages whenever possible. They\u2019re like S3 but worse because they\n> (1) are opaque to your other development tools and (2) have unusual\n> limitations like requiring some files to only be in the root directory for\n> them to be loadable by some Snowflake functions. Just use S3.\n\nThankfully there\u2019s a better way: dynamic code injection. Yep, you heard that\nright!\n\n### Dynamic code injection to Python UDFs\n\nDeveloping Python code within a Snowflake function is ... challenging. There\nare plenty of great editors and type checkers and test frameworks that run on\nPython code in normal Python files. There are none that work on Python code\nwithin your Snowflake SQL functions. Our recommendation: don\u2019t develop Python\nwithin SQL functions. Instead, use the magic of Python to inject the code at\nruntime!\n\nOur Python UDFs download their code and dependencies during initial execution\nfrom our ML service. This means it\u2019s possible to fix bugs, improve\nperformance, and adjust the behavior of our Python UDFs without changing the\nUDF! Just re-run the SQL statement and the UDF will fetch new code and execute\nit.\n\n> Lesson\n\n> Not storing your Python code in SQL warehouse also means you get normal\n> CI/CD workflows, git versioning, syntax highlighting and all the other\n> normal development tools you\u2019re used to.\n\nMost importantly, this means we can use normal Python development tools and\nworkflows to improve our Python UDFs very quickly: just save the current file\nand re-run your SQL query. There are few things more valuable than rapid\niteration in software development.\n\n> Lesson\n\n> During local development you can use ngrok to provide a host to put in your\n> Snowflake network rule. This way your warehouse can download the Python code\n> you\u2019re developing from your development machine, as you develop it. No need\n> to wait for pushes or release pipelines or even re-running \u201ccreate or\n> replace function\u201d!\n\nHere\u2019s an example of a Python UDF that downloads and executes its own code\nduring startup:\n\n    \n    \n    create or replace function my_schema.my_udf(...) returns ... language python runtime_version = 3.10 HANDLER = 'handler' external_access_integrations = (my_access_integration) packages = ('snowflake-snowpark-python', 'requests') secrets = ('authToken' = my_secret ) AS $$ import _snowflake, requests, os, sys, pandas, time from functools import cache os.environ[\"AUTH_TOKEN\"] = _snowflake.get_generic_secret_string('authToken') def getBootstrapCode(): return requests.get(f'https://your-domain.com/api/get_bootstrap', headers={\"x-auth-token\": os.environ[\"AUTH_TOKEN\"]}).text @cache def bootstrap(): exec(getBootstrapCode(), globals(), globals()) runBootstrap() # created during code injection @_snowflake.vectorized(input=pandas.DataFrame) def handler(inputDf): bootstrap() import my_request_handler # created by bootstrap's exec return my_request_handler.run(inputDf) # executes the model $$;\n\nIn the above code you\u2019ll notice that in the \"handler\" we\u2019re calling \"bootstrap()\". The \"bootstrap\" function downloads code from our ML service (a webserver) and executes it with \"exec\". It\u2019s the Python version of \"curl | bash\", but using trusted code from a server you control.\n\n> Lesson\n\n> Snowflake runs many instances of your Python UDF in the same \u201ccontainer\u201d.\n> That means they share the same writable \"/tmp\" volume. Snowflake recommends\n> using their FileLock example to prevent different instances from overwriting\n> each others\u2019 files. In our experience, that doesn\u2019t work unless you\u2019re super\n> careful with file flushing and also add multiprocessing locks.\n\n> Instead, we recommend a simpler approach: pick a random subdirectory of /tmp\n> during initialization. Then each instance of your Python UDF will have its\n> own folder to do work within and never risk overwrites from sibling\n> instances. The Snowpark disks are tiny so optimizing for disk I/O isn\u2019t\n> worthwhile.\n\nWith dynamic code injection it\u2019s possible to rapidly iterate on Python UDFs\nwhile developing. It also means your models can fetch different assets at\ndifferent times. If you\u2019ve trained one model per customer, it\u2019s easy to fetch\neach customer\u2019s model at runtime. Likewise if your code needs access to assets\nin S3, or a feature store, or a model registry, or to send logs somewhere,\nthis approach makes it easy.\n\nAs a bonus, you can return different code and state to your Python UDFs at\nruntime based on conditions within your ML service. This allows your ML\nservice to decide which version of a model to run, decoupling ML model\nreleases from database schema releases. Your ML team can fix model bugs, or\nship model improvements, without them needing to learn dbt or your database\nteam needing to be involved. Don\u2019t look now, but I think we\u2019re getting closer\nto true CI/CD!\n\n> Lesson\n\n> Favor software development practices over database development practices\n> when it comes to ML architecture decisions, even when using Snowflake.\n> Getting inferences from ML models is a lot more similar to software\n> engineering than data engineering.\n\n### Debugging within Snowpark\n\nTo help with debugging and understanding what your model is doing, you can\nconfigure Python\u2019s \"logging\" library to stream events to a table in Snowflake.\nKeep in mind that it sometimes takes well over ten minutes for events to show\nup in the table, and events may not show up if the function errors, so this\nisn\u2019t a great option for real-time debugging and iteration.\n\n> Lesson\n\n> Hear us out: For real-time debugging, we recommend throwing exceptions with\n> whatever state you want to know. The event table logging is far too slow.\n> Instead \"raise Exception({\u201cshow-me\u201d: \u201csomething\u201d})\"! It\u2019s like a\n> \"print(...)\" that\u2019ll show up immediately in the Snowflake console while\n> you\u2019re debugging.\n\n### Limitations of Snowpark UDFs\n\nFirst up, there are no GPUs. At the beginning of this post we discussed\nneeding an architecture where adding GPUs was possible. So while Snowpark may\nbe a good short-term solution, it\u2019s not the ideal solution. For that stay\ntuned for the next section.\n\nIf you don\u2019t need GPUs here are some additional limitations to keep in mind:\n\nFew packages: Snowflake Snowpark doesn\u2019t have access to \"pip\" or PyPi.\nInstead, it has access to a few thousand packages in the Snowflake Anaconda\nchannel spanning tens of thousands of individual versions. For comparison,\nPypi has hundreds of thousands of packages and millions of versions. So it\u2019s\nquite likely some of the packages you\u2019re using aren\u2019t in Snowpark. To work\naround that you can change the packages you\u2019re using or download and unzip\nthem into your environment. Unzipping packages only works for \u201cpure\u201d Python\npackages (if your package needs to compile C-extension you\u2019re out of luck).\n\nTo find out what packages are in Snowpark, look in\ninformation_schema.packages:\n\n    \n    \n    select * from information_schema.packages where language = 'python';\n\nLow disk space: The standard Snowflake warehouse allocates about 500MB to the\nwritable \"/tmp\" directory that your Python UDFs have access to. That\u2019s plenty\nof space for Python programs but barely any space for many ML models. To get\nmore disk space you need to upgrade to a Snowpark-optimized warehouse. If your\nuse case supports steaming file reads in from elsewhere, that may be an option\ninstead of downloading the file locally.\n\nSingle threaded: The Python Snowpark environment is designed to work best with\nsingle-threaded models. Spawning new processes is blocked and will raise an\nexception. You may need to configure your model to only use one core.\n\nNo compilation support: Some Python packages require compiling C-extensions\nwhen they install. That\u2019s not supported by Snowpark, and there\u2019s no viable\nworkaround at this time.\n\nAll-or-nothing batches: When you\u2019re running a zillion inferences there\u2019s\nalways the possibility of a bug that throws an exception. If any one of your\ninferences raises an exception the whole batch is lost. It doesn\u2019t matter that\nonly one row of the zillion had the issue. The query is terminated and the\ninferences are lost. You need to build your own error handling logic to\nprevent one rogue inference from tanking the whole batch of inferences.\n\n### Success with Snowpark\n\nDespite the limitations it\u2019s possible to have a lot of success with Snowpark,\nand we\u2019ve been excited to build on top of it. When it works, it works really\nwell. Looking ahead, we have some guesses for the future of Snowpark and\nrelated technologies from our friends at Snowflake.\n\n## The future is nigh\n\nSnowflake has several exciting ML-related features in development. Of course,\nthere are Snowpark Python UDFs that continue to improve with every release.\nThere\u2019s Snowpark ML which provides friendly APIs for training certain models\nand creating Snowpark UDFs for those models. And lastly there is Snowpark\nContainer Services, which allows for hosting docker containers within the\nSnowflake compute environment, including containers with access to GPUs.\n\nTo create a truly viable ML platform, Snowflake will need to merge these\nseemingly-disparate projects into a single coherent ML experience. We bet\nthat\u2019s what they\u2019re working on now. We think they will bring the best of each\nof these worlds together. Here\u2019s what we mean:\n\n### Snowpark Python UDFs\n\nWhat it\u2019ll bring to the table: The great strength here is the \u201cscales with\nyour warehouse\u201d style of on-demand compute. This is undeniably convenient and\na natural fit for generating and storing inferences during orchestrated SQL\nqueries. External Access makes live code injection possible, which enables the\nmarriage of true ML development workflows with scalable-on-demand compute.\n\nWhat they\u2019ll discard: The inability to customize Python environments beyond a\nfew thousand hand-selected packages. The lack of true network support. The\nlack of any hardware or Linux system customization at all, most obviously\nGPUs. All of this they can and will bring in from Snowpark Container Services\ninstead.\n\n### Snowpark ML\n\nWhat it\u2019ll bring to the table: The notebook API is a banger for end users\ngetting started with new models one at a time. The registry is the first of\nmany workflow-level features that Snowflake will need and is probably building\nto support real ML use cases. Things like model monitoring and alerting, two-\nway git sync, feature pipelines, shadow deployments, etc. are most likely\nalready in development from this team to enable a fabulous end-user experience\nfor managing lots of ML models and pipelines.\n\nWhat they\u2019ll discard: A real ML team needs a real API that can be called from\na production system, not just a notebook. \"create or replace function\" (a la\nSnowpark Python UDFs) is a weird way to create entire ML pipelines, but at\nleast it\u2019s scalable. Snowpark ML currently only supports three types of\nmodels, plus \u201ccustom\u201d models that need to inherit from a Snowflake-written\nwrapper class in a notebook. None of this is going to work for serious teams.\n(To say nothing of a 5GB model size limitation that we assume is temporary.)\nThe freedom afforded by the runtime environment of Snowpark Container Services\nis what they\u2019ll want to go with instead.\n\n### Snowpark Container Services\n\nWhat it\u2019ll bring to the table: It\u2019s all about Docker (and GPUs!). Support for\ncustom environments with totally custom Linux environments, packages and tools\nwill make it possible to run totally custom ML models in Snowflake for the\nvery first time.\n\nWhat they\u2019ll discard: More control over scaling and concurrency is necessary\nto make Snowpark Container Services viable for large ML workloads. When they\nmerge that scaling behavior of Snowpark Python UDFs with the full environment\ncustomization of Snowpark Container Services \u2013 and add in a more natural\ndocker repo interface, and avoid the \u201c10-minute timeout\u201d mistakes of the past\n\u2013 it\u2019ll be Game On for ML workloads in Snowflake!\n\n### The Snowflake-based ML architecture of the future\n\nSnowflake has the beginnings of something really special. If they can build a\nsingle product with the scaling characteristics of Snowpark Python UDFs; the\nhardware & software flexibility of Snowpark Container Services; and the high-\nlevel ML workflows promised by the Snowpark ML roadmap, they will have a\nDatabricks killer on their hands.\n\nWe think this is coming in the years ahead from Snowflake. We can\u2019t wait.\n\n## Wrapping up\n\nArchitecting ML pipelines is hard. There are many constraints imposed by the\nmodel\u2019s requirements, by the volume of the data, and by the latency demanded\nat inference time. Of course there\u2019s also the cost of compute and the need for\nan efficient developer experience in both creating and maintaining the\nsolution. There are no easy answers!\n\nThe most flexible option is to host your model wherever it runs best and call\nout to it from a Python UDF. If you ever want to call the same model outside\nof SQL (e.g. as a REST API for your product), this is a good path to follow.\n\nIf you\u2019re able to fit your model into Snowpark, and you only need to call your\nmodel from SQL, then Snowpark Python UDFs are a slam dunk. It\u2019s the simplest\narchitecture, and simplicity counts for a lot.\n\nSnowpark Container Services and Snowpark ML are compelling demos from\nSnowflake that will hopefully grow into true options for real-world ML\nworkloads as they add scale and flexibility, respectively.\n\nFinally, if you\u2019re like me, you\u2019re excited for a future where Snowflake\u2019s many\nML projects combine into something unified and compelling.\n\nUntil then, happy architecting!\n\nBy the way, if you\u2019re looking for an easy way to deploy your ML models into\nyour Snowflake warehouse, sign up for Modelbit!\n\n## Deploy Custom ML Models to Production with Modelbit\n\nJoin other world class machine learning teams deploying customized machine\nlearning models to REST Endpoints.\n\nGet Started for Free\n\nModelbit is trained with love, tested with burritos, and deployed in San\nFrancisco, California. Find us at founders@modelbit.com.\n\n##### Contact Us\n\nEmail Us\n\nSales\n\nLinkedIn\n\nTwitter\n\n##### Resources\n\nPricing\n\nCustomers\n\nAbout Us\n\nBlog\n\nChangelog\n\nSecurity\n\nDocumentation\n\nSystem Status\n\nOWL-ViT Demo\n\nModel Hub\n\n##### Product\n\nTrain ML models on GPUs\n\nDeploy from anywhere\n\nInfer everywhere\n\nBacked by your git repo\n\nLogs, monitoring & more\n\nHex & Modelbit for ML\n\n\u00a9 2023 Nineteenth Street Labs, Inc. All rights reserved\n\n", "frontpage": false}
