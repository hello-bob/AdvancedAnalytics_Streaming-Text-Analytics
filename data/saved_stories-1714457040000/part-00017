{"aid": "40202024", "title": "The limits of foreign propaganda and the foundations of an effective response", "url": "https://tnsr.org/2024/03/from-panic-to-policy-the-limits-of-foreign-propaganda-and-the-foundations-of-an-effective-response/", "domain": "tnsr.org", "votes": 3, "user": "no_exit", "posted_at": "2024-04-29 18:22:55", "comments": 0, "source_title": "From Panic to Policy: The Limits of Foreign Propaganda and the Foundations of an Effective Response", "source_text": "From Panic to Policy: The Limits of Foreign Propaganda and the Foundations of\nan Effective Response - Texas National Security Review\n\nBuy Print Magazine\n\nBuy Print Magazine\n\nThe Scholar\n\n#### PDF coming soon\n\nVol 7, Iss 2 Spring 2024\n\nDisinformation\n\n-\n\n# From Panic to Policy: The Limits of Foreign Propaganda and the Foundations\nof an Effective Response\n\nDisinformation March 26, 2024\n\nGavin Wilde\n\n###### American leaders and scholars have long feared the prospect that\nhostile foreign powers could subvert democracy by spreading false, misleading,\nand inflammatory information by using various media. Drawing on both\nhistorical experience and empirical literature, this article argues that such\nfears may be both misplaced and misguided. The relationship between people\u2019s\nattitudes and their media consumption remains murky, at best, despite\ntechnological advances promising to decode or manipulate it. This limitation\nextends to foreign foes as well. Policymakers therefore risk becoming\npessimistic toward the public and distracted from the domestic, real-world\ndrivers of their confidence in democratic institutions. Policy interventions\nmay also prove detrimental to democratic values like free expression and to\nthe norms that the United States aims to foster in the information\nenvironment.\n\nFacebook ShareLinkedin ShareGoogle Plus ShareTwitter ShareMail Share\n\nRussia\u2019s interference in the 2016 U.S. presidential election led to intense\npublic and scholarly debates over the role of foreign propaganda \u2014 deliberate\nand systematic attempts to use media to shape perceptions and direct behavior\nwithin domestic politics.1 Russia\u2019s brazen operation and Donald Trump\u2019s\nvictory were both unexpected, leaving analysts grasping for answers about the\nextent to which Russian activities may have influenced the outcome. The\nepisode breathed new life into an old American fear: widescale societal\nmanipulation by malicious foreign actors weaponizing media at home.2 Such\nconcerns went beyond Russia. China\u2019s investment in social media, for example,\nled to congressional hearings in which representatives spoke ominously about\ninformation campaigns by rival great powers.3 Such campaigns seem particularly\ninsidious. They putatively threaten national security not by changing the\nbalance of military power but by eroding faith in democratic institutions.4\n\nWith the 2024 U.S. presidential election looming, these anxieties seem well\nfounded. That Chinese or Russian intelligence services seek to use technology\nand propaganda to covertly sway the American public is not in doubt.5\nGovernments, civil society organizations, and online platforms have\ndemonstrated how narratives can spread online, spurred on by fake and foreign\nactors.6 Meanwhile, online data-harvesting is largely unregulated in the\nUnited States, fueling speculation that insights into Americans\u2019 lives might\nbe used to target them with both greater precision and persuasiveness. Insofar\nas national leaders presume that democratic institutions depend on citizens\nmaking rational calculations based on verifiable facts, the potential for\ndisruption can seem catastrophic. Policymakers and researchers have therefore\nrallied to defend what is presumed to be the primary target of foreign\npropaganda, democracy itself: the trust among citizens and in institutions\nnecessary for this participatory system of governance to function properly.\n\nYet this rise of interest and effort is based on potentially misleading views\nabout the prospects for propaganda. Contrary to prevailing assumptions, a\nrange of recent empirical studies have failed to validate any uniform, causal\nrelationship between online media and major changes in human attitudes and\nbehaviors. Moreover, research in this area remains limited in scope and beset\nby methodological challenges.7 Attempting to trace or wield influence is\ndifficult, even with the help of systematic data collection. Both would-be\nonline propagandists and policymakers often fail to appreciate this\ncomplexity.\n\nThis failure may lead to ineffective policy prescriptions, relying on\nmilitary, foreign policy, and national security tools to address what are\nlikely homegrown domestic issues. Insofar as policymakers aim to protect\ndemocracy from such subversion, outsized fears of foreign encroachment, undue\nfaith in the power of media and technology, and pessimism toward the American\npublic may prove equally corrosive to the trust in institutions ostensibly\nunder greatest threat. Political leaders and institutions thus risk losing\nfaith in the very public they exist to serve.\n\nThis article begins by describing the unsettled academic debate about the\nimpact of media on people. The second section briefly outlines how this debate\nhas persisted across political and academic discourse over the last century.\nThe next section interrogates how technological advances came to revive the\nnotion of media\u2019s direct effects on people, in large part by citing the\nputative powers of data aggregation about them. The fourth section explains\nwhy the temptation by governments to intervene in the information environment\nrisks backfiring, making foreign online influence a convenient scapegoat for\nhome-grown Digital Age socio-political problems.8 The conclusion recommends a\nmore introspective, domestic-focused approach to combatting foreign propaganda\nonline \u2014 one that starts by acknowledging its limitations, accepting people\u2019s\nown agency in the media they consume, and remembering that trust in democracy\nstems foremost from its ability to meet their real-world needs.\n\n## Propaganda\u2019s Unsettled Questions\n\nAt present, there is no consensus in the extant literature about the\neffectiveness of foreign propaganda.9 Rather than aspiring to settle these\ndisputes, this article argues that their very persistence is itself\ninstructive: If the relationship between people and the media they read,\nwatch, and listen to remains mysterious for researchers, it is likely no more\nscrutable to foreign adversaries. Moreover, insofar as media is but one avenue\nof subversion \u2014 the success of which seems to depend in part on preexisting\npolitical conditions \u2014 research and policy emphasis focused on countering\nonline manipulation by foreign actors may be empirically and politically\nmisplaced.\n\nResearchers have studied, from a range of perspectives, how states seek to\ninterfere in the domestic affairs of others, particularly in elections.\nAccording to some political scientists, outsiders find polarized publics\nparticularly attractive, as domestic partisans often amplify narratives that\nputatively advance foreign state interests, inform the direction of the\ntargeted state\u2019s foreign policy, or influence its foreign relations.10 Judging\nfrom several historical case studies, \u201ccovert dissemination of scandalous\nexpos\u00e9s or disinformation on rival candidates\u201d \u2014 alongside other acts such as\npublic threats, promises, campaign donations, and quid pro quos \u2014 may have a\nstatistically significant effect on election outcomes.11 Broadly, however, the\nperceived success of foreign interference appears to hinge on preexisting\nconditions within the target population, including uncertainty and doubt in\ntheir state institutions, elites, and leadership.12 The U.S. military\u2019s own\nattempts at \u201cwinning hearts and minds\u201d through propaganda operations in\nAfghanistan and elsewhere have cost hundreds of millions of dollars, with\nmixed success: \u201cOver the years, huge amounts of money have been spent on\ninformation operations programs that are largely anchored in advertising and\nmarketing styles of communication, with little concurrent investment, it would\nappear, in detailed understanding of audiences and environments.\u201d13\n\n> This suggests that people are far less impressionable than presumed, their\n> views much less moldable with any skill or reasonable expectation of success\n> \u2014 by states or any other actors.\n\nThere is no question of the roles that media play in popular discourse \u2014\ncreating and enabling authoritative voices, continuously shaping and reshaping\nwhat is considered socially acceptable behavior.14 In this regard, it is\nunsurprising that foreign actors try to use various media \u2014 from newspapers to\nbroadcasts to digital social platforms \u2014 as prime avenues for subversion.\nNevertheless, media\u2019s role in the construction of people\u2019s identities,\nbeliefs, and behaviors remains a contested scientific question.15 People may\nexercise more agency and discretion about the media they interact with than is\ncommonly portrayed in accounts about the spread of \u201cfake news.\u201d16 Cognitive\nscientist Hugo Mercier asserts that most efforts to sway people \u2014 by\nadvertisers, politicians, or propagandists \u2014 are largely ignored, and that\nhumanity\u2019s biggest problem is more the truth it fails to internalize, less the\nfalsehoods it accepts as true.17 Where false or inflammatory content does seem\nto resonate, the question arises as to whether people already consciously\nintended to accept it.18 Most inaccurate or misleading information \u201creaches\npeople who are already misinformed \u2014 or at least very open to being\nmisinformed,\u201d says Nieman Lab\u2019s Joshua Benton.19\n\nHowever detrimental self-delusion and ignorance may be to social cohesion,\nthey might simply prove more useful to people\u2019s everyday life than facts.\nAccording to philosopher Dan Williams, the marketplace of ideas might be more\naptly described as a marketplace of rationalizations, in which people and\norganizations compete to justify their preferred beliefs, in exchange for\nmoney, attention, and social status.20 A range of studies suggest that such\ndesires are immutable, overpowering even a conscious preference for truth and\naccuracy.21 People may therefore learn to value most the worldviews that best\nsuit their own social contexts.22\n\nFor example, in a recent study of Russia\u2019s online operations in the runup to\nthe 2016 U.S. presidential election, Eady et al. found no significant linkages\nbetween exposure to the subversive content and subsequent changes in\nattitudes, polarization, or voting behaviors.23 Other studies concluded that\ncontent shared via social media had no discernable effect on people\u2019s beliefs\nor opinions and that significant changes to people\u2019s on-platform experience\ndid not significantly alter their attitudes or levels of polarization.24 These\nstudies contradict previous scholarship suggesting Russia\u2019s efforts might have\nmeasurably altered public opinion.25\n\nEven where propaganda may thrive online, \u201cwhether or not it has any impact on\npolitical outcomes such as levels of political knowledge, trust in democratic\ninstitutions, or political polarization remains an open question,\u201d according\nto the Hewlett Foundation, a U.S.-based private foundation.26 This suggests\nthat people are far less impressionable than presumed, their views much less\nmoldable with any skill or reasonable expectation of success \u2014 by states or\nany other actors.27 This would not be the first time, however, that American\nthreat perceptions about propaganda have solidified before any scientific\nconsensus could.\n\n## Historical Echoes\n\nCurrent research and policy discussions about propaganda and foreign influence\nresemble those from previous decades. In the 1920s and 1930s, journalist\nWalter Lippmann and several of his contemporaries analyzed the process of\npublic persuasion, drawing on their experience working to rally public support\nfor U.S. involvement in World War I. Their work initially rested on one key\nassumption: that media had a direct and powerful influence on the American\npublic, whom they considered \u201cvolatile, unstable, rootless, alienated, and\ninherently susceptible to manipulation.\u201d28\n\nLippmann found it unrealistic for the average citizen to develop what he\ncalled omnicompetence on weighty issues, to break free from their own social\nclusters to make the world somehow intelligible.29 Edward Bernays, a prominent\nAmerican public relations practitioner-scholar, took Lippmann\u2019s misanthropic\nview a step further, arguing that the so-called engineering of consent, \u201cwhen\nused for social purposes, is among our most valuable contributions to the\nefficient functioning of modern society.\u201d Unapologetically elitist in\napproach, Bernays held that government had a solemn duty to interpret\nimportant facts and events on behalf of what he considered an otherwise dim or\ndisinterested public, to lead them \u201cto socially constructive goals and\nvalues.\u201d30 This duty, he claimed, was one of democracy\u2019s defining features.\nCommunications theorist Harold Lasswell went so far as to advocate that U.S.\nofficials shield democracy from authoritarianism through systematic, state-\nled, mass manipulation of their own public.31\n\nConsequently, research into media effects was framed as a liberal democratic\nimperative to counter fascism (and later communism).32 This model of media\ninfluence from the interwar period was later caricatured by scholars as the\n\u201chypodermic needle\u201d or \u201cmagic bullet\u201d model for its simplicity \u2014 signifying\nthe gradual repudiation of the notion of an all-powerful media on one side,\nthe public on the other, with little in between.33 While Lippmann claimed that\nknowledge \u201coriginated in individuals by means of isolated contact with\nobjects,\u201d his philosophical opponent, scholar John Dewey, contended that\nknowledge instead sprang from human interaction.34 Sociologist Joseph Klapper\nlater expanded on this theme, arguing that media had little direct influence\non people, but instead mostly reinforced their biases and attitudes about the\nworld.35\n\nIn the post\u2013World War II period, the term propaganda gradually receded from\ncommon, often pejorative use in favor of less ideologically charged terms like\ncommunication, information, and persuasion.36 This shift reflected growing\nacceptance among humanities scholars at the time of the need to factor for not\nonly new communication technologies, but also the perplexities of the human\ncondition.37 Research funding from major donors like the Ford Foundation began\nto shift away from fuzzy means of studying people\u2019s behavior, and instead\ntoward examining it like chemistry or physics, using quantitative methods.38\nThe idea that social phenomena could be explained, if not manipulated, through\nthe physical sciences also captured the imaginations of cyberneticists and\ninformation theorists.39 It appealed to a worldview in which information was\nobjectified \u2014 like matter or energy \u2014 subject to the laws of nature, able to\nbe deliberately amassed and directed against an opponent.40 However,\nessentializing information in this way inevitably led to objectifying the\npeople who encountered it.\n\nConsequently, by mid-century, this preoccupation began to draw criticism from\nhard-science devotees, who resented the focus on finding uniform, stable\ndynamics within disorderly social relationships.41 Historian John Gaddis\ncharacterizes this period as one in which \u201cthe \u2018soft\u2019 sciences became \u2018harder\u2019\njust as the \u2018hard\u2019 sciences were becoming softer.\u201d42\n\nThe 1950s and 1960s were marked by anti-communist fervor in Washington, and\nthe media was a frequent target.43 Most prominently, Senator Joseph McCarthy\nembodied the prevailing conviction that communist regimes might succeed in\ntheir plots to corrode democracies from within. As historian Jennifer Miller\ndetails, national leaders sought to help citizens \u201cdistinguish between\nhealthy, \u2018correct\u2019 ideas and harmful, \u2018false\u2019 ones ... claiming that democracy\nstemmed from psychological vigilance, rather than representative institutions\nor political rights.\u201d44 Ironically, the very liberties democracy putatively\nguaranteed remained hopelessly out of reach for many Americans \u2014 particularly\npersons of color \u2014 at the time.45\n\nThis was also the period when the television became a ubiquitous fixture in\nAmerican homes, spurring even more nuance in media studies over the ensuing\ndecades.46 Scholars gradually gave up on validating so-called direct effects \u2014\nthe idea that people might respond uniformly to a given media stimulus.47 They\ninstead introduced concepts like agenda-setting, priming, and framing to\ndescribe the complex dynamics at play between mass media, prominent figures,\nand audiences.48 They asserted that meaning is neither fixed by the messenger,\nnor passively received by its recipient, nor necessarily transparent to\noutsiders \u2014 therefore, media influence is both a discursive construction and a\nbyproduct of socio-economic conditions.49\n\nAs new information and communications technologies heralded the dawn of the\nDigital Age, media would become more interactive and diffuse, reviving the\nprospect that direct effects might be identified \u2014 if not perfected \u2014 by a\nmore granular understanding of individual and public preferences revealed\nthrough these interactions. The long-sought promise of a data-fied and\ncomputable \u2014 and thus predictable and moldable \u2014 public seemed finally within\nreach.50\n\n## Data Deluge\n\nThe advent of the Internet upended many of the prevailing paradigms about the\nrelationship between the media and the public. A scarcity of information,\nfiltered by the former, gave way to a scarcity of attention among the\nlatter.51 After the turn of the century, online media would blur the\ndistinction between the two groups altogether. It would throw into doubt\nearlier theorizing about media effects, making \u201cpublic opinion\u201d simultaneously\never-present, yet somehow elusive.52 So-called surveillance capitalism would\nmark the tradeoff between citizens and media: convenience in connectivity in\nexchange for granular insights on everyday life.53\n\nIn the fallout from Russian interference in the 2016 election, concern and\nscandal emerged over British consulting firm Cambridge Analytica\u2019s harvesting\nof data from millions of Facebook users and selling it to political\ncampaigns.54 Similar data-harvesting concerns would later punctuate\ncongressional hearings about China-based social media platform TikTok\u2019s\ninfluence in 2023.55 Policy discourse about media manipulation now stems from\nthe supposed power of big data about Americans being paired with algorithms\nfeeding information to Americans.56 This logic entails several self-\nreinforcing assumptions: New technologies will create new ways to generate,\ncollect, and analyze data about people, revealing otherwise unobservable\nphenomena.57 Automation will minimize human error and bias, thereby making the\ndata more \u201craw.\u201d58 The resulting judgments about these phenomena will\ntherefore be more accurate.59\n\n> Unlike chemical reactions, people do not operate according to any fixed\n> trajectories or rules, but are self-contradictory, paradoxical, and\n> unpredictable.\n\nThis logic has served several disciplines well, leading to breakthroughs in\nfields from genetics to supply chains.60 Meanwhile, researchers, politicians,\nnews producers \u2014 and, more recently, social media platforms \u2014 have also\napplied this data-centric paradigm to explain the complex relationship between\nthe media people consume, their attitudes and behaviors, and, by extension,\nthe phenomenon of suasion.61\n\nSocial media platforms like Facebook and Twitter (now X) became major\nproponents of this logic, as they assumed a leading role as intermediaries\nbetween users and content. Users, advertisers, and researchers also relegated\nto platforms the task of identifying value and ascribing meaning to whatever\ndata this relationship generated. The result, according to Sun-ha Hong, was\nthe prospect of \u201cunprecedented knowledge for the human subject, precisely by\nshifting accepted norms around what counts as better knowledge.\u201d62 Such power\nis both extensive in practice and seemingly bottomless in promise: human\nbehavior, reduced and reconstituted into a vast pool of measurable units.63\nOnline media offered a seemingly sterile laboratory through which to observe\nand study this behavior, ostensibly objectively, in isolation from its most\nconfounding, real-world variables.64\n\nYet no matter how automated, determining which factors qualify as \u201cdata\u201d\nonline remains a subjective exercise.65 Unlike chemical reactions, people do\nnot operate according to any fixed trajectories or rules, but are self-\ncontradictory, paradoxical, and unpredictable. Societies evolve variously\nacross time and geography and conform to no optimal model.66 As a result,\nobservers can be tempted to view flurries of social media activity as\ndeterministic markers or avenues of influence, absent additional context.67\n\nSuch flurries of activity are frequently measured against the most direct and\nworst conceivable outcomes, such as foreign manipulation. But unlike economics\nor medicine \u2014 whereby catastrophic events can be contrasted against an\noptimally functioning model \u2014 communications studies lack such a baseline from\nwhich to start.68 Even in the pre-Internet era when the media ecosystem was\nmore settled and coherent, political warfare, conspiracism, and falsehoods\nalso persisted.69 There is no community with a \u201cview from nowhere\u201d to serve as\na control group.70 As a result, a person\u2019s media exposure, however extensively\nit might be measured, is not all-encompassing or wholly representative of\ntheir lived experience.71 People use media as much to escape their reality as\nto shape it, as much to assert their identity as to formulate it, as much to\nvalidate their lived experience as to interpret it.72\n\nIn historical terms, humanity has only just begun to generate and collect the\noceans of data now available.73 The quality of research inquiry has, in many\ninstances, suffered from such abundance. The search for statistically\nmeaningful correlations has largely become a market unto itself.74 The\nemphasis on statistical significance over practical importance coincided with\nthe deluge of data over past decades, infusing various fields of study \u2014 often\nto questionable ends.75 According to economist Gary Smith, trust in data and\ntrust in science are not synonymous and can undermine each other: 76\n\n> A virtually unlimited number of coincidental sequences, correlations, and\n> clusters can be discovered in large databases. ... Those who do not\n> appreciate the inevitability of patterns are sure to be impressed. Those who\n> are seduced by these shiny patterns are likely to be disappointed. Those who\n> act on the basis of data-mined conclusions are likely to lose faith.77\n\nThe main beneficiaries of the idea that people can be decoded through their\nonline activities are not foreign adversaries or researchers, but major social\nmedia platforms and advertisers themselves.78 The latter industry \u2014 arguably\nthe largest repository and beneficiary of user data on earth \u2014 operates on the\nassumption that seeing leads to clicking, which then leads to buying. However,\nthe science behind the effect of digital advertising on consumption is also\nunsettled.79\n\nSocial interactions remain largely grounded in the material world, and\npeople\u2019s capacity to absorb communication and juggle relationships also\nremains constrained.80 To depend primarily on social media data to understand\nhow narratives impact users\u2019 real-world attitudes and behaviors \u2014 much less to\ntry and shape them \u2014 is thus like trying to discern the plot of a film by\nstaring into the beam of the projector.81 When it comes to data, the closest\nthing to natural law is \u201cgarbage in, garbage out.\u201d82 This law applies equally\nto the researcher exploring media\u2019s effects and to the foreign adversary\nseeking to exploit them.\n\n## Contesting the Space\n\nStates often grapple with the uncertainties of an external threat, prompting\nexcessive policy remedies aimed at returning to some previous state of\nfamiliarity or equilibrium.83 The less clarity about another state\u2019s intent\nand capacity to do harm, the greater the tendency for anxiety.84 For instance,\nat the height of the Cold War, the United States knew all too well how\ndestructive nuclear weapons could be. What was less clear were Soviet\ncapabilities and intentions. The perceived threat of online manipulation now\ninverts this dynamic: Ill intent from adversarial states is evident, and the\ntradecraft of online propagandists is well documented. What remains unclear is\nthe degree to which \u201cinformation warfare\u201d is a causal factor to real-world\nevents.85 This lack of clarity notwithstanding, the propaganda elements of\nRussian interference in 2016 sparked a paradigm shift in how U.S. policymakers\nconceptualized information as both a threat and a warfighting function.86\n\nIt is reasonable for states to be wary of foreign influence and subversion. In\nthis vein, leaders understandably feel compelled to protect the public\u2019s sense\nof routine, stability, and national character.87 Political scientists refer to\nthis as \u201contological security\u201d \u2014 the idea that states must secure their social\nexistence first before they can succeed at much else.88 States thus generally\nperceive information as a threat in three general categories: technological\n(the ability to defend networks), intelligence (the ability to avoid\nsurprise), and cognitive (the ability to protect the public\u2019s sense of well-\nbeing).89 Moscow in 2016 breached all three, the last category perhaps most\njarringly.\n\nThe prospect that adversaries might exploit domestic socio-political fissures\nby using relatively novel cyber means fueled outrage in the U.S. national\nsecurity community.90 By 2020, the United States had marshalled military, law\nenforcement, diplomatic, intelligence, economic, and public messaging tools\nspecifically to thwart foreign attempts to undermine public confidence in the\nelectoral process. Most notably, U.S. Cyber Command reportedly undertook an\noperation to disrupt a notorious Russian troll farm ahead of the 2018 mid-term\nelections. By autumn 2020, the U.S. intelligence community was preemptively\nand directly warning Americans of Russian efforts to influence public\nopinion.91 This was even though the real-world effects of Russian interference\non voting behaviors in 2016 remained contested among researchers, and despite\nthe risk of lending Russian actors both unnecessary amplification at home and\nunearned clout in Moscow. Meanwhile, domestic political and media figures have\nbeen found to be among the biggest purveyors of disinformation about the\nintegrity of the vote in subsequent elections.92\n\n> Over the past 25 years, the media ecosystem\u2019s largely top-down structure has\n> nearly vanished, replaced by a more diffuse and immediate \u2014 in a word,\n> democratic \u2014 architecture.\n\nU.S. civilian and military leaders are loath to cede what they consider a\ncontested information domain to adversaries.93 But such measures are not\nwithout risk. Left unchecked, states\u2019 suspicions of foreign orchestration\nbehind every unpreferred narrative fuels the hubris of attempting such\norchestration themselves.94 For example, the U.S. Department of Homeland\nSecurity\u2019s recent efforts to counter disinformation online were met with\nskepticism from privacy and free speech advocates.95 Some commentators\nlikewise consider a potential wholesale ban on TikTok \u2014 as recently passed by\nthe U.S. House of Representatives and advocated by the Biden administration,\nstate legislatures, and rival tech firms \u2014 to be \u201can entirely un-American,\nundemocratic, and inappropriate response to an unproven risk.\u201d96 Government\nengagement with social media platforms about disinformation has also elicited\nallegations of soft censorship.97 Indeed, a policy bias toward intervening in\nthe information environment risks backfiring by undermining the very trust and\nconfidence it was designed to safeguard.98\n\nLiberal democracies encounter structural limitations on which media and\nspeech-related issues can be legally, normatively, and effectively cast as\nnational security concerns. For government agencies that are unavoidably\nassociated with partisan or political agendas, the goal of cleaning up or\ncontesting the information environment from a credible, neutral position is\none at which they are destined to fall short. Worse, democracies may begin to\nresemble foreign foes, such as when the U.S. Central Command reportedly\ncreated a small network of inauthentic social media profiles to boost\nmessaging.99 Aside from being easily detected, the operation looked\nsuspiciously like the very Russian behavior that had prompted outrage from\nWashington in 2016. Democracies thus risk responding to autocratic adversaries\nby poorly imitating them, likely being branded as hypocrites in the process by\nwould-be partners in condemning online propaganda.100\n\nThe hard truth for democracies in the Digital Age: their citizens are free to\nfool themselves, says former Stanford Internet Observatory director Alex\nStamos. \u201cBut that is not something that\u2019s necessarily being done to them. ...\nhunting down their speech and then changing it or pushing information on them\nis the kind of impulse that probably makes things worse,\u201d particularly if\ndriven by governments aiming to reassert their own authority or to reimpose\nsome sense of ontological security.101\n\nThe urge to intervene among national leaders is also likely spurred in part by\nthe memory of an era when the information space was far more hierarchical and\nconfined. Over the past 25 years, the media ecosystem\u2019s largely top-down\nstructure has nearly vanished, replaced by a more diffuse and immediate \u2014 in a\nword, democratic \u2014 architecture.102 Political scientists predicted as much in\nthe late 1990s as the Internet became ubiquitous, noting that it would create\nnew and competing claims upon citizens\u2019 allegiances.103 The Digital Age\npresented humanity with more facts \u2014 all of them more subject to individual\ninterpretation \u2014 than it had ever encountered previously.104 Major upticks in\nconspiracism, political polarization, populism, and distrust followed. For\nmany researchers, this heralded the beginning of a \u201cpost-truth\u201d era and\nsignaled the end of a shared sense of reality \u2014 absent which, they argue, a\ndemocracy ceases to function.105 A dwindling faith in traditional authority\ncame with a variety of sense-making options online.106 A once-dominant\nmonoculture fractured into smaller sub-groupings, some adhering to ideologies\nthat were demonstrably false, incomprehensible to, or even violently at odds\nwith other ways of thinking.\n\nThis disorienting information landscape may very well undermine the social\ntrust necessary for democracy to thrive. Researchers and policymakers,\nhowever, can easily conflate this disorientation with, or attribute it to,\nforeign-orchestrated propaganda. To the extent the latter is effective, its\nimpacts are more likely to be indirect and emergent (intertwined with other\nsocial and political phenomena) than direct and contingent (prompting\nattitudes or behaviors that would otherwise not have occurred).107 Complexity\nscience explores this dynamic in nature: extreme dependency on initial\nconditions renders the search for singular causes of various phenomena\nfruitless and makes their effects wildly unpredictable.108\n\nOnline media has made it too easy to conflate the volume of observed foreign\nattempts at online manipulation with demonstrable consequences.109 However, as\nintelligence scholars Cormac et al. note, \u201coverestimating the \u2018hidden hand\u2019\ncan lead to conspiracism about foreign actors, undermine trust in democratic\ninstitutions, and provide a convenient scapegoat for domestic divisions.\u201d110\nThis makes it difficult to hold authorities accountable for the domestic\nconditions that may lead certain communities to accept falsehoods and\nmischaracterizations, while the online and foreign aspects of their spread\noccupy the most attention. However, as Lippmann conceded, \u201cthe slogans of\npolitics are not the essence of politics.\u201d111 Social cohesion stems more from\nthe formative function democratic institutions are supposed to play in the\nreal world \u2014 servicing the needs of citizens \u2014 rather than the often\nperformative role they might now play in Digital Age media.112\n\n## Protect Democracy: At Home and Offline\n\nDecisionmakers should situate their threat perceptions, operational decisions,\nand rhetoric within broader historical, research, and political contexts.113\nTo begin from the assumption that online propaganda is necessarily successful,\nmerely understudied, may legitimize foreign adversaries\u2019 attempts \u2014 thereby\ndoing a measure of their work for them. As Cormac et al. note, the success of\ncovert subversion is determined by prominent \u201cobservers judg[ing] that an\noperation met the goals that proponents set out to achieve.\u201d114 In this\nregard, more deliberate ignoring of online propaganda is potentially in\norder.115 As artificial intelligence now threatens to open the floodgates of\nsynthetically produced content (so-called deepfakes), hypervigilance is likely\nto be ineffective, entailing significant opportunity and attention costs.116\n\n> Left unchecked, such instincts trend more toward technocracy and oligarchy\n> than strengthened democracy.\n\nDirect, causal linkages between propaganda and personal beliefs and behaviors\nremain speculative, at best. How large crowds behave and how their beliefs are\nformed \u2014 consciously or subconsciously \u2014 remains a largely open question.117\nInsofar as media exposure does influence people, research suggests it likely\ndoes so in concert with myriad other structural, real-world factors that have\ngone relatively underexplored.118 Media scholar David Karpf explains:\n\n> That we could counter adversary advances in digital propaganda with advances\n> of our own, or that we could regulate our way out of this psychometric arms\n> race ... is a story with clear villains, clear plans, and precise strategies\n> that might very well be foiled next time around. It is a story that keeps\n> being told, because it is so easy to tell. But we pay a price for the\n> telling and retelling of this story. The problem is that the myth of the\n> digital propaganda wizard is fundamentally at odds with the myth of the\n> attentive public. If the public is so easily duped, then our political\n> elites need not be concerned with satisfying their public obligations.119\n\nTo whatever degree foreign subversion does capitalize on domestic discontent,\ndecisionmakers should turn their focus toward safeguarding democratic trust at\nhome, in real-world spaces. A recent major survey among citizens in 22\ndemocracies by the Organization for Economic Co-operation and Development\nfinds that trust in institutions is shaped by three factors. The first is\nequal opportunity access to the policymaking process, particularly for\ndisadvantaged, less affluent, less educated, and minority groups. The second\nis individual policymaker responsiveness to citizen concerns. The final factor\nis the perceived degree of corruption, cronyism, and nepotism in government,\nincluding its capture by special interests and transparency in lobbying.120\nThese findings are neither surprising nor simple to address. But rather than a\nreflexive, militarized policy response to safeguard against attempts at\nforeign subversion, policymakers should focus first and foremost on these\ndomestic factors. Their prospects for success are arguably no dimmer than\nthose for solving \u2014 or hijacking \u2014 human fallibility through digital media or\ntechnology.121\n\nThe democratic form of government, being rooted in free expression, has always\nbeen subject to \u2014 and required a degree of tolerance for \u2014 lies,\nmisinterpretations, and machinations. As was true a century ago, attaining a\nhealthier politics will require national security leaders construing and\ndepicting the information environment as more than just a mechanism that can\nbe calibrated at will.122 Recent studies suggest that alarmism about online\nmanipulation itself might diminish faith in democracy and legitimize calls for\nexcessive curbs on speech.123 Instead, policymakers should assume that even\nthe best resourced and sophisticated actors in that space operate under\nidentical, heavy constraints possibly to marginal effects.124\n\nOtherwise, policymakers and researchers will find themselves right back where\nLippmann started: pessimistic about the public\u2019s ability to sort facts from\nnonsense, and thus determined to imbue elites and authorities with the power\nto interject and interpret on its behalf.125 Left unchecked, such instincts\ntrend more toward technocracy and oligarchy than strengthened democracy.126\n\nAmericans must ultimately be slower to accept the premise that foreign online\nmanipulation is more prevalent, their neighbors more gullible, and human\nbehavior more dependent on media than is likely the case.127 Dewey once\nasserted that, provided the right conditions, American citizens are fully\ncapable of living free from outside coercion.128 In this regard, shutting off\navenues for foreign malign influence also means ensuring decisionmakers are\nnot distracted or absolved from servicing the needs of the public.129 Scholars\nhave debated for the past hundred years about where confidence was better\nplaced: in the power of the citizen and of democratic institutions, or in the\nability of concerted propagandists to subvert them.130 The choice today is no\nless stark.\n\nGavin Wilde is a senior fellow at the Carnegie Endowment for International\nPeace, where his research focuses on cyber, propaganda, emerging technology,\nand Russia issues. He is also an adjunct professor at the Alperovitch\nInstitute for Cybersecurity Studies at Johns Hopkins University.\n\nAcknowledgments: The author wishes to express sincere gratitude to the editors\nof the Texas National Security Review, two anonymous reviewers, Michael van\nLandingham, Sam Forsythe, Lilly Muller, Jeff Rogg, Stepanie Carvin, Jill\nKastner, Alicia Wanless, Jon Bateman, Yoel Roth, and other Carnegie colleagues\nfor their generous contributions of time and expertise.\n\nImage: Sebastian Wallroth (CC BY 4.0 DEED)\n\n#### Endnotes\n\n1 U.S. Office of the Director of National Intelligence, Assessing Russian\nActivities and Intentions in Recent U.S. Elections, January 6, 2017,\nhttps://www.dni.gov/files/documents/ICA_2017_01.pdf. Propaganda is defined\nhere as \u201cthe deliberate and systematic attempt to shape perceptions,\nmanipulate cognitions, and direct behavior to achieve a response that furthers\nthe desired intent of the propagandist.\u201d For a discussion, see Garth S. Jowett\nand Victoria J. O\u2019Donnell, Propaganda & Persuasion, 6^th ed. (Los Angeles:\nSAGE Publications, 2018), 1-7.\n\n2 Jeffery L. Bineham, \u201cA Historical Account of the Hypodermic Model in Mass\nCommunication,\u201d Communication Monographs 55, no. 3 (1988): 230-246,\nhttps://doi.org/10.1080/03637758809376169.\n\n3 Brian Fung, \u201cLawmakers Say TikTok Is a National Security Threat, but\nEvidence Remains Unclear,\u201d CNN, March 21, 2023,\nhttps://www.cnn.com/2023/03/21/tech/tiktok-national-security-\nconcerns/index.html.\n\n4 David A. Siegel, \u201cDemocratic Institutions and Political Networks,\u201d eds.\nJennifer Victor et al., The Oxford Handbook of Political Networks (Oxford:\nOxford Academic, 2016), https://doi.org/10.1093/oxfordhb/9780190228217.013.35.\n\n5 U.S. Department of State, GEC Special Report: Pillars of Russia\u2019s\nDisinformation and Propaganda Ecosystem, August 2020,\nhttps://www.state.gov/russias-pillars-of-disinformation-and-propaganda-report;\nand Albert Zhang et al., \u201cGaming Public Opinion: The CCP\u2019s Increasingly\nSophisticated Cyber-Enabled Influence Operations,\u201d Australian Strategic Policy\nInstitute, April 26, 2023, http://www.aspi.org.au/report/gaming-public-\nopinion.\n\n6 Dustin Volz and Michael R. Gordon, \u201cChina Is Investing Billions in Global\nDisinformation Campaign, U.S. Says,\u201d Wall Street Journal, September 28, 2023,\nhttps://www.wsj.com/world/china/china-is-investing-billions-in-global-\ndisinformation-campaign-u-s-says-88740b85.\n\n7 Chico Q. Camargo and Felix M. Simon, \u201cMis- and Disinformation Studies Are\nToo Big to Fail: Six Suggestions for the Field\u2019s Future,\u201d Harvard Kennedy\nSchool Misinformation Review, September 20, 2022,\nhttp://dx.doi.org/10.37016/mr-2020-106; and Jon Bateman and Dean Jackson,\n\u201cCountering Disinformation Effectively: An Evidence-Based Policy Guide,\u201d\nCarnegie Endowment for International Peace, January 31, 2023, 11-15,\nhttps://carnegieendowment.org/files/Carnegie_Countering_Disinformation_Effectively.pdf.\n\n8 The \u201cDigital Age\u201d refers to the period from the 1970s with the advent of the\npersonal computer, through the subsequent prevalence of digital technologies\nin the 1980s and the widespread use of the Internet by the late 1990s, to the\npresent. For a discussion, see Tendai S. Muwani et al., \u201cThe Global Digital\nDivide and Digital Transformation: The Benefits and Drawbacks of Living in a\nDigital Society,\u201d in Digital Transformation for Promoting Inclusiveness in\nMarginalized Communities, eds. Munyaradzi Zhou et al., (Hershey, PA: IGI\nGlobal, 2022), 217-36, http://dx.doi.org/10.4018/978-1-6684-3901-2.ch011.\n\n9 Zarine Kharazian et al., \u201cSome Criticism of Misinformation Research Fails to\nAccurately Represent the Field it Critiques,\u201d Center For An Informed Public:\nUniversity of Washington, January 24, 2024,\nhttps://www.cip.uw.edu/2024/01/24/misinformation-field-research.\n\n10 Johannes Bubeck and Nikolay Marinov, Rules and Allies: Foreign Election\nInterventions (Cambridge: Cambridge University Press, 2019); Michael Tomz and\nJessica Weeks, \u201cPublic Opinion and Foreign Electoral Intervention,\u201d American\nPolitical Science Review 114, no. 3 (August 2020): 856\u201373,\nhttps://doi.org/10.1017/S0003055420000064; Daniel Corstange and Nikolay\nMarinov, \u201cTaking Sides in Other People\u2019s Elections: The Polarizing Effect of\nForeign Intervention,\u201d American Journal of Political Science 56, no. 3\n(February 2012): 655\u201370, https://doi.org/10.1111/j.1540-5907.2012.00583.x; and\nBenjamin E. Goldsmith and Yusaku Horiuchi, \u201cDoes Russian election interference\ndamage support for U.S. alliances? The case of Japan,\u201d European Journal of\nInternational Relations 29, no. 2 (2023), 427\u2013448,\nhttps://doi.org/10.1177/13540661221143214.\n\n11 Dov H. Levin, \u201cPartisan Electoral Interventions by the Great Powers:\nIntroducing the PEIG Dataset,\u201d Conflict Management and Peace Science 36, no. 1\n(2019): 88\u2013106, https://doi.org/10.1177/0738894216661190; and Dov H. Levin\n\u201cWhen the Great Power Gets a Vote: The Effects of Great Power Electoral\nInterventions on Election Results,\u201d International Studies Quarterly 60, no. 2\n(June 2016): 189-202, https://doi.org/10.1093/isq/sqv016.\n\n12 Sarah Sunn Bush and Lauren Prather, Monitors and Meddlers: How Foreign\nActors Influence Local Trust in Elections (Cambridge: Cambridge University\nPress, 2022), 47.\n\n13 Tom Vanden Brook, \u201cPropaganda Fails in Afghanistan, Report Says,\u201d USA\nToday, December 4, 2013,\nhttps://www.usatoday.com/story/news/nation/2013/12/04/information-operations-\npropaganda-afghanistan-pentagon/3870179.\n\n14 Patricia Moy et al., \u201cAgenda-Setting, Priming, and Framing\u201d in The\nInternational Encyclopedia of Communication Theory and Philosophy, eds. Klaus\nJensen et al. (Hoboken, NJ: John Wiley & Sons, Ltd, 2016) 1-13,\nhttps://doi.org/10.1002/9781118766804.wbiect266.\n\n15 Joseph Uscinski et al., \u201cCause and Effect: On the Antecedents and\nConsequences of Conspiracy Theory Beliefs,\u201d Current Opinion in Psychology 47\n(October 2022): https://doi.org/10.1016/j.copsyc.2022.101364.\n\n16 Felix M. Simon and Chico Q. Camargo, \u201cAutopsy of a Metaphor: The Origins,\nUse and Blind Spots of the \u2018Infodemic,\u2019\u201d New Media & Society 25, no. 8 (2023):\n2219-2240, https://doi.org/10.1177/14614448211031908.\n\n17 Hugo Mercier, Not Born Yesterday: The Science of Who We Trust and What We\nBelieve (Princeton, NJ: Princeton University Press, 2020).\n\n18 Andreas Jungherr and Ralph Schroeder, \u201cDisinformation and the Structural\nTransformations of the Public Arena: Addressing the Actual Challenges to\nDemocracy,\u201d Social Media + Society 7, no. 1 (January 2021):\nhttps://journals.sagepub.com/doi/full/10.1177/2056305121988928.\n\n19 Joshua Benton, \u201cGood News: Misinformation Isn\u2019t as Powerful as Feared! Bad\nNews: Neither Is Information,\u201d Nieman Lab, January 10, 2023,\nhttps://www.niemanlab.org/2023/01/good-news-misinformation-isnt-as-powerful-\nas-feared-bad-news-neither-is-information.\n\n20 Daniel Williams, \u201cThe Marketplace of Rationalizations,\u201d Economics &\nPhilosophy 39, no. 1 (March 2023): 99\u2013123,\nhttps://doi.org/10.1017/S0266267121000389.\n\n21 Cameron Anderson et al., \u201cIs the Desire for Status a Fundamental Human\nMotive? A Review of the Empirical Literature,\u201d Psychological Bulletin 141, no.\n3 (May 2015): 574\u2013601, https://doi.org/10.1037/a0038781; and Dan M. Kahan,\n\u201cMisconceptions, Misinformation, and the Logic of Identity-Protective\nCognition,\u201d (May 24, 2017), Cultural Cognition Project Working Paper Series\nNo. 164, Yale Law School, Public Law Research Paper No. 605, Yale Law &\nEconomics Research Paper No. 575, http://dx.doi.org/10.2139/ssrn.2973067.\n\n22 Brendan Nyhan, \u201cWhy Fears of Fake News Are Overhyped,\u201d Reasonable Doubt,\nFebruary 4, 2019, https://gen.medium.com/why-fears-of-fake-news-are-\noverhyped-2ed9ca0a52c9; and Gideon Lewis-Kraus, \u201cHow Harmful Is Social\nMedia?,\u201d The New Yorker, June 3, 2022,\nhttps://www.newyorker.com/culture/annals-of-inquiry/we-know-less-about-social-\nmedia-than-we-think.\n\n23 Gregory Eady et al., \u201cExposure to the Russian Internet Research Agency\nForeign Influence Campaign on Twitter in the 2016 U.S. Election and Its\nRelationship to Attitudes and Voting Behavior,\u201d Nature Communications 14, no.\n62 (January 9, 2023): https://doi.org/10.1038/s41467-022-35576-9.\n\n24 2020 Election Research Project, \u201cFirst Four Papers from U.S. 2020 Facebook\n& Instagram Research Election Study Published in Science and Nature,\u201d Medium,\nJuly 27, 2023, https://medium.com/@2020_election_research_project/first-four-\npapers-from-us-2020-facebook-instagram-research-election-study-published-in-\nscience-c099c235fc6c.\n\n25 Damian J. Ruck et al., \u201cInternet Research Agency Twitter Activity Predicted\n2016 U.S. Election Polls,\u201d First Monday 24, no. 7 (July 1, 2019):\nhttps://doi.org/10.5210/fm.v24i7.10107.\n\n26 Joshua A. Tucker et al., \u201cSocial Media, Political Polarization, and\nPolitical Disinformation: A Review of the Scientific Literature,\u201d William &\nFlora Hewlett Foundation, March 19, 2018, 15-16, 57,\nhttps://hewlett.org/library/social-media-political-polarization-political-\ndisinformation-review-scientific-literature.\n\n27 Claes Wallenius, \u201cDo Hostile Information Operations Really Have the\nIntended Effects? A Literature Review,\u201d Journal of Information Warfare 21, no.\n2 (Spring 2022): https://www.jinfowar.com/journal/volume-21-issue-2/do-\nhostile-information-operations-really-have-intended-effects-literature-review.\n\n28 Bineham, \u201cA Historical Account of the Hypodermic Model in Mass\nCommunication,\u201d 232. Also see Jeffrey Whyte, \u201cA New Geography of Defense: The\nBirth of Psychological Warfare,\u201d Political Geography 67, (November 2018):\n32-45, https://doi.org/10.1016/j.polgeo.2018.09.004.\n\n29 Sean Illing, \u201cIntellectuals Have Said Democracy Is Failing for a Century.\nThey Were Wrong.,\u201d Vox, December 20, 2018,\nhttps://www.vox.com/2018/8/9/17540448/walter-lippmann-democracy-trump-brexit.\n\n30 Edward L. Bernays, \u201cThe Engineering of Consent,\u201d The Annals of the American\nAcademy of Political and Social Science 250 (March 1947): 113\u2013120,\nhttps://www.jstor.org/stable/1024656; and Karl R. Popper, The Open Society and\nIts Enemies: New One-Volume Edition (Princeton, NJ: Princeton University\nPress, 2013).\n\n31 Jill Lepore, If Then: How the Simulmatics Corporation Invented the Future\n(New York: Liveright Publishing, 2020), 33.\n\n32 W. Russell Neuman, The Digital Difference: Media Technology and the Theory\nof Communication Effects (Cambridge, MA: Harvard University Press, 2018),\n28-29.\n\n33 Bineham, \u201cA Historical Account of the Hypodermic Model in Mass\nCommunication.\u201d\n\n34 David Greenberg, \u201cLippmann vs. Mencken: Debating Democracy,\u201d Raritan 32,\nno. 2 (Fall 2012): 117-140, https://www.proquest.com/scholarly-\njournals/lippmann-vs-mencken-debating-democracy/docview/1238178273/se-2.\n\n35 Robert H. Wicks, \u201cStandpoint: Joseph Klapper and the Effects of Mass\nCommunication: A Retrospective,\u201d Journal of Broadcasting & Electronic Media\n40, no. 4 (September 1996): 563\u2013569,\nhttps://doi.org/10.1080/08838159609364377.\n\n36 Andrea Scarantino and Gualtiero Piccinini, \u201cInformation Without Truth,\u201d\nMetaphilosophy 41, no. 3 (April 2010): 313\u2013330,\nhttps://www.jstor.org/stable/24439828.\n\n37 Jowett and O\u2019Donnell, Propaganda & Persuasion, 54-55.\n\n38 Gabriel A. Almond and Stephen J. Genco, \u201cClouds, Clocks, and the Study of\nPolitics,\u201d World Politics 29, no. 4 (July 1977): 489-522,\nhttps://doi.org/10.2307/2010037; Lepore, If Then, 54-55.\n\n39 Peter Kirschenmann, \u201cProblems of Information in Dialectical Materialism,\u201d\nStudies in Soviet Thought 8, no. 2/3 (1968): 105\u2013121,\nhttps://www.jstor.org/stable/20098325.\n\n40 John Arquilla and David Ronfeldt, \u201cInformation, Power, and Grand Strategy:\nIn Athena\u2019s Camp - Section 2\u201d (Santa Monica, CA: RAND Corporation), 1997, 145,\nhttps://apps.dtic.mil/sti/pdfs/ADA485246.pdf. This philosophy persisted among\nRussian, Chinese \u2014 and later, Western \u2014 military thinkers. For a discussion,\nsee Tim Stevens, \u201cInformation Matters: Informational Conflict and the New\nMaterialism\u201d (September 14, 2012). Paper for presentation at Millennium Annual\nConference, \u2018Materialism and World Politics\u2019, October 20-21, 2012, London\nSchool of Economics, https://ssrn.com/abstract=2146565.\n\n41 Albert O. Hirschman, A Bias for Hope: Essays on Development and Latin\nAmerica (New Haven, CT: Yale University Press, 1971), 27.\n\n42 John Lewis Gaddis, \u201cInternational Relations Theory and the End of the Cold\nWar,\u201d International Security 17, no. 3 (Winter 1992-1993): 5, 53-54,\nhttps://doi.org/10.2307/2539129.\n\n43 Nancy E. Bernhard, U.S. Television News and Cold War Propaganda, 1947-1960\n(Cambridge: Cambridge University Press, 1999), 83-84.\n\n44 Jennifer Miller, \u201cDemocracy and Misinformation,\u201d Perspectives on History,\nJune 10, 2019, https://www.historians.org/research-and-\npublications/perspectives-on-history/summer-2019/democracy-and-misinformation.\n\n45 Andrea Friedman, Citizenship in Cold War America: The National Security\nState and the Possibilities of Dissent (Amherst, MA: University of\nMassachusetts Press, 2014), 17.\n\n46 Marshall McLuhan, \u201cElectronics and the Changing Role of Print,\u201d Audio\nVisual Communication Review 8, no. 5 (1960): 74\u201383,\nhttps://www.jstor.org/stable/30216955.\n\n47 James W. Carey, Communication as Culture: Essays on Media and Society, rev.\ned. (New York: Routledge, 2009), 14-23.\n\n48 Dietram A. Scheufele and David Tewksbury, \u201cFraming, Agenda Setting, and\nPriming: The Evolution of Three Media Effects Models,\u201d Journal of\nCommunication 57, no. 1 (March 2007): 9\u201320,\nhttps://doi.org/10.1111/j.0021-9916.2007.00326.x.\n\n49 Stuart Hall, \u201cEncoding and Decoding in the Television Discourse,\u201d CCCS\nstenciled paper no. 7 (Birmingham: Centre for Contemporary Cultural Studies,\n1973), https://core.ac.uk/download/pdf/81670115.pdf.\n\n50 Lepore, If Then, 3-4.\n\n51 Michael H. Goldhaber, \u201cAttention Shoppers!,\u201d Wired, December 1, 1997,\nhttps://www.wired.com/1997/12/es-attention.\n\n52 Hsuan-Ting Chen, \u201cSpiral of Silence on Social Media and the Moderating Role\nof Disagreement and Publicness in the Network: Analyzing Expressive and\nWithdrawal Behaviors,\u201d New Media & Society 20, no.10 (October 2018): 3917\u201336,\nhttps://doi.org/10.1177/1461444818763384.\n\n53 Evgeny Morozov, \u201cCapitalism\u2019s New Clothes,\u201d The Baffler, February 4, 2019,\nhttps://thebaffler.com/latest/capitalisms-new-clothes-morozov.\n\n54 Heidi Tworek, \u201cCambridge Analytica, Trump, and the New Old Fear of\nManipulating the Masses,\u201d Nieman Lab, May 15, 2017,\nhttps://www.niemanlab.org/2017/05/cambridge-analytica-trump-and-the-new-old-\nfear-of-manipulating-the-masses.\n\n55 Tori Otten, \u201cTikTok Is a Problem\u2014but Not Our Biggest Social Media Problem,\u201d\nThe New Republic, March 24, 2023,\nhttps://newrepublic.com/article/171372/tiktok-not-congress-biggest-social-\nmedia-problem.\n\n56 Matthew Rosenberg et al., \u201cHow Trump Consultants Exploited the Facebook\nData of Millions,\u201d New York Times, March 17, 2018,\nhttps://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-\ncampaign.html; and Sapna Maheshwari and Amanda Holpuch, \u201cWhy the U.S. is\nWeighing Whether to Ban TikTok,\u201d New York Times, May 23, 2023,\nhttps://www.nytimes.com/article/tiktok-ban.html.\n\n57 David Beer, The Data Gaze: Capitalism, Power and Perception (London: SAGE\nPublications Ltd, 2019), 25.\n\n58 Lisa Gitelman, ed., Raw Data Is an Oxymoron (Cambridge, MA: MIT Press,\n2013), 3.\n\n59 Danah Boyd and Kate Crawford, \u201cCritical Questions for Big Data:\nProvocations for a Cultural, Technological, and Scholarly Phenomenon,\u201d\nInformation, Communication & Society 15, no. 5 (May 2012): 662\u2013679,\nhttps://doi.org/10.1080/1369118X.2012.678878.\n\n60 David Biro, \u201cHow Big Data Is Changing Science,\u201d Mosaic Science, October 2,\n2018, https://medium.com/mosaic-science/how-big-data-is-changing-\nscience-97201e911bf0.\n\n61 Sun-ha Hong, Technologies of Speculation: The Limits of Knowledge in a\nData-Driven Society (New York: New York University Press, 2020), 13-52;\nAntoinette Rouvroy, \u201cThe End(s) of Critique: Data-Behaviorism vs. Due-\nProcess,\u201d in Privacy, Due Process, and the Computational Turn, eds. Mireille\nHildebrandt and Katja de Vries (New York: Routledge, 2013), 143\u2013168; Richard\nE. Petty and Duane T. Wegener, \u201cAttitude Change: Multiple Roles for Persuasion\nVariables,\u201d in The Handbook of Social Psychology, 4th ed. (New York: McGraw-\nHill, 1998), 323\u2013390.\n\n62 Hong, Technologies of Speculation, 7, 20.\n\n63 Claudia Aradau and Tobias Blanke, Algorithmic Reason: The New Government of\nSelf and Other (Oxford: Oxford University Press, 2022), 1-18.\n\n64 Steven T. Smith et al., \u201cInfluence Estimation on Social Media Networks\nUsing Causal Inference,\u201d IEEE Statistical Signal Processing Workshop, Freiburg\nim Breisgau, Germany, 2018, 328-332, https://doi.org/10.1109/SSP.2018.8450823;\nLepore, If Then, 326.\n\n65 Hong, Technologies of Speculation, 19.\n\n66 Rob Kitchin, \u201cBig Data, New Epistemologies and Paradigm Shift,\u201d Big Data &\nSociety 1, no. 1 (April 2014): 1\u201312, https://doi.org/10.1177/2053951714528481;\nDavid Pinsof, \u201cThe Evolution of Social Paradoxes\u201d PsyArXiv (March 2023),\nhttps://doi.org/10.31234/osf.io/avh9t; and Eran Fisher and Yoav Mehozay, \u201cHow\nAlgorithms See Their Audience: Media Epistemes and the Changing Conception of\nthe Individual,\u201d Media, Culture & Society 41 no. 8 (March 2019): 1176-1191,\nhttps://doi.org/10.1177/0163443719831598.\n\n67 Neuman, The Digital Difference, 95; Hong, Technologies of Speculation,\n24-25; Kitchin, \u201cBig Data, New Epistemologies and Paradigm Shift;\u201d and Kate\nCrawford, The Atlas of AI: Power, Politics, and the Planetary Costs of\nArtificial Intelligence (New Haven, CT: Yale University Press, 2021), 214.\n\n68 Neuman, The Digital Difference, 33, 89-90.\n\n69 Jill Kastner and William C. Wohlforth, \u201cA Measure Short of War,\u201d Foreign\nAffairs, June 22, 2021,\nhttps://www.foreignaffairs.com/articles/world/2021-06-22/measure-short-war;\nand Heidi Tworek, \u201cDisinformation: It\u2019s History,\u201d Centre for International\nGovernance Innovation, July 14, 2021,\nhttps://www.cigionline.org/articles/disinformation-its-history.\n\n70 Tommaso Venturini, \u201cFrom Fake to Junk News, the Data Politics of Online\nVirality,\u201d in Data Politics: Worlds, Subjects, Rights, eds. Didier Bigo et\nal., (London: Routledge, 2019), https://hal.science/hal-02003893.\n\n71 Daniyar Sabitov, \u201cProblematics of Big Data Representation in Media\u201d\n(master\u2019s thesis, Charles University in Prague, 2020),\nhttps://doi.org/10.13140/RG.2.2.14133.91365.\n\n72 Jowett and O\u2019Donnell, Propaganda & Persuasion, 206-207.\n\n73 Bernard Marr, \u201cHow Much Data Do We Create Every Day? The Mind-Blowing Stats\nEveryone Should Read,\u201d Forbes, May 18, 2018,\nhttps://www.forbes.com/sites/bernardmarr/2018/05/21/how-much-data-do-we-\ncreate-every-day-the-mind-blowing-stats-everyone-should-read.\n\n74 Christie Aschwanden, \u201cWe\u2019re All \u2018P-Hacking\u2019 Now,\u201d Wired, November 26, 2019,\nhttps://www.wired.com/story/were-all-p-hacking-now.\n\n75 For an extensive review of positivism and its effects on the social\nsciences, see Jason Blakely, We Built Reality: How Social Science Infiltrated\nCulture, Politics, and Power (New York: Oxford University Press, 2020).\n\n76 Gary Smith, Distrust: Big Data, Data-Torturing, and the Assault on Science\n(Oxford: Oxford University Press, 2023), 126, 154, 158, 197-199.\n\n77 Smith, Distrust: Big Data, Data-Torturing, and the Assault on Science, 186.\n\n78 Joseph Bernstein, \u201cBad News: Selling the Story of Disinformation,\u201d\nHarper\u2019s, September 2021, https://harpers.org/archive/2021/09/bad-news-\nselling-the-story-of-disinformation; and C. W. Anderson, \u201cFake News Is Not a\nVirus: On Platforms and Their Effects,\u201d Communication Theory 31, no. 1\n(February 2021): 42\u201361, https://doi.org/10.1093/ct/qtaa008.\n\n79 Colin F. Jackson, \u201cInformation Is Not a Weapons System,\u201d Journal of\nStrategic Studies 39, no. 5\u20136 (2016): 820-846,\nhttps://doi.org/10.1080/01402390.2016.1139496; Tim Hwang, Subprime Attention\nCrisis: Advertising and the Time Bomb at the Heart of the Internet (New York:\nFarrar, Straus, and Giroux, 2020), 62; and Jesse Frederik and Maurits Martijn,\n\u201cThe New Dot Com Bubble Is Here: It\u2019s Called Online Advertising,\u201d The\nCorrespondent, November 6, 2019, https://thecorrespondent.com/100/the-new-dot-\ncom-bubble-is-here-its-called-online-advertising.\n\n80 R. I. M. Dunbar, \u201cDo Online Social Media Cut through the Constraints That\nLimit the Size of Offline Social Networks?,\u201d Royal Society Open Science 3, no.\n1 (January 2016), https://doi.org/10.1098/rsos.150292.\n\n81 Tung-Hui Hu, A Prehistory of the Cloud (Cambridge, MA: MIT Press, 2015),\nxx.\n\n82 Margaret Rouse, \u201cGarbage In, Garbage Out,\u201d Techopedia, January 4, 2017,\nhttps://www.techopedia.com/definition/3801/garbage-in-garbage-out-gigo.\n\n[83] Jane Kellett Cramer, \u201cNational Security Panics: Overestimating Threats to\nNational Security\u201d (PhD diss., Massachusetts Institute of Technology, 2002),\n30, 34-35, 37, 85, http://hdl.handle.net/1721.1/8312.\n\n84 Robert Jervis, Perception and Misperception in International Politics, rev.\ned. (Princeton, NJ: Princeton University Press, 2017), 67-76.\n\n85 Lennart Maschmeyer et al., \u201cDonetsk Don\u2019t Tell \u2013 \u2018Hybrid War\u2019 in Ukraine\nand the Limits of Social Media Influence Operations,\u201d Journal of Information\nTechnology & Politics (May 14, 2023): 1\u201316,\nhttps://doi.org/10.1080/19331681.2023.2211969.\n\n86 Timothy D. Haugh et al.,\u201c16th Air Force and Convergence for the Information\nWar,\u201d The Cyber Defense Review 5, no. 2 (Summer 2020): 29\u201343,\nhttps://cyberdefensereview.army.mil/CDR-Content/Articles/Article-\nView/Article/2288588/16th-air-force-and-convergence-for-the-information-war;\nHerbert Lin, \u201cDoctrinal Confusion and Cultural Dysfunction in DoD: Regarding\nInformation Operations, Cyber Operations, and Related Concepts,\u201d Cyber Defense\nReview 5, no. 2 (Summer 2020): 89\u2013106, https://www.jstor.org/stable/26923525;\nand Sarah P. White, \u201cThe Organizational Determinants of Military Doctrine: A\nHistory of Army Information Operations,\u201d Texas National Security Review 6, no.\n1 (Winter 2022-2023): 51-78, http://dx.doi.org/10.26153/tsw/44440.\n\n87 Hans Morgenthau, Politics among Nations: The Struggle for Power and Peace,\n5^th ed. (New York: Knopf, 1978), 138-140.\n\n88 Jennifer Mitzen, \u201cOntological Security in World Politics: State Identity\nand the Security Dilemma,\u201d European Journal of International Relations 12, no.\n3 (September 2006): 341\u2013370, https://doi.org/10.1177/1354066106067346; and\nAmir Lupovici, \u201cOntological Security, Cyber Technology, and States\u2019\nResponses,\u201d European Journal of International Relations 29, no. 1 (March\n2023): 153\u2013178, https://doi.org/10.1177/13540661221130958.\n\n89 Elgin M. Brunner and Myriam Dunn Cavelty, \u201cThe Formation of In-Formation by\nthe U.S. Military: Articulation and Enactment of Infomanic Threat Imaginaries\non the Immaterial Battlefield of Perception,\u201d Cambridge Review of\nInternational Affairs 22 no. 4 (December 2009): 629\u2013646,\nhttps://doi.org/10.1080/09557570903325454.\n\n90 Tim Mak, \u201cSenate Report: Russians Used Social Media Mostly To Target Race\nIn 2016,\u201d NPR, October 8, 2019,\nhttps://www.npr.org/2019/10/08/768319934/senate-report-russians-used-used-\nsocial-media-mostly-to-target-race-in-2016.\n\n91 Ellen Nakashima, \u201cU.S. Cyber Command Operation Disrupted Internet Access of\nRussian Troll Factory on Day of 2018 Midterms,\u201d Washington Post, February 27,\n2019, https://www.washingtonpost.com/world/national-security/us-cyber-command-\noperation-disrupted-internet-access-of-russian-troll-factory-on-day-\nof-2018-midterms/2019/02/26/1827fc9e-36d6-11e9-af5b-b51b7ff322e9_story.html;\nDevlin Barrett, Sari Horwitz, and Rosalind S. Helderman, \u201cRussian Troll Farm,\n13 Suspects Indicted in 2016 Election Interference,\u201d Washington Post, February\n17, 2018, https://www.washingtonpost.com/world/national-security/russian-\ntroll-farm-13-suspects-indicted-for-interference-in-us-\nelection/2018/02/16/2504de5e-1342-11e8-9570-29c9830535e5_story.html; U.S.\nDepartment of State, \u201cDisarming Disinformation: Our Shared Responsibility,\u201d\nlast updated February 8, 2024, https://www.state.gov/disarming-\ndisinformation/; U.S. Office of the Director of National Intelligence,\n\u201cIntelligence Community Assessment on Foreign Threats to the 2020 U.S. Federal\nElections,\u201d March 10, 2021,\nhttps://www.dni.gov/files/ODNI/documents/assessments/ICA-declass-16MAR21.pdf;\nU.S. Department of the Treasury, \u201cTreasury Escalates Sanctions Against the\nRussian Government\u2019s Attempts to Influence U.S. Elections,\u201d April 15,2021,\nhttps://home.treasury.gov/news/press-releases/jy0126; and U.S. Office of the\nDirector of National Intelligence, \u201cStatement by NSCC Director William\nEvanina: Election Threat Update for the American Public,\u201d August 7, 2020,\nhttps://www.dni.gov/index.php/newsroom/press-releases/press-\nreleases-2020/3473-statement-by-ncsc-director-william-evanina-election-threat-\nupdate-for-the-american-public.\n\n92 David Bauder et al., \u201cFox, Dominion Reach $787M Settlement over Election\nClaims,\u201d AP News, April 18, 2023, https://apnews.com/article/fox-news-\ndominion-lawsuit-trial-trump-2020-0ac71f75acfacc52ea80b3e747fb0afe.\n\n93 Ellen Nakashima, \u201cPentagon Opens Sweeping Review of Clandestine\nPsychological Operations,\u201d Washington Post, September 19, 2022,\nhttps://www.washingtonpost.com/national-security/2022/09/19/pentagon-\npsychological-operations-facebook-twitter.\n\n94 Grigory L. Tulchinsky, \u201cInformation Wars as a Conflict of Interpretations:\nActivating the \u2018Third Party,\u2019\u201d Russian Journal of Communication 5, no. 3\n(2013): 244\u2013251, https://doi.org/10.1080/19409419.2013.822054; and Whyte, The\nBirth of Psychological War, 5.\n\n95Amy Goodman, \u201cDept. of Homeland Security Ramps Up Efforts to Police Online\nSpeech on Ukraine, COVID & Afghanistan,\u201d Democracy Now!, November 4, 2022,\nhttps://www.democracynow.org/2022/11/4/dhs_police_online_discourse_the_intercept.\n\n96 Chris Stokel-Walker, \u201cBanning TikTok Is a Bad Solution to the Wrong\nProblem,\u201d Washington Post, March 15, 2023,\nhttps://www.washingtonpost.com/opinions/2023/03/15/tiktok-ban-propaganda-\nbytedance-china; Rebecca Picciotto, \u201cWhite House Urges Senate to \u2018Move\nSwiftly\u2019 on TikTok Bill as Lawmakers Drag Their Heels,\u201d CNBC, March 17, 2024,\nhttps://www.cnbc.com/2024/03/17/white-house-senate-tiktok-bill.html.\n\n97 Mayze Teitler, \u201cMissouri v. Biden Raises More First Amendment Questions\nThan It Answers,\u201d Just Security, July 19, 2023,\nhttps://www.justsecurity.org/87311/missouri-v-biden-raises-more-questions-\nthan-it-answers.\n\n98 Albert O. Hirschman, The Rhetoric of Reaction: Perversity, Futility,\nJeopardy (Cambridge, MA: Harvard University Press, 1991), 136-137.\n\n99 Nakashima, \u201cPentagon Opens Sweeping Review of Clandestine Psychological\nOperations.\u201d\n\n100 Alicia Wanless, \u201cThere Is No Getting Ahead of Disinformation Without\nMoving Past It,\u201d Lawfare, May 8, 2023, https://www.lawfareblog.com/there-no-\ngetting-ahead-disinformation-without-moving-past-it.\n\n101 Peter Kafka, \u201cAre We Too Worried about Misinformation?,\u201d Vox, January 16,\n2023, https://www.vox.com/recode/2023/1/16/23553802/misinformation-twitter-\nfacebook-alex-stamos-peter-kafka-media-column; and Noortje Marres, \u201cWhy We\nCan\u2019t Have Our Facts Back,\u201d Engaging Science, Technology, and Society 4 (July\n24, 2018): 423\u2013443, https://doi.org/10.17351/ests2018.188.\n\n102 Martin Gurri, The Revolt of the Public and the Crisis of Authority in the\nNew Millennium (San Francisco: Stripe Press, 2018), 395-396.\n\n103 Robert O. Keohane and Joseph S. Nye, \u201cPower and Interdependence in the\nInformation Age,\u201d Foreign Affairs 77, no. 5 (1998): 81-94,\nhttps://doi.org/10.2307/20049052.\n\n104 Nils Gilman, \u201cDictatorships and Data Standards,\u201d The American Interest,\nApril 17, 2018, https://www.the-american-\ninterest.com/2018/04/17/dictatorships-data-standards.\n\n105 Doug Irving, \u201cTruth Decay Is Putting U.S. National Security at Risk,\u201d RAND\nCorporation, June 28, 2023, https://www.rand.org/blog/rand-\nreview/2023/06/truth-decay-is-putting-us-national-security-at-risk.html; and\nJonathan Haidt, \u201cWhy the Past 10 Years of American Life Have Been Uniquely\nStupid,\u201d The Atlantic, April 11, 2022,\nhttps://www.theatlantic.com/magazine/archive/2022/05/social-media-democracy-\ntrust-babel/629369.\n\n106 W. Lance Bennett and Barbara Pfetsch, \u201cRethinking Political Communication\nin a Time of Disrupted Public Spheres,\u201d Journal of Communication 68, no. 2\n(April 2018): 243\u2013253, https://doi.org/10.1093/joc/jqx017.\n\n107 Jowett and O\u2019Donnell, Propaganda & Persuasion, 199.\n\n108 James Gleick, Chaos: Making a New Science (New York: Penguin Books, 2008),\n96.\n\n109 Gillian Murphy et al., \u201cWhat Do We Study When We Study Misinformation? A\nScoping Review of Experimental Research (2016-2022),\u201d Harvard Kennedy School\nMisinformation Review, November 15, 2023,\nhttps://misinforeview.hks.harvard.edu/article/what-do-we-study-when-we-study-\nmisinformation-a-scoping-review-of-experimental-research-2016-2022.\n\n110 Rory Cormac et al., \u201cWhat Constitutes Successful Covert Action? Evaluating\nUnacknowledged Interventionism in Foreign Affairs,\u201d Review of International\nStudies 48, no. 1 (January 2022): 111-128,\nhttps://doi.org/10.1017/S0260210521000231.\n\n111 David Greenberg, \u201cLippmann vs. Mencken: Debating Democracy,\u201d 119.\n\n112 Yuval Levin, A Time to Build: From Family and Community to Congress and\nthe Campus, How Recommitting to Our Institutions Can Revive the American Dream\n(New York: Basic Books, 2020), 29-42.\n\n113 Anderson, \u201cFake News Is Not a Virus.\u201d\n\n114 Cormac et al., \u201cWhat Constitutes Successful Covert Action? Evaluating\nUnacknowledged Interventionism in Foreign Affairs,\u201d 118.\n\n115 Anastasia Kozyreva et al., \u201cCritical Ignoring as a Core Competence for\nDigital Citizens,\u201d Current Directions in Psychological Science 32, no. 1\n(2023): 81\u201388, https://doi.org/10.1177/09637214221121570.\n\n116 Josh A. Goldstein et al., \u201cGenerative Language Models and Automated\nInfluence Operations: Emerging Threats and Potential Mitigations,\u201d Stanford\nInternet Observatory, January 2023, https://cdn.openai.com/papers/forecasting-\nmisuse.pdf; and Michael Caulfield, \u201cRecalibrating Our Approach to\nMisinformation,\u201d EdSurge, December 19, 2018,\nhttps://www.edsurge.com/news/2018-12-19-recalibrating-our-approach-to-\nmisinformation.\n\n117 Ren\u00e9e DiResta, \u201cHow Online Mobs Act Like Flocks Of Birds,\u201d Noema, November\n3, 2022, https://www.noemamag.com/how-online-mobs-act-like-flocks-of-birds.\n\n118 Jungherr and Schroeder, \u201cDisinformation and the Structural Transformations\nof the Public Arena.\u201d\n\n119 David Karpf, \u201cOn Digital Disinformation and Democratic Myths,\u201d MediaWell,\nDecember 10, 2019, https://mediawell.ssrc.org/articles/on-digital-\ndisinformation-and-democratic-myths.\n\n120 Organization for Economic Co-operation and Development, Building Trust to\nReinforce Democracy: Main Findings from the 2021 OECD Survey on Drivers of\nTrust in Public Institutions (July 13, 2022),\nhttps://doi.org/10.1787/b407f99c-en.\n\n121 For a discussion on digital literacy\u2019s role in countering foreign\npropaganda, see Calder Walton, \u201cWhat\u2019s Old Is New Again: Cold War Lessons for\nCountering Disinformation,\u201d Texas National Security Review 5, no. 4 (Fall\n2022): 49-72, http://dx.doi.org/10.26153/tsw/43940.\n\n122 Th\u00e9ophile Lenoir, \u201cReconsidering the Fight Against Disinformation,\u201d Tech\nPolicy Press, August 1, 2022, https://techpolicy.press/reconsidering-the-\nfight-against-disinformation.\n\n123 Andreas Jungherr and Adrian Rauchfleisch, \u201cNegative Downstream Effects of\nAlarmist Disinformation Discourse: Evidence from the United States,\u201d Political\nBehavior (January 12, 2024): https://doi.org/10.1007/s11109-024-09911-3.\n\n124 Kate Starbird et al., \u201cDisinformation as Collaborative Work: Surfacing the\nParticipatory Nature of Strategic Information Operations,\u201d Proceedings of the\nACM on Human-Computer Interaction 3, Issue CSCW (November 7, 2019):\nhttps://doi.org/10.1145/3359229.\n\n125 Benton, \u201cGood News: Misinformation Isn\u2019t as Powerful as Feared! Bad News:\nNeither Is Information.\u201d\n\n126 Illing, \u201cIntellectuals Have Said Democracy Is Failing for a Century. They\nWere Wrong.\u201d\n\n127 Alice E. Marwick, \u201cWhy Do People Share Fake News? A Sociotechnical Model\nof Media Effects,\u201d Georgetown Law Technology Review 2, no. 2 (July 2018):\nhttps://georgetownlawtechreview.org/why-do-people-share-fake-news-a-\nsociotechnical-model-of-media-effects/GLTR-07-2018.\n\n128 John Dewey, \u201cCreative Democracy\u2014The Task Before Us,\u201d in John Dewey: The\nLater Works, 1925-1953, Volume 14: 1939-1941 (Carbondale, IL: Southern\nIllinois University Press, 2008), 224-230.\n\n129 John Dewey, The Public and Its Problems (New York: H. Holt and Company,\n1927), 206.\n\n130 Matthew Festenstein, \u201cDewey\u2019s Political Philosophy,\u201d The Stanford\nEncyclopedia of Philosophy, eds. Edward Zalta and Uri Nodelman (Spring 2023),\nhttps://plato.stanford.edu/archives/spr2023/entries/dewey-political.\n\nGavin Wilde\n\n### Gavin Wilde\n\nRead more about author Gavin Wilde Read More\n\n### Related Articles\n\nStabilizing Haiti: A Guide for Policymakers\n\n## Stabilizing Haiti: A Guide for Policymakers\n\nstrategist\n\nWeak States Spring 2024\n\nIan Murray, Chris Bernotavicius\n\nProposals for a security-focused intervention in Haiti are logical given the\nrampant instability and endless escalation of gang violence. Many argue that\nHaiti\u2019s foundational problems of economic underdevelopment, violence, and weak\ninstitutions cannot be...\n\nClimate Change and Military Power: Hunting for Submarines in the Warming Ocean\n\n## Climate Change and Military Power: Hunting for Submarines in the Warming\nOcean\n\nscholarly\n\nMilitary Operations Spring 2024\n\nAndrea Gilli, Mauro Gilli, Antonio Ricchi, Aniello Russo, Sandro Carniel\n\nClimate change will have significant effects on military power, capabilities,\neffectiveness, and employment. Yet, scholars have paid little attention to\nthis topic. We address this gap by investigating the effects of changing ocean\nconditions on anti-submarine...\n\nCracks in the Ivory Tower?\n\n## Cracks in the Ivory Tower?\n\nfoundation\n\nTNSR Winter 2023/2024\n\nFrancis J. Gavin\n\nIn his introduction to Volume 7, Issue 1, the chair of our editorial board,\nFrank Gavin, reflects on the joys of being a professor and the importance of\nhigher education. He also expresses concern about the health of American\nuniversities and calls on them to...\n\nTop\n\n### Hello From Texas!\n\n  * Roundtables\n  * Buy Print\n  * Submissions\n  * About\n  * Contact Us\n\n  * Design by Cast from Clay\n\n\u00d7\n\nStay in the know\n\n## Sign up to the TNSR newsletter:\n\nJoin\n\n", "frontpage": true}
