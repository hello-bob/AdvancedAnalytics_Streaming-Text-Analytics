{"aid": "40117425", "title": "How to add code interpreter to Llama 3", "url": "https://e2b.dev/blog/how-to-add-code-interpreter-to-llama3", "domain": "e2b.dev", "votes": 1, "user": "mlejva", "posted_at": "2024-04-22 18:42:54", "comments": 0, "source_title": "How to add code interpreter to Llama 3", "source_text": "How to add code interpreter to Llama 3\n\n###### Docs\n\n###### Changelog\n\n###### Blog\n\n###### Discord\n\nGuide\n\nApr 22, 2024\n\nTereza Tizkova\n\n# How to add code interpreter to Llama 3\n\nAt this moment, Llama 3 is one of the most capable open-source models. In this\nguide, we give Llama 3 code interpreter capabilities and test it on data\nanalysis and data visualization task.\n\n### Full code on GitHub\n\n### Code Interpreter SDK\n\nWe will show how to build a code interpreter with Llama 3 on Groq, and powered\nby open-source Code Interpreter SDK by E2B. The E2B Code Interpreter SDK\nquickly creates a secure cloud sandbox powered by Firecracker. Inside this\nsandbox is a running Jupyter server that the LLM can use.\n\n### Key links\n\n  * Get started with E2B\n\n  * Get started with Llama\n\n  * Get started with Groq\n\n  * Follow E2B\n\n### Overview\n\n  1. Setup\n\n  2. Configuration and API keys\n\n  3. Creating code interpreter\n\n  4. Calling Llama 3\n\n  5. Connecting Llama 3 and code interpreter\n\n  1. ### Setup\n\nWe will be working in Jupyter notebook. First, we install the code\ninterpreter.\n\n    \n    \n    %pip install groq e2b_code_interpreter\n\n  2. ### Configuration and API keys\n\nThen we store the Groq and E2B API keys and set the model name for the Llama 3\ninstance you will use. In the system prompt we define sets the rules for the\ninteraction with Llama.\n\n    \n    \n    # TODO: Get your Groq AI API key from https://console.groq.com/ GROQ_API_KEY = \"\" # TODO: Get your E2B API key from https://e2b.dev/docs E2B_API_KEY = \"\" # Or use 8b version # MODEL_NAME = \"llama3-8b-8192\" MODEL_NAME = \"llama3-70b-8192\" SYSTEM_PROMPT = \"\"\"you are a python data scientist. you are given tasks to complete and you run python code to solve them. - DO NOT RESPOND WITH ANYTHING ELSE BUT PYTHON CODE - DO NOT FORGET ANY IMPORTS LIKE `import numpy as np` - the python code runs in jupyter notebook. - every time you generate code, it's executed in a separate cell in jupyter notebook. - display visualizations using matplotlib or any other visualization library directly in the notebook. don't worry about saving the visualizations to a file. - you have access to the internet and can make api requests. - you also have access to the filesystem and can read/write files. - you can install any pip package (if it exists) if you need to but the usual packages for data analysis are already preinstalled. - you can run any python code you want, everything is running in a secure sandbox environment.\"\"\"\n\n  3. ### Creating code interpreter\n\nWe define a function that uses the E2B code interpreter to execute code in a\nJupyter Notebook cell.\n\n    \n    \n    def code_interpret(e2b_code_interpreter, code): print(\"Running code interpreter...\") exec = e2b_code_interpreter.notebook.exec_cell( code, on_stderr=lambda stderr: print(\"[Code Interpreter]\", stderr), on_stdout=lambda stdout: print(\"[Code Interpreter]\", stdout), # You can also stream code execution results # on_result=... ) if exec.error: print(\"[Code Interpreter ERROR]\", exec.error) else: return exec.results\n\n  4. ### Calling Llama 3\n\nNow we import required libraries for the Jupyter notebook to interact with the\nGroq API.\n\nWe define two functions. The match_code_blocks will extract code blocks from\ntext responses. The chat_with_llama will handle communication with Llama.\n\nSee the Groq documentation to get started.\n\n    \n    \n    import os import json import re from groq import Groq client = Groq(api_key=GROQ_API_KEY) def match_code_blocks(text): pattern = re.compile(r'```(?:python)?[\\n\\r](.*?)```', re.DOTALL) return pattern.findall(text) def chat_with_llama(e2b_code_interpreter, user_message): print(f\"\\n{'='*50}\\nUser message: {user_message}\\n{'='*50}\") messages = [ {\"role\": \"system\", \"content\": SYSTEM_PROMPT}, {\"role\": \"user\", \"content\": user_message} ] response = client.chat.completions.create( model=MODEL_NAME, messages=messages, ) content = response.choices[0].message.content # print(f\"\\nLlama 3 Response:\\n{content}\") # print(\"===\") code_results = [] code_blocks = match_code_blocks(content) for code in code_blocks: print(f\"Code to run: {code}\") code_interpreter_results = code_interpret(e2b_code_interpreter, code) print(f\"Tool Result: {code_interpreter_results}\") code_results.append(code_interpreter_results) return code_results\n\n  5. ### Connecting Llama 3 and code interpreter\n\nFinally, we can instantiate the code interpreter and pass the E2B API key.\n\n    \n    \n    from e2b_code_interpreter import CodeInterpreter with CodeInterpreter(api_key=E2B_API_KEY) as code_interpreter: all_code_blocks_results = chat_with_llama( code_interpreter, \"Visualize a distribution of haight of men based on the latest data you know\" ) for result in all_code_blocks_results: print(result[0]) # Each code block can have multiple code interpreter results first_result = all_code_blocks_results[0][0] # This will render the image # You can also access the data directly # first_result.png # first_result.jpg # first_result.pdf # ... first_result\n    \n    \n    ================================================== User message: Visualize a distribution of haight of men based on the latest data you know ================================================== Code to run: import matplotlib.pyplot as plt import numpy as np import scipy.stats as stats # According to the World Health Organization (WHO), the average height for an adult male is approximately 172 cm (5 ft 8 in) with a standard deviation of around 8-10 cm. # Let's simulate a distribution of heights with a mean of 172 cm and a standard deviation of 9 cm heights = np.random.normal(loc=172, scale=9, size=10000) # Visualize the distribution plt.hist(heights, bins=30, density=True, alpha=0.6, color='g') # Plot a fitted normal distribution curve x = np.linspace(150, 200, 100) y = stats.norm.pdf(x, loc=172, scale=9) plt.plot(x, y, 'r--') plt.xlabel('Height (cm)') plt.ylabel('Probability Density') plt.title('Distribution of Heights of Men') plt.show() Running code interpreter... Tool Result: [<e2b_code_interpreter.models.Result object at 0x7a0a3c156fe0>] <Figure size 640x480 with 1 Axes>\n\n### Full code on GitHub\n\n### Key links\n\n  * Get started with E2B\n\n  * Get started with Llama\n\n  * Get started with Groq\n\n  * Follow E2B\n\nE2B\n\nE2B is building the cloud for AI agents.\n\nA platform and infrastructure where AI agents can act autonomously and as the\nfirst class citizen.\n\nBy E2B\n\nMap of AI Agents\n\nMap of Agents' SDKs\n\nChatGPT Plugin\n\nAgent Protocol\n\nSmol Developer in Cloud\n\nLinks\n\nGitHub\n\nTwitter\n\nDiscord\n\nLinkedIn\n\nCompany\n\nContact\n\nBlog\n\nChangelog\n\n\u00a92023 FoundryLabs, Inc. All rights reserved.\n\n", "frontpage": false}
