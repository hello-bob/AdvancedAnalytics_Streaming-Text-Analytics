{"aid": "40174186", "title": "Smart Roads Get Better Eyesight", "url": "https://spectrum.ieee.org/smart-road-camera-radar-fusion", "domain": "ieee.org", "votes": 1, "user": "rbanffy", "posted_at": "2024-04-26 20:56:25", "comments": 0, "source_title": "Smart Roads Get Better Eyesight", "source_text": "Smart Roads Get Better Eyesight - IEEE Spectrum\n\nOpens in a new window Opens an external website Opens an external website in a\nnew window\n\nThis website utilizes technologies such as cookies to enable essential site\nfunctionality, as well as for analytics, personalization, and targeted\nadvertising purposes. You may change your settings at any time or accept the\ndefault settings. You may close this banner to continue with only essential\ncookies. Privacy Policy\n\nStorage Preferences\n\nIEEE.orgIEEE Xplore Digital LibraryIEEE StandardsMore Sites\n\nSign InJoin IEEE\n\nSmart Roads Get Better Eyesight\n\nShare\n\nFOR THE TECHNOLOGY INSIDER\n\nExplore by topic\n\nAerospaceArtificial IntelligenceBiomedicalClimate TechComputingConsumer\nElectronicsEnergyHistory of\nTechnologyRoboticsSemiconductorsTelecommunicationsTransportation\n\nIEEE Spectrum\n\nFOR THE TECHNOLOGY INSIDER\n\n### Topics\n\nAerospaceArtificial IntelligenceBiomedicalClimate TechComputingConsumer\nElectronicsEnergyHistory of\nTechnologyRoboticsSemiconductorsTelecommunicationsTransportation\n\n### Sections\n\nFeaturesNewsOpinionCareersDIYEngineering Resources\n\n### More\n\nNewslettersPodcastsSpecial ReportsCollectionsExplainersTop Programming\nLanguagesRobots Guide \u2197IEEE Job Site \u2197\n\n### For IEEE Members\n\nCurrent IssueMagazine ArchiveThe InstituteThe Institute Archive\n\n### For IEEE Members\n\nCurrent IssueMagazine ArchiveThe InstituteThe Institute Archive\n\n### IEEE Spectrum\n\nAbout UsContact UsReprints & Permissions \u2197Advertising \u2197\n\n### Follow IEEE Spectrum\n\n### Support IEEE Spectrum\n\nIEEE Spectrum is the flagship publication of the IEEE \u2014 the world\u2019s largest\nprofessional organization devoted to engineering and applied sciences. Our\narticles, podcasts, and infographics inform our readers about developments in\ntechnology, engineering, and science.\n\nJoin IEEE\n\nSubscribe\n\nAbout IEEEContact & SupportAccessibilityNondiscrimination PolicyTermsIEEE\nPrivacy PolicyCookie PreferencesAd Privacy Options\n\n\u00a9 Copyright 2024 IEEE \u2014 All rights reserved. A not-for-profit organization,\nIEEE is the world's largest technical professional organization dedicated to\nadvancing technology for the benefit of humanity.\n\n## Enjoy more free content and benefits by creating an account\n\n## Saving articles to read later requires an IEEE Spectrum account\n\n## The Institute content is only available for members\n\n## Downloading full PDF issues is exclusive for IEEE Members\n\n## Downloading this e-book is exclusive for IEEE Members\n\n## Access to Spectrum 's Digital Edition is exclusive for IEEE Members\n\n## Following topics is a feature exclusive for IEEE Members\n\n## Adding your response to an article requires an IEEE Spectrum account\n\n## Create an account to access more content and features on IEEE Spectrum ,\nincluding the ability to save articles to read later, download Spectrum\nCollections, and participate in conversations with readers and editors. For\nmore exclusive content and features, consider Joining IEEE .\n\n## Join the world\u2019s largest professional organization devoted to engineering\nand applied sciences and get access to all of Spectrum\u2019s articles, archives,\nPDF downloads, and other benefits. Learn more \u2192\n\n## Join the world\u2019s largest professional organization devoted to engineering\nand applied sciences and get access to this e-book plus all of IEEE Spectrum\u2019s\narticles, archives, PDF downloads, and other benefits. Learn more \u2192\n\nCREATE AN ACCOUNTSIGN IN\n\nJOIN IEEESIGN IN\n\nClose\n\n## Access Thousands of Articles \u2014 Completely Free\n\n## Create an account and get exclusive content and features: Save articles,\ndownload collections, and talk to tech insiders \u2014 all free! For full access\nand benefits, join IEEE as a paying member.\n\nCREATE AN ACCOUNTSIGN IN\n\nTransportationNewsJournal WatchComputing\n\n# Smart Roads Get Better Eyesight\n\n##\n\nA new way of fusing camera and radar data helps track vehicles at greater\ndistances\n\nEdd Gent\n\n23 Apr 2024\n\n4 min read\n\n1\n\nUSTC researchers captured car-tracking data from a radar [green], camera\n[blue], and a fusion of the two [yellow] on an expressway in Heifei, China.\n\nYao Li\n\nintelligent transportation systems journal watch millimeter wave radar self-\ndriving cars sensor fusion smart road smart roads traffic flow\n\nThis article is part of our exclusive IEEE Journal Watch series in partnership\nwith IEEE Xplore.\n\nSmart roads with advanced vehicle-sensing capabilities could be the linchpin\nof future intelligent transportation systems and could even help extend\ndriverless cars\u2018 perceptual range. A new approach that fuses camera and radar\ndata can now track vehicles precisely at distances of up to 500 meters.\n\nReal-time data on the flow and density of traffic can help city managers avoid\ncongestion and prevent accidents. So-called \u201croadside perception,\u201d which uses\nsensors and cameras to track vehicles, can help create smart roads that\ncontinually gather this information and relay it to control rooms.\n\n\u201cThis is the first work that offers a practical solution that combines these\ntwo types of data and works in real-world deployments and with really\nchallenging distances.\u201d \u2014Yanyong Zhang, University of Science and Technology\nof China, Hefei\n\nInstalling large numbers of road-side sensors can be expensive, though, as\nwell as time consuming to maintain, says Yanyong Zhang, a professor of\ncomputer science at the University of Science and Technology of China (USTC)\nin Hefei. For smart roads to be cost effective you need to use as few sensors\nas possible, she says, which means sensors need to be able to track vehicles\nat significant distances.\n\nUsing a new approach to fuse data from high-definition cameras and millimeter-\nwave radar, her team has created a system that can pinpoint vehicle locations\nto within 1.3 meters at ranges of up to 500 meters. The results were outlined\nin a recent paper in IEEE Robotics and Automation Letters.\n\n\u201cIf you can extend the range as far as possible, then you can reduce the\nnumber of sensing devices you need to deploy,\u201d says Zhang. \u201cThis is the first\nwork that offers a practical solution that combines these two types of data\nand works in real-world deployments and with really challenging distances.\u201d\n\n### Where Camera-Radar Fusion Becomes Necessary\n\nCameras and radar are both good low-cost options for vehicle tracking, says\nZhang, but individually they struggle at distances much beyond 100 meters.\nFusing radar and camera data can significantly extend ranges, but to do so\ninvolves surmounting a range of challenges due to sensors generating\ncompletely different kinds of data. While the camera captures a simple 2D\nimage, the radar output is inherently 3D and can in fact be processed to\ngenerate a bird\u2019s-eye view. Most approaches to camera-radar fusion to date\nhave simply projected the camera data onto the radar\u2019s birds-eye view, says\nZhang, but the researchers discovered that this was far from optimal.\n\nIn order to better understand the problem, the USTC team installed a radar and\na camera on a pole at the end of a straight stretch of expressway close to the\nuniversity. They also installed a lidar on the pole to take ground-truth\nvehicle-location measurements, and two vehicles with high precision GPS units\nwere driven up and down the road to help calibrate the sensors.\n\nThe researchers installed a camera, radar and lidar to track vehicles on an\nexpressway in Heifei, China.Yao Li\n\nOne of Zhang\u2019s Ph.D. students, Yao Li, then carried out experiments with the\ndata collected by the sensors. He discovered that projecting 3D radar data\nonto the 2D images resulted in considerably lower location errors at longer\nranges, compared to the standard approach in which image data is mapped onto\nthe radar data. This led them to the conclusion that it would make more sense\nto fuse the data in the 2D images, before projecting it back to a bird\u2019s-eye\nview for vehicle tracking.\n\nAs well as allowing precise localization at distances of up to 500 meters, the\nresearchers showed that the new technique also boosted the average precision\nof tracking at shorter distances by 32 percent compared to previous\napproaches. While the researchers have tested the approach only offline on\npreviously collected datasets, Zhang said the underlying calculations are\nrelatively simple and should be possible to implement in real time on standard\nprocessors.\n\nUsing more than one sensor also entails careful synchronization, to ensure\nthat their data streams match up. Over time, environmental disturbances\ninevitably cause the sensors to drift apart, and they have to be recalibrated.\nThis involves driving the GPS-equipped vehicle up and down the expressway to\ncollect ground truth location measurements that can be used to tune the\nsensors.\n\nThis is time consuming and costly, so the researchers also built a self-\ncalibration capability into their system. The process of projecting the radar\ndata onto the 2D image is governed by a transformation matrix based on the\nsensors\u2019 parameters and physical measurements done during the calibration\nprocess. Once the data has been projected, an algorithm then tries to match up\nradar data points with the corresponding image pixels.\n\nIf the distance between these data points starts to increase, that suggests\nthe transformation matrix is becoming increasingly inaccurate as the sensors\nmove. By carefully tracking this drift, the researchers are able to\nautomatically adjust the transformation matrix to account for the error. This\nonly works up to a point, says Zhang, but it could still significantly reduce\nthe number of full-blown calibrations required.\n\nAltogether, Zhang says this makes their approach practical to deploy in the\nreal world. As well as providing better data for intelligent transport\nsystems, she thinks this kind of roadside perception could also provide future\nself-driving cars with valuable situational awareness.\n\n\u201cIt\u2019s a little futuristic, but let\u2019s say there is something happening a few\n100 meters away and the car is not aware of it, because it\u2019s congested, and\nits sensing range couldn\u2019t reach that far,\u201d she says. \u201cSensors along the\nhighway can disseminate this information to the cars that are coming into the\narea, so that they can be more cautious or select a different route.\u201d\n\nFrom Your Site Articles\n\n  * The Man Who Invented Intelligent Traffic Control a Century Too Early \u203a\n  * Smart Road to Parked Car: Talk to Me \u203a\n\nRelated Articles Around the Web\n\n  * Smart Road, Smart Car: The Automated Highway System | FHWA \u203a\n\nintelligent transportation systemsjournal watchmillimeter waveradarself-\ndriving carssensor fusionsmart roadsmart roadstraffic flow\n\nEdd Gent\n\nis a freelance science and technology writer based in Bengaluru, India. See\nfull bio \u2192\n\nThe Conversation (0)\n\nSort by\n\nRoboticsNewsHumanoid Robots\n\n## Video Friday: RACER Heavy\n\n5 hours ago\n\n4 min read\n\nEnergyNewsClimate Tech\n\n## As Ukraine Builds New Reactors, Renewables Beckon\n\n5 hours ago\n\n5 min read\n\nArtificial IntelligenceMagazineOpinion\n\n## Travels with Perplexity AI\n\n7 hours ago\n\n3 min read\n\n## Related Stories\n\nTransportationArtificial IntelligenceNews\n\n## Startups Say India Is Ideal for Testing Self-Driving Cars\n\nAerospaceNewsClimate TechJournal WatchClimate Change\n\n## Oh, Buoy! Satellite Data Helps Pinpoint Ocean Waves\n\nBiomedicalNewsJournal Watch\n\n## Tiny Sensor Aims to Monitor Tumors in Real Time\n\n", "frontpage": false}
