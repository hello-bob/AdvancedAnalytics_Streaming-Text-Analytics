{"aid": "40139434", "title": "Simulating Jupiter", "url": "https://emildziewanowski.com/flowfields/", "domain": "emildziewanowski.com", "votes": 7, "user": "imadr", "posted_at": "2024-04-24 01:32:39", "comments": 0, "source_title": "Emil Dziewanowski - Technical Artist", "source_text": "Flowfields | Emil Dziewanowski - Technical Artist\n\nEmil Dziewanowski\n\nTECHNICAL ARTIST\n\nPREV\n\nNEXT\n\n# Flowfields\n\nEmil Dziewanowski\n\nTECHNICAL ARTIST\n\nPREVIOUS\n\nNEXT\n\n# Flowfields\n\nRealistic is not necessarily the most convincing. Audio designers know that\nwell and use frozen leeks and watermelons to create sounds of breaking bones\nand tearing flesh. Chalk shot from slingshot was safer alternative for actual\nfirearms in old westerns. Fake doesn\u2019t have to mean worse, especially when it\nis hard to tell the difference. With that in mind I will try to create complex\nflow without using computational fluid dynamics.\n\n## New, Better Jupiter\n\nJupiter\u2019s is undeniably beautiful, but it\u2019s safest to admire it from a\ndistance. Characteristic patterns observed on the surface are, in fact,\nmassive storms and Earth-sized cyclones. Jovian winds can reach speeds of\nhundreds of kilometers per hour, although they may appear quaint from orbit.\n\nI plan to feature a Jupiter-like planet as part of the skybox. While not a\nunique concept and often seen in the sci-fi genre, I want to take it a step\nfurther by animating it. In reality, the motion of the atmosphere is too slow\nto be noticed. However, I will speed it up substantially to make the movement\nobvious. This should capture players\u2019 attention and remind them that the\naction is taking place on a distant, alien world.\n\n## Flow\n\nWhile I don\u2019t want to create a carbon copy of Jupiter, there is a set of\nfeatures that immediately come to mind when thinking about gas planet.\nHopefully, by recreating these, I will get the visuals reminiscent of Jupiter.\n\nThere are three distinct flow patterns I want to replicate :\n\n  * Cyclones: A couple of large, easily identifiable vortices, much like Jupiter\u2019s \u2018Great Red Spot.\u2019 Typically elongated, they are often accompanied by a \u2018wake\u2019 \u2013 a trail of secondary vortices.\n  * Jets: These are linear currents that run parallel to the equator, with easily visible turbulent transition layers.\n  * Storms: Smaller, more volatile, and less defined flow structures that contribute to the texture of the atmosphere.\n\n## Animating Fluids\n\nRecreating water or any other sort of fluid in games is challenging.\nComputational fluid dynamics is demanding in terms of memory and processing\npower, but that hasn\u2019t prevented game developers from including water in their\ngames. With a set of clever hacks and workarounds, there is no need for\nexpensive simulation.\n\n### Color Cycling\n\nColor cycling is a technique with a long history, dating back to systems like\nthe NES. It\u2019s akin to painting by numbers, where colors representing different\nnumbers change each frame. Despite its simplicity, when applied to well-\nprepared input sprites, it can produce eye-catching effects.\n\n### Frame-by-Frame Animation\n\nFor a while, the frame-by-frame approach was the standard solution. Each frame\nwas stored as a separate sprite, which demanded a lot of memory. As a result,\nthis method was typically reserved for short animation loops consisting of\nonly a few frames.\n\nLimited number of animation frames leads to a \u2018choppy\u2019 motion, typical of 90s\nshooters.\n\n### Texture Scrolling\n\nAs soon as games moved into fully textured 3D environments, texture scrolling\nbecame a viable option for creating rivers. This method involves incrementing\none of the UV components over time to create the illusion of moving texture.\nWhen combined with appropriate geometry and shaders, texture scrolling can\nyield impressive results and remains a popular choice.\n\nWhile versatile this technique is limited to laminar flow \u2013 it is non-trivial\nto add vortices or any other complex flow patterns.\n\n### Quake UV Distortion\n\nId Software, the developer behind Quake, is renowned for its innovations. The\nwater distortion they created is rarely listed among them, but is still worth\nlooking into. This simple formula lends Quake\u2019s lava, water, and portals their\ndistinctive appearance.\n\nAlthough it\u2019s straightforward to replicate using shaders, the original effect\nwas made without them, relying instead on software rendering.\n\n### Unreal WaterPaint\n\nWaterPaint is one of the most intriguing methods for simulating fluids in\ngames, yet it\u2019s also one of the most challenging to understand. It appears to\ngenerate the surface of the liquid and subsequently uses this information to\ndistort a texture. The system\u2019s complexity borders on overengineering,\nparticularly given that the resulting effect is often overlooked in a fast-\npaced shooter.\n\nSimilarly to Quake this technique also predates shaders. Texture pixels are\nmanipulated by CPU and then sampled just like in the case of normal texture.\n\nThe methods mentioned are decades old and, on their own, may not hold up well\ntoday. However, they still have value as components within larger, more\ncomplex systems.\n\n## Velocity Texture\n\nLet\u2019s create a \u201cuniversal\u201d flow shader capable of representing any motion of\nthe fluid. Intuitively, we\u2019ll need two textures: one representing the color of\nthe flowing substance, and another one storing the velocity field. This\nvelocity field texture will be a 2-component 2D texture, with the red\ncomponent representing the x component of the normalized velocity and the\ngreen component representing the y component.\n\nThe velocity field is then used to incrementally modify the texture\ncoordinates of the color texture, in the same manner like in the \u2018Texture\nScrolling\u2019 described previously. However, in this case, the velocity values\nvary for each pixel.\n\nThe result, while interesting, is rather disappointing as it doesn\u2019t\naccurately simulate fluid motion. Instead, it is an animated distortion that\ngradually bends the color texture over time.\n\nThe formula worked for simple scrolling because in that case the motion was\nlinear and constant. At each point, the velocity was the same. However, here\nthe velocity is more complex \u2013 it is defined per pixel. The correct approach\nwould be to use integration.\n\n## Euler Method\n\nLet\u2019s simplify the problem. Imagine we have a tiny speck of dust sitting on\nthe surface of water that\u2019s moving. We describe the water\u2019s movement using a\ntexture that shows its velocity. Now, we want to figure out the path this\nspeck of dust would take.\n\nThe first solution that comes to mind is to take a small step forward, check\nand update the velocity, then take another step using the updated velocity,\nand repeat this process. This is called Explicit Euler Method:\n\nThe Explicit or Forward Euler method is often seen as the most basic and least\naccurate numerical integration method. The larger the integration step,\ndenoted as \u201ch,\u201d the greater the error, and these errors accumulate over time.\nEven in the example shown, the integrated path represented by the orange\narrows deviates significantly from the particle\u2019s true path, depicted by the\ngray line. Fortunately this inaccuracy won\u2019t be noticeable in the animation.\n\nThe problem is, it\u2019s not easy to transform Euler Method directly into a\nshader. We need to keep track of the particle\u2019s position after each step, and\nthis is something shader alone cannot do. Position, in form of a deformed\ncolor texture, has to be stored in a texture.\n\nThe shader reads the texture storing the color of the fluid and deforms it\nslightly based on the velocity texture. The resulting deformation is then\nwritten back into the color texture. This operation is performed every frame\nof the animation.\n\nTo complicate the problem further, it\u2019s generally not possible to read from\nand write to the same texture in a fragment shader. Unreal Engine solves this\nproblem with Canvas.\n\n## Canvas Node Setup\n\nCanvas enables the use of a flow shader (Material) to be drawn into a Render\nTarget texture. What sets Canvas apart is its capability to use the same\nRender Target in both the input and output of the flow shader, forming a\nfeedback loop. To make this process work, several components are necessary:\n\n  * Render Target Texture: This image stores the state of the flow, or the color of the fluid in our case. It must be created before the animation begins and initial color has to be set.\n  * Rendering Event: The process of updating the animation has to be performed every frame, or at least every frame the animated object is visible.\n  * Flow Material Instance: An instance of the Flow Material is necessary, and it has to be supplied with its own Render Target Texture.\n\nOnce all these elements are in place, the Rendering Event, which corresponds\nto one step of fluid simulation, can be achieved using just 3 nodes:\n\n  * Begin Draw Canvas to Render Target\n  * Draw Material\n  * End Draw\n\nWith everything set up, the resulting animation should look like this:\n\nThe initial image is shifted in a more fluid manner, with each pixel moving\nmore continuously. However, it still falls short of resembling the motion of a\nliquid.\n\n## Improving Velocity Field\n\nUp until now, we\u2019ve relied on basic smoothed 2D vector noise. While sufficient\nfor testing basic functionality, it not enough to realistically representing\nfluid flow. Liquids tend to swirl around, forming vortices and other complex\npatterns, which simple noise cannot approximate effectively.\n\nFortunately, a mathematical operator, the curl, can be particularly useful\nhere. By applying it to scalar noise, we transform it into a velocity field\nfull of vortices.\n\nTo describe curl in the simplest way possible \u2013 in 2D case curl will create a\nclockwise flow around areas brighter than the surrounding, and\ncounterclockwise flow around darker areas. I describe curl in more detail in\nDissecting Curl Noise article.\n\nThere are multiple ways to calculate curl. DDX and DDY operators are useful in\nShadertoy, where the input is not a static texture but a procedural noise. For\nmore traditional applications like Unreal and Unity, it\u2019s probably better to\ngenerate it using image generation software like Substance Designer or\nPhotoshop. Any software capable of generating a normal map from a grayscale\nimage will be helpful here, as converting a normal map to curl is simply a\nmatter of swizzling and inverting channels.\n\nThe addition of swirly motion adds a fluid-like quality to the animation,\nalthough it still appears somewhat static.\n\nThe stationary vortices are the reason behind the artificial appearance. This\ncan be addressed by distorting velocity field using the same function that\nmanipulated lava in Quake.\n\nThe flow still lacks the complexity needed to resemble natural motion, but\nthis can be remedied with a more detailed velocity field.\n\n## Mixing\n\nWhen the algorithm runs for too long, another problem becomes apparent:\nmixing. While it\u2019s a desired feature, after a while, it turns the flow colors\ninto a solid mass, devoid of any visual interest.\n\nTo remedy that, color can be reintroduced by sampling the initial color\ntexture and blending it with the Render Target texture. This process involves\nusing a point grid mask to mimic pigment dissolving in the fluid.\n\nThat solves the issue of mixing, but the pattern of points remains too\nnoticeable. By using a noise texture and applying Quake distortion to it, the\neffect becomes less conspicuous and more natural.\n\nJupiter\u2019s appearance is attributed to its water-ammonia clouds, which have a\nrange of compositions and colors. These clouds undergo atmospheric\ncirculation, occasionally pushing layers from below to the surface. This\nphenomenon results in changes in surface colors and structure over time.\n\nI\u2019ll artificially limit cloud compositions to 3 and assign a texture channel\nto each. Then, to simulate shifts in composition, I\u2019ll utilize color cycling.\nIn shader terms, the initial color, before being sampled and mixed with the\nrender target, will undergo slight modifications over time. The result may\nlook psychedelic, but ultimately, it will replaced by more natural set of\ncolors. Right now those rainbow patterns serve as an useful placeholder.\n\nThe left side displays the initial color, while the right side shows the flow.\n\n## Sharpening\n\nAnother side effect of mixing is the blurring of the texture. As the image\nbecomes progressively smoother, the details are lost, causing the texture to\nappear low-resolution, which is certainly an undesirable outcome.\n\nThe obvious solution is to use sharpening \u2013 an operation opposite to blurring.\nIn its simplest form, it samples five pixels \u2013 the original one and its four\nneighbors \u2013 and returns their weighted sum. The layout of the pixels with\ntheir respective weights is called a kernel.\n\nI will use a slightly different formula, one that isolates the \u2018delta\u2019 or\nchange in color. This delta is then multiplied by the strength of sharpening.\nThis approach gives me more control over the effect.\n\nThe material graph representation might seem daunting at first glance, but\nit\u2019s essentially the result of repeating the same sampling operation multiple\ntimes with different parameters.\n\nSharpen is a separate Canvas rendering operation that follows the animation\nstep.\n\nSharpening enhances the details but also introduces stripe artifacts.\n\nThis occurs because it is part of the feedback loop. It amplifies the\ndifference between pixels, and the next sharpening step further magnifies the\ndifference. This continues until the color values reach their maximum or\nminimum value.\n\nThe solution to that problem is far from elegant but very effective \u2013 clamping\nthe calculated difference. This way, the difference doesn\u2019t increase\nexponentially and the artifacts have no chance to form.\n\nSharpening with clamping:\n\nWith that in place, we can consider the whole system complete \u2013 we have a set\nof tools that allow for recreating a wide array of flow types in real-time.\nNow, to make further improvements, we need to enhance the input data \u2013\nspecifically, the velocity field.\n\n## Flow Patterns\n\nThere are 3 flow patterns that can be easily identified on Jupiter:\n\n  * Cyclones\n  * Jets\n  * Storms\n\nThis list is by no means exhaustive. While there are numerous smaller and less\nnoticeable flow details, many of them can be replicated using the same\ntechniques employed for the main three patterns.\n\nI will attempt to translate these patterns into corresponding velocity fields.\nThis way, the complex flow on Jupiter can be broken down into individual flow\ncomponents. These components could then be rearranged later to create a new,\nunique gas giant.\n\n## Creating Flowfields\n\nAs mentioned earlier, in a real-game scenario like Unreal or Unity, it\u2019s not\npractical to generate the velocity field from scratch. It\u2019s more efficient to\ngenerate most of the components in Substance Designer or Photoshop and then\ncombine them in the shader to achieve the desired result. This approach allows\nus to create complex patterns with no additional costs.\n\nI chose to create velocity textures in Substance Designer due to its\nflexibility and non-destructive workflow.\n\n### Cyclones\n\nA cyclone is essentially a large vortex. Creating one involves generating a\nlarge blurred black or white dot and passing it through the curl operator. To\nadd more complexity, the result can be combined with another operator \u2013 the\ngradient. This allows the cyclone to either suck in or expel matter, making it\nmore dynamic.\n\nRelation between curl and gradient is explained here in more detail.\n\nThe velocity field is generated by blending a mixture of curl and gradient\noperators over the previously created flow pattern.\n\nSubstance Designer enables the creation of more complex and detailed velocity\nfields. In this case, the cyclone flowfield was slightly deformed and\nelongated, featuring a non-linear speed distribution. Unlike a flowfield\ngenerated in a shader from scratch, all these details incur no additional cost\n\u2013 everything is baked into the texture.\n\n### Jets\n\nThe bands around Jupiter are known as belts and zones. Belts consist of\ndarker, warmer clouds, while zones are characterized by brighter clouds made\nof ice. Strong currents form at the transitions between these bands. These\ncurrents, known as jets, run parallel to the equator and alternate in\ndirection. Where two jets meet, the flow becomes turbulent, creating chains of\nvortices.\n\nReplicating that is relatively simple: blurred stripes represent the laminar\nflow of the jets, while a curl applied to a series of dots creates vortices.\nIt\u2019s worth noticing the color of the dots; the spin of resulting vortices has\nto match the direction of the surrounding jets.\n\nOnce again, the flowfield generated in Designer exhibits more detail.\nTransition vortices are more scattered and vary in size. Additionally, jets\nare slightly disturbed to create a more wavy flow.\n\n### Storms\n\n\u201cStorms\u201d is the term I used to encompass all the smaller vortices and\nturbulent streams that accompany the main currents. They are essentially\nnoise, and I will approach creating them in the same way I would create noise.\n\nNoise is typically comprised of multiple layers called octaves. Each\nsubsequent octave contains smaller details and has a diminishing influence. In\nthe case of a velocity field, each layer also has to be animated separately.\n\nThose layers are then blended together to form complex, turbulent motion.\n\nSubstance Designer features storms gathered into clusters. Two versions of\nthat texture are packed into a single texture and blended using moving masks\nto simulate quickly shifting currents.\n\nIt\u2019s a different approach that results in patches of turbulent flow, as\nopposed to the uniformly distributed storms generated in Shadertoy. These\npatches resemble what can be observed on Jupiter more closely.\n\n### Combined\n\nThe division into cyclones, jets, and storms was artificial but proved quite\nuseful for illustrating some of the techniques that can be used to mimic real\nflowfields. Each flow pattern can be achieved in many different ways, with no\nsingle approach that can be described as the \u201cright\u201d one.\n\nTo merge all these components together, a simple addition would suffice, but\nusing alpha blending allows for accentuating some features like cyclones and\ntoning down turbulence in certain areas.\n\nAt this stage, when all the components are ready, blending them together is\nmore a matter of artistic choice than mathematics. After all, none of the\npresented techniques have solid grounding in physics \u2013 they are just\napproximations of natural phenomena.\n\n## 2010: The Year We Make Contact\n\nWhen I started working on the animation of the gas giant, I was really excited\nabout the idea because I naively thought that this was going to be something\nnovel, never tried before. Obviously, I was wrong. Films like \u2018Outland\u2019,\n\u20182010: The Year We Make Contact\u2019, and \u2018Contact\u2019 all featured animated Jupiter.\n\nThe most interesting portrayal here is the rendition created by Digital\nProductions for \u20182010: The Year We Make Contact\u2019. The technology behind it is\na marvel of CGI, even though it looks like a perfectly executed practical\neffect.\n\nThe basic idea remains largely the same: utilizing a flowfield to deform the\ninitial image. However, the execution differs significantly. While I used\nSubstance Designer to generate flow textures, the team at Digital Productions\nutilized actual fluid mechanics to simulate the flow. My solution to the\nproblem of mixing was to artificially reintroduce the color, whereas they\nsidestepped the problem entirely by converting the image into particles.\n\nRemarkably, all of this was accomplished without the aid of modern CGI\nsoftware or computing power. Instead, it relied on the ingenuity of a team of\nbrilliant engineers and artists, supported by the CRAY X-MP.\n\nThe work of Larry Yaeger and Craig Upson is described in greater detail in\nSiggraph and Cinefex articles. Additionally, there is a documentary available\non YouTube.\n\n## Further Developement\n\nThe presented methods should be sufficient to create convincing-looking flow,\nbut not necessarily a visually appealing planet. Achieving that requires\nseveral additional steps:\n\n  * Colors: Currently, the R, G, and B channels represent different substances. Ultimately they will be replaced with a color texture.\n  * UV Mapping: Currently, the texture is just a square; it needs to be wrapped around a sphere. However, I plan to use the method described in Flat Planets and apply it to a flat disc.\n  * Shading: Atmosphere is lit differently than a solid, opaque object. A specialized shading model has to be created to complete the effect.\n\n## Conclusions\n\nThe initial setup required some effort, both in Unreal and in Substance\nDesigner, but once in place, it allowed for easy tweaking and modifications.\nSince it does not rely on computational fluid dynamics, the motion can be\nhandcrafted, which is both a strength and a challenge. It offers total freedom\nto create any flow imaginable, but requires the artist to have a basic\nunderstanding of fluid dynamics.\n\nMost importantly, it can compete with actual fluid simulations while using\nonly a fraction of resources. A full planet with a 1024\u00d71024 texture takes\nless than 0.5ms to render, which is a modest price for such VFX.\n\n", "frontpage": true}
