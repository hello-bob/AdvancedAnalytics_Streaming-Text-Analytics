{"aid": "40104089", "title": "Dream \u2013 A Distributed RAG Experimentation Framework", "url": "https://github.com/aishwaryaprabhat/goku/tree/main/goku/dream", "domain": "github.com/aishwaryaprabhat", "votes": 1, "user": "jtsymonds", "posted_at": "2024-04-21 08:38:02", "comments": 0, "source_title": "goku/goku/dream at main \u00b7 aishwaryaprabhat/goku", "source_text": "goku/goku/dream at main \u00b7 aishwaryaprabhat/goku \u00b7 GitHub\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\naishwaryaprabhat / goku Public\n\n  * Notifications\n  * Fork 4\n  * Star 51\n\n/\n\n# dream\n\n/\n\n## Directory actions\n\n## More options\n\n## Directory actions\n\n## More options\n\n## Latest commit\n\naishwaryaprabhat\n\nadded toc to README\n\nApr 15, 2024\n\n7cb3060 \u00b7 Apr 15, 2024Apr 15, 2024\n\n## History\n\nHistory\n\n/\n\n# dream\n\n/\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n### parent directory\n\n..  \n  \n### assets\n\n|\n\n### assets\n\n| notebooks tidied up| Apr 15, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| working dream| Apr 14, 2024  \n  \n### 1_Unstructued_Data_Preparation.ipynb\n\n|\n\n### 1_Unstructued_Data_Preparation.ipynb\n\n| notebooks tidied up| Apr 15, 2024  \n  \n### 2_Distributed_Golden_Dataset_Creation.ipynb\n\n|\n\n### 2_Distributed_Golden_Dataset_Creation.ipynb\n\n| notebooks tidied up| Apr 15, 2024  \n  \n### 3_Distributed_RAG_Experimentation_Evaluation.ipynb\n\n|\n\n### 3_Distributed_RAG_Experimentation_Evaluation.ipynb\n\n| notebooks tidied up| Apr 15, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| added toc to README| Apr 15, 2024  \n  \n### download_dataset.sh\n\n|\n\n### download_dataset.sh\n\n| Merge working ray setup (#1)| Apr 10, 2024  \n  \n### eval_results.csv\n\n|\n\n### eval_results.csv\n\n| working dream| Apr 14, 2024  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| pre-article stuff for preview| Apr 14, 2024  \n  \n## README.md\n\n# DREAM: Distributed RAG Experimentation Framework\n\nDistributed RAG Experimentation Framework (DREAM) is a blueprint comprising of\na kubernetes native architecture and sample code to demonstrate how Retrieval\nAugmented Generation experiments, evaluation and tracking can be conducted in\na distributed manner using Ray, LlamaIndex, Ragas, MLFlow and MinIO.\n\n## Table of Contents\n\n  * Why DREAM?\n  * Architecture\n  * Installation\n  * Code Overview\n\n    * Unstructured Data Preparation\n    * Distributed Golden Dataset Creation\n    * Distributed RAG Experimentation, Evaluation & Tracking\n\n## Why DREAM?\n\nGiven the myriad of options for LLMs, embedding models, retrieval methods, re-\nranking methods and so on, it can be challenging to determine which\ncombination will work best for your usecase. Who has the time to explore each\ncombination one by one? DREAM shows you how to setup the necessary Kubernetes\ntooling and run the code necessary to explore the vast search space\nefficiently.\n\nBy setting up the necessary K8s tooling and running the experimentation,\nevaluation and tracking in a distributed manner, we ultimately want to be able\nto compare and contrast the different combinations of RAG parameters and pick\nthe one that works best for our usecase.\n\n## Architecture\n\n## Installation\n\n  * For installation of Kubernetes , follow the steps provided in the setup doc. You can skip the setup of Argo Workflows, Argo Events, Milvus and other GOKU components not needed for DREAM.\n  * Make sure that the minor version of the Python kernel used in the notebook is the same as that of your Ray cluster. It is advised that you use Conda and Conda virtual environments.\n  * You might find it useful to pip install -r requirements.txt once you have activated your conda virtual environment.\n  * To verify your Ray and Conda setup, you can launch a notebook and run the following code\n\n    \n    \n    import ray import os os.environ['RAY_ADDRESS'] = 'ray://localhost:10001' # Initialize Ray # ray.init() @ray.remote def square(num): \"\"\"A remote function to compute the square of a number.\"\"\" return num * num # Create a list to hold references to the asynchronous tasks futures = [] # Distribute the computation of squares across Ray workers for i in range(100): futures.append(square.remote(i)) # Retrieve and print the results results = ray.get(futures) print(results)\n\n## Code Overview\n\n### Unstructured Data Preparation\n\n  * In this notebook, we download a bunch of PDFs to act as our unstructured data.\n  * We then upload these PDFs into a S3 (MinIO) bucket for use later on.\n\n### Distributed Golden Dataset Creation\n\n  * In this notebook, we use the Ragas framework to\n  * With our Jupyter notebook acting as the Ray driver, we use the ray client to submit the Ray job for creating the golden dataset in a distributed manner.\n  * In each Ray task, upto 3 PDFs are loaded from S3 and then the ragas framework's TestsetGenerator is used for synthetic test data generation. Pandas dataframes with the synthetic data are returned by each task.\n  * The driver (Jupyter notebook), combines the dataframes and dumps the combined dataframe as a csv file onto S3.\n\n### Distributed RAG Experimentation, Evaluation & Tracking\n\n  * With our Jupyter notebook acting as the Ray driver, we use the ray client to submit the Ray Tune job.\n  * Our search space spans over 3x RAG methods, 2x LLMs 2x embedding models. We use 3 RAG methods native to LlamaIndex - chunks with overlap, sentence window retrieval and hierarchical automerging retrieval. We use gpt-3.5-turbo and gpt-4 as our LLMs, with text-embedding-3-small and text-embedding-3-large as our embedding models. For evaluation, we use the ragas framework's faithfulness, answer_relevancy, context_precision, context_recall, answer_correctness and answer_similarity as metrics.\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
