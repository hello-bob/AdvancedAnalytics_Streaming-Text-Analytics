{"aid": "40117164", "title": "AI now surpasses humans in almost all performance benchmarks", "url": "https://newatlas.com/technology/ai-index-report-global-impact/", "domain": "newatlas.com", "votes": 4, "user": "miles", "posted_at": "2024-04-22 18:21:11", "comments": 2, "source_title": "AI now surpasses humans in almost all performance benchmarks", "source_text": "AI now surpasses humans in almost all performance benchmarks\n\n\u00a9 2024 New Atlas\n\nTechnology\n\n# AI now surpasses humans in almost all performance benchmarks\n\nBy Paul McClure\n\nApril 19, 2024\n\n  * Facebook\n  * Twitter\n  * Flipboard\n  * LinkedIn\n\nAI now surpasses humans in almost all performance benchmarks\n\nA comprehensive report has detailed the global impact of AI\n\nDALL-E\n\nView 5 Images\n\n1/5\n\nA comprehensive report has detailed the global impact of AI\n\nDALL-E\n\n2/5\n\nAI has already surpassed many human performance benchmarks\n\nAI Index 2024\n\n3/5\n\nAn example MATH question asked of the AI. Yikes!\n\nHendryks et al./AI Index 2024\n\n4/5\n\nA sample question used to test an AI's visual commonsense reasoning\n\nZellers et al./AI Index 2024\n\n5/5\n\nHow text-to-image generation has improved with progressive versions of\nMidjourney\n\nMidjourney/AI Index 2024\n\nView gallery - 5 images\n\n## Stand back and take a look at the last two years of AI progress as a\nwhole... AI is catching up with humans so quickly, in so many areas, that\nfrankly, we need new tests.\n\nStanford University\u2019s Institute for Human-Centered Artificial Intelligence\n(HAI) has released the seventh annual issue of its comprehensive AI Index\nreport, written by an interdisciplinary team of academic and industrial\nexperts.\n\nThis edition has more content than previous editions, reflecting the rapid\nevolution of AI and its growing significance in our everyday lives. It\nexamines everything from which sectors use AI the most to which country is\nmost nervous about losing jobs to AI. But one of the most salient takeaways\nfrom the report is AI\u2019s performance when pitted against humans.\n\nMore Stories\n\nTechnology\n\nThe bad and the ugly: AI is harmful, unreliable and running out of data\n\nDrones\n\nSolar-cell-packin' drone uses sunlight for on-the-spot recharging\n\nFor people that haven't been paying attention, AI has already beaten us in a\nfrankly shocking number of significant benchmarks. In 2015, it surpassed us in\nimage classification, then basic reading comprehension (2017), visual\nreasoning (2020), and natural language inference (2021).\n\nAI is getting so clever, so fast, that many of the benchmarks used to this\npoint are now obsolete. Indeed, researchers in this area are scrambling to\ndevelop new, more challenging benchmarks. To put it simply, AIs are getting so\ngood at passing tests that now we need new tests \u2013 not to measure competence,\nbut to highlight areas where humans and AIs are still different, and find\nwhere we still have an advantage.\n\nIt's worth noting that the results below reflect testing with these old,\npossibly obsolete, benchmarks. But the overall trend is still crystal clear:\n\nAI has already surpassed many human performance benchmarks\n\nAI Index 2024\n\nLook at those trajectories, especially how the most recent tests are\nrepresented by a close-to-vertical line. And remember, these machines are\nvirtual toddlers.\n\nThe new AI Index report notes that in 2023, AI still struggled with complex\ncognitive tasks like advanced math problem-solving and visual commonsense\nreasoning. However, \u2018struggled\u2019 here might be misleading; it certainly doesn't\nmean AI did badly.\n\nPerformance on MATH, a dataset of 12,500 challenging competition-level math\nproblems, improved dramatically in the two years since its introduction. In\n2021, AI systems could solve only 6.9% of problems. By contrast, in 2023, a\nGPT-4-based model solved 84.3%. The human baseline is 90%.\n\nAnd we're not talking about the average human here; we're talking about the\nkinds of humans that can solve test questions like this:\n\nAn example MATH question asked of the AI. Yikes!\n\nHendryks et al./AI Index 2024\n\nThat's where things are at with advanced math in 2024, and we're still very\nmuch at the dawn of the AI era.\n\nThen there's visual commonsense reasoning (VCR). Beyond simple object\nrecognition, VCR assesses how AI uses commonsense knowledge in a visual\ncontext to make predictions. For example, when shown an image of a cat on a\ntable, an AI with VCR should predict that the cat might jump off the table or\nthat the table is sturdy enough to hold it, given its weight.\n\nThe report found that between 2022 and 2023, there was a 7.93% increase in\nVCR, up to 81.60, where the human baseline is 85.\n\nA sample question used to test an AI's visual commonsense reasoning\n\nZellers et al./AI Index 2024\n\nCast your mind back, say, five years. Imagine even thinking about showing a\ncomputer a picture and expecting it to 'understand' the context enough to\nanswer that question.\n\nNowadays, AI generates written content across many professions. But, despite a\ngreat deal of progress, large language models (LLMs) are still prone to\n\u2018hallucinations,\u2019 a very charitable term pushed by companies like OpenAI,\nwhich roughly translates to \"presenting false or misleading information as\nfact.\"\n\nLast year, AI\u2019s propensity for 'hallucination' was made embarrassingly plain\nfor Steven Schwartz, a New York lawyer who used ChatGPT for legal research and\ndidn\u2019t fact-check the results. The judge hearing the case quickly picked up on\nthe legal cases the AI had fabricated in the filed paperwork and fined\nSchwartz US$5,000 (AU$7,750) for his careless mistake. His story made\nworldwide news.\n\nHaluEval was used as a benchmark for hallucinations. Testing showed that for\nmany LLMs, hallucination is still a significant issue.\n\nTruthfulness is another thing generative AI struggles with. In the new AI\nIndex report, TruthfulQA was used as a benchmark to test the truthfulness of\nLLMs. Its 817 questions (about topics such as health, law, finance and\npolitics) are designed to challenge commonly held misconceptions that we\nhumans often get wrong.\n\nGPT-4, released in early 2024, achieved the highest performance on the\nbenchmark with a score of 0.59, almost three times higher than a GPT-2-based\nmodel tested in 2021. Such an improvement indicates that LLMs are\nprogressively getting better when it comes to giving truthful answers.\n\nWhat about AI-generated images? To understand the exponential improvement in\ntext-to-image generation, check out Midjourney's efforts at drawing Harry\nPotter since 2022:\n\nHow text-to-image generation has improved with progressive versions of\nMidjourney\n\nMidjourney/AI Index 2024\n\nThat's 22 months' worth of AI progress. How long would you expect it would\ntake a human artist to reach a similar level?\n\nUsing the Holistic Evaluation of Text-to-Image Models (HEIM), LLMs were\nbenchmarked for their text-to-image generation capabilities across 12 key\naspects important to the \u201creal-world deployment\u201d of images.\n\nHumans evaluated the generated images, finding that no single model excelled\nin all criteria. For image-to-text alignment or how well the image matched the\ninput text, OpenAI\u2019s DALL-E 2 scored highest. The Stable Diffusion-based\nDreamlike Photoreal model was ranked highest on quality (how photo-like),\naesthetics (visual appeal), and originality.\n\n## Next year's report is going to be bananas\n\nYou'll note this AI Index Report cuts off at the end of 2023 \u2013 which was a\nwildly tumultuous year of AI acceleration and a hell of a ride. In fact, the\nonly year crazier than 2023 has been 2024, in which we've seen \u2013 among other\nthings \u2013 the releases of cataclysmic developments like Suno, Sora, Google\nGenie, Claude 3, Channel 1, and Devin.\n\nEach of these products, and several others, have the potential to flat-out\nrevolutionize entire industries. And over them all looms the mysterious\nspectre of GPT-5, which threatens to be such a broad and all-encompassing\nmodel that it could well consume all the others.\n\nAI isn\u2019t going anywhere, that\u2019s for sure. The rapid rate of technical\ndevelopment seen throughout 2023, evident in this report, shows that AI will\nonly keep evolving and closing the gap between humans and technology.\n\nWe know this is a lot to digest, but there's more. The report also looks into\nthe downsides of AI's evolution and how it's affecting global public\nperceptions of its safety, trustworthiness, and ethics. Stay tuned for the\nsecond part of this series, in the coming days!\n\nSource: Stanford University HAI\n\nView gallery - 5 images\n\n## Tags\n\nTechnologyArtificial IntelligenceLLM (Large Language Model)GPTOpen AIStanford\nUniversity\n\n  * Facebook\n  * Twitter\n  * Flipboard\n  * LinkedIn\n\n15 comments\n\nPaul McClure\n\nBefore realizing his writing passion, Paul worked as an intensive care nurse\nand a criminal defense lawyer for many years. He has a keen interest in mental\nhealth and addiction, chronic illness, and medical technology. After\ngraduating with a Bachelor of Arts in journalism and creative writing in 2022,\nPaul joined New Atlas in 2023. Before starting with New Atlas, Paul had\nwritten for several online publications in the areas of health and well-being,\nparenting, entertainment, and popular culture.\n\n## Most Viewed\n\n  * Good Thinking\n\n### $300,000 robotic micro-factories pump out custom-designed homes\n\n  * Automotive\n\n### BYD's roofless, no-windscreen, scissor-door supercar: Headed for\nproduction\n\n  * Automotive\n\n### Outside's rejiggered camper van blows open van life dreams\n\nLoad More\n\nby Taboolaby Taboola\n\nSponsored LinksSponsored Links\n\nPromoted LinksPromoted Links\n\nYou May Like\n\nBestatter packt aus: Anspruch auf Sterbegeld ist vielen unbekanntPro\nVerbraucher\n\nKein Scherz: Das kostet ein Treppenlift 2024 dank dieser\nJungunternehmerinTreppenlift Testsieger\n\nWarum viele Deutsche trotz Preistief zu viel f\u00fcr Ihre Solaranlage\nzahlenSolaranlagen\n\nBis zu 50% weniger PKV-Beitrag zahlen: Geheimtipp, den jeder Privatversicherte\nkennen sollteCheckfox\n\n15 comments\n\nSign in to post a comment. Please keep comments to less than 150 words. No\nabusive material or spam will be published.\n\nChase April 19, 2024 12:21 AM\n\nAnd yet in many situations AI autonomous driving systems are still roughly\nequivalent to letting Ray Charles take the wheel. I remain unimpressed, but\nthat's probably because I don't have any use for AI-backed features and tools\nthat others have fallen in love with.\n\nPaulm April 19, 2024 02:40 AM\n\nGreat article. We certainly live in interesting times\n\nnameless minion April 19, 2024 06:19 AM\n\nI'm a mere human, so you must excuse my lack of understanding in this arena,\nbut it seems to me that if an AI has scanned a million/billion/trillion math\nproblems similar to the ones it would \"see\" in the MATH assessment, it's not\nsurprising that it could solve a new, similar problem. What am I missing?\n\nmediabeing April 19, 2024 10:04 AM\n\nYes, A.I. has come and is going a long way. Knowledge and data manipulation is\nits thing. The link between knowing and actual doing is where A.I. is behind.\nIn time, A.I. will overcome this as well, and away we'll go.\n\nakarp April 19, 2024 10:09 AM\n\nThis is quite over-representing AI capabilities!!! The harry potter example is\nthe best example. Its NOT AI actually generating a realistic harry potter.\nThis clearly shows that Midjourney is copying an image from the Harry Potter\nMovies...NOT making it's own image that an artist would truly create.\n\nakarp April 19, 2024 10:10 AM\n\n@Nameless Minion: exactly...AI is still mostly 'copying' what has been done vs\nactually create. (But maybe this can be said of most human activity, so we\nwill see this progress into 'intelligence at some point?)\n\njimbo92107 April 19, 2024 10:14 AM\n\nAI will continue to struggle with concepts that are subtle and existential.\nRhetorical tricks like deliberate vagueness, ambiguity, irony, and satire will\nelude its capabilities, as will foundational concepts like truth, falsehood,\ngood, and evil. Beware of self-serving solutions to these problems. If you\ndefine greed as good... Well, that would be ironic.\n\nUsername April 19, 2024 10:25 AM\n\n\"Humans\" is a meaning less benchmark. Which human? Einstein or high school\nflunky?\n\nWhite Rabbit April 19, 2024 11:08 AM\n\nGreat examples of both why we should and shouldn't be concerned. The fact that\nwe are (or are supposed to be) impressed by these results is of great concern,\nespecially considering that in the case of the MATH problems at least the\nfirst solution is wrong. Consider the 3 yellow marbles. They are said to be\nidentical, but in order to choose 2, they must be distinguishable (if only by\nlocation). But since they are distinct, it must also be possible to choose a\ndifferent pair. Any cribbage player will tell you that there are 3 pairs in 3\nof kind - not just 1. Note that the question (\"How many different groups of\ntwo marbles can Tom choose?\" ) is about choosing marbles. It includes no\nreference to color, which means the solution is just 6 Choose 2 => 15\\. In the\nVCR case, note how much information has been given in the question. \"How did\n[person2] get the money that's in front of her?\" Embedded are the assumptions\nthat the 2 shapes are persons, that (at least) one is female, and that\nwhatever is front of her is money. Moreover, it's a multiple choice question\nwhich necessarily confines the answer to a very small range of possibilities.\nTwo of these refer directly to the shape in question while the others refer to\n\"she\" so there are really only 2 options. Note that he similarly limited set\nof \"reasons\" doesn't include any reference the vending, so only the music-\nrelated option is viable. This isn't even close to \"understand[ing] the\ncontext\" - most of it is provided. How would VCR deal with a less leading\nquestion like \"What's happening in this image?\"\n\nDaishi April 19, 2024 05:55 PM\n\nThe scariest thing about this is things are still improving very rapidly.\nPeople used to say AI can only copy, it can't show creativity or bring new\nideas but increasingly it appears that it can. The list of things it can't do\nkeeps getting shorter.\n\nOne example to address the point @White Rabbit made is you can upload a meme\nor funny image to GPT-4V and it will explain why the image is funny. It can\ntake a very open-ended prompt and understand humor which is an impressive step\ntowards shortening that list.\n\nLoad More\n\n## GET OUR NEWSLETTER\n\nOver 220,000 people receive our email newsletter. Get your daily dose of\nextraordinary ideas!\n\nRegister\n\nFollow Us\n\n  * twitter\n  * instagram\n  * pinterest\n  * flipboard\n  * facebook\n  * linkedin\n\n\u00a9 2024 New Atlas\n\n# Notice\n\nWe and selected third parties use cookies or similar technologies for\ntechnical purposes and, with your consent, for functionality, experience,\nmeasurement and marketing (personalized ads) as specified in the cookie\npolicy.\n\nWith respect to advertising, we and 847 selected , may use precise geolocation\ndata, and identification through device scanning in order to store and/or\naccess information on a device and process personal data like your usage data\nfor the following : personalised advertising and content, advertising and\ncontent measurement, audience research and services development.\n\nYou can freely give, deny, or withdraw your consent at any time by accessing\nthe preferences panel. If you give consent, it will be valid only in this\ndomain. Denying consent may make related features unavailable.\n\nUse the \u201cAccept\u201d button to consent. Use the \u201cReject\u201d button to continue\nwithout accepting.\n\nPress again to continue 0/2\n\n", "frontpage": false}
