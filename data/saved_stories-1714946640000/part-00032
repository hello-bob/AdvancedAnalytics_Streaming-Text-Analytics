{"aid": "40264767", "title": "Web Scraping Ajax and JavaScript Sites (2011)", "url": "https://blog.databigbang.com/web-scraping-ajax-and-javascript-sites/", "domain": "databigbang.com", "votes": 2, "user": "wslh", "posted_at": "2024-05-05 13:30:59", "comments": 0, "source_title": "Web Scraping Ajax and Javascript Sites", "source_text": "Web Scraping Ajax and Javascript Sites | Data Big Bang Blog\n\n# Data Big Bang Blog\n\n## Creativity and Problem Solving for Data Science (whatever it may mean...) | An experimental spin-off from Nektra Advanced Computing\n\n# Menu\n\n# Web Scraping Ajax and Javascript Sites\n\n# Introduction\n\nMost crawling frameworks used for scraping cannot be used for Javascript or\nAjax. Their scope is limited to those sites that show their main content\nwithout using scripting. One would also be tempted to connect a specific\ncrawler to a Javascript engine but it\u2019s not easy to do. You need a fully\nfunctional browser with good DOM support because the browser behavior is too\ncomplex for a simple connection between a crawler and a Javascript engine to\nwork. There is a list of resources at the end of this article to explore the\nalternatives in more depth.\n\nThere are several ways to scrape a site that contains Javascript:\n\n  1. Embed a web browser within an application and simulate a normal user.\n  2. Remotely connect to a web browser and automate it from a scripting language.\n  3. Use special purpose add-ons to automate the browser\n  4. Use a framework/library to simulate a complete browser.\n\nEach one of these alternatives has its pros and cons. For example using a\ncomplete browser consumes a lot of resources, especially if we need to scrape\nwebsites with a lot of pages.\n\nIn this post we\u2019ll give a simple example of how to scrape a web site that uses\nJavascript. We will use the htmlunit library to simulate a browser. Since\nhtmlunit runs on a JVM we will use Jython, an [excellent] programming\nlanguage,which is a Python implementation in the JVM. The resulting code is\nvery clear and focuses on solving the problem instead of on the aspects of\nprogramming languages.\n\n## Setting up the environment\n\n### Prerequisites\n\n  1. JRE or JDK.\n  2. Download the latest version of Jython from http://www.jython.org/downloads.html.\n  3. Run the .jar file and install it in your preferred directory (e.g: /opt/jython).\n  4. Download the htmlunit compiled binaries from: http://sourceforge.net/projects/htmlunit/files/.\n  5. Unzip the htmlunit to your preferred directory.\n\n## Crawling example\n\nWe will scrape the Gartner Magic Quadrant pages at:\nhttp://www.gartner.com/it/products/mq/mq_ms.jsp . If you look at the list of\ndocuments, the links are Javascript code instead of hyperlinks with http urls.\nThis is may be to reduce crawling, or just to open a popup window. It\u2019s a very\nconvenient page to illustrate the solution.\n\n### gartner.py\n\n?\n\n123456789101112131415161718192021| import\ncom.gargoylesoftware.htmlunit.WebClient as WebClientimport\ncom.gargoylesoftware.htmlunit.BrowserVersion as BrowserVersiondef\nmain():webclient = WebClient(BrowserVersion.FIREFOX_3_6) # creating a new\nwebclient object.url = \"http://www.gartner.com/it/products/mq/mq_ms.jsp\"page =\nwebclient.getPage(url) # getting the urlarticles =\npage.getByXPath(\"//table[@id='mqtable']//tr/td/a\") # getting all the\nhyperlinksfor article in articles:print \"Clicking on:\", articlesubpage =\narticle.click() # click on the article linktitle =\nsubpage.getByXPath(\"//div[@class='title']\") # get titlesummary =\nsubpage.getByXPath(\"//div[@class='summary']\") # get summaryif len(title) > 0\nand len(summary) > 0:print \"Title:\", title[0].asText()print \"Summary:\",\nsummary[0].asText()# breakif __name__ == '__main__':main()  \n---|---  \n  \n### run.sh\n\n?\n\n1| /opt/jython/jython -J-classpath \"htmlunit-2.8/lib/*\" gartner.py  \n---|---  \n  \n## Final notes\n\nThis article is just a starting point to move ahead of simple crawlers and\npoint the way for further research. As this is a simple page, it is a good\nchoice for a clear example of how Javascript scraping works.You must do your\nhomework to learn to crawl more web pages or add multithreading for better\nperformance. In a demanding crawling scenario a lot of things must be taken\ninto account, but this is a subject for future articles.\n\nIf you want to be polite don\u2019t forget to read the robots.txt file before\ncrawling...\n\n## If you like this article, you might also be interested in\n\n  1. Distributed Scraping With Multiple Tor Circuits\n  2. Precise Scraping with Google Chrome\n  3. Running Your Own Anonymous Rotating Proxies\n  4. Automated Browserless OAuth Authentication for Twitter\n\n## Resources\n\n  1. HtmlUnit\n  2. ghost.py is a webkit web client written in python\n  3. Crowbar web scraping environment\n  4. Google Chrome remote debugging shell from Python\n  5. Selenium web application testing system \u2013 Watir \u2013 Sahi \u2013 Windmill Testing Framework\n  6. Internet Explorer automation\n  7. jSSh Javascript Shell Server for Mozilla\n  8. http://trac.webkit.org/wiki/QtWebKit\n  9. Embedding Gecko\n  10. Opera Dragonfly\n  11. PyAuto: Python Interface to Chromum\u2019s automation framework\n  12. Related questions on Stack Overflow\n  13. Scrapy\n  14. EnvJS: Simulated browser environment written in Javascript\n  15. Setting up Headless XServer and CutyCapt on Ubuntu\n  16. CutyCapt: Capture WebKit\u2019s rendering of a web page.\n  17. Google webmaste blog: A spider\u2019s view of Web 2.0\n  18. OpenQA\n  19. Python Webkit DOM Bindings\n  20. Berkelium Browser\n  21. uBrowser\n  22. Using HtmlUnit on .NET for Headless Browser Automation (using IKVM)\n  23. Zombie.js\n  24. PhantomJS\n  25. PyPhantomJS\n  26. CasperJS\n  27. Web Inspector Remote\n  28. Offscreen/Headless Mozilla Firefox (via @brutuscat)\n  29. Web Scraping with Google Spreadsheets and XPath\n  30. Web Scraping with YQL and Yahoo Pipes\n\nPhoto taken by xiffy\n\nJanuary 11, 2011Sebastian Wain ajax, automation, browser, crawling, gartner,\nhtmlunit, java, javascript, jvm, jython, python, scraping, web\n\nRead our Windows Driver Development and Custom Windows Software Development\nservices. In addition to this, there are some services \u533a\u5757\u94fe\u6280\u672f and this one\nblockchain software development or smart contracts development Also, get your\ndata protected by Data Loss Prevention Solution Development and Data Loss\nPrevention Solution Development Extend Office with our service office plugin\ndevelopment Es importante agregar que desarrollo blockchain y no olvidar \u79c1\u4eba\u533a\u5757\u94fe\n~\n\n", "frontpage": false}
