{"aid": "40058469", "title": "Machine Learning and AI Beyond the Basics Book", "url": "https://github.com/rasbt/MachineLearning-QandAI-book", "domain": "github.com/rasbt", "votes": 2, "user": "Heidaradar", "posted_at": "2024-04-16 23:13:01", "comments": 0, "source_title": "GitHub - rasbt/MachineLearning-QandAI-book: Machine Learning Q and AI book", "source_text": "GitHub - rasbt/MachineLearning-QandAI-book: Machine Learning Q and AI book\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nrasbt / MachineLearning-QandAI-book Public\n\n  * Notifications\n  * Fork 37\n  * Star 163\n\nMachine Learning Q and AI book\n\nwww.amazon.com/machine-learning-ai-essential-questions/dp/1718503768\n\n### License\n\nBSD-3-Clause license\n\n163 stars 37 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# rasbt/MachineLearning-QandAI-book\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nrasbtreorg6a20626 \u00b7\n\n## History\n\n49 Commits  \n  \n### img\n\n|\n\n### img\n\n| update cover  \n  \n### supplementary\n\n|\n\n### supplementary\n\n| reorg  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| finetuning examples  \n  \n### CODE_LICENSE.txt\n\n|\n\n### CODE_LICENSE.txt\n\n| code license  \n  \n### README.md\n\n|\n\n### README.md\n\n| Update README.md  \n  \n## Repository files navigation\n\n# Machine Learning and AI Beyond the Basics Book\n\nThe Supplementary Materials for the Machine Learning Q and AI book by\nSebastian Raschka.\n\nPlease use the Discussions for any questions about the book!\n\n#### About the Book\n\nIf you\u2019ve locked down the basics of machine learning and AI and want a fun way\nto address lingering knowledge gaps, this book is for you. This rapid-fire\nseries of short chapters addresses 30 essential questions in the field,\nhelping you stay current on the latest technologies you can implement in your\nown work.\n\nEach chapter of Machine Learning Q and AI asks and answers a central question,\nwith diagrams to explain new concepts and ample references for further reading\n\n  * Multi-GPU training paradigms\n  * Finetuning transformers\n  * Differences between encoder- and decoder-style LLMs\n  * Concepts behind vision transformers\n  * Confidence intervals for ML\n  * And many more!\n\nThis book is a fully edited and revised version of Machine Learning Q and AI,\nwhich was available on Leanpub.\n\n#### Reviews\n\n> \u201cOne could hardly ask for a better guide than Sebastian, who is, without\n> exaggeration, the best machine learning educator currently in the field. On\n> each page, Sebastian not only imparts his extensive knowledge but also\n> shares the passion and curiosity that mark true expertise.\u201d -- Chris Albon,\n> Director of Machine Learning, The Wikimedia Foundation\n\n#### Links\n\n  * Preorder directly from No Starch press\n  * Preorder directly from Amazon\n  * Supplementary Materias and Discussions\n\n## Table of Contents\n\nTitle| URL Link| Supplementary Code  \n---|---|---  \n1| Embeddings, Representations, and Latent Space  \n2| Self-Supervised Learning  \n3| Few-Shot Learning  \n4| The Lottery Ticket Hypothesis  \n5| Reducing Overfitting with Data  \n6| Reducing Overfitting with Model Modifications  \n7| Multi-GPU Training Paradigms  \n8| The Keys to the Success of Transformers  \n9| Generative AI Models  \n10| Sources of Randomness| data-sampling.ipynb dropout.ipynb random-\nweights.ipynb  \nPART II: COMPUTER VISION  \n11| Calculating the Number of Parameters| conv-size.ipynb  \n12| The Equivalence of Fully Connected and Convolutional Layers| fc-cnn-\nequivalence.ipynb  \n13| Large Training Sets for Vision Transformers  \nPART III: NATURAL LANGUAGE PROCESSING  \n14| The Distributional Hypothesis  \n15| Data Augmentation for Text| backtranslation.ipynb noise-injection.ipynb\nsentence-order-shuffling.ipynb synonym-replacement.ipynb synthetic-data.ipynb\nword-deletion.ipynb word-position-swapping.ipynb  \n16| \u201cSelf\u201d-Attention  \n17| Encoder- And Decoder-Style Transformers  \n18| Using and Finetuning Pretrained Transformers  \n19| Evaluating Generative Large Language Models| BERTScore.ipynb bleu.ipynb\nperplexity.ipynb rouge.ipynb  \nPART IV: PRODUCTION AND DEPLOYMENT  \n20| Stateless And Stateful Training  \n21| Data-Centric AI  \n22| Speeding Up Inference  \n23| Data Distribution Shifts  \nPART V: PREDICTIVE PERFORMANCE AND MODEL EVALUATION  \n24| Poisson and Ordinal Regression  \n25| Confidence Intervals| four-methods.ipynb four-methods-vs-true-value.ipynb  \n26| Confidence Intervals Versus Conformal Predictions|\nconformal_prediction.ipynb  \n27| Proper Metrics  \n28| The K in K-Fold Cross-Validation  \n29| Training and Test Set Discordance  \n30| Limited Labeled Data  \n  \n## About\n\nMachine Learning Q and AI book\n\nwww.amazon.com/Machine-Learning-AI-Essential-Questions/dp/1718503768\n\n### Topics\n\nmachine-learning deep-neural-networks ai deep-learning transformers\nartificial-intelligence\n\n### Resources\n\nReadme\n\n### License\n\nBSD-3-Clause license\n\nActivity\n\n### Stars\n\n163 stars\n\n### Watchers\n\n7 watching\n\n### Forks\n\n37 forks\n\nReport repository\n\n## Languages\n\n  * Jupyter Notebook 99.0%\n  * Python 1.0%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
