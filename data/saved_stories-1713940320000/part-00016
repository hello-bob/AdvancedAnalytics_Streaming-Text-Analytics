{"aid": "40135646", "title": "Cloudflare: Lessons from building an automated SDK pipeline", "url": "https://blog.cloudflare.com/lessons-from-building-an-automated-sdk-pipeline", "domain": "cloudflare.com", "votes": 6, "user": "rattray", "posted_at": "2024-04-23 18:47:54", "comments": 0, "source_title": "Lessons from building an automated SDK pipeline", "source_text": "Lessons from building an automated SDK pipeline\n\nGet Started Free|Contact Sales\n\n## The Cloudflare Blog\n\nSubscribe to receive notifications of new posts:\n\n# Lessons from building an automated SDK pipeline\n\n04/23/2024\n\n  * Jacob Bednarz\n\n12 min read\n\nIn case you missed the announcement from Developer Week 2024, Cloudflare is\nnow offering software development kits (SDKs) for Typescript, Go and Python.\nAs a reminder, you can get started by installing the packages.\n\n    \n    \n    // Typescript npm install cloudflare // Go go get -u github.com/cloudflare/cloudflare-go/v2 // Python pip install --pre cloudflare\n\nInstead of using a tool like curl or Postman to create a new zone in your\naccount, you can use one of the SDKs in a language that you\u2019re already\ncomfortable with or that integrates directly into your existing codebase.\n\n    \n    \n    import Cloudflare from 'cloudflare'; const cloudflare = new Cloudflare({ apiToken: process.env['CLOUDFLARE_API_TOKEN'] }); const newZone = await cloudflare.zones.create({ account: { id: '023e105f4ecef8ad9ca31a8372d0c353' }, name: 'example.com', type: 'full', });\n\nSince their inception, our SDKs have been manually maintained by one or more\ndedicated individuals. For every product addition or improvement, we needed to\norchestrate a series of manually created pull requests to get those changes\ninto customer hands. This, unfortunately, created an imbalance in the\nfrequency and quality of changes that made it into the SDKs. Even though the\nproduct teams would drive some of these changes, not all languages were\ncovered and the SDKs fell to either community-driven contributions or to the\nmaintainers of the libraries to cover the remaining languages. Internally, we\ntoo felt this pain when using our own services and, instead of covering all\nlanguages, decided to rally our efforts behind the primary SDK (Go) to ensure\nthat at least one of these libraries was in a good state.\n\nThis plan worked for newer products and additions to the Go SDK, which in turn\nhelped tools like our Terraform Provider stay mostly up to date, but even this\nfocused improvement was still very taxing and time-consuming for internal\nteams to maintain. On top of this, the process didn\u2019t provide any guarantees\non coverage, parity, or correctness because the changes were still manually\nmaintained and susceptible to human error. Regardless of the size of\ncontribution, a team member would still need to coordinate a minimum of 4 pull\nrequests (shown in more depth below) before a change was considered shipped\nand needed deep knowledge of the relationship between the dependencies in\norder to get it just right.\n\nThe pull requests previously required to ship an SDK change.\n\nFollowing the completion of our transition to OpenAPI from JSON Hyper-Schema,\nwe caught up internally and started discussing what else OpenAPI could help us\nunlock. It was at that point that we set the lofty goal of using OpenAPI for\nmore than just our documentation. It was time to use OpenAPI to generate our\nSDKs.\n\nBefore we dove headfirst into generating SDKs, we established some guiding\nprinciples. These would be non-negotiable and determine where we spent our\neffort.\n\n### You should not be able to tell what underlying language generated the SDK\n\nThis was important for us because too often companies build SDKs using\nautomation. Not only do you end up with SDKs that are flavored based on\ngenerator language, but the SDKs then lack the language nuances or patterns\nthat are noticeable to users familiar with the language.\n\nFor example, a Rubyist may use the following if expression:\n\n    \n    \n    do_something if bar?\n\nWhereas most generators do not have this context and would instead default to\nthe standard case where if/else expressions are spread over multiple lines.\n\n    \n    \n    if bar? do_something end\n\nDespite being a simple and non-material example, it demonstrates a nuance that\na machine cannot decipher on its own. This is terrible for developers because\nyou\u2019re then no longer only thinking about how to solve the original task at\nhand, but you also end up tailoring your code to match how the generator has\nbuilt the SDK and potentially lose out on the language features you would\nnormally use. The problem is made significantly worse if you\u2019re using a\nstrongly typed language to generate a language without types, since it will be\nstructuring and building code in a way that types are expected but never used.\n\n### Lowering the mean time to uniform support\n\nWhen a new feature is added to a product, it\u2019s great that we add API support\ninitially. However, if that new feature or product never makes it to whatever\nlanguage SDK you are using to drive your API calls, it\u2019s as good as non-\nexistent. Similarly, not every use case is for infrastructure-as-code tools\nlike Terraform, so we needed a better way of meeting our customers with\nuniformity where they choose to integrate with our services.\n\nBy extension, we want uniformity in the way the namespaces and methods are\nconstructed. Ignoring the language-specific parts, if you\u2019re using one of our\nSDKs and you are looking for the ability to list all DNS records, you should\nbe able to trust that the method will be in the dns namespace and that to find\nall records, you can call a list method regardless of which one you are using.\nExample:\n\n    \n    \n    // Go client.DNS.Records.List(...) // Typescript client.dns.records.list(...) // Python client.dns.records.list(...)\n\nThis leads to less time digging through documentation to find what invocation\nyou need and more time using the tools you\u2019re already familiar with.\n\n### Fast feedback loops, clear conventions\n\nCloudflare has a lot of APIs; everything is backed by an API somewhere.\nHowever, not all Cloudflare APIs are designed with the same conventions in\nmind. Those APIs that are on the critical path and regularly experience\ntraffic surges or malformed input are naturally more hardened and more\nresilient than those that are infrequently used. This creates a divergence in\nquality of the endpoint, which shouldn\u2019t be the case.\n\nWhere we have learned a lesson or improved a system through a best practice,\nwe should make it easy for others to be aware of and opt into that pattern\nwith little friction at the earliest possible time, ideally as they are\nproposing the change in CI. That is why when we built the OpenAPI pipeline for\nAPI schemas, we built in mechanisms to allow applying linting rules, using\nredocly CLI, that will either warn the engineer or block them entirely,\ndepending on the severity of the violation.\n\nFor example, we want to encourage usage of fine grain API tokens, so we should\npresent those authentication schemes first and ensure they are supported for\nnew endpoints. To enforce this, we can write a redocly plugin:\n\n    \n    \n    module.exports = { id: 'local', assertions: { apiTokenAuthSupported: (value, options, location) => { for (const i in value) { if (value.at(i)?.hasOwnProperty(\"api_token\")) { return []; } } return [{message: 'API Token should be defined as an auth method', location}]; }, apiTokenAuthDefinedFirst: (value, options, location) => { if (!value.at(0)?.hasOwnProperty(\"api_token\")) { return [{message: 'API Tokens should be the first listed Security Option', location}]; } return []; }, }, };\n\nAnd the rule configuration:\n\n    \n    \n    rule/security-options-defined: severity: error subject: type: Operation property: security where: - subject: type: Operation property: security assertions: defined: true assertions: local/apiTokenAuthSupported: {} local/apiTokenAuthDefinedFirst: {}\n\nIn this example, should a team forget to put the API token authentication\nscheme first, or define it at all, the CI run will fail. Teams are provided a\nhelpful failure message with a link to the conventions to discover more if\nthey need to understand why the change is recommended.\n\nThese lints can be used for style conventions, too. For our documentation\ndescriptions, we like descriptions to start with a capital letter and end in a\nperiod. Again, we can add a lint to enforce this requirement.\n\n    \n    \n    module.exports = { id: 'local', assertions: { descriptionIsFormatted: (value, options, location) => { for (const i in value) { if (/^[A-Z].*\\.$/.test(value)) { return []; } } return [{message: 'Descriptions should start with a capital and end in a period.', location}]; }, }, };\n    \n    \n    rule/security-options-defined: severity: error subject: type: Schema property: description assertions: local/descriptionIsFormatted: {}\n\nThis makes shipping endpoints of the same quality much easier and prevents\nteams needing to sort through all the API design or resiliency patterns we may\nhave introduced over the years \u2013 possibly even before they joined Cloudflare.\n\n## Building the generation machine\n\nOnce we had our guiding principles, we started doing some analysis of our\nsituation and saw that if we decided to build the solution entirely in house,\nwe would be at least 6\u20139 months away from a single high quality SDK with the\npotential for additional follow-up work each time we had a new language\naddition. This wasn\u2019t acceptable and prevented us from meeting the requirement\nof needing a low-cost followup for additional languages, so we explored the\nOpenAPI generation landscape.\n\nDue to the size and complexity of our schemas, we weren\u2019t able to use most off\nthe shelf products. We tried a handful of solutions and workarounds, but we\nweren\u2019t comfortable with any of the options; that was, until we tried\nStainless. Founded by one of the engineers that built what many consider to be\nthe best-in-class API experiences at Stripe, Stainless is dedicated to\ngenerating SDKs. If you've used the OpenAI Python or Typescript SDKs, you've\nused an SDK generated by Stainless.\n\nThe way the platform offering works is that you bring your OpenAPI schemas and\nmap them to methods with the configuration file. Those inputs then get fed\ninto the generation engine to build your SDKs.\n\n    \n    \n    resources: zones: methods: list: get /zones\n\nThe configuration above would allow you to generate various\nclient.zones.list() operations across your SDKs.\n\nThis approach means we can do the majority of our changes using the existing\nAPI schemas, but if there is an SDK-specific issue, we can modify that\nbehavior on a per-SDK basis using the configuration file.\n\nAn added benefit of using the Stainless generation engine is that it gives us\na clear line of responsibility when discussing where a change should be made.\n\n  * Service team: Knows their service best and manages the representation for end users.\n  * API team: Understands and implements best practices for APIs and SDK conventions, builds centralized tooling or components within the platform for all teams, and translates service mappings to align with Stainless.\n  * Stainless: Provides a simple interface to generate SDKs consistently.\n\nThe decision to use Stainless has allowed us to move our focus from building\nthe generation engine to instead building high-quality schemas to describe our\nservices. In the span of a few months, we have gone from inconsistent,\nmanually maintained SDKs to automatically shipping three language SDKs with\nhands-off updates freely flowing from the internal teams. Best of all, it is\nnow a single pull request workflow for the majority of our changes \u2013 even if\nwe were to add a new language or integration to the pipeline!\n\nJust a single pull request is now required to ship an SDK change.\n\n## Lessons from our journey, for yours\n\n### Mass updates, made easy\n\nDepending on the age of your APIs, you will have a diverging history of how\nthey are represented to customers. That may be as simple as path parameters\nbeing inconsistent or perhaps something more complex like different HTTP\nmethods for updates. While you can handle these individually at any sort of\nscale, that just isn\u2019t feasible. As of this post, Cloudflare offers roughly\n1,300 publicly documented endpoints, and we needed a more automatable\nsolution. For us, that was codemods. Codemods are a way of applying\ntransformations to perform large scale refactoring of your codebase. This\nallows you to programmatically rewrite expressions, syntax or other parts of\nyour code without having to manually go through every file. Think of it like\nfind and replace, but on steroids and with more context of the underlying\nlanguage constructs.\n\nWe started with a tool called comby. We wrapped it in a custom CLI tool that\nknew how to speak to our version control endpoints and wired it in a way that\nprovides a comby configuration TOML file, pull request description, and commit\nmessage for each transformation we needed to apply. Here is a sample comby\nconfiguration where we updated the URI paths to be consistently suffixed with\n_id instead of other variations (_identifier, Identifier, etc.) where we had a\nplural resource followed by an individual identifier.\n\n    \n    \n    [account-id-1-path-consistency] match = 'paths/~accounts~1{account_identifier1}' rewrite = 'paths/~accounts~1{account_id}' [account-id-camelcase-path-consistency] match = 'paths/~accounts~1{accountId}' rewrite = 'paths/~accounts~1{account_id}' [placeholder-identifier-to-id] match = ':[_~_identifier}]' # need the empty hole match here since we are using unbalanced } rewrite = '_id}' [route-consistency-for-resource-plurals] match = ':[topic~/\\w+/]{:[id~\\w+]}' rewrite = ':[topic]{:[id]}' rule = 'where rewrite :[id] { :[x] -> :[topic] }, rewrite :[id] { /:[x]s/ -> :[x]_id }' [property-identifier-to-id] match = 'name: :[topic]_identifier' rewrite = 'name: :[topic]_id'\n\nFor an interactive version of this configuration, check out the comby\nplayground.\n\nThis approach worked for the majority of our internal changes. However,\nknowing how difficult migrations can be, we also wanted a tool that we could\nprovide to customers to use for their own SDK migrations. In the past we\u2019ve\nused comby for upgrades in the Terraform Provider with great feedback. While\ncomby is powerful, once you start using more complex expressions, the syntax\ncan be difficult to understand unless you are familiar with it.\n\nAfter looking around, we eventually found Grit. It is a tool that does\neverything we need (including the custom CLI) while being very familiar to\nanyone that understands basic Javascript through a query language, known as\nGritQL. An added bonus here is that we are able to contribute to the Grit\nPattern Library, so our migrations are only ever a single CLI invocation away\nfor anyone to use once they have the CLI installed.\n\n    \n    \n    // Migrate to the Golang v2 library grit apply cloudflare_go_v2\n\n### Consistency, consistency, consistency\n\nDid I mention consistency is important? Before attempting to feed your OpenAPI\nschemas into any system (especially a homegrown one), get them consistent with\nthe practices, structures, and how you intend to represent them. This makes\ndetermining what is a bug in your generation pipeline vs a bug in your schema\nmuch easier. If it\u2019s broken everywhere, it\u2019s the generation pipeline,\notherwise it\u2019s an isolated bug to track down in your schema.\n\nHaving consistency leads into a better developer experience. From our examples\nabove, if your routes always follow the plural resource name followed by an\nidentifier, the end user doesn\u2019t have to think about what the inputs need to\nbe. The consistency and conventions lead them there \u2013 even if your\ndocumentation is lacking.\n\n### Use shared $refs sparingly\n\nIt seems like a great idea for reusability at the time of writing them, but\nwhen overused, $refs make finding correct values problematic and lead to cargo\ncult practices. In turn, this leads to lower quality and difficult-to-change\nschemas despite looking more usable from the outset. Consider the following\nschema example:\n\n    \n    \n    thing_base: type: object required: - id properties: updated_at: $ref: '#/components/schemas/thing_updated_at' created_at: $ref: '#/components/schemas/thing_updated_at' id: $ref: '#/components/schemas/thing_identifier' thing_updated_at: type: string format: date-time description: When the resource was last updated. example: \"2014-01-01T05:20:00Z\" thing_created_at: type: string format: date-time description: When the resource was created. example: \"2014-01-01T05:20:00Z\" thing_id: type: string description: Unique identifier of the resource. example: \"2014-01-01T05:20:00Z\"\n\nDid you spot the bug? Have another look at the created_at value. You likely\ndidn\u2019t catch it at first glance, but this is a common issue when needing to\nreference reusable values. Here, it is a minor annoyance as the documentation\nwould be incorrect (created_at would have the description of updated_at), but\nin other cases, it could be a completely incorrect schema representation.\n\nFor us, the correct usage of $ref values is predominantly where you have\npotential for multiple component schemas that may be used as part of a oneOf,\nallOf or anyOf directive.\n\n    \n    \n    dns_record: oneOf: - $ref: '#/components/schemas/dns-records_ARecord' - $ref: '#/components/schemas/dns-records_AAAARecord' - $ref: '#/components/schemas/dns-records_CAARecord' - $ref: '#/components/schemas/dns-records_CERTRecord' - $ref: '#/components/schemas/dns-records_CNAMERecord' - $ref: '#/components/schemas/dns-records_DNSKEYRecord' - $ref: '#/components/schemas/dns-records_DSRecord' - $ref: '#/components/schemas/dns-records_HTTPSRecord' - $ref: '#/components/schemas/dns-records_LOCRecord' - $ref: '#/components/schemas/dns-records_MXRecord' - $ref: '#/components/schemas/dns-records_NAPTRRecord' - $ref: '#/components/schemas/dns-records_NSRecord' - $ref: '#/components/schemas/dns-records_PTRRecord' - $ref: '#/components/schemas/dns-records_SMIMEARecord' - $ref: '#/components/schemas/dns-records_SRVRecord' - $ref: '#/components/schemas/dns-records_SSHFPRecord' - $ref: '#/components/schemas/dns-records_SVCBRecord' - $ref: '#/components/schemas/dns-records_TLSARecord' - $ref: '#/components/schemas/dns-records_TXTRecord' - $ref: '#/components/schemas/dns-records_URIRecord' type: object required: - id - type - name - content - proxiable - created_on - modified_on\n\nWhen in doubt, consider the YAGNI principle instead. You can always refactor\nand extract this later once you have enough uses to determine the correct\nabstraction.\n\n### Design your ideal usage and work backwards\n\nBefore we wrote a single line of code to solve the problem of generation, we\nprepared language design documents for each of our target languages that\nfollowed the README-driven design principles. This meant our focus from the\ninitial design was on the usability of the library and not on the technical\nchallenges that we would eventually encounter. This led us to identify\nproblems and patterns early with how various language nuances would surface to\nthe end user without investing in anything more than a document. Python\nkeyword arguments, Go interfaces, how to enforce required parameters, client\ninstantiation and overrides, types \u2013 all considerations made up front that\nhelped minimize the number of unknowns as we built out support.\n\n## What\u2019s next?\n\nWhen we embarked on the OpenAPI journey, we knew it was only the beginning and\nwould eventually open more doors and quality of life improvements for teams\nand customers alike. Now that we have a few language SDKs available, we\u2019re\nturning our attention to generating our Terraform Provider using the same\nguiding principles to further minimize the maintenance burden. But that\u2019s\nstill not all. Coming later in 2024 are more improvements and integrations\nwith other parts of the Cloudflare Developer Platform, so stay tuned.\n\nIf you haven\u2019t already, check out one of the SDKs in Go, Typescript and Python\ntoday. If you\u2019d like support for a different language, go here to submit your\ndetails to help determine the next language. We\u2019d love to hear what languages\nyou would like offered as a Cloudflare SDK.\n\nWe protect entire corporate networks, help customers build Internet-scale\napplications efficiently, accelerate any website or Internet application, ward\noff DDoS attacks, keep hackers at bay, and can help you on your journey to\nZero Trust.\n\nVisit 1.1.1.1 from any device to get started with our free app that makes your\nInternet faster and safer.\n\nTo learn more about our mission to help build a better Internet, start here.\nIf you're looking for a new career direction, check out our open positions.\n\nDiscuss on Hacker News\n\nSDK\n\nFollow on X\n\nJacob Bednarz|@jacobbednarz\n\nCloudflare|@cloudflare\n\nRelated posts\n\nApril 04, 2024 1:05 PM\n\n## New tools for production safety \u2014 Gradual deployments, Source maps, Rate\nLimiting, and new SDKs\n\nToday we are announcing five updates that put more power in your hands \u2013\nGradual Deployments, Source mapped stack traces in Tail Workers, a new Rate\nLimiting API, brand-new API SDKs, and updates to Durable Objects \u2013 each built\nwith mission-critical production services in mind...\n\nBy\n\n  * Tanushree Sharma,\n\n  * Jacob Bednarz\n\nDeveloper Week, Cloudflare Workers, Rate Limiting, SDK, Observability\n\n  * Getting Started\n  * Free plans\n  * For enterprises\n  * Compare plans\n  * Get a recommendation\n  * Request a demo\n  * Contact Sales\n\n  * Resources\n  * Learning Center\n  * Analyst reports\n  * Cloudflare Radar\n  * Cloudflare TV\n  * Case Studies\n  * Webinars\n  * White Papers\n  * Developer docs\n  * theNet\n\n  * Solutions\n  * Connectivity cloud\n  * SSE and SASE services\n  * Application services\n  * Network services\n  * Developer services\n\n  * Community\n  * Community Hub\n  * Project Galileo\n  * Athenian Project\n  * Cloudflare for Campaigns\n  * Critical Infrastructure Defense Project\n  * Connect 2024\n\n  * Support\n  * Help center\n  * Cloudflare Status\n  * Compliance\n  * GDPR\n  * Trust & Safety\n\n  * Company\n  * About Cloudflare\n  * Our team\n  * Investor relations\n  * Press\n  * Careers\n  * Diversity, equity & inclusion\n  * Impact/ESG\n  * Network Map\n  * Logos & press kit\n  * Become a partner\n\n\u00a9 2024 Cloudflare, Inc. | Privacy Policy | Terms of Use | Report Security Issues |Cookie Preferences | Trademark\n\n", "frontpage": false}
