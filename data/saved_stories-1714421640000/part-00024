{"aid": "40198281", "title": "Open Source Datadog Guide", "url": "https://github.com/nimbushq/og-datadog", "domain": "github.com/nimbushq", "votes": 1, "user": "kevinslin", "posted_at": "2024-04-29 13:45:38", "comments": 0, "source_title": "GitHub - nimbushq/og-datadog: Open Source Datadog Guide", "source_text": "GitHub - nimbushq/og-datadog: Open Source Datadog Guide\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nnimbushq / og-datadog Public\n\n  * Notifications\n  * Fork 0\n  * Star 5\n\nOpen Source Datadog Guide\n\n### License\n\nCC-BY-4.0 license\n\n5 stars 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# nimbushq/og-datadog\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nkevinslinupdate capitalizationApr 24, 20245a2baee \u00b7 Apr 24, 2024Apr 24, 2024\n\n## History\n\n8 Commits  \n  \n### .github/workflows\n\n|\n\n### .github/workflows\n\n| init commit| Apr 2, 2024  \n  \n### figures\n\n|\n\n### figures\n\n| update| Apr 2, 2024  \n  \n### CODE_OF_CONDUCT.md\n\n|\n\n### CODE_OF_CONDUCT.md\n\n| init commit| Apr 2, 2024  \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n| formatting updates| Apr 3, 2024  \n  \n### LICENSE.txt\n\n|\n\n### LICENSE.txt\n\n| init commit| Apr 2, 2024  \n  \n### README.bak.md\n\n|\n\n### README.bak.md\n\n| update capitalization| Apr 24, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| update| Apr 24, 2024  \n  \n## Repository files navigation\n\n# The Open Guide to Datadog\n\n> NOTE: This guide is a fork of the awesome The Open Guide to Amazon Web\n> Services. Formatting, layout, and conduct is either directly used as is or\n> heavily inspired from said guide.\n\n## Table of Contents\n\nPurpose\n\n  * Why an Open Guide?\n  * Scope\n  * Legend\n\nDatadog in General\n\n  * Basics\n  * Gotchas\n\nDatadog Services\n\n  * Metrics\n  * Logs\n  * Traces\n\nSpecial Topics\n\n  * Billing and Cost Management\n\n## Why an Open Guide?\n\nThere's not much documentation that dive deep into Datadog usage beyond the\nofficial docs. While these docs are a great starting point, they lack detail\nwhen you go off the golden path.\n\nThis guide is by and for engineers who use Datadog. It aims to be a useful,\nliving reference that consolidates links, tips, gotchas, and best practices.\n\nBefore using the guide, please read the license and disclaimer.\n\n### Please help!\n\nThis is an early in-progress draft! It\u2019s our first attempt at assembling this\ninformation, so is far from comprehensive still, and likely to have omissions\nor errors.\n\nPlease help by contributing to the guide. This guide is open to contributions,\nso unlike a blog, it can keep improving. Like any open source effort, we\ncombine efforts but also review to ensure high quality.\n\n## Scope\n\n  * Currently, this guide covers selected \u201ccore\u201d signals, such as Infrastructure (Metrics), Log Management (logs), and APM (Traces). We expect it to expand.\n  * It is not a tutorial, but rather a collection of information you can read and return to. It is for both beginners and the experienced.\n  * The goal of this guide is to be:\n\n    * Brief: Keep it dense and use links\n    * Practical: Basic facts, concrete details, advice, gotchas, and other \u201cfolk knowledge\u201d\n    * Current: We can keep updating it, and anyone can contribute improvements\n    * Thoughtful: The goal is to be helpful rather than present dry facts. Thoughtful opinion with rationale is welcome. Suggestions, notes, and opinions based on real experience can be extremely valuable. (We believe this is both possible with a guide of this format, unlike in some other venues.)\n  * This guide is not sponsored by Datadog. It is written by and for engineers who use Datadog.\n\n## Legend\n\n  * \ud83d\udcb8 Cost issues, discussion, and gotchas\n  * \u2757 \u201cSerious\u201d gotcha (used where risks or time or resource costs are significant: critical security risks, mistakes with significant financial cost, or poor architectural choices that are fundamentally difficult to correct)\n\n### Basics\n\n  * Datadog is the all in one observability platform that markets itself as the \"single plane of glass\" solution for observability related use cases. They are the dominant player in the commercial observability market.\n  * Datadog has different sites around the world that store and process data locally to a particular region. You choose the site when creating an account. There is no automatic way of transferring data or configuration between datadog sites.\n\n### Tips\n\n  * If you care about vendor lock in, its a good idea to use the OpenTelemetry libraries to instrument your applications. This makes it possible to migrate vendors in the future or use multiple vendors at the same time\n\n### Gotchas\n\n  * Datadog offers FedRAMP Moderate Impact compliance in its us1-fed site - onboarding requires a manual account migration if you're already using a different site\n  * While datadog offers support for the OpenTelemetry collector, adopting it means you forego one of Datadog's strongest qualities - seamless integration with existing services. These integrations exist for the datadog agent but is not available if you use the open telemetry collector\n\n## Metrics\n\n### Metric Basics\n\n  * metrics is provided by Datadog's Infrastructure and Metrics offering\n\n### Metric Tips\n\n  * Datadog offers rich integrations into many popular services like nginx and kubernetes which can automatically collect the right metrics and populate pre-built dashboards\n\n### Metric Gotchas\n\n  * if you're using Datadog's integration to automatically collect metrics from your cloud provider, know that those metrics are subject to delays of anywhere between 2min to 20min. Datadog provides provider specific (eg. metric streams for AWS) which can cut the delay but incur additional costs\n  * because Datadog charges per host, it can make certain workloads that involve short lived host (eg. running kubernetes or utilizing spot instances) prohibitively expensive \ud83d\udcb8\n  * understand that datadog default time aggregation behavior render max and min statistics inaccurate with large time windows. This is because Datadog buckets data points and averages values in those buckets.\n\n> For example, when examining four hours, data points are combined into two-\n> minute buckets. This is called a rollup. As the time interval you\u2019ve defined\n> for your query increases, the granularity of your data decreases.\n\n    * In order to see accurate statistics that are not average, you'll need to manually rollup by the desired statistic\n    \n        # regular query - will hide max values due to time aggregation sum:kubernetes.cpu.usage.total{*} by {pod_name} # query with rollup - shows true max values sum:kubernetes.cpu.usage.total{*} by {pod_name}.rollup(max)\n\n## Logs\n\n### Logs Basics\n\n  * logs are provided by Datadog's Log Management offering\n\n### Logs Tips\n\n  * Datadog charges predominantly based on indexed log events. If you have logs that you're not using, use the exclusion filters to avoid paying for indexing \ud83d\udcb8\n  * The default retention rate for logs is 15 days. You can change this to 1 day, 3 day, 7 day, 30 day, or greater than 30 day retention depending on your needs. The longer the retention, the more it will cost to index logs \ud83d\udcb8\n  * You can use flex logs to store historical logs at $0.05/million events (this is 50x cheaper than the default on demand price). Note that this does add variable compute cost at query time \ud83d\udcb8\n\n### Logs Gotchas\n\n  * If you use services like Cloud SIEM that price based on per million logs scanned - note that excluding logs using an exclusion filter does not exclude it from scanning or the associated cost that come with that \ud83d\udcb8\n\n## Traces\n\n### Trace Basics\n\n  * traces are provided by Datadog's APM offering\n\n### Trace Tips\n\n  * You can sample traces using the datadog agent. The default sample rate if you're using the datadog agent is 10 traces per second. The datadog agent uses head based sampling which means the sampling decision happens at the start of the trace\n  * Datadog Agent provides separate sampling mechanisms for errors and rare traces - these mechanisms preserve errors and rare traces. Note that errors and rare traces are sampled locally which means that there is no guarantee the full trace will be available in a distributed trace\n  * You can control trace ingestion costs by changing the default sampling rate of the datadog agent \ud83d\udcb8\n\n### Trace Gotchas\n\n  * like metrics, Datadog charges per host for traces. They also require that hosts with traces also have infrastructure monitoring turned on which means you pay double per host. This can make certain workloads that involve short lived host (eg. running kubernetes or utilizing spot instances) prohibitively expensive \ud83d\udcb8\n  * Setting any library specific sampling rate will override the default sampling of the datadog agent\n\n## Billing and Cost Management\n\n### Basics\n\n  * Datadog prices varies by each service which charge among multiple dimensions\n\n### Tips\n\n  * You can make use of AWS Private Link to reduce egress fees from AWS by 90%. Be aware that this is only available in the us1 and ap1 site \ud83d\udcb8\u2757\n  * Make use of usage commitments to get discounts from the list price. Unless you are very confident in predicting your usage, it's safer to go month to month vs annual \ud83d\udcb8\n\n### Gotchas\n\n  * For metrics, logs, and traces, Datadog charges $0.10/GB for data ingress. Note that there is generally a corresponding charge from your cloud provider for egress fees. AWS for example charges charges $0.09/GB of egress. This effectively doubles your data transfer fee when using Datadog \ud83d\udcb8\n\n## About\n\nOpen Source Datadog Guide\n\n### Resources\n\nReadme\n\n### License\n\nCC-BY-4.0 license\n\n### Code of conduct\n\nCode of conduct\n\nActivity\n\nCustom properties\n\n### Stars\n\n5 stars\n\n### Watchers\n\n1 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
