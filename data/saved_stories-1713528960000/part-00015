{"aid": "40083096", "title": "Diagnosing Workqueues", "url": "https://lwn.net/Articles/967016/", "domain": "lwn.net", "votes": 1, "user": "signa11", "posted_at": "2024-04-19 03:09:03", "comments": 0, "source_title": "Diagnosing workqueues [LWN.net]", "source_text": "Diagnosing workqueues [LWN.net]\n\nLWN .net News from the source\n\n  * Content\n\n    * Weekly Edition\n    * Archives\n    * Search\n    * Kernel\n    * Security\n    * Events calendar\n    * Unread comments\n    * LWN FAQ\n    * Write for us\n  * Edition\n\n    * Return to the Front page\n\n| |\n\nSubscribe / Log in / New account\n\n# Diagnosing workqueues\n\nDid you know...?LWN.net is a subscriber-supported publication; we rely on\nsubscribers to keep the entire operation going. Please help out by buying a\nsubscription and keeping LWN on the net.  \n---  \n  \nBy Daroc Alden April 9, 2024\n\nSCALE\n\nThere are many mechanisms for deferred work in the Linux kernel. One of them,\nworkqueues, has seen increasing use as part of the move away from software\ninterrupts. Alison Chaiken gave a talk at SCALE about how they compare to\nsoftware interrupts, the new challenges they pose for system administrators,\nand what tools are available to kernel developers wishing to diagnose problems\nwith workqueues as they become increasingly prevalent.\n\n#### Background on software interrupts\n\nSoftware interrupts are a mechanism that allows Linux to split the work done\nby interrupt handlers into two parts. The interrupt handler invoked by the\nhardware does the minimum amount of work, and then raises a software interrupt\nfor the kernel to run later that does the actual work. This can reduce the\namount of time spent in the registered interrupt handler, which ensures that\ninterrupts get serviced efficiently.\n\nChaiken explained that when a hardware interrupt raises a software interrupt,\nthere are two possible cases. When no software interrupt is already running on\nthe CPU, the new software interrupt can start running immediately. When a\nsoftware interrupt is already running on the CPU, the new interrupt is\nenqueued to be handled later \u2014 even if the new interrupt would actually be\nhigher priority than the currently running one. There are ten different kinds\nof software interrupt, and each kind has a specific priority. Chaiken showed a\nlist of these priorities, and remarked that even without knowing anything else\nabout the design of software interrupts, seeing network interrupts listed\nabove timer interrupts might make people \"feel some foreboding\".\n\nThese priority inversions are a problem on their own, because they contribute\nto latency and jitter for high-priority tasks, but the priority system also\nintroduces other problems. The lowest priority interrupts are part of the\nkernel's read-copy-update (RCU) system. Chaiken called the RCU system\n\"basically the kernel's garbage collector\". This means that not servicing\ninterrupts fast enough can actually cause the kernel to run out of memory.\n\nOn the other hand, servicing software interrupts too much can disrupt latency-\nsensitive operations such as audio processing \u2014 a common issue for kernel\nmaintainers is a software interrupt that runs too long and refuses to yield,\neffectively tying up a core.\n\nTo balance these two problems, there are two heuristic limits used to balance\nlatency against fairness. MAX_SOFTIRQ_TIME is the maximum time that a software\ninterrupt is allowed to run; it is set to 2ms. MAX_SOFTIRQ_RESTART is the\nmaximum number of times that a software interrupt that is itself interrupted\nby something else will be restarted; it is set to ten attempts. Unfortunately,\nthese parameters are hard-coded and built into the kernel. They were\nsupposedly set to good values via experimentation, but Linux runs on so many\ndifferent kinds of device that no setting could be optimal for all of them.\n\"No one has the nerve to change them\", she said, which is \"not a great\nsituation\". She summed up the problems with software interrupts by saying that\nthey \"are not the most beloved feature of the kernel\" and that there have\nalready been several attempts to get rid of them across many versions of the\nkernel.\n\nBut progress removing software interrupts is slow. Despite those efforts,\nthere are still 250 call sites of local_bh_disable() \u2014 a function which\nChaiken called \"the villain of this part of the talk\". local_bh_disable()\nprevents software interrupts from being run on a particular CPU. In practice,\nhowever, it functions as a lock to protect data structures from being\nconcurrently accessed by software-interrupt handlers. One audience member\nasked which resources were guarded by the bottom half lock. Chaiken responded\nthat \"no one actually knows\" because the calls are spread throughout the\nkernel.\n\nEven worse, software interrupts are largely opaque, because they run in an\ninterrupt context \u2014 just like hardware interrupts do. They don't have access\nto many kernel facilities \u2014 such as debug logging. \"You can't be printing from\ninterrupt handlers\". There are a few ways to get visibility, but they're\ncumbersome compared to the functionality available to the rest of the kernel.\n\nEven though software interrupts are difficult to work with, there are some\nobservability tools. Chaiken did a demo on her laptop \u2014 \"On which I am running\na kernel which no sane person would use on a computer used for a presentation\"\n\u2014 showing how to use the stackcount program to get stack traces for all the\nsoftware interrupts currently running.\n\nIncreasingly, there has been a push to move some of the work done by software\ninterrupts to the workqueue mechanism, which Chaiken called \"just an all-\naround better design\".\n\n#### Workqueues\n\nWorkqueues have existed in the kernel for a long time, but they have recently\nseen a lot of new functionality added. \"The hardest part of this presentation\nhas been that workqueues have changed so much in the last 18 months I've had\ntrouble keeping up\".\n\nWorkqueues are a generic way for drivers and other kernel components to\nschedule delayed work. Each workqueue is \u2014 theoretically \u2014 associated with a\nsingle component, which can add whatever work to the queue it likes. In\nactuality, a lot of the kernel uses shared workqueues that are not specific to\na component. Each workqueue is also associated with a pool of kernel theads\nthat will service tasks from that queue.\n\nBy default, Linux creates two worker pools per CPU, one normal priority and\none high priority. These pools contain dedicated workers, which the kernel\nwill spawn more of or remove as required. The fact that these pools are\nadjusted automatically also means that an administrator who runs into a\nproblem with a misbehaving workqueue item cannot solve the problem by changing\nthe priority of the worker, or pinning it to a separate core. As more\nfunctionality gets moved over to workqueues, problems and bug reports will\nundoubtedly start becoming more common.\n\nThe proper way to change what happens with items in workqueues is to use the\n\"workqueue API that manages work\" as opposed to managing the workers directly.\nChaiken showed a demonstration of how this could be done. She picked out a\nworkqueue and showed that it was running on a particular pool that was also\nservicing many other workqueues. Then she changed the priority of the\nworkqueue itself, and showed that this had caused the workqueue to change to a\ndifferent worker pool \u2014 one that matched its new attributes. In response to an\naudience question, she clarified that \"the kernel will just create new work\npools, if there is no work pool that matches a work queue.\"\n\n\"Treatment of affinity of workqueues has really improved in recent kernels\",\nshe remarked. Since pinning individual workers to CPU cores is not possible,\nrecent kernels allow the user to change the CPU affinity of the workqueues\nthemselves. The addition of features like this mean that workqueues in general\nhave gotten substantially more useful over the last 18 months, which Chaiken\ncalled a \"march of progress\".\n\nShe also showed a demonstration of the much more flexible tracing and\ndebugging capabilities available with workqueues. She used the LGPL-licensed\ndrgn debugger with a set of workqueue-specific debugging scripts from the\nkernel. wq_dump.py shows the current workqueue configuration, including which\nworker pools exist and how they are arranged between cores. wq_monitor.py\nshows the behavior of workqueues in real time, which can be helpful for\ndiagnosing problems with how work is scheduled.\n\nWorkqueues also show up under the sysfs filesystem in\n/sys/devices/virtual/workqueue, which can be a quick way to get information on\na workqueue without breaking out a debugger. Only workqueues configured with\nthe WQ_SYSFS flag appear there, so Chaiken noted that \"if a workqueue is\ngiving you heartburn, one of the things you can do is make a tiny kernel\npatch\" to enable the flag.\n\nFinally, workqueue workers run in process context instead of interrupt context\n\u2014 meaning that many of the kernel's normal debugging facilities, such as trace\npoints, debug logs, etc., are available when an item from a workqueue is being\nprocessed.\n\nIn the Q&A after the talk, one audience member asked what resources they could\nuse to learn more about workqueues. Chaiken responded that \"the documentation\nfor workqueues is excellent\". \"You can learn a lot by just reading the\nkernel's entry documentation, and using these tools.\" She also provided a link\nto her slides, which themselves contain many links to the resources she\nreferenced while putting together the talk.\n\nAnother audience member asked whether there were existing tools that could\nmigrate work between pools based on observed latency. Chaiken responded that\n\"a lot of this stuff is so new that people haven't really grokked it yet\", but\nalso warned that anyone creating a tool like that would \"really need [...]\ntests which characterize your workload and its performance\".\n\nReaders who wish to dive into more of the details can find a recording of\nChaiken's talk here. Her talk left me with the impression that workqueues\npromise to be easier to manage and debug than software interrupts. Despite\nthese benefits, there are downsides to workqueues \u2014 such as increased latency\n\u2014 that are hard to mitigate. It will be a long time before software interrupts\ncan be completely eliminated, and switching \u2014 when so many different parts of\nthe kernel use software interrupts \u2014 will certainly be painful. Kernel\ndevelopers and system administrators alike will require a good working\nknowledge of workqueues, but that knowledge is readily available in the form\nof documentation and new tools.\n\nIndex entries for this article  \n---  \nConference| Southern California Linux Expo/2024  \n  \n(Log in to post comments)\n\n### Diagnosing workqueues\n\nPosted Apr 10, 2024 12:38 UTC (Wed) by abatters (\u272d supporter \u272d, #6932) [Link]\n\n> You can't be printing from interrupt handlers\n\nprintk() works from any context (https://lwn.net/Articles/800946/), so I'm not\nsure what this means. Maybe that it is just a bad idea to routinely printk()\nfrom interrupt handlers for performance reasons?\n\n### Diagnosing workqueues\n\nPosted Apr 11, 2024 4:28 UTC (Thu) by alison (subscriber, #63752) [Link]\n\nMost likely I was simply wrong! I know that printk has been completely\nrewritten in recent kernels, so perhaps text output to the console is less\ncostly than before.\n\n### Diagnosing workqueues\n\nPosted Apr 12, 2024 1:43 UTC (Fri) by nevets (subscriber, #11875) [Link]\n\nYeah, adding a printk in the wrong interrupt handler could easily livelock\nyour system. That is, cause the interrupt handler to take longer than the time\nit is called again, and you end up with an interrupt storm locking up the\nmachine.\n\nThat's why I created trace_printk() that writes into the tracing ring buffer\nand takes less than a micosecond to do so.\n\nCopyright \u00a9 2024, Eklektix, Inc. This article may be redistributed under the\nterms of the Creative Commons CC BY-SA 4.0 license Comments and public\npostings are copyrighted by their creators. Linux is a registered trademark of\nLinus Torvalds\n\n", "frontpage": false}
