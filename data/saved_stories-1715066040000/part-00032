{"aid": "40280035", "title": "Boilerplate Busting in Functional Languages", "url": "https://lambdaland.org/posts/2024-05-01_definitely_not_about_monads/", "domain": "lambdaland.org", "votes": 1, "user": "ashton314", "posted_at": "2024-05-06 22:03:45", "comments": 0, "source_title": "Boilerplate Busting in Functional Languages", "source_text": "Boilerplate Busting in Functional Languages | Lambda Land\n\nBoilerplate Busting in Functional Languages\n\n# Boilerplate Busting in Functional Languages\n\n##### 6 May 2024\n\nFeatured\n\nProgramming-Languages, Macros, Programming\n\nThis is the story of how I solved a problem (ugly, cumbersome boilerplate\ncode) that I ran into while writing a program in a functional language\n(Elixir). Functional programming languages often pride themselves on\nexpressiveness and elegance; but occasionally they are not amenable to the\nmost obvious solutions to the problems we wish to solve. In this case, the\nsimplest solution to my problem would have been to have a global mutable\nvariable. But no one likes those.\n\nThe solution most programmers would have found obviates mutation, but the code\nends up being rather clunky. This inelegance stems from two intertwined issues\npulling the code in different directions. However, the two concerns are so\nintertwined that it can be difficult to see them as separate issues at all! In\nthis blog post, I hope I can show you a new way of looking at this class of\nproblem that will let you see what those two issues are, and how to cleanly\nsplit them apart to get nice, maintainable, functional code.\n\n> You take your analytic knife, put the point directly on the term Quality and\n> just tap, not hard, gently, and the whole world splits, cleaves, right in\n> two... and the split is clean. There\u2019s no mess. No slop. No little items\n> that could be one way or the other. Not just a skilled break but a very\n> lucky break. Sometimes the best analysts, working with the most obvious\n> lines of cleavage, can tap and get nothing but a pile of trash. And yet here\n> was Quality; a tiny, almost unnoticeable fault line; a line of illogic in\n> our concept of the universe; and you tapped it, and the whole universe came\n> apart, so neatly it was almost unbelievable.\n>\n> Zen and the Art of Motorcycle Maintenance, Robert M. Pirsig\n\n## The Setup #\n\nI will use concrete example to describe my specific problem, though the issue\nis general enough that you likely have encountered it. After I walk through\nthe example I\u2019ll cover the essential elements that make my solution work, and\nhow it generalizes to similar problems.\n\nSuppose that you are writing an application that lets people track their\nworkout habits. Every time that they succeed in meeting a goal, they register\nwhat they accomplished. Now you have a database full of logged events like\n\u201cwent to the gym\u201d or \u201cswam 1000 m\u201d or \u201cran a mile\u201d, etc. Now you need some way\nto convert this set of events into reward points\u2014preferably in a way that the\nuser finds motivating.\n\nTable 1: An example of such habit records for a user.\n\nuser_id| date| event_type| event_amount  \n---|---|---|---  \n69105| 2024-05-01| gym| 1  \n69105| 2024-05-02| swim| 1000  \n69105| 2024-05-03| gym| 1  \n69105| 2024-05-04| run| 1.61  \n  \nBut every user is different, so let\u2019s say that you make it so that users can\ncustomize exactly how goal completions translate into reward points. Somewhere\nin your app you let users write a little equation that your program will then\nevaluate against the events that they have logged. In the end, the user gets a\nsingle point value.\n\n    \n    \n    points = get(\"gym\") * 10 + get(\"swim\") * (get(\"run\") + get(\"gym\"))\n    \n    \n    { \"op\": \"+\", \"args\": [ { \"op\": \"*\", \"args\": [ { \"query\": \"gym\" }, { \"num\": 10 } ] }, { \"op\": \"*\", \"args\": [ { \"query\": \"swim\" }, { \"op\": \"+\", \"args\": [ { \"query\": \"run\" }, { \"query\": \"gym\" } ] } ] } ] }\n    \n    \n    points = get(\"gym\") * 10 + get(\"swim\") * (get(\"run\") + get(\"gym\")) = 2 * 10 + 1000 * ( 1.16 + 2 ) = 3180\n    \n    \n    def interpret(user_id, {op: op, args: [arg1, arg2]}) do arg1_eval = interpret(user_id, arg1) arg2_eval = interpret(user_id, arg2) case op do \"+\" -> arg1_eval + arg2_eval \"*\" -> arg1_eval * arg2_eval end end def interpret(_user_id, {num: n}), do: n def interpret(user_id, {query: q}), do: query_db(user_id, q)\n\nCode Snippet 1: Sample interpreter for the simple language.\n\nThis is, in essence, a little interpreter. I will not go over how to build an\ninterpreter here, but the gist of it is that you walk down the AST of the\nequation and evaluate the leaves and nodes recursively until you wind up with\na single number of points at the end.\n\nNow let\u2019s say that you are processing a large number of such requests, and you\nwould like to batch all of the database calls. In the previous example, there\nwere four database queries, one of which (\"gym\") was a duplicate. (Each get in\nthe surface syntax or query node in the AST induces a database query.) To\nimprove performance, you could batch all of these database calls\u2014thereby also\neliminating duplicate queries\u2014and then have this data on hand as you walk the\nAST.\n\nSo here is the new operation we would like to perform: we want to walk through\nAST, collect all of the database calls into a set, and replace each instance\nof a database query (query nodes) in the expression to a reference (query_ref\nnodes) that we can link to the batched results. We will create a fresh\nidentifier every time we encounter a new query; duplicate queries will use the\nfirst reference.\n\n    \n    \n    { \"op\": \"+\", \"args\": [ { \"op\": \"*\", \"args\": [ { \"query\": \"gym\" }, { \"num\": 10 } ] }, { \"op\": \"*\", \"args\": [ { \"query\": \"swim\" }, { \"op\": \"+\", \"args\": [ { \"query\": \"run\" }, { \"query\": \"gym\" } ] } ] } ] }\n    \n    \n    { \"op\": \"+\", \"args\": [ { \"op\": \"*\", \"args\": [ { \"query_ref\": 0 }, { \"num\": 10 } ] }, { \"op\": \"*\", \"args\": [ { \"query_ref\": 1 }, { \"op\": \"+\", \"args\": [ { \"query_ref\": 2 }, { \"query_ref\": 0 } ] } ] } ] } { \"queries\": [\"gym\", \"swim\", \"run\"] }\n\nNow we need to implement it.\n\n### First attempt #\n\nWe could just create a variable that we can mutate as we walk down the tree:\nevery time we encounter a node that looks like { \"query\": _ }, we generate a\nfresh identifier (or look up an old one if it\u2019s a duplicate query) and replace\nit with { \"query_ref\": _id }. Once we\u2019re done walking the tree, we have a new\nAST with query_ref nodes instead of query nodes, and a list of queries that we\ncan execute in one go.\n\nThis could work, but the fact that we are using global mutable state should\nring alarm bells for anyone\u2014not just functional programmers. Whenever we call\nour transform function, we would have to ensure that we clear out the old list\nof accumulated information. Don\u2019t forget about all the other problems that\nglobal mutable state brings. There must be a better way.\n\n### Second attempt #\n\nHow might our function be more pure? Instead of just returning a modified\ntree, we can return a tuple of the new AST node plus a list of queries. (I\u2019ll\ncall this specific shape an AST-queries-tuple throughout.) This eliminates the\nneed for a global variable, and now every call to our optimization function is\npure. It\u2019s easier to test and reason about.\n\n    \n    \n    def transform_queries({:query, query_text}) do query_id = fresh_query_id() {{:query_ref, query_id}, [{query_id, query_text}]} end def transform_queries({:+, lhs, rhs}) do {new_ast_l, queries_l} = transform_queries(lhs) {new_ast_r, queries_r} = transform_queries(rhs) {{:+, new_ast_l, new_ast_r}, queries_l ++ queries_r} end ...\n\nHowever, this means that we have to take care to combine this information\nwhenever we do a recursive call. It becomes even more cumbersome when we recur\nover elements in a list and we need to combine all their results together. A\nwell-crafted reduce makes things work OK, but I think you can agree the\nfollowing code isn\u2019t the most straightforward to read and understand what\u2019s\ngoing on.\n\n    \n    \n    def transform_queries({:max, args}) do # args is a list args |> Enum.map(&transform_queries) |> Enum.reduce(fn {x, qs}, {max_acc, q_acc} -> {max(x, max_acc), qs ++ q_acc} end) end\n\nThis is quite a bit of boilerplate. It\u2019s not the worst code ever\u2014it\u2019s\ncertainly better than our first solution with a global variable\u2014but we seem to\nbe saying more than we need to here.\n\n## Finding the cleavage point #\n\nHow can we clean up this code? The code is messy because there are actually\ntwo competing concerns here: we have some main computation that we care about\n(transforming the tree) and some side information (the set of database\nqueries) that we\u2019d like to collect in parallel. If we can separate these\nconcerns, our code will improve.\n\nNow that we see the two intertwined issues, how do we go about separating\nthem? We will still carry around the AST-queries-tuple, but we are going to\npull out the logic that governs how we keep track of the list of queries and\nkeep it separate from the AST transformation logic.\n\nFirst, let\u2019s define a module, a type to help us keep track of an AST-queries-\ntuple, and a function wrap that takes some AST and pairs it with an empty list\nof queries:\n\n    \n    \n    defmodule AstList do @type t() :: {Ast.t(), [Query.t()]} @spec wrap(Ast.t()) :: t() def wrap(v), do: {v, []} end\n\nSecond, the clever bit: we write a function that lets us manipulate the AST\nvalue inside the tuple without worrying about how to combine the sets of\nqueries. We\u2019ll call this function thread, and it takes an AST-queries-tuple\nand gives it to a function argument that expects just the AST bit. That\nfunction argument should return a new AST-queries-tuple. Our function thread\nwill then merge the two lists of queries together without the function\nparameter ever having to worry about it.\n\n    \n    \n    @spec thread(t(), (Ast.t() -> t())) :: t() def thread({ast, queries}, f) do {m_dd, m_ll} = f.(m_d) {m_dd, m_ll ++ m_l} end\n\nNow we can use this to write our transform_queries function! Before we get\nthere, remember that Elixir has a handy set of customizable infix operators\nthat we can use as shorthand:^1\n\n    \n    \n    def m ~>> f, do: thread(m, f)\n\nThat means that instead of writing this:\n\n    \n    \n    def transform_queries({:+, lhs, rhs}) do {new_ast_l, queries_l} = transform_queries(lhs) {new_ast_r, queries_r} = transform_queries(rhs) {{:+, new_ast_l, new_ast_r}, queries_l ++ queries_r} end\n\nWe can just write:\n\n    \n    \n    def transform_queries({:+, lhs, rhs}) do transform_queries(lhs) ~> fn new_lhs -> transform_queries(rhs) ~> fn new_rhs -> wrap({:+, new_lhs, new_rhs}) end end end\n\nYou might be able to see now how this would make writing this little\noptimization pass a lot cleaner. We can go a step further on the syntax\nthough: with a little metaprogramming imagination, we can write some shorthand\nfor the ~> notation that looks more like variable assignment in a with. It\u2019s\nnot that hard to do.^2\n\n    \n    \n    defp transform_threading([{:<-, _, [var, expr]} | rst]) do quote do unquote(expr) ~>> fn unquote(var) -> unquote(transform_threading(rst)) end end end defp transform_threading([expr]), do: expr defmacro threading (do: {:__block__, _, lines}) do transform_threading(lines) end\n\nNow we can write the handler for + like so:\n\n    \n    \n    def transform_queries({:+, lhs, rhs}) do threading do new_lhs <- transform_queries(lhs) new_rhs <- transform_queries(rhs) wrap({:+, new_lhs, new_rhs}) end end\n\nAnd that gets transformed into the nested anonymous function notation we saw\npreviously.\n\n### What do we get? #\n\nNow we don\u2019t have to think about merging the list of queries any more: the ~>>\noperator handles all that for us. Bigger savings come if we think about making\na version of map that works with our AST-queries-tuples. We\u2019ll call it mapM\nsince it\u2019s like a map that we\u2019re mashing the results together:\n\n    \n    \n    @spec mapM(vs :: [Ast.()], f :: (Ast.t() -> t())) :: t() def mapM(vs, f) do results = vs |> Enum.map(f) { results |> Enum.map(&elem(&1, 0)), results |> Enum.map(&elem(&1, 1)) |> Enum.reduce([], &++/2) } end\n\nHere we map over a list of Ast values, collect all the resulting sets of\nqueries, and merge them together. This gives us a big savings when we write\nsomething like the max function:\n\n    \n    \n    def transform_queries({:max, args}) do args |> mapM(&transform_queries) ~>> &wrap({:max, &1}) end\n    \n    \n    def transform_queries({:max, args}) do # args is a list args |> Enum.map(&transform_queries) |> Enum.reduce(fn {x, qs}, {max_acc, q_acc} -> {max(x, max_acc), qs ++ q_acc} end) end\n\nNotice that all the handling of the extra information has been lifted out of\nour code. Not only does it make it clearer what the core intent of the\nfunctions are, but we also get some added flexibility around how we structure\nthat extra data. If we wanted to use a map or a set instead of a list of\ntuples as the second element in the AST-queries-tuple, then with this\nrefactoring we only have to modify the wrap, thread, and mapM functions. The\nrest of the code can stay the same!\n\nSo, with a little bit of work, we\u2019ve gone from a solution using global mutable\nstate \ud83e\udd22 to passing around a AST-queries-tuple \ud83d\ude10 to abstracting out the tuple\nentirely, gaining clarity and flexibility along the way. \ud83e\udd29 Our threading-\nrelated functions are actually generic enough that they don\u2019t need to be about\nASTs and lists of queries\u2014as long as we are doing some main computation with a\nlittle extra data gathering on the side, this pattern should apply.\n\nWouldn\u2019t it be nice if this pattern had a name?\n\n## It was a monad all along! #\n\nSurprise! This is exactly the writer monad! This whole post has been a monad\ntutorial in disguise!\n\nIf you\u2019ve been exposed to monads before, you might recognize wrap as return\nand thread as bind or\u2014as the Haskell programmers like to call it\u2014>>=. The\nthread do ... end macro is just do notation. (I couldn\u2019t think of a clever\nname for mapM, so I just pretended the M stood for mash instead of monad.)\n\n\u201cMonad\u201d is just an interface.^3 That\u2019s all there is to it. To make your data\nstructure (like our AST-queries-tuple) conform to the Monad interface, you\nneed functions like wrap and thread. Once you have those, you have a monad.^4\nThat\u2019s pretty much all there is to it.\n\n### Different kinds of monads #\n\nThere isn\u2019t a fixed number of monads; there are however a set of more-or-less \u201cstandard\u201d monads which have been discovered to be generally useful; the Haskell Wiki has a nice list here. Among these is the \u201cmaybe\u201d monad, which lets you focus on the happy-path of computation and abstracts away the failure path. In Elixir, you can see this pattern with the {:ok, term()} | :error idiom. (The with notation commonly seen in this idiom closely follows Haskell\u2019s do notation.) There are many other useful monads besides the writer and maybe monads. Some of these (like the IO monad) are pretty specific to Haskell and other pure functional languages that don\u2019t support the same kinds of control flow or constructs; others have wider application.\n\n### What monad tutorials get wrong #\n\nMost of the value (I think) of monads is not having return and bind, but all\nthe helper functions like mapM, do notation, and friends. While I was writing\nsome Haskell, I got to know all the monad-related functions and how useful\nthey were. These helper functions are what make programming with monads\nnatural and powerful. The core functions bind and return are all you \u201cneed\u201d to\nmake a monad, but no one would actually program with just those.\n\nIf you ever find something that you think would work well modeled as a monad,\nbe sure to implement additional functions beyond bind and return. You can see\na list of functions Haskell implements for monads here if you want some\ninspiration.\n\n## Why Haskell uses monads so much #\n\nYou hear a lot about monads with languages like Haskell, but not so much with\nother functional languages like Elixir or Rust. Part of this is need, and part\nis because of ergonomics.\n\nHaskell needs monads to implement effectful computation. Effects include\nexceptions (modeled by the maybe monad) or logging information (the writer\nmonad). Languages that have these effects natively don\u2019t strictly need these\nmonads. (Though, as we\u2019ve seen, writing a monad can help other languages, even\nwhen they have uncontrolled side-effects, like Elixir.)\n\nHaskell makes using monads ergonomic through its typeclass mechanism. Other\nlanguages have more constrained method dispatching mechanisms, so you have to\njump through some hoops to get monads to work as seamlessly as they do in\nHaskell.\n\n### Typeclasses vs. interfaces #\n\nIf you\u2019re familiar with an OO language, you\u2019ve almost certainly come across\nthe idea of an interface: it\u2019s just a specification of methods an object needs\nto implement. Typeclasses are similar: they specify a set of functions needed\nfor a type to belong to a typeclass. There are a few key differences between\ntypeclasses and interfaces however:\n\n  * Interfaces are closed, meaning, if an object doesn\u2019t implement the interface, you can\u2019t do anything about it, unless you modify the definition of the object itself.\n\nIn contrast, typeclasses are open, meaning that I can implement the requisite\nfunctions to turn a datatype into a monad, even if I can\u2019t modify the\ndefinition of the datatype itself.\n\n  * Interfaces specify methods that dispatch on their object. If I call thing.dance(), then I will look up the dance method in whatever class thing belongs to.\n\nTypeclass functions can dispatch on the return type of the function. For\nexample, the wrap (i.e. return) function needs to dispatch on whatever type\nit\u2019s expected to return. If I said something like:\n\n    \n        thing1 :: Robot = return \"Marvin\" thing2 :: Person = return \"Arthur\"\n\nreturn would dispatch to the version specified for the Robot type for thing1,\nand Person\u2019s implementation for thing2. This makes the monad functions really\ngeneric; with a return that can dispatch on the expected return type, you can\nwrite return without thinking much about which monad exactly you\u2019re using.\n\n### Using monads in non-Haskell languages #\n\nIn languages that don\u2019t have typeclasses, you need to take special steps to\nensure that you dispatch to the proper variant of the monad. Racket has a\nmonad library that works via a generics interface system, plus a few tricks to\nteach return (called pure in this library) what type it should return. I am\nsure the same tricks would apply to Elixir. Indeed, Elixir has protocols,\nwhich are like interfaces, but they are open. They still dispatch on the shape\nof the first argument passed to them, you would need to pull a trick like\nRacket\u2019s pure function and pass an argument to ignore just to get the dispatch\nright.\n\nElixir has less need for monads than Haskell because its functions are impure.\n(A function can do arbitrary IO, send messages, throw exceptions, etc.) but\nthere are still cases (as we have seen) where a monad can make life easier.\nConsider using a monad library the next time you need to avoid ugly side-\neffects!\n\n## Breaking boilerplate in your functional projects #\n\nFunctional languages are not immune to sprouting boilerplate. And while most\nof the design patterns in a certain OO cookbook are \u201cinvisible or simpler\u201d in\nfunctional languages,^5 some patterns crop up when similar problems arise.\n\nMonads are a powerful tool for dividing the essential from the incidental in a\nprogram. Exactly what constitutes the essential versus incidental parts\u2014along\nwith how to separate them\u2014can be tricky to see at first. I think this is\nbecause separating these concerns in mainstream functional languages get less\nvisibility, and not because of any inherent difficulty of the problem. Perhaps\nif everyone started out programming by learning Racket and got comfortable\nwith functional idioms, monads would be as natural as the Visitor pattern.^6\n\nI was surprised and delighted when a monadic solution appeared as the most\nnatural solution to a problem I was working on. Now, you might say that\u2019s\nbecause I work as a programming languages researcher. However, the last two\ntimes I was working in industry, we had some sort of language interpreter, and\nI had to walk an AST. Knowing the writer monad would have saved me a lot of\ntime and effort. I hope you can start seeing some monadic patterns in your\ncode, and that you\u2019ll be able to make a monad to make it easier to reason\nabout and refactor your code as well.\n\n## Further reading #\n\n  * https://wiki.haskell.org/All_About_Monads\n  * https://learnyouahaskell.com/a-fistful-of-monads\n\n## Acknowledgements #\n\nThanks to Scott Wiersdorf for the initial impetus to write this, as well as\nsome thoughtful feedback on the prose and outline. Thanks also to Mark\nEricksen for some additional comments.\n\n  1. It would be nice if we could use >>= for this shorthand... but I\u2019m getting ahead of myself. \u21a9\ufe0e\n\n  2. \ud83d\ude09 Pun intended. If you don\u2019t get it, just wait. \u21a9\ufe0e\n\n  3. There\u2019s a subtle difference between interfaces and typeclasses, and I\u2019ll get to that shortly. This is meant to build intuition. \u21a9\ufe0e\n\n  4. Monad laws yadda yadda yadda... OK, there are certain properties (called the \u201cmonad laws\u201d\u2014don\u2019t worry, they\u2019re not that scary even though the name sounds ominous) that these functions need to satisfy, but they\u2019re pretty easy to hit. If you don\u2019t satisfy these laws, your monad won\u2019t behave predictably. \u21a9\ufe0e\n\n  5. Peter Norvig. https://norvig.com/design-patterns/design-patterns.pdf \u21a9\ufe0e\n\n  6. Certainly it would be more comfortable than the AbstractSingletonProxyFactoryBean! \u21a9\ufe0e\n\nMastodon\n\n\u00a9 Ashton Wiersdorf 2024\n\n", "frontpage": false}
