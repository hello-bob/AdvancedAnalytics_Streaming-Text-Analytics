{"aid": "40188501", "title": "AI Automated Alert Correlation", "url": "https://www.keephq.dev/post/aiops-finding-incidents-in-the-haystack-of-alerts", "domain": "keephq.dev", "votes": 1, "user": "talboren", "posted_at": "2024-04-28 13:38:39", "comments": 0, "source_title": "Keep", "source_text": "Keep\n\n# AIOps! Finding Incidents in the Haystack of Alerts\n\nTal Borenstein\n\n\u2022\n\nApril 11, 2024\n\nBack to all Blog Posts\n\nThe challenge of managing alerts and incidents looms large in the realm of\nAIOps (Artificial Intelligence for IT Operations). Surprisingly, traditional\napproaches often rely on rule-based engines, raising the question, \"Where is\nAI?\".\n\nAt Keep, we're pushing the boundaries with an innovative solution: an AI-\npowered alert correlation engine.\n\n### The Challenge: A Sea of Alerts, Incidents & Events\n\nIn today's complex IT landscape, organizations face an avalanche of alerts\nstemming from diverse sources like Kubernetes clusters, cloud providers, and\nthird-party tools. These alerts often lack context, inundating teams with\nnoise and making it arduous to discern crucial incidents from the noise. This\ndeluge not only overwhelms IT teams but also hampers incident response and\nresolution times, ultimately impacting business continuity.\n\n### A New Approach: AI Automated Alert Correlation\n\nAt Keep, we're spearheading a paradigm shift with our AI automated alert\ncorrelation engine. Unlike conventional rule-based systems, our approach\nleverages state-of-the-art LLM models trained on real-world incident data.\n\nThere are two key components to our model training strategy:\n\n  1. General Incident Training: We train our models on a rich repository of general incidents sourced from open knowledge bases like GitLab's production infrastructure incidents. By analyzing historical incidents across diverse environments, our models learn to discern patterns and anomalies, enabling more accurate incident detection.\n  2. Customer-Specific Training: Upon onboarding customers, our engineers fine-tune the model to adapt to their specific data sources and events. This entails learning from past incidents, customizing rules, and refining the model's understanding of the customer's infrastructure. This tailored approach ensures that our AI engine is finely attuned to each customer's unique environment, maximizing its effectiveness.\n\n### The Quest for Efficiency: Finding the Needle\n\nOur AI engine acts as a discerning needle, swiftly identifying and correlating\nincidents in real-time. By automating the correlation process, we alleviate\nthe burden on IT teams, enabling them to focus their efforts on resolving\ncritical issues promptly. Furthermore, our AI engine continuously learns and\nevolves, adapting to shifting patterns and emerging threats, thereby enhancing\nits efficacy over time.\n\n### Feedback Loop\n\nBut how does our AI engine achieve such precision?\n\nOur feedback loop is a dynamic mechanism that ensures continuous improvement.\nUsers have the ability to flag alerts that were correlated falsely or add\nmissing alerts from the feed. These actions serve as input for refining the\nmodel, updating the training data, and enhancing its accuracy.\n\n### Continuous Learning and Improvement\n\nWith each iteration of the feedback loop, our AI engine becomes increasingly\nadept at distinguishing between genuine incidents and false alarms. It learns\nfrom past mistakes, fine-tunes its model, and hones its ability to discern\nsubtle nuances in the alert data. As a result, the efficacy of our alert\ncorrelation engine evolves organically, ensuring unparalleled accuracy and\nreliability in incident detection.\n\n### Integrations, integrations, integrations!\n\nLastly, but significantly, Keep operates as a plug-in solution, eliminating\nthe need to overhaul your existing IRM stack or migrate users to a new\nplatform. Simply integrate it into your infrastructure, allow the model to\nlearn, and experience the benefits of an enhanced workflow seamlessly.\n\n## Discover more posts\n\n### Unifying alerts from various sources\n\nDemonstrate the strength of a unified API in consolidating and managing\nalerts.\n\nShahar Glazner\n\n\u2022\n\nNovember 26, 2023\n\n### Observability vendor lock-in is in the small details\n\nIn the world of observability, vendor lock-in slows progress and spikes costs.\nOpenTelemetry broke some chains but didn't free us entirely. This post shows\nthe bridge between talk and action and how platforms like Keep offer\nflexibility, interoperability, cost optimization, community-driven support,\nand an escape from vendor lock-in traps. If you maintain >1\nobservability/monitoring system, are concerned with vendor lock-in, and need\nhelp keeping track of what's going on and where, this post is for you.\n\nTal Borenstein\n\n\u2022\n\nOctober 31, 2023\n\n### Extending Grafana with Workflows\n\nWe all have that one service that, for some Phantom-de-la-machina reason, gets\nstuck and requires some manual action, like maybe a reboot or a REST call.\n\nGil Zellner\n\n\u2022\n\nSeptember 14, 2023\n\n### Getting started with Keep \u2014 Observability Alerting with ease\n\nCreating and maintaining effective alerts, avoiding alert fatigue, and\npromoting a strong alerting culture can be difficult tasks. Keep addresses\nthese challenges by treating alerts as code, integrating with observability\ntools, and using LLMs.\n\nDaniel Olabemiwo\n\n\u2022\n\nMay 14, 2023\n\n### Building a new shift-left approach for alerting\n\nAlerting (aka monitors/alarms) always felt like a second-class citizen within\nall the different monitoring/observability/infrastructure tools with a very\nnarrow feature set, which in turn results in poor alerts, alert fatigue (yes,\nyour muted Slack channel), unreliable product and a complete alerting-hell.\n\nTal Borenstein\n\n\u2022\n\nApril 10, 2023\n\n### Current problems in the alerting space\n\nIn the past month, we have engaged in conversations with over 50 engineers,\nengineering managers, and SREs to gather feedback on the products we are\ndeveloping at Keep. Here is a summary of what we have learned.\n\nShahar Glazner\n\n\u2022\n\nMarch 19, 2023\n\n\u00a9 2023 KeepHQ. All rights reserved.\n\nCompany\n\nTwitterfounders@keephq.dev\n\nLegal\n\nTerms of ServicePrivacy Policy\n\n", "frontpage": false}
