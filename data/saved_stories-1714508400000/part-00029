{"aid": "40210988", "title": "A Synthetic Transplant (2023)", "url": "https://www.integralworld.net/lane279.html", "domain": "integralworld.net", "votes": 1, "user": "indigodaddy", "posted_at": "2024-04-30 13:55:58", "comments": 0, "source_title": "A Synthetic Transplant, Offloading Human Intelligence in Favor of A.I. Governance, David Lane and Kelly Diem-Lane", "source_text": "A Synthetic Transplant, Offloading Human Intelligence in Favor of A.I.\nGovernance, David Lane and Kelly Diem-Lane\n\nTRANSLATE THIS ARTICLEPowered by Google \u00dcbersetzerIntegral World: Exploring\nTheories of EverythingAn independent forum for a critical discussion of the\nintegral philosophy of Ken Wilber\n\n  * home\n  * about\n  * new\n  * essays\n  * AI\n  * book\n\nDavid Christopher Lane, Ph.D, is a Professor of Philosophy at Mt. San Antonio\nCollege and Founder of the MSAC Philosophy Group. He is the author of several\nbooks, including The Sound Current Tradition (Cambridge University Press,\n2022) and the graphic novel, The Cult of the Seven Sages, translated into\nTamil (Kannadhasan Pathippagam, 2024). His website is neuralsurfer.comKelly\nDiem-Lane is currently a sophomore in college after having graduated high\nschool at age 15. He is the author of several small books including When\nComputers Become Human (published in China and translated into Mandarin, 2017)\nand Creature Compassion (2022). His fields of interest are Artificial\nIntelligence and Virtual Reality technologies.\n\n# A Synthetic Transplant\n\n## Offloading Human Intelligence in Favor of A.I. Governance\n\n### David Christopher Lane and Kelly Diem-Lane\n\n> Summary by ChatGPT: The essay \"A Synthetic Transplant\" by David Lane and\n> Kelly Diem-Lane explores the implications of increasingly offloading human\n> intelligence to Artificial Intelligence (AI) and technological systems. The\n> authors caution against over-reliance on technology, as it might lead to a\n> loss of human competency in basic skills and potentially a loss of\n> individuality. They also touch on concerns such as economic displacement,\n> power concentration, and reality manipulation associated with AI's\n> advancement. Through historical and contemporary examples, they exhibit how\n> humanity's over-dependence on technology could lead to a \"Synthetic\n> Temptation,\" where AI governs significant aspects of life, thereby\n> transforming the essence of human experience.\n\n> \u201cIt seems probable that once the machine thinking method had started, it\n> would not take long to outstrip our feeble powers... They would be able to\n> converse with each other to sharpen their wits. At some stage, therefore, we\n> should have to expect the machines to take control.\u201d --Alan Turing\n\nI suspect we are not ready for the coming tech tsunami that is inevitably\ngoing to swamp the planet.The clich\u00e9' \u201cWhy reinvent the wheel\u201d is an oft used\nexpression to remind us that it is a waste of time and energy to do over what\nhas already been done. It is also a reminder that whenever we can offload a\ntask instead of doing it ourselves, we would be well advised to do such. But\nthe danger is that the more we do so, the less competent we may become in\nmastering or performing that specific function.There is a plethora of examples\nwhich illustrate this in human history. Where once we were competent in making\nfire from raw materials, such as flint stones or sticks, today we use matches\nor portable lighters. Where once we relied on our own navigational senses for\ntraveling, to track animals, and to locate edible plants, today we utilize\nsmart phone applications. As such, we increasingly rely on the tools we make,\nusually in the hopes of making our lives easier and more productive.Socrates\ndecried the written word since he believed it would hamper our poetic\nmemories. His point, though containing an element of truth, didn't stick. The\nprinted word was too beneficial to ignore. While history has had its share of\nluddites, the progressive nature of technology is irresistible for most.The\ndifference now is that informational-laden systems evolve at an exponential\nrate and because of this we can envision a future where we become so reliant\nand dependent on technology that we become dumber in the process. With\nArtificial Intelligence we are bit by bit offloading our human intelligence in\nfavor of A.I. governance.Just a few decades ago, in writing a letter it was\nelemental to know how to spell, how to use correct grammar, and how to\nconstruct a proper reply but with spell-check, grammar-monitoring, and auto-\nfill, these tasks can be automated. With the advent of ChatGPT, nobody needs\nto know how to write an essay or a story or even analyze a legal brief. The\nlarge language models (LLMs) can do it for you and within seconds, thereby\nsaving massive amounts of time, energy, and frustration.But this is only the\nfirst small wave in an oncoming set of much larger swells, as Mustafa Suleyman\n(co-founder of DeepMind) so clearly explains in his recent book, The Coming\nWave: Technology, Power, and the Twenty-First Century's Greatest Dilemma.It is\na scary read for what it portends is nothing less than the radical\ntransformation of what it is to be human, particularly as A.I. and Synthetic\nBiology are conjoined at the hip. As John Naughton, writing for The Guardian,\nwarns,\n\n> Translated into terms of technological waves, Suleyman's evolutionary\n> sequence looks like this: humans first used technology to operate on the\n> physical world \u2014 the world of atoms; then they worked on bits, the units of\n> information; and now they are working on creating new forms of biological\n> life. Or, to put it more crudely: first we invented mechanical muscles; now\n> we are messing with our brains; and soon we will be doing this with our\n> biology. However you portray it, though, the reality is that we are in the\n> process of creating monsters that we have no idea how to manage.\n\nWe have been offloading our intelligence to computational devices since the\nvery first pocket calculators. Though, one could argue that using any physical\ntool\u2014from abacuses to slide-rulers to even our own hands\u2014is a way to alleviate\nthe burden of remembering numbers and elemental facts.The next step in this\ndirection has already been climbed with the advent of smart glasses and\nVirtual Reality goggles. As we walk, we can be notified about what type of\nplants we are looking at, what kind of special a caf\u00e9 is offering, and with\nembedded QR codes, get instant access to websites and much more.Of course, it\nis only a matter of time (and getting beyond our initial fears and\nsqueamishness) when we allow neural implants to augment our limited\nintelligence even more.But in all these cases, we are succumbing to what can\nbe rightly called the Synthetic Temptation, where we let go of our own\ninitiatives and let Artificial Intelligence serve as our guru. Now to be\nclear, there is much in favor of succumbing to such a richly informed\nOverlord, particularly when we have no expertise in a specific area.Yet, this\nis also a double-edged sword, since we may never be motivated to learn the\nprimary skills necessary to be more, not less, self-sufficient. So wedded are\nwe to the electronic cloud that surrounds us that if it fails, we are at quite\nliterally at wit's end.This is the inherent danger that we face by over-\nrelying on A.I.The question that looms in the balance is how much or how\nlittle we should augment ourselves with computational systems, especially if\nwe are not sure if their interests align with our own.Jaron Lanier, the famed\npioneer in all things VR, worries that in our rush for all things tech, we\nlose sight of our own humanity. Indeed, the more we divorce algorithms from\nour emotional and spiritual selves, he suggests, the more we become\n\u201cobjectified\u201d in the process. Ironically, ChatGPT4 provides a very revealing\nsummary of Lanier's perspective and lists what all of us should be keenly\naware of before surrendering our individuality to Synthetic Intelligences:Loss\nof Individuality: Lanier fears that over-reliance on AI algorithms,\nparticularly in social media and online platforms, can lead to a loss of\nindividual thought and autonomy. If people are constantly being fed what\nalgorithms determine they want to see or hear, it reduces their exposure to\ndiverse ideas and perspectives.Economic Displacement: Like many, Lanier is\nconcerned about the potential of AI to displace jobs. As automation increases,\nthere could be a significant shift in how economies function and how\nindividuals earn a living.Concentration of Power: AI tools, especially those\nused in big data analytics and prediction, can become tools of power\nconcentration. The companies or entities that control these tools can wield\nsignificant influence over society, potentially overshadowing democratic\ninstitutions.Reality Manipulation: With the advancement of AI, the line\nbetween what's real and what's computer-generated can blur. This could lead to\nmisinformation, manipulated videos (deepfakes), and a general distrust in\ndigital content.Depersonalization: As decisions become increasingly made by\nalgorithms, there's a fear that human stories, emotions, and nuances get lost.\nThis can lead to a society where decisions feel impersonal and\ndehumanized.Devaluation of Personal Experience: Lanier has expressed concerns\nthat AI could diminish the value of personal experience and intuition. As\npeople come to rely on AI for recommendations or insights, they might start to\nundervalue their own experiences or feelings.Over-Optimization: AI systems\noften work by optimizing for specific goals. However, over-optimization can\nlead to unforeseen consequences and can miss the broader, holistic\npicture.Loss of Connection: On a deeper philosophical level, Lanier has mused\non the idea that an over-reliance on AI and digital systems can lead to a loss\nof connection with the organic, natural world.Jaron Lanier isn't totally\npessimistic about A.I., since he clearly sees how it can benefit humanity in\nways that are truly spectacular\u2014from medicine to weather forecasting to\nmanufacturing and more.Yet, his skepticism is that we are too prone to give\nourselves over to these algorithms because of their ease of use.This is\nalready obvious, given how easy it is to create essays, pictures, art,\nbusiness plans, spreadsheets, tax returns, legal briefs, and so on.In our rush\nto offload our own intelligence to our A.I. offspring, we must ask the most\nimportant question that confronts us:Is it worth the risk?Max Tegmark from\nM.I.T., author of Life 3.0, argues that \u201c\"Everything we love about\ncivilization is a product of intelligence, so amplifying our human\nintelligence with artificial intelligence has the potential of helping\ncivilization flourish like never before - as long as we manage to keep the\ntechnology beneficial.\"But he contextualizes that optimism with the following,\n\n> \u201cSadly, I now feel that we're living the movie 'Don't look up' for another\n> existential threat: unaligned superintelligence. We may soon have to share\n> our planet with more intelligent \u201cminds\u201d that care less about us than we\n> cared about mammoths. A recent survey showed that half of AI researchers\n> give AI at least 10% chance of causing human extinction. Since we have such\n> a long history of thinking about this threat and what to do about it, from\n> scientific conferences to Hollywood blockbusters, you might expect that\n> humanity would shift into high gear with a mission to steer AI in a safer\n> direction than out-of-control superintelligence. Think again: instead, the\n> most influential responses have been a combination of denial, mockery, and\n> resignation so darkly comical that it's deserving of an Oscar.\u201d\n\nThus, we confront what can be called the Tegmark Paradox. Yes, Artificial\nIntelligence can be the greatest advance humankind has ever known and\nexceptionally beneficial, but it can, if unchecked, lead to a dystopian future\nof unimaginable horror.Underlying all of this is the Alignment Problem, making\ncertain that a future superintelligence is in accord with human flourishing.\nBut this very field has no certainties only probabilities, and that leads to a\ngambling outcome. Are the odds in our favor for a benign symbiosis with A.I.?\n\u2014as Dan Brown's clich\u00e9d novel, Origin, implies? Or are they simply 50/50,\nmaking for an unknown roll of the dice where we must close our eyes and hope\nfor the best?Most in the Silicon Valley are well aware of the potential\ndangers inherent in letting A.I. become untethered, without a priori guard\nrails and buffers. But as much as they admit to these risks, the competition\nis such that there is already an engineering arms race to develop and exploit\nSynthetic Intelligences to their company's advantage, lest their corrivals\nhave an undue advantage over them. This is acutely true when it comes to\nnations desiring to harness the power of A.I. for general surveillance and for\nmilitary purposes.The most frightening aspect of A.G.I. (Artificial General\nIntelligence) and its ultimate progeny S.F.I (Super Functional Intelligence)\nis that they follow a Kurzweilian law of accelerating returns. If any one\nperson, company, or country masters the technology first, even if just by\ndays, they will have an exponential jump over their counterparts, forever\nleaving them trying to catch up.John Carmack, the wonder genius of game\ndevelopment and computer programming, who is not prone to hyperbole, believes\nthat by 2029 we will most likely have the first true instantiations of\nA.G.I.If this is true, we have much less than a decade to be prepared for what\nthe future has in store for us.Given the super quick and massive adoption of\nChatGPT and other A.I. related programs from the late 2022 till today, I\nsuspect we are not ready for the coming tech tsunami that is inevitably going\nto swamp the planet.My hunch is that it will be impossible to surf that tidal\nwave, much less contain it.Perhaps we will be like the dinosaurs that preceded\nus millions of years ago, who became extinct due to unexpected climatic\nchanges, which included a massive asteroid that hit near Chicxulub, Mexico,\nand left a crater 110 miles wide.We are already awash for hours a day in a\ndigital stream, but at least we have (or believe we have) some control over\nit.That, I fear, will soon not be the case. Instead of swimming with the\ncurrent of Synthetic Intelligence and directing its current, we may soon just\ndrown in it.As ChatGPT concluded when prompted about this very concern:The\nphrase \"drown in its wake\" is metaphorical and could be interpreted in various\nways, but it generally suggests being overwhelmed or overtaken by something\nlarger or more powerful. When applied to the idea of superintelligence that's\nnot aligned with human interests, the phrase captures a real concern: that\nsuch an intelligence could act in ways that are detrimental to humanity.Here's\nwhy many thinkers and experts in the field of artificial intelligence (AI)\nethics and safety are concerned:Speed and Capability: A superintelligent\nsystem would be far more capable than any human, and could potentially act\nfaster than we can respond or understand.Alignment Challenge: Ensuring that an\nAI's goals are perfectly aligned with human values is a difficult problem.\nEven small misalignments could result in actions that are at odds with our\ninterests.Unintended Consequences: A superintelligent AI might find ways to\nachieve its objectives that we didn't anticipate. For example, if we told an\nAI to maximize human happiness, it might decide the best way to do that is to\nplug us all into some kind of \"pleasure machine\" rather than promoting genuine\nwell-being.Irreversibility: Once a misaligned superintelligence starts taking\nactions, it might be difficult or impossible to reverse those\nactions.Existential Risk: At the extreme end, a misaligned superintelligence\ncould pose an existential risk to humanity, either by directly acting against\nus or by making decisions that inadvertently lead to our downfall.\n\n> \u201cThe upheavals [of AI] can escalate quickly and become scarier and even\n> cataclysmic. Imagine how a medical robot, originally programmed to rid\n> cancer, could conclude that the best way to obliterate cancer is to\n> exterminate humans who are genetically prone to the disease.\u201d \u2014 Nick Bilton\n\n> \u201cThe exponential progress of technology is altering the phenomenological\n> experience of human sensation, robbing us of our ability to get in touch\n> with our humanity and reflect upon the triumphs and madness of our techno-\n> society. Ironically, in our obstinate desire to humanize robots and\n> Artificial Intelligence, our individual existence is, in turn, being\n> digitized and robotized by our own technological inventions.\u201d \u2014 Danny\n> Castillones Sillada\n\n#### AND FOR A MORE POSITIVE CONCLUSION\n\n##### Old School and Analog and Not art of the Electric Grid\n\nhttps://sites.google.com/view/neuralsurferbookshop/\n\n### Comments\n\n> zak \u00b7 Oct 6, 2023Well done David, and an informative piece pointing out the\n> major issues with AI.I think only a 10 percent chance of extinction through\n> AI seems to be a reasonable riskI mean, water kills us fire kills us, or\n> anything misused or just an accident. And so, this will be accepted and\n> pursued with diligence.As for your \u201c pleasure machine\u201d example of AI running\n> amuck, I think they will program it to be balanced enough to avoid that kind\n> of stuff.Overall, I don\u2019t fear AI, I fear the potential misuse by humans,\n> not the tech itself. It's basically just another programmable device. The\n> programmer is the one who's dangerous!\n\n1\n\n> David Christopher Lane \u00b7 Oct 5, 2023Dear Jan Krikke,Thank you for your\n> comment. You raise an important issue when you ask, \"Who would design an AI\n> system that has the potential to kill people? Who would design an aircraft\n> that could decide by itself to crash, or an atomic bomb that would self-\n> detonate?\"Putting aside the notion of Skynet, Terminator, and killer robots,\n> we are already witnessing the troublesome downsides of A.I. with fake\n> pictures, fake videos, fake voices, and even fake dental advertisements with\n> a famous actor (Tom Hanks). Because A.I. only gets better over time and is\n> much easier to use, bad actors can use such to create havoc across a variety\n> of platforms.And, yes, accidents can happen and unintentional consequences\n> can occur even with the most benign of intentions.The recent book, The\n> Coming Wave, by the co-founder of DeepMind and Tegmark's Life 3.0 is\n> informative and predictive about being concerned about what can happen and\n> will most likely happen.Personally, I tend to be a first adopter of all\n> things tech, including V.R. and A.I.-related products. I also happen to be\n> an optimist by nature concerning these developments. But it would be unwise,\n> I would suggest, to ignore the downsides.For example, those doing gain-of-\n> function research on viruses may have the very best of intentions, but lab\n> leaks are a real possibility and something that we must be very cautious\n> of.... even to the point of curtailing some of these activities.We shouldn't\n> be naive about A.I.At present, A.I. is generally domain-specific, as you\n> mentioned, but some systems have wider applications and can do multiple\n> functions.There is now a rush to see if A.G.I. (Artificial General\n> Intelligence) is not only possible but viable in the very near term (thus my\n> citation of John Carmack).If this does occur, we are opening up a new can of\n> worms. Moreover, if AGI can become functionally autonomous and act upon its\n> own programming then that also presents us with a new set of problems.I\n> realize that we don't need to scare ourselves silly about AI and become\n> catatonic because of our overly wrought projections.However, we need to wake\n> up and be aware that AI has a potential far beyond what we may at present\n> imagine.Thanks for your input.You may enjoy this interview as\n> well.youtu.be/Zc4csOv7QtM?si=ZDJTgyGi0xjUHNiC\n\n1\n\n> bjm \u00b7 Oct 6, 2023@David Christopher Lane,Sam Harris on AI risks :\n> www.youtube.com/watch?v=GmlrEgLGozw\n\n1\n\n> Jan Krikke \u00b7 Oct 5, 2023\u201cThe upheavals [of AI] can escalate quickly and\n> become scarier and even cataclysmic. Imagine how a medical robot, originally\n> programmed to rid cancer, could conclude that the best way to obliterate\n> cancer is to exterminate humans who are genetically prone to the\n> disease.\u201dThese kinds of scare stories are common in the AI community, but\n> they never explain how it would happen. Who would design an AI system that\n> has the potential to kill people? Who would design an aircraft that could\n> decide by itself to crash, or an atomic bomb that would self-detonate?\n> Accidents happen but AI turning into killers is a sophomoric fantasy.All AI\n> systems are domain-specific. An AI designed the perform an operation can't\n> drive a vehicle. Autopilots in cars make mistakes, and they are corrected as\n> soon as they are detected.The same would happen with a medical AI system. AI\n> systems can offer solutions the designer did not anticipate, but they are\n> always made within the parameters set by the system designers. An AI medical\n> robot won't go out in the street on a killing spree.The only intelligent\n> aspect of AI is the designer and the only aspect of the mind impacted by AI\n> is memory. All our knowledge is stored in our memory. Since AI can be\n> equipped with far more memory, it will outperform humans. AI can process\n> more options faster than humans can. It explains why IBM's Big Blue could\n> beat world chess champion Kasparov.\n\n0\n\n> bjm \u00b7 Oct 6, 2023@Jan Krikke said \"All AI systems are domain-specific.\"As a\n> programmer myself, I generally agree. Not only that, all narrow programs are\n> brittle. At some point they fail at even slightly generalizing or they are\n> very dependent on certain hardware and attached peripherals and have those\n> limits built in.Yet, the internet has already connected billions of devices\n> with eyes and ears and the ability to capture human attention. This is\n> already a radical \"cybernating\" of human+computer (billions already in this\n> mutual relationship and feedback loop).Further, deep learning in broad\n> realms of language, vision, reasoning, human psychology and so on is\n> obliterating the limits of narrow AI, especially as they are now training on\n> other media and modes, now call LMMs: large multimodal models. The latest\n> GPT-4V (vision) could look at a screen shot (image) of GPT-4 getting an\n> answer wrong, see that it was wrong and then correct it.Further, attaching\n> extra \"intelligence modules\" and delegating to external plugins, APIs and\n> tools already means GPT-4 is growing in leaps and bounds in capability\n> beyond just writing bad poetry. This isn't even including the 1000s of\n> startups already fine-tuning GPT and open-source LLMs for narrower domains\n> and tasks like therapy, law, being a friend/gf/bf. We are already hooking up\n> LLM into robots and they are destroying narrowly programmed/trained robots\n> and general tasks.A single God-AI might not gain control of the whole world,\n> but injecting 1000s or billions of them (narrow or general) into human\n> culture is an experiment we are all now about to undertake...\n\n0  \n---  \n  \nx\n\nx\n\nOriginaltext\n\nDiese \u00dcbersetzung bewerten\n\nMit deinem Feedback k\u00f6nnen wir Google \u00dcbersetzer weiter verbessern\n\n## \ud83c\udf6a Privacy & Transparency\n\nWe and our partners use cookies to Store and/or access information on a\ndevice. We and our partners use data for Personalised advertising and content,\nadvertising and content measurement, audience research and services\ndevelopment . An example of data being processed may be a unique identifier\nstored in a cookie. Some of our partners may process your data as a part of\ntheir legitimate business interest without asking for consent. To view the\npurposes they believe they have legitimate interest for, or to object to this\ndata processing use the vendor list link below. The consent submitted will\nonly be used for data processing originating from this website. If you would\nlike to change your settings or withdraw consent at any time, the link to do\nso is in our privacy policy accessible from our home page..\n\nVendor List | Privacy Policy\n\n", "frontpage": false}
