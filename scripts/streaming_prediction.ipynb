{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7040a554-46dc-4f62-a882-5da3226fa098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.classification import LogisticRegression, LinearSVC, RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder, Tokenizer, StopWordsRemover, CountVectorizer, IDF, PCA, HashingTF\n",
    "\n",
    "\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit, sum, when\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca444d20-156a-4644-a14d-407ca1c5ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change file path\n",
    "file_path = \"/Users/hydraze/Library/CloudStorage/GoogleDrive-tohziyu2@gmail.com/My Drive/Studies/KU Leuven/Courses/Classes/Y1S2/Advanced Analytics in Business/Project/3/AdvancedAnalytics_Streaming-Text-Analytics/\"\n",
    "os.chdir(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2beb48c6-4b18-41b1-b764-ca31cfec88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pickled model via pipeline api\n",
    "mPath =  file_path+\"models/best_model\"\n",
    "best_model = PipelineModel.load(mPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "febe474c-5e7c-4aae-9d5e-391a2f441e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy predict function that returns a random probability. Normally you'd use your loaded globals()['my_model'] here\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "\n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "\n",
    "    # Data cleaning (to update concurrently with the other jupyter notebook)\n",
    "    \n",
    "    # Extracting type of post: Show HN\n",
    "    df = df.withColumn('isShowHN', when(df.title.contains(\"Show HN\"), 1).otherwise(0))\n",
    "    \n",
    "    # Extracting time of day\n",
    "    extract_time_of_day_udf = udf(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S').strftime('%H'))\n",
    "    \n",
    "    df = df.withColumn('time_of_day', extract_time_of_day_udf(df.posted_at))\n",
    "    \n",
    "    # Extracting day of week\n",
    "    weekDay =  udf(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S').strftime('%w'))\n",
    "    \n",
    "    df = df.withColumn('day_of_week', weekDay(df.posted_at))\n",
    "\n",
    "    # Fill null values\n",
    "    df = df.na.fill({\"title\": \"\", \"source_title\": \"\", \"source_text\": \"\"})\n",
    "    \n",
    "    # And then predict using the loaded model (uncomment below):\n",
    "    df_result = best_model.transform(df)\n",
    "    df_result.select('aid', 'comments', 'frontpage', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd1dec46-1893-4cc8-bdc5-3f3c4ea36b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/16 23:21:37 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:21:37 WARN BlockManager: Block input-0-1715894497200 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/16 23:21:39 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:21:39 WARN BlockManager: Block input-0-1715894499400 replicated to only 0 peer(s) instead of 1 peers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2024-05-16 23:21:40 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/16 23:21:41 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:21:41 WARN BlockManager: Block input-0-1715894501400 replicated to only 0 peer(s) instead of 1 peers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+----------+\n",
      "|     aid|comments|frontpage|prediction|\n",
      "+--------+--------+---------+----------+\n",
      "|40376539|       0|    false|       1.0|\n",
      "|40376550|       0|    false|       1.0|\n",
      "+--------+--------+---------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/16 23:21:43 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:21:43 WARN BlockManager: Block input-0-1715894503400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/16 23:21:47 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:21:47 WARN BlockManager: Block input-0-1715894507400 replicated to only 0 peer(s) instead of 1 peers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2024-05-16 23:21:50 =========\n",
      "+--------+--------+---------+----------+\n",
      "|     aid|comments|frontpage|prediction|\n",
      "+--------+--------+---------+----------+\n",
      "|40376553|       0|    false|       1.0|\n",
      "|40376554|       0|    false|       1.0|\n",
      "|40376563|       0|    false|       1.0|\n",
      "+--------+--------+---------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/16 23:21:50 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:21:50 WARN BlockManager: Block input-0-1715894510600 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/16 23:21:52 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:21:52 WARN BlockManager: Block input-0-1715894512400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/16 23:21:57 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:21:57 WARN BlockManager: Block input-0-1715894517400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/16 23:21:59 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:21:59 WARN BlockManager: Block input-0-1715894519600 replicated to only 0 peer(s) instead of 1 peers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2024-05-16 23:22:00 =========\n",
      "+--------+--------+---------+----------+\n",
      "|     aid|comments|frontpage|prediction|\n",
      "+--------+--------+---------+----------+\n",
      "|40376573|       0|    false|       1.0|\n",
      "|40376578|       0|    false|       1.0|\n",
      "|40376581|       0|    false|       1.0|\n",
      "|40376583|       0|    false|       1.0|\n",
      "+--------+--------+---------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/16 23:22:01 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:22:01 WARN BlockManager: Block input-0-1715894521400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/16 23:22:05 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job 66 cancelled as part of cancellation of all jobs\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:2731)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$doCancelAllJobs$2(DAGScheduler.scala:1114)\n",
      "\tat scala.runtime.java8.JFunction1$mcVI$sp.apply(JFunction1$mcVI$sp.java:23)\n",
      "\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:1113)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3022)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "24/05/16 23:22:05 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:22:05 WARN BlockManager: Block input-0-1715894525600 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/16 23:22:06 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:22:06 WARN BlockManager: Block input-0-1715894526000 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/16 23:22:07 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:22:07 WARN BlockManager: Block input-0-1715894527000 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/16 23:22:08 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:22:08 WARN BlockManager: Block input-0-1715894528200 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/16 23:22:10 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:22:10 WARN BlockManager: Block input-0-1715894530400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/16 23:22:12 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/16 23:22:12 WARN BlockManager: Block input-0-1715894532000 replicated to only 0 peer(s) instead of 1 peers\n"
     ]
    }
   ],
   "source": [
    "# Likely the usual streaming\n",
    "ssc = StreamingContext(sc, 10)\n",
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.foreachRDD(process)\n",
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a836d1-5f25-4600-8e61-1c262573868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/09 18:12:05 WARN StreamingContext: StreamingContext has not been started yet\n",
      "24/05/09 18:12:07 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/09 18:12:07 WARN BlockManager: Block input-0-1715271127000 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/09 18:12:10 ERROR JobScheduler: Error running job streaming job 1715271130000 ms.0\n",
      "org.apache.spark.SparkException: An exception was raised by Python:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/streaming/util.py\", line 71, in call\n",
      "    r = self.func(t, *rdds)\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/4h/j84nnmnn0nj01mk0ndxyk7n40000gn/T/ipykernel_54142/3537873331.py\", line 10, in process\n",
      "    df = spark.createDataFrame(rdd)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/sql/session.py\", line 1443, in createDataFrame\n",
      "    return self._create_dataframe(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/sql/session.py\", line 1483, in _create_dataframe\n",
      "    rdd, struct = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/sql/session.py\", line 1056, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/sql/session.py\", line 1007, in _inferSchema\n",
      "    schema = _infer_schema(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/sql/types.py\", line 1670, in _infer_schema\n",
      "    raise PySparkTypeError(\n",
      "pyspark.errors.exceptions.base.PySparkTypeError: [CANNOT_INFER_SCHEMA_FOR_TYPE] Can not infer schema for type: `str`.\n",
      "\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/05/09 18:12:11 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/09 18:12:11 WARN BlockManager: Block input-0-1715271131000 replicated to only 0 peer(s) instead of 1 peers\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00ba62-43c0-4333-8579-5b1318c9ad24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
