{"aid": "40048480", "title": "Can AI read our minds? Probably not but that doesn't mean we shouldn't worry", "url": "https://theconversation.com/can-ai-read-our-minds-probably-not-but-that-doesnt-mean-we-shouldnt-be-worried-227057", "domain": "theconversation.com", "votes": 2, "user": "jethronethro", "posted_at": "2024-04-16 04:50:48", "comments": 0, "source_title": "Can AI read our minds? Probably not, but that doesn\u2019t mean we shouldn\u2019t be worried", "source_text": "Can AI read our minds? Probably not, but that doesn\u2019t mean we shouldn\u2019t be\nworried\n\nMenu Close\n\nAcademic rigour, journalistic flair\n\nIconic Bestiary / Shutterstock\n\n# Can AI read our minds? Probably not, but that doesn\u2019t mean we shouldn\u2019t be\nworried\n\nPublished: April 16, 2024 5.22am CEST\n\nSam Baron, Jenny Judge, The University of Melbourne\n\n### Authors\n\n  1. Sam Baron\n\nAssociate Professor, Philosophy of Science, The University of Melbourne\n\n  2. Jenny Judge\n\nLecturer in Philosophy of Mind and Cognitive Science, The University of\nMelbourne\n\n### Disclosure statement\n\nThe authors do not work for, consult, own shares in or receive funding from\nany company or organisation that would benefit from this article, and have\ndisclosed no relevant affiliations beyond their academic appointment.\n\n### Partners\n\nUniversity of Melbourne provides funding as a founding partner of The\nConversation AU.\n\nView all partners\n\n#####\n\nWe believe in the free flow of information\n\n###### Republish our articles for free, online or in print, under Creative\nCommons licence.\n\nEmail\n\nX (Twitter)\n\nFacebook\n\nLinkedIn\n\nWhatsApp\n\nMessenger\n\nPrint\n\nEarlier this year, Neuralink implanted a chip inside the brain of 29-year-old\nUS man Noland Arbaugh, who is paralysed from the shoulders down. The chip has\nenabled Arbaugh to move a mouse pointer on a screen just by imagining it\nmoving.\n\nIn May 2023, US researchers also announced a non-invasive way to \u201cdecode\u201d the\nwords someone is thinking from brain scans in combination with generative AI.\nA similar project sparked headlines about a \u201cmind-reading AI hat\u201d.\n\nCan neural implants and generative AI really \u201cread minds\u201d? Is the day coming\nwhen computers can spit out accurate real-time transcripts of our thoughts for\nanyone to read?\n\nSuch technology might have some benefits \u2013 particularly for advertisers\nlooking for new sources of customer targeting data \u2013 but it would demolish the\nlast bastion of privacy: the seclusion of our own minds. Before we panic,\nthough, we should stop to ask: is what neural implants and generative AI can\ndo really \u201creading minds\u201d?\n\n## The brain and the mind\n\nAs far as we know, conscious experience arises from the activity of the brain.\nThis means any conscious mental state should have what philosophers and\ncognitive scientists call a \u201cneural correlate\u201d: a particular pattern of nerve\ncells (neurons) firing in the brain.\n\nSo, for each conscious mental state you can be in \u2013 whether it\u2019s thinking\nabout the Roman Empire, or imagining a cursor moving \u2013 there is some\ncorresponding pattern of activity in your brain.\n\nSo, clearly, if a device can track our brain states, it should be able to\nsimply read our minds. Right?\n\nWell, for real-time AI-powered mind-reading to be possible, we need to be able\nto identify precise, one-to-one correspondences between particular conscious\nmental states and brain states. And this may not be possible.\n\n## Rough matches\n\nTo read a mind from brain activity, one must know precisely which brain states\ncorrespond to particular mental states. This means, for example, one needs to\ndistinguish the brain states that correspond to seeing a red rose from the\nones that correspond to smelling a red rose, or touching a red rose, or\nimagining a red rose, or thinking that red roses are your mother\u2019s favourite.\n\nOne must also distinguish all of those brain states from the brain states that\ncorrespond to seeing, smelling, touching, imagining or thinking about some\nother thing, like a ripe lemon. And so on, for everything else you can\nperceive, imagine or have thoughts about.\n\nTo say this is difficult would be an understatement.\n\nTake face perception as an example. The conscious perception of a face\ninvolves all sorts of neural activity.\n\nRead more: Nobody knows how consciousness works \u2013 but top researchers are\nfighting over which theories are really science\n\nBut a great deal of this activity seems to relate to processes that come\nbefore or after the conscious perception of the face \u2013 things like working\nmemory, selective attention, self-monitoring, task planning and reporting.\n\nWinnowing out those neural processes that are solely and specifically\nresponsible for the conscious perception of a face is a herculean task, and\none that current neuroscience is not close to solving.\n\nEven if this task were accomplished, neuroscientists would still only have\nfound the neural correlates of a certain type of conscious experience: namely,\nthe general experience of a face. They wouldn\u2019t thereby have found the neural\ncorrelates of the experiences of particular faces.\n\nSo, even if astonishing advances were to happen in neuroscience, the would-be\nmind-reader still wouldn\u2019t necessarily be able to tell from a brain scan\nwhether you are seeing Barack Obama, your mother, or a face you don\u2019t\nrecognise.\n\nThat wouldn\u2019t be much to write home about, as far as mind-reading is\nconcerned.\n\n## But what about AI?\n\nBut don\u2019t recent headlines involving neural implants and AI show some mental\nstates can be read, like imagining cursors move and engaging in inner speech?\n\nNot necessarily. Take the neural implants first.\n\nNeural implants are typically designed to help a patient perform a particular\ntask: moving a cursor on a screen, for example. To do that, they don\u2019t have to\nbe able to identify exactly the neural processes that are correlated with the\nintention to move the cursor. They just need to get an approximate fix on the\nneural processes that tend to go along with those intentions, some of which\nmight actually be underpinning other, related mental acts like task-planning,\nmemory and so on.\n\nThus, although the success of neural implants is certainly impressive \u2013 and\nfuture implants are likely to collect more detailed information about brain\nactivity \u2013 it doesn\u2019t show that precise one-to-one mappings between particular\nmental states and particular brain states have been identified. And so, it\ndoesn\u2019t make genuine mind-reading any more likely.\n\nIt may not be possible to perfectly map brain states onto mental states. Maxim\nGaigul / Shutterstock\n\nNow take the \u201cdecoding\u201d of inner speech by a system comprised of a non-\ninvasive brain scan plus generative AI, as reported in this study. This system\nwas designed to \u201cdecode\u201d the contents of continuous narratives from brain\nscans, when participants were either listening to podcasts, reciting stories\nin their heads, or watching films. The system isn\u2019t very accurate \u2013 but still,\nthe fact it did better than random chance at predicting these mental contents\nis seriously impressive.\n\nSo, let\u2019s imagine the system could predict continuous narratives from brain\nscans with total accuracy. Like the neural implant, the system would only be\noptimised for that task: it wouldn\u2019t be effective at tracking any other mental\nactivity.\n\nRead more: How close are we to reading minds? A new study decodes language and\nmeaning from brain scans\n\nHow much mental activity could this system monitor? That depends: what\nproportion of our mental lives consists of imagining, perceiving or otherwise\nthinking about continuous, well-formed narratives that can be expressed in\nstraightforward language?\n\nNot much.\n\nOur mental lives are flickering, lightning-fast, multiple-stream affairs,\ninvolving real-time percepts, memories, expectations and imaginings, all at\nonce. It\u2019s hard to see how a transcript produced by even the most fine-tuned\nbrain scanner, coupled to the smartest AI, could capture all of that\nfaithfully.\n\n## The future of mind reading\n\nIn the past few years, AI development has shown a tendency to vault over\nseemingly insurmountable hurdles. So it\u2019s unwise to rule out the possibility\nof AI-powered mind-reading entirely.\n\nBut given the complexity of our mental lives, and how little we know about the\nbrain \u2013 neuroscience is still in its infancy, after all \u2013 confident\npredictions about AI-powered mind-reading should be taken with a grain of\nsalt.\n\n  * Artificial intelligence (AI)\n  * Consciousness\n  * Brain science\n  * Mind\n  * mental state\n  * Brain scan\n  * Large language models\n\n### Events\n\nMore events\n\n### Jobs\n\n  * ##### Associate Professor, Occupational Therapy\n\n  * ##### GRAINS RESEARCH AND DEVELOPMENT CORPORATION CHAIRPERSON\n\n  * ##### Technical Skills Laboratory Officer\n\n  * ##### Faculty of Law - Academic Appointment Opportunities\n\n  * ##### Audience Development Coordinator (fixed-term maternity cover)\n\nMore jobs\n\nCopyright \u00a9 2010\u20132024, The Conversation Media Group Ltd\n\n", "frontpage": false}
