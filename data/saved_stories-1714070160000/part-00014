{"aid": "40156603", "title": "Sandia Pushes the Neuromorphic AI Envelope with Hala Point \"Supercomputer\"", "url": "https://www.nextplatform.com/2024/04/24/sandia-pushes-the-neuromorphic-ai-envelope-with-hala-point-supercomputer/", "domain": "nextplatform.com", "votes": 1, "user": "rbanffy", "posted_at": "2024-04-25 12:20:59", "comments": 0, "source_title": "Sandia Pushes The Neuromorphic AI Envelope With Hala Point \u201cSupercomputer\u201d", "source_text": "Sandia Pushes The Neuromorphic AI Envelope With Hala Point \u201cSupercomputer\u201d\n\nLatest\n\n  * [ April 24, 2024 ] Sandia Pushes The Neuromorphic AI Envelope With Hala Point \u201cSupercomputer\u201d AI\n  * [ April 23, 2024 ] Sweetened IT Spending Forecast Is Not Precisely A GenAI Boom Compute\n  * [ April 23, 2024 ] AI At The Edge: From Theory To Practice Edge\n  * [ April 22, 2024 ] Meta\u2019s Llama 3 AI Is Smart, But Who Is Going To Profit From It? AI\n  * [ April 19, 2024 ] TSMC Will Have An AI Business Bigger Than All Of Intel Foundry Compute\n  * [ April 17, 2024 ] What Happens When Hyperscalers And Clouds Buy Most Servers And Storage? Compute\n  * [ April 17, 2024 ] Power Efficiency, Customization Will Drive Arm\u2019s Role In AI AI\n  * [ April 16, 2024 ] Ampere Readies 256-Core CPU Beast, Awaits The AI Inference Wave Compute\n\n# Sandia Pushes The Neuromorphic AI Envelope With Hala Point \u201cSupercomputer\u201d\n\nApril 24, 2024 Timothy Prickett Morgan AI, Compute 0\n\nNot many devices in the datacenter have been etched with the Intel 4 process,\nwhich is the chip maker\u2019s spin on 7 nanometer extreme ultraviolet immersion\nlithography. But Intel\u2019s Loihi 2 neuromorphic processor is one of them, and\nSandia National Laboratories is firing up a supercomputer with 1,152 of them\ninterlinked to create what Intel is calling the largest neuromorphic system\nevery assembled.\n\nWith Nvidia\u2019s top-end \u201cBlackwell\u201d GPU accelerators now pushing up to 1,200\nwatts in their peak configurations, and require liquid cooling, and other\naccelerators no doubt following as their sockets get inevitably bigger as\nMoore\u2019s Law scaling for chip making slows, this is a good time to take a step\nback and see what can be done with a reasonably scaled neuromorphic system,\nwhich not only has circuits which act more like real neurons used in real\nbrains and also burn orders of magnitude less power than the XPUs commonly\nused in the datacenter for all kinds of compute.\n\nNext-generation computing architectures are something we obviously keep an eye\non here at The Next Platform, just in case a particular flavor of dataflow\nengine, neuromorphic processor, or quantum computer advances sufficiently to\nwork at scale on real-world workloads. We have been keeping an eye on the\nTrueNorth effort by IBM, which is derived from work that Big Bluedid with the\nUS Defense Advanced Research Projects Agency, the Akida neuromorphic processor\nfrom BrainChip, the memristor-based and synaptic-inspired storage of Knowm,\nand of course the Loihi 1 and Loihi 2 family of chips from Intel.\n\nIt is the Loihi 2 neuromorphic processor that is at the heart of the new Hala\nPoint system that is at Sandia being put through its paces to see how it can\nbe applied to various artificial intelligence workloads and how this compares\nto AI approaches based on CPUs, GPUs, and other compute engines. Sandia likes\nto test put new architectures, given that this is one of the mandates of the\nnational HPC labs around the world.\n\nThe first Loihi neuromorphic chip from Intel Labs, the research arm of the\nchip maker, was launched in September 2017 and appeared in the Pohoiki Beach\nsystem, which had 64 of these Loihi 1 processors linked to each other, in July\n2019. At the time, Intel said that the Loihi 1 chip, which implements a\nspiking neural network architecture like the fatty tissue you carry around in\nyour noggin, was roughly equivalent to 130,000 neurons and 128 million\nsynapses. Intel eventually scaled up a system called Pohoiki Springs that had\nover 800 Loihi chips linked together and provided over 100 million neurons for\nAI models to make use of. (A human brain has about 100 billion neurons, or a\nfactor of 1,000X more, just for context.)\n\nThe Pohoiki Beach and Pohoiki Springs machines were made available out of\nIntel Labs to hundreds of AI researchers and has not yet been commercialized.\nAnd neither will be the Hala Point system based on the second-generation Loihi\n2 neuromorphic processor, which was announced in September 2021. But it is at\nleast going into Sandia, which has created a tool called Whetstone that can\nconvert various kinds of convolutional neural networks running on CPUs and\nGPUs to spiking neural networks running on machines like those based on the\nLoihi and Loihi 2 chips.\n\nBy shifting to the Intel 4 process, the Loihi 2 chip could be roughly half the\narea of the Loihi 1 and have the same number of neuron cores, 8X more neurons\nat 1 million, and nearly the same number of synapses (123 million) as the\nLoihi 1. Here are the speeds and feeds of the two chips:\n\nAnd here is a block diagram of the Loihi 2 chip for your review:\n\nThe number of embedded processor cores on the Loihi device, which are\nprogrammed using C or Python and which are used to encode and decode data used\nby the spiking neural network software, was doubled up to six from three on\nthe Loihi 1.\n\nWhich brings us up to Hala Point. With 1,152 of these Loihi 2 chips, the\ncluster of machines now at Sandia has 140,544 neuron cores and 2,304 host X86\ncores. Those neuron cores implement 1.15 billion neurons, which is about 1\npercent of what the human brain has and roughly equivalent to the brain of an\nowl. This Hala Point machine has a total of 138.2 billion synapses.\n\nThat is about a factor of 10X more brain power than the Pohoiki Springs\nmachine that researchers around the world were playing with for the past two\nyears.\n\nThere are a dozen cards in the Hala Point server nodes, and each card includes\nsix Loihi 2 compute complexes with eight Loihi 2 chips each. That\u2019s 48 Loihi 2\nchips per card and that works out to 576 Loihi 2 chips in a 6U rack mounted\nenclosure. So this supercomputer, which burns a mere 2,600 watts, fits in 12U\nof a 42U rack.\n\nHala Point is able to process 380 trillion synaptic operations per second and\n240 trillion neuron operations per second and has an aggregate memory\nbandwidth of 16 PB per second. Running sparse deep neural networks at 8-bit\ndata resolution, this 12U system can do an equivalent of 20 petaops of\ncrunching at a power efficiency of 15 teraops per watt.\n\nWhy stop there? A mere 174 of these 6U enclosures \u2013 a mere 87X increase in\ncomputing power over the Hala Point system \u2013 would have the same number of\n\u201cneurons\u201d as the human brain.\n\nThe fun bit is the human brain burns about 20 watts, and those 174 enclosures\nwould burn 226.2 kilowatts of juice, or about 11,310X that of the brain. Such\na 100 billion neuron cluster of Loihi 2 chips would take up 25 racks of space,\nwhich is 1.55 million cubic inches of space compared to the 1,200 cubic inches\nof the average human brain. The brain is 128,900X more space efficient than\nsuch a cluster of Loihi 2 chips could be.\n\nHere\u2019s the funner bit: If Moore\u2019s Law could double chip density every two\nyears without any effort, it would only take 34 years to match the brain on\nspace efficiency and only 27 years to match the brain on energy efficiency. 3D\nstacking, which is absolutely possible with the Loihi chips, would shorten\nthat time perhaps and make a more reasonable compute complex.\n\nWe have a more interesting question: What happens if you could make a\nsimulated human brain with 1 trillion simulated neurons, or 10 trillion\nsimulated neurons, instead of real human brain with 100 billion real neurons?\nWould it be \u201csmarter,\u201d whatever that means?\n\nIf we survive this current extinction-level event, rest assured of one thing:\nSomeone will try to answer those questions. And it may not take all that much\nmoney to do it. This sounds a lot cheaper than trying to do it with heaven\nonly knows how many GPUs. . . .\n\n#### Sign up to our Newsletter\n\nFeaturing highlights, analysis, and stories from the week directly from us to\nyour inbox with nothing in between. Subscribe now\n\n### Related Articles\n\nHPC\n\n### OSC Blends Intel HBM CPUs And Nvidia HBM GPUs For \u201cCardinal\u201d Supercomputer\n\nFebruary 20, 2024 Timothy Prickett Morgan HPC 1\n\nFor a lot of state universities in the United States, and their equivalent\npolitical organizations of regions or provinces in other nations across the\nglobe, it is a lot easier to find extremely interested undergraduate and\ngraduate students who want to contribute to the font of knowledge in high\nperformance ...\n\nCompute\n\n### For CPU Makers and OEMs Alike, It\u2019s A Platform View\n\nApril 9, 2021 Jeffrey Burt Compute 0\n\nDell took a look at the two weeks between the rollouts by AMD and Intel of\ntheir latest server processors and, after some debate, decided to unveil its\nentire portfolio of new and enhanced systems \u2013 featuring the new chips from\nboth vendors \u2013 at the launch of AMD\u2019s latest ...\n\nCompute\n\n### The Next \u2013 And More Profitable \u2013 10 Percent Of Server Share For AMD\n\nFebruary 11, 2022 Timothy Prickett Morgan Compute 4\n\nWhen this is all said and done, Intel will deserve some kind of award for\nkeeping its 14 nanometer processes moving along enough as it gets its 10\nnanometer and 7 nanometer processes knocked together to still, somehow, manage\nto retain dominant market share in the server space. Or, maybe ...\n\n#### Be the first to comment\n\n### Leave a Reply Cancel reply\n\nThis site uses Akismet to reduce spam. Learn how your comment data is\nprocessed.\n\n###### About\n\nThe Next Platform is published by Stackhouse Publishing Inc in partnership\nwith the UK\u2019s top technology publication, The Register.\n\nIt offers in-depth coverage of high-end computing at large enterprises,\nsupercomputing centers, hyperscale data centers, and public clouds. Read\nmore...\n\n###### Newsletter\n\nFeaturing highlights, analysis, and stories from the week directly from us to\nyour inbox with nothing in between. Subscribe now\n\nAll Content Copyright The Next Platform\n\n", "frontpage": false}
