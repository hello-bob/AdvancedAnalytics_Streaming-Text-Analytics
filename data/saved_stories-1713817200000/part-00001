{"aid": "40114275", "title": "Finding a second bug in glibc's condition variable with TLA+. (2022)", "url": "https://probablydance.com/2022/09/17/finding-the-second-bug-in-glibcs-condition-variable/", "domain": "probablydance.com", "votes": 1, "user": "fanf2", "posted_at": "2024-04-22 13:42:03", "comments": 0, "source_title": "Finding the \u201cSecond Bug\u201d in glibc\u2019s Condition Variable", "source_text": "Finding the \u201cSecond Bug\u201d in glibc\u2019s Condition Variable | Probably Dance\n\n# Probably Dance\n\nI can program and like games\n\n### Finding the \u201cSecond Bug\u201d in glibc\u2019s Condition Variable\n\n#### by Malte Skarupke\n\nI continue to have no time for big programming projects, so here is a short\nblog post. Two years ago I looked into a bug in the glibc implementation of\ncondition variables: Sometimes pthread_cond_signal() doesn\u2019t do anything,\nwhich can easily hang your program. The bug is still not fixed, partially\nbecause a mitigation patch was available right away that seemed to make it go\naway. Except that people kept on showing up in the bug report saying that they\nstill hit the bug sometimes, raising the suspicion that there might be a\nsecond bug. I finally got around to looking into this. I found that the\nmitigation patch only helps a little, it\u2019s still the same bug, and the patch I\nsubmitted (unreviewed, don\u2019t use yet) would actually fix it.\n\nAs I mentioned last time, one of the affected programming languages is Ocaml.\nTheir master lock occasionally doesn\u2019t notify a sleeper because sometimes\npthread_cond_signal() doesn\u2019t do anything. And then the whole process hangs\nforever, because that\u2019s what happens when someone doesn\u2019t get woken up in\ncooperative multithreading.\n\nChecking this code in TLA+ happens to be easier than the code I was checking\nlast time, because this results in a deadlock, which can be checked quickly.\nLast time I had to write temporal formulas, which make TLA+ run slowly, but a\ndeadlock is easy to find: Find a state that has no successor states. All TLA+\nhas to do is enumerate all states. So whenever you can, try to write your TLA+\ncode so that it causes a deadlock on error.\n\nThe Ocaml masterlock can be directly translated into the PlusCal language of\nTLA+. It just wraps a normal mutex and adds a count of waiters, to make\ncooperative multithreading slightly more efficient: You can quickly check if\nanyone actually wants the lock, so you don\u2019t have to give it up if nobody is\nwaiting. For our purposes we don\u2019t even need the yield function, just\nst_masterlock_acquire() and st_masterlock_release() ended up being enough.\nThen all we have to do is call those in a loop on multiple threads. Here is\nthe code in PlusCal (it\u2019s calling the mutex and condition-variable functions\nwe wrote last time)\n\n123456789101112131415161718192021222324252627282930313233343536373839404142434445|\nprocedure acquire_masterlock(){acquire_masterlock_start:call\nlock_mutex();acquire_masterlock_loop:while (busy){waiters := waiters + 1;call\ncv_wait();acquire_lock_after_wait:waiters := waiters -\n1;};acquire_masterlock_after_loop:busy := TRUE;call\nunlock_mutex();return;}procedure\nrelease_masterlock(){release_masterlock_start:call\nlock_mutex();release_masterlock_after_lock:busy := FALSE;call\nunlock_mutex();release_masterlock_signal:call cv_signal();return;};fair\nprocess (Proc \\in Procs)variable num_loops = MaxNumLoops;{proc_start:while\n(num_loops > 0){num_loops := num_loops - 1;either { call acquire_masterlock();\n}or { goto proc_done; };proc_loop_done:call\nrelease_masterlock();};proc_done:skip;}  \n---|---  \n  \nIf you clicked on the github link, you will see that this is a direct\ntranslation. But the point is that it\u2019s fairly straightforward code. Now we\njust have to run this with the magic number 3, three Procs and MaxNumLoops=3,\nand three hours later we have a trace that shows how you can hang even with\nthe mitigation patch. (full reproduce steps at the bottom of this blog post)\n\nOne reason why I didn\u2019t find this problem last time is that the trace is even\nmore complicated. The mitigation patch does help for smaller traces, with\nfewer threads or smaller numbers for MaxNumLoops. To hit the bug you need a\nvery specific long interleaving. This will be gibberish unless you have spent\nmany hours studying the glibc condition variable code:\n\n  1. Find the magic interleaving that makes you hit the \u201cpotential steal\u201d code path in pthread_cond_wait(), discussed last time\n  2. Run the pthread_cond_broadcast() from the mitigation patch while no other thread is waiting, so that it will early-out without doing anything\n  3. Then signal again and trigger a call to quiesce_and_switch_g1()\n  4. At the same time as step 3 have a thread wait, consuming the leftover signal from the \u201cpotential steal\u201d in step 1, then wait again\n  5. Now have step 3 finish with g_size=2 (because of the two waits) for the new g1, then signal after the switch, leaving g_size=1\n  6. Then have step 4 finish the second wait, consuming the signal from step 5\n\nYou\u2019re now left with g_size=1 for the new g1 even though nobody is waiting on\nit. The next call to pthread_cond_signal() just reduces g_size to 0 without\nwaking anyone. Any signal after that will work again.\n\nThis is still really complicated for me, so I\u2019m not sure exactly where the\nproblem is, but it is suspicious that the pthread_cond_broadcast() in my trace\nwould just early-out because nobody was waiting, so that the mitigation patch\ndoesn\u2019t result in any change to the state. If that can happen, TLA+ just had\nto find an interleaving where the lingering signal from the \u201cpotential steal\u201d\ncauses problems later.\n\nWhy didn\u2019t I find this last time? Because I stopped looking after I had found\nthe initial problem, and after the mitigation patch made the problem go away\nwith my trace. Turns out I needed to run an even bigger job to find the\nproblem with the mitigation patch.\n\nSo now the state of the glibc condition variable is\n\n  1. It mostly works except occasionally a thread can take too long to wake up, which will cause it to steal a signal from a later wakeup. (and then the later thread doesn\u2019t wake)\n  2. To fix that the code tries to detect whether we potentially stole a signal. But the response to that can leave the condition variable in a broken state, so that a later pthread_cond_signal() will signal on the wrong futex, causing sleepers to not be woken.\n  3. To fix that there is a mitigation patch which various distributions are running. But that mitigation patch has two issues:\n\n     * it doesn\u2019t work for the reasons that the author thinks it does (discussed last time)\n     * it sometimes doesn\u2019t do anything, which allows the broken state to cause problems later. (discovered in this blog post)\n\nBoth of these fixes makes the issue less likely to happen, but also make it\nharder to understand (and debug). What\u2019s the solution? I submitted a patch for\nthis already a year ago: Fix the start of the chain of errors by broadening\nthe scope of grefs, so that no waiter can ever be missed when we close a\ngroup. Then the \u201cpotential stealing\u201d code path becomes unnecessary, and the\nbug in that path goes away, and the mitigation patch becomes unnecessary. The\nimplementation also becomes simpler to reason about: My \u201cpatch\u201d is actually a\nseries of six patches in which the first one fixes the bug and the remaining\nfive just clean up code. (but a word of warning: this patch is unreviewed and\nI wouldn\u2019t be at all surprised if there is still a problem with it. This is\ntricky code. See comment by Ricardo below)\n\nIf anyone has specific steps I can take to get this into glibc, I will try to\ndo them. Last time I gave up a bit too easily because I got burned out on this\nproblem after having spent way too many hours debugging it. Actually getting\nthe fix in was too much extra work as a project to do in my spare time. But\nit\u2019s been two years, so my burnout on this particular problem is gone and I\u2019m\ngame. As long as there are steps that actually work to get this in.\n\n## Appendix: Detailed Steps to Reproduce\n\n  1. Download TLA+ https://github.com/tlaplus/tlaplus/releases/tag/v1.7.1#latest-tla-files\n  2. Run the toolbox\n  3. Click \u201cFile -> Open Spec -> Add New Spec\u201d then select ocaml_mutex.tla\n  4. Click \u201cTLC Model Checker -> New Model\u201d, click OK\n  5. In the model under\n\n     * What is the behavior spec: leave as default \u201cSpec\u201d\n     * What is the model?\n\n       * UseSpinlockForCVMutex <\\- TRUE\n       * AlwaysSetGrefs <\\- FALSE (this flag controls whether my patch should be used)\n       * Procs <\\- {P0, P1, P2}, also select \u201cSet of model values\u201d and \u201cSymmetry set\u201d\n       * UseSpinlockForMutex <\\- TRUE\n       * UsePatch <\\- TRUE (this flag controls whether the mitigation patch should be used)\n       * MaxNumLoops <\\- 3\n     * What to check?\n\n       * Check \u201cDeadlock\u201d (should be checked by default)\n       * Invariants: leave empty\n       * Properties: leave empty\n  6. Click \u201cTLC Model Checker -> Run Model\u201d\n  7. Watch the progress in the \u201cModel Checking Results\u201d column. Once per minute it should populate the table \u201cTime, Diameter, States Found, Distinct States, Queue Size.\u201d After ~2.5 hours, when \u201cDiameter\u201d reaches 342, a new panel should open up titled \u201cTLC Errors\u201d, and it should say \u201cDeadlock reached.\u201d in the first window.\n  8. Now you have 341 states to look at in the Error-Trace, in full detail. The \u201cpc\u201d variable shows you which line each process was on for every state. All other variables are also visible. They are a pretty direct translation from the C code. It should be possible to figure out by having the C code and TLA+ code side-by-side to see the minor differences. I uploaded a table with only the relevant information here. (this was from a run with slightly different source code, with the AlwaysSetGrefs commented out. This means your trace will be slightly different and the line numbers of the spreadsheet won\u2019t align if you try to add more information. You\u2019ll need to create your own by exporting the trace)\n\n(optional step before 6: Click on \u201cAdditional TLC Options\u201d and increase\n\u201cNumber of worker threads\u201d for your machine, also \u201cFraction of physical memory\nallocated to TLC\u201d and set \u201cProfiling\u201d to \u201cOff\u201d, this should speed up the\nchecking)\n\n### Share this:\n\n  * Twitter\n  * Facebook\n\nLike Loading...\n\n### Related\n\nUsing TLA+ in the Real World to Understand a Glibc BugOctober 31, 2020In\n\"Programming\"\n\nIntroducing the Asserting MutexFebruary 8, 2014In \"Programming\"\n\nAutomated Game AI TestingJanuary 15, 2022In \"Games\"\n\nPublished: September 17, 2022\n\nFiled Under: Programming\n\nTags: Condition variable : Glibc : TLA+\n\n### 3 Comments to \u201cFinding the \u201cSecond Bug\u201d in glibc\u2019s Condition Variable\u201d\n\n  1. Ricardo says:\n\nSeptember 18, 2022 at 07:32\n\nIn my private copy of NixOS/nixpkgs, I\u2019ve tried replacing glibc\u2019s condvar\nmitigation patch (which I\u2019ve been using for 18 months) with your patch (well,\nthe first one out of the 6, which you said contains the minimal amount of\nchanges to fix the bug) and I\u2019ve ran into a relatively consistent deadlock\nwhile building Poly/ML 5.9. Specifically, it freezes (for at least 2 hours)\nright after showing \u201c*****Writing object code******\u201d. This is on a machine\nwith 32 cores and lots of background compilation going on at the same time\n(i.e. with a very high load) and it happened at least 3 times already.\n\nIt could be a bug in Poly/ML or even an unrelated bug, but I suspect that\nglibc\u2019s conditional variable bug or a related one might not be completely\nfixed yet, even after applying your patch...\n\nReply\n\n     * Malte Skarupke says:\n\nSeptember 18, 2022 at 12:01\n\nThanks, I added a warning to the text. I wouldn\u2019t be surprised if there were\nissues with the patch. This is complicated code. I have only proved it\ncorrect, not tried it. (though it did pass all glibc tests)\n\nI would have expected bugs with one of the later patches in the series, not\nthe first... I\u2019ll re-review it, and also check if something needs to change\nabout it when it is applied against the new glibc version.\n\nReply\n\n     * Malte Skarupke says:\n\nSeptember 21, 2022 at 07:04\n\nAn update since I expect progress to be slow: I found a bug in the first patch\nin the series. It\u2019s fixed by the third patch in the series... I will try to\nredo the patches, double-checking that each one works individually, and also\nre-apply them to the latest version of glibc. (the first four patches still\nwork, but patch 5 doesn\u2019t work against latest)\n\nAt my current speed, it will take me somewhere between a day and two weeks to\ndo that.\n\nReply\n\n### Leave a comment Cancel reply\n\nThis site uses Akismet to reduce spam. Learn how your comment data is\nprocessed.\n\n\u00ab Previous Post\n\nNext Post \u00bb\n\n#### Recent Posts\n\n  * How I use LLMs to program\n  * Transform Matrices are Great and You Should Understand Them\n  * Two Kids Put Me on a Two Sleep Schedule\n  * Beautiful Branchless Binary Search\n  * Fine-grained Locking with Two-Bit Mutexes\n\n#### Archives\n\n  * April 2024\n  * October 2023\n  * September 2023\n  * April 2023\n  * December 2022\n  * September 2022\n  * June 2022\n  * February 2022\n  * January 2022\n  * October 2021\n  * July 2021\n  * April 2021\n  * January 2021\n  * November 2020\n  * October 2020\n  * August 2020\n  * July 2020\n  * June 2020\n  * May 2020\n  * April 2020\n  * March 2020\n  * January 2020\n  * December 2019\n  * September 2019\n  * August 2019\n  * June 2019\n  * April 2019\n  * March 2019\n  * June 2018\n  * May 2018\n  * April 2018\n  * January 2018\n  * December 2017\n  * November 2017\n  * October 2017\n  * September 2017\n  * August 2017\n  * February 2017\n  * January 2017\n  * December 2016\n  * November 2016\n  * June 2016\n  * April 2016\n  * March 2016\n  * February 2016\n  * December 2015\n  * September 2015\n  * July 2015\n  * June 2015\n  * May 2015\n  * February 2015\n  * January 2015\n  * December 2014\n  * November 2014\n  * October 2014\n  * September 2014\n  * August 2014\n  * June 2014\n  * May 2014\n  * April 2014\n  * March 2014\n  * February 2014\n  * January 2014\n  * October 2013\n  * September 2013\n  * August 2013\n  * May 2013\n  * February 2013\n  * January 2013\n  * December 2012\n  * November 2012\n  * October 2012\n  * August 2012\n  * July 2012\n  * April 2012\n  * March 2012\n  * February 2012\n  * January 2012\n  * October 2011\n  * September 2011\n  * August 2011\n  * July 2011\n  * June 2011\n  * May 2011\n\n#### Categories\n\n  * Children\n  * Games\n  * Links\n  * Math\n  * Politics and Economics\n  * Programming\n  * Uncategorized\n\n#### Meta\n\n  * Register\n  * Log in\n  * Entries feed\n  * Comments feed\n  * WordPress.com\n\nBlog at WordPress.com.\n\n  * Comment\n  * Reblog\n  * Subscribe Subscribed\n\n    * Probably Dance\n    * Already have a WordPress.com account? Log in now.\n\n  * Privacy\n  *     * Probably Dance\n    * Customize\n    * Subscribe Subscribed\n    * Sign up\n    * Log in\n    * Copy shortlink\n    * Report this content\n    * View post in Reader\n    * Manage subscriptions\n    * Collapse this bar\n\n%d\n\n", "frontpage": false}
