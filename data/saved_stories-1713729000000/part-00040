{"aid": "40104420", "title": "Type information for faster Python C extensions", "url": "https://bernsteinbear.com/blog/typed-c-extensions/", "domain": "bernsteinbear.com", "votes": 2, "user": "thunderbong", "posted_at": "2024-04-21 09:56:27", "comments": 0, "source_title": "Type information for faster Python C extensions", "source_text": "Type information for faster Python C extensions | Max Bernstein\n\nhome blog lisp favorites pl resources bread recipes rss\n\n# Type information for faster Python C extensions\n\nJanuary 13, 2024\n\nPyPy is an alternative implementation of the Python language. PyPy\u2019s C API\ncompatibility layer has some performance issues. Carl Friedrich Bolz-Tereick\nand I are working on a way to make PyPy\u2019s C API interactions much faster. It\u2019s\nlooking very promising. Here\u2019s a sketch of how it works.\n\n## The C API as lingua franca\n\nPython is pretty widely-used. For years, CPython was the only implementation,\nand CPython was not designed to be fast. The Python community needed some\nprograms to go faster and determined that the best path forward was to write\nsome modules in C and interact with them from Python. Worked just fine.\n\nThen other Python runtimes like PyPy came along. PyPy includes a JIT compiler\nand its execution of normal Python code is very fast, at least until it hits a\ncall from Python to a C extension function. Then things go a little bit\nsideways. First and foremost because the PyPy JIT can\u2019t \u201csee into\u201d the native\ncode; it\u2019s generated outside of the JIT by some other compiler and is\ntherefore opaque. And second of all because the binding API for the\naforementioned C modules (\u201cThe C API\u201d) requires a totally different object and\nmemory representation than PyPy has internally.\n\nPyPy has its own object model, runtime, and moving garbage collector, all to\nget better performance. Unfortunately, this means that whenever you call a C\nAPI function from PyPy, it has to stop what it\u2019s doing, set up some C API\nscaffolding, do the C API call, and then take down the scaffolding.\n\nFor example, the C API is centered around PyObject pointers. PyPy does not use\nPyObjects in the normal execution of Python code. When it interacts with C API\ncode, it has to allocate a PyObject, make it point into the PyPy heap, call\nthe C API function, and then (potentially) free the PyObject. (This ignores\nGIL stuff and exception checking, which is also an issue.)\n\nFig. 1 - C extensions deal in PyObject* so any runtime that wants to interface\nwith them has to also deal in PyObject*.\n\nThat\u2019s a lot of overhead. (And there\u2019s more, too. See Antonio Cuni\u2019s excellent\nblog post.) And it\u2019s a hard problem that has bitten multiple alternative\nPython runtimes^1.\n\nIn addition to the overhead of boxing into a PyObject, the underlying C\nfunction that the C extension calls may not even need the PyObject to exist in\nthe first place. For example, a lot of C API functions are structured like\nthis:\n\n    \n    \n    long inc_impl(long num) { return num + 1; } PyObject* inc(PyObject* obj) { long num = PyLong_AsLong(obj); if (num < 0 && PyErr_Occurred()) { return NULL; } long result = inc_impl(num); return PyLong_FromLong(result); }\n\nIn this example, the PyObject* code inc is only a wrapper around another\nfunction inc_impl that works directly on C integers.\n\nFig. 2 - The runtimes still have to manufacture PyObject* even if the\nunderlying C code doesn\u2019t know anything about Python. The unboxing is an\nanother source of overhead, unfortunately.\n\nAll of the bits in the middle between the JIT and the C implementation (the\nentire inc function, really) are \u201cwasted work\u201d because the work is not needed\nfor the actual execution of the user\u2019s program.\n\nSo even if the PyPy JIT is doing great work and has eliminated memory\nallocation in Python code\u2014PyPy could have unboxed some heap allocated Python\ninteger object into a C long, for example\u2014it still has to heap allocate a\nPyObject for the C API... only to throw it away soon after.\n\nIf there was a way to communicate to PyPy that inc expects a long and is going\nto unbox it into a C long (and will also return a C long), it wouldn\u2019t need to\ndo any of these shenanigans.\n\nAnd yes, ideally there wouldn\u2019t be a C API call at all. But sometimes you have\nto (perhaps because you have no control over the code), and you might as well\nspeed up that call. Let\u2019s see if it can be done.\n\n## Potsdam\n\nThis is where I come into this. I was at the ECOOP conference in 2022 where\nCarl Friedrich introduced me to some other implementors of alternative Python\nruntimes. I got to talk to the authors of PyPy and ZipPy and GraalPython over\nsome coffee and beer. They\u2019re really nice.\n\nThey\u2019ve been collectively working on a project called HPy. HPy is a new design\nfor a C API Python that takes alternative runtimes into account. As part of\nthis design, they were investigating a way to pipe type information from C\nextension modules through the C API and into a place where the host runtime\ncan read it.\n\nIt\u2019s a tricky problem because not only is there a C API, but also a C ABI\n(note the \u201cB\u201d for \u201cbinary\u201d). While an API is an abstract contract between\ncaller and callee for how to call a function, an ABI is more concrete. In the\ncase of the C ABI, it means not changing struct layouts or sizes, adding\nfunction parameters, things like that. This is kind of a tight constraint and\nit wasn\u2019t clear what the best backward-compatible way to add type information\nwas.\n\nSometime either in this meeting or shortly after, I had an idea for how to do\nit without changing the API or ABI and I decided to take a stab at\nimplementing it for Cinder (the Python runtime I was working on at the time).\n\n## The solution: sketchy C things?\n\nIn order to better understand the problems, let\u2019s take a look at the kind of\ntype information we want to add. This is the kind of type metadata we want to\nadd to each typed method, represented as a C struct.\n\n    \n    \n    struct PyPyTypedMethodMetadata { int arg_type; int ret_type; void* underlying_func; }; typedef struct PyPyTypedMethodMetadata PyPyTypedMethodMetadata;\n\nIn this artificially limited example, we store the type information for one\nargument (but more could be added in the future), the type information for the\nreturn value, and the underlying (non-PyObject*) C function pointer.\n\nBut it\u2019s not clear where to put that in a PyMethodDef. The existing\nPyMethodDef struct looks like this. It contains a little bit of metadata and a\nC function pointer (the PyObject* one). In an ideal world, we would \u201cjust\u201d add\nthe type metadata to this struct and be done with it. But we can\u2019t change its\nsize for ABI reasons.\n\n    \n    \n    struct PyMethodDef { const char *ml_name; /* The name of the built-in function/method */ PyCFunction ml_meth; /* The C function that implements it */ int ml_flags; /* Combination of METH_xxx flags, which mostly describe the args expected by the C func */ const char *ml_doc; /* The __doc__ attribute, or NULL */ }; typedef struct PyMethodDef PyMethodDef;\n\nWhat to do? Well, I decided to get a little weird with it and see if we could\nsneak in a pointer to the metadata somehow. My original idea was to put the\nentire PyPyTypedMethodMetadata struct behind the PyMethodDef struct (kind of\nlike how malloc works), but that wouldn\u2019t work so well: PyMethodDefs are\ncommonly statically allocated in arrays, and we can\u2019t change the layout of\nthose arrays.\n\nBut what we can do is point the ml_name field to a buffer inside another\nstruct^2.\n\nThen, when we notice that a method is marked as typed (with a new METH_TYPED\nflag we can add to the ml_flags bitset), we can read backwards to find the\nPyPyTypedMethodMetadata struct. Here\u2019s how you might do that in C:\n\n    \n    \n    struct PyPyTypedMethodMetadata { int arg_type; int ret_type; void* underlying_func; const char ml_name[100]; // New field! }; typedef struct PyPyTypedMethodMetadata PyPyTypedMethodMetadata; PyPyTypedMethodMetadata* GetTypedSignature(PyMethodDef* def) { assert(def->ml_flags & METH_TYPED); // A new type of flag! return (PyPyTypedMethodMetadata*)(def->ml_name - offsetof(PyPyTypedMethodMetadata, ml_name)); }\n\nAnd here\u2019s a diagram to illustrate this because it\u2019s really weird and\nconfusing.\n\nI started off with a mock implementation of this in C (no Python C API, just\nfake structures to sketch it out) and it worked. So I implemented a hacky\nversion of it in Cinder, but never shipped it because my integration with\nCinder was a little too hacky. I wrote up the ideas for posterity in case\nsomeone wanted to take up the project.\n\nA year later, nobody else had, so I decided to poke Carl Friedrich and see if\nwe could implement it in PyPy. We\u2019ll see how that implementation looks in a\nminute. But first, an aside on where C extensions come from.\n\n## Where do all the C extensions come from?\n\nWell, in PyPy, there are none in the standard library. PyPy has been almost\nentirely written in Python so that the code is visible to the JIT. But people\nlike using Python packages, and some Python packages contain C extensions.\n\nThere are a couple of different ways to write a C extension. The \u201csimplest\u201d\n(as in, all the components are visible and there is no magic and there are no\nexternal dependencies) is to hand-write it. If you don\u2019t want to do that, you\ncan also use a binding generator to write the glue code for you. I have the\nmost experience with Cython, but other binding generators like nanobind,\npybind11, and even CPython\u2019s own Argument Clinic exist too!\n\n### Hand-written\n\nLet\u2019s recall the inc/inc_impl function from earlier. That\u2019s a reasonable\nexample of a function that could be integrated as a hand-written C extension\nto Python. In order to make it callable from Python, we have to make a full C\nextension module. In this case, that\u2019s just a list of function pointers and\nhow to call them.\n\n    \n    \n    #include <Python.h> long inc_impl(long arg) { return arg+1; } PyObject* inc(PyObject* module, PyObject* obj) { (void)module; long obj_int = PyLong_AsLong(obj); if (obj_int == -1 && PyErr_Occurred()) { return NULL; } long result = inc_impl(obj_int); return PyLong_FromLong(result); } static PyMethodDef mytypedmod_methods[] = { {\"inc\", inc, METH_O, \"Add one to an int\"}, {NULL, NULL, 0, NULL}}; static struct PyModuleDef mytypedmod_definition = { PyModuleDef_HEAD_INIT, \"mytypedmod\", \"A C extension module with type information exposed.\", -1, mytypedmod_methods, NULL, NULL, NULL, NULL}; PyMODINIT_FUNC PyInit_mytypedmod(void) { PyObject* m = PyState_FindModule(&mytypedmod_definition); if (m != NULL) { Py_INCREF(m); return m; } return PyModule_Create(&mytypedmod_definition); }\n\nWe have an array of PyMethodDef structs, one for each method we want to wrap.\nThen we have a PyModuleDef to define the module, which can also contain\nattributes and some other stuff. Then we provide a sort of __new__ function\nfor the module, in the form of a PyInit_ function. This is found by dlopen in\nthe C extension loader built into Python.\n\nIt\u2019s possible to manually augment this module by adding a\nPyPyTypedMethodMetadata struct and a METH_TYPED flag. It\u2019s a little\ncumbersome, but if it speeds up interactions with the module... well,\nextension authors might be cajoled into adding the type information or at\nleast accepting a pull request.\n\nBut not all extensions are hand-written. Many are generated by binding\ngenerators like Cython. And Cython is interesting because it can generate the\ntype signatures automatically...\n\n### Cython\n\nUnlike many other binding generators for Python, Cython provides a fully-\nfeatured Python-like programming language that compiles to C. The types obey\ndifferent rules than in normal Python code and can be used for optimization.\nCython also has primitive types. Let\u2019s see an example.\n\nIn this snippet of Cython code, we make a function that adds two machine\nintegers and returns a machine integer.\n\n    \n    \n    cpdef int add(int a, int b): return a + b\n\nCython will generate a very fast C function that adds two machine integers.\nCalls to this from Cython are type checked at compile time and will be as fast\nas your C compiler allows:\n\n    \n    \n    static int add(int __pyx_v_a, int __pyx_v_b) { return __pyx_v_a + __pyx_v_b; }\n\nSince we used cpdef instead of cdef, Cython will also generate a wrapper C\nextension function so that this function can be called from Python.\n\nThis means that the generated Cython wrapper code looks like (a much uglier\nversion of) below. You don\u2019t need to understand or really even read the big\nblob of cleaned-up and annotated generated code below. You just need to say\n\u201cooh\u201d and \u201caah\u201d and \u201cwow, so many if-statements and so much allocation and so\nmany function calls.\u201d\n\nAnd it\u2019s also a little worse than the METH_O example above since it has to\nunwrap an array of fastcall args and do some argument processing.\n\n    \n    \n    static PyObject *add_and_box(CYTHON_UNUSED PyObject *__pyx_self, int __pyx_v_a, int __pyx_v_b) { int result = add(__pyx_v_a, __pyx_v_b, 0); // Check if an error occurred (unnecessary in this case) if (result == ((int)-1) && PyErr_Occurred()) { return NULL; } // Wrap result in PyObject* return PyLong_FromLong(result); } static PyObject *add_python(PyObject *__pyx_self, PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds) { // Check how many arguments were given PyObject* values[2] = {0,0}; if (__pyx_nargs == 2) { values[1] = __pyx_args[1]; values[0] = __pyx_args[0]; } else if (__pyx_nargs == 1) { values[0] = __pyx_args[0]; } // Check if any keyword arguments were given Py_ssize_t kw_args = __Pyx_NumKwargs_FASTCALL(__pyx_kwds); // Match up mix of position/keyword args to parameters if (__pyx_nargs == 0) { // ... } else if (__pyx_nargs == 1) { // ... } else if (__pyx_nargs == 2) { // ... } else { // ... } // Unwrap PyObject* args into C int int __pyx_v_a = PyLong_AsLong(values[0]); // Check for error (unnecessary if we know it's an int) if ((__pyx_v_a == (int)-1) && PyErr_Occurred()) { return NULL; } int __pyx_v_b = PyLong_AsLong(values[1]); // Check for error (unnecessary if we know it's an int) if ((__pyx_v_b == (int)-1) && PyErr_Occurred()) { return NULL; } // Call generated C implementation of add return add_and_box(__pyx_self, __pyx_v_a, __pyx_v_b); }\n\nNow, to be clear: this is probably the fastest thing possible for interfacing\nwith CPython. Cython has been worked on for years and years and it\u2019s very\nfast. But CPython isn\u2019t the only runtime in town and the other runtimes have\ndifferent performance characteristics, as we explored above.\n\nSince so many C extension are generated with Cython, there\u2019s a big\nopportunity: if we manage to get the Cython compiler to emit typed metadata\nfor the functions it compiles, those functions could become much faster under\nruntimes such as PyPy.\n\nIn order to justify such a code change, we have to see how much faster the\ntyped metadata makes things. So let\u2019s benchmark.\n\n## A small, useless benchmark\n\nLet\u2019s try benchmarking the interpreter interaction with the native module with\na silly benchmark. It\u2019s a little silly because it\u2019s not super common (in use\ncases I am familiar with anyway) to call C code in a hot loop like this\nwithout writing the loop in C as well. But it\u2019ll be a good reference for the\nmaximum amount of performance we can win back.\n\n    \n    \n    # bench.py import mytypedmod def main(): i = 0 while i < 10_000_000: i = mytypedmod.inc(i) return i if __name__ == \"__main__\": print(main())\n\nWe\u2019ll try running it with CPython first because CPython doesn\u2019t have this\nproblem making PyObjects\u2014that is just the default object representation in the\nruntime.\n\n    \n    \n    $ python3.10 setup.py build $ time python3.10 bench.py 10000000 846.6ms $\n\nOkay so the text output is a little fudged since I actually measured this with\nhyperfine, but you get the idea. CPython takes a very respectable 850ms to go\nback and forth with C 10 million times.\n\nNow let\u2019s see how PyPy does on time, since it\u2019s doing a lot more work at the\nboundary.\n\n    \n    \n    $ pypy3.10 setup.py build $ time pypy3.10 bench.py 10000000 2.269s $\n\nYeah, okay, so all that extra unnecessary work that PyPy does (before our\nchanges) ends up really adding up. Our benchmark of inc takes three times as\nlong as CPython. Oof. But this post is all about adding types. What if we add\ntypes to the C module and measure with our changes to PyPy?\n\nHere are the changes to the C module:\n\n    \n    \n    diff --git a/tmp/cext.c b/tmp/cext-typed.c index 8f5b31f..52678cb 100644 --- a/tmp/cext.c +++ b/tmp/cext-typed.c @@ -14,8 +14,15 @@ PyObject* inc(PyObject* module, PyObject* obj) { return PyLong_FromLong(result); } +PyPyTypedMethodMetadata inc_sig = { + .arg_type = T_C_LONG, + .ret_type = T_C_LONG, + .underlying_func = inc_impl, + .ml_name = \"inc\", +}; + static PyMethodDef mytypedmod_methods[] = { - {\"inc\", inc, METH_O, \"Add one to an int\"}, + {inc_sig.ml_name, inc, METH_O | METH_TYPED, \"Add one to an int\"}, {NULL, NULL, 0, NULL}}; static struct PyModuleDef mytypedmod_definition = {\n\nAnd now let\u2019s run it with our new patched PyPy:\n\n    \n    \n    $ pypy3.10-patched setup.py build $ time pypy3.10-patched bench.py 10000000 168.1ms $\n\n168ms! To refresh your memory, that\u2019s 5x faster than CPython and 13x faster\nthan baseline PyPy. I honestly did not believe my eyes when I saw this number.\nAnd Carl Friedrich and I think there is still room for more improvements like\ndoing the signature/metadata finding inside the JIT instead of calling that C\nfunction.\n\nThis is extraordinarily promising.\n\nBut as I said before, most applications don\u2019t consist of a Python program\ncalling a C function and only a C function in a tight loop. It would be\nimportant to profile how this change affects a representative workload. That\nwould help motivate the inclusion of these type signatures in a binding\ngenerator such as Cython.\n\nIn the meantime, let\u2019s take a look at how the changes look in the PyPy\ncodebase.\n\n## Implementing in PyPy: PyPy internals\n\nPyPy is comprised of two main parts:\n\n  * A Python interpreter\n  * A tool to transform interpreters into JIT compilers\n\nThis means that instead of writing fancy JIT compiler changes to get this to\nwork, we wrote an interpreter change. Their cpyext (C API) handling code\nalready contains a little \u201cinterpreter\u201d of sorts to make calls to C\nextensions. It looks at ml_flags to distinguish between METH_O and\nMETH_FASTCALL, for example.\n\nSo we added a new case that looks like this pseudocode:\n\n    \n    \n    diff --git a/tmp/interp.py b/tmp/typed-interp.py index 900fa9c..b973f13 100644 --- a/tmp/interp.py +++ b/tmp/typed-interp.py @@ -1,7 +1,17 @@ def make_c_call(meth, args): if meth.ml_flags & METH_O: assert len(args) == 1 + if meth.ml_flags & METH_TYPED: + return handle_meth_typed(meth, args[0]) return handle_meth_o(meth, args[0]) if meth.ml_flags & METH_FASTCALL: return handle_meth_fastcall(meth, args) # ... + +def handle_meth_typed(meth, arg): + sig = call_scary_c_function_to_find_sig(meth) + if isinstance(arg, int) and sig.arg_type == int and sig.ret_type == int: + unboxed_arg = convert_to_unboxed(arg) + unboxed_result = call_f_func(sig.underlying_func, unboxed_arg) + return convert_to_boxed(unboxed_result) + # ...\n\nSince the JIT probably already knows about the types of the arguments to the C\nextension function (and probably has also unboxed them), all of the\nintermediate checks and allocation can be elided. This makes for much less\nwork!\n\nTo check out the actual changes to PyPy, look at this stack of commits.\n\n## Next steps\n\nThis project isn\u2019t merged or finished. While we have a nice little test suite\nand a microbenchmark, ideally we would do some more:\n\n  * Get other native types (other int types, double) working\n  * Get multiple parameters working (fastcall)\n  * Hack a proof of concept of this idea into Cython\n  * Make the signature more expressive\n\n    * Perhaps we should have a mini language kind of like CPython\u2019s Argument Clinic\n  * Integrate this into other runtimes such as GraalPython or even CPython\n\n    * While this won\u2019t help CPython just yet, they might find it useful when they do some more optimizations in the JIT\n\nLet us know if you have any ideas!\n\n## Updates and other ideas\n\nlifthrasiir on Hacker News points out that this struct should be versioned for\nfuture-proofing. They also suggest potentially avoiding METH_TYPED by shipping\na sort of sibling symbol _PyPyTyped_foo for each foo. That\u2019s interesting.\n\nWenzel Jakob (of pybind11 and nanobind fame) wrote in that we should not\nignore overloads (apparently fairly common in the wild) in our implementation.\nApparently people like to make, for example, myextension.abs(x) where the call\nto abs_float or abs_int is dispatched in the binding glue (a real example that\nI found in a search on GitHub is available here). A JIT like PyPy could make\nthe dynamic dispatch go away.\n\nAnother idea, from Carl Friedrich, a little more difficult: what if the Cython\ncompiler could generate Python code or bytecode? Or, what if PyPy could ingest\nCython code?\n\n  1. This C API problem has bitten pretty much every alternative runtime to CPython. They all try changing something about the object model for performance and then they all inevitably hit the problem of pervasive C API modules in the wild. This is part of what hurt the Skybison project. \u21a9\n\n  2. I later learned that this is common in the Linux kernel. \u21a9\n\nThis blog is open source. See an error? Go ahead and propose a change.\n\n", "frontpage": false}
