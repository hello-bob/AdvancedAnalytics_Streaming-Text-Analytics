{"aid": "40165188", "title": "LAP: Lua Async Protocol", "url": "https://github.com/civboot/civlua/tree/main/lib/lap", "domain": "github.com/civboot", "votes": 1, "user": "vitiral", "posted_at": "2024-04-26 02:03:49", "comments": 0, "source_title": "civlua/lib/lap at main \u00b7 civboot/civlua", "source_text": "civlua/lib/lap at main \u00b7 civboot/civlua \u00b7 GitHub\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\ncivboot / civlua Public\n\n  * Notifications\n  * Fork 0\n  * Star 19\n\n/\n\n# lap\n\n/\n\n## Directory actions\n\n## More options\n\n## Directory actions\n\n## More options\n\n## Latest commit\n\nvitiral\n\n[ds] add keyPath and tryPath. Also small fd/lap changes\n\nApr 25, 2024\n\nba53aea \u00b7 Apr 25, 2024Apr 25, 2024\n\n## History\n\nHistory\n\n/\n\n# lap\n\n/\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n### parent directory\n\n..  \n  \n### PKG.lua\n\n|\n\n### PKG.lua\n\n| lap initial documentation and commits| Apr 24, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| update fd for upload| Apr 24, 2024  \n  \n### lap-0.1-0.rockspec\n\n|\n\n### lap-0.1-0.rockspec\n\n| pkgrock: lap-0.1-0| Apr 24, 2024  \n  \n### lap.lua\n\n|\n\n### lap.lua\n\n| [ds] add keyPath and tryPath. Also small fd/lap changes| Apr 25, 2024  \n  \n### test.lua\n\n|\n\n### test.lua\n\n| lap initial documentation and commits| Apr 24, 2024  \n  \n## README.md\n\n# LAP: Lua Asynchronous Protocol\n\nLua has one of the coolest yet most underutilized asynchronous programming\ntools: the coroutine module, specifically coroutine.yield. Lua's yield can be\ncalled from any depth, resuming execution at the callsite upon\ncoroutine.resume. This means that if we swap out traditionally blocking APIs\nlike file:read with ones that are non-blocking and yielding (i.e. by running\nIO in a separate thread or using unix's aio interface) we use most libraries\nasynchronously without changing a single line of code.\n\nFor an example of implementing the LAP protocol see fd\n\nLAP is a lightweight zero-dependency asynchronous protocol which aims to take\nadvantage of this. It is architected to allow libraries to provide a\nlightweight \"asynchronous mode\" so that they can be used asynchronously by a\ncoroutine executor. This allows users and library authors to write code that\nlooks synchronous but which can be executed asynchronously at the application\nauthor's discression.\n\nThis folder also contains the lap.lua library, see the Library section.\nLibrary authord do not need to depend on this library to work with the LAP\nprotocol.\n\nThe LAP protocol has two components:\n\n  * yielding protocol: An ultra simple yet optionally-performant to communicate with the executor loop (example: see lap.Lap)\n  * two global tables which libraries can use to schedule coroutines (LAP_READY) and register their asynchronous API (LAP_FNS_ASYNC and LAP_FNS_SYNC)\n\nLibrary authors can fully support the protocol by following the Yielding\nProtocol below and copy/pasting the following:\n\n    \n    \n    LAP_FNS_SYNC = LAP_FNS_SYNC or {} LAP_FNS_ASYNC = LAP_FNS_ASYNC or {} // register functions to switch modes, see end of lap.lua for example table.insert(LAP_FNS_SYNC, function() ... end) table.insert(LAP_FNS_ASYNC, function() ... end) // implement your asynchronous functions by following the protocol.\n\nLibrary authors should make their default API synchronous (blocking) by\ndefault, except for items that cannot be used synchronously.\n\n## LAP_READY Global Table\n\nLAP_READY is a global key/value table where the keys are the coroutines which\nshould be run at some later time (by the executor). The values are arbitrary\n(typically a string identifier for debugging).\n\nThis means that a coroutine can schedule another coroutine cor by simply doing\nLAP_READY[cor] = \"my_identifier\". This simple feature can be used for many\npurposes such as creating Channel datastructures as well as handling any/all\nbehavior. See the Library section for details.\n\n## Yielding Protocol\n\nLAP's yielding protocol makes it trivial for Lua libraries to interface with\nexecutors. Libraries can simply call coroutine.yield with one of the following\nand a compliant executor will perform the behavior specified if it is\nsupported (else it will run the coroutine on the next loop).\n\n  * yield(nil) or yield(false): forget the coroutine, the executor will not run it.\n\n  * yield(true): run the corroutine again as soon as possible.\n\n    * Should prevent the executor loop from sleeping.\n    * Equivalent to: LAP_READY[coroutine.running()] = true; coroutine.yield()\n  * yield(\"sleep\", sleepSec): run the coroutine again after sleepSec seconds (a float).\n\n  * yield(\"poll\", fileno, events): tell the coroutine to use unix's poll(fileno, events) syscall to determine when ready.\n\n  * Other yield values may be defined by application-specific executors. If the executor doesn't recognize a value it can either throw an error or treat it as true (aka \"ready\"), depending on the application requirements.\n\n## Global Variables\n\nThere are four global variables:\n\n  * LAP_READY: contains the currently ready coroutines for the executor loop to resume.\n  * LAP_FNS_SYNC / LAP_FNS_ASYNC: contains functions to switch lua to synchronous / asynchronous modes, respectively.\n  * LAP_ASYNC: is set to true when in async mode to determine behavior at runtime.\n\nThe sync/async tables allows a user to write code in a blocking style yet it\ncan be run asynchronously, such as the following. You can even switch back and\nforth so that tests can be run in both modes.\n\n    \n    \n    function getLines(path, fn) local lines = {} for line in io.lines(path) do table.insert(lines, line) end return lines end\n\n> Recomendation: use lap.async() and lap.sync() to switch modes.\n\n## lap Library\n\nThe (pure lua) [lap.lua](./lap.lua) lap library implements:\n\n  * lap.Lap(...) default implementation of a single loop (aka \"lap\") in an executor.\n\n  * lap.Any and lap.all for interacting with lists of coroutines.\n\n  * lap.channel() which creates the Recv and Send channel types to send values between coroutines.\n\n  * lap.async() / lap.sync(): switches all registered libraries to async/sync mode (just calls every function in LAP_FNS_(SYNC/ASYNC))\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
{"aid": "40165200", "title": "Drink Me: (Ab)Using a LLM to Compress Text", "url": "https://o565.com/llm-text-compression/", "domain": "o565.com", "votes": 1, "user": "batch12", "posted_at": "2024-04-26 02:04:48", "comments": 0, "source_title": "DRINK ME: (Ab)Using a LLM to compress text", "source_text": "DRINK ME: (Ab)Using a LLM to compress text\n\no565\n\nSign in Subscribe\n\nFeatured\n\n# DRINK ME: (Ab)Using a LLM to compress text\n\n#### J\n\nApr 26, 2024 \u2022 7 min read\n\n### Introduction\n\nLarge language models are trained on huge datasets of text to learn the\nrelationships and contexts of words within larger documents. These\nrelationships are what allows the model to generate text.\n\nRecently I've read concerns about LLMs being trained on copyrighted text and\nreproducing it. This got me thinking: Can training text be extracted from an\nLLM? The answer, of course, is yes, and this isn't a new (or open) question.\nThis led me to wonder what it would take to extract entire books- or have an\nLLM reproduce text it's never directly been trained on. I figured that, for\nthe most part, many texts contain sections that would naturally align with the\nlanguage relationships the model has learned. If that's the case, then perhaps\nI could use the model to infer those relationships and correct its course\nwhenever it deviates.\n\nSo that's how I got here.\n\nTo see if this would work, I decided to use technology that I am familiar\nwith. I'll use llama.cpp via its python bindings.\n\n### How it Works...\n\nThe solution I put together has the following key functions:\n\nload_document(filename):\n\n  * This reads a text file and tokenizes it using the model's tokenizer. If the text is too long for the model's context window, it is split into smaller parts that fit within this window. This prevents token overflow.\n\ngenerate_text(prompt, max_tokens=1):\n\n  * This generates text, n tokens at a time, with 0.0 as the temperature and a static seed. It essentially continues the text from where the input text stopped.\n\ncompress_text(source_text):\n\n  * This function attempts to compress the input text by generating parts of it using the LLM. If the generated text matches the start of the source text, it continues\u2013 otherwise, it adds the character directly to the compressed string.\n  * To record the generated text, the function notes how many tokens were generated and places that number between a delimiter.\n\ndecompress_text(compressed_text):\n\n  * Decompresses text compressed by the compress_text function. It splits the text using the delimiter and reconstructs the original text by generating missing parts or directly appending the text.\n\n### Testing\n\nI used two texts for test. For the first, I decided to use the first chapter\nof \"Alice's Adventures in Wonderland\" as I assumed it would be in the model's\ntraining data. As I expected, I got very good compression.\n\n#### Compression\n\nHere's the meat of the compression function:\n\n##### Code\n\n    \n    \n    \"\"\"Compress text by generating and comparing segments to the source text.\"\"\" generated_text = \"\" compressed_string = \"\" gen_count = 0 i = 0 # let's loop until we have generated the entire source text while generated_text != source_text: # get a new token part = generate_text(generated_text) # if our generated text aligns with the source text then tally it if source_text.startswith(str(generated_text + part)) and len(part) > 0: gen_count += 1 generated_text += part i = len(generated_text) if debug: print(BLUE + part + RESET, end=\"\", flush=True) # if not, then grab a letter from the source document # hopefully we'll be back on track during the next loop else: i += 1 if gen_count > 0: compressed_string += f\"{re.escape(DELIMITER)}{gen_count}{re.escape(DELIMITER)}\" gen_count = 0 generated_text += source_text[i - 1] compressed_string += source_text[i - 1] if debug: print(source_text[i - 1], end=\"\", flush=True)\n\n##### Results\n\nHere's the model processing the script. The text in blue matches text\ngenerated by the LLM and white is from the source text. Yes, it's slow.\n\n#### The \"Compressed\" content:\n\nHere's what the output looks like. Yes, it's in JSON format and yes it's ugly,\nbut this is just a proof of concept, right? For the sake of clarity in this\npost, I picked an easy-to-read delimiter: @\n\nThis is the complete \"compressed\" text of Chapter 1.\n\n    \n    \n    [\"\\ufeffCH@2@I.@1@Down@7@\\n\\n@15@\\n@18@\\n@13@\\n@6@ \\u201c@17@s@2@\\n@79@ _@13@ _@72@ a\\n@10@_,@106@ how@100@as@51@cup@24@ down@26@\\u201d,@4@\\n@17@\\n@3@ underneath@11@cup@62@ fell@9@Which@23@?@4@\\n@19@\\n@35@ lear@2@se@12@room@2@\\n@5@ _@25@ go@1@d\\np@20@\\n@19@ no@13@ thought@2@ nice@22@ _@2@\\n@16@ walk@5@ward@12@she@3@gl@11@,@9@the@1@ word@7@ to@27@\\n(and@21@\\n@120@ Din@59@ here@5@ get@15@ream@19@\\n@82@ tell@111@ the wind@21@ e@55@ a@50@ walked@11@\\n@43@first@35@\\n@104@\\n@43@,@31@ would@7@ should@21@,@6@ h@43@\\n@17@\\n@17@\\n@17@\\n@8@,@11@,@21@,\\u201d@2@ on@2@ large@23@ was@5@ _@1@_@21@ it@4@_@12@\\nse@2@ nice@1@ hist@8@,@2@e@6@ and@9@_@34@\\n@1@ th@1@t@5@ _@45@soon@11@ _@63@hot@3@,@10@* @3@ @3@ @1@ @3@ *@10@\\n@1@*@10@ @27@\\n@20@right@5@ that@14@ that@9@wait@35@\\n@36@fl@4@ is@36@ going@11@ for@3@ when@37@\\n@13@ and@6@ cl@34@sat@7@Come@16@\\nr@2@;@16@ very@2@,@24@\\n@49@But@69@ very@3@ on@17@Well@14@ if@23@ can cre@11@\\n@37@,@39@ generally@13@ much@28@ life\"]\n\n###### 11,994 to 986 Characters\n\nWow, that's a pretty big reduction. The compressed text is only about 8% of\nthe original size.\n\nFor fun, I compressed the whole file. This method reduced the number of\ncharacters from 174,355 to 25,360 - the compressed text being 15% of the\noriginal.\n\n#### Decompression\n\nCompression is pointless if I can't reverse it. Let's look at the decompress\nfunction:\n\n##### Code\n\n    \n    \n    decompressed_text = \"\" # split the parts into sections, text and generation counts parts = re.split(rf'({re.escape(DELIMITER)}\\d+{re.escape(DELIMITER)})', compressed_text) for part in parts: # if we're looking at a generation count, then generate text if re.match(rf'{re.escape(DELIMITER)}\\d+{re.escape(DELIMITER)}', part): number = int(part[1:-1]) for count in range(number): part = generate_text(decompressed_text) if debug: print(GREEN + part + RESET, end=\"\", flush=True) decompressed_text = decompressed_text + part else: # just add the text to the decompressed string decompressed_text += part if debug: print(part, end=\"\", flush=True)\n\n##### Results\n\nIt works!\n\n### One more thing\n\n  * I don't know how well this will perform across different GPUs, as I've heard that outputs could vary. While I don't have the ability to test this, I confirmed that the results were consistent between a GPU and a CPU.\n  * I haven't gotten around to uploading the script to Github. Once I do, I'll post it here.\n\n#### Here's a draft version of this post, compressed:\n\n    \n    \n    [\"\\nWarning@1@ What f@1@ows@1@ not practical, well@1@written,@1@ finished@5@lso probably not the@1@ idea. It was fun th@1@u@1@h.@1@Int@1@duction@1@Large language@1@ are trained@1@ huge datas@3@ to learn the relationships and contexts of@1@ within larger doc@1@ments@1@ These relationships are what@1@s the@3@ text.\\nRec@1@ I@2@ read concerns@1@ LL@2@ trained@1@ copyright@1@ text and repro@1@ing@1@.@1@ got@2@: Can training text be extracted@5@ The@1@, of@4@, and this@1@n@4@ (@1@ open@1@ question@1@ This led@3@ what it@1@ take@1@ extract entire@1@- or have an LL@1@ repro@1@e text it'@1@ ne@1@r dire@1@tly been@3@ I fig@1@ed that, for@1@ most@2@ many texts contain sections@1@ would natur@1@y align@2@ language relationships the@4@ If that@2@ the@2@ then@1@ I@2@ the@2@ infer those relationships@1@ correct its course whenever@1@ dev@2@.@1@So th@1@t@2@ how@1@ got@1@. @1@To see@2@ would@5@ use technology th@1@t I am@2@.@1@'ll use ll@3@ via its p@1@hon bind@1@.\\nHow@1@ Works...\\n@1@ solution I put@1@ has the@1@ key fun@2@ns@2@load@1@document(fil@1@ame@1@\\n@1@ reads a@3@ token@2@ using@1@ model@2@ to@1@n@2@ If@1@ text@3@ for@2@'@5@ is@2@ smaller parts th@1@t fit@1@ this@2@ This prev@1@ token over@1@ow.@13@):@2@ generates@1@, n@1@ at@3@ w@1@h 0.0 as@3@ a static@1@. It ess@1@i@1@y continues@1@ text@2@ the input text stopped@2@compress@3@sour@1@e_@1@):@3@ attempts@3@ input@1@ by generating parts@4@ LL@3@ the@1@ te@1@ mat@1@s@1@ start@2@ source@2@ it continues\\u2013 o@1@rwise@2@ adds@1@ character directly to@1@ comp@1@ string@1@\\nTo record@1@ generated@2@ the fun@1@ion notes how@1@ tokens@1@ gener@1@ed@1@ places that@1@ between a del@1@.\\nde@10@De@2@ text comp@2@ the compress@8@ te@1@ using@3@er@1@ recon@5@ by generating missing@1@ or directly app@1@ the text.@1@Testing\\nI used two texts for t@1@t. For@2@,@1@ decided@2@ the@4@Al@8@\\\"@1@ I ass@1@med@3@ in@7@ As I@2@ I got very good compression. @1@Com@1@\\nHere'@1@ the meat@2@ compression function@2@Code@1@\\nResults@1@Here'@1@ the model processing@1@ script. The text in blue mat@1@s text gener@1@ed@2@ LL@1@ and white is from@1@ source@2@ Yes@4@ slow. @2@The \\\"Com@2@ content:@1@Here@2@ wh@1@t@1@ output@2@. Yes@4@ in JSON@1@ and@1@ it@2@ u@1@y,@1@ this@1@ just@4@, right@1@ For@3@ clarity in@4@ pic@1@d an easy@4@ del@1@: @\\nThis@3@lete \\\"@4@ of Chapter@2@.@2@De@2@ @1@Com@1@ion is point@1@ if I@3@ reverse@2@ Let@2@ look@1@ the@1@p@1@s@8@\\nIt@2@\\nNot@2@I don@2@ know@3@ will perform ac@1@s@1@ GP@1@, as@1@'@1@ heard@1@ outputs cou@1@d@2@ While I don@3@ the ability@3@,@1@ confirmed@1@ the results@2@ bet@1@en a GPU@5@I haven@2@ gotten arou@1@d@1@ u@1@oad@1@ the sc@1@t@2@hub. Once I@5@ post it@3@Here'@1@ this post, comp\"]\n\n###### 3,436 to 2,691 Characters\n\nAs expected, the method performs better better on data that the model has been\ntrained on, but there's still some reduction in size.\n\n#### Thoughts\n\n  * The model is huge\n  * Would it practical to train a model for the purpose of compression?\n  * Could this method be used to identify any data that was used to train a model?\n  * Do different models yield better results?\n  * Can this be extended to other data types, like images?\n\n## Sign up for more like this.\n\nEnter your email\n\nSubscribe\n\n## Security Paralysis\n\nFear is our body's response to a perceived threat. Deeply ingrained in our\nsurvival instincts, fundamental to our human nature, it's designed to protect\nus from harm by prompting a response-- fight, flight, or, as in the case of\nthis topic - freeze. While each of these reactions has its\n\nJul 25, 2023 1 min read\n\no565 \u00a9 2024\n\nPowered by Ghost\n\n", "frontpage": false}
{"aid": "40165207", "title": "An Engineer's Guide to Integrating ARI into Existing Acme Clients", "url": "https://letsencrypt.org/2024/04/25/guide-to-integrating-ari-into-existing-acme-clients.html", "domain": "letsencrypt.org", "votes": 2, "user": "randompeach", "posted_at": "2024-04-26 02:05:40", "comments": 0, "source_title": "An Engineer\u2019s Guide to Integrating ARI into Existing ACME Clients", "source_text": "An Engineer\u2019s Guide to Integrating ARI into Existing ACME Clients - Let's\nEncrypt\n\nSkip navigation links\n\n# An Engineer\u2019s Guide to Integrating ARI into Existing ACME Clients\n\nApr 25, 2024 \u2022 Samantha Frank\n\nFollowing our previous post on the foundational benefits of ACME Renewal\nInformation (ARI), this one offers a detailed technical guide for\nincorporating ARI into existing ACME clients.\n\nSince its introduction in March 2023, ARI has significantly enhanced the\nresiliency and reliability of certificate revocation and renewal for a growing\nnumber of Subscribers. To extend these benefits to an even broader audience,\nincorporating ARI into more ACME clients is essential.\n\nTo foster wider adoption, we\u2019re excited to announce a new compelling\nincentive: certificate renewals that utilize ARI will now be exempt from all\nrate limits. To capitalize on this benefit, renewals must occur within the\nARI-suggested renewal window, and the request must clearly indicate which\nexisting certificate is being replaced. To learn how to request a suggested\nrenewal window, select an optimal renewal time, and specify certificate\nreplacement, continue reading!\n\n## Integrating ARI Into an Existing ACME Client\n\nIn May 2023, we contributed a pull request to the Lego ACME client, adding\nsupport for draft-ietf-acme-ari-01. In December 2023 and February 2024, we\ncontributed two follow-up pull requests (2066, 2114) adding support for\nchanges made in draft-ietf-acme-ari-02 and 03. These experiences provided\nvaluable insight into the process of integrating ARI into an existing ACME\nclient. We\u2019ve distilled these insights into six steps, which we hope will be\nuseful for other ACME client developers.\n\nNote: the code snippets in this post are written in Golang. We\u2019ve structured\nand contextualized them for clarity, so that they might be easily adapted to\nother programming languages as well.\n\n### Step 1: Detecting support for ARI\n\nWhile Let\u2019s Encrypt first enabled ARI in Staging and Production environments\nin March 2023, many ACME clients are used with a variety of CAs, so it\u2019s\ncrucial to ascertain if a CA supports ARI. This can be easily determined: if a\n\u2018renewalInfo\u2019 endpoint is included in the CA\u2019s directory object, then the CA\nsupports ARI.\n\nIn most any client you\u2019ll find a function or method that is responsible for\nparsing the JSON of the ACME directory object. If this code is deserializing\nthe JSON into a defined type, it will be necessary to modify this type to\ninclude the new \u2018renewalInfo\u2019 endpoint.\n\nIn Lego, we added a \u2018renewalInfo\u2019 field to the Directory struct, which is\naccessed by the GetDirectory method:\n\n    \n    \n    type Directory struct { NewNonceURL string `json:\"newNonce\"` NewAccountURL string `json:\"newAccount\"` NewOrderURL string `json:\"newOrder\"` NewAuthzURL string `json:\"newAuthz\"` RevokeCertURL string `json:\"revokeCert\"` KeyChangeURL string `json:\"keyChange\"` Meta Meta `json:\"meta\"` RenewalInfo string `json:\"renewalInfo\"` }\n\nAs we discussed above, not all ACME CAs currently implement ARI, so before we\nattempt to make use of the \u2018renewalInfo\u2019 endpoint we should ensure that this\nendpoint is actually populated before calling it:\n\n    \n    \n    func (c *CertificateService) GetRenewalInfo(certID string) (*http.Response, error) { if c.core.GetDirectory().RenewalInfo == \"\" { return nil, ErrNoARI } }\n\n### Step 2: Determining where ARI fits into the renewal lifecycle of your\nclient\n\nThe next step involves selecting the optimal place in the client\u2019s workflow to\nintegrate ARI support. ACME clients can either run persistently or be executed\non-demand. ARI is particularly beneficial for clients that operate\npersistently or for on-demand clients that are scheduled to run at least\ndaily.\n\nIn the case of Lego, it falls into the latter category. Its renew command is\nexecuted on-demand, typically through a job scheduler like cron. Therefore,\nincorporating ARI support into the renew command was the logical choice. Like\nmany ACME clients, Lego already has a mechanism to decide when to renew\ncertificates, based on the certificate\u2019s remaining validity period and the\nuser\u2019s configured renewal timeframe. Introducing calls to ARI should take\nprecedence over this mechanism, leading to a modification of the renew command\nto consult ARI before resorting to the built-in logic.\n\n### Step 3: Constructing the ARI CertID\n\nThe composition of the ARI CertID is a crucial part of the ARI specification.\nThis identifier, unique to each certificate, is derived by combining the\nbase64url encoded bytes of the certificate\u2019s Authority Key Identifier (AKI)\nextension and its Serial Number, separated by a period. The approach of\ncombining AKI and serial number is strategic: the AKI is specific to an\nissuing intermediate certificate, and a CA may have multiple intermediates. A\ncertificate\u2019s serial number is required to be unique per issuing intermediate,\nbut serials can be reused between intermediates. Thus the combination of AKI\nand serial uniquely identifies a certificate. With this covered, let\u2019s move on\nto constructing an ARI CertID using only the contents of the certificate being\nreplaced.\n\nSuppose the \u2018keyIdentifier\u2019 field of the certificate\u2019s Authority Key\nIdentifier (AKI) extension has the hexadecimal bytes\n69:88:5B:6B:87:46:40:41:E1:B3:7B:84:7B:A0:AE:2C:DE:01:C8:D4 as its ASN.1 Octet\nString value. The base64url encoding of these bytes is\naYhba4dGQEHhs3uEe6CuLN4ByNQ=. Additionally, the certificate\u2019s Serial Number,\nwhen represented in its DER encoding (excluding the tag and length bytes), has\nthe hexadecimal bytes 00:87:65:43:21. This includes a leading zero byte to\nensure that the serial number is interpreted as a positive integer, as\nnecessitated by the leading 1 bit in 0x87. The base64url encoding of these\nbytes is AIdlQyE=. After stripping the trailing padding characters (\"=\") from\neach encoded part and concatenating them with a period as a separator, the ARI\nCertID for this certificate is aYhba4dGQEHhs3uEe6CuLN4ByNQ.AIdlQyE.\n\nIn the case of Lego, we implemented the above logic in the following function:\n\n    \n    \n    // MakeARICertID constructs a certificate identifier as described in // draft-ietf-acme-ari-03, section 4.1. func MakeARICertID(leaf *x509.Certificate) (string, error) { if leaf == nil { return \"\", errors.New(\"leaf certificate is nil\") } // Marshal the Serial Number into DER. der, err := asn1.Marshal(leaf.SerialNumber) if err != nil { return \"\", err } // Check if the DER encoded bytes are sufficient (at least 3 bytes: tag, // length, and value). if len(der) < 3 { return \"\", errors.New(\"invalid DER encoding of serial number\") } // Extract only the integer bytes from the DER encoded Serial Number // Skipping the first 2 bytes (tag and length). The result is base64url // encoded without padding. serial := base64.RawURLEncoding.EncodeToString(der[2:]) // Convert the Authority Key Identifier to base64url encoding without // padding. aki := base64.RawURLEncoding.EncodeToString(leaf.AuthorityKeyId) // Construct the final identifier by concatenating AKI and Serial Number. return fmt.Sprintf(\"%s.%s\", aki, serial), nil }\n\nNote: In the provided code, we utilize the RawURLEncoding, which is the\nunpadded base64 encoding as defined in RFC 4648. This encoding is similar to\nURLEncoding but excludes padding characters, such as \u201c=\u201d. Should your\nprogramming language\u2019s base64 package only support URLEncoding, it will be\nnecessary to remove any trailing padding characters from the encoded strings\nbefore combining them.\n\n### Step 4: Requesting a suggested renewal window\n\nWith the ARI CertID in hand, we can now request renewal information from the\nCA. This is done by sending a GET request to the \u2018renewalInfo\u2019 endpoint,\nincluding the ARI CertID in the URL path.\n\n    \n    \n    GET https://example.com/acme/renewal-info/aYhba4dGQEHhs3uEe6CuLN4ByNQ.AIdlQyE\n\nThe ARI response is a JSON object that includes a \u2018suggestedWindow\u2019, with\n\u2018start\u2019 and \u2018end\u2019 timestamps indicating the recommended renewal period, and\noptionally, an \u2018explanationURL\u2019 providing additional context about the renewal\nsuggestion.\n\n    \n    \n    { \"suggestedWindow\": { \"start\": \"2021-01-03T00:00:00Z\", \"end\": \"2021-01-07T00:00:00Z\" }, \"explanationURL\": \"https://example.com/docs/ari\" }\n\nThe \u2018explanationURL\u2019 is optional. However, if it\u2019s provided, it\u2019s recommended\nto display it to the user or log it. For instance, in cases where ARI suggests\nan immediate renewal due to an incident that necessitates revocation, the\n\u2018explanationURL\u2019 might link to a page explaining the incident.\n\nNext, we\u2019ll cover how to use the \u2018suggestedWindow\u2019 to determine the best time\nto renew the certificate.\n\n### Step 5: Selecting a specific renewal time\n\ndraft-ietf-acme-ari provides a suggested algorithm for determining when to\nrenew a certificate. This algorithm is not mandatory, but it is recommended.\n\n  1. Select a uniform random time within the suggested window.\n\n  2. If the selected time is in the past, attempt renewal immediately.\n\n  3. Otherwise, if the client can schedule itself to attempt renewal at exactly the selected time, do so.\n\n  4. Otherwise, if the selected time is before the next time that the client would wake up normally, attempt renewal immediately.\n\n  5. Otherwise, sleep until the next normal wake time, re-check ARI, and return to \u201c1.\u201d\n\nFor Lego, we implemented the above logic in the following function:\n\n    \n    \n    func (r *RenewalInfoResponse) ShouldRenewAt(now time.Time, willingToSleep time.Duration) *time.Time { // Explicitly convert all times to UTC. now = now.UTC() start := r.SuggestedWindow.Start.UTC() end := r.SuggestedWindow.End.UTC() // Select a uniform random time within the suggested window. window := end.Sub(start) randomDuration := time.Duration(rand.Int63n(int64(window))) rt := start.Add(randomDuration) // If the selected time is in the past, attempt renewal immediately. if rt.Before(now) { return &now } // Otherwise, if the client can schedule itself to attempt renewal at exactly the selected time, do so. willingToSleepUntil := now.Add(willingToSleep) if willingToSleepUntil.After(rt) || willingToSleepUntil.Equal(rt) { return &rt } // TODO: Otherwise, if the selected time is before the next time that the client would wake up normally, attempt renewal immediately. // Otherwise, sleep until the next normal wake time. return nil }\n\n### Step 6: Indicating which certificate is replaced by this new order\n\nTo signal that a renewal was suggested by ARI, a new \u2018replaces\u2019 field has been\nadded to the ACME Order object. The ACME client should populate this field\nwhen creating a new order, as shown in the following example:\n\n    \n    \n    { \"protected\": base64url({ \"alg\": \"ES256\", \"kid\": \"https://example.com/acme/acct/evOfKhNU60wg\", \"nonce\": \"5XJ1L3lEkMG7tR6pA00clA\", \"url\": \"https://example.com/acme/new-order\" }), \"payload\": base64url({ \"identifiers\": [ { \"type\": \"dns\", \"value\": \"example.com\" } ], \"replaces\": \"aYhba4dGQEHhs3uEe6CuLN4ByNQ.AIdlQyE\" }), \"signature\": \"H6ZXtGjTZyUnPeKn...wEA4TklBdh3e454g\" }\n\nMany clients will have an object that the client deserializes into the JSON\nused for the order request. In the Lego client, this is the Order struct. It\nnow includes a \u2018replaces\u2019 field, accessed by the NewWithOptions method:\n\n    \n    \n    // Order the ACME order Object. // - https://www.rfc-editor.org/rfc/rfc8555.html#section-7.1.3 type Order struct { ... // replaces (optional, string): // a string uniquely identifying a previously-issued // certificate which this order is intended to replace. // - https://datatracker.ietf.org/doc/html/draft-ietf-acme-ari-03#section-5 Replaces string `json:\"replaces,omitempty\"` } ... // NewWithOptions Creates a new order. func (o *OrderService) NewWithOptions(domains []string, opts *OrderOptions) (acme.ExtendedOrder, error) { ... if o.core.GetDirectory().RenewalInfo != \"\" { orderReq.Replaces = opts.ReplacesCertID } }\n\nWhen Let\u2019s Encrypt processes a new order request featuring a \u2018replaces\u2019 field,\nseveral important checks are conducted. First, it\u2019s verified that the\ncertificate indicated in this field has not been replaced previously. Next, we\nensure that the certificate is linked to the same ACME account that\u2019s making\nthe current request. Additionally, there must be at least one domain name\nshared between the existing certificate and the one being requested. If these\ncriteria are met and the new order request is submitted within the ARI-\nsuggested renewal window, the request qualifies for exemption from all rate\nlimits. Congratulations!\n\n## Moving Forward\n\nThe integration of ARI into more ACME clients isn\u2019t just a technical upgrade,\nit\u2019s the next step in the evolution of the ACME protocol; one where CAs and\nclients work together to optimize the renewal process, ensuring lapses in\ncertificate validity are a thing of the past. The result is a more secure and\nprivacy-respecting Internet for everyone, everywhere.\n\nAs always, we\u2019re excited to engage with our community on this journey. Your\ninsights, experiences, and feedback are invaluable as we continue to push the\nboundaries of what\u2019s possible with ACME.\n\nWe\u2019re grateful to be partnering with Princeton University on our ACME Renewal\nInformation work, thanks to generous support from the Open Technology Fund.\n\nInternet Security Research Group (ISRG) is the parent organization of Let\u2019s\nEncrypt, Prossimo, and Divvi Up. ISRG is a 501(c)(3) nonprofit. If you\u2019d like\nto support our work, please consider getting involved, donating, or\nencouraging your company to become a sponsor.\n\n## Support a more secure and privacy-respecting Web.\n\nDonate\n\nLet's Encrypt is a free, automated, and open certificate authority brought to\nyou by the nonprofit Internet Security Research Group (ISRG). Read all about\nour nonprofit work this year in our 2023 Annual Report.\n\n548 Market St, PMB 77519, San Francisco, CA 94104-5401, USA\n\nSend all mail or inquiries to:\n\nPO Box 18666, Minneapolis, MN 55418-0666, USA\n\n  * GitHub\n  * Twitter\n  * Mastodon\n\nView our privacy policy. View our trademark policy.\n\n###### Subscribe to our Newsletter\n\n", "frontpage": false}
{"aid": "40165212", "title": "Chipotle tells employees not to eat chicken on the job", "url": "https://qz.com/chipotle-earnings-stock-chicken-supply-consumer-demand-1851435334", "domain": "qz.com", "votes": 2, "user": "cwwc", "posted_at": "2024-04-26 02:06:19", "comments": 0, "source_title": "Chipotle tells employees not to eat chicken on the job", "source_text": "Chipotle tells employees not to eat chicken on the job\n\n  * Gizmodo\n  * Jalopnik\n  * Kotaku\n  * Quartz\n  * The Root\n  * The Onion\n  * The Inventory\n\n#### Support Quartz\n\nFund next-gen business journalism with $10 a month\n\nSearch\n\nFree Newsletters\n\nWe may earn a commission from links on this page\n\nBusiness News\n\nPOULTRY PROBLEMS\n\n# Chipotle tells employees not to eat chicken on the job\n\n## The fast food chain told employees to choose another protein option for\ntheir meals to preserve supply\n\nBy\n\nFrancisco Velasquez\n\nPublished11 hours ago\n\nWe may earn a commission from links on this page.\n\nChipotle CEO Brian Niccol said the chain plans to deploy some of its avocado-\ncutting robots at its busier locations as early as this year.Image: Getty\nImages North America (Getty Images)\n\nChipotle is hogging its chicken from employees in a bid to keep up with\nsurging demand from customers.\n\n#### Related Content\n\nChipotle just did a 50-for-1 stock split. Here's what that means\n\nChipotle will pass the California minimum wage hike on to customers\n\nAre self-driving cars safe enough yet?\n\nShare\n\nSubtitles\n\n  * Off\n  * English\n\nShare this Video\n\nFacebookTwitterEmail\n\nRedditLink\n\nview video\n\nAre self-driving cars safe enough yet?\n\n\u201cDue to the high demand for chicken in our restaurants and sustained success\nof our Chicken Al Pastor, last week we asked all our corporate and in-\nrestaurant employees to temporarily select another protein option for their\nmeals to preserve our supply,\u201d said Laurie Schalow, Chipotle\u2019s chief corporate\naffairs and food safety officer, in a statement to Quartz.\n\nAdvertisement\n\n#### Related Content\n\nChipotle just did a 50-for-1 stock split. Here's what that means\n\nChipotle will pass the California minimum wage hike on to customers\n\nAre self-driving cars safe enough yet?\n\nShare\n\nSubtitles\n\n  * Off\n  * English\n\nShare this Video\n\nFacebookTwitterEmail\n\nRedditLink\n\nAre self-driving cars safe enough yet?\n\nThat comes just a day after the restaurant chain reported earnings that\nrevealed its sales were being driven by its Braised Beef Barbacoa and Al\nPastor Chicken menu items.\n\nAdvertisement\n\nChipotle\u2019s Schalow said that the company has \u201csince informed employees they\ncan return to ordering chicken in their meals as normal.\u201d The turnaround comes\njust days after Bloomberg reported that the internal changes would be\nimplemented immediately and last pending further notice.\n\nAdvertisement\n\n## More retail news\n\nChipotle says its avocado-cutting robot is coming soon\n\nShoppers in Asia are powering the global luxury industry (again)\n\nSmucker\u2019s nearly $1 billion PB&J business is anything but crusty\n\nRed Lobster could file for bankruptcy soon\n\nOreo maker Mondelez is being fined for limiting cross-border sales\n\n## \ud83d\udcec Sign up for the Daily Brief\n\nOur free, fast, and fun briefing on the global economy, delivered every\nweekday morning.\n\n", "frontpage": false}
{"aid": "40165213", "title": "Pen.el \u2013 Emacs-based operating system designed with holiness in mind", "url": "https://github.com/semiosis/pen.el", "domain": "github.com/semiosis", "votes": 1, "user": "pyinstallwoes", "posted_at": "2024-04-26 02:06:39", "comments": 0, "source_title": "GitHub - semiosis/pen.el", "source_text": "GitHub - semiosis/pen.el\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nsemiosis / pen.el Public\n\n  * Notifications\n  * Fork 13\n  * Star 62\n\n### License\n\nGPL-3.0 license\n\n62 stars 13 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# semiosis/pen.el\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n2 Branches\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nmullikine26.04.24Apr 26, 2024966e4c2 \u00b7 Apr 26, 2024Apr 26, 2024\n\n## History\n\n12,567 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| 21.02.21| Feb 20, 2021  \n  \n### config\n\n|\n\n### config\n\n| 13.04.24| Apr 13, 2024  \n  \n### docs\n\n|\n\n### docs\n\n| 26.04.24| Apr 26, 2024  \n  \n### scripts-host\n\n|\n\n### scripts-host\n\n| 1642029698| Jan 12, 2022  \n  \n### scripts\n\n|\n\n### scripts\n\n| 25.04.24| Apr 24, 2024  \n  \n### src\n\n|\n\n### src\n\n| 26.04.24| Apr 25, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| 16.02.22| Feb 15, 2022  \n  \n### CHANGELOG.org\n\n|\n\n### CHANGELOG.org\n\n| 02.01.24| Jan 2, 2024  \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n| Mon 03 Jan 2022 11:45:56| Jan 2, 2022  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Create LICENSE| Feb 22, 2021  \n  \n### Makefile\n\n|\n\n### Makefile\n\n| 1642634990| Jan 19, 2022  \n  \n### README.html\n\n|\n\n### README.html\n\n| 12.02.24| Feb 12, 2024  \n  \n### README.org\n\n|\n\n### README.org\n\n| 06.03.24| Mar 5, 2024  \n  \n## Repository files navigation\n\n# Pen.el (a holy OS)\n\nPen.el is an emacs-based operating system designed with holiness in mind. It\u2019s\na free and holy OS made with emacs, debian linux and docker.\n\nThis project is not in a ready state\n\nIt\u2019s holy because:\n\n  * This software is dedicated to supporting one\u2019s Christian faith\n\n    * Facilitate:\n\n      * Praying\n      * Praising\n      * Running churches\n      * Maintaining holiness\n      * Bible studies\n  * Features:\n\n    * Bible software comparable to Logos / e-Sword.\n    * Integrates lots of Christian resources.\n    * Lots of scripts for working with Bible-verses etc.\n\n      * Extracting Bible verses from websites, documents, etc.\n      * Canonicalising Bible-refs\n      * Formatting Bible passages in various ways.\n      * etc.\n  * Policies:\n\n    * Avoid AI fiction and ensure it is kept at a safe distance\n    * Strict ban on proprietary software\n\n## Aims\n\n  * Provide the user with free (but advanced) Bible study software, and\n  * Provide trustworthy Christian resources that are all offline.\n  * Make it easier to maintain one\u2019s Christian faith by eliminating all the distractions, yet being featureful and fun.\n  * Able to be the main operating system somebody uses (It\u2019s my main OS).\n\nUsing Pen.el, there should be no need to go online most of the time, as it\nshould contain everything you need to be content with your computing. The\nBible-software I hope will be as featureful as any of the other options\navailable, but completely free, and also low maintenance.\n\n## Intended users\n\n  * emacs/linux savvy:\n\n    * pastors,\n    * church deacons,\n    * chaplains,\n    * theology students\n    * anyone wanting software that respects a user\u2019s desire to remain holy\n\n## Bible word-study\n\n## Technical details\n\n  * It runs in a docker container.\n  * It\u2019s primarily text-based computing environment with emacs as the main component towards that end.\n\n## Quick installation\n\n    \n    \n    git clone \"https://github.com/semiosis/pen.el\" mkdir -p ~/.pen # Add the scripts to the PATH echo export PATH=\"$(realpath .)/pen.el/scripts:\\$PATH\" >> ~/.profile # Add this to prevent C-s from freezing the terminal echo \"stty stop undef 2>/dev/null; stty start undef 2>/dev/null\" | tee -a ~/.zshrc >> ~/.bashrc # Source your .profile . ~/.profile # Run pen pen\n\n## It\u2019s about holiness\n\n    \n    \n    holiness The state of being holy. \"a life of holiness and total devotion to God\" Set-apart from the world, and drawing nearer to God. A life of discipline, focus, and attention to matters of righteous living. It is, as Paul states in Romans 12:1-2, a life fully presented to God in a way that transforms our lives to God's glory rather than conforming our lives to the ways of the world. Romans 12:1-2 Therefore, I urge you, brothers and sisters, in view of God\u2019s mercy, to offer your bodies as a living sacrifice, holy and pleasing to God\u2014this is your true and proper worship. 2 Do not conform to the pattern of this world, but be transformed by the renewing of your mind. Then you will be able to test and approve what God\u2019s will is\u2014his good, pleasing and perfect will.\n\n## Weekly Bible-study\n\n## Always pray\n\nEphesians 6:18 - With all prayer and petition pray at all times in the Spirit,\nand with this in view, be on the alert with all perseverance and petition for\nall the saints, (NASB)\n\n# My thoughts and bible references regarding theology\n\nActs 13:48 - And when the Gentiles heard this, they began rejoicing and\nglorifying the word of the Lord, and as many as were appointed to eternal life\nbelieved. (ESV)\n\nI\u2019ve been thinking about belief, faith, works, law and receiving the Holy\nSpirit! Please let me know what you think if you have the time. I\u2019m trying to\nget clearer on this.\n\nhttps://github.com/semiosis/thoughts-on-theology\n\n# Jesus Christ is Lord! :)\n\n## About\n\nNo description, website, or topics provided.\n\n### Resources\n\nReadme\n\n### License\n\nGPL-3.0 license\n\nActivity\n\nCustom properties\n\n### Stars\n\n62 stars\n\n### Watchers\n\n3 watching\n\n### Forks\n\n13 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Sponsor this project\n\n  * patreon.com/mullikine\n\n## Packages 0\n\nNo packages published\n\n## Contributors 2\n\n  * mullikine Shane Mulligan\n  * aindilis\n\n## Languages\n\n  * Emacs Lisp 34.9%\n  * Vim Script 29.5%\n  * Shell 19.2%\n  * Vim Snippet 9.7%\n  * Lua 3.1%\n  * Perl 1.5%\n  * Other 2.1%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
