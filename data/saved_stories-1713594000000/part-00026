{"aid": "40091605", "title": "Three Shifts Re-Defining the Semiconductor Landscape", "url": "https://semiconductor.substack.com/p/three-shifts-re-defining-the-semiconductor", "domain": "semiconductor.substack.com", "votes": 2, "user": "osnium123", "posted_at": "2024-04-19 20:31:20", "comments": 0, "source_title": "Three Shifts Re-defining the Semiconductor Landscape", "source_text": "Three Shifts Re-defining the Semiconductor Landscape\n\n# Bits and Bytes\n\nShare this post\n\n#### Three Shifts Re-defining the Semiconductor Landscape\n\nsemiconductor.substack.com\n\n#### Discover more from Bits and Bytes\n\nA newsletter about the semiconductor landscape and its evolution in the next\nwave of computing\n\nOver 1,000 subscribers\n\nContinue reading\n\nSign in\n\n# Three Shifts Re-defining the Semiconductor Landscape\n\nPushkar Ranade\n\nApr 18, 2024\n\n2\n\nShare this post\n\n#### Three Shifts Re-defining the Semiconductor Landscape\n\nsemiconductor.substack.com\n\n1\n\nShare\n\n> \u201cI've never seen any technology advance faster than this. Artificial\n> intelligence compute coming online appears to be increasing by a factor of\n> ten every six months. Obviously, that can\u2019t continue at such a high rate\n> forever but...I've never seen anything like it...the chip rush is bigger\n> than any gold rush that has ever existed.\u201d\n>\n> Elon Musk, Bosch World Conference, March 2024\n\nThe semiconductor industry has periodically been reshaped by tectonic shifts\nin the broader computing landscape. While the foundational geometric scaling\nof silicon technology has followed a secular trend established by Moore\u2019s Law,\nevery successive era of computing over the last six decades has fundamentally\ntransformed the semiconductor industry that drove it forward. We are in the\nearly days of the next inflection.\n\nThe PC era that began in the 1980s established the CPU as the enabling silicon\nplatform, which in turn shaped the evolution of semiconductor technology and\nestablished the pre-eminence of the Integrated Device Manufacturing (IDM)\nbusiness model over the following decade. The mobile era that began in the\nmid-2000s established the mobile SoC as the enabling silicon platform and\nestablished the pre-eminence of the foundry-fabless ecosystem over the decade\nthat followed. The AI era is in its early days and has already begun to alter\nthe contours of the semiconductor landscape.\n\nThree major shifts are re-defining the semiconductor landscape today. Looking\nback a decade later, these are likely to be the foundational transformations\nin the semiconductor industry catalyzed by the emergence of AI computing.\n\n###\n\nOne: From CPUs to GPUs\n\n> \u201c...because of this new machine learning paradigm, the kinds of computations\n> we want to run are quite different than traditional handwritten twisty C++\n> code that a lot of basic CPUs were designed to run effectively, and so we\n> want different kinds of hardware in order to run these computations more\n> efficiently. And we can actually in some sense focus on a narrower set of\n> things we want computers to do and do them extremely well and extremely\n> efficiently, and then be able to have you know that increasing scale\n> actually be even more possible.\u201d\n>\n> Jeff Dean, Chief Scientist, Google DeepMind and Google Research, February\n> 2024 (Link)\n\nIn so much as the Central Processing Unit (CPU) has been \u201ccentral\u201d to high\nperformance computing in datacenters, that central role is now increasingly\nbeing fulfilled by the Graphics Processing Unit (GPU). A more appropriate\ntechnical descriptor of this shift would be \u201cfrom Scalar to Vector\u201d or \u201cfrom\nScalar to Tensor\u201d, reflecting the transition in the underlying computer\narchitecture.\n\nA new computer architecture drives the emergence and ascendance of every\nsuccessive era of computing. Scalar architectures dominated the PC era (CPUs).\nVector architecture started as the de-facto architecture for gaming chips\n(GPUs) and morphed to become the dominant architecture for the AI era.\n\nThe \u201cGPU\u201d moniker is now an amusing misnomer since GPUs that enable AI\ncomputing are no longer dedicated graphics processing units at all. They are\nsimply general-purpose, programmable shader-based vector computers that happen\nto be highly power-efficient for massively parallelized machine learning\nworkloads that tend to be dominated by matrix multiplication and other linear\nalgebra primitives. While GPUs are the dominant platform for machine learning\ntoday, other custom-designed vector or tensor-based architectures can be\nequally if not more efficient for reduced precision linear algebra-based\nworkloads.\n\n> \u201c...it seems like the world is going to be very compute constrained for a\n> while and I think almost all of the datacenters around the world will over\n> time be AI instead of conventional CPUs...if you ask what percentage of the\n> energy (in datacenters) is being used for neural nets, it's going to over\n> time be probably 80-90%...\u201d\n>\n> Elon Musk, January 2024\n\nIn the PC era, the CPU quickly became the primary volume driver and largest\nrevenue generator for the semiconductor industry and in turn, became the\nfoundational platform that drove innovation in silicon technology. As the\nprimary beneficiary of this shift to CPU-centric computing, Intel was able to\nset the pace and direction of Moore\u2019s Law during the PC era. Transistor\ntechnology was defined and optimized to be \u201cCPU-first\u201d, as evidenced by\nIntel\u2019s groundbreaking transistor innovations through the 1990s and 2000s.\nFoundry suppliers would later adapt and waterfall these innovations to suit\nthe needs of other applications.\n\nIn the mobile era, the Application Processor Unit (APU), which integrated a\nCPU and a GPU with a host of other functionality in a single System on a Chip\n(SoC) drove 10X higher unit volumes than the standalone CPU and became the\nprimary volume driver for the semiconductor foundry ecosystem. Over the last\ndecade, the dominance of the mobile SoC platform ensured that the APU set the\npace and direction of Moore\u2019s Law \u2013 Apple\u2019s iPhone roadmap has an outsized\ninfluence on TSMCs process technology cadence and roadmap. Transistor\ntechnology is now optimized to be \u201cmobile SoC-first\u201d, to be later adapted for\nother applications.\n\nAn interesting question then is how this dynamic may shift in the AI era \u2013 the\ndatacenter GPU has already established itself as the primary enabler of\ngenerative AI model training workloads and has also driven exponential revenue\ngrowth for product designers (e.g. NVIDIA) and silicon foundry suppliers (e.g.\nTSMC). GPUs will over time drive increasing wafer volumes for the foundry\nsuppliers. In addition, since datacenter GPUs are a system solution rather\nthan a discrete chip solution, they already drive large (if not the largest)\nunit volumes for system integration and advanced packaging technologies (e.g.\nCoWoS at TSMC). NVIDIA is now TSMCs second largest customer by revenue (Link)\nand the GPUs it builds are bound to play an outsized role in setting the\nfoundry process and packaging technology cadence and roadmap.\n\n> \u201cThere\u2019s about a trillion dollars\u2019 worth of installed base of data centers.\n> Over the course of the next four or five years, we\u2019ll have two trillion\n> dollars\u2019 worth of data centers that will be powering software around the\n> world.\u201d\n>\n> Jensen Huang, January 2024\n\nNVIDIA GPUs rapidly consumed the majority of datacenter chip market revenue\nshare. If the GPU extends its reach from training to inference, its share of\nthe total semiconductor market revenue will expand further (source: Link)\n\nEven if one assumes a $500B computing infrastructure buildout (half of\nJensen\u2019s $1T estimate) over the rest of the decade, it still implies massive\ndemand growth for datacenter GPUs in the coming years. Datacenter GPUs used\nfor AI training drive large revenue, but significantly less wafer volume\ncompared to the CPU. Over time, if GPUs become the enabling platform for AI\ninference workloads too, then they will drive far more volume, comparable to,\nif not eclipsing that of the mobile SoC. If this trend holds, then the GPU\ncould become the new \u201ccentral\u201d processing unit.\n\n> \u201cInference is incredibly hard...the goal of somebody who's doing inference\n> is to engage a lot more users, to apply the software to a large installed\n> base...And so, the problem with inference is that it is actually an\n> installed base problem and that takes enormous patience, years and years of\n> success and dedication to architectural compatibility.\u201d\n>\n> Jensen Huang, March 2024 on why he believes GPU solutions will win in AI\n> inference.\n\nShare\n\n###\n\nTwo: From Chips to Systems\n\nA defining trait of the PC platform was its ability to become easily\nmodularized. This enabled the PC industry to become horizontal and allowed a\nwave of independent original equipment manufacturers (OEMs) and original\ndevice manufacturers (ODMs) to thrive. Michael Dell famously started\nassembling PCs from his dorm room and grew his startup into a multi-billion-\ndollar enterprise. ASUS, Compaq, HP and many other PC vendors were able to\nbuild highly successful businesses by assembling the outputs of discrete\ncomponent manufacturers. And because the CPU was the primary unit of compute\nfor the PC, Intel became the largest semiconductor beneficiary of this\nmodularization. Even though Intel only supplied one component (the CPU), it\nenjoyed an outsized revenue share in the PC market.\n\nIn the mobile era, some single chip (or single component) suppliers did become\nlarge players (e.g. Qualcomm\u2019s modem chip), but they were unable to reach the\ndominance that the CPU enabled for Intel in the PC era because the largest\nrevenue share in the mobile era went to companies building integrated systems\nrather than single chips. Apple is the most extreme example of this value\naggregation. Android phone manufacturers (e.g. HTC, Samsung, Google) were\nsuccessful because they also achieved some level of system integration, but\nthey were not able to command the profitability of a fully integrated provider\nlike Apple. More importantly, full integration enabled Apple to arguably build\na better product and hone high-skill manufacturing processes and technologies\nthat became a sustaining competitive advantage for them and their outsourced\nassembly partner (Foxconn).\n\nThe scalable unit of compute has shifted from a discrete \u201cchip\u201d (e.g. a CPU or\na GPU w/ or w/o DRAM) to a complete computer system in a box (e.g. NVIDIA DGX\n100). Multiple box clusters (pods) can be combined to form super-pods to\nprovide datacenter scale compute (BOM=Bill of Materials, ASP = Average Selling\nPrice)\n\nAn equally significant, but relatively unnoticed shift is underway in how\nmodern AI computing systems are built and who is building them. NVIDIA is no\nlonger just a chip (or even a graphics card) supplier - it builds the entire\ncomputer \u2013 the DGX box integrates 35,000+ components and weighs 70 lbs.\nDesigning and building such a box is a high-skill and lengthy manufacturing\nendeavor in itself, much akin to how Apple designs and builds the iPhone.\nMoreover, less than a dozen of those 35,000+ components are advanced node\nsilicon chips, and these include not just compute (CPU and GPU) chips, but\ncustom designed high-speed network processor chips as well. NVIDIA has become\nfar more than a merchant chip company or even a semiconductor company \u2013 it is\na systems (and software) company, designing complex computers and getting them\nbuilt via a vast supplier network along a complex, global supply chain \u2013 an\nincredibly wide moat for any traditional discrete chip company to cross.\n\nNVIDIA also offers an authorized reference design platform (HGX100) which\nthird party OEMs can build upon to create custom variants. Pure-play third\nparty OEMs can assemble such systems too, just as they assembled PCs and\nserver systems earlier. However, given the complexity of these new systems and\nthe tight integration required across every layer of abstraction up to and\nincluding software, it remains to be seen if pure-play third party integrators\nwill be able to achieve best-in-class performance without any reference\ndesigns from the primary vendor.\n\nIn essence, the modular unit of compute is shifting from a chip (e.g. a\ndiscrete CPU) to a tightly integrated system in a box (including CPUs, GPUs,\nnetworking, DRAM, I/O peripherals and much more). If the unit of compute for\nthe datacenter is shifting from a chip to a box, it is highly integrated\nsystems companies that will get an outsized share of the total market revenue.\nIt is interesting to note that AMD as a discrete silicon provider (with the\nMI300 AI accelerator) gets just a fraction of the share of wallet that NVIDIA\nenjoys by selling the entire DGX computer (Link). Similarly, Intel Xeon CPUs\nare a part of each DGX box that NVIDIA sells \u2013 yet Intel gets just a fraction\nof the premium that NVIDIA earns by selling the integrated box. As the unit of\ncompute shifts from the chip to the system, the lion\u2019s share of semiconductor\nrevenue in the AI era will go to systems companies and not to discrete chip\ncompanies.\n\nShare\n\n###\n\nThree: From Horizontal to Vertical\n\n> \u201cVertically integrated firms will often dominate in the most demanding tiers\n> of markets that have grown to substantial size, while a horizontally\n> stratified, or disintegrated, industry structure will often be the dominant\n> business model in the tiers of the market that are less demanding of\n> functionality.\u201d\n>\n> Clayton M. Christensen (Link)\n\nFull stack ownership is a critical asset in the AI era of computing. Pseudo-\nvertical integration down the computing stack is now economically viable,\ntechnologically achievable and strategically vital, prompting every major\ntechnology company to design their own chips and computing systems.\n\nIn the 1990s, Andy Grove astutely observed the transformation of computing\nfrom a vertically integrated business to independent and horizontal\nbusinesses. This transformation provided the catalyst for integrated device\nmanufacturers like Intel to thrive in the PC era. Intel famously established\nthe predominant computer architecture (x86) and by combining it with the\nability to manufacture the most advanced chips at scale was able to become the\nlargest semiconductor company in the world. The mobile era broke the dominance\nof the integrated manufacturing and design model and paved the way for the\nfoundry-fabless business model to thrive. The AI era is facilitating the rise\nof computing as a pseudo-vertically integrated business. There are several\nstrategic reasons that have driven this trend for over a decade, but the rapid\nrise of generative AI in just the last 2 years is accelerating this\ntransformation and will have a significant impact on the traditional\nsemiconductor industry landscape.\n\nSix of the seven largest companies in the world are now designing their own\nsilicon chips. Only one of these six companies (NVIDIA) is a dedicated\nmerchant silicon supplier. The only company in the list that is not building\nits own silicon is a petroleum company.\n\nAI computing, especially datacenter training represents the most demanding\ncompute workload for semiconductors today and has now reached a scale where\nvertical integration down to silicon is not only economically viable, but\nstrategically vital, exactly as observed by Clayton Christensen. Seven of the\nworld\u2019s ten largest companies are now designing their own custom silicon\n(ranging from small ASICs to state-of-the-art general-purpose CPUs, networking\nprocessors and many other chips). The large cloud providers and technology\ncompanies started by building discrete silicon chips \u2013 but they quickly\nevolved to designing entire computing systems themselves \u2013 Google\u2019s TPU Pod or\nTesla\u2019s Dojo are examples of this trend. It is interesting to note that the\nmodular and horizontal semiconductor ecosystem that burgeoned and matured\nduring the prior two eras of computing is now enabling today\u2019s largest\ncompanies to easily re-integrate vertically down the computing stack \u2013 with\nsilicon wafer fabrication, packaging and assembly being the only functions\nthat still need to be outsourced. Companies like Amazon started out by\ndesigning networking processors and within a few years began designing domain\nspecific accelerators and general-purpose CPUs as well.\n\nI wrote about custom silicon development at AWS and Apple earlier:\n\n#### On the Origins of AWS Custom Silicon\n\nPushkar Ranade\n\n\u00b7\n\nNovember 30, 2022\n\nRead full story\n\n#### How Apple Disrupted the US Semiconductor Industry\n\nPushkar Ranade\n\n\u00b7\n\nJanuary 23, 2022\n\nRead full story\n\nMicrosoft, Amazon, Google, Tesla, Meta and others are designing not just their\nown chips, but entire high-performance computing systems, much like the NVIDIA\nDGX box described earlier.\n\nGoogle\u2019s Tensor Processing Unit (TPU) family of chips and systems (pods) is an\nexample of vertical integration by Cloud Service Providers\n\nOpenAI which doesn\u2019t even operate its own datacenters yet is assembling its\nown hardware team too (Link). These companies will leverage the existing\nsemiconductor manufacturing and assembly ecosystem to varying degrees to build\ntheir own compute systems designed and optimized for their most prevalent and\nstrategic workloads. As compute capacity becomes one of the most vital\ntechnology assets in the AI era, the strategic incentives for vertical\nintegration will only grow stronger over time and will likely change the\nbalance of power in the pure-play semiconductor design landscape.\n\n###\n\nSummary\n\nEvery era of computing has initially been supported a plurality of competing\nhardware and software solutions, but eventually the majority share of market\nrevenue has disproportionately gone to just one or two dominant entities: IBM\n(mainframes), DEC (minicomputers), Intel + Microsoft (PC), Apple + Google\n(Mobile). Companies that successfully achieve the transition from discrete\nchips to integrated systems (including software) and from scalar-based\narchitectures to tensor-based architectures will be best positioned to win in\nthe AI era of computing. Interestingly, the incumbent merchant chip and system\nproviders will be competing fiercely not only amongst themselves and a new\ncrop of silicon, systems and software start-ups, but more so against their own\ncustomers who are integrating vertically down to silicon and building custom\nsilicon chips and systems to displace their suppliers.\n\nThe chip wars for supremacy in the AI era have begun \u2013 and this time, winning\nthe battle will require more than just chips.\n\n> The views expressed herein are the authors\u2019 own.\n\nThanks for reading Bits and Bytes! Subscribe for free to receive new posts and\nsupport my work.\n\n2 Likes\n\n\u00b7\n\n2 Restacks\n\n2\n\nShare this post\n\n#### Three Shifts Re-defining the Semiconductor Landscape\n\nsemiconductor.substack.com\n\n1\n\nShare\n\n1 Comment\n\nSO3 hrs agoDr. Ranade, in light of your observations, it seems that the\nfoundry model is the only viable model for Samsung and Intel. Having said\nthat, can you foresee some of the large system integrators basically pushing\nfor customized silicon technology for their own needs? Finally, given that\nadvanced logic chips are only a small percentage of the total number of chips\navailable used in these systems, will the advanced foundries be able to\ncapture enough value to sustain the increase in development and manufacturing\ncosts?Expand full commentLikeReplyShare  \n---  \n  \nThe Apple-TSMC Partnership\n\nThe TSMC-Apple partnership has been one of the defining relationships of the\nmobile computing era. Without Apple as a predictable, high volume and...\n\nMar 6, 2022 \u2022\n\nPushkar Ranade\n\n16\n\nShare this post\n\n#### The Apple-TSMC Partnership\n\nsemiconductor.substack.com\n\n5\n\nThe Leadership Philosophy of Jensen Huang\n\n\u201cWhat is this machine that you are trying to create? What is its output, what\nis its input, what are the conditions that it is in? What is the industry...\n\nOct 17, 2023 \u2022\n\nPushkar Ranade\n\n17\n\nShare this post\n\n#### The Leadership Philosophy of Jensen Huang\n\nsemiconductor.substack.com\n\nChip Wars\n\nA New Semiconductor World Order\n\nFeb 20, 2022 \u2022\n\nPushkar Ranade\n\n15\n\nShare this post\n\n#### Chip Wars\n\nsemiconductor.substack.com\n\n4\n\nReady for more?\n\n\u00a9 2024 Pushkar Ranade\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}
