{"aid": "40113166", "title": "Sex offender banned from using AI tools in landmark UK case", "url": "https://www.theguardian.com/technology/2024/apr/21/sex-offender-banned-from-using-ai-tools-in-landmark-uk-case", "domain": "theguardian.com", "votes": 1, "user": "croes", "posted_at": "2024-04-22 11:05:49", "comments": 0, "source_title": "Sex offender banned from using AI tools in landmark UK case", "source_text": "Sex offender banned from using AI tools in landmark UK case | Artificial intelligence (AI) | The Guardian\n\nSkip to main contentSkip to navigation\n\nSkip to navigation\n\nPrint subscriptions\n\nSign in\n\nSearch jobs\n\nSearch\n\n  * Europe edition\n\n  * UK edition\n\n  * US edition\n\n  * Australia edition\n\n  * International edition\n\nThe Guardian - Back to homeThe Guardian\n\n  * World\n  * UK\n  * Climate crisis\n  * Ukraine\n  * Environment\n  * Science\n  * Global development\n  * Football\n  * Tech\n  * Business\n  * Obituaries\n\nThere are increasing concerns over the use of AI in creating deepfakes and sex\nabuse images. Photograph: Dominic Lipinski/PA\n\nThere are increasing concerns over the use of AI in creating deepfakes and sex\nabuse images. Photograph: Dominic Lipinski/PA\n\nThe ObserverArtificial intelligence (AI)\n\n# Sex offender banned from using AI tools in landmark UK case\n\nThe decision could set a precedent for future monitoring of people convicted\nof indecent image offences\n\nShanti Das, Home affairs correspondent\n\nSun 21 Apr 2024 08.00 CEST\n\nShare\n\nA sex offender convicted of making more than 1,000 indecent images of children\nhas been banned from using any \u201cAI creating tools\u201d for the next five years in\nthe first known case of its kind.\n\nAnthony Dover, 48, was ordered by a UK court \u201cnot to use, visit or access\u201d\nartificial intelligence generation tools without the prior permission of\npolice as a condition of a sexual harm prevention order imposed in February.\n\nThe ban prohibits him from using tools such as text-to-image generators, which\ncan make lifelike pictures based on a written command, and \u201cnudifying\u201d\nwebsites used to make explicit \u201cdeepfakes\u201d.\n\nDover, who was given a community order and \u00a3200 fine, has also been explicitly\nordered not to use Stable Diffusion software, which has reportedly been\nexploited by paedophiles to create hyper-realistic child sexual abuse\nmaterial, according to records from a sentencing hearing at Poole magistrates\ncourt.\n\nThe case is the latest in a string of prosecutions where AI generation has\nemerged as an issue and follows months of warnings from charities over the\nproliferation of AI-generated sexual abuse imagery.\n\nLast week, the government announced the creation of a new offence that makes\nit illegal to make sexually explicit deepfakes of over-18s without consent.\nThose convicted face prosecution and an unlimited fine. If the image is then\nshared more widely offenders could be sent to jail.\n\nCreating, possessing and sharing artificial child sexual abuse material was\nalready illegal under laws in place since the 1990s, which ban both real and\n\u201cpseudo\u201d photographs of under-18s. In previous years, the law has been used to\nprosecute people for offences involving lifelike images such as those made\nusing Photoshop.\n\nRecent cases suggest it is increasingly being used to deal with the threat\nposed by sophisticated artificial content. In one going through the courts in\nEngland, a defendant who has indicated a guilty plea to making and\ndistributing indecent \u201cpseudo photographs\u201d of under-18s was bailed with\nconditions including not accessing a Japanese photo-sharing platform where he\nis alleged to have sold and distributed artificial abuse imagery, according to\ncourt records.\n\nIn another case, a 17-year-old from Denbighshire, north-east Wales, was\nconvicted in February of making hundreds of indecent \u201cpseudo photographs\u201d,\nincluding 93 images and 42 videos of the most extreme category A images. At\nleast six others have appeared in court accused of possessing, making or\nsharing pseudo-photographs \u2013 which covers AI generated images \u2013 in the last\nyear.\n\nThe Internet Watch Foundation (IWF) said the prosecutions were a \u201clandmark\u201d\nmoment that \u201cshould sound the alarm that criminals producing AI-generated\nchild sexual abuse images are like one-man factories, capable of churning out\nsome of the most appalling imagery\u201d.\n\nSusie Hargreaves, the charity\u2019s chief executive, said that while AI-generated\nsexual abuse imagery currently made up \u201ca relatively low\u201d proportion of\nreports, they were seeing a \u201cslow but continual increase\u201d in cases, and that\nsome of the material was \u201chighly realistic\u201d. \u201cWe hope the prosecutions send a\nstark message for those making and distributing this content that it is\nillegal,\u201d she said.\n\nIt is not clear exactly how many cases there have been involving AI-generated\nimages because they are not counted separately in official data, and fake\nimages can be difficult to tell from real ones.\n\nLast year, a team from the IWF went undercover in a dark web child abuse forum\nand found 2,562 artificial images that were so realistic they would be treated\nby law as though they were real.\n\nThe Lucy Faithfull Foundation (LFF), which runs the confidential Stop It Now\nhelpline for people worried about their thoughts or behaviour, said it had\nreceived multiple calls about AI images and that it was a \u201cconcerning trend\ngrowing at pace\u201d.\n\nIt is also concerned about the use of \u201cnudifying\u201d tools used to create\ndeepfake images. In one case, the father of a 12-year-old boy said he had\nfound his son using an AI app to make topless pictures of friends.\n\nskip past newsletter promotion\n\nSign up to Observed\n\nFree weekly newsletter\n\nAnalysis and opinion on the week's news and culture brought to you by the best\nObserver writers\n\nPrivacy Notice: Newsletters may contain info about charities, online ads, and\ncontent funded by outside parties. For more information see our Privacy\nPolicy. We use Google reCaptcha to protect our website and the Google Privacy\nPolicy and Terms of Service apply.\n\nafter newsletter promotion\n\nIn another case, a caller to the NSPCC\u2019s Childline helpline said a \u201cstranger\nonline\u201d had made \u201cfake nudes\u201d of her. \u201cIt looks so real, it\u2019s my face and my\nroom in the background. They must have taken the pictures from my Instagram\nand edited them,\u201d the 15-year-old said.\n\nThe charities said that as well as targeting offenders, tech companies needed\nto stop image generators from producing this content in the first place. \u201cThis\nis not tomorrow\u2019s problem,\u201d said Deborah Denis, chief executive at the LFF.\n\nThe decision to ban an adult sex offender from using AI generation tools could\nset a precedent for future monitoring of people convicted of indecent image\noffences.\n\nSex offenders have long faced restrictions on internet use, such as being\nbanned from browsing in \u201cincognito\u201d mode, accessing encrypted messaging apps\nor from deleting their internet history. But there are no known cases where\nrestrictions were imposed on use of AI tools.\n\nIn Dover\u2019s case, it is not clear whether the ban was imposed because his\noffending involved AI-generated content, or due to concerns about future\noffending. Such conditions are often requested by prosecutors based on\nintelligence held by police. By law, they must be specific, proportionate to\nthe threat posed, and \u201cnecessary for the purpose of protecting the public\u201d.\n\nA Crown Prosecution Service spokesperson said: \u201cWhere we perceive there is an\nongoing risk to children\u2019s safety, we will ask the court to impose conditions,\nwhich may involve prohibiting use of certain technology.\u201d\n\nStability AI, the company behind Stable Diffusion, said the concerns about\nchild abuse material related to an earlier version of the software, which was\nreleased to the public by one of its partners. It said that since taking over\nthe exclusive licence in 2022 it had invested in features to prevent misuse\nincluding \u201cfilters to intercept unsafe prompts and outputs\u201d and that it banned\nany use of its services for unlawful activity.\n\nExplore more on these topics\n\n  * Artificial intelligence (AI)\n  * The Observer\n  * Computing\n  * Deepfake\n  * Sex offenders register\n  * Online abuse\n  * Prisons and probation\n  * Crown Prosecution Service\n\nShare\n\nReuse this content\n\n## Most viewed\n\n## Most viewed\n\n  * World\n  * UK\n  * Climate crisis\n  * Ukraine\n  * Environment\n  * Science\n  * Global development\n  * Football\n  * Tech\n  * Business\n  * Obituaries\n\n  * News\n  * Opinion\n  * Sport\n  * Culture\n  * Lifestyle\n\nOriginal reporting and incisive analysis, direct from the Guardian every\nmorning\n\nSign up for our email\n\n  * Help\n  * Complaints & corrections\n  * SecureDrop\n  * Work for us\n  * Privacy policy\n  * Cookie policy\n  * Terms & conditions\n  * Contact us\n\n  * All topics\n  * All writers\n  * Digital newspaper archive\n  * Facebook\n  * YouTube\n  * Instagram\n  * LinkedIn\n  * Twitter\n  * Newsletters\n\n  * Advertise with us\n  * Search UK jobs\n\nBack to top\n\n\u00a9 2024 Guardian News & Media Limited or its affiliated companies. All rights\nreserved. (dcr)\n\n", "frontpage": false}
