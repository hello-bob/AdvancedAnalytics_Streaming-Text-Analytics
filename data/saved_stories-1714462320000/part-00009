{"aid": "40206084", "title": "Chat with PDF locally using Llama 3", "url": "https://recurse.chat/blog/posts/local-docs", "domain": "recurse.chat", "votes": 1, "user": "xyc", "posted_at": "2024-04-30 00:48:44", "comments": 0, "source_title": "Local Docs, Local AI: Chat with PDF locally using Llama 3", "source_text": "Local Docs, Local AI: Chat with PDF locally using Llama 3 | RecurseChat Blog\n\nRecurseChat\n\nPostsTags\n\n# Local Docs, Local AI: Chat with PDF locally using Llama 3\n\nPublished on\n\n    Saturday, April 27, 2024\n\nAuthors\n\n    \n\n  * Name\n    Xiaoyi Chen\nTwitter\n\n    @chxy\n\n## Chat with PDF offline\n\nRecurseChat is a macOS app that helps you use local AI as a daily driver. When\nRecurseChat initially launched on Hacker News, we received overwhelming\nsupport and feedback.\n\n> The app looks great! - ggerganov\n\n> Cool, instant buy for me - brigleb\n\n> Love this! Just purchased. I am constantly harping on decentralized AI and\n> love seeing power in simplicity. - bradnickel\n\nHowever, at the time of this launch, it couldn't converse with your local\ndocuments. A local AI app isn't complete if it can't talk to local documents.\n\nIt's here: RecurseChat now supports chatting with local documents like PDFs\nand markdown completely locally and offline.\n\nHere is how you can start chatting with your local documents using\nRecurseChat: Just drag and drop a PDF file onto the UI, and the app prompts\nyou to download the embedding model and the chat model. This only needs to be\ndone once. Now you have an offline ChatGPT for your PDF files. The responses\nreference the relevant pieces of the original document. Turn off wifi, it\nstill works.\n\n## Meta Llama 3\n\nMeta Llama 3 took the open LLM world by storm, delivering state-of-the-art\nperformance on multiple benchmarks. In version 1.0.101, we added support for\nMeta Llama 3 for local chat completion.\n\nYou can chat with your local documents using Llama 3, without extra\nconfiguration.\n\n## RAG and the Mac App Sandbox\n\nUnder the hood, chat with PDF feature is powered by Retrieval Augmented\nGeneration (RAG).\n\nRecurseChat is the first macOS app on the Mac App Store that performs\nRetrieval Augmented Generation (RAG) completely locally and offline.\n\n\"Wait, but I've seen RAG apps running on macOS before. What's new?\"\n\nGreat question! They are on macOS, but not on the Mac App Store. Is there\nanything different? Here is why it matters: Mac App Store enforced sandboxing,\nwhich means the app runs in a restricted environment.\n\nThe files that RecurseChat can have access to are its data folder (For\nexample, the models downloaded, the database the app uses), the files opened\nby the system dialog, and the files you dragged and dropped onto the UI. Not\nthe same story about non-sandboxed apps. They can access any file on your\nsystem, even data in sandboxed apps.\n\nYou can verify whether an app is secured by Mac App Sandbox by using codesign\ntool in the terminal:\n\n    \n    \n    codesign -d --entitlements - /Applications/RecurseChat.app | grep com.apple.security.app-sandbox\n\nIf the app is sandboxed, you will see an output including\ncom.apple.security.app-sandbox like below:\n\n    \n    \n    Executable=/Applications/RecurseChat.app/Contents/MacOS/RecurseChat [Key] com.apple.security.app-sandbox\n\nTry replacing /Applications/RecurseChat.app with the path to the app you want\nto check. Chances are, your apps downloaded outside of the Mac App Store might\nor might not be sandboxed, but apps from your Mac App Store purchases should\nbe sandboxed, as well as system applications such as Safari\n(/Applications/Safari.app) and QuickTime Player\n(/System/Applications/QuickTime Player.app).\n\nHistorically, Apple has prioritized security in its operating system design.\nThe iOS sandbox was introduced with the launch of iOS in 2007, becoming a core\npart of the iOS security model. iOS apps by default run under sandboxes,\nmaking iOS a highly secure mobile platform. Mac followed the path to introduce\nsandbox in 2011 with the release of OS X 10.7 Lion.\n\nBut because of the diversity of macOS apps, Mac sandbox was only enforced on\napps distributed through the Mac App Store. Even Obsidian.md, a privacy-\nfocused app, did not implement App Sandbox. (We absolutley love Obsidian as a\ntool, and we find ourselves resonating with Obsidian's philosophy, but we\nthink Obsidian could benefit from sandbox security mechanism, especially given\nthe variety of community plugins.)\n\nAlthough developing a sandboxed app is non-trivial, privacy is of paramount\nimportance as a principle of RecurseChat. We have ensured RecurseChat works\ninside the app sandbox and still has a smooth UX. The sandbox mechanism serves\nas a foundation for developing private and personalized AI apps.\n\n## RAG stack\n\nLet's go into details of the RAG implementation. Our RAG stack is powered by\nthe following technologies:\n\n### Chunking\n\nPDF file is parsed into text content using PDF.js, then chunked using\nlangchain.\n\n### Embedding\n\nThe chunks are then embedded using llama.cpp embedding model. At this moment,\nwe support FlagEmbedding. In the future, we will support more embedding\nmodels.\n\nSince we provide direct access to the underlying llama.cpp server ^1, You can\nalso use the API to embed text content of your choice if you are interested.\n\nFor example, you can embed text content using the following API call:\n\n    \n    \n    curl http://localhost:15242/v1/embeddings \\ -H \"Content-Type: application/json\" \\ -H \"Authorization: Bearer no-key\" \\ -d '{ \"input\": \"hello\" }'\n\nResponse will be in the following format:\n\n    \n    \n    {\"data\":[{\"embedding\":[0.0006718881777487695,0.0426122322678566,0.020298413932323456,...]}]}\n\n### Vector Database\n\nVector DB is a highly contested field in RAG applications. Superlinked has a\nnice comparison table of 38 vector databases to choose from.\n\nWe settled down on Qdrant, a high-performance vector database developed in\nRust, for its superior performance ^2 and production readiness ^3. The vector\ndatabase runs locally on your machine. Once a document is indexed, we store\nthe embeddings in the vector database. The document does not need to be re-\nindexed unless it's modified, making follow-up queries fast. When we store the\nembeddings, we also store the metadata of the document, so that we can provide\ncitations to the original document.\n\nWe also offer a couple of convenient shortcuts for managing the local vector\ndatabase, so you can manage the storage or perform customized queries. You\nhave ownership over your document index.\n\nFor example, you can open Qdrant dashboard and visualize your document\nembeddings:\n\n### Augment Query\n\nWhen you chat with the document, the query is augmented with the context based\non the similarity of the query to the document embeddings. The augmented query\nis then passed to the chat completion model.\n\n### Chat completion\n\nFor local models, we use llama.cpp for chat completion. If you choose a local\nmodel for chat completion, the app works completely offline.\n\nFor OpenAI compatible models, we use OpenAI SDK for chat completion. This\nallows us to support online providers like Groq and Together AI, as well as\nendpoints that support OpenAI compatible API such as Ollama. If you use an\nonline LLM provider, you don't need to worry about incurring a large embedding\ncost as you only pay for the chat completion API.\n\n## What's next?\n\nMany of our users have quite a few documents that they want as a persistent\ncontext of their conversations. We are working on making chatting with your\nwealth of local documents easier.\n\nWe'd also love to hear about your ideal local document workflows and use\ncases, and how we can make RecurseChat more useful for you. Feel free to reach\nout to us on Twitter or Email.\n\n## Footnotes\n\n  1. You can start a llama.cpp server with -m param pointing to your embedding GGUF model and --embedding to enable embedding. \u21a9\n\n  2. Qdrant Benchmark: https://qdrant.tech/benchmarks/ \u21a9\n\n  3. According to https://github.com/orgs/qdrant/discussions/2914#discussioncomment-7455058, Qdrant scales to billions of vectors. \u21a9\n\nDiscuss on Twitter\n\n## Tags\n\npdfllama-3rag\n\n\u2190 Back to the blog\n\nRecurseChat\n\n\u2022\n\n\u00a9 2024\n\n\u2022\n\nRecurseChat Blog\n\n", "frontpage": false}
