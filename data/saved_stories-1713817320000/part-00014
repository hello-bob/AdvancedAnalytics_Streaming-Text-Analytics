{"aid": "40114557", "title": "I Doubt That AI Can Match the Human Mind", "url": "https://mindmatters.ai/2019/02/why-i-doubt-that-ai-can-match-the-human-mind/", "domain": "mindmatters.ai", "votes": 8, "user": "udev4096", "posted_at": "2024-04-22 14:09:51", "comments": 0, "source_title": "Why I Doubt That AI Can Match the Human Mind", "source_text": "Why I Doubt That AI Can Match the Human Mind | Mind Matters\n\nMind Matters _Natural and Artificial Intelligence News and Analysis\n\n  * Articles\n  * Podcast\n  * Videos\n  * Subscribe\n  * Donate\n  * Search\n\nWater droplet on glossy surface of freshness orange and red apple\n\n^\n\n    Jonathan Bartlett\n    February 25, 2019\n    6\n    Artificial Intelligence, Philosophy of Mind\n\n# Why I Doubt That AI Can Match the Human Mind\n\n_Computers are exclusively theorem generators, while humans appear to be axiom\ngenerators _\n\n    Jonathan Bartlett\n    February 25, 2019\n    6\n    Artificial Intelligence, Philosophy of Mind\n\nShare\n\n    Facebook\n    Twitter\n    LinkedIn\n    Flipboard\n    Print\n    Email\n\nA reader wrote recently to ask why, in the midst of numerous recent artificial\nintelligence (AI) advances, at Mind Matters we remain skeptical of the ability\nof AI to match human cognitive abilities. My response requires a bit more\ntechnical background than I usually need to provide but sometimes it\u2019s\nunavoidable. (If you want to go directly to a less technical version, here\u2019s a\ntalk I gave recently on a similar subject.)\n\nFirst, though, cognitive ability is only one aspect of intelligence. Those who\nthink that artificial intelligence will eventually equal human intelligence\nface many hurdles, including problems of consciousness, emotion, etc. Here, we\nare looking at only one problem\u2014cognitive ability.\n\nConsider the difference between axioms and theorems. An axiom is a\nfoundational truth, which cannot be proven within the system in which it\noperates. A theorem is a derivative truth, whose truth value we can know based\non axioms. Computers are exclusively theorem generators, while humans appear\nto be axiom generators.\n\nComputers are much better than humans at processing theorems\u2014by several orders\nof magnitude. However, they are limited by the fact that they cannot establish\naxioms. They are entirely boxed into their own axiomatic rules.\n\nYou can see this in several aspects of computer science. The Halting Problem\nis probably the best known. In essence, you cannot create a computer program\nthat will tell if another arbitrarily chosen program will ever finish. In\nfact, the problem is deeper than that: While the Halting Problem itself comes\nwith a handy proof (which is why it is so often cited), we also find that\nabsent outside information, computers have trouble telling if practically any\nprogram with loops will complete without directly running the program to\ncompletion. That is, I can program a computer to recognize certain traits of\nhalters and/or non-halters. But without that programming, it cannot tell the\ndifference. I have to add axioms to the program in order to process the\ninformation.\n\nGiven a set of axioms, computers can produce theorems very swiftly. But no\nincrease in speed allows them to jump the theorem/axiom gap. AI research\nidentifies the axioms needed to solve certain types of problems and then lets\nthe computer loose to calculate theorems that depend on them.\n\nAI research also creates more and more powerful axioms. That is, a previous\ngeneration may have started with axioms A, B, and C, but current generations\nhave found more fundamental axioms, D, E, and F which reduce A, B, and C to\ntheorems.\n\nA question now appears: Is there a super-axiom that allows all of these axioms\nto be reduced to theorems? The answer is no. The same logic that shows that\nthe Halting Problem can\u2019t be solved can be used to show why the super-axiom\ndoes not exist. This distinction is essentially the same as the one between\nfirst-order and second-order logic.\n\nComputers cannot process second-order logical statements in the same way as\nfirst-order logical statements. Some systems are described as second-order\nlogic processors but they work is by picking out a subset of second order\npropositions, reducing them to first-order propositions, and then processing\nthem as first-order logic. This is identical to the process I mentioned with\nrespect to the Halting Problem. Humans can identify specific traits that\nwill/will not halt and have the computer identify those traits but the\ncomputer itself cannot generate them on its own.\n\nIn fact, if I were to hazard a guess, I would say that the point where\ncomputers break down is infinity. The halting problem deals with identifying\nprograms that will have infinite states and second-order logic deals with\npropositions that require an infinite number of comparisons. As I mentioned,\nafter humans discover truths about them, we can encode these specific truths\nas new axioms into the system. But computers cannot discover the truths by\nthemselves. For instance, try to imagine how a computer program (AI or\notherwise) could establish the well-ordering property of the natural numbers\nwithout using any other second-order logic operation (or even try to do so!).\n\nAdditionally, all of the axioms considered so far are dependent axioms. That\nis, given a system, these axioms are implied by the system even though they\naren\u2019t deducible from it. However, there are other types of axioms which are\nindependent and set the ground rules of the system to begin with. These are\neven more general axioms that go outside the system altogether. An example of\na system that is outside another system is non-Euclidian geometries. Non-\nEuclidian geometries operate by swapping out some of the fundamental Euclidian\naxioms for other axioms.\n\nSo, in all of these cases, we can see that humans are supplying axioms and\ncomputers are processing the axioms into theorems. The computer is never the\nsupplier of the axiom.\n\nNow, here\u2019s a criticism someone might offer: Perhaps humans are much more\nlimited than we realize. We have a fixed set of axioms and we are merely\nincreasing our ability to express them. At some point, we are going to exhaust\nthe number of axioms that we can actually process. If that happened, it is\nvery possible that computers will achieve parity with humans in this realm.\nBut it would also mean the end of science and mathematics.\n\nHowever, I think that the history of science and mathematics suggests that\nhumans will continue to generate axioms through time. The discoveries of\nmathematics through history are real discoveries of new axioms. A human grasp\nof infinity enables us to pull in axioms when they are needed (as I discuss in\nthis paper, \u201cUsing Turing Oracles in Cognitive Models of Problem-Solving\u201d\n(open access).\n\nIn summary, my primary reason for doubting that AI can match human\nintelligence is that the difference between mind and machine is a difference\nof kind, not of quantity. Understanding the distinction will help us exploit\nthe abilities of each to their maximum potential. There are other reasons for\ndoubting the future equivalence of AI and human intelligence, but this is the\none I would consider first.\n\nJonathan Bartlett\n\nJonathan Bartlett is the Research and Education Director of the Blyth\nInstitute.\n\nNote: Many consider the theory of artificial intelligence a foregone\nconclusion due to materialism, and it is just up to the computer scientists to\nfigure out the details. But, what if materialism is not the only game in town?\nDiscover the exciting new scientific frontier of methodological holism in the\nnew journal Communications of the Blyth Institute.\n\nAlso by Jonathan Bartlett: Google Search: It\u2019s Secret of Success Revealed\n\nand\n\nDid AI show that we are \u201ca peaceful species\u201d triggered by religion?\n\nAlso: Human intelligence as a Halting Oracle (Eric Holloway)\n\n# ^Why I Doubt That AI Can Match the Human Mind\n\n  * About\n  * The Center\n  * Grants\n  * Research\n  * Subscribe\n\nSubscribe\n\n  * Apple Podcasts\n  * Spotify\n  * TuneIn\n  * RSS\n\nTopics\n\n  * Androids, Robots, Drones, and Machines\n  * Apocalypticism, Dystopia, and the Singularity\n  * Applied Intelligence, Problem Solving, and Innovation\n  * Artificial Intelligence\n  * Automation, Jobs, and Training\n  * Government Policy\n  * Hype and Limits\n  * Mind, Brain, and Human Intelligence\n  * Natural Human, Animal, and Organismic Intelligence\n  * Philosophy of Mind\n  * Sci-fi Saturdays\n  * Social Factors\n  * Technocracy and Big Tech\n  * Transhumanism\n\nAuthors\n\n  * Contributors\n  * Jonathan Bartlett\n  * William A. Dembski\n  * Brendan Dixon\n  * Michael Egnor\n  * Winston Ewert\n  * Eric Holloway\n  * Erik J. Larson\n  * Robert J. Marks\n  * Adam Nieri\n  * Denyse O\u2019Leary\n  * Gary Smith\n  * Richard W. Stevens\n  * Gary Varner\n  * Heather Zeiger\n\nSubscribe\n\n  * Apple Podcasts\n  * Spotify\n  * TuneIn\n  * RSS\n\nEpisodes\n\n  * The Non-Physical Nature of Being: More with Dr. Selmer Bringsjord\n  * Exploring the Immaterial: A Conversation with Dr. Selmer Bringsjord\n  * Is Methodological Naturalism Necessary for Scientific Progress?\n  * The State of Innovation and the Impact of AI\n  * Consciousness and Agency: A Critique of Methodological Naturalism\n\nArticles\n\n  * Joe Rogan Spins Bizarre Take on Evolution and AI\n  * Helpful Video Maps Out Gen Z Mental Health Crisis\n  * More COSM 2023 Videos on YouTube!\n  * Remote Work: Liberation or a Major Step Back?\n  * Doc Ock and His Sentient AI Arms\n\nTopics\n\n  * Androids, Robots, Drones, and Machines\n  * Apocalypticism, Dystopia, and the Singularity\n  * Applied Intelligence, Problem Solving, and Innovation\n  * Artificial Intelligence\n  * Automation, Jobs, and Training\n  * Government Policy\n  * Hype and Limits\n  * Mind, Brain, and Human Intelligence\n  * Natural Human, Animal, and Organismic Intelligence\n  * Philosophy of Mind\n  * Sci-fi Saturdays\n  * Social Factors\n  * Technocracy and Big Tech\n  * Transhumanism\n\nFooter Logos\n\nDiscovery Institute Center for Natural and Artificial Intelligence\n\nAbout Mind Matters and The Center for Intelligence\n\nMind Matters features original news and analysis at the intersection of\nartificial and natural intelligence. Through articles and podcasts, it\nexplores issues, challenges, and controversies relating to human and\nartificial intelligence from a perspective that values the unique capabilities\nof human beings. Mind Matters is published by the Walter Bradley Center for\nNatural and Artificial Intelligence.\n\nFollow\n\n  * Articles\n  * Episodes\n  * About\n  * Subscribe\n  * Donate\n\n1x\n\n", "frontpage": true}
