{"aid": "40178636", "title": "What can language models do?", "url": "https://every.to/chain-of-thought/what-can-language-models-actually-do", "domain": "every.to/chain-of-thought", "votes": 1, "user": "dshipper", "posted_at": "2024-04-27 09:35:36", "comments": 0, "source_title": "What Can Language Models Actually Do?", "source_text": "What Can Language Models Actually Do?\n\nSubscribe\n\n\u2261\n\n  * About\n  * Collections\n  * Contact Us\n  * Sponsor Us\n  * Login\n\nChain of Thought\n\n# What Can Language Models Actually Do?\n\nPart one: Language models as text compressors\n\nby Dan Shipper\n\nApril 26, 2024\n\n37 3\n\nDALL-E/Every illustration.\n\nThis is the first of a five-part series I'm writing about redefining human\ncreativity in the age of AI.\n\nSubscribe\n\nI want to help save our idea of human creativity.\n\nArtificial intelligence can write, illustrate, design, code, and much more.\nBut rather than eliminating the need for human creativity, these new powers\ncan help us redefine and expand it.\n\nWe need to do a technological dissection of language models, defining what\nthey can do well\u2014and what they can\u2019t. By doing so, we can isolate our own role\nin the creative process.\n\nIf we can do that, we\u2019ll be able to wield language models for creative\nwork\u2014and still call it creativity.\n\nTo start, let\u2019s talk about what language models can do.\n\n## The psychology and behavior of language models\n\nThe current generation of language models is called transformers, and in order\nto understand what they do, we need to take that word seriously. What kind of\ntransformations can transformers do?\n\nMathematically, language models are recursive next-token predictors. They are\ngiven a sequence of text and predict the next bit of text in the sequence.\nThis process runs over and over in a loop, building upon its previous outputs\nself-referentially until it reaches a stopping point. It\u2019s sort of like a\nsnowball rolling downhill and picking up more and more snow along the way.\n\nBut this question is best asked at a higher level than simply mathematical\npossibility. Instead, what are the inputs and outputs we observe from today\u2019s\nlanguage models? And what can we infer about how they think?\n\nIn essence, we need to study LLMs\u2019 behavior and psychology, rather than their\nbiology and physics.\n\nThis is a sketch based on experience. It\u2019s a framework I\u2019ve built for the\npurposes of doing great creative work with AI.\n\n## A framework for what language models do\n\nLanguage models transform text in the following ways:\n\n  * Compression: They compress a big prompt into a short response.\n  * Expansion: They expand a short prompt into a long response.\n  * Translation: They convert a prompt in one form into a response in another form.\n\nThese are manifestations of their outward behavior. From there, we can infer a\nproperty of their psychology\u2014the underlying thinking process that creates\ntheir behavior:\n\n  * Remixing: They mix two or more texts (or learned representations of texts) together and interpolate between them.\n\nI\u2019m going to break down these elements in successive parts of this series over\nthe next few weeks. None of these answers are final, so consider this a public\nexploration that\u2019s open for critique. Today, I want to talk to you about the\nfirst operation: compression.\n\n## Language models as compressors\n\nLanguage models can take any piece of text and make it smaller:\n\nSource: All images courtesy of the author.\n\nThis might seem simple, but, in fact, it\u2019s a marvel. Language models can take\na big chunk of text and smush it down like a foot crushing a can of Coke.\nExcept it doesn\u2019t come out crushed\u2014it comes out as a perfectly packaged and\nproportional mini-Coke. And it\u2019s even drinkable! This is a Willy Wonka-esque\nmagic trick, without the Oompa Loompas.\n\nLanguage model compression comes in many different flavors. A common one is\nwhat I\u2019ll call comprehensive compression, or summarization.\n\n## Language models are comprehensive compressors\n\nHumans comprehensively compress things all the time\u2014it\u2019s called summarization.\nLanguage models are good at it in the same way a fifth grader summarizes a\nchildren\u2019s novel for a book report, or the app Blinkist summarizes nonfiction\nbooks for busy professionals.\n\nThis kind of summarizing is intended to take a source text, pick out the ideas\nthat explain its main points for a general reader, and reconstitute those into\na compressed form for faster consumption:\n\nThese summaries are intended to be both comprehensive (they note all the main\nideas) and helpful for the average reader (they express the main ideas at a\nhigh level with little background knowledge assumed).\n\nIn the same way, a language model like Anthropic\u2019s Claude, given the text of\nthe Ursula K. LeGuin classic A Wizard of Earthsea, will easily output a\ncomprehensive summary of the book\u2019s main plot points:\n\nBut comprehensive compression isn\u2019t the only thing language models can do. You\ncan compress text without being comprehensive\u2014which creates room for totally\ndifferent forms of compression.\n\n### Language models are engaging compressors\n\nIf we require our compression to be interesting instead of comprehensive,\ncompressions look less like book reports and more like email subject lines,\narticle headlines, book titles, and subtitles. If we graphed them by how much\nattention is required to consume them, it would look like this:\n\nThrough this lens, book titles are just as much a compression as a kid\u2019s book\nreport; they just prioritize different requirements for what the compression\nis trying to capture. Language models excel at this type of compression, too.\n\nFor example, at Every we use an internal AI tool to help us turn the content\nof our stories into headlines. It\u2019s specifically aimed at interestingness, as\nopposed to comprehensiveness. When I fed it the text of A Wizard of Earthsea,\nit suggested these titles:\n\n  * The Shadow's Name\n  * The Warrior Mage's Shadow Quest\n  * The Shadow Defeated\n\nThese are pretty good! But language model compression doesn\u2019t stop at just\nthese two dimensions of compression.\n\n## Language models compress over many different dimensions\n\nThere are many dimensions along which compression can be run. Here are some\nexamples of headlines, all written by Claude:\n\n  * Clickbaiting: \"You Won\u2019t Believe What This Young Wizard Discovered on a Shadow Isle!\"\n  * Intrigue: \"Secrets of the Shadowy Mage Isle\"\n  * Vibe-y: \"chill wizard explores shady island, finds self\"\n  * Alliteration: \"The Wizard\u2019s Winding, Wondrous Wanderings\"\n  * Snark: \"Oh, Another 'Chosen One' Wizard Story Set on an Island, How Original\"\n  * Paranoia: \"They\u2019re Watching: A Wizard\u2019s Harrowing Shadow Odyssey\"\n  * Pessimism: \"The Gloomy Account of a Doomed Mage on Hopeless Shadow Rock\"\n  * Confusion: \"Wait, What's Happening? A Wizard Goes Somewhere Shadowy, I Think?\"\n  * Absurdist: \"Schr\u00f6dinger's Wizard Simultaneously Visits and Doesn't Visit Shadow Isle\"\n  * Ironic detachment: \"I Guess This Wizard Goes to Some Dumb Island or Whatever\"\n  * Gaslighting: \"There Is No Shadow Isle, You're Just Imagining Things\"\n\nWhen we started talking about compression, we began with this graphic:\n\nIf we wanted to revise it with our expanded idea of compression along many\ndifferent dimensions, we might do something like this:\n\nLanguage model compression doesn\u2019t just turn a large gray rectangle into a\nsmall gray rectangle. It can turn it into a tiny rectangle, or a red rectangle\nwith rounded corners, or an elongated rectangle with a gradient fill.\n\nSubscribe\n\nEach of the outputs of compression carry some family resemblance to the\noriginal input. In other words, there\u2019s always some amount of common overlap\nbetween the prompt and response, but the exact overlap (and the areas of\ndifference) is going to depend on the type of compression you\u2019re running.\n\nThe dimensions of compression can also be arbitrarily specific and combined\ntogether. Here are some example prompts:\n\n  * A tweet in the style of Dan Shipper but with more snark and paranoia\n  * Analysis in the style of George Saunders but make it gaslight-y\n  * A book summary in the style of a Scott Alexander book review, but make it concise\n\nFor example, using the last prompt as a jumping-off point, here\u2019s a concise\nbook summary of A Wizard of Earthsea that Claude created in the style of Scott\nAlexander from Slate Star Codex:\n\n> \u201cA Wizard of Earthsea is about the dangers of power without wisdom.\n\n> The young wizard Ged, in a fit of youthful pride and anger, summons a shadow\n> creature from the realm of the dead. This goes about as well as you would\n> expect. The shadow hunts Ged across the world and he must flee from it,\n> until finally his old master tells him that he can't run away from his own\n> shadow. Ged realizes that the only way out is through\u2014he has to turn around,\n> chase down the shadow, and reintegrate it into himself.\n\n> This is a pretty standard \"power corrupts\" story, but it's unusually wise in\n> depicting Ged's flaw not as a desire for power itself, but as a lack of\n> education in how to use power. Ged isn't evil, he's just young and dumb.\n\n> His eventual victory comes from understanding how the universe works, not\n> from overwhelming firepower. The real treasure was the wisdom he gained\n> along the way.\n\n> Le Guin once said her books were about \u2018the journey that is inward, and not\n> the other journey.\u2019\n\n> A Wizard of Earthsea literalizes this, as Ged sails further and further away\n> from the known lands in pursuit of his shadow, only to realize he has to\n> integrate it back into himself. We all have to take this journey eventually.\n> The shadow represents the parts of ourselves we try to deny and push away.\n> But there's no escape\u2014in the end, the only way to grow is to acknowledge\n> your shadow, accept it, and become whole.\u201d\n\nI don\u2019t know if this is exactly what Scott Alexander would write about A\nWizard of Earthsea, but it\u2019s certainly in the neighborhood. There are a few\nthings it gets right. The first line is a concise, engaging summary of the\nbook\u2019s main point, which Alexander does better than almost anyone. And the\nline, \u201cThis is a pretty standard \u2018power corrupts\u2019 story,\u201d feels very much like\nhis voice.\n\nSo we\u2019ve made some progress. Our concept of language models as compressors now\nincludes the idea that they \u201ccompress\u201d text across an arbitrary number of\ndimensions or requirements.\n\nWhen is that useful in creative work?\n\n## Why compression is useful\n\nLet\u2019s start with comprehensive compressions like book reports. If we graphed\nthem by the amount of depth they convey and attention they require, they would\nprobably be on the bottom-left quadrant of the graph\u2014little depth, little\nattention required:\n\nThings that exist in this bottom-left quadrant have a pejorative connotation\nbecause they require a low level of engagement with a complex idea:\n\nComprehensive compressions are the McDonald\u2019s french fries of the intellectual\nlandscape: ubiquitous, tasty, cheap, and low status.\n\nBut this kind of summary is an important output of creative work because it\nrespects the fundamentally limited attention of human beings. Humans need to\nroam widely over the intellectual landscape before they go deep, and this kind\nof summary allows us to sample ideas that might be useful without a lot of\ninvestment. In that way, it\u2019s like a mini-advertisement for the idea it\ncontains\u2014like a blooming flower is an advertisement for nectar.\n\nThe trouble is that doing compressions like this is, generally, drudgery.\nAnyone who has had to write a summary of their essay for an X post, or has\nneeded to spend a few hours rereading a complex topic so that they could\nsummarize it in a few sentences, will know what I mean.\n\nBut language models are good at compression that sits more at the bottom of\nthe funnel of engagement with ideas, too. They help you go deeper into the\nnuances of an idea instead of just skimming the surface:\n\nIn a needle-in-the-haystack compression, they can find the answer to a\ndifficult question in a long piece of text. For example, I\u2019ve long been a fan\nof Ludwig Wittgenstein\u2019s philosophical thinking, but his writing is incredibly\ndense. I\u2019ve fed one of his books into Claude and gotten answers to specific\nquestions\u2014which is a compression of the book into a form that\u2019s usable for me:\n\nInstead of puzzling over the text, I can think up new ideas and create new\npieces of writing that were previously impossible. There\u2019s too much\ninformation to consume, and it\u2019s too complicated for me to understand without\nthis kind of support.\n\nOnce you start to look at things this way, you\u2019ll see compression everywhere.\nEmails are often compressions of what people said in meetings. Poems are\ncompressions of sensory experiences. Good decisions are compressions of the\nresults of previous decisions. Basic programming is compressions of Stack\nOverflow answers.\n\nThis view of the world will help you see a significant chunk of the situations\nin which language models can be useful for creative work.\n\nAs the cognitive scientist Alison Gopnik has written, language models are\ncultural technologies. They give us the best of what humanity knows about any\ntopic\u2014in the right form for any given context. In that way, language models\nare an extension of a trend that started with writing itself and has extended\nto the printing press, the internet, and finally our present moment with AI.\n\nThis is a superpower for creatives:\n\nKnowledge can make its way to you\u2014wherever you are, whenever you need it,\ncompressed in just the right format for you to use.\n\nWhat do you want to make with it?\n\n\u2014\n\nNext week, we\u2019ll talk about language models\u2019 next operation:\n\nExpansion.\n\nDan Shipper is the cofounder and CEO of Every, where he writes the Chain of\nThought column and hosts the podcast How Do You Use ChatGPT? You can follow\nhim on X at @danshipper and on LinkedIn, and Every on X at @every and on\nLinkedIn.\n\nSubscribe\n\n#### What did you think of this post?\n\nAmazing Good Meh Bad\n\n### Like this? Become a subscriber.\n\nSubscribe \u2192\n\nOr, learn more.\n\n## Read this next:\n\nChain of Thought\n\n## Can a Startup Kill ChatGPT?\n\nGoogle is dangerous\u2014a founder cracked on Zyn and Diet Coke more so\n\n247 2 Mar 15, 2024 by Dan Shipper\n\nChain of Thought\n\n## GPT-4 Can Use Tools Now\u2014That\u2019s a Big Deal\n\nWhat \"function calling\" is, how it works, and what it means\n\n159 3 Jun 16, 2023 by Dan Shipper\n\nChain of Thought\n\n## How Hard Should I Push Myself?\n\nWhat the science of stress tells us about peak performance\n\n161 2 Oct 17, 2023 by Dan Shipper\n\nThanks for rating this post\u2014join the conversation by commenting below.\n\n## Comments\n\n@german88castillo about 14 hours ago\n\nWas a bit skeptical at first but blown away by the end. Great stuff.\n\n\u2661 1 \u00b7 Reply\n\nDan Shipper about 14 hours ago\n\n@german88castillo thanks!!\n\n\u2661 0 \u00b7 Reply\n\n@nicky_5977 6 minutes ago\n\nIncredible writing Dan ;-)\n\nI loved the way you re told the GenAI story in your own authentic voice. I am\nwith you in that it helps one dig deeper when it comes to collaboration\ncreativity & LLM\u2019s.\n\nI find that as I interact with Claude, and iterate on the output, the best of\nwhat I want to say, eventually does come out.\n\nThank you for making my Saturday morning.\n\n\u2661 0 \u00b7 Reply\n\n## Every smart person you know is reading this newsletter\n\nGet one actionable essay a day on AI, tech, and personal development\n\nSubscribe\n\nAlready a subscriber? Login\n\nContact Us \u00b7 Sponsor Us \u00b7 Search \u00b7 Terms\n\n\u00a92024 Every Media, Inc\n\nBy continuing to browse the site, you agree to our use of cookies.\n\n", "frontpage": false}
