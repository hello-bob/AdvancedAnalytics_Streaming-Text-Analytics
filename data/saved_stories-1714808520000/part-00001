{"aid": "40252330", "title": "LocalAI: Self-hosted OpenAI alternative reaches 2.14.0", "url": "https://github.com/mudler/LocalAI/releases/tag/v2.14.0", "domain": "github.com/mudler", "votes": 1, "user": "mudler", "posted_at": "2024-05-03 21:00:03", "comments": 0, "source_title": "Release v2.14.0 \u00b7 mudler/LocalAI", "source_text": "Release v2.14.0 \u00b7 mudler/LocalAI \u00b7 GitHub\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nmudler / LocalAI Public\n\n  * Notifications\n  * Fork 1.5k\n  * Star 19.9k\n\n# v2.14.0\n\nLatest\n\nLatest\n\nmudler released this 03 May 07:29\n\nv2.14.0\n\nb58274b\n\n## \ud83d\ude80 AIO Image Update: llama3 has landed!\n\nWe're excited to announce that our AIO image has been upgraded with the latest\nLLM model, llama3, enhancing our capabilities with more accurate and dynamic\nresponses. Behind the scenes uses\nhttps://huggingface.co/NousResearch/Hermes-2-Pro-Llama-3-8B-GGUF which is\nready for function call, yay!\n\n## \ud83d\udcac WebUI enhancements: Updates in Chat, Image Generation, and TTS\n\nChat| TTS| Image gen  \n---|---|---  \n  \nOur interfaces for Chat, Text-to-Speech (TTS), and Image Generation have\nfinally landed. Enjoy streamlined and simple interactions thanks to the\nefforts of our team, led by @mudler, who have worked tirelessly to enhance\nyour experience. The WebUI interface serves as a quick way to debug and assess\nmodels loaded in LocalAI - there is much to improve, but we have now a small,\nhackable interface!\n\n## \ud83d\uddbc\ufe0f Many new models in the model gallery!\n\nThe model gallery has received a substantial upgrade with numerous new models,\nincluding Einstein v6.1, SOVL, and several specialized Llama3 iterations.\nThese additions are designed to cater to a broader range of tasks , making\nLocalAI more versatile than ever. Kudos to @mudler for spearheading these\nexciting updates - now you can select with a couple of click the model you\nlike!\n\n## \ud83d\udee0\ufe0f Robust Fixes and Optimizations\n\nThis update brings a series of crucial bug fixes and security enhancements to\nensure our platform remains secure and efficient. Special thanks to @dave-\ngray101, @cryptk, and @fakezeta for their diligent work in rooting out and\nresolving these issues \ud83e\udd17\n\n## \u2728 OpenVINO and more\n\nWe're introducing OpenVINO acceleration, and many OpenVINO models in the\ngallery. You can now enjoy fast-as-hell speed on Intel CPU and GPUs. Applause\nto @fakezeta for the contributions!\n\n## \ud83d\udcda Documentation and Dependency Upgrades\n\nWe've updated our documentation and dependencies to keep you equipped with the\nlatest tools and knowledge. These updates ensure that LocalAI remains a robust\nand dependable platform.\n\n## \ud83d\udc65 A Community Effort\n\nA special shout-out to our new contributors, @QuinnPiers and @LeonSijiaLu, who\nhave enriched our community with their first contributions. Welcome aboard,\nand thank you for your dedication and fresh insights!\n\nEach update in this release not only enhances our platform's capabilities but\nalso ensures a safer and more user-friendly experience. We are excited to see\nhow our users leverage these new features in their projects, freel free to hit\na line on Twitter or in any other social, we'd be happy to hear how you use\nLocalAI!\n\n## \ud83d\udce3 Spread the word!\n\nFirst off, a massive thank you (again!) to each and every one of you who've\nchipped in to squash bugs and suggest cool new features for LocalAI. Your\nhelp, kind words, and brilliant ideas are truly appreciated - more than words\ncan say!\n\nAnd to those of you who've been heros, giving up your own time to help out\nfellow users on Discord and in our repo, you're absolutely amazing. We\ncouldn't have asked for a better community.\n\nJust so you know, LocalAI doesn't have the luxury of big corporate sponsors\nbehind it. It's all us, folks. So, if you've found value in what we're\nbuilding together and want to keep the momentum going, consider showing your\nsupport. A little shoutout on your favorite social platforms using\n@LocalAI_OSS and @mudler_it or joining our sponsors can make a big difference.\n\nAlso, if you haven't yet joined our Discord, come on over! Here's the link:\nhttps://discord.gg/uJAeKSAGDy\n\nEvery bit of support, every mention, and every star adds up and helps us keep\nthis ship sailing. Let's keep making LocalAI awesome together!\n\nThanks a ton, and.. exciting times ahead with LocalAI!\n\n## What's Changed\n\n### Bug fixes \ud83d\udc1b\n\n  * fix: config_file_watcher.go - root all file reads for safety by @dave-gray101 in #2144\n  * fix: github bump_docs.sh regex to drop emoji and other text by @dave-gray101 in #2180\n  * fix: undefined symbol: iJIT_NotifyEvent in import torch ##2153 by @fakezeta in #2179\n  * fix: security scanner warning noise: error handlers part 2 by @dave-gray101 in #2145\n  * fix: ensure GNUMake jobserver is passed through to whisper.cpp build by @cryptk in #2187\n  * fix: bring everything onto the same GRPC version to fix tests by @cryptk in #2199\n\n### Exciting New Features \ud83c\udf89\n\n  * feat(gallery): display job status also during navigation by @mudler in #2151\n  * feat: cleanup Dockerfile and make final image a little smaller by @cryptk in #2146\n  * fix: swap to WHISPER_CUDA per deprecation message from whisper.cpp by @cryptk in #2170\n  * feat: only keep the build artifacts from the grpc build by @cryptk in #2172\n  * feat(gallery): support model deletion by @mudler in #2173\n  * refactor(application): introduce application global state by @dave-gray101 in #2072\n  * feat: organize Dockerfile into distinct sections by @cryptk in #2181\n  * feat: OpenVINO acceleration for embeddings in transformer backend by @fakezeta in #2190\n  * chore: update go-stablediffusion to latest commit with Make jobserver fix by @cryptk in #2197\n  * feat: user defined inference device for CUDA and OpenVINO by @fakezeta in #2212\n  * feat(ux): Add chat, tts, and image-gen pages to the WebUI by @mudler in #2222\n  * feat(aio): switch to llama3-based for LLM by @mudler in #2225\n  * feat(ui): support multilineand style ul by @mudler in #2226\n\n### \ud83e\udde0 Models\n\n  * models(gallery): add Einstein v6.1 by @mudler in #2152\n  * models(gallery): add SOVL by @mudler in #2154\n  * models(gallery): add average_normie by @mudler in #2155\n  * models(gallery): add solana by @mudler in #2157\n  * models(gallery): add poppy porpoise by @mudler in #2158\n  * models(gallery): add Undi95/Llama-3-LewdPlay-8B-evo-GGUF by @mudler in #2160\n  * models(gallery): add biomistral-7b by @mudler in #2161\n  * models(gallery): add llama3-32k by @mudler in #2183\n  * models(gallery): add openvino models by @mudler in #2184\n  * models(gallery): add lexifun by @mudler in #2193\n  * models(gallery): add suzume-llama-3-8B-multilingual-gguf by @mudler in #2194\n  * models(gallery): add guillaumetell by @mudler in #2195\n  * models(gallery): add wizardlm2 by @mudler in #2209\n  * models(gallery): Add Hermes-2-Pro-Llama-3-8B-GGUF by @mudler in #2218\n\n### \ud83d\udcd6 Documentation and examples\n\n  * \u2b06\ufe0f Update docs version mudler/LocalAI by @localai-bot in #2149\n  * draft:Update model-gallery.md with correct gallery file by @QuinnPiers in #2163\n  * docs: update gallery, add rerankers by @mudler in #2166\n  * docs: enhance and condense few sections by @mudler in #2178\n  * [Documentations] Removed invalid numberings from troubleshooting mac by @LeonSijiaLu in #2174\n\n### \ud83d\udc52 Dependencies\n\n  * \u2b06\ufe0f Update ggerganov/llama.cpp by @localai-bot in #2150\n  * \u2b06\ufe0f Update ggerganov/llama.cpp by @localai-bot in #2159\n  * \u2b06\ufe0f Update ggerganov/llama.cpp by @localai-bot in #2176\n  * \u2b06\ufe0f Update ggerganov/whisper.cpp by @localai-bot in #2177\n  * update go-tinydream to latest commit by @cryptk in #2182\n  * build(deps): bump dependabot/fetch-metadata from 2.0.0 to 2.1.0 by @dependabot in #2186\n  * \u2b06\ufe0f Update ggerganov/llama.cpp by @localai-bot in #2189\n  * \u2b06\ufe0f Update ggerganov/whisper.cpp by @localai-bot in #2188\n  * \u2b06\ufe0f Update ggerganov/llama.cpp by @localai-bot in #2203\n  * \u2b06\ufe0f Update ggerganov/llama.cpp by @localai-bot in #2213\n\n### Other Changes\n\n  * Revert \":arrow_up: Update docs version mudler/LocalAI\" by @mudler in #2165\n  * Issue-1720: Updated Build on mac documentations by @LeonSijiaLu in #2171\n  * \u2b06\ufe0f Update ggerganov/llama.cpp by @localai-bot in #2224\n\n## New Contributors\n\n  * @QuinnPiers made their first contribution in #2163\n  * @LeonSijiaLu made their first contribution in #2171\n\nFull Changelog: v2.13.0...v2.14.0\n\n### Contributors\n\ncryptk, mudler, and 6 other contributors\n\n7 people reacted\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
