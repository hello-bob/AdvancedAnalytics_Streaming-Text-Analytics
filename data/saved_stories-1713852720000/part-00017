{"aid": "40123052", "title": "Apple Hugs: Human Gaussian Splats (CVPR 2024)", "url": "https://github.com/apple/ml-hugs", "domain": "github.com/apple", "votes": 2, "user": "yeldarb", "posted_at": "2024-04-22 22:26:19", "comments": 0, "source_title": "GitHub - apple/ml-hugs: Official repository of HUGS: Human Gaussian Splats (CVPR 2024)", "source_text": "GitHub - apple/ml-hugs: Official repository of HUGS: Human Gaussian Splats\n(CVPR 2024)\n\n## Navigation Menu\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\napple / ml-hugs Public\n\n  * Notifications\n  * Fork 0\n  * Star 2\n\nOfficial repository of HUGS: Human Gaussian Splats (CVPR 2024)\n\nmachinelearning.apple.com/research/hugs\n\n### License\n\nView license\n\n2 stars 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# apple/ml-hugs\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nanuragranjadd submodulesApr 22, 20247e1076b \u00b7 Apr 22, 2024Apr 22, 2024\n\n## History\n\n4 Commits  \n  \n### assets\n\n|\n\n### assets\n\n| first commit| Apr 15, 2024  \n  \n### cfg_files\n\n|\n\n### cfg_files\n\n| first commit| Apr 15, 2024  \n  \n### hugs\n\n|\n\n### hugs\n\n| first commit| Apr 15, 2024  \n  \n### scripts\n\n|\n\n### scripts\n\n| first commit| Apr 15, 2024  \n  \n### submodules\n\n|\n\n### submodules\n\n| add submodules| Apr 22, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| first commit| Apr 15, 2024  \n  \n### .gitmodules\n\n|\n\n### .gitmodules\n\n| first commit| Apr 15, 2024  \n  \n### ACKNOWLEDGEMENTS\n\n|\n\n### ACKNOWLEDGEMENTS\n\n| first commit| Apr 15, 2024  \n  \n### CODE_OF_CONDUCT.md\n\n|\n\n### CODE_OF_CONDUCT.md\n\n| first commit| Apr 15, 2024  \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n| first commit| Apr 15, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| first commit| Apr 15, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| Update README.md| Apr 17, 2024  \n  \n### main.py\n\n|\n\n### main.py\n\n| first commit| Apr 15, 2024  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| first commit| Apr 15, 2024  \n  \n## Repository files navigation\n\n# HUGS: Human Gaussian Splats\n\nThis repository is a reference implementation for HUGS. HUGS reconstructs both\nthe background scene and an animatable human from a single video using neural\nradiance fields.\n\n[Paper] | [Project Page]\n\n> HUGS: Human Gaussian Splats, Muhammed Kocabas, Jen-Hao Rick Chang, James\n> Gabriel, Oncel Tuzel, Anurag Ranjan IEEE Computer Vision and Pattern\n> Recognition (CVPR) 2024\n\n# Getting Started\n\nWe tested our system with Ubuntu 22.04.3 using a CUDA 11.7 compatible GPU.\n\n  * Clone our repo:\n\n    \n    \n    git clone --recursive git@github.com:apple/ml-hugs.git\n\n  * Run the setup script to create a conda environment and install the required packages.\n\n    \n    \n    source scripts/conda_setup.sh\n\n# Preparing the datasets and models\n\n## Datasets\n\n  * Download the SMPL neutral body model\n\n    * Register to SMPL website.\n\n    * Download v1.1.0 and SMPL UV obj file from the download page.\n\n    * Extract the files and rename basicModel_neutral_lbs_10_207_0_v1.0.0.pkl to SMPL_NEUTRAL.pkl.\n\n    * Put the files into ./data/smpl/ folder with the following structure:\n        \n                data/smpl/ \u251c\u2500\u2500 SMPL_NEUTRAL.pkl \u2514\u2500\u2500 smpl_uv.obj\n\n  * Download NeuMan dataset and pretrained models:\n\n    * Data (download)\n    * Pretrained models (download)\n\nAlternately, run the following script to set up data and pretrained models.\n\n    \n        source scripts/prepare_data_models.sh\n\n  * Download AMASS dataset for novel animation rendering:\n\n    * AMASS dataset is used for rendering novel poses.\n    * We used SFU mocap(SMPL+H G) and MPI_mosh (SMPL+H G) subsets, please download from AMASS.\n    * Put the downloaded mocap data in to ./data/ folder.\n\nAfter following the above steps, you should obtain a folder structure similar\nto this:\n\n    \n    \n    data/ \u251c\u2500\u2500 smpl \u2502 \u251c\u2500\u2500 SMPL_FEMALE.pkl \u2502 \u251c\u2500\u2500 SMPL_MALE.pkl \u2502 \u251c\u2500\u2500 SMPL_NEUTRAL.pkl \u2502 \u251c\u2500\u2500 smpl_uv.obj \u251c\u2500\u2500 neuman \u2502 \u2514\u2500\u2500 dataset \u2502 \u251c\u2500\u2500 bike \u2502 \u251c\u2500\u2500 citron \u2502 \u251c\u2500\u2500 jogging \u2502 \u251c\u2500\u2500 lab \u2502 \u251c\u2500\u2500 parkinglot \u2502 \u2514\u2500\u2500 seattle \u251c\u2500\u2500 MPI_mosh \u2502 \u251c\u2500\u2500 00008 \u2502 \u251c\u2500\u2500 00031 \u2502 \u251c\u2500\u2500 ... \u2502 \u2514\u2500\u2500 50027 \u2514\u2500\u2500 SFU \u251c\u2500\u2500 0005 \u251c\u2500\u2500 0007 \u251c\u2500\u2500 ... \u2514\u2500\u2500 0018\n\n# Training\n\nTo train HUGS on NeuMan dataset, there are three different modes you can\nchoose from: 1. joint human and scene 2. human only, 3. scene only.\n\n  1. Joint human and scene training\n\nThis is the original HUGS setup where jointly optimize human Gaussians and\nscene Gaussians.\n\n    \n        python main.py --cfg_file cfg_files/release/neuman/hugs_human_scene.yaml dataset.seq=lab\n\n  2. Human only training\n\nThis mode only optimizes the Triplane+MLP model introduced in HUGS.\n\n    \n        python main.py --cfg_file cfg_files/release/neuman/hugs_human.yaml dataset.seq=lab\n\n  3. Scene only training\n\nThis setup is identical to original 3DGS paper. Here we provide the script to\nrun it on the NeuMan dataset\n\n    \n        python main.py --cfg_file cfg_files/release/neuman/hugs_scene.yaml dataset.seq=lab\n\ncfg_files/release directory contains the final configuration files we used to\ntrain HUGS. Please refer to the config.py file to see different config\nparameters and their meanings.\n\nNote: Expect to see slight differences compared to the pretrained models. This\nis due to the inherent randomness in the rendering process, which makes\nachieving deterministic results across multiple runs challenging, even when\nproper seeding is applied. So it is expected to obtain results slightly\ndifferent than what is reported in the paper.\n\n# Evaluation and Animation\n\nHere we show how to perform evaluation with the pretrained models on the\nNeuMan dataset.\n\n    \n    \n    python scripts/evaluate.py -o <<path to the output directory>>\n\nThis command will print out the PSNR, SSIM, and LPIPS metrics for a given\npretrained model.\n\n# Citation\n\n    \n    \n    @inproceedings{ kocabas2024hugs, title={{HUGS}: Human Gaussian Splatting}, author={Kocabas, Muhammed and Chang, Jen-Hao Rick and Gabriel, James and Tuzel, Oncel and Ranjan, Anurag}, booktitle = {2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, year = {2024}, url={https://arxiv.org/abs/2311.17910} }\n\n# License\n\nThe code is released under the LICENSE terms.\n\n## About\n\nOfficial repository of HUGS: Human Gaussian Splats (CVPR 2024)\n\nmachinelearning.apple.com/research/hugs\n\n### Topics\n\nneural-rendering gaussian-splatting\n\n### Resources\n\nReadme\n\n### License\n\nView license\n\n### Code of conduct\n\nCode of conduct\n\nActivity\n\nCustom properties\n\n### Stars\n\n2 stars\n\n### Watchers\n\n7 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * Python 99.8%\n  * Shell 0.2%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
