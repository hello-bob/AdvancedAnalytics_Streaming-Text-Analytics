{"aid": "40130079", "title": "Deep Diving into the Erlang Scheduler", "url": "https://blog.appsignal.com/2024/04/23/deep-diving-into-the-erlang-scheduler.html", "domain": "appsignal.com", "votes": 1, "user": "unripe_syntax", "posted_at": "2024-04-23 09:22:48", "comments": 0, "source_title": "Deep Diving Into the Erlang Scheduler | AppSignal Blog", "source_text": "Deep Diving Into the Erlang Scheduler | AppSignal Blog\n\n  * Features\n\n### Monitoring features\n\n    * Error tracking\n\n    * Performance monitoring\n\n    * Host monitoring\n\n    * Anomaly detection\n\n    * Uptime monitoring\n\n    * Metric dashboards\n\n    * Workflow\n\n    * Log management\n\n    * Automated Dashboards\n\n  * Languages\n\n### Supported Languages\n\n    * Ruby (on Rails) APM\n\n    * Elixir APM\n\n    * Node.js APM\n\n    * JavaScript Error Tracking\n\n    * Python APM\n\n  * Learn\n  * Docs\n  * Blog\n  * Pricing\n\n  * Login\n  * Start free trial\n\nMenu\n\nelixir\n\n# Deep Diving Into the Erlang Scheduler\n\nSapan Diwakar on Apr 23, 2024\n\nErlang is renowned for its remarkable fault tolerance and high concurrency.\nErlang's scheduler efficiently handles many lightweight processes. The\nscheduler plays a crucial role in managing processes, concurrency, and system\nresources, efficiently coordinating these elements to help Erlang maintain\nfault tolerance and support high levels of concurrency in its applications.\n\nThis post will dissect some of the scheduler's key components and shed light\non how it works internally.\n\nLet's get started!\n\n## Processes in Erlang\n\nErlang processes are lightweight, independent units of execution managed by\nthe Erlang runtime system. They are created and scheduled by the Erlang\nvirtual machine (BEAM), and each Erlang process has its own memory space.\nThese should not be confused with operating system processes or threads.\n\nOS processes are entities managed by the OS and typically have more overhead\nin terms of memory and resources, as well as inter-process communication.\nWhile threads are lighter than OS processes, they are still heavier than a\ntypical Erlang process and share a common memory space within a process.\nCommunication is usually easier between threads of the same process but still\nrequires synchronization mechanisms.\n\nOn the other hand, the Erlang VM (BEAM) is capable of spawning several\nlightweight processes with independent memory space and can communicate easily\nusing message passing. The scheduler inside the VM manages processes,\nallocates resources to processes, and context-switches between them.\n\n## Erlang Scheduler Architecture \u2014 Preemptive Scheduling\n\nIn a single-core setup, only one process can occupy the CPU core at any given\ntime. To emulate a concurrent system, the scheduler employs a preemptive,\npriority-based scheduling mechanism (don't worry, we will explore what this\nmeans soon) that rapidly switches between available processes to create the\nillusion that all processes are executing simultaneously. The Erlang Virtual\nMachine (BEAM) schedules processes to run sequentially, with one process\nrunning for a duration, being suspended, and then allowing another process to\ntake its turn. This process management strategy is characteristic of\nconcurrency and does not entail true parallelism (which is not possible on a\nsingle-core system). Tasks appear to run concurrently due to fast context\nswitching, although they actually execute sequentially on a single core.\n\nTo identify processes for potential swapping, Erlang introduces the concept of\n\"reductions\". In Erlang, a reduction represents a unit of work performed by\nBEAM, encompassing fundamental operations such as function application,\narithmetic calculations, or message passing. The scheduler keeps track of the\nreductions executed by each process, preempting a process when it reaches a\ncertain reduction count, thereby allowing another process to run.\n\n### Reductions\n\nThe idea of \"reduction\" in Erlang is inherited from its Prolog ancestry. In\nProlog, every execution step is termed a goal-reduction, involving breaking\ndown a logic problem into individual components and solving each part\naccordingly.\n\nTo promote fairness among processes, Erlang's preemptive scheduling relies on\nreductions rather than time slices. If a process exhausts its allocated\nreductions, it can be preempted, even if its execution isn't complete. This\napproach prevents a single process from monopolizing the CPU for an extended\nperiod, fostering fairness among concurrent processes. By using reductions as\nthe foundation for preemption, Erlang mitigates the risk of processes starving\nfor CPU time. This design ensures that every process, irrespective of its\nworkload, is periodically allowed to execute.\n\nMoreover, reductions are flexibly applied based on the type of operation a\nprocess is performing. For example, certain operations, such as I/O\noperations, may consume various reductions. This adaptability allows the\nscheduler to effectively handle different types of operations.\n\nIn other languages, traditional blocking I/O operations can lead to\ninefficient resource utilization, as threads might be blocked while waiting\nfor I/O to complete. Erlang's asynchronous and non-blocking I/O model allows\nprocesses to continue executing other tasks while waiting for I/O operations\nto complete. This minimizes the impact of blocking operations on overall\nsystem performance.\n\n\u2193 Article continues below\n\n#### Is your app broken or slow? AppSignal lets you know.\n\nMonitoring by AppSignal \u2192\n\n### Priority\n\nEach process in Erlang can have a priority value that decides how often the\nscheduler will execute that process. A process priority can be set using the\nProcess.flag/2 (or process_flag/2 on Erlang) function call:\n\nelixir\n\n    \n    \n    iex> Process.spawn( fn -> Process.flag(:priority, :high) # ... end, [:link] )\n\nThere are 4 priority levels: low, normal, high, and max. max is reserved for\ninternal use in Erlang and should not be used in application code. Processes\non each priority level get a separate run queue and are scheduled in the\nnormal round-robin fashion as described above.\n\nExcept low and normal, Erlang executes the processes of each priority queue\nexclusively. This means that if there is a process in the max priority queue,\nonly max priority processes will be executed, and all other processes will be\nblocked. Similarly, if there is a process in the high priority queue, low and\nnormal processes will not be executed until all processes from the high\npriority queue are executed (or are non-runnable). low and normal queues\nbehave slightly differently \u2014 the processes inside both queues are interleaved\nsuch that normal priority processes are executed more often than low priority\nones, but normal processes do not block the execution of low priority\nprocesses.\n\nDue to the blocking behavior of high priority processes, they should be used\nvery rarely and only for short-lived tasks. Overusing high priority processes\nis bound to lead to outages and affect the responsiveness of an application,\nas all other regular OTP processes run on normal priority.\n\nAnother point that's important here is that Erlang places no restrictions on\ncommunication between different priority levels of processes. So a high-\npriority process can wait for a message from a lower-priority process. This is\nallowed, but will effectively lower the priority of the high-priority process.\n\n## Running on Multiple Cores\n\nUp to this point, we've explored how the scheduler orchestrates processes\nwithin a single-core system. However, in a multi-core environment, where\nadditional resources are available for parallel processing, the Erlang VM\ncreates a dedicated \"run queue\" for each available core. This enables true\nparallelism, as multiple processes can run simultaneously (one on each\navailable core). Within each run queue, all processes adhere to the preemptive\nscheduling mechanism we discussed earlier.\n\nTypically, Erlang processes share the same run queue as their parent process,\nand a work-stealing algorithm may come into play to ensure load balancing. For\ninstance, if there are two cores in the system and one consistently handles\nbusy processes while the other remains relatively idle, the Erlang schedulers\non both cores engage in periodic communication. This communication facilitates\nthe movement of processes from the heavily loaded core to the less busy one,\nensuring a more equitable distribution of workloads across both cores.\n\nIn the broader context, beyond Erlang's internal run queues, the operating\nsystem plays a role in managing the scheduling of threads onto OS-level cores.\nThis implies that processes not only experience swapping within the Erlang run\nqueue but also may undergo a complete context switch or be moved to a\ndifferent core at the OS level.\n\nNote that, because of the concept of work-stealing inside the Erlang VM, it is\nusually beneficial to run a single Erlang application instance on multiple\ncores rather than running separate instances of the same application on\ndifferent cores of the same machine. In a single instance, the schedulers\ndedicated to each core can better communicate between them to share the load\nequitably compared to a multi-node cluster where schedulers cannot share\nprocess load (even if all of that cluster's nodes are on the same physical\nmachine).\n\n## Performance and Optimization\n\nErlang's scheduler takes out most of the complexities involved in building a\nconcurrent system. It automatically frees the developer from having to think\nabout things like lock contention, thread overhead, and load balancing by\nhandling these issues out of the box with its preemptive scheduling algorithm.\n\nErlang provides various scheduler-related parameters that can be tuned for\noptimal performance. Parameters like +S (scheduler count) and +P (maximum\nnumber of processes) allow you to configure the number of scheduler threads\nand processes.\n\nFor example, you can start Erlang with erl +S Schedulers:SchedulerOnline to\ncontrol the number of scheduler threads. By default, Erlang uses the number of\nCPU cores to identify these values automatically. Note that while both\nScheduler and SchedulerOnline accept values up to 1024, starting more\nschedulers than the number of CPU cores does not have any positive benefits\nfor an app.\n\nAnother possible step to fine-tune performance is to control the priorities of\nprocesses, as we've discussed. It is indeed possible to execute certain high-\npriority tasks in Erlang.\n\nNevertheless, this comes with an inherent risk of potentially rendering a\nsystem unresponsive and increasing latency, as processes with a high priority\nmay block all other normal/low-priority processes. Conversely, marking tasks\nidentified as intentionally low priority can be advantageous to prioritize\nother processes above them.\n\nSo be careful and use your judgment.\n\n## Wrapping Up\n\nIn this post, we've seen that the Erlang scheduler stands as a cornerstone in\nErlang's architecture, fostering fault tolerance, concurrency, and\nadaptability. Its preemptive and dynamic nature equips developers to build\nresilient, highly concurrent systems capable of handling failures and\nutilizing resources optimally. Understanding the intricacies of the Erlang\nscheduler can empower you to craft scalable and robust distributed\napplications.\n\nIf you are interested in learning more about the scheduler, I recommend\nchecking out the Scheduling chapter in The BEAM Book and Processes from the\nErlang Efficiency Guide.\n\nHappy coding!\n\nP.S. If you'd like to read Elixir Alchemy posts as soon as they get off the\npress, subscribe to our Elixir Alchemy newsletter and never miss a single\npost!\n\nP.P.S. AppSignal has an integration for Erlang \u2014 check it out.\n\n# Share this article\n\nRSS\n\n# Sapan Diwakar\n\nOur guest author Sapan Diwakar is a full-stack developer. He writes about his\ninterests on his blog and is a big fan of keeping things simple, in life and\nin code. When he\u2019s not working with technology, he loves to spend time in the\ngarden, hiking around forests, and playing outdoor sports.\n\nAll articles by Sapan Diwakar\n\nBecome our next author!\n\nFind out more\n\n# Subscribe to our Elixir Alchemy email series and receive deep insights about\nElixir, Phoenix and other developments.\n\n# AppSignal monitors your apps\n\nAppSignal provides insights for Ruby, Rails, Elixir, Phoenix, Node.js, Express\nand many other frameworks and libraries. We are located in beautiful\nAmsterdam. We love stroopwafels. If you do too, let us know. We might send you\nsome!\n\nDiscover AppSignal\n\n## Features\n\n  * Error tracking\n\n  * Performance monitoring\n\n  * Host monitoring\n\n  * Anomaly detection\n\n  * Uptime monitoring\n\n  * Metric dashboards\n\n  * Workflow\n\n  * Log management\n\n  * Automated Dashboards\n\n## Resources\n\n  * Plans & pricing\n\n  * Documentation\n\n  * Blog\n\n  * Customer Stories\n\n  * Compare AppSignal to Datadog\n\n  * Compare AppSignal to New Relic\n\n  * Changelog\n\n  * Learning Center\n\n  * Why AppSignal\n\n## Support\n\nDo you need help, have a feature request or just need someone to rubber duck\nwith? Get in touch with one of our engineers.\n\n  * Contact us\n\n  * Live chat\n\n  * Status\n\n  * Security\n\n## About us\n\nAppSignal is located in the beautiful Netherlands. We love stroopwafels. If\nyou do too, let us know. We might send you some!\n\n  * About\n\n  * Jobs\n\n  * Write for Our Blog\n\n  * Diversity\n\n  * Open Source\n\n  * Twitter\n\n## Languages\n\n  * Ruby\n\nActive Record, Capistrano, Delayed::Job, Garbage Collection, Global VM Lock,\nGrape, GraphQL, Hanami, MongoDB, Padrino, Puma, Que, Rake, Resque, Ruby on\nRails, Shoryuken, Sidekiq, Sinatra, Webmachine\n\n  * Elixir\n\nEcto, Erlang, Finch, Oban, Phoenix, Plug\n\n  * Node.js\n\nExpress, Fastify, fs Module, GraphQL, Knex.js, Koa, MongoDB, Mongoose, MySQL,\nNestJS, Next.js, PostgreSQL, Prisma, Redis, Remix, Restify\n\n  * JavaScript\n\nReact, Vue, Angular, Ember, Preact, Stimulus\n\n  * Python\n\nCelery, Django, FastAPI, Flask, Jinja2, Psycopg2, Redis, Request, Starlette,\nWSGI and ASGI\n\n  * Terms & Conditions\n  * Privacy Policy\n  * Cookie Policy\n  * GDPR compliance\n  * Contact us / Imprint\n\n", "frontpage": false}
