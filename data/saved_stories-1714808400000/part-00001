{"aid": "40251824", "title": "What is an observability pipeline, anyway?", "url": "https://www.datable.io/post/what-is-an-observability-pipeline", "domain": "datable.io", "votes": 1, "user": "jacobprall", "posted_at": "2024-05-03 20:09:32", "comments": 0, "source_title": "datable", "source_text": "datable\n\nApril 30, 2024\n\n# What is an observability pipeline anyway?\n\n## What is an observability pipeline anyway?\n\nObservability pipelines are a fairly new product category, and there\u2019s a lot\nof terminology floating around that may seem contradictory or confusing. To\nhelp you navigate this emerging space, we\u2019re going to break down what\nobservability pipelines are - what they do, why you might need one, and how to\nchoose the right tools for the job.\n\nKey Takeaways\n\n  1. An observability pipeline is a real-time, extract-transform-load (ETL) pipeline for telemetry data (logs, metrics and traces). It enables the user to pre-process data before it lands in a destination (for example, S3, Elasticsearch, or Datadog).\n  2. Vendors like Mezmo, Cribl and Datable.io sell tools to make building these pipelines easier, with varying levels of operational complexity and capabilities.\n  3. At their best, observability pipelines give insight into your data and help you take actions to reduce cloud costs, improve data quality and governance, and boost developer productivity.\n  4. Not every observability pipeline is created equal. What kinds of telemetry data does it support? Is it a control plane, or a streaming pipeline? Does it support stateful processing? These questions will help you pick the right tool for your use case.\n\nFor a quick refresher on observability terminology, check out our blogs on\nlogs, metrics, and traces.\n\n## How we got here\n\nTo better understand the what and why of observability pipelines, we\u2019ll start\nwith an overview of a typical observability set up - without observability\npipelines.\n\nImagine the architectural components of a simplified monolithic e-commerce\nplatform, circa 2010. You have a client for users to interact with your site,\na web server for handling traffic, a core backend service where business logic\nhappens, and a relational database. It\u2019s all deployed on the same rack, with\ninterprocess communication happening locally.\n\nTo start collecting and leveraging telemetry data, we might begin with\ncollecting and analysing logs. Back in the before times, you\u2019d have to page\nthe person working at your data centre. They would log into the physical\nmachine to surface application logs. Next came sshing into your hardware - but\nonce your app starts running on multiple machines, SSHing isn\u2019t sufficient.\n\nThat brings us to today\u2019s centralised log forwarders. Assuming the web server\nand core service application are both emitting logs at runtime, we would add a\nlog forwarder to run next to our app, ingesting the logs that are generated\nand sending them to some destination for processing and analysis. That\u2019s one\nforwarder per app deployed. This is the world of fluentd and Logstash (the L\nin the ELK stack).\n\nIn a modern setup, you\u2019d use a lightweight log forwarder like Vector or\nFluentbit. Alternatively, you could use a more general purpose telemetry data\nforwarder - in OpenTelemetry parlance, this is called a collector. OTel\ncollectors don\u2019t stop at ingesting logs - they also support ingesting and\nforwarding metrics and traces.\n\nIt\u2019s important to note that while collectors and log forwarders may support\nsome light transformations on your data, they are both designed for high\nthroughput and low latencies, not for processing.\n\nNow we can see our logs from the outside of our application. Now let\u2019s say we\nwant to collect metrics. For metrics (and traces), agents are generally\nrequired to extract the information you need from the application during\nruntime. Agents act from within your application or infrastructure to collect\nand forward internal information. In the case of metrics, this could be your\nCPU usage, response times, or requests-per-second. They can be open source\n(eg. Prometheus, Nagios, OpenTelemetry) or proprietary (eg. New Relic,\nDatadog).\n\nFor simplicity, our agents will send metrics via the /metrics endpoint\nwhenever they are requested by a Prometheus deployment.\n\nBetween logs and metrics, we should have a solid grasp of the health of our\nsystem. If we wanted traces, we\u2019d again have to instrument our app with\nlanguage native agents to generate and forward that data to a collector or\nstraight to a vendor like New Relic.\n\nAs you may have noticed, our sample stack does not have a particularly modern\narchitecture. Many orgs will reach for an event-driven microservices\narchitecture, with many containerized apps communicating asynchronously. With\neach container generating its own metrics, logs and traces, observability for\ncloud-native deployments is particularly complex to implement and maintain.\n\nAdoption of the OTel collector is growing, as it simplifies the collection and\nforwarding of all telemetry data (logs, metrics and traces). This centralises\nthe collection process, allowing for simplified config management.\n\nCollectors are good for parsing and redirecting data, but they are generally\ndifficult to operate, limited in their processing capabilities, and give no\nvisibility into the data you\u2019re collecting and forwarding. In most orgs,\nsimple adjustments require complicated configuration management that involves\nmultiple stakeholders. Something as simple as dropping info logs or\nconfiguring sampling can take days to sort out. Ultimately, these tools are\nnot designed to support cross-functional data exploration, or to perform\ncomplex (read: meaningful) transformations.\n\nThat\u2019s where observability pipelines come in.\n\n## What is an Observability Pipeline?\n\nObservability pipelines are real-time data processing pipelines that ingest,\ntransform and route telemetry data. Observability pipeline vendors like Mezmo,\nCribl or Datable.io offer platforms for building and managing these pipelines.\n\nWithout an observability pipeline, telemetry data is collected and forwarded\nto downstream consumers in (roughly) the same form as it was emitted. As\nmentioned above, collectors and forwarders are designed to be lightweight,\nwith limited processing capabilities. Without a layer for standardisation or\nnormalisation, data quality suffers, making it harder to extract meaningful\ninsights and respond to outages.\n\nWith an observability pipeline tool in place, data in your pipeline can be\naggregated, sampled, transformed, filtered, and routed easily.\n\n## Why are Observability Pipelines Necessary?\n\nWhen applications are instrumented for telemetry, even small applications can\nproduce massive amounts of real-time event data. To get the most out of that\ntelemetry data and minimise costs, it\u2019s necessary to process that data before\nit\u2019s sent to downstream consumers (i.e. data warehouses, Elasticsearch\nclusters, or vendors like Datadog and New Relic).\n\nObservability pipelines let you quickly understand the data you're collecting,\nand make decisions to manage the complexity, volume, and quality of telemetry\ndata. But systems that can handle the bandwidth, throughput, and processing\nrequired when dealing with telemetry data are typically expensive to build and\nmaintain.\n\nObservability pipeline tools sit between your application and the destination,\nproviding a singular interface for pre-processing data. They can be used for a\nwide range of data transformation tasks, including removing PII, enforcing\ndata models, alerting on data spikes, and directing traffic between different\ndownstream applications to reduce redundant data storage and processing.\n\n## Benefits of Observability Pipelines\n\nThe biggest reason devs turn to observability pipelines is to make their\ntelemetry data more useful, with the aim of improving operational efficiency\nand minimising costs. After all, less data is easier to manage and faster to\nsearch.\n\n### Data Quality & Governance\n\nOne way to improve operational efficiency is to improve the quality and\nrichness of your telemetry data. This, in turn, improves the usability of that\ndata, which can lead to tangible differences in MTTR. In practice, this looks\nlike schema enforcement, data normalisation and enrichment, and more.\nAdditionally, many observability pipelines support filtering for PII, helping\nto ensure regulatory compliance.\n\n### Cost Reduction\n\nObservability pipelines can lower observability costs in a few ways. They de-\ncouple source systems that generate data from downstream observability vendors\nlike New Relic or Datadog, which makes churning simple. This can provide a\nsignificant amount of leverage in pricing negotiations. They also provide the\nability to direct and split traffic, which can help organisations with many\ndownstream consumers reduce the cost of their data ingestion and storage.\n\nFor example, lower value data can be redirected to S3, while high-impact data\nis forwarded to Datadog, or multiple vendors simultaneously like Splunk and\nSnowflake. Observability pipelines can also help downsample and filter\nirrelevant data, further minimising the footprint of your telemetry data.\n\n### Reduced Tool Sprawl\n\nWithout a global view of your telemetry data, tracking down what is going\nwhere gets complicated fast. With an observability pipeline in place, managing\ndata streams across different downstream consumers is faster and easier.\nAdopting or churning from tools is as simple as adding or removing pipelines.\nMany orgs end up paying for redundant feature sets and data storage.\nObservability pipelines can help consolidate tool sprawl and optimise storage\ncosts.\n\n## Choosing an Observability Pipeline\n\n### Telemetry data support\n\nMost observability pipelines will only support one or two of the three major\ntelemetry data sources (logs, metrics, or traces), but not all three.\nDatable.io is capable of ingesting all three categories of telemetry data,\noffering a unified interface for insights into your observability.\n\n### Transformation Capabilities\n\nAnother important factor to consider when choosing an observability pipeline\nplatform is what kind of transformations can be applied to your telemetry\ndata, and how those transformations are implemented.\n\nCompanies like Mezmo and Cribl, or tools like Vector offer rigid, pre-defined\nfunctions you can run against your data for simple transformations. Others,\nparticularly Datadog, use the term \u201cobservability pipelines'' to describe\ntheir Control Plane product. A control plane differs from an observability\npipeline in that a control plane acts as a central repository for\nconfigurations that are applied to your collectors/forwarders. This enables\nefficient config management, but does not unlock advanced processing features.\n\nDatable.io is the only observability pipeline tool that lets you write\narbitrary transformations against your data in JavaScript. This means you can\nperform the exact transformations you need through a few lines of JS.\n\n### Routing options\n\nProprietary pipelines often require vendor-specific tooling and destinations.\nDatable.io supports destinations like S3, Datadog, and New Relic, as well as\nany HTTP endpoint. This makes testing different vendors simple. By decoupling\nyour vendor from your observability, you also open the opportunity to\nnegotiate for better rates. We\u2019ve seen reductions in the range of 30%-50% off\nannual vendor bills.\n\n### Wrapping Up\n\nObserving your system\u2019s health is table stakes for building a successful\nproduct. But modern tooling introduces a lot of complexity, redundancy, and\ncosts. Observability pipelines act as an intermediary processing layer,\nhelping you take control over your observability ecosystem and maximise the\nvalue of your telemetry data.\n\nIf you\u2019re interested in giving Datable.io a try, sign up for our private beta\nwaitlist here.\n\nThanks for reading, until next time!\n\nTake control of your telemetry data\n\nJoin the waitlist\n\nhello@datable.io\n\n\u00a9 2024. Datable\n\n###### Product\n\nBlogDocsFeatures\n\n###### Solutions\n\nStartupsSaaSEnterprises\n\n###### Company\n\nAboutCareersBlog\n\n", "frontpage": false}
