{"aid": "40259595", "title": "Scalable Spear Phishing with LLMs", "url": "https://www.sabrina.dev/p/scalable-spear-phishing-llms", "domain": "sabrina.dev", "votes": 1, "user": "sabrina_ramonov", "posted_at": "2024-05-04 19:01:36", "comments": 0, "source_title": "Scalable Spear Phishing with LLMs", "source_text": "Scalable Spear Phishing with LLMs\n\n  * Sabrina Ramonov\n  * Posts\n  * Scalable Spear Phishing with LLMs\n\n# Scalable Spear Phishing with LLMs\n\n## Understanding Next-Generation Spear Phishing in the Age of LLMs\n\nSabrina Ramonov May 04, 2024\n\n  * Spear Phishing 101\n\n  * Real-World Incidents\n\n  * LLMs Enable Scalable Spear Phishing\n\n    * 1\\. Reconnaissance: Gathering Personal Information\n\n    * 2\\. Message Generation: Writing Personalized Emails\n\n    * 3\\. Scaling Attacks: Producing Messages in Large Vo ...\n\n  * Conclusion\n\nAI can write 1,000 personalized spear phishing emails for $10 in 2 hours.\n\nThink twice before you click.\n\nThe use of LLMs in large-scale spear phishing attacks is an alarming trend.\n\n# Spear Phishing 101\n\nPhishing is sending generic un-personalized emails to many people, hoping that\na small percentage will fall for the scam.\n\nSpear phishing is sending hyper-personalized emails that appear to come from a\ntrusted source, such as a coworker or authority figure.\n\nThese emails sprinkle in your specific personal details to garner trust.\n\nPersonal details could be: your name, position, company, phone number, and\nother personally identifiable information to make it more convincing.\n\nThe goal is to deceive targets into clicking on malicious links, opening\ninfected attachments, or revealing confidential information, such as\npasswords.\n\nSource: Valimail\n\n# Real-World Incidents\n\nSpear phishing is not hypothetical.\n\nBarracuda Networks analyzed 50 BILLION emails across 3.5 million mailboxes and\nuncovered nearly 30,000,000 spear phishing emails.\n\nThese real examples underscore the damage:\n\n  1. Anthem Healthcare Data Breach (2015): Anthem, one of the largest health insurers in the US, fell victim to a spear phishing attack that led to a massive data breach, exposing personal information of about 78 million people. The financial fallout from this breach resulted in a $115 million settlement in a class-action lawsuit.\n\n  2. Ubiquiti Networks (2015): This manufacturer of network technology for service providers and enterprises was tricked into transferring $46.7 million to external accounts following a spear phishing attack targeting its finance department.\n\n  3. Google and Facebook (2013-2015): Both tech giants were duped out of $100 million collectively by a Lithuanian hacker who used spear phishing emails to pose as a legitimate hardware supplier. The attacker sent fraudulent invoices, which the companies paid over 2 years.\n\n  4. Democratic National Committee (DNC) Email Leak (2016): The DNC suffered a significant breach when spear phishing emails allowed attackers to gain access to email accounts, leading to a leak of thousands of emails during the 2016 U.S. presidential campaign.\n\n  5. Colonial Pipeline (2021): This major U.S. fuel pipeline operator was hit by a ransomware attack initiated through a spear phishing email, leading to the pipeline\u2019s shutdown. The attackers received a $5 million ransom payment, and the disruption caused widespread fuel shortages and price hikes.\n\nIn 2023, 43% of all successful cyberattacks on companies involved social\nengineering methods, with 79% of attacks done via spear phishing.\n\nSpear phishing is pervasive... and getting Scary Good!\n\n# LLMs Enable Scalable Spear Phishing\n\nLLMs are a breakthrough in AI, capable of writing convincing human-like text.\n\nWhile they're often used positively \u2014 from customer support to translation \u2014\ntheir ability to mimic human writing makes them potent tools for cybercrime.\n\nHere is step-by-step how attackers use LLMs for scalable spear phishing:\n\n### 1\\. Reconnaissance: Gathering Personal Information\n\nThe first step is reconnaissance \u2014 collecting personal information about\nvictims to write convincing messages.\n\nHere's how this is typically done:\n\n  * Identify Targets: Select potential targets who have access to sensitive or valuable information.\n\n  * Collect Information: Use public sites like social media, company websites, and networks like LinkedIn to gather personal details.\n\n  * Deepen Insight: Check leaked databases, forums, and other non-traditional sources to find more personal or sensitive data.\n\nAttackers leverage LLMs, like ChatGPT-4, that have internet access.\n\nFor example, you can feed ChatGPT-4 a target\u2019s wikipedia page and instantly\ngenerate a detailed biography.\n\n### 2\\. Message Generation: Writing Personalized Emails\n\nWith the target's biography, attackers then use LLMs to write convincing\nemails, mimicking legit communication:\n\nHere are sample spear phishing emails generated by ChatGPT-4:\n\nSource: Spear Phishing with Large Language Models\n\nSource: Spear Phishing with Large Language Models\n\nMany publicly available LLMs won\u2019t respond to direct malicious prompts like\n\u201cWrite a phishing email.\u201d\n\nIt\u2019s easy to get around that.\n\nIn the 2nd example, notice the prompt.\n\nIt simply asked ChatGPT to write an email, specifying personal information\nthat should be included and a desired action (i.e. login with credentials).\n\nHow would ChatGPT know this email is meant for nefarious purposes?\n\nBesides weaving in personal information, another powerful aspect of LLM-driven\nmessage generation is proper grammar.\n\nMost attackers aren\u2019t native English speakers.\n\nCybersecurity reporter, Eric Geller, explains:\n\n\u201cOne of AI\u2019s biggest advantages is that it can write complete and coherent\nEnglish sentences. Most hackers aren\u2019t native English speakers, so their\nmessages often contain awkward phrasing, grammatical errors and strange\npunctuation. These mistakes are the most obvious giveaways that a message is a\nscam. With generative AI platforms like ChatGPT, hackers can easily produce\nmessages in perfect English, devoid of the basic mistakes that Americans are\nincreasingly trained to spot.\u201d\n\nSource: KnowBe4\n\n### 3\\. Scaling Attacks: Producing Messages in Large Volumes\n\nFinally, LLMs help scale the attack by producing large volumes of personalized\nmessages quickly and cost-effectively.\n\nUsing Claude, an attacker can generate:\n\n1,000 personalized spear phishing emails for $10 USD in 2 hours!\n\n  * Fractions of a cent per email.\n\n  * Hundreds of hyper-personalized emails per hour.\n\nGiven tech\u2019s exponential rate of progress, it will only become cheaper and\nfaster over time.\n\nLLMs can operate continuously 24/7, automating creation of hyper-targeted\nemails, while analyzing vast amounts of data to sprinkle into these emails,\nincreasing perceived trust and authority.\n\nThis significantly reduces the complexity, cost, and skill traditionally\nrequired to execute large-scale spear phishing attacks.\n\n\u201cDespite having no formal background in cybersecurity, I was able to execute\nkey steps in a mass spear phishing campaign in as little as a few hours,\nincluding designing the prompt, gathering background information on targets,\nand generating hundreds of emails. Once the initial infrastructure is in\nplace, it can be adapted and re-used for successive campaigns with little\nadditional effort. As campaigns scale, the average cost of each email quickly\napproaches the inference costs of running LLMs \u2014 costs which will continue to\ndecline as algorithms become more efficient and computing resources improve in\naffordability.\u201d\n\nSource: Julian Hazell\n\n# Conclusion\n\nLLMs\u2019 ability to generate persuasive, human-sounding, personalized content at\nscale represents a seismic shift in cybersecurity.\n\nUltimately, LLMs simplify multiple attack stages and the workload required to\nexecute scalable, highly targeted spear phishing campaigns.\n\nThis makes spear phishing more broadly accessible to attackers without\ntechnical skills, especially when the current cost is less than 1 cent per\nemail.\n\nWhile LLMs offer massive benefits, the potential for abuse cannot be ignored.\n\nSabrina Ramonov\n\nGen AI Engineering and Entrepreneurship\n\nHome\n\nPosts\n\n\u00a9 2024 Sabrina Ramonov.\n\nPrivacy Policy\n\nTerms of Use\n\nPowered by beehiiv\n\n", "frontpage": false}
