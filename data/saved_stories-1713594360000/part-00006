{"aid": "40092323", "title": "Interview with Fei-Fei Li", "url": "https://issues.org/interview-godmother-ai-fei-fei-li/", "domain": "issues.org", "votes": 1, "user": "T-A", "posted_at": "2024-04-19 21:52:27", "comments": 0, "source_title": "\u201cAI Is a Tool, and Its Values Are Human Values.\u201d", "source_text": "Interview With Fei-Fei Li\n\n###### Search Issues\n\nMenu Subscribe\n\n  * By Topic\n\n    * Agriculture and Food\n    * Artificial Intelligence and Machine Learning\n    * Biological Technology\n    * Climate\n    * Defense and National Security\n    * Digital Landscape\n    * Diversity, Equity, and Inclusion\n    * Education\n    * Energy\n    * Engineering and Infrastructure\n    * Environment\n    * Ethics, Values, and Philosophy\n    * Global Affairs\n    * Innovation Policy\n    * Medicine\n    * Public Health\n    * Research Conduct\n    * Science and Society\n    * Science Politics\n    * Space\n    * Transportation\n    * Workforce\n  * By Focus\n\n    * Navigating a Polluted Information Ecosystem\n\nFake news, misinformation, and disinformation have become bywords for the\nkinds of false and misleading information that\u2019s rampant online. But these\nterms\u2014and a focus on fact-checking problematic content more generally\u2014provide\nlittle understanding of the ways people create and share information. The\nessays here identify ways to help people navigate today\u2019s polluted information\necosystems. Read responses to this series.\n\n    * Human Gene Editing\n\nRecent technological breakthroughs\u2014most notably the development of CRISPR\nprecision gene editing\u2014have given scientists unprecedented power to manipulate\nthe building blocks of life, including the human genome.\n\n  * By Section\n\n    * Perspectives\n    * Real Numbers\n    * Forum\n    * Editor\u2019s Journal\n    * Fiction and Poetry\n    * Book Reviews\n  * By Interview\n\n    * Carla Hayden\n    * Arati Prabhakar\n    * Ben S. Bernanke\n    * Freeman Hrabowski III\n    * Eddie Bernice Johnson\n    * Anne Case\n    * Jeremy Farrar\n    * Alondra Nelson\n    * Sethuramen Panchanathan\n\nNational Academy of Sciences Arizona State University\n\nChesley Bonestell, \u201cThe Exploration of Mars\u201d (1953), oil on board, 143/8 x 28\ninches, gift of William Estler, Smithsonian National Air and Space Museum.\nReproduced courtesy of Bonestell LLC.\n\nVol. XL, No. 3, Spring 2024\n\nInterview\n\n# \u201cAI Is a Tool, and Its Values Are Human Values.\u201d\n\nBy Fei-Fei Li, Sara Frueh\n\nComputer scientist and \u201cgodmother of AI\u201d Fei-Fei Li explains why artificial\nintelligence and public life are at an inflection point\u2014and contemplates how\nto unleash positive changes while mitigating risks.\n\nFei-Fei Li has been called the godmother of AI for her pioneering work in\ncomputer vision and image recognition. Li invented ImageNet, a foundational\nlarge-scale dataset that has contributed to key developments in deep learning\nand artificial intelligence. She previously served as chief scientist of AI at\nGoogle Cloud and as a member of the National Artificial Intelligence Research\nResource Task Force for the White House Office of Science and Technology\nPolicy and the National Science Foundation.\n\nLi is currently the Sequoia Professor of Computer Science at Stanford\nUniversity, where she cofounded and codirects the Institute for Human-Centered\nAI. She also cofounded the national nonprofit AI4ALL, which aims to increase\ninclusion and diversity in AI education. Li is a member of the National\nAcademy of Engineering and the National Academy of Medicine, and her recent\nbook is The Worlds I See: Curiosity, Exploration, and Discovery at the Dawn of\nAI.\n\nIn an interview with Issues editor Sara Frueh, Li shares her thoughts on how\nto keep AI centered on human well-being, the ethical responsibilities of AI\nscientists and developers, and whether there are limits to the human qualities\nAI can attain.\n\nIllustration by Shonagh Rae.\n\nWhat drew you into AI? How did it happen, and what appealed to you about it?\n\nLi: It was a pure intellectual curiosity that developed around 25 years ago.\nAnd the audacity of a curious question, which is: What is intelligence, and\ncan we make intelligent machines? That was just so much fun to ponder.\n\nMy original entry point into science was physics. I was an undergrad in\nphysics at Princeton. And physics is a way of thinking about big and\nfundamental questions. One fun aspect of being a physics student is that you\nlearn about the physical world, the atomic world.\n\n> What is intelligence, and can we make intelligent machines? That was just so\n> much fun to ponder.\n\nThe question of intelligence is a contrast to that. It\u2019s so much more\nnebulous. Maybe one day we will prove that it\u2019s all just physically realized\nintelligence, but before that happens, it\u2019s just a whole different way of\nasking those fundamental questions. That was just fascinating. And of all the\naspects of intelligence, visual intelligence is a cornerstone of intelligence\nfor animals and humans. The pixel world is so rich and mathematically\ninfinite. To make sense of it, to be able to understand it, to be able to live\nwithin it, and to do things in it is just so fascinating to me.\n\nWhere are we at in the development of AI? Do you see us as being at a\ncrossroads or inflection point, and if so, what kind?\n\nLi: We\u2019re absolutely at a very interesting time. Are we at an inflection\npoint? The short answer is yes, but the longer answer is that technologies and\nour society will go through many inflection points. I don\u2019t want to overhype\nthis by saying this is the singular one.\n\nSo it is an inflection point for several reasons. One is the power of new AI\nmodels. AI as a field is relatively young\u2014it\u2019s 60, maybe 70 years old by now.\nIt\u2019s young enough that it\u2019s only come of age to the public recently. And\nsuddenly we\u2019ve got these powerful models like large language models\u2014and that\nitself is an inflection point.\n\nThe second reason it\u2019s an inflection point is the public has awakened to AI.\nWe\u2019ve gone through a few earlier, smaller inflection points, like when AlphaGo\nbeat a human Go player in 2016, but AlphaGo didn\u2019t change public life. You can\nsit here and watch a computer play a Go master, but it doesn\u2019t make your life\ndifferent. ChatGPT changed that\u2014whether you\u2019re asking a question or trying to\ncompose an email or translate a language. And now we have other generative AI\ncreating art and all that. That just fundamentally changed people, and that\npublic awakening is an inflection point.\n\nAnd the third is socioeconomic. You combine the technology with the public\nawakening, and suddenly many of the doings of society are going to be impacted\nby this powerful technology. And that has profound impacts on business,\nsocioeconomic structure, and labor, and there will be intended and unintended\nconsequences\u2014including for democracy.\n\nThinking about where we go from here\u2014you cofounded and lead the Institute for\nHuman-Centered AI (HAI) at Stanford. What does it mean to develop AI in a\nhuman-centered way?\n\nLi: It means recognizing AI is a tool. And tools don\u2019t have independent\nvalues\u2014their values are human values. That means we need to be responsible\ndevelopers as well as governors of this technology\u2014which requires a framework.\nThe human-centered framework is anchored in a shared commitment that AI should\nimprove the human condition\u2014and it consists of concentric rings of\nresponsibility and impact, from individuals to community to society as a\nwhole.\n\n> You combine the technology with the public awakening, and suddenly many of\n> the doings of society are going to be impacted by this powerful technology.\n\nFor example, human centeredness for the individual recognizes that this\ntechnology can empower or harm human dignity, can enhance or take away human\njobs and opportunity, and can enhance or replace human creativity.\n\nAnd then you look at community. This technology can help communities. But this\ntechnology can also exacerbate the bias or the challenges among different\ncommunities. It can become a tool to harm communities. So that\u2019s another\nlevel.\n\nAnd then society\u2014this technology can unleash incredible, civilizational-scale\npositive changes like curing diseases, discovering drugs, finding new\nmaterials, creating climate solutions. Even last year\u2019s fusion milestone was\nvery much empowered by AI and machine learning. In the meantime, it can really\ncreate risks to society and to democracy, like disinformation and painful\nlabor market change.\n\nA lot of people, especially in Silicon Valley, talk about increased\nproductivity. As a technologist, I absolutely believe in increased\nproductivity, but that doesn\u2019t automatically translate into shared prosperity.\nAnd that\u2019s a societal level issue. So no matter if you look at the individual,\ncommunity, or society, a human-centered approach to AI is important.\n\nAre there policies or incentives that could be implemented to ensure that AI\nis developed in ways that enhance human benefits and minimize risks?\n\nLi: I think education is critical. I worry that the United States hasn\u2019t\nembraced effective education for our population\u2014whether it\u2019s K\u201312 or\ncontinuing education. A lot of people are fearful of this technology. There is\na lack of public education on what this is. And I cringe when I read about AI\nin the news because it either lacks technical accuracy or it is going after\neyeballs. The less proper education there is, the more despair and anxiety it\ncreates for our society. And that\u2019s just not helpful.\n\n> As a technologist, I absolutely believe in increased productivity, but that\n> doesn\u2019t automatically translate into shared prosperity.\n\nFor example, take children and learning. We\u2019re hearing about some\nschoolteachers absolutely banning AI. But we also see some children starting\nto use AI in a responsible way and learning to take advantage of this tool.\nAnd the difference between those who understand how to use AI and those who do\nnot is going to have extremely profound downstream effects.\n\nAnd of course, skillset education is also important. It\u2019s been how many\ndecades since we entered the computing age? Yet I don\u2019t think US K\u201312\ncomputing education is adequate. And that will also affect the future.\n\nThoughtful policies are important, but by policy I don\u2019t mean regulation\nexclusively. Policy can effectively incentivize and actually help to create a\nhealthier ecosystem. I have been advocating for the National AI Research\nResource, which would provide the public sector and the academic world with\ndesperately needed computing and data resources to do more AI research and\ndiscovery. And that\u2019s part of policy as well.\n\nAnd of course there are policies that need to look into the harms and\nunintended consequences of AI, especially in areas like health care,\neducation, manufacturing, and finance.\n\nYou mentioned that you\u2019ve been advocating for the National AI Research\nResource (NAIRR). An NSF-led pilot of NAIRR has just begun, and legislation\nhas been introduced in Congress\u2014the Create AI Act\u2014that would establish it at\nfull scale. How would that shape the development of AI in a way that benefits\npeople?\n\nLi: The goal is to resource our public sector. NAIRR is a vision for a\nnational infrastructure for AI research that democratizes the tools needed to\nadvance discovery and innovation. The goal is to create a public resource that\nenables academic and nonprofit AI researchers to access the tools they\nneed\u2014including data, computing power, and training.\n\n> The difference between those who understand how to use AI and those who do\n> not is going to have extremely profound downstream effects.\n\nAnd so let\u2019s look at what public sector means, not just in terms of AI, but\nfundamentally to our country and to our civilization. The public sector\nproduces public goods in several forms. The first form is knowledge expansion\nand discovery in the long arc of civilizational progress, whether it\u2019s\nprinting books or writing Beethoven\u2019s Sixth Symphony or curing diseases.\n\nThe second public good is talent. The public sector is shouldering the\neducation of students and continued skilling of the public. And resourcing the\npublic sector well means investing in the future of these talents.\n\nAnd last but not least, the public sector is what the public should be able to\ntrust when there is a need to assess, evaluate, or explain something. For\nexample, I don\u2019t know exactly how ibuprofen works; most people don\u2019t. Yet we\ntrust ibuprofen to be used in certain conditions. It\u2019s because there have been\nboth public- and private-sector studies and assessments and evaluations and\nstandardizations of how to use these drugs. And that is a very important\nprocess, so that by and large our public trusts using medications like\nibuprofen.\n\nWe need the public sector to play that evaluative role in AI. For example, HAI\nhas been comparing large language models in an objective way, but we\u2019re so\nresource-limited. We wish we could do an even better job, but we need to\nresource the public sector to do that.\n\nYou\u2019re working on AI for health care. People think about AI as being used for\ndrug discovery, but you\u2019re thinking about it in terms of the human experience.\nHow do you think AI can improve the human experience in our fractured,\nfrustrating health care system? And how did your own experience shape your\nvision for that?\n\nLi: I\u2019ve been involved in AI health care for a dozen years\u2014really motivated by\nmy personal journey of taking care of an ailing parent for the past three\ndecades. And now two ailing parents. I\u2019ve been at the front and center of\ncaring\u2014not just providing moral support, but playing the role of home nurse,\ntranslator, case manager, advocate, and all that. So I\u2019ve seen that so much\nabout health care is not just drug names and treatment plans and X-ray\nmachines. Health care is people caring for people. Health care is ensuring\npatients are safe, are getting adequate, timely care, and are having a\ndignified care process.\n\nAnd I learned we are not resourced for that. There are just not enough humans\ndoing this work, and nurses are so in demand. And care for the elderly is even\nworse.\n\nThat makes me think that AI can assist with care\u2014seeing, hearing, triaging,\nand alerting. Depending on the situation, for example, it could be a pair of\neyes watching a patient fall and alerting a person. It could be software\nrunning in the background and constantly watching for changes of lab results.\nIt could be a conversation engine or software that answers patient questions.\nThere are many forms of AIs that can help in the care delivery aspect of\nhealth care.\n\nWhat are the ethical responsibilities of engineers and scientists like you who\nare directly involved in developing AI?\n\nLi: I think there is absolutely individual responsibility in terms of how we\nare developing the technology. There are professional norms. There are laws.\nThere\u2019s also the reflection of our own ethical value system. I will not be\ninvolved in using AI to develop a drug that is illegal and harmful for people,\nfor example. Most people won\u2019t. So there\u2019s a lot, from individual values to\nprofessional norms to laws, where we have responsibility.\n\nBut I also feel we have a little bit of extra responsibility at this stage of\nAI because it\u2019s new. We have a responsibility in communication and education.\nThis is why HAI does so much work with the policy world, with the business\nworld, with the ecosystem, because if we can use our resources to communicate\nand educate about this technology in a responsible way, it\u2019s so much better\nthan people reading misinformation that creates anxiety or irresponsible\nexpectations of utopia. I guess it\u2019s individual and optional, but it is a\nlegit responsibility we can take.\n\nWhen you think about AI\u2019s future, what worries you the most, and what gives\nyou hope?\n\nLi: It\u2019s not AI\u2019s future, it\u2019s humanity\u2019s future. We don\u2019t talk about\nelectricity\u2019s future, we don\u2019t talk about steam\u2019s future. At the end of the\nday, it is our future, our species\u2019 future, and our civilization\u2019s future\u2014in\nthe context of AI.\n\n> If we can use our resources to communicate and educate about this technology\n> in a responsible way, it\u2019s so much better than people reading misinformation\n> that creates anxiety or irresponsible expectations of utopia.\n\nSo the dangers and the hopes of our future rely on people. I\u2019m always more\nhopeful because I have hope in people. But when I get down or low, it\u2019s also\nbecause of people, not because of this technology. It\u2019s people\u2019s lack of\nresponsibility, people\u2019s distortion of what this technology is, and also,\nfrankly, the unfair role power and money play that is instigated or enhanced\nby this technology.\n\nBut then the positive side is the same. The students, the future generation,\nthe people who are trying to do good, the doctors using AI to cure diseases,\nthe biologists using AI to protect species, the agriculture companies using AI\nto innovate on farming. That\u2019s the hope I have for AI.\n\nAre there aspects of human intelligence that you think will always be beyond\nthe capabilities of AI?\n\nLi: I naturally think about compassion and love. I think this is what defines\nus as human\u2014possibly one of the most unique things about humans. Computers\nembody our values. But humans have the ability to love and feel compassion.\nRight now, it\u2019s not clear there is a mathematical path toward that.\n\n###### Your participation enriches the conversation\n\nRespond to the ideas raised in this essay by writing to forum@issues.org. And\nread what others are saying in our lively Forum section.\n\n###### Share\n\n#### Cite this Article\n\nLi, Fei-Fei, and Sara Frueh. \u201c\u201cAI Is a Tool, and Its Values Are Human\nValues.\u201d.\u201d Issues in Science and Technology 40, no. 3 (Spring 2024): 26\u201329.\nhttps://doi.org/10.58875/LBZG7966\n\nVol. XL, No. 3, Spring 2024\n\n###### Share\n\n###### Download PDF\n\nSubscribe to Issues\n\n#### Newsletter Sign-up\n\n##### Sign up for our free weekly newsletter to receive the latest news and\nideas from Issues.\n\n###### In Focus\n\n### Navigating a Polluted Information Ecosystem\n\nFake news, misinformation, and disinformation have become bywords for the\nkinds of false and misleading information that\u2019s rampant online. But these\nterms\u2014and a focus on fact-checking problematic content more generally\u2014provide\nlittle understanding of the ways people create and share information. The\nessays here identify ways to help people navigate today\u2019s polluted information\necosystems.\n\n#### Related Articles\n\n##### How Health Data Integrity Can Earn Trust and Advance Health\n\nJochen Lennerz, Nick Schneider, Karl Lauterbach\n\nEfforts to share health data across borders snag on legal and regulatory\nbarriers. Before detangling the fine print, let\u2019s agree on overarching\nprinciples.\n\nRead More\n\n##### Living Computers\n\nLisa Margonelli\n\nOnce called \u201cliving computers\u201d by three of the founders of computer science,\ncomputational technology has pervaded society to such a degree that the\nhumanities\u2014which are increasingly regarded as less useful than STEM\ndisciplines\u2014are more crucial than ever to making sense of the present.\n\nRead More\n\n### Related Articles\n\n  * #### Mud, Muddling, and Science Policy\n\nLisa Margonelli\n\nThe devolution of big policy to small places poses new challenges around\nestablishing spaces for democratic decisionmaking, building knowledge to\ninform those decisions, and effectively linking the two.\n\nRead More\n\n  * #### Amanda Arnold Sees the Innovation Ecosystem from a Unique Perch\n\nAmanda Arnold, Megan Nicholson\n\nAmanda Arnold, vice president of governmental affairs and policy at Valneva, a\nprivate vaccine development company, talks about the role industry plays in\nthe science policy enterprise and what she has learned about the US innovation\necosystem from working across sectors.\n\nRead More\n\n\u00a9 2024 Arizona State University. All Rights Reserved.\n\nPO Box 877705, Tempe, AZ 85287\n\nDisclaimer\n\n#### Join the Conversation\n\nSign up for the Issues in Science and Technology newsletter to get the latest\npolicy insights delivered direct to your inbox. When you do, you'll receive a\nspecial offer for nearly 50% off a one-year subscription to the magazine\u2014or\nsimply subscribe now at this special rate.\n\nNotifications\n\n", "frontpage": false}
