{"aid": "40175446", "title": "Tesla Autopilot feature was involved in 13 fatal crashes, US regulator says", "url": "https://www.theguardian.com/technology/2024/apr/26/tesla-autopilot-fatal-crash", "domain": "theguardian.com", "votes": 16, "user": "pseudolus", "posted_at": "2024-04-26 23:26:18", "comments": 10, "source_title": "Tesla Autopilot feature was involved in 13 fatal crashes, US regulator says", "source_text": "Tesla Autopilot feature was involved in 13 fatal crashes, US regulator says | Tesla | The Guardian\n\nSkip to main contentSkip to navigation\n\nSkip to navigation\n\nPrint subscriptions\n\nSign in\n\nSearch jobs\n\nSearch\n\n  * Europe edition\n\n  * UK edition\n\n  * US edition\n\n  * Australia edition\n\n  * International edition\n\nThe Guardian - Back to homeThe Guardian\n\n  * World\n  * UK\n  * Climate crisis\n  * Ukraine\n  * Environment\n  * Science\n  * Global development\n  * Football\n  * Tech\n  * Business\n  * Obituaries\n\nA Tesla model 3 drives on autopilot along the 405 highway in Westminster,\nCalifornia, in 2022. Photograph: Mike Blake/Reuters\n\nA Tesla model 3 drives on autopilot along the 405 highway in Westminster,\nCalifornia, in 2022. Photograph: Mike Blake/Reuters\n\nTesla\n\n# Tesla Autopilot feature was involved in 13 fatal crashes, US regulator says\n\nFederal transportation agency finds Tesla\u2019s claims about feature don\u2019t match\ntheir findings and opens second investigation\n\nGuardian staff and agencies\n\nShare\n\nUS auto-safety regulators said on Friday that their investigation into Tesla\u2019s\nAutopilot had identified at least 13 fatal crashes in which the feature had\nbeen involved. The investigation also found the electric carmaker\u2019s claims did\nnot match up with reality.\n\nThe National Highway Traffic Safety Administration (NHTSA) disclosed on Friday\nthat during its three-year Autopilot safety investigation, which it launched\nin August 2021, it identified at least 13 Tesla crashes involving one or more\ndeath, and many more involving serious injuries, in which \u201cforeseeable driver\nmisuse of the system played an apparent role\u201d.\n\nTesla among electric carmakers forced to cut prices as market stalls\n\nRead more\n\nIt also found evidence that \u201cTesla\u2019s weak driver engagement system was not\nappropriate for Autopilot\u2019s permissive operating capabilities\u201d, which resulted\nin a \u201ccritical safety gap\u201d.\n\nThe NHTSA also raised concerns that Tesla\u2019s Autopilot name \u201cmay lead drivers\nto believe that the automation has greater capabilities than it does and\ninvite drivers to overly trust the automation\u201d.\n\nTesla said in December that its largest-ever recall, covering 2.03m US\nvehicles \u2013 or nearly all of its vehicles on US roads \u2013 was to better ensure\ndrivers pay attention when using its advanced driver-assistance system.\n\nAfter closing the first investigation, regulators opened another, this one\ninto whether that recall to install new Autopilot safeguards was adequate.\n\nThe NHTSA said it was opening the second investigation after identifying\nconcerns due to crash events after vehicles had had the recall software update\ninstalled \u201cand results from preliminary NHTSA tests of remedied vehicles\u201d.\n\nThat recall investigation covers models Y, X, S, 3 and Cybertruck vehicles in\nthe US equipped with Autopilot and produced in the 2012 to 2024 model years,\nNHTSA said.\n\nThe agency said Tesla has issued software updates to address issues that\nappear related to its concerns but has not made them \u201ca part of the recall or\notherwise determined to remedy a defect that poses an unreasonable safety\nrisk\u201d. The NHTSA also cited Tesla\u2019s statement \u201cthat a portion of the remedy\nboth requires the owner to opt in and allows a driver to readily reverse it\u201d.\n\nTesla said in December that Autopilot\u2019s software system controls \u201cmay not be\nsufficient to prevent driver misuse\u201d and could increase the risk of a crash.\n\nTesla did not immediately respond to a request for comment.\n\nIn February, Consumer Reports, a non-profit organization that evaluates\nproducts and services, said its testing of Tesla\u2019s Autopilot recall update\nfound that changes did not adequately address many safety concerns raised by\nthe NHTSA and urged the agency to require the automaker to take \u201cstronger\nsteps\u201d, saying Tesla\u2019s recall \u201caddresses minor inconveniences rather than\nfixing the real problems\u201d.\n\nTesla\u2019s Autopilot is intended to enable cars to steer, accelerate and brake\nautomatically within their lane, while enhanced Autopilot can assist in\nchanging lanes on highways but does not make vehicles autonomous.\n\nOne component of Autopilot is Autosteer, which maintains a set speed or\nfollowing distance and works to keep a vehicle in its driving lane.\n\nTesla said in December it did not agree with the NHTSA\u2019s analysis but would\ndeploy an over-the-air software update that will \u201cincorporate additional\ncontrols and alerts to those already existing on affected vehicles to further\nencourage the driver to adhere to their continuous driving responsibility\nwhenever Autosteer is engaged\u201d.\n\nThe NHTSA\u2019s then top official, Ann Carlson, said in December that the\ninvestigation determined that more needed to be done to ensure drivers are\nengaged when Autopilot is in use. \u201cOne of the things we determined is that\ndrivers are not always paying attention when that system is on,\u201d Carlson said.\n\nThe NHTSA opened its August 2021 investigation of Autopilot after identifying\nmore than a dozen crashes in which Tesla vehicles hit stationary emergency\nvehicles.\n\nSeparately, since 2016, the NHTSA has opened more than 40 special Tesla crash\ninvestigations in cases where driver systems such as Autopilot were suspected\nof being used, with 23 crash deaths reported to date.\n\nTesla\u2019s recall includes increasing prominence of visual alerts and the\ndisengaging of Autosteer if drivers do not respond to inattentiveness warnings\nand additional checks upon engaging Autosteer. Tesla said it would restrict\nAutopilot use for one week if significant improper usage is detected.\n\nTesla disclosed in October that the US justice department issued subpoenas\nrelated to its Full Self-Driving (FSD) and Autopilot features. Reuters\nreported in October 2022 that Tesla was under criminal investigation.\n\nTesla in February 2023 recalled 362,000 US vehicles to update its FSD beta\nsoftware after the NHTSA said the vehicles did not adequately adhere to\ntraffic safety laws and could cause crashes.\n\nExplore more on these topics\n\n  * Tesla\n  * Elon Musk\n  * Self-driving cars\n  * Automotive industry\n  * news\n\nShare\n\nReuse this content\n\n## Most viewed\n\n## Most viewed\n\n  * World\n  * UK\n  * Climate crisis\n  * Ukraine\n  * Environment\n  * Science\n  * Global development\n  * Football\n  * Tech\n  * Business\n  * Obituaries\n\n  * News\n  * Opinion\n  * Sport\n  * Culture\n  * Lifestyle\n\nOriginal reporting and incisive analysis, direct from the Guardian every\nmorning\n\nSign up for our email\n\n  * Help\n  * Complaints & corrections\n  * SecureDrop\n  * Work for us\n  * Privacy policy\n  * Cookie policy\n  * Terms & conditions\n  * Contact us\n\n  * All topics\n  * All writers\n  * Digital newspaper archive\n  * Facebook\n  * YouTube\n  * Instagram\n  * LinkedIn\n  * Twitter\n  * Newsletters\n\n  * Advertise with us\n  * Search UK jobs\n\nBack to top\n\n\u00a9 2024 Guardian News & Media Limited or its affiliated companies. All rights\nreserved. (dcr)\n\n", "frontpage": true}
