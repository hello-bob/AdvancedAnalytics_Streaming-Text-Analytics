{"aid": "40257469", "title": "My Journey Inside the Voice Clone Factory", "url": "https://www.theatlantic.com/technology/archive/2024/05/elevenlabs-ai-voice-cloning-deepfakes/678288/", "domain": "theatlantic.com", "votes": 1, "user": "fortran77", "posted_at": "2024-05-04 13:22:14", "comments": 0, "source_title": "ElevenLabs Is Building an Army of Voice Clones", "source_text": "My Journey Inside ElevenLabs' Voice-Clone Factory - The Atlantic\n\n## More From Artificial Intelligence\n\n## More From Artificial Intelligence\n\nExplore This Series\n\n  * ### ElevenLabs Is Building an Army of Voice Clones\n\nCharlie Warzel\n\n  * ### I Witnessed the Future of AI, and It\u2019s a Broken Toy\n\nCaroline Mimbs Nyce\n\n  * ### Would Limitlessness Make Us Better Writers?\n\nRachel Khong\n\n  * ### It\u2019s the End of the Web as We Know It\n\nJudith DonathBruce Schneier\n\nTechnology\n\n# ElevenLabs Is Building an Army of Voice Clones\n\nA tiny start-up has made some of the most convincing AI voices. Are its\ncreators ready for the chaos they're unleashing?\n\nBy Charlie Warzel\n\nDaniel Stier for The Atlantic\n\nMay 4, 2024, 7 AM ET\n\nMy voice was ready. I\u2019d been waiting, compulsively checking my inbox. I opened\nthe email and scrolled until I saw a button that said, plainly, \u201cUse voice.\u201d I\nconsidered saying something aloud to mark the occasion, but that felt wrong.\nThe computer would now speak for me.\n\nI had thought it\u2019d be fun, and uncanny, to clone my voice. I\u2019d sought out the\nAI start-up ElevenLabs, paid $22 for a \u201ccreator\u201d account, and uploaded some\nrecordings of myself. A few hours later, I typed some words into a text box,\nhit \u201cEnter,\u201d and there I was: all the nasal lilts, hesitations, pauses, and\nmid-Atlantic-by-way-of-Ohio vowels that make my voice mine.\n\nIt was me, only more pompous. My voice clone speaks with the cadence of a\npundit, no matter the subject. I type I like to eat pickles, and the voice\nspits it out as if I\u2019m on Meet the Press. That\u2019s not my voice\u2019s fault; it is\ntrained on just a few hours of me speaking into a microphone for various\npodcast appearances. The model likes to insert ums and ahs: In the recordings\nI gave it, I\u2019m thinking through answers in real time and choosing my words\ncarefully. It\u2019s uncanny, yes, but also quite convincing\u2014a part of my essence\nthat\u2019s been stripped, decoded, and reassembled by a little algorithmic model\nso as to no longer need my pesky brain and body.\n\nListen to the author's AI voice:\n\nUsing ElevenLabs, you can clone your voice like I did, or type in some words\nand hear them spoken by \u201cFreya,\u201d \u201cGiovanni,\u201d \u201cDomi,\u201d or hundreds of other fake\nvoices, each with a different accent or intonation. Or you can dub a clip into\nany one of 29 languages while preserving the speaker\u2019s voice. In each case,\nthe technology is unnervingly good. The voice bots don\u2019t just sound far more\nhuman than voice assistants such as Siri; they also sound better than any\nother widely available AI audio software right now. What\u2019s different about the\nbest ElevenLabs voices, trained on far more audio than what I fed into the\nmachine, isn\u2019t so much the quality of the voice but the way the software uses\ncontext clues to modulate delivery. If you feed it a news report, it speaks in\na serious, declarative tone. Paste in a few paragraphs of Hamlet, and an\nElevenLabs voice reads it with a dramatic storybook flare.\n\nListen to ElevenLabs read Hamlet:\n\nElevenLabs launched an early version of its product a little over a year ago,\nbut you might have listened to one of its voices without even knowing it. Nike\nused the software to create a clone of the NBA star Luka Don\u010di\u0107\u2019s voice for a\nrecent shoe campaign. New York City Mayor Eric Adams\u2019s office cloned the\npolitician\u2019s voice so that it could deliver robocall messages in Spanish,\nYiddish, Mandarin, Cantonese, and Haitian Creole. The technology has been used\nto re-create the voices of children killed in the Parkland school shooting, to\nlobby for gun reform. An ElevenLabs voice might be reading this article to\nyou: The Atlantic uses the software to auto-generate audio versions of some\nstories, as does The Washington Post.\n\nIt\u2019s easy, when you play around with the ElevenLabs software, to envision a\nworld in which you can listen to all the text on the internet in voices as\nrich as those in any audiobook. But it\u2019s just as easy to imagine the potential\ncarnage: scammers targeting parents by using their children\u2019s voice to ask for\nmoney, a nefarious October surprise from a dirty political trickster. I tested\nthe tool to see how convincingly it could replicate my voice saying outrageous\nthings. Soon, I had high-quality audio of my voice clone urging people not to\nvote, blaming \u201cthe globalists\u201d for COVID, and confessing to all kinds of\njournalistic malpractice. It was enough to make me check with my bank to make\nsure any potential voice-authentication features were disabled.\n\nI went to visit the ElevenLabs office and meet the people responsible for\nbringing this technology into the world. I wanted to better understand the AI\nrevolution as it\u2019s currently unfolding. But the more time I spent\u2014with the\ncompany and the product\u2014the less I found myself in the present. Perhaps more\nthan any other AI company, ElevenLabs offers a window into the near future of\nthis disruptive technology. The threat of deepfakes is real, but what\nElevenLabs heralds may be far weirder. And nobody, not even its creators,\nseems ready for it.\n\nIn mid-November, I buzzed into a brick building on a London side street and\nwalked up to the second floor. The corporate headquarters of ElevenLabs\u2014a $1\nbillion company\u2014is a single room with a few tables. No ping-pong or beanbag\nchairs\u2014just a sad mini fridge and the din of dutiful typing from seven\nemployees packed shoulder to shoulder. Mati Staniszewski, ElevenLabs\u2019 29-year-\nold CEO, got up from his seat in the corner to greet me. He beckoned for me to\nfollow him back down the stairs to a windowless conference room ElevenLabs\nshares with a company that, I presume, is not worth $1 billion.\n\nStaniszewski is tall, with a well-coiffed head of blond hair, and he speaks\nquickly in a Polish accent. Talking with him sometimes feels like trying to\nengage in conversation with an earnest chatbot trained on press releases. I\nstarted our conversation with a few broad questions: What is it like to work\non AI during this moment of breathless hype, investor interest, and genuine\ntechnological progress? What\u2019s it like to come in each day and try to\nmanipulate such nascent technology? He said that it\u2019s exciting.\n\nWe moved on to what Staniszewski called his \u201cinvestor story.\u201d He and the\ncompany\u2019s co-founder, Piotr Dabkowski, grew up together in Poland watching\nforeign movies that were all clumsily dubbed into a flat Polish voice. Man,\nwoman, child\u2014whoever was speaking, all of the dialogue was voiced in the same\ndroning, affectless tone by male actors known as lektors.\n\nThey both left Poland for university in the U.K. and then settled into tech\njobs (Staniszewski at Palantir and Dabkowski at Google). Then, in 2021,\nDabkowski was watching a film with his girlfriend and realized that Polish\nfilms were still dubbed in the same monotone lektor style. He and Staniszewski\ndid some research and discovered that markets outside Poland were also relying\non lektor-esque dubbing.\n\nMati Staniszewski\u2019s \u201cinvestor story\u201d as CEO of ElevenLabs begins in Poland,\nwhere he grew up watching foreign films clumsily dubbed into a flat voice.\n(Daniel Stier for The Atlantic)\n\nThe next year, they founded ElevenLabs. AI voices were everywhere\u2014think Alexa,\nor a car\u2019s GPS\u2014but actually good AI voices, they thought, would finally put an\nend to lektors. The tech giants have hundreds or thousands of employees\nworking on AI, yet ElevenLabs, with a research team of just seven people,\nbuilt a voice tool that\u2019s arguably better than anything its competitors have\nreleased. The company poached researchers from top AI companies, yes, but it\nalso hired a college dropout who\u2019d won coding competitions, and another \u201cwho\nworked in call centers while exploring audio research as a side gig,\u201d\nStaniszewski told me. \u201cThe audio space is still in its breakthrough stage,\u201d\nAlex Holt, the company\u2019s vice president of engineering, told me. \u201cHaving more\npeople doesn\u2019t necessarily help. You need those few people that are\nincredible.\u201d\n\nElevenLabs knew its model was special when it started spitting out audio that\naccurately represented the relationships between words, Staniszewski told\nme\u2014pronunciation that changed based on the context (minute, the unit of time,\ninstead of minute, the description of size) and emotion (an exclamatory phrase\nspoken with excitement or anger).\n\nMuch of what the model produces is unexpected\u2014sometimes delightfully so. Early\non, ElevenLabs\u2019 model began randomly inserting applause breaks after pauses in\nits speech: It had been training on audio clips from people giving\npresentations in front of live audiences. Quickly, the model began to improve,\nbecoming capable of ums and ahs. \u201cWe started seeing some of those human\nelements being replicated,\u201d Staniszewski said. The big leap was when the model\nbegan to laugh like a person. (My voice clone, I should note, struggles to\nlaugh, offering a machine-gun burst of \u201chaha\u201ds that sound jarringly inhuman.)\n\nCompared with OpenAI and other major companies, which are trying to wrap their\nlarge language models around the entire world and ultimately build an\nartificial human intelligence, ElevenLabs has ambitions that are easier to\ngrasp: a future in which ALS patients can still communicate in their voice\nafter they lose their speech. Audiobooks that are ginned up in seconds by\nself-published authors, video games in which every character is capable of\ncarrying on a dynamic conversation, movies and videos instantly dubbed into\nany language. A sort of Spotify of voices, where anyone can license clones of\ntheir voice for others to use\u2014to the dismay of professional voice actors. The\ngig-ification of our vocal cords.\n\nWhat Staniszewski also described when talking about ElevenLabs is a company\nthat wants to eliminate language barriers entirely. The dubbing tool, he\nargued, is its first step toward that goal. A user can upload a video, and the\nmodel will translate the speaker\u2019s voice into a different language. When we\nspoke, Staniszewski twice referred to the Babel fish from the science-fiction\nbook The Hitchhiker\u2019s Guide to the Galaxy\u2014he described making a tool that\nimmediately translates every sound around a person into a language they can\nunderstand.\n\nEvery ElevenLabs employee I spoke with perked up at the mention of this\nmoonshot idea. Although ElevenLabs\u2019 current product might be exciting, the\npeople building it view current dubbing and voice cloning as a prelude to\nsomething much bigger. I struggled to separate the scope of Staniszewski\u2019s\nambition from the modesty of our surroundings: a shared conference room one\nfloor beneath the company\u2019s sparse office space. ElevenLabs may not achieve\nits lofty goals, but I was still left unmoored by the reality that such a\nsmall collection of people could build something so genuinely powerful and\nrelease it into the world, where the rest of us have to make sense of it.\n\nElevenLabs\u2019 voice bots launched in beta in late January 2023. It took very\nlittle time for people to start abusing them. Trolls on 4chan used the tool to\nmake deepfakes of celebrities saying awful things. They had Emma Watson\nreading Mein Kampf and the right-wing podcaster Ben Shapiro making racist\ncomments about Representative Alexandria Ocasio-Cortez. In the tool\u2019s first\ndays, there appeared to be virtually no guardrails. \u201cCrazy weekend,\u201d the\ncompany tweeted, promising to crack down on misuse.\n\nElevenLabs added a verification process for cloning; when I uploaded\nrecordings of my voice, I had to complete multiple voice CAPTCHAs, speaking\nphrases into my computer in a short window of time to confirm that the voice I\nwas duplicating was my own. The company also decided to limit its voice\ncloning strictly to paid accounts and announced a tool that lets people upload\naudio to see if it is AI generated. But the safeguards from ElevenLabs were\n\u201chalf-assed,\u201d Hany Farid, a deepfake expert at UC Berkeley, told me\u2014an attempt\nto retroactively focus on safety only after the harm was done. And they left\nglaring holes. Over the past year, the deepfakes have not been rampant, but\nthey also haven\u2019t stopped.\n\nI first started reporting on deepfakes in 2017, after a researcher came to me\nwith a warning of a terrifying future where AI-generated audio and video would\nbring about an \u201cinfocalypse\u201d of impersonation, spam, nonconsensual sexual\nimagery, and political chaos, where we would all fall into what he called\n\u201creality apathy.\u201d Voice cloning already existed, but it was crude: I used an\nAI voice tool to try to fool my mom, and it worked only because I had the\nhalting, robotic voice pretend I was losing cell service. Since then, fears of\nan infocalypse have lagged behind the technology\u2019s ability to distort reality.\nBut ElevenLabs has closed the gap.\n\nThe best deepfake I\u2019ve seen was from the filmmaker Kenneth Lurt, who used\nElevenLabs to clone Jill Biden\u2019s voice for a fake advertisement where she\u2019s\nmade to look as if she\u2019s criticizing her husband over his handling of the\nIsrael-Gaza conflict. The footage, which deftly stitches video of the first\nlady giving a speech with an ElevenLabs voice-over, is incredibly convincing\nand has been viewed hundreds of thousands of times. The ElevenLabs technology\non its own isn\u2019t perfect. \u201cIt\u2019s the creative filmmaking that actually makes it\nfeel believable,\u201d Lurt said in an interview in October, noting that it took\nhim a week to make the clip.\n\n\u201cIt will totally change how everyone interacts with the internet, and what is\npossible,\u201d Nathan Lambert, a researcher at the Allen Institute for AI, told me\nin January. \u201cIt\u2019s super easy to see how this will be used for nefarious\npurposes.\u201d When I asked him if he was worried about the 2024 elections, he\noffered a warning: \u201cPeople aren\u2019t ready for how good this stuff is and what it\ncould mean.\u201d When I pressed him for hypothetical scenarios, he demurred, not\nwanting to give anyone ideas.\n\nDaniel Stier for The Atlantic\n\nA few days after Lambert and I spoke, his intuitions became reality. The\nSunday before the New Hampshire presidential primary, a deepfaked, AI-\ngenerated robocall went out to registered Democrats in the state. \u201cWhat a\nbunch of malarkey,\u201d the robocall began. The voice was grainy, its cadence\nstilted, but it was still immediately recognizable as Joe Biden\u2019s drawl.\n\u201cVoting this Tuesday only enables the Republicans in their quest to elect\nDonald Trump again,\u201d it said, telling voters to stay home. In terms of\npolitical sabotage, this particular deepfake was relatively low stakes, with\nlimited potential to disrupt electoral outcomes (Biden still won in a\nlandslide). But it was a trial run for an election season that could be\nflooded with reality-blurring synthetic information.\n\nResearchers and government officials scrambled to locate the origin of the\ncall. Weeks later, a New Orleans\u2013based magician confessed that he\u2019d been paid\nby a Democratic operative to create the robocall. Using ElevenLabs, he\nclaimed, it took him less than 20 minutes and cost $1.\n\nAfterward, ElevenLabs introduced a \u201cno go\u201d\u2013voices policy, preventing users\nfrom uploading or cloning the voice of certain celebrities and politicians.\nBut this safeguard, too, had holes. In March, a reporter for 404 Media managed\nto bypass the system and clone both Donald Trump\u2019s and Joe Biden\u2019s voices\nsimply by adding a minute of silence to the beginning of the upload file. Last\nmonth, I tried to clone Biden\u2019s voice, with varying results. ElevenLabs didn\u2019t\ncatch my first attempt, for which I uploaded low-quality sound files from\nYouTube videos of the president speaking. But the cloned voice sounded nothing\nlike the president\u2019s\u2014more like a hoarse teenager\u2019s. On my second attempt,\nElevenLabs blocked the upload, suggesting that I was about to violate the\ncompany\u2019s terms of service.\n\nFor Farid, the UC Berkeley researcher, ElevenLabs\u2019 inability to control how\npeople might abuse its technology is proof that voice cloning causes more harm\nthan good. \u201cThey were reckless in the way they deployed the technology,\u201d Farid\nsaid, \u201cand I think they could have done it much safer, but I think it would\nhave been less effective for them.\u201d\n\nThe core problem of ElevenLabs\u2014and the generative-AI revolution writ large\u2014is\nthat there is no way for this technology to exist and not be misused. Meta and\nOpenAI have built synthetic voice tools, too, but have so far declined to make\nthem broadly available. Their rationale: They aren\u2019t yet sure how to unleash\ntheir products responsibly. As a start-up, though, ElevenLabs doesn\u2019t have the\nluxury of time. \u201cThe time that we have to get ahead of the big players is\nshort,\u201d Staniszewski said. \u201cIf we don\u2019t do it in the next two to three years,\nit\u2019s going to be very hard to compete.\u201d Despite the new safeguards,\nElevenLabs\u2019 name is probably going to show up in the news again as the\nelection season wears on. There are simply too many motivated people\nconstantly searching for ways to use these tools in strange, unexpected, even\ndangerous ways.\n\nIn the basement of a Sri Lankan restaurant on a soggy afternoon in London, I\npressed Staniszewski about what I\u2019d been obliquely referring to as \u201cthe bad\nstuff.\u201d He didn\u2019t avert his gaze as I rattled off the ways ElevenLabs\u2019\ntechnology could be and has been abused. When it was his time to speak, he did\nso thoughtfully, not dismissively; he appears to understand the risks of his\nproducts. \u201cIt\u2019s going to be a cat-and-mouse game,\u201d he said. \u201cWe need to be\nquick.\u201d\n\nLater, over email, he cited the \u201cno go\u201d\u2013voices initiative and told me that\nElevenLabs is \u201ctesting new ways to counteract the creation of political\ncontent,\u201d adding more human moderation and upgrading its detection software.\nThe most important thing ElevenLabs is working on, Staniszewski said\u2014what he\ncalled \u201cthe true solution\u201d\u2014is digitally watermarking synthetic voices at the\npoint of creation so civilians can identify them. That will require\ncooperation across dozens of companies: ElevenLabs recently signed an accord\nwith other AI companies, including Anthropic and OpenAI, to combat deepfakes\nin the upcoming elections, but so far, the partnership is mostly theoretical.\n\nThe uncomfortable reality is that there aren\u2019t a lot of options to ensure bad\nactors don\u2019t hijack these tools. \u201cWe need to brace the general public that the\ntechnology for this exists,\u201d Staniszewski said. He\u2019s right, yet my stomach\nsinks when I hear him say it. Mentioning media literacy, at a time when trolls\non Telegram channels can flood social media with deepfakes, is a bit like\nshowing up to an armed conflict in 2024 with only a musket.\n\nThe conversation went on like this for a half hour, followed by another\nsession a few weeks later over the phone. A hard question, a genuine answer,\nmy own palpable feeling of dissatisfaction. I can\u2019t look at ElevenLabs and see\nbeyond the risk: How can you build toward this future? Staniszewski seems\nunable to see beyond the opportunities: How can\u2019t you build toward this\nfuture? I left our conversations with a distinct sense that the people behind\nElevenLabs don\u2019t want to watch the world burn. The question is whether, in an\nindustry where everyone is racing to build AI tools with similar potential for\nharm, intentions matter at all.\n\nTo focus only on deepfakes elides how ElevenLabs and synthetic audio might\nreshape the internet in unpredictable ways. A few weeks before my visit,\nElevenLabs held a hackathon, where programmers fused the company\u2019s tech with\nhardware and other generative-AI tools. Staniszewski said that one team took\nan image-recognition AI model and connected it to both an Android device with\na camera and ElevenLabs\u2019 text-to-speech model. The result was a camera that\ncould narrate what it was looking at. \u201cIf you\u2019re a tourist, if you\u2019re a blind\nperson and want to see the world, you just find a camera,\u201d Staniszewski said.\n\u201cThey deployed that in a weekend.\u201d\n\nRepeatedly during my visit, ElevenLabs employees described these types of\nhybrid projects\u2014enough that I began to see them as a helpful way to imagine\nthe next few years of technology. Products that all hook into one another\nherald a future that\u2019s a lot less recognizable. More machines talking to\nmachines; an internet that writes itself; an exhausting, boundless comingling\nof human art and human speech with AI art and AI speech until, perhaps, the\nprovenance ceases to matter.\n\nI came to London to try to wrap my mind around the AI revolution. By staring\nat one piece of it, I thought, I would get at least a sliver of certainty\nabout what we\u2019re barreling toward. Turns out, you can travel across the world,\nmeet the people building the future, find them to be kind and introspective,\nask them all of your questions, and still experience a profound sense of\ndisorientation about this new technological frontier. Disorientation. That\u2019s\nthe main sense of this era\u2014that something is looming just over the horizon,\nbut you can\u2019t see it. You can only feel the pit in your stomach. People build\nbecause they can. The rest of us are forced to adapt.\n\nCharlie Warzel is a staff writer at The Atlantic and the author of its\nnewsletter Galaxy Brain, about technology, media, and big ideas. He can be\nreached via email.\n\n", "frontpage": false}
