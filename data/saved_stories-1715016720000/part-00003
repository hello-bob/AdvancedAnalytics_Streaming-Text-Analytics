{"aid": "40272221", "title": "Does Containerization Affect the Performance of Databases?", "url": "https://dok.community/blog/does-containerization-affect-the-performance-of-databases/", "domain": "dok.community", "votes": 1, "user": "TalktoCrystal", "posted_at": "2024-05-06 07:46:21", "comments": 0, "source_title": "Does containerization affect the performance of databases? - Data on Kubernetes Community", "source_text": "Does containerization affect the performance of databases? - Data on\nKubernetes Community\n\n## Data on Kubernetes Day Europe 2024 talks are now available for streaming!\n\nWatch Now!\n\nGet Newsletter Become a Sponsor\n\n  * Learn\n\n    * DoK Library\n    * DoK Reports\n    * DoK Landscape\n    * Databases on K8s Whitepaper\n  * Community\n  * Events\n  * Blog\n  * About\n\n    * About Us\n    * Ambassadors\n    * Sponsors\n    * Become a Sponsor\n    * Newsroom\n    * Private Wiki\n\nBlog\n\n# Does containerization affect the performance of databases?\n\nMay 02, 2024 by Guest Post\n\nThis post has been provided by DML community sponsor ApeCloud\n\nThe wave of database containerization is on the rise, as clearly shown in\nFig.1. Databases and analytics are now a major part of the tech scene. Yet, a\ncommon dilemma persists: Does containerization impact database performance? If\nyes, what factors come into play? How can we tackle performance and stability\nissues brought about by containerization?\n\n## Advantages and technical principles of containerization\n\nContainerization is a smart way to bundle an app and all its necessary parts\ninto a self-contained, portable and immutable runtime environment. Think of it\nas a tech wizardry that simplifies the process of packaging, deploying, and\nmanaging applications. This magic is made possible by container runtime\nengines such as Docker or Containerd. These engines are responsible for\ncreating, deploying, and supervising containers.\n\nKubernetes (K8s), is a game-changer in the world of container orchestration.\nThis open-source platform functions as a central hub for managing containers,\noffering a scalable infrastructure that automates a wide range of operations.\nAs a dominant container orchestration tool, it handles everything from\nseamless deployment to efficient scaling, comprehensive management, and smart\nscheduling.\n\n### Advantages of containerization\n\n  1. Flexibility and portability. The deployment and migration of databases are simpler and more reliable. With containerization, the runtime environment and version of databases can be claimed through declarative API in the form of IaC (Infrastructure as Code).\n  2. Resource isolation and scalability. By leveraging container runtime engines, containerization ensures that each database instance operates in its own isolated environment with dedicated resources. This separation minimizes interference between workloads, allowing for more efficient use of computing power and enhancing both performance and reliability.\n  3. More user-friendly scheduling strategies. Containerization\u2019s fine-grained resource management paves the way for smarter scheduling strategies. It enables tailored deployment tactics for different scenarios, such as blending offline and online workloads to balance resource usage or combining various database workloads to boost overall efficiency. Additionally, increasing deployment density can lead to significant reductions in computational costs.\n\n### Technical principles and categories of containerization\n\n#### Virtualization\n\nSpeaking of containers, virtualization cannot be ignored. Virtualization is a\ntechnique that abstracts and isolates computing resources, allowing multiple\nvirtual instances to run simultaneously on the same physical server. This is\nachieved by employing a software layer called Hypervisor between the hardware\nand the operating system. This layer partitions the physical server into\nmultiple virtual machines, each with its own independent operating system and\nresources.\n\nContainerization, on the other hand, is a more lightweight virtualization\ntechnique. It leverages operating system-level virtualization to create\nisolated pockets where applications and their required environments can run.\nOften, containerization is paired with virtualization to cater to various\nneeds for isolation in different computing scenarios.\n\n#### Breaking down virtualization+container technologies\n\nAccording to resource isolation and virtualization methods, mainstream\nvirtualization + container technologies can be categorized as follows:\n\n  1. Standard Containers, which adhere to the Open Container Initiative (OCI) standards, like Docker/Containerd, use runC as their runtime and are the go-to for K8s workloads today.\n  2. User-Space Kernel Containers, such as gVisor, also meet OCI standards and use runsc as their runtime, known for better isolation and security but at the cost of performance, making them ideal for less demanding workloads.\n  3. Microkernel Containers, which employ hypervisors like Firecracker and Kata-Container, comply with OCI specification too, and use either runC or runv as their runtime, striking a balance among security, isolation, and performance, sitting somewhere between standard containers and user-space kernel containers.\n  4. Virtual Machines, including KVM, Xen, VMWare, form the foundational virtualization layer for major cloud providers\u2019 servers, typically acting as Nodes in K8s, and operate at a more fundamental level than containers.\n\nFig. 2. Comparison of system architecture of various lightweight\nvirtualization methods. Orange for kernel space, green for user space. [2]\n\n#### Exploring OCI-compliant containerization technologies\n\nThe following paragraphs analyze several mainstream containerization\ntechnologies that comply with the OCI specification.\n\n  1. ### RunC\n\nRunC is an OCI-compliant container runtime integral to the Docker/Containerd\ncore container engine. It leverages Linux\u2019s Namespace and Cgroup functions to\ncreate a secure isolation for containers. During container operation, runC\nemploys Namespaces to segregate a container\u2019s processes, networking, file\nsystem, and IPC (Inter-Process Communication). It also utilizes Cgroups to\nconstrain the resource consumption of the container\u2019s processes. This\nisolation method ensures that applications within the container operate in a\nrelatively self-contained environment, isolated from the host system and other\ncontainers. While runC\u2019s isolation approach does introduce some overhead, such\noverhead is confined to namespace mapping, constraints check, and certain\naccounting procedures, which is theoretically minimal. Furthermore, the\naccounting overhead can be ignored when syscalls involve lengthy operations.\nIn general, the Namespace+Cgroup-based isolation approach has minimal impact\non the CPU, memory, and I/O performance.\n\nFig. 3. Architecture of RunC\n\n  2. ### Kata Containers\n\nImagine a secure bubble where each application operates in its own space,\nshielded from the outside world. That\u2019s what Kata Containers offers by\nharnessing the power of virtual machine technology. Building on Intel\u2019s Clear\nContainers innovation, Kata Containers merge the lightweight oversight of\nvirtual machine monitors with the agility of container runtimes.\n\nEach container gets its own virtual machine, complete with a unique kernel and\nuser space, ensuring that applications are kept in their own secure\ncompartments. This approach ramps up isolation, making it tough for\ncontainerized apps to peek into the host\u2019s resources. But there\u2019s a trade-off:\nthe extra steps of booting up and managing these virtual machines might slow\ndown syscalls and I/O operations a bit when compared to the classic container\nruntimes.\n\nFig. 4. Architecture of Kata Containers\n\n  3. ### gVisor\n\ngVisor is a cutting-edge container runtime that leverages user-space\nvirtualization to deliver enhanced security and isolation. At the heart of\ngVisor is a unique \u201cSandboxed Kernel\u201d that operates within the container\nitself, simulating and managing the operating system\u2019s interfaces.\n\nThis clever design ensures that containerized applications are kept separate\nfrom the Host Kernel, preventing them from directly meddling with or accessing\nthe host\u2019s resources. Although this approach significantly boosts security,\nit\u2019s worth noting that it might also lead to an increase in syscalls and I/O\nperformance overhead when compared to standard container runtimes.\n\nFig. 5. Architecture of gVisor\n\n  4. ### Firecracker\n\nFirecracker is a specialized virtualization solution tailored for serverless\ncomputing and light workloads. It leverages the concept of micro-VMs, treating\neach container as a standalone virtual machine.\n\nAt its core, Firecracker uses KVM (Kernel-based Virtual Machine) for\nvirtualization. Every container runs in its own VM, with its own kernel and\nroot filesystem, and it interacts with the host system through separate\nvirtual device emulators. This approach ensures a higher level of security and\nisolation. However, when compared to conventional container runtimes,\nFirecracker might result in a higher overhead for syscalls and I/O operations.\n\nFig. 6. Architecture of Firecracker\n\n#### Comparing the fundamentals\n\nTable. 1. Overview of implementations of virtualization and isolation in\nContainerization\n\nContainerd-RunC| Kata-Container| gVisor| FireCracker-Containerd  \n---|---|---|---  \nIsolation Mechanisms| Namespace + Cgroup| Guest Kernel| Sandboxed Kernel|\nmicroVM  \nOCI Runtime| RunC| Clear Container + runv| runsc| RunC  \nVirtualization| Namespace| QEMU/Cloud Hypervisor+KVM| Rule-Based Execution|\nrust-VMM + KVM  \nvCPU| Cgroup| Cgroup| Cgroup| Cgroup  \nMemory| Cgroup| Cgroup| Cgroup| Cgroup  \nSyscall| Host| Guest + Host| Sentry| Guest + Host  \nDisk I/O| Host| virtio| Gofer| virtio  \nNetwork I/O| Host + veth| tc + veth| netstack| tap + virtio-net  \n  \nAdditionally, some have analyzed how container engines like Containerd and\nCRI-O differ in their approach[3][5]. These comparisons, however, are beyond\nthe scope of this discussion and are left for curious readers to investigate\nfurther.\n\n## How K8s and containerization impact databases\n\nAs stated before, containerization brings a host of benefits to databases. It\nstreamlines the process of deploying and managing databases, offering a\nuniform and isolated runtime environment. This technology facilitates the\neffortless deployment and agile migration of databases across diverse and\ncomplex settings, while also providing a more standardized and user-friendly\napproach to version control. Furthermore, with the backing of K8s, the various\nroles and components within a database can be seamlessly and dynamically\nintegrated.\n\n### The challenges containerization presents databases\n\nHowever, the combination of K8s and containerization brings forth numerous\nchallenges for databases, stemming from the very nature of how databases\noperate. In contrast to the usual stateless applications, databases are\ncharacterized by:\n\n  1. Databases are intricate applications with multiple roles. A fully-fledged database consists of multiple roles, each with a specific function. For example, in a MySQL primary-secondary architechture, there are two MySQL containers, one serving as the primary and the other as the secondary. The primary offers the Read-Write ability while the secondary is Read-Only and serves as a hot standby. These roles are distinct and expressing their unequal relationship accurately is vital. Additionally, it\u2019s critical to manage these roles correctly during operations such as creation, restart, deletion, backup, and high availability. At the core of this is how to manage the data dependencies across containers, and both containers and K8s currently lack a well-abstracted and resolved solution for handling such interdependencies.\n  2. Databases demand robust data persistence and consistency. They have exacting storage requirements that cannot be met by containerization alone, necessitating additional components like the Container Storage Interface (CSI) and PersistentVolume for production-level workloads. The choice of storage medium also dictates the range of operations a database can perform. For instance, cloud disks provide high durability, snapshot backup capabilities, and the flexibility to attach or detach from various computing nodes, which are beneficial for database backup, restore, and ensuring high availability. In contrast, these features may be limited on local disks. For example, when it comes to a node failure, a local disk data replica could be permanently lost, bringing a significant challenge to maintaining high availability, and backup options are also restricted. Different storage solutions means varying degrees of persistence, different database feature set and architectures.\n  3. Databases are powerhouses that need to perform at top speed. Databases come with a variety of performance needs that can be sorted into categories like CPU, memory, network, and storage. For instance, when it comes to handling massive data analysis, products like ClickHouse and Greenplum are heavy on CPU and storage I/O. On the flip side, databases such as Redis and Memcached are more demanding on memory and network I/O. Then there are the classic workhorses like MySQL and PostgreSQL, which are traditional OLTP databases that also lean heavily on CPU and storage I/O. What\u2019s more, even within a single database, the thirst for resources can shift dramatically based on the type of query being run.\n  4. Databases come with their own set of security needs. The data stored in databases is often of high importance and confidentiality, which is why they demand stringent measures for environment isolation, data access control, and auditing.\n\nTo wrap it up, when it comes to running databases on the combined platform of\ncontainers and K8s, both the databases themselves and the container+K8s system\nface a slew of tough hurdles. Databases have to be flexible enough to handle\nthe fleeting lifecycle of containers, floating IPs, constant upgrades to their\nunderlying infrastructure, and the complexities of performance in various\nenvironments. Meanwhile, containerization and k8s must tackle issues like\nintroducing roles, orchestrating containers with underlying needs for a global\nconsistent data state, living up to high performance expectations, and staying\nin line with robust security measures.\n\nIn light of the previously mentioned aspects 1, 2, and 4, KubeBlocks has\ncrafted a set of thorough solutions. For those curious, additional details can\nbe found at http://kubeblocks.io. Now, back to the main focus of our\ndiscussion, the subsequent parts of this article will dive into a more\ndetailed examination of how containerization affects database performance.\n\n### How K8s and containerization affect database performance\n\nAs previously noted, database performance relies on key elements like CPU,\nmemory, storage, and network. This section dives into how K8s and\ncontainerization might affect database performance with respect to these\nfactors. It\u2019s worth mentioning that while K8s has certain scheduling and\naffinity strategies that could influence performance, these strategies are not\ninherently tied to containerization and are therefore beyond the scope of this\ndiscussion.\n\nThe upcoming sections will show how containerization affects the performance\nof applications, particularly databases, from the previously mentioned\nviewpoints. These sections gathered a wealth of industry research papers and\nrecent test results to dissect and understand the underlying causes and\ndiscrepancies in the data. Extra tests are also carried out to fill in the\ngaps, focusing on specific areas that were previously overlooked, like how\nK8s\u2019 Container Network Interface (CNI) influences network efficiency.\n\n#### CPU\n\nTest server: Quad-Core Hyper Thread 4 Intel Core i5-7500, 8GB RAM, 1TB disk,\nUbuntu 18.04 LTS.\n\nCase: The experimental data and scenarios presented here draw from the study\ndetailed in paper[1]. In Case 1, prime number computations are executed using\nsysbench with four concurrent threads. The performance is measured by the\nnumber of events processed each second. This test case is designed to simulate\na purely computational workload, with the majority of operations occurring in\nuser space, making syscalls negligible. Consequently, it is expected that\nperformance across various container technologies would be similar in theory.\n\nResult: The CPU performance across different containers shows negligible\ndifferences, with a modest performance dip of approximately 4% when compared\nto running on bare metal systems.\n\nAnalysis: The observed 4% drop in performance is likely due to the CPU\nrestrictions imposed by Cgroup. When the number of concurrent processes in\nSysbench matches the number of Hyper Threads, there\u2019s a significant chance of\nCgroup throttling. In such cases, the process must wait for a CFS period(100ms\nby default) due to the throttle. Cgroup allocates resources based on jiffies\nrather than seconds, making it nearly impossible for a container with 4 vCPUs\nto achieve 400% utilization. Some performance loss is expected, and the\nfrequency of this throttling can be tracked in the cpu.stat file within the\nCgroup.\n\nFig. 6. Architecture of Firecracker\n\nCase: Video decoding is performed using Davi1d, and the video files are\nseveral hundred megabytes in size. This test involves a considerable amount of\nsyscalls because it\u2019s necessary to read data from the disk. These syscalls can\naffect the performance of the application to some extent.\n\nResult: The performance of runC and Kata-QEMU shows a decline of around 4%,\nwhich aligns with the outcomes observed in the prime number tests. gVisor-\nptrace exhibits a more significant performance drop of 13%, whereas gVisor-KVM\ndelivers performance that matches that of a bare-metal setup.\n\nAnalysis: Video decoding involves sequential reading, and Linux has read-ahead\noptimization for sequential reads. Therefore, the majority of I/O operations\ndirectly read data from the page cache. RunC is primarily constrained by\nCgroup limitations, while the other three solutions are more affected by how\nsyscalls are executed. The paper does not further analyze the differences\nbetween gVisor-ptrace and gVisor-KVM. gVisor employs a component called gofer\nfor file system operations, which comes with its unique caching approach.\nFurther analysis may need to focus on gVisor\u2019s syscall processes and its\ncaching mechanisms.\n\nFig. 8. CPU performance (Dav1d benchmark) (Xingyu Wang 2022)\n\n#### Memory\n\nCase: RAMSpeed, with 4 sub-scenarios (Copy, Scale, Add, Triad). The specific\ndetails of the underlying principles are not elaborated here.\n\nResult: The performance of various solutions is similar.\n\nAnalysis: Once memory is allocated and page fault is handled, in theory,\ncontainerization should not have a significant impact on memory access. The\nreal factors that affect memory performance are syscalls such as mmap and brk.\nHowever, in this test, the proportion of such syscalls is minimal.\n\nFig. 9. Memory access performance (Xingyu Wang 2022)\n\nCase: Redis-Benchmark with sub-scenarios (GET, SET, LPUSH, LPOP, SADD).\n\nResult: K8s+containerization has minimal impact on runC and Kata-QEMU, while\ngVisor experiences significant degradation. gVisor-ptrace sees a performance\ndrop of approximately 95%, and gVisor-KVM experiences a reduction of about\n56%.\n\nAnalysis: Redis operates a single-threaded application with heavy network I/O.\nAll network I/O operations are performed through syscalls, which significantly\nhampers gVisor\u2019s performance. The original paper mistakenly attributed the\nperformance loss mainly to memory allocation. However, Redis internally uses\njemalloc, the user-space memory management tool. Jemalloc leverages mmap\nsyscalls to request large blocks of memory from the operating system and then\nallocates smaller blocks locally. Due to jemalloc\u2019s mature memory allocation\nand caching mechanisms, the frequency of mmap syscalls is minimal. When Redis\nis under full load, CPU sys usage for network I/O is around 70%. Thus, the\nmain reason for gVisor\u2019s performance issues in this context is the overhead\nfrom intercepting syscalls and its internal network stack, known as netstack.\nThis evaluation also suggests that gVisor is not an ideal choice for\nenvironments with intensive network I/O demands.\n\nFig. 10. Redis performance for different container runtimes (Xingyu Wang 2022)\n\n#### Disk I/O\n\nCase: IOZone reads and writes a 16GB file.\n\nResult: K8s + containerization shows negligible effects on sequential read and\nwrite performance. However, Kata-QEMU exhibits a notable performance drop,\nwith degradation ranging between 12-16%.\n\nAnalysis: Reading and writing large blocks of data is, in essence, a\nsequential process. As previously discussed, sequential reading is enhanced by\nthe operating system\u2019s ability to anticipate and prepare data in advance, with\nthe bulk of sequential reading and writing tasks being handled by the page\ncache. The original study examined the effects on Kata-QEMU and identified the\nvirtio-9p file system as the source of these impacts. The virtio-9p system was\noriginally created for network applications and lacks tailored optimizations\nfor use in virtual environments.\n\nFig. 11. Disk read and write performance (Xingyu Wang 2022)\n\nCase: Conducting tests on tmpfs (a temporary file storage in shared memory) to\nisolate and assess the effects of syscalls and memory copying on performance.\n\nResult: Except for gVisor, the performance of other solutions is similar.\n\nAnalysis: gVisor incurs higher syscall overhead, resulting in similar\nperformance degradation as observed in the redis-benchmark scenario.\n\nFig. 12. Disk read and write performance (tmpfs overlay) (Xingyu Wang 2022)\n\nCase: A single-threaded SQLite data insertion benchmark, where shorter\nexecution time is preferred.\n\nResult: RunC performs similarly to bare metal, Kata has a 17% increase in\nexecution time, and gVisor sees a 125% increase in execution time.\n\nAnalysis: Database workloads are complex and involve a combination of CPU,\nmemory, network, and disk I/O. They also frequently make syscall calls. In\nsuch intricate environments, gVisor may not be the optimal choice.\n\nFig. 13. Database record insertion performance (Xingyu Wang 2022)\n\n#### Network I/O\n\nCase: TCP stream throughput test, higher throughput is preferred.\n\nResult: gVisor exhibits poorer network performance, similar to what was\nobserved in the redis-benchmark case. The impact on the other solutions is\nminimal.\n\nAnalysis: gVisor is limited by its syscall mechanism and netstack\nimplementation, resulting in overall lower throughput.\n\nFig. 14. TCP_STREAM network performance (Xingyu Wang 2022)\n\nCase: This case evaluates TCP_RR, TCP_CRR, and UDP_RR. RR stands for request\nand response, where the TCP connection is established only once and reused for\nsubsequent requests. CRR indicates creating a new TCP connection for each\ntest. TCP_RR corresponds to a long connection scenario, while TCP_CRR\ncorresponds to a short connection scenario.\n\nResult: RunC performs similarly to bare metal; Kata experiences a small loss;\ngVisor still suffers from a substantial performance decline, the underlying\nprinciples of which are the same as mentioned before.\n\nFig. 15. TCP_RR, TCP_CRR and UDP_RR performance (Xingyu Wang 2022)\n\n#### CNI network\n\nContainers are commonly used with K8s, and container orchestration based on\nK8s has become the de facto standard. In a K8s environment, networking is\ntypically implemented through a combination of CNI and container technologies.\nThere\u2019s a variety of well-liked CNIs out there, such as Calico, Flannel,\nCilium and etc. In the latest versions, both Calico and Cilium extensively\nutilize eBPF (extended Berkeley Packet Filter) technology. Although the\nspecific implementations may differ, these two CNIs exhibit comparable\nperformance in many testing scenarios. For the nitty-gritty on their\nperformance, please refer to CNI Benchmark: Understanding Cilium Network\nPerformance[6].\n\nThe following tests compare the Cilium eBPF legacy host-routing mode and the\nCilium eBPF mode to examine the specific impact of the CNI on database\nperformance.\n\nLegacy host-routing:\n\nIn the traditional host-routing mode of Cilium eBPF, iptables plays a crucial\nrole in filtering and directing data packets. It remains an essential tool for\nsetting up and controlling the rules that govern how network traffic is\nrouted. Within this framework, Cilium steers the data flow towards its own\nproxy using iptables rules, after which the proxy takes over, processing and\nrelaying the traffic accordingly.\n\nIn this mode, Cilium leverages the NAT (Network Address Translation) of\niptables to modify the source and destination IP addresses for NAT and service\nload balancing.\n\neBPF-based host-routing:\n\nIn the new eBPF-based routing mode, Cilium no longer relies on iptables.\nInstead, it leverages the extended Berkeley Packet Filter (eBPF) of the Linux\nkernel for packet filtering and forwarding. eBPF host-routing allows bypassing\nall iptables and upper stack overhead within the host namespace, as well as\nreducing some context switch overhead during traversal of virtual network\ninterfaces. Network packets are captured early from the network device facing\nnetwork and directly delivered into the network namespace of the K8s Pod. For\noutgoing traffic, packets continue to pass through a veth pair, but are\nswiftly captured by eBPF and sent straight to the external network interface.\neBPF directly consults the routing tables, ensuring that this enhancement is\nfully transparent and seamlessly integrates with any other routing services\noperating on the system.\n\nFig. 16. Comparison of legacy and eBPF container networking [6]\n\nTest environment:\n\nKubernetes: v1.25.6 CNI: cilium:v1.12.14\n\nNode CPU: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz RAM 128G\n\nRedis: 7.0.6, 2 vCPU, Maxmemory: 2Gi\n\nCase:\n\nTable. 2. Overview of different service routing paths in K8s\n\nNetwork| Source| Target  \n---|---|---  \nNodeLocal2HostPod| Hostnetwork| Node| Local Pod  \nNodeLocal| Ethernet| Node| Local Process  \nPodLocal2Pod| Pod| Pod| Local Pod  \nNode2HostPod| Hostnetwork| Node| Remote Pod  \nNodeLocal2NodePort| NodePort| Node| Local  \nNode2Node| Ethernet| Node| Remote Process  \nNodeLocal2Pod| Pod| Node| Local Pod  \nPod2Pod| Pod| Pod| Remote Pod  \nNode2NodePort| NodePort| Node| Remote NodePort  \nPod2NodePort| Pod + NodePort| Pod| Remote NodePort  \nNode2Pod| Pod| Node| Remote Pod  \n  \nResult:\n\nLegacy host-routing with iptables:\n\nFig. 17. Redis benchmark under legacy host-routing with iptables\n\nFig. 18. Comparison between Host network and Pod network under legacy host-\nrouting\n\neBPF-based host-routing:\n\nFig. 19. Redis benchmark under eBPF-based host-routing\n\nFig. 20. Comparison between Host network and Pod network under eBPF-based\nhost-routing\n\nAnalysis: Traditional host-routing methods can drag down network efficiency,\ncreating a substantial 40% performance gap between Pod networks and host\nnetworks. However, using eBPF for host-routing can significantly level the\nplaying field, bringing the response times of Pod and host networks much\ncloser together. This improvement holds up no matter how complex the routing\nrules are, effectively closing the performance rift between the two types of\nnetworks. This advancement is a game-changer, especially for applications that\nrely heavily on network performance, such as Redis.\n\n#### Summary\n\nIn terms of CPU, memory, and disk I/O, runC exhibits performance closest to\nbare metal. Kata Containers has slightly lower performance compared to runC\nbut offers better security and isolation. gVisor, due to its syscall\nimplementation, has the poorest performance. This could be attributed to\ngVisor\u2019s emphasis on security features. However, newer versions of gVisor are\ncontinuously improving its performance.\n\nNetworking requires particular attention, as it is influenced by the\nKubernetes CNI (Container Network Interface). During tests that combined\nCilium eBPF with runC, it was observed that container network performance\ncould match that of the host network. Additionally, Cilium offers support for\nKata-containers, but its compatibility with other container technologies is\nsomewhat restricted.\n\nIn summary, runC offers performance that is on par with traditional bare metal\nsetups in many respects, which is why it\u2019s the go-to option for running\nKubernetes tasks. Kata Containers may lag a bit behind runC in terms of speed,\nbut it compensates with enhanced isolation, striking a good balance between\nefficiency and security. gVisor, on the other hand, allows for more adaptable\nisolation but at the cost of reduced performance, making it a better fit for\nsituations where security is more critical than speed. Firecracker is often\nused in scenarios similar to those of Kata Containers.\n\nTherefore, for running database workloads, runC and Kata-containers are the\nrecommended top choices.\n\n### Common database performance issues\n\nDatabase performance woes are a frequent headache for many. The article delves\ninto the typical scenarios that lead to such issues, offering an analysis of\nthe intricate workings of databases and their supporting infrastructure. It\nalso highlights the areas where our team is striving to make improvements.\n\n#### Disk I/O hang\n\nImagine a situation where MySQL is busy writing temporary files to the page\ncache, which involves frequent updates to the Ext4 file system\u2019s metadata.\nDuring such intense activity, both the CPU and I/O can become heavily engaged.\nThe MySQL process might experience frequent CPU throttling, leading to an\naccumulation of dirty pages. Eventually, the system tries to clean up by\nflushing these pages, which can saturate the hardware channels with dirty I/O\noperations. If, by chance, the process is paused by the CPU while it holds the\nExt4 Journal Lock, it can cause other processes using the same file system to\nfreeze. If these suspensions are frequent and prolonged, they can lead to an\nIO hang. This issue is especially prevalent in environments where local disks\nare shared, like on bare metal systems or with hostpath CSI storage. A widely\naccepted solution is to regulate the flow of BufferedIO, a functionality now\nsupported by Cgroup V2.\n\nAs shown, bottlenecks often arise not from a solitary issue but from a complex\ninterplay of interconnected elements. When it comes to disk I/O hang-ups,\nseveral components are at play: the page cache interacts with memory and disk\nI/O; CPU Throttle is linked to how the CPU is scheduled; and the Ext4 Journal\nsystem is tied to locking mechanisms. It\u2019s this intricate web of factors, each\naffecting the other, that culminates in a full-blown IO hang.\n\nIt is worth mentioning that many database vendors recommend using XFS as the\npreferred file system to optimize I/O operations. For a deeper understanding\nof the profound impact of disk I/O on databases, you can refer to A testing\nreport for optimizing PG performance on Kubernetes[7].\n\n#### Out of memory (OOM)\n\nUtilizing Cgroup for memory isolation alters the operating system\u2019s approach\nto memory management, which differs from the traditional bare metal methods.\nThis change results in increased challenges and demands on the system when it\ncomes to allocating and reclaiming memory.\n\nImagine a Pod that\u2019s designed to operate with a memory budget of 1 GB for both\nits request and limit. Within this 1GB of physical memory, all page allocation\nand reclaim must take place. Now, consider that databases are particularly\nmemory-hungry; even just firing up a blank database can gobble up several\nhundred megabytes. This leaves a slim margin for any actual applications to\nuse. Throw in some extra tasks like monitoring or log collection, often run\nalongside the main application as sidecars, and you\u2019re looking at a high risk\nof the database running out of memory in no time.\n\nBut the real horror isn\u2019t the Out of Memory (OOM) error itself; it\u2019s the\nagonizingly slow descent into failure that happens before the OOM even occurs.\nIt is an endless nightmare for databases and other Pods residential on same\nNode. Before the system finally falls to OOM, the page reclaim mechanism\ndesperately tries to reclaim enough memory, engaging in a lengthy and\ninefficient slow path. It tirelessly repeats this cycle, again and again,\nuntil it hits a set limit and gives up. Throughout this process, clients\nconnected to the database might experience a frustrating number of transaction\ntimeouts and abrupt disconnections.\n\nThe process known as \u201cpage reclaim slow path\u201d doesn\u2019t just disrupt a single\nCgroup Namespace; it has broader implications across the operating system.\nThis is because the OS shares many data structures at the host level. Take a\nPod\u2019s memory, for example: it may be part of a specific Cgroup Namespace in\ntheory, but in reality, the Host Kernel manages it through a unified Buddy\nSystem that relies on a global lock. This means that if one Pod is under heavy\nmemory strain and initiates the slow path for page reclaim, it can\ninadvertently slow down memory management subsystem for other Pods that are\notherwise functioning well. In extreme cases, this can lead to a slowdown of\ndatabases across the entire Node, all because one Pod\u2019s memory limit is too\nrestrictive.\n\nSolving this problem for good would require more sophisticated isolation\nstrategies, such as those using microkernels or virtual machines, which would\nallocate separate memory management spaces for different Pods. Additionally,\nan alternative approach is to proactively monitor and assess various\nperformance metrics within the database when OOM is unavoidable, therefore to\nensure a \u201cfail fast\u201d approach.\n\n#### Too many connections\n\nOLTP databases typically feature a specially pre-allocated buffer pool, where\nthe memory allocation is relatively stable. The components that tend to\nfluctuate in size include the connection structures, the working memory for\nintermediate calculations, page tables, page cache, etc.\n\nFor multi-process model databases like Postgresql and Oracle, each connection\nto the database is essentially a separate process. Now, imagine you have a\nlarge buffer pool, which is a storage area in memory for data. When you create\na new process, the system needs to set up a map to keep track of all that\ndata, and this map is not small. For every 4 KB of data in the buffer pool,\nthe system needs 8 bytes for this entry. Therefore the ratio between page\ntables and the buffer pool is 8/4K = 1/512. So, if you have 512 connections,\nthe memory needed for these entries is just as big as the buffer pool itself!\nThis can really limit how much a database can grow, especially when you need\nto handle lots of users at the same time, leading to a hefty hidden cost in\nmemory that many might not even notice.\n\nTypically, there are two strategies to address this issue. The first strategy\ninvolves deploying a proxy layer in front of the database. The layer\nintercepts numerous incoming connections and maintains a much smaller number\nof connections to the actual database backend. For instance, if the proxy\nholds P connections to the backend database but can handle C connections from\nthe application (C >> P), the connection reuse can significantly ease the load\non the database. The second strategy employs Hugepages, which, if with a size\nof 2M, changes the page table to buffer pool ratio to 1/256k (from 8/2M). This\nadjustment nearly eliminates the page table overhead and allows a multi-\nprocess model to support a far greater number of connections. However,\nHugepages come with their own set of complications and can add considerable\nstrain to resource management. As a result, the proxy-based approach is often\nseen as the more favorable and user-friendly option.\n\nThere are two main approaches to multi-threading. The first approach assigns\none thread per connection. While this avoids the issue of duplicating page\ntables as connections multiply, it can lead to problems like resource\nconflicts and too many context switches, which in turn can worsen performance.\nNevertheless, these problems can be mitigated by introducing a proxy. The\nsecond approach uses a Thread Pool, where many connections (C) are handled by\nfewer threads (P) (C >> P). This method is used by systems like Percona MySQL.\n\nBoth Proxies and Thread Pools aim to reuse connections, albeit through\ndifferent implementations. Additionally, combining these strategies can\nenhance system capacity and reduce overall load.\n\nTable. 3. Overview of different database process-connection models\n\nNumber of Connections: Number of Processes| Page Tables| Notes  \n---|---|---  \nMulti-Process| Proxy| C:P| *P| C >> P  \nDirect Connection| C:C| *C  \nMulti-Thread| Thread Pool| C:P| *1| C >> P  \nPer Thread| C:C| *1  \n  \n#### TCP retran\n\nNetworking will affect databases in mainly two aspects.\n\nOne is latency. Network latency affects the duration of data transmission,\nwhich in turn impacts the overall response time of the client. As latency\nrises, more connections are needed to handle the same volume of requests in a\ngiven time, leading to increased memory usage, context switches, and resource\ncontention, all of which degrade performance over time.\n\nThe other is about bandwidth. The quality of network transmission and the\nassociated delays are heavily influenced by the available bandwidth of\nindividual TCP connections, as well as the peak bandwidth capabilities of\nnetwork devices and switch ports. Congestion in any of these areas can cause\npacket loss at the OS Kernel or hardware level, which leads to retransmissions\nand packet disorder, further increasing latency and sparking a cascade of\nperformance issues.\n\nBeyond performance, networking problems can also affect system availability\nand stability, such as triggering failover due to heartbeat timeouts from high\nlatency or causing significant delays in data replication between primary and\nstandby systems.\n\n#### CPU schedule wait\n\nIn some VM-based containerization solutions, the processes running inside the\ncontainer don\u2019t have a direct counterpart in the Host Kernel. To the Host\nKernel, it only sees processes that are part of the VM\u2019s virtualization layer.\nIf you spot a process in the \u201crunning\u201d state within the VM, it doesn\u2019t\nnecessarily mean that it\u2019s actively running on the Host. This is because the\nHost and the VM operate on two distinct CPU scheduling systems. A process in\nthe VM actually starts running only when it\u2019s in the \u201crunning\u201d state and the\ncorresponding VM process on the Host is also active.\n\nThe interval from when a process is set to \u201crunning\u201d until it\u2019s truly executed\nis known as the additional scheduling wait time. This latency can impact\ndatabase performance, and in cases where performance is critical, strategies\nlike reducing the Host\u2019s workload or configuring VM CPU affinity can help\nreduce this impact.\n\n#### Lock & latch\n\nIn database technology, a Lock is designed to safeguard resources, while a\nLatch is meant to secure critical regions. Despite their different purposes,\nboth rely on the same underlying mechanisms at the operating system level. In\nLinux, for example, futexes are often employed to create mutexes and condition\nvariables that operate at a higher level.\n\nWhen resources like CPU, I/O, and memory are abundantly available, the\nscalability of databases is typically limited by their own transaction and\nlocking systems. Take the TPC-C benchmark as an example: most standalone\ndatabases hit a scalability ceiling somewhere between 32 Cores (64 Hyper\nThreads) ~ 64 Cores (128 Hyper Threads). Beyond 32 Cores, the additional CPUs\ncontribute less and less to the overall performance of the database.\n\nThe discussion of this issue isn\u2019t particularly relevant to containers, so it\nwill not be elaborated upon in this article.\n\n#### Various performance bottlenecks\n\nTable. 4. Overview of different database performance bottlenecks\n\nStorage Engine| Disk I/O| I/O Unit| Process Model| Performance Bottlenecks  \n---|---|---|---|---  \nMySQL| InnoDB| DirectIO + BufferedIO| Page| Multi-Thread| I/O bandwidth + Lock\n+ Connections  \nPostgreSQL| HeapTable| BufferedIO| Page| Multi-Process| I/O bandwidth + Lock +\nConnections  \nMongoDB| WiredTiger| BufferedIO/DirectIO| Page| Multi-Thread| I/O bandwidth +\nLock + Connections  \nRedis| RDB + Aof| BufferedIO| Key-Value| Single-Thread*| CPU Sys(Network)  \n  \n  * For MySQL, it\u2019s crucial to monitor the management of overflow temporary files. These files, managed through BufferedIO, can lead to a rapid accumulation of dirty pages within the operating system if not properly constrained by Cgroup. This can result in a bottleneck where the flushing of these dirty pages consumes nearly all the bandwidth of the storage device, leading to a slowdown or even a halt in processing regular requests\u2014a classic case of disk I/O hang.\n  * PostgreSQL operates in a multi-process model, so it is important to monitor the number of connections and the size of the page table. While Hugepages can alleviate some of the page table\u2019s load, they come with their own set of drawbacks. Utilizing proxies like pgBouncer for connection pooling is a better solution. When enabling full-page writes, PostgreSQL has a strong demand for I/O bandwidth, making I/O bandwidth the bottleneck. When both I/O and the number of connections work well, PostgreSQL\u2019s internal lock mechanism can become the bottleneck under higher concurrency. For more details, you can refer to A testing report for optimizing PG performance on Kubernetes[7].\n  * MongoDB generally delivers consistent performance, but it tends to encounter issues with disk I/O and connection limits. The WiredTiger storage engine does an impressive job managing the flow between cache and I/O, which minimizes the chances of I/O hang-ups even when there\u2019s high demand for I/O resources. However, it\u2019s worth noting that the workload for an OLTP (Online Transaction Processing) database is more intricate than that of MongoDB, making it a tougher challenge to maintain equilibrium.\n  * Redis often hits a bottleneck with its network performance, so it\u2019s crucial to keep an eye on the latency between your application and the Redis server. The latency is dictated by the quality of your network connections. When Redis is running at full tilt, it\u2019s the network stack that gobbles up more than 70% of the CPU usage. To tackle this challenge and boost network performance, Redis 6.0 rolled out a new feature: network I/O multi-threading. Despite this upgrade, the core worker thread in Redis remains single-threaded, preserving the platform\u2019s hallmark simplicity while ramping up its overall efficiency.\n\n## Summary\n\nBased on a comprehensive review of industry research, this article fills in\nthe gaps by testing the combination of containers and network CNI, delving\ninto how containerization affects CPU, memory, disk I/O, and Networking. It\nsheds light on the performance impact mechanisms of containerization and\noffers solutions. The analysis of test data reveals that runC + cilium eBPF\nprovides a containerization approach with performance nearly matching that of\nbare metal systems. For those prioritizing enhanced security and isolation,\nKata-containers emerges as a stellar alternative.\n\nFurthermore, building upon containerization, the article provides a\ntheoretical analysis of common performance bottlenecks in databases. It\nhighlights the complex dependencies of heavy workload databases on the Host\nKernel, drawing attention to often-overlooked factors such as page tables,\nJournal Lock, TCP Retran, and CPU schedule wait. Many of these issues are not\nspecific to containerization, but are prevalent in general. Lastly, the\narticle provides a qualitative analysis of several popular databases and\nsummarizes common issues based on the team\u2019s years of operational experiences.\nIt is hoped that these issues will receive ongoing attention and be addressed\nat the architectural level.\n\nDatabase containerization has become a frequently discussed topic. To be one\nof them, or not? The question lingers in the minds of every decision-maker.\nFrom our perspective, the key challenges of database containerization, such as\nperformance, stability, and stateful dependencies, are being addressed and\nsolved one by one. Each challenge will have a perfect answer as long as there\nis a demand.\n\n# References\n\n[1] Wang, Xing et al. \u201cPerformance and isolation analysis of RunC, gVisor and\nKata Containers runtimes.\u201d Cluster Computing 25 (2022): 1497-1513.\n\n[2] Goethals, Tom et al. \u201cA Functional and Performance Benchmark of\nLightweight Virtualization Platforms for Edge Computing.\u201d 2022 IEEE\nInternational Conference on Edge Computing and Communications (EDGE) (2022):\n60-68.\n\n[3] Espe, Lennart et al. \u201cPerformance Evaluation of Container Runtimes.\u201d\nInternational Conference on Cloud Computing and Services Science (2020).\n\n[4] 10 insights on real-world container use:\nhttps://www.datadoghq.com/container-report/.\n\n[5] Kube container Performance CRI-O vs containerD maybe alternatives:\nhttps://www.reddit.com/r/kubernetes/comments/x75sb4/kube_container_performance_crio_vs_containerd/.\n\n[6] CNI Benchmark: Understanding Cilium Network Performance:\nhttps://cilium.io/blog/2021/05/11/cni-benchmark/.\n\n[7] A testing report for optimizing PG performance on Kubernetes:\nhttps://kubeblocks.io/blog/A-testing-report-for-optimizing-PG-performance-on-\nKubernetes.\n\nclose\n\n### Learn\n\n  * DoK Library\n  * DoK Reports\n  * DoK Landscape\n\n### About\n\n  * About Us\n  * Ambassadors\n  * Sponsors\n  * Become a Sponsor\n  * Newsroom\n  * Private Wiki\n\n  * Community\n  * Events\n  * Blog\n\n#### Sign up for our newsletter\n\nSign up Now\n\n\u00a9 Copyright 2024 Constantia LLC - Content Distributed under CC BY 4.0\n\nWe are using advertisement, analytics, performance and others cookies to give\nyou the best experience on our website.\n\nYou can find out more about which cookies we are using or switch them off in .\n\nPrivacy Overview\n\nThis website uses cookies so that we can provide you with the best user\nexperience possible. Cookie information is stored in your browser and performs\nfunctions such as recognising you when you return to our website and helping\nour team to understand which sections of the website you find most interesting\nand useful.\n\n3rd Party Cookies\n\nThis website uses Google Analytics to collect anonymous information such as\nthe number of visitors to the site, and the most popular pages.\n\nKeeping this cookie enabled helps us to improve our website.\n\nPlease enable Strictly Necessary Cookies first so that we can save your\npreferences!\n\nNotifications\n\n", "frontpage": false}
