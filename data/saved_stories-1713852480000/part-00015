{"aid": "40120840", "title": "Design of Gesture Recognition Libraries for Web (2022)", "url": "https://www.akselipalen.com/2022/05/24/design-of-gesture-recognition-libraries-for-web/", "domain": "akselipalen.com", "votes": 1, "user": "ctoth", "posted_at": "2024-04-22 21:13:35", "comments": 0, "source_title": "Design of Gesture Recognition Libraries for Web", "source_text": "Design of Gesture Recognition Libraries for Web \u2013 Akseli Pal\u00e9n\n\nSkip to content\n\nAkseli Pal\u00e9n\n\nWeb Tech, Art, Mathematics\n\nResearch\n\n# Design of Gesture Recognition Libraries for Web\n\nPosted on 2022-05-24\n\nIf you are a web developer, you might have dealt with mouse and touch\ngestures. You might have written code to detect a swipe from a stream of\nnative browser events like touchmove, or you might have used a dedicated\nsoftware library for the task. If you were mad enough, you might even have\nthought about building a neat gesture recognition library yourself. I happen\nto be that mad kind. To help us all, this article attempts to put together\nwhat is needed to build such a gesture library.\n\nTherefore I reviewed multiple gesture recognition libraries and analysed their\ndesign approaches and interfaces. This article lists the findings, including\nhow do the libraries name the gestures, how do they expose the recognised data\nfor the developer, and how do their interfaces bind gestures to elements. You\ncan also find links to the libraries, common pitfalls in gesture detection,\nconflicts with the browsers, and ways to deal with them. There are lots to\ncover so hold on to your hats and enjoy.\n\nTable of Contents\n\n  * 1\\. List of gesture recognition libraries\n\n    * 1.1. General-purpose gesture libraries\n    * 1.2. Component frameworks or plugins that do gesture recognition\n    * 1.3. Additional gesture libraries worth to mention\n  * 2\\. What is gesture recognition?\n  * 3\\. Definitions\n  * 4\\. Typology of gestures\n\n    * 4.1. Browser gestures\n    * 4.2. Tap\n    * 4.3. Double tap\n    * 4.4. Hold\n    * 4.5. Move\n    * 4.6. Swipe\n    * 4.7. Pinch\n    * 4.8. Rotate\n    * 4.9. Transform pinch\n    * 4.10. Resize\n    * 4.11. Hover\n    * 4.12. Wheel\n    * 4.13. Orientation change\n    * 4.14. Direction\n    * 4.15. Custom gesture\n  * 5\\. Gesture event object properties\n\n    * 5.1. General properties of gesture event objects\n    * 5.2. Tap and hold events\n    * 5.3. Double tap events\n    * 5.4. Move, drag, and pan events\n    * 5.5. Swipe and flinch events\n    * 5.6. Rotate events\n    * 5.7. Scaling pinch events\n    * 5.8. Transform pinch events\n    * 5.9. Resize events\n  * 6\\. Gesture configuration parameters\n\n    * 6.1. Tap options\n    * 6.2. Hold and press options\n    * 6.3. Move, drag, and pan options\n    * 6.4. Swipe and flinch options\n    * 6.5. Rotate options\n    * 6.6. Resize options\n    * 6.7. Geometric restrictions\n    * 6.8. Enable or disable touch or mouse\n    * 6.9. Options to limit the number of concurrent gestures\n    * 6.10. Options for delegating the input events\n    * 6.11. Default coordinate system\n    * 6.12. Prevention of browser default behaviour\n    * 6.13. Options for stopping event propagation\n    * 6.14. Enabling passive touch event listeners\n    * 6.15. Manual or automatic recognition start\n    * 6.16. Inertia and animation options\n    * 6.17. Styling to apply during the gesture\n    * 6.18. Configuring gestures via data attributes\n  * 7\\. Binding gestures to elements\n\n    * 7.1. Binding via event listeners\n    * 7.2. Binding via component attributes\n    * 7.3. Binding via element abilities\n    * 7.4. Lazy binding\n  * 8\\. Usability for end users\n\n    * 8.1. Problems with time-restricted gestures\n    * 8.2. Problems with space-restricted gestures\n    * 8.3. Handling more than two pointers\n    * 8.4. Multitouch emulation with a mouse\n    * 8.5. Blocking gestures\n    * 8.6. Responsiveness\n  * 9\\. Usability for developers\n\n    * 9.1. Gesture end versus gesture cancel\n    * 9.2. Mouse and touch conflict\n\n      * 9.2.1. Difference in targeting\n      * 9.2.2. Delayed click on mobile\n    * 9.3. Conflicts with default behaviour\n\n      * 9.3.1. Touch Action\n      * 9.3.2. User Select\n      * 9.3.3. More tricks\n    * 9.3. Scroll and touchmove conflict\n    * 9.4. Handling of nested or duplicate listeners\n    * 9.5. Where to place the browser event listeners\n    * 9.6. Browser compatibility\n  * 10\\. Unit testing\n\n    * 10.1. Gesture simulation\n    * 10.2. Triggering gestures manually\n    * 10.3. Tooling\n  * 11\\. Conclusion\n  * References\n  * Contribute\n\n## 1\\. List of gesture recognition libraries\n\nI picked the following software libraries for the review by using web search,\nmy knowledge, and pre-existing lists of gesture handling packages. The libs\ncan be grouped in two main categories: the general purpose libs and the\ncomponent frameworks. Note that some of the libraries are under active\ndevelopment and their features prone to change. Therefore I recorded the\nreviewed versions and their release months.\n\n### 1.1. General-purpose gesture libraries\n\nHammer.js \u2013 Library for detecting mouse and touch gestures. Version 2.0.8\nApril 2016. ZingTouch \u2013 Gesture detection library for modern web. Version\n1.0.6 March 2018. Interact.io \u2013 Drag-n-drop, resize and multitouch\ninteraction. Version 1.10.11 March 2021. jQuery Finger \u2013 One-finger mouse and\ntouch gestures for jQuery. Version 0.1.6 October 2016. jquery.touch \u2013 Mouse\nand touch gestures for jQuery. Version 1.1.0 March 2017. jQuery Touch Events \u2013\nMouse and touch gestures for jQuery. Version 2.0.3 April 2020. AlloyFinger \u2013\nMinimalistic touch event abstraction. Version 0.1.15 January 2019.\n\n### 1.2. Component frameworks or plugins that do gesture recognition\n\nnippleJS \u2013 Joystick simulation with mouse and touch. Version 0.9.1 March 2022.\nReact Tappable \u2013 Basic tap, hold, and pinch gestures for React. Version 1.0.4\nApril 2018. React-Touch \u2013 Touch gesture bindings for React components. Version\n0.4.4 July 2018. Vue-Tap-and-Hold \u2013 Lightweight tap and hold events for Vue.\nVersion 1.0.7 May 2018. Vue Touch Events \u2013 Tap, swipe, and hold events for Vue\n2. Version 3.2.2 May 2021. Vue3 Touch Events \u2013 Tap, swipe, and hold for Vue 3.\nVersion 4.1.0 May 2021. YUI \u2013 A vast UI lib that has some gesture recognition.\nVersion 3.18.1 October 2014. Ext JS \u2013 Components and gesture recognition for\nSencha. Version 7.5.1 February 2022. Tapspace \u2013 A lib for zoomable UIs with\ngesture recognition. Version 1.6.0 October 2020.\n\n### 1.3. Additional gesture libraries worth to mention\n\nThese libs were not included in the review because they were either out of\nscope of the review or too limited or outdated in features. Yet I saw them\nworth to mention.\n\nPressure.js \u2013 Handling of force touch and pointer pressure. Out of scope of\nthe review. Nice examples. Deeptissue.js \u2013 Touch abstraction for MSPoint and\nWebKit Touch. Outdated. Hover on Touch \u2013 Alternative hover function with\ntouch. Narrow purpose. Good concept. RangeTouch \u2013 Improved touch experience\nfor range input. Narrow purpose. Solid implementation. Swiper \u2013 Touch-based\nswipe navigation. Out of scope of the review. Very popular. React Point \u2013\nNormalise mouse and touch events to simple point events in React. Narrow\npurpose.\n\n## 2\\. What is gesture recognition?\n\nWhat does gesture recognition in web browsers mean? When a user interacts with\na web browser via mouse, touches, stylus or any other pointer-like device, the\nbrowser emits a sequence of input events, usually about 30 to 60 times per\nsecond. These include mouse events like mousedown and touch events like\ntouchmove. Each event carries raw data about the interaction, like the x and y\ncoordinates and a reference to the element that triggered the event. The task\nfor the gesture recogniser is to first capture the event sequence and then\nresolve if the sequence resembles a larger gesture, like a swipe, rotation, or\neven something as simple as a click or hold.\n\nThe gesture recognition is not trivial. Especially so in the web where input\nmethods and environments vary from a single mouse on a large desktop monitor\nto multitouch on a small mobile screen. The needs to recognise gestures vary\ntoo, from the need to build a simple slider component on your page to the need\nto provide a general-purpose gesture library for all web developers.\nTherefore, as we saw above, multiple libraries and tools exist.\n\n## 3\\. Definitions\n\nFor clarity, let us first distinguish the following general concepts before\ndiving into the individual gestures.\n\nA software library, or lib for short, is a modular piece of code intended to\nact as a building block for other software. Also known as a software package\nor module. A host application, or app for short, is the application for end\nusers that builds upon software libraries such as a gesture recognition\nlibrary. An application programming interface, or API for short, is provided\nby the lib and acts as a vocabulary for the host app developer to access the\nfeatures of the library.\n\nThe end user, or user for short, is the human who interacts with the\napplication via gestures by using mouse, touch or other pointing device. The\napp developer, or dev for short, is the coder who integrates the gesture\nlibrary into the host app. The gesture library designer, or lib designer for\nshort, is the one who designed and built or will need to design and build the\ngesture recognition library.\n\nA native browser event or just browser event is a raw, low-level event created\nand emitted by the web browser when the user interacts on the page with a\nmouse, touch surface, or other pointing device. A gesture event is an abstract\nevent constructed and emitted by the gesture library after it recognises a\npossible gesture in a sequence of browser events.\n\nThe target element or target is the HTML element on which the user performs\nthe gesture. To avoid confusion, note that the target element emits events\nthat propagate further and therefore make the target element a source of\nevents for the gesture recognisers. From the perspective of the user it is a\ntarget and from the perspective of the recogniser it is a source.\n\nThe gesture triggers are the conditions on the target element that lead to the\nrecognition of the gesture. The gesture effect is what the gesture causes on\nthe web page. For example, the user moves a finger up on a mobile web page so\nthe page scrolls down. The finger movement is the trigger and the page scroll\nis the effect. The distinction is important as some of the libs handle only\nthe triggers and leaves the effect for the developer, while others do both.\n\nAlso because some gestures capture rotation angles and directions, let ccw be\nour abbreviation for the counter-clockwise rotation. Let ccw+x be the ccw\nrotation when it is relative to the positive x axis. Respectively, let cw+x\ndenote clockwise rotation from the positive x axis. The unit of rotation,\nusually degrees or radians, will be noted next to this direction abbreviation.\n\n## 4\\. Typology of gestures\n\nNext, I have listed names that the libs use for the gestures, like \u201ctap\u201d or\n\u201chold\u201d. Naming things is a convention and a good API often follows conventions\nto make things easy for the dev to understand. The list below groups the names\nby gesture type and briefly describes each gesture. The list notes the words\nused in libs\u2019 documentation and the exact names of emitted events.\n\nMost of the libs have a basic event for each gesture, like \u201crotate\u201d and then\nadditional events for its life cycle, like \u201crotatestart\u201d, \u201crotatemove\u201d, and\n\u201crotateend\u201d. I documented the both kinds. Also, some of the libs treat\ngestures as abilities to be given to elements and that is reflected in the\nnaming. Below you can find names for the abilities too.\n\n### 4.1. Browser gestures\n\nFor reference, let us begin by listing the native, low-level UI events emitted\nby the modern web browsers:\n\n  * mousedown, mouseenter, mouseleave, mousemove, mouseout, mouseover, mouseup\n  * click: fires after mousedown+mouseup [mdn]\n  * dblclick: fires after two rapid click events [mdn]\n  * auxclick: fires after clicking any mouse button except the primary button.\n  * contextmenu: usually right mouse button or context menu key [mdn]\n  * touchstart, touchmove, touchend, touchcancel [w3c]\n  * pointerover, pointerenter, pointerdown, pointermove, pointerup, pointercancel, pointerout, pointerleave, gotpointercapture, lostpointercapture [mdn]\n  * wheel: default action is to scroll or zoom the document [w3c]\n\nThere are also non-standard events implemented by some browsers:\n\n  * gesturestart, gesturechange, gestureend in Safari [mdn]\n  * MSGestureStart, MSGestureEnd, MSGestureTap, MSGestureHold, MSGestureChange, MSInertiaStart in Internet Explorer [mdn]\n  * MouseScrollEvent in Firefox [mdn]\n  * mousewheel in various browsers [mdn]\n\n### 4.2. Tap\n\nThe tap gesture is the most basic gesture there is. Tap is commonly used for\npointing, selection, and activation.\n\nCommon names: tap, click, single tap\n\nEvent names: \u2013 tap : the name used by practically every reviewed lib \u2013\nsingletap : jquery-touch-events, extjs \u2013 singleTap : alloyfinger\n\nLife cycle events: \u2013 tapstart, tapmove, tapend : jquery-touch-events \u2013 down,\nmove, up, cancel : interactjs \u2013 tapcancel : extjs\n\nAbility names: tappable : react-tappable\n\nSome libs, like jQuery Touch Events and Ext JS, define both tap and singletap\ngestures. How are they different? If the user performs multiple taps in\nsequence, each tap will immediately fire a tap event. In contrast, the\nsingletap event will fire only when there was one single tap. Therefore the\nsingletap event cannot fire immediately because it needs to be distinguished\nfrom a double tap.\n\n### 4.3. Double tap\n\nThe double tap gesture consists of two consecutive taps happening quickly in\nthe same place. The double tap is commonly used for activation and zooming in.\n\nCommon names: double tap, double click\n\nEvent names: \u2013 doubletap : hammer, interactjs, jquery.finger, jquery-touch-\nevents, extjs \u2013 doubleTap : jquery.touch, alloyfinger\n\n### 4.4. Hold\n\nThe hold gesture happens when a user keeps the pointer still and pressed at\nleast for a moment. The hold is commonly used for activation, selection, and\nsecondary action. Sometimes it used to emulate mouse hover in devices without\nmouse. The names for the gesture are plenty. It is amazing how one simple\ngesture can have so many different names.\n\nCommon names: hold, press, long tap, long press, tap hold, tap and hold\n\nEvent names: \u2013 hold : interactjs, vue-tap-and-hold, vue3-touch-events \u2013 press\n: hammer, jquery.finger, react-tappable, vue3-touch-events \u2013 tapAndHold :\njquery.touch \u2013 taphold : jquery-touch-events, hover-on-touch \u2013 longtap : vue-\ntouch-events, vue3-touch-events \u2013 longTap : alloyfinger \u2013 touchhold : vue-\ntouch-events \u2013 longpress : extjs\n\nAdditional life cycle events: \u2013 pressUp : hammer \u2013 release : vue3-touch-events\n\nAbility names: \u2013 holdable : react-touch\n\nThe difference between a long tap and a hold, according to Vue-Touch-Events,\nis that while the long tap triggers immediately after the mouse button is\nreleased or the finger lifted, the hold triggers immediately after the\nrequired time duration has passed and thus before the release.\n\n### 4.5. Move\n\nThe move gesture where user presses the pointer down, moves the pointer and\nthen lifts it. The gesture is commonly used for drag and drop, scrolling\npages, panning viewports, and reordering items; anything that attempts to move\nthings from a place to another. The move gesture also has many names, often\nrepresenting intentions of the gesture.\n\nCommon names: drag, pan, move, translate, slide\n\nEvent names: \u2013 drag : jquery.finger, vue3-touch-events, extjs \u2013 pan : hammer,\nzingtouch \u2013 pressMove : alloyfinger \u2013 moved : vue-touch-events \u2013 gesturemove :\nyui\n\nDirectional events: \u2013 panleft, panright, panup, pandown : hammer\n\nLife cycle events: \u2013 panstart, panmove, panend, pancancel : hammer \u2013\ndragstart, dragmove, draginertiastart, dragend : interactjs \u2013 dragstart, drag,\ndragend, dragcancel : extjs \u2013 dragStart, dragEnd, dragEnter, dragOver,\ndragLeave, drop : jquery.touch \u2013 start, moving, moved, end : vue-touch-events\n\u2013 press, drag.once, drag, release : vue3-touch-events \u2013 gesturemovestart,\ngesturemove, gesturemoveend : yui\n\nAbility names: \u2013 draggable : interactjs, react-touch\n\nRelated concepts: \u2013 dropzone onto which draggables can be dropped : interactjs\n\n### 4.6. Swipe\n\nThe swipe gesture could be described as a quick move gesture to a certain\ndirection. The swipe is commonly used in mobile devices to navigate between\nviews, to remove or hide items, such as notifications, and to reveal items and\nbuttons by sliding away a panel covering them.\n\nCommon names: swipe, flick\n\nEvent names: \u2013 swipe : hammer, zingtouch, alloyfinger, vue-touch-events,\nvue3-touch-events, extjs \u2013 flick : jquery.finger, yui\n\nLife cycle events: \u2013 swipeend : jquery-touch-events \u2013 swipestart, swipe,\nswipecancel : extjs\n\nDirectional events: \u2013 swipeleft, swiperight, swipeup, swipedown : hammer,\njquery-touch-events \u2013 swipeUp, swipeDown, swipeLeft, swipeRight :\njquery.touch, react-touch \u2013 swipe.up, swipe.down, swipe.left, swipe.right :\nvue-touch-events, vue3-touch-events\n\nAbility names: \u2013 swipeable : react-touch\n\nAdditionally, there is edge swipe that is a subclass of the swipe gesture. It\nis a swipe that began near the edge of the target element. Ext JS implements\nthe gesture with the following event names: edgeswipe, edgeswipestart,\nedgeswipeend, edgeswipecancel.\n\n### 4.7. Pinch\n\nThe pinch gesture is a multifinger gesture where the pointers are moving\neither towards or away from each other. The pinch is used for scaling and\nzooming in and out. In geographical map applications the pinch is often\ncombined with the move and rotation gestures to explore the map.\n\nCommon names: pinch zoom, expand, scale, distance\n\nEvent names: \u2013 pinch : hammer, alloyfinger, zingtouch, extjs \u2013 expand :\nzingtouch \u2013 distance : zingtouch\n\nDirectional events: \u2013 pinchin, pinchout : hammer\n\nLife cycle events: \u2013 pinchstart, pinchmove, pinchend, pinchcancel : hammer \u2013\npinchstart, pinch, pinchend, pinchcancel : extjs\n\n### 4.8. Rotate\n\nLike the pinch, the rotate gesture requires two or more pointers. During the\ngesture the pointers move around their mean point, constructing a rotation\nangle to apply to elements.\n\nThe gesture is used to orientate images or rotate the viewport, although it is\na bit tedious for human hands to perform rotations over 90 degrees in this\nway. On the good side, the libs seem to agree on the name.\n\nCommon names: rotate, rotation\n\nEvent names: \u2013 rotate : hammer, zingtouch, alloyfinger, extjs\n\nLife cycle events: \u2013 rotatestart, rotatemove, rotateend, rotatecancel : hammer\n\u2013 rotatestart, rotate, rotateend, rotatecancel : extjs\n\n### 4.9. Transform pinch\n\nTransform pinch is a gesture that combines the move, pinch, and rotate\ngestures. For some libs, like react-tappable, the transform gesture is called\nthe pinch gesture. The transform is used for moving and rotating objects and\nfor navigation. Due to its general nature, the gesture can act as the base\nclass for other gestures on the software level.\n\nCommon names: gesture, transform, multipoint, pinch, multitouch\n\nEvent names: \u2013 gesture : zingtouch, tapspace \u2013 pinch : react-tappable\n\nLife cycle events: \u2013 gesturestart, gesturemove, gestureend : interactjs,\ntapspace \u2013 multipointStart, multipointEnd : alloyfinger \u2013 pinchStart,\npinchMove, pinchEnd : react-tappable\n\nAbility names: \u2013 gesturable : interactjs \u2013 pinchable : react-tappable \u2013\ntouchable : tapspace\n\n### 4.10. Resize\n\nThe resize gesture is a move gesture that the user performs near the edge of\nthe target element with the intention to resize the element. In addition to\nresizing widgets, it is used for modifying area selection and cropping images.\nIt can be debated if the resize is truly a gesture or a way to utilise the\nmove gesture. Yet, one of the libs implements it.\n\nLife cycle events: \u2013 resizestart, resizemove, resizeinertiastart, resizeend :\ninteractjs\n\nAbility names: \u2013 resizable : interactjs\n\n### 4.11. Hover\n\nAlthough the hover is impossible to execute on touch devices, on the desktop\nthe mouse cursor can be moved over the element without clicking. It can be\nused for previewing and to make the click target stand out before the user\ndecides to click. Some of the libs consider this a gesture and recognise it\naccordingly. Often developers of touch-targeted apps simulate or replace the\nmouse hover with the hold gesture.\n\nCommon names: hover, over\n\nEvent names: \u2013 rollover : vue3-touch-events\n\n### 4.12. Wheel\n\nThe wheel gesture happens when the user rolls the mouse wheel. It is used for\nscrolling the page and zooming in and out. The wheel can be rolled up and down\nand sometimes also left and right.\n\nMany laptops simulate the wheel roll by detecting two fingers moving on the\ntouchpad or dedicating an area for scrolling near the touchpad edge.\n\nThe native wheel events behave differently depending on the device, the\noperating system and the browser. Especially the speed and direction can vary.\nTherefore some of the gesture libs have decided to abstract it as a gesture.\n\nCommon names: wheel, mouse wheel, scroll\n\nEvent names: \u2013 wheel : tapspace \u2013 mousewheel : yui \u2013 scrollstart, scrollend :\njquery-touch-events\n\nAbility names: \u2013 wheelable : tapspace\n\n### 4.13. Orientation change\n\nThe orientation change happens when a mobile device is tilted on its side or\nup. The gesture is used for readjusting the viewport size and refreshing the\nlayout.\n\nCommon names: tilt, screen rotate, orientation change\n\nEvent names: \u2013 orientationchange : jquery-touch-events\n\n### 4.14. Direction\n\nThe direction is a special gesture implemented by NippleJS, a lib that\nsimulates a joystick on touch screens. It is similar to the drag gesture,\nalthough it captures only the direction relative to the starting point of the\ndrag. The direction gesture comes in two flavours, dir and plain. The former\ndivides the joystick angle into four directions: up, down, left, and right.\nThe latter divides the angle into two halves: up and down, or left and right.\n\nEvent names: \u2013 dir, plain : nipplejs\n\nLife cycle events: \u2013 start, move, end : nipplejs\n\n### 4.15. Custom gesture\n\nSome of the libs provide tools for the developer to construct customised\ngestures. For example, Hammer.js gives an example of quadrupletap:\n\n    \n    \n    var quadrupleTap = new Hammer.Tap({ event: 'quadrupletap', taps: 4 })\n\nZingTouch helps the developer in a similar fashion. Here is a gesture that\nrequires two fingers to be pressed simultaneously no more than 500 ms.\n\n    \n    \n    var twoFingerTap = new ZingTouch.Tap({ numInputs: 2, maxDelay: 500 })\n\nA two-finger tap gesture\n\nA drag gesture along a path\n\nReact-touch provides an exceptional feature to create custom shaped drag\ngestures. We could even classify them as a separate gesture type, the path\ngesture. To define a path gesture, the developer prepares a sequence of\ndirections that together describe the rough path the user must perform to\ntrigger the gesture. Such a gesture can, for example, resemble a full circle\nor letters L or U, and be used for typing or to replace passwords and PIN\ncodes. See CustomGesture by react-touch for details.\n\n## 5\\. Gesture event object properties\n\nAn event object is a collection of key-value properties.\n\nWhen the lib recognises a gesture, it triggers a gesture event and calls all\nregistered handler functions. The functions are passed an event object. The\nevent object has properties that describe the gesture, for example how long it\nlasted.\n\nThe set of available properties and their names depend on the lib. Below we\nfirst go through some general properties the libs provide and then special\nproperties unique for each gesture type. The property names are written in\ncursive and their types and units within parens ().\n\n### 5.1. General properties of gesture event objects\n\nGesture event objects often carry similar properties, especially within the\nsame library. Here we can see various general properties the reviewed libs\ndeliver in their event objects.\n\n  * type of the gesture\n\n    * hammer: type (string)\n  * movement of the gesture center relative to the previous event\n\n    * hammer: deltaX, deltaY, deltaTime\n    * interactjs: dx, dy (px)\n  * page x and y coordinates of the starting event\n\n    * interactjs: x0, y0 (px)\n  * viewport x and y coordinates of the starting event\n\n    * interactjs: clientX0, clientY0 (px)\n  * total distance traveled during the gesture\n\n    * hammer: distance\n  * average angle traveled during the gesture\n\n    * hammer: angle\n  * current velocity\n\n    * hammer: velocityX, velocityY\n    * interactjs: velocityX, velocityY\n  * highest reached velocity during the gesture\n\n    * hammer: velocity\n  * current speed measure of the pointer. In physics, velocity has a direction while speed does not.\n\n    * interactjs: speed\n  * general direction of the gesture i.e. up, down, left, right\n\n    * hammer: direction, offsetDirection\n  * scale and rotation during the gesture\n\n    * hammer: scale, rotation\n  * center position of the gesture\n\n    * hammer: center\n  * original native browser event\n\n    * hammer: srcEvent\n    * jquery.finger: originalEvent\n    * jquery.touch: event\n  * target element that received the browser event\n\n    * hammer: target\n    * interactjs: target\n    * jquery.touch: element\n    * jquery-touch-events: target\n    * tapspace: element\n  * interaction-defining object created at the binding\n\n    * interactjs: interactable\n    * tapspace: item\n  * type of pointer used\n\n    * hammer: pointerType\n    * interactjs: pointerType\n    * extjs: pointerType\n  * event life cycle type i.e. start, move, end, cancel\n\n    * hammer: eventType (string), isFirst (boolean), isLast (boolean)\n  * list of current pointers of the gesture\n\n    * hammer: pointers\n  * list of new, changed, or removed pointers\n\n    * hammer: changedPointers\n  * identity of the pointer if there is only one.\n\n    * interactjs: pointerId\n  * reference to the preventDefault method of the browser event\n\n    * hammer: preventDefault\n  * a method to stop propagation\n\n    * react-tappable: stopPropagation\n  * the gesture the event is a part of\n\n    * interactjs: interaction\n  * event creation time\n\n    * interactjs: timeStamp\n\n### 5.2. Tap and hold events\n\nHere are event object properties found specific to the tap and hold gestures.\n\n  * x and y relative to the document\n\n    * jquery.touch: x, y\n  * x and y relative to the element\n\n    * jquery.touch: ex, ey\n    * jquery-touch-events: offset\n  * x and y relative to the screen\n\n    * jquery-touch-events: position\n  * duration of the tap\n\n    * zingtouch: interval (ms)\n    * intearctjs: dt\n    * jquery.touch: duration\n    * jquery-touch-events: duration (ms)\n  * starting point coordinates\n\n    * jquery-touch-events: startOffset, startPosition\n  * starting points of tap touches\n\n    * tapspace: points\n  * ending point coordinates\n\n    * jquery-touch-events: endOffset, endPosition\n  * timestamp at end\n\n    * jquery-touch-events: endTime\n\n### 5.3. Double tap events\n\nIn addition to the above tap event properties, the some double tap events had\nthe following properties.\n\n  * event object for each participated tap\n\n    * jquery-touch-events: firstTap, secondTap\n  * time between the taps\n\n    * interactjs: dt\n    * jquery-touch-events: interval (ms)\n\n### 5.4. Move, drag, and pan events\n\nThe following event object properties were found specific to the move gesture.\n\n  * current x and y coordinates on the page\n\n    * jquery.finger: x, y\n    * jquery.touch: x, y\n  * current x and y coordinates on the element\n\n    * jquery.touch: ex, ey\n  * change in x and y coordinates since the last event\n\n    * jquery.finger: dx, dy\n    * react-touch: dx, dy\n  * absolute change in x and y coordinates since the last event; can be used as a simple speed measure\n\n    * jquery.finger: adx, ady\n  * change in x and y since the gesture start\n\n    * react-touch: translateX, translateY\n  * the point where the gesture started\n\n    * jquery.touch: start\n  * total travel distance during the gesture\n\n    * zingtouch: distanceFromOrigin\n    * jquery.touch: distance\n  * average dragging speed\n\n    * jquery.touch: velocity\n  * average move direction during the gesture\n\n    * zingtouch: directionFromOrigin (degrees)\n    * jquery.finger: orientation, direction\n  * direction relative to the previous event\n\n    * zingtouch: currentDirection (degrees ccw+x)\n  * interaction with a drop area\n\n    * interactjs: dragEnter, dragLeave\n\n### 5.5. Swipe and flinch events\n\nThe following event object properties were found specific to the swipe\ngesture.\n\n  * distance swiped\n\n    * jquery.touch: distance (px)\n  * distance along x or y axis\n\n    * jquery-touch-events: xAmount, yAmount\n  * duration of the swipe\n\n    * jquery.touch: duration (ms)\n    * jquery-touch-events: duration (ms)\n  * average angle of the gesture\n\n    * zingtouch: currentDirection (degrees ccw+x)\n  * general direction of the gesture like up, down, left, right\n\n    * jquery-touch-events: direction\n  * speed of the gesture\n\n    * zingtouch: velocity\n    * jquery.touch: velocity (px/ms)\n  * starting point and ending point\n\n    * jquery-touch-events: startEvent, endEvent\n\n### 5.6. Rotate events\n\nThe following event object properties were found specific to the rotate\ngesture.\n\n  * angle between touch points at the beginning\n\n    * zingtouch: angle (degrees ccw+x)\n  * change in angle during the gesture\n\n    * zingtouch: distanceFromOrigin (degrees ccw)\n  * change in angle relative to the previous event\n\n    * zingtouch: distanceFromLast (degrees ccw)\n\n### 5.7. Scaling pinch events\n\nThe following properties were found specific to the pinch gesture that scales\nbut does not rotate or move.\n\n  * list of touches\n\n    * react-tappable: touches\n  * distance between touch points\n\n    * zingtouch: distance (px)\n    * react-tappable: distance (px)\n    * extjs: distance (px)\n  * center point of the gesture\n\n    * zingtouch: center\n  * change in pinch distance relative to the previous event\n\n    * zingtouch: change (px)\n  * ratio of the current distance per the initial distance\n\n    * extjs: scale\n\n### 5.8. Transform pinch events\n\nThe transforming pinch has properties of scaling pinch but also some\nproperties of rotation and move.\n\n  * center point of the gesture\n\n    * react-tappable: center\n  * displacement of the center since the gesture start\n\n    * react-tappable: displacement ({x,y})\n  * velocity of displacement\n\n    * react-tappable: displacementVelocity ({x,y})\n  * total travel distance of the center during the gesture\n\n    * tapspace: distance (px)\n  * distance between the first two touches\n\n    * interactjs: distance\n    * react-tappable: distance (px)\n  * angle of the line between the first two touches\n\n    * interactjs: angle\n    * react-tappable: angle (degrees)\n  * change in angle since the previous event\n\n    * interactjs: da\n  * change in angle since the gesture start\n\n    * react-tappable: rotation (degrees)\n  * current angular velocity\n\n    * react-tappable: rotationVelocity (degrees/ms)\n  * scaling ratio of the distance since the gesture start\n\n    * interactjs: scale\n    * react-tappable: zoom\n  * change in scaling ratio since the previous event\n\n    * interactjs: ds\n    * react-tappable: zoomVelocity\n  * rectangle that encloses all touch points\n\n    * interactjs: box\n  * event creation time\n\n    * react-tappable: time (ms since epoch)\n  * how long the gesture has lasted\n\n    * tapspace: duration (ms)\n\n### 5.9. Resize events\n\nThe following properties were found specific to the resize events.\n\n  * edges that were dragged\n\n    * interactjs: edges\n  * new size of the target after resize\n\n    * interactjs: rect\n  * size change in relation to the previous event\n\n    * interactjs: deltaRect\n\n## 6\\. Gesture configuration parameters\n\nMost of the libs allow the developer to adjust the gesture recognition\nparameters. The parameters include things like number of required pointers or\ndistance to travel before recognition.\n\nBelow I have mapped all the different parameters the libs implement, their\nproperty names, units, and built-in default values. I left out parameters not\nrelated to interaction, such as a namespace from which Vue lib reads its\nvalues.\n\nThe option names are written in cursive. The default values and units are\nnoted within parens ().\n\n### 6.1. Tap options\n\nThe libs allow tap gesture detection to be configured in the following ways:\n\n  * number of taps required to trigger:\n\n    * hammer: taps\n  * number of pointers required:\n\n    * zingtouch: numInputs (1)\n  * maximum time between taps:\n\n    * hammer: interval\n    * jquery.finger: doubleTapInterval\n    * jquery.touch: tapDelay (250 ms)\n  * maximum hold time for each tap:\n\n    * hammer: time\n    * zingtouch: maxDelay (300 ms)\n    * vue-tap-and-hold: tapTime (200 ms)\n  * maximum allowed movement during tap:\n\n    * hammer: threshold\n    * zingtouch: tolerance (10 px)\n    * react-tappable: moveThreshold (100 px)\n    * vue-touch-events: tapTolerance (10 px)\n    * tapspace: tapMaxTravel (20 px)\n  * disable click event and fire only tap:\n\n    * jquery.touch: noClick\n    * vue-touch-events: disableClick\n\n### 6.2. Hold and press options\n\nThe libs allow the hold gesture detection to be configured in the following\nways.\n\n  * minimum required press time:\n\n    * jquery.finger: pressDuration\n    * jquery.touch: tapAndHoldDelay (500 ms)\n    * react-tappable: pressDelay (1000 ms)\n    * react-touch: holdFor (1000 ms)\n    * vue-tap-and-hold: holdTime (1000 ms)\n    * vue-touch-events: touchHoldTolerance (400 ms), longTapTimeInterval (400 ms)\n  * maximum allowed movement during hold:\n\n    * react-tappable: pressMoveThreshold (5 px)\n  * how often to re-emit a progress event during hold:\n\n    * react-touch: updateEvery (250 ms)\n\n### 6.3. Move, drag, and pan options\n\nThe libs allow the drag gesture detection to be configured in the following\nways.\n\n  * number of touch points required:\n\n    * zingtouch: numInputs (1)\n  * minimum distance required:\n\n    * zingtouch: threshold (1 px)\n    * jquery.finger: motionThreshold\n    * jquery.touch: dragThreshold (10 px)\n    * yui: minDistance (0 px)\n  * minimum time required to recognise as a drag:\n\n    * jquery.touch: dragDelay (200 ms)\n    * yui: minTime (0 ms)\n  * how often to emit events during the gesture:\n\n    * vue3-touch-events: dragFrequency (100 ms)\n  * restrict the elements that can be targets for a drop:\n\n    * jquery.touch: dropFilter, dropFilterTraversal\n  * simulate friction\n\n    * interactjs: inertia\n  * mouse button required to trigger the gesture:\n\n    * yui: button\n  * direction to which the dragged element is allowed to move:\n\n    * interactjs: startAxis, lockAxis\n  * enable automatic scroll of the container if the dragged element is dragged across an edge.\n\n    * interactjs: autoScroll (boolean, false)\n\n### 6.4. Swipe and flinch options\n\nThe libs allow the swipe gesture detection to be configured in the following\nways.\n\n  * number of touch points required\n\n    * zingtouch: numInputs (1)\n  * speed the gesture must reach to be a swipe\n\n    * zingtouch: escapeVelocity (0.2 px/ms)\n    * yui: minVelocity (0 px/ms)\n  * distance the gesture must travel to be a swipe\n\n    * jquery.touch: swipeThreshold (30 px)\n    * react-touch: swipeDistance (100 px)\n    * vue-touch-events: swipeTolerance (30 px)\n    * yui: minDistance (10 px)\n  * duration the gesture is allowed to remain still\n\n    * zingtouch: maxRestTime (100 ms)\n  * maximum duration of the gesture\n\n    * jquery.finger: flickDuration\n  * direction of the swipe\n\n    * yui: axis (string, \u2018x\u2019 or \u2018y\u2019)\n\n### 6.5. Rotate options\n\nSome of the libraries provide options to configure rotate gesture detection.\n\n  * a point on the rotated element that must stay fixed during rotation\n\n    * tapspace: pivot (point)\n\n### 6.6. Resize options\n\nThe following configuration options were found for resizing:\n\n  * which areas act as handles for resizing\n\n    * interactjs: edges\n  * allow the target element to be resized beyond {0,0}\n\n    * interactjs: invert (boolean)\n  * maintain aspect ratio during resize\n\n    * interactjs: aspectRatio (boolean)\n\n### 6.7. Geometric restrictions\n\nSome libraries also allow special parameters that restrict or modify the\neffect of the gesture. For example, Interact.js allows the developer to set\nmodifiers that can limit how far the target element can be dragged, or set up\na grid the draggable will snap at drop. Also the resize options we saw above\nare a kind of geometric restrictions for the gesture effect.\n\n  * restriction pipeline:\n\n    * interactjs: modifiers (array)\n\n### 6.8. Enable or disable touch or mouse\n\nThe libraries that handle both mouse and touch events might have configuration\nsettings to disable either one.\n\n  * use touch events in the gesture recognition:\n\n    * jquery.touch: useTouch\n  * use mouse events in the gesture recognition:\n\n    * jquery.touch: useMouse\n\n### 6.9. Options to limit the number of concurrent gestures\n\nBrowsers and operating systems set a hard limit on how many cursors or touch\npoints can be active at a time. In a similar fashion, the libs can limit how\nmany concurrent gestures there can be. Interact.js allows this limit to be\nspecified for the whole document and for single elements.\n\n  * maximum number of concurrent gestures on the whole document\n\n    * interactjs: max (integer : infinity)\n  * maximum number of concurrent gestures on an element\n\n    * interactjs: maxPerElement (integer : 1)\n\nModern browsers expose the maximum supported number of touch points via\nnavigator.maxTouchPoints.\n\n### 6.10. Options for delegating the input events\n\nBecause mouse events do not target the element on which the gesture started,\nunlike touch events, some libs provide options that make the lib listen the\nwhole document in addition to the interactive element. In other words, the\nhandling of gestures is delegated to the document element.\n\nIn addition to the whole document, the options can target specific elements\nfor delegation. By default, the events bubble in DOM towards the document\nroot. Some libs provide tools to redirect the events to other elements not\nalong the default bubbling path. I could not find information on when it is\nnecessary set up a custom bubbling path, although I suspect it lets the\ndeveloper to set a large area to listen for the events for a single gesture.\n\nThe following gesture options were found for event delegation:\n\n  * interactjs: allowFrom, ignoreFrom (Element)\n  * jquery.touch: trackDocument, trackDocumentNormalize, delegateSelector (string)\n  * yui: root (Element)\n\n### 6.11. Default coordinate system\n\nThe browser events present their x and y coordinates in multiple reference\nframes. The page coordinates are relative to the whole document, the screen\ncoordinates are relative to the display, and the client coordinates are\nrelative to the browser viewport. In the context of browsers, the positive y\naxis points down.\n\nMost of the libs give the coordinates in multiple systems. Some others allow\nto configure which of the systems is used for the x and y coordinates:\n\n  * jquery.touch: coordinates (string : \u2018page\u2019)\n\n### 6.12. Prevention of browser default behaviour\n\nMost of the libs offer some way to enable or disable native preventDefault\ncalls via their configuration options. The options can affect either all the\ngestures handled by the lib, or single gesture type, or single gesture\nlistener.\n\n  * interactjs: preventDefault (string : \u2018always\u2019, \u2018never\u2019, or \u2018auto\u2019)\n  * jquery.touch: preventDefault (object)\n  * vue-touch-events: prevent (boolean)\n  * yui: preventDefault\n  * tapspace: preventDefault (boolean : true)\n\n### 6.13. Options for stopping event propagation\n\nMost of the libs offer some way for the developer to stop browser events that\nparticipated a gesture from propagating further in the DOM. A decade or two\nago there might have been a performance gain from doing so, especially if the\ndocument was very deep. Nowadays the gain is negligible and the act of\nstopping the event can cause more problems than it solves. For details see The\nDangers of Stopping Event Propagation by Philip Walton at CSS-Tricks.\n\nThe libs could expose a stopPropagation method in their gesture events.\nHowever, because a gesture is often a sequence of browser events, it might not\nbe possible to stop them all via the method. Therefore the stopping is done\nvia an option in advance.\n\n  * vue-touch-events: stop (boolean)\n\n### 6.14. Enabling passive touch event listeners\n\nSome of the libs allow control on whether the event listeners are registered\nas passive or not. A passive listener promises the browser that they do not\ncall the native preventDefault in its handler function. That allows the\nbrowsers to optimise performance for better responsiveness. See\naddEventListener at MDN for details about passive listeners.\n\n  * vue-touch-events: disablePassive (boolean)\n\n### 6.15. Manual or automatic recognition start\n\nSome of the libs allow the developer to configure whether to start the\nrecognition immediately after binding or manually later. The manual option\ngives the developer better control on when the element becomes interactive.\nConsider an example by Interact.js where element becomes draggable only after\na successful double tap.\n\n  * interactjs: manualStart (boolean), enabled (boolean)\n\n### 6.16. Inertia and animation options\n\nMost of the libs leave the effect of the gesture completely to the developer\nto decide. However, some libraries take care of the effect too, by providing\nprebuilt interaction and allowing its configuration. An example of such\ninteraction is moving the element with the drag gesture. One aspect of the\nmoving is the simulation of inertia or friction by animation. Options found in\nthe review for animation include:\n\n  * amount of friction i.e. how quickly the element slows down\n\n    * interactjs: resistance\n  * stopping speed at the end of the animation\n\n    * interactjs: endSpeed (px/s)\n  * enable the animation only after the gesture has ended\n\n    * interactjs: endOnly\n  * is the user able to interact with the element during the animation\n\n    * interactjs: allowResume\n  * duration of the animation after the gesture\n\n    * interactjs: smoothEndDuration\n\n### 6.17. Styling to apply during the gesture\n\nSome of the libs, especially the component framework plugins, allow the\ndeveloper to set a class name, for example \u2018active\u2019, that is automatically\napplied to the interactive element at the beginning of the gesture and removed\nat the end. In a similar fashion, Interact.js styles the mouse cursor for drag\nand resize gestures.\n\n  * interactjs: styleCursor (boolean : true), cursorChecker (function)\n  * vue-touch-events: touchClass (string : \u201d)\n\n### 6.18. Configuring gestures via data attributes\n\nWhile most of the libraries take the configuration options in an object,\njQuery Touch Events take the approach to read them from the dataset attributes\nof the element.\n\n    \n    \n    <div id=\"myElement\" data-xthreshold=\"500\"></div>\n\n## 7\\. Binding gestures to elements\n\nDevelopers need to \u201cbind\u201d together the element, the gesture, and the effect.\n\nAfter knowing which types of gestures the developer can expect, the next task\nfor the developer is to decide where and how to react to the gesture. The act\nof connecting the the gesture, the element and the functionality together is\ncalled binding.\n\nThere seems to be many ways for binding, although the major way is to listen\nevents and register event handlers that trigger when the event happens. An\nalternative way for the gesture libs to bind is to provide a wrapper method\nfor each gesture type so that the method does the binding internally.\nAdditionally in the component framework context, the component markup can\ndirectly contain instructions what events to listen and how to react.\n\nAll in all, the ways of binding are plenty and each lib implements them in\ntheir own flavour. Below, we go through them and give examples for each.\n\n### 7.1. Binding via event listeners\n\nHammer.js wraps the target element and begins to listen the browser events and\nemit gesture events. The gesture events can then be listened and handled via\nthe wrapper.\n\n    \n    \n    var hammertime = new Hammer(myElement, myOptions) hammertime.on('pan', handlerFn)\n\nZingTouch takes the approach where the developer first defines a region to be\nlistened for the browser events. Then the developer binds the region to a\ncertain gesture, a handler function, and an element within that region. The\nhandler function then, when triggered, executes the effect of the gesture,\nlike rotating the element. The region approach might feel superfluous but it\nhelps with the mouse gestures for reasons we will discuss in the section\n\u201cMouse and touch conflict\u201d.\n\n    \n    \n    var listenerArea = document.getElementById('.container') var inputArea = document.getElementById('.inputarea') var rotateTarget = document.getElementById('#rotatetarget') var region = new ZingTouch.Region(listenerArea) region.bind(inputArea, 'rotate', function (ev) { rotateTarget.style.transform = 'rotate(' + ev.angle + 'deg)'; })\n\nThe jQuery plugin libraries jQuery Touch Events, jQuery Finger, and\njQuery.touch work almost identically. They make jQuery objects to emit gesture\nevents that the developer can listen with .on(name, handler) and .off(name)\nmethods. A notable difference is that jquery.touch requires a .touch(opts)\ncall before gesture events begin emitting. I did not test whether the other\nlibs emit the events from the beginning or only after the first .on(name,\nhandler) registration.\n\n    \n    \n    $('#myElement').on('tap', handlerFn)\n\nBoth jQuery Finger and jQuery.touch allow additional selector parameter for\nthe libs to support the event delegation pattern. Following the pattern, an\nelement higher in the DOM tree listens to events and includes the events in\nthe recognition only if the selected element was the original target. For\nexample in the following snippet, the container is listened for events to\nrecognise a swipe gesture on the bar element.\n\n    \n    \n    $('#container').on('swipeLeft', '.bar', handlerFn)\n\nBoth jQuery Touch Events and jQuery.touch implement method wrappers for an\nalternative way to bind elements to handler functions.\n\n    \n    \n    $('#myElement').tap(handlerFn)\n\nAlloyFinger implements the similar event listener pattern as the jQuery\nplugins. It also allows defining the handler functions directly in the options\nobject.\n\n    \n    \n    var af = new AlloyFinger(element, { tap: handlerFn, swipe: anotherFn })\n\n### 7.2. Binding via component attributes\n\nReact and Vue based libraries instruct the developer to bind the handler\nfunctions directly in the component markup. For example, the following Vue-\nTouch-Events snippet binds a tap handler function to a span element via\nv-touch:tap attribute.\n\n    \n    \n    <span v-touch:tap=\"handlerFn\">Tap me</span>\n\n### 7.3. Binding via element abilities\n\nInteract.js takes the approach where it gives elements abilities, like\n\u201cdraggable\u201d, \u201cresizable\u201d, and \u201cgesturable\u201d. The developer can either specify\nevent handler functions in the parameters or listen the draggable for events\nas below.\n\n    \n    \n    interact('#target').draggable(parameters).on('move', handlerFn)\n\nA bit similar ability-giving terminology is used by React-touch. The following\nReact code is copied directly from the docs of the lib. The special Holdable\nelement has the ability to detect hold gestures and react to them even during\nthe hold.\n\n    \n    \n    import { Holdable } from 'react-touch'; <Holdable onHoldComplete={handleHold}> ({ holdProgress }) => <Button style={{opacity: holdProgress}} /> </Holdable>\n\nTapspace has chosen the approach where the target element is first wrapped as\na touchable and then enabled for specific interaction. The following example\nmakes the element in a Tapspace viewport draggable.\n\n    \n    \n    var touchable = new tapspace.Touchable(view, elem) touchable.start({ translate: true })\n\n### 7.4. Lazy binding\n\nThe libs that wrap the target element, like Hammer.js and jQuery Touch Events,\ncould begin the gesture recognition and event emission right away. On the\nother hand, listening to browser events and detecting gestures is relatively\nlaborious for the app, so why to do the work if no one is listening?\n\nFor example, assume we want to listen an element only for tap events so we\ncall wrapper.on('tap', handler). In this case, does the library need to\nrecognise and emit also drag and swipe gestures? No, because no one is\nlistening. The on(...) call is enough to signal the lib what we want.\n\nTherefore in libs like YUI the gesture recognition begins only after the first\nlistener is registered. However, the logic for such an intelligent API can\ncomplicate the library code so much that some of the libs, like jQuery.touch\nand Tapspace require the developer to specify beforehand what gestures to\nrecognise and emit.\n\n## 8\\. Usability for end users\n\nGestural interaction is often more intuitive way for users to interact than\ntyping. However, it has its pitfalls in usability and accessibility. In this\nsection we go through issues found during the review.\n\n### 8.1. Problems with time-restricted gestures\n\nThe double click, hold gesture, and other time-restricted gestures might be\ndifficult for users to find or physically impaired users to execute.\nEnvironment affects a lot too, for example a precise double click becomes\nharder in a shaking bus. See this UX Q&A about problems of the long press.\n\nIt is an open question should the gesture library be responsible to answer the\nusability concerns by limiting its features or should the responsibility be\nleft to app developers. For example, if the lib intentionally did not\nimplement hold and double tap gestures, the developers might be pushed to\nreach their design goals using only single tap.\n\n### 8.2. Problems with space-restricted gestures\n\nTiny targets are especially hard to hit with touch.\n\nThe smaller the area, the longer it takes to hit it. This is known as Fitts\u2019s\nlaw. The target should be large enough for the gesture to be performed quickly\nenough. Also with touch devices the hit point is not so precisely visible for\nthe user as with the mouse. It can be hard to hit a small target by touch even\nwhen there is plenty of time.\n\nA problem with gestures that especially require multiple pointers is that when\nthe touch points are too close to each other, they could become recognised\nonly as one. If the area on which the gesture is to be performed is too small,\nit can be problematic for the user to keep the pointers far enough.\n\nOn the other hand, dragging over long distances can be challenging. The user\nmight need to readjust the hand position and drop the dragged item\naccidentally. For details, see Drag-n-Drop by Laubheimer at NN/g.\n\n### 8.3. Handling more than two pointers\n\nThe human hand has usually five fingers, which can all touch the surface\nintentionally or accidentally.\n\nLibraries that provide pinch or rotation gestures usually work well with one\nor two touch points. However, not every library behaves well if additional\nfingers touch the screen, intentionally or not.\n\nFor example, react-tappable mentions a known issue that any touch event with\nthree or more touches is ignored.\n\nTapspace gestures are designed to work with any number of pointers. The lib\nuses a transform estimator named Nudged to handle the math required to extract\nmove, scale, and rotation properties from any number of touch points.\nDisclaimer: I am the author of both Tapspace and Nudged.\n\n### 8.4. Multitouch emulation with a mouse\n\nUsers with mouse are limited to one pointer and therefore cannot execute\nmultitouch gestures such as rotation. Hammer.js provides a tool named Touch\nEmulator that emulates two touch points when a mouse button and a shift key\nare pressed simultaneously. Moving the mouse cursor away from the original\nlocation while keeping the shift pressed emulates a pinch, and moving the\ncursor radially around the original location emulates a rotation.\n\n### 8.5. Blocking gestures\n\nSome gestures must block the default browser behaviour to work correctly.\nHammer.js calls them blocking gestures. Due to their blocking nature, the lib\nhas the vertical drag, pinch and rotate gestures disabled by default. When\nenabled, they block the default page scroll behaviour on the target element.\nUsers might be annoyed when they scroll a long page and suddenly there is an\nelement that steals the gesture for its own purposes.\n\nMap widgets sometimes solve the issue by requiring at least two pointers to\ninteract with the map. However, it is possible that users scroll the page by\nusing two or more fingers.\n\n### 8.6. Responsiveness\n\nShould a swipe gesture trigger a page flip or should the page already move\nduring the gesture? To make the UI feel responsive, the latter is better.\nAlso, the speed of the page flip should match the speed of the gesture. For\nfurther tips and details, see this guide for using gestures in material design\nby Google.\n\n## 9\\. Usability for developers\n\nBuilding an application is a complex task. The handling of gestures is no\ndifferent. In this section I gathered findings of things both the developer\nand the lib designer must think when they write gesture handling code.\n\n### 9.1. Gesture end versus gesture cancel\n\nBrowsers emit touchend and touchcancel events. Some of the libs interpret\nthese both as the end of the gesture, while others keep the concepts separate.\nFor example, Hammer.js keeps the end and cancel separate, whereas ZingTouch\nand Tapspace combine them into a single end event. What is the difference?\n\nThe end event denotes a completion of a successful gesture and the cancel\nevent denotes that the gesture was not successful. When the cancellation\noccurs, the recommended action for the app or the gesture lib is to undo any\neffects caused by the cancelled gesture. For example if a drag is cancelled,\nthe dragged element should return back to its initial position. Instead, if\nthe drag is ended, the dragged element should stay to where the gesture moved\nit.\n\nAnother situation where the clear separation between end and cancel is\nnecessary is when two gesture recognisers compete, for example a drag versus a\nswipe. The winner must somehow prevent the effects of the loser. That is\npossible if the loser can be gracefully cancelled. See this Ext JS gesture doc\nsection for detailed explanation.\n\nIn Pointer Event API, a mobile browser fires pointercancel event if the built-\nin gesture recognition classifies the gesture as page navigation. The winning\ngesture cancels the losing gestures. The cancelled \u201closer\u201d gestures should\nrevert their effects and let the winner continue.\n\n### 9.2. Mouse and touch conflict\n\nMost of the libs attempt to simplify the gesture handling by especially\nabstracting mouse and touch interaction behind the same interface. The two\ninteraction methods are different in many ways, not only in the number of\npointers.\n\n#### 9.2.1. Difference in targeting\n\nThe most problematic difference between native mouse and touch events, in my\nopinion, is that while the touch events always have their target on the\nelement that the touch began, the mouse events do not. The mouse events have\ntheir target on the element the cursor points at the time. These dynamics of\nthe target causes trouble for the libs that attempt to unify the mouse and\ntouch input behind the same API.\n\nA lib developer could ignore the difference at first, only to find later that\ndragging elements with a mouse is painful for quick-handed users. This is\nbecause, if a user moves the cursor too quickly, the cursor escapes the\ndragged element and the drag ends immediately. For details about the targeting\ndifference between mouse and touch, see this HTML5Rocks article.\n\nThe gesture libs try to solve the problem basically by collecting the mouse\nevents from a larger area. In practice, this means handling the mouse events\nhigher in the DOM hierarchy. The details between the libs differ. We will go\nthrough a few examples.\n\nZingTouch requires the developer to define a region in which all the gestures\nare happening. Given that the mouse stays within the region, the gesture can\nbe recognised correctly even if the mouse travels outside the original target\nelement.\n\nYUI library provides standAlone option for its move gesture. The gesture has\nlife cycle of start, move, and end events. When standAlone is set false on an\nelement, the element triggers move and end events only if the start event\nhappened on the same element.\n\nTapspace handles the difference by listening touch events on the target but\ndelegating the mouse events onto a viewport element that is an ancestor of the\ntarget. In a fashion similar to the region of ZingTouch, the viewport handles\nall the mouse events. The viewport remembers the original element on which the\nmouse gesture began at mousedown. As long as the mouse button is pressed down,\nthe viewport detects all mouse events, replaces their target with the\noriginal, and then re-emits the modified events as rat events. The rats have\ntheir target fixed to the original, so they are safe to be digested like touch\nevents by any gesture recogniser within the viewport.\n\nMost modern browsers implement Element.setPointerCapture() to let developers\ndeal with the issue. Some modern browsers also implement Pointer Lock API to\nfurther control the pointer behaviour.\n\n#### 9.2.2. Delayed click on mobile\n\nMobile web browsers are required to delay the click event on touch devices.\nThe delay, commonly 300 milliseconds, is needed to let the browser separate a\nclick from a double tap which the mobile browsers use for zooming by default.\nThe delay, although tiny, is enough to make the UI feel sluggish as presented\nin this article about response times by Jacob Nielsen.\n\nMany of the libs, for example Interact.js, implement the gestures so that\nthere is no need for the delay. Interact.js calls this feature the fast click.\nFor more details on the tap delay problem and how to solve it, see this Chrome\ndeveloper blog article.\n\n### 9.3. Conflicts with default behaviour\n\nBy default, many browser recognise and react to user gestures. Common examples\non mobile devices are scrolling the page with move or swipe gesture and\nzooming into an element by double tapping it. The default behaviour is not\nalways what the developer wants. Also the defaults might not be easy to\ndisable and therefore the libs offer help either via automation or\ninstructions.\n\n#### 9.3.1. Touch Action\n\nAs recommended by Interact.js, set touch-action: none in CSS of the target\nelement to prevent the default touch behaviour, like copying an image element\nor zooming into the element. See touch-action at MDN for details.\n\nHammer.js helps the developer by managing the touch action rule automatically\ndepending on the gesture. The developer can configure the behaviour with the\ntouchAction option.\n\n#### 9.3.2. User Select\n\nAs recommended by Interact.js, set user-select: none in CSS to disable text\nselection on the target element. The selection can be annoying for example\nduring dragging. However, the ability to copy text or portions of the page\nmight be useful for the user, so think it through before disabling.\n\n#### 9.3.3. More tricks\n\nThere are a few more tricks to improve the gesture experience via CSS styling,\nincluding the non-standard -webkit-user-drag and -webkit-touch-callout rules.\nHammer.js has put together a good list of CSS properties to consider, see\nHammer.defaults.cssProps. See also Hammer.js Tips \u2018n Tricks\n\n### 9.3. Scroll and touchmove conflict\n\nWhen a page is navigated by touch on a mobile device, some mobile browsers\nfire only touchmove event and some browser might fire both scroll and\ntouchmove events, according to jQuery Touch Events docs.\n\nOn a desktop or laptop device, a mouse wheel roll or similar action on a\ntouchpad fires a wheel event. The wheel event scrolls the web page by default\nthus causing also a scroll event.\n\n### 9.4. Handling of nested or duplicate listeners\n\nIn a DOM element hierarchy, a parent and a child can both listen to same\ngesture events. Alternatively, an element can have multiple listeners for the\nsame event. One aspect the lib designer should prepare for is how these\nsituations are solved.\n\nFor example, consider the situation where both the parent and the child listen\nfor a pan gesture event. The event can freely propagate from the child to the\nparent. When the user executes the pan gesture, the both handlers will be\nactivated and the both elements will move. For the user, it might look like\nonly the parent is moving if the elements are moving at unison. Alternatively,\nit might look like the children is moving at double speed because it followed\nthe parent in addition to the gesture.\n\nBrowsers provide two methods for preventing the same event triggering\nunintended actions: event.preventDefault and event.stopPropagation. The\nlatter, stopPropagation, is prone to cause unforeseen side-effects that are\nhard to debug. A good treatment on the subject with real-world examples is\navailable at The Dangers of Stopping Event Propagation by Philip Walton at\nCSS-Tricks. Due to the problems of stopPropagation, the gesture libraries\nprefer the preventDefault method.\n\nAlthough the preventDefault is primarily designed to prevent browser\nbehaviour, the libs can utilise it as a general way to signal that the event\nis handled. In the jquery.finger library, calling the event.preventDefault\nwill, in addition to the browser default behaviour, prevent triggering the\nparent and possible other listening ancestors.\n\nThe Ext JS takes the approach where the handler can claim the gesture so that\nno other gesture will finish. See Ext JS Claiming a Gesture for details.\n\n### 9.5. Where to place the browser event listeners\n\nIs it better to place the listeners directly on the target element or let the\nevents bubble up to listeners of its ancestors? The latter is called event\ndelegation. The benefits of the event delegation are debatable. See for\nexample this Stack Overflow answer.\n\nThe Ext JS lib has chosen the approach where the browser events will bubble\nall the way to the window object and the gesture recognition is done there.\nSee Ext JS Gestures for details.\n\nOverall, the problem of where to place the listeners is connected to things we\ndiscussed above in the sections \u201cHandling of nested or duplicate listeners\u201d\nand \u201cMouse and touch conflict\u201d.\n\n### 9.6. Browser compatibility\n\nThe reviewed libraries have different targets when it comes to browser\ncompatibility. Fortunately, modern web browsers respect the standards set by\nWorld Wide Web Consortium in a cheerful degree.\n\nHammer.js maintains a chart that shows which gestures are compatible with\nwhich browsers. Hammer.js Browser/device support\n\njQuery Touch Events provides a utility function isTouchCapable() to determine\nif the browser or device supports touch events.\n\n## 10\\. Unit testing\n\nOne way to test gesture recognition is to simulate hand movements.\n\nQuality software requires unit tests to ensure everything works as intended.\nThe tests become especially helpful during the maintenance phase of the\nsoftware life-cycle. A small bug fix can easily cause unexpected side effects\nafter the time has faded the quirky design details from the mind of the lib\ndesigner. Unit tests make the maintenance burden bearable.\n\nGesture recognition is somewhat harder to test than for example a math\nlibrary. A math function has numeric inputs and outputs that are easy to write\nin code by hand. Gestures are dynamic input from physical users, a real-world\nphenomenon that can amount to hundreds of data points over a few hundred\nmilliseconds for a single gesture. Also, as we have seen above, the gestures\ncan vary and be restricted in speed, direction, duration, and other ways. Due\nto these hardships, the lib designers have come up helpful tools.\n\n### 10.1. Gesture simulation\n\nWriting the sequences of data points by hand would be very tedious. Therefore\nbuilding unit tests for gesture recognition require some kind of tools to\ncreate a wide range of test gestures in a relatively lightweight manner.\nFortunately these tools exist and the gesture libraries utilise them in a\nvarying degree. The following list presents the tools spotted during the\nreview.\n\n  * Virtual Pointer \u2013 Simulates a pointer with jQuery\n  * YUI gesture-simulate \u2013 Gesture simulation for YUI\n  * Ghosture \u2013 Simulate touch gestures in headless tests. Disclaimer: I am its lazy maintainer.\n\nThe simulation tools provide API to run virtual gestures in the browser. The\ngesture runner creates synthetic input events and emits them from specific\nelement at specific coordinates. The synthetic events work exactly as the real\nevents and bubble up the DOM accordingly. The task for the lib test designer\nis to first program the gestures and setup the recognisers and then see if the\nrecogniser worked as expected.\n\nBecause the real DOM is involved, the tests need to be run in a real browser.\nThe programmers and continuous integration workflows are used to running tests\non the command line. Fortunately, headless browsers testing is a thing.\nHeadless browsers allow web apps and test suites to run in a virtual browser\ncompletely from the command line. See Headless Chrome and Puppeteer for\nexample.\n\n### 10.2. Triggering gestures manually\n\nSome of the libs provide ability to trigger the gesture events manually. This\nis different from the gesture simulation in the way that the manual triggering\ndoes not involve the gesture recognition nor the raw browser events.\n\nThe following snippet displays the trigger method of jQuery Touch Events.\n\n    \n    \n    $('#myElement').trigger('tap')\n\nWhile manual triggering can be helpful to test apps that utilise gestures, it\ndoes not help the lib designer who needs to test that the recogniser works as\nintended. For the lib designer, the gesture simulation is the way to go.\n\n### 10.3. Tooling\n\nAside from programmatic unit tests, some of the reviewed libraries offer\ntooling for manual testing. For example Interact.js has its dev-tools package\nthat hints the developer about missing handlers and recommended CSS styles.\n\n## 11\\. Conclusion\n\nIn this article we reviewed a bunch of gesture recognition libraries and\nanalysed their features and approaches to gestures. While every library brings\nits own personality to the mix, some general patterns can be seen both in\nterminology and usage.\n\nNot all gestures had consistent naming throughout the libraries. Especially\nhold and drag gestures had varying names. In contrast, the gestures tap,\ndouble tap, swipe, and rotate were rather uniformly named.\n\nWe saw three techniques to bind gesture recognition to elements: via event\nlisteners, element abilities, and component attributes. The event listener\ntechnique is the most common way for binding. It also works under the hood of\nthe other two techniques, although the two successfully simplify things for\nthe developer.\n\nWe also saw many challenges the gesture recognition designer needs to solve to\nprovide best possible user experience. Especially the conflict between mouse\nand touch and the needs to override default browser behaviour require deep\nunderstanding from the lib designer and the app developer. Fortunately the\nlibraries provided lots of help in form of features and instructions.\n\nI hope these findings turn out helpful to you. Whether you are programming\ngestures, using a gesture lib, or building one, there is lots of details to\nconsider and it is good to have them listed in one place. And whatever you do,\nif you were to learn only one thing from this article, please, do not come up\nwith yet another name for the hold gesture!\n\n## References\n\nMost of the references are provided as links throughout the article. Here we\nlist additional references that act as the golden standard for the user\ninteraction in web browsers.\n\n  * W3C. UI Events. Editor\u2019s Draft, 20 Oct 2021. Available at https://w3c.github.io/uievents/\n  * W3C. Touch Events. W3C Recommendation 10 Oct 2013. Available at https://www.w3.org/TR/touch-events/\n  * MDN. Touch Events Web API. 15 May 2022. Available at https://developer.mozilla.org/en-US/docs/Web/API/Touch_events\n  * MDN. UI Events Web API. 11 May 2022. Available at https://developer.mozilla.org/en-US/docs/Web/API/UI_Events\n\nGesture graphics are collected and derived from the following copyleft\nsources:\n\n  * Public Domain Vectors. Available at https://publicdomainvectors.org/\n\n## Contribute\n\nI wish to keep the article in good shape so if you spot inconsistencies or\nerrors, please let me know: akseli.palen@gmail.com. Thank you.\n\ngestures, javascript, open source, review, software library, touch ui,\nusability, user interface, web\n\nAkseli Pal\u00e9n\n\nHi! I am a creative full-stack web developer and entrepreneur with strong\nfocus on building open source packages for JavaScript community and helping\npeople at StackOverflow. I studied information technology at Tampere\nUniversity and graduated with distinction in 2016. I wish to make it easier\nfor people to communicate because it is the only thing that makes us one. View\nall posts by Akseli Pal\u00e9n \u2192\n\n## 1 Comment\n\n  1. Pingback: Touch Gesture Icon Set for Public Domain \u2013 Akseli Pal\u00e9n\n\n### Leave a Comment Cancel reply\n\n## Contact me at\n\n  * GitHub\n  * Stack Overflow\n  * Twitter\n  * Email\n\n## Categories\n\n  * Art (7)\n  * Lifestyle (5)\n  * Projects (33)\n  * Research (4)\n  * Work (19)\n\n## Tags\n\nanimation (2) climate change (2) cms (2) collaboration (2) contribution (1)\ndjango (2) document management (3) environment (3) ergonomy (1) file sharing\n(3) fractals (2) geography (3) gis (2) graphics (9) gymnastics (2) home (1)\nhousing (3) javascript (18) json (1) jsperf (1) lifestyle (3) maps (2) master\nof science (2) mathematics (7) microplastics (1) nature (2) nodejs (4) nokia\n(2) open source (18) photography (3) portfolio (6) probability (2) programming\n(4) renovation (2) software library (13) tampere university (3) thesis (3)\ntouch ui (4) usability (2) user interface (3) visualization (2) web (12)\nwebsite (15) wordpress (5) zoomable ui (5)\n\n## Meta\n\n  * Log in\n  * Entries feed\n  * Comments feed\n  * WordPress.org\n\n## My Businesses\n\n  * Tmi Akseli Pal\u00e9n\n  * Pax Kartat\n  * Avaruusotus.fi\n\n## Friends\n\n  * Er\u00e4renki\n  * Pirjo Pal\u00e9n\n  * J.S. Meresmaa\n  * Jussi Kivi\n  * Valorbyte Oy\n  * Marjo Levlin\n\n## Contact me at\n\n  * GitHub\n  * Stack Overflow\n  * Twitter\n  * Email\n\n2022 \u00a9 Akseli Pal\u00e9n\n\n", "frontpage": false}
