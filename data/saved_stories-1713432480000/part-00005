{"aid": "40070925", "title": "Do Best Practices Matter?", "url": "https://www.telkins.dev/blog/do-best-practices-really-matter", "domain": "telkins.dev", "votes": 2, "user": "jshchnz", "posted_at": "2024-04-17 22:51:26", "comments": 0, "source_title": "Do best practices really matter?", "source_text": "Do best practices really matter? | Trevor Elkins Blog\n\nTrevor Elkins\n\nAbout\n\nPublished on\n\n    2024-04-16\n\n/\n\n11 min read\n\n# Do best practices really matter?\n\nAuthors\n\n    \n\n  * Name\n    Trevor Elkins\nTwitter\n\n    @rovert_snikle\n\nLately I've been re-examining a lot of what I once thought to be best\npractices.\n\nHere's a common software engineer origin story. You join a team fresh out of\ncollege with a blank slate. Your first code review happens and a senior\nengineer rips it to shreds.\n\n> \"You should have used a factory pattern here\"\n>\n> \"You should avoid using singletons\"\n>\n> \"I think this query is going to be slow\"\n>\n> \"You should write more tests to cover these edge cases\"\n\nYou don't question much and after several fixes and back-and-forth discussions\nyour change is finally accepted. You feel proud and validated! Finally,\nexperiencing what it feels like to be a real software engineer. Rinse and\nrepeat dozens of times and soon you are promoted to a mid-level position. Now\nyou find yourself repeating the same lessons to the new hires. The cycle is\nstarting anew. You glance over at Clean Code and The Pragmatic Programmer \u2014\ngifted by your manager \u2014 sitting on your desk. The business keeps humming\nalong, you think. You're doing something right.\n\n## Shipping at all costs\n\nThe beginning of my career was much like I just described. Our executives\npeered into their crystal balls and came up with a company vision. Their\nproduct manager minions then broke the vision down into a series of roadmaps\nand features, and tasked the engineering team with building these features as\nquickly as possible. The faster we could ship, the better. It was a simple\nequation, but always met with resistance from the engineering team. \"We need\nto do it right\", we would say. \"We need to follow best practices\".\n\nUltimately a compromise was made. We would ship as quickly as possible, but we\nrequired some extra time to also write tests and refactor the code as needed.\nThis was the best of both worlds, we thought. We could still maintain our high\nlevel of code quality which felt like a victory. But as time went on, I began\nto question the value of these best practices. The tests we wrote were often\nflaky and didn't catch the bugs we thought they would. The refactoring we did\noften introduced new bugs and took longer than we thought. The best practices\nwe followed often felt like cargo cult programming. We were doing them because\nwe were thought they were right, not because they actually helped us.\n\nCracks in the facade were forming, but it wasn't until I joined Stripe that I\nfinally understood the bigger picture. Stripe has a culture around \"shipping\"\nalthough initially I didn't know what that meant. Hadn't I been shipping code\nmy entire career? After finally joining their team, I was surprised to find\nthat they didn't follow many of the best practices I had been taught. There\nweren't as many tests as I thought there would be. They didn't use many design\npatterns. The codebase was foreign and lacked the object structure I was used\nto. Instead, everyone was focused and bought in on shipping.\n\n## The OOP Myth\n\nStripe uses Ruby for most of their codebase, or at least did when I was there,\nand the first thing I noticed was how little OOP they used for such a highly\nOOP language. How can that be when I was taught OOP was the best way to write\nsoftware? Instead, most of the code was procedural. You have some bag of data\nand perform business logic on it using \"commands\" which are essentially\nfunctions. Teams have their own module containing a set of public data and\ncommands for other teams to use, and private data and commands for their own\nuse. The result was a structure like this:\n\n    \n    \n    lib/ capital/ commands/ create_loan.rb get_loan_offers.rb make_loan_payment.rb data/ loan.rb loan_offer.rb private/ commands/ calculate_interest.rb calculate_principal.rb data/ interest.rb principal.rb issuing/ ...\n\nIn the OOP world I would have expected to see a Loan class with methods like\ncreate, get_offers, and make_payment. But in the Stripe world, the Loan class\nwas just a data struct with no functionality. The business logic was all in\nthe commands directory. Our data layer did use an ORM framework with some OOP,\nbut that was basically it.\n\nI was surprised how easily I could jump in and understand another team's\ncodebase. This was a revelation to me and got me thinking: what is OOP\nactually trying to solve?\n\n## What makes code maintainable?\n\nI thought OOP and design patterns were meant to make your code maintainable.\nThinking more about this, I came up top traits of maintainable code in my\nexperience:\n\n  1. Readable: The code is easy to read and understand. It's easy to see what it's doing and why it's doing it. Code is read far more often than it is written.\n  2. Discoverable: It's easy to understand how code is supposed to be used in common cases. For example, most users don't want to read through a massive man curl page to figure out how to make a simple HTTP request.\n  3. Predictable: It's easy to understand what the code will do in a given situation, e.g. no side effects.\n  4. Limited blast radius: It's easy to understand the impact of a change. For example, if I change this line of code, what else will happen?\n  5. Debuggable: It's easy to understand what went wrong when something goes wrong.\n  6. Testable: It's easy to write tests for the code. This includes being able to mock out dependencies and not having to set up a lot of state to test a small piece of code.\n\nIt turns out the command structure checks all of these boxes. It's dead simple\nto understand. There's no layer of indirection trying to piece together OOP\nhierarchies. It encapsulates the business logic developers actually want to\nrun in a single place, you don't have to figure out how to wire together a\nbunch of objects on your own. And testing is dead simple, it's just a function\nwith easy to understand inputs and outputs.\n\n## What is worth testing?\n\nOK so maybe OOP isn't needed to write great code, but what about tests? I\nnever bought into fancy code coverage metrics, but tried to write varying\nlevels of unit, integration, and end-to-end tests for all my features. Now,\nI've come to realize that many tests are not worth writing. This boils down\ninto a few ideas:\n\n  1. The Pareto Principle (80-20 rule) is particularly relevant to testing. After you've written a test for the happy path and a few error cases, the ROI for tests rapidly diminishes. Remember, tests are code too, and they need to be maintained. By adding more tests, you're making code harder to refactor and change. There's a hidden cost to tests that many devs don't consider.\n\n  2. Am I testing business logic or boilerplate code? I've seen tests where 75% of the code is just setting up the test and wiring dependecies together. You aren't getting much value out of these tests relative to their cost.\n\n  3. A good rule of thumb is simply thinking to yourself, \"What is the cost of this code failing?\" If you doubt your answer, then it's probably not worth testing. For example, I've seen an extroadinary amount of effort go into testing extreme edge cases that would never happen with a real user. It would have been better for the dev to work on features. At Stripe, the cost of its money-movement code failing would be catastrophic so there is a lot of rigorous testing around it. But the same isn't true for other features.\n\n  4. Integration and E2E tests are much more valuable than unit tests. You can test a lot more in less code, although the tradeoff is that they are slower and more brittle. Investing in good integration and E2E tests (and their environment) is one of the highest ROI things you can do.\n\nThis is all to say that many devs get caught up in the idea that they need to\ntest everything. But in reality lots of code is not worth testing, so focus on\na few solid test cases and move on. If a feature is very high-stakes, I'll\nwrite a few extra test cases, although the bar for that is high. It's a better\nvalue to the business to move fast and occasionally have a bug or two if that\nmeans you get to ship extra features.\n\nIf you're building medical device software then maybe ignore this advice :)\n\n## The scalable myth\n\nDevelopers are trained in the way of \"premature optimization is the root of\nall evil\". You write O(N^2) algorithms and push them to production because \"N\nwill be small in practice\", until in rare cases it isn't, but somehow this\nthinking often gets lost in system design.\n\nI've seen a lot of over-engineering when it comes to system design. I'm plenty\nguilty of this myself. It turns out that modern hardware is incredibly fast\nand your data might not be as big as you think! While it's good to consider\nscale, very few of the features I thought would have scaling issues actually\ncaused a problem. Most scaling issues I've seen were caused by bugs and not\nthe actual feature itself. I'd rather ship a feature and have to turn it off\ndue to a load issue than worry about imaginary scale problems. It's a good\nproblem to have in most cases. If a feature becomes successful you can always\nimprove its performance later on. You'd be surprised how many businesses could\nsurvive off a simple Docker container hosted on a cheap VPS instance these\ndays.\n\nI think this is partly caused by the engineering culture of a company. Much\nlike Conway's Law where systems tend to mirror their own communication\nstructures (e.g. org charts), devs will over-engineer their system designs in\norder to match the format of their system design review. In other words, if\nthere is a fancy review process engineers will think they need a system with\nall the bells and whistles.\n\n## Delivering value\n\nThe point I'm trying to make is that it's easy to get caught up in things that\ndon't matter in the end. Focus on shipping changes as often and early as\npossible so users can get something in their hands to play with. Learn from\ntheir feedback and keep iterating. Soon you'll have successful software.\n\nFor example, one of my favorite practical techniques is to include a misc JSON\ncolumn on my tables to stuff random data in that doesn't fit the rest of my\nschema. Both MySQL and PostgreSQL support this natively. At first I thought\nthis was a horrible idea and would kill my database performance. But in\npractice, this hasn't been an issue at all. It's a great way to ship features\nquickly and not worry about slight schema changes. If a feature becomes\nsuccessful, I can easily perform a migration to make it better.\n\nWhat happened to me, and I think many other engineers, is that we lose sight\nof what we're actually trying to achieve. We're not trying to write the best\ncode that impresses other engineers, we're trying to deliver value to the\nbusiness. The best code is the code that delivers the most value. This is not\nto say that we should write bad code, but that we should be pragmatic about\nwhat we're doing. We should be asking ourselves, \"Is this the best use of my\ntime?\" and \"Is this the best use of the company's time?\" Sure, I could spend\n40 hours making this code perfect, but is that really worth it? What if I\ncould spend 10 hours and build something 95% as good?\n\nThis sounds soulless, but it's not. Looking back now, most of those meetings\nand long PR discussions for arbitrary code quality were a waste of time and\ndidn't matter. Best practices can have good advice, and they can also be\nabused if followed blindly. I've had to unlearn some of my enterprise Java\nhabits.\n\nI think the best engineers are the ones who can balance these two things. They\ncan write code that is good enough, and they can ship it quickly. They can\nunderstand when it's worth writing a test, refactoring, using a design\npattern, etc, and also when it's not.\n\nDiscuss on Twitter\n\n## Tags\n\ncareer-advicesoftware-quality\n\n## Previous Article\n\nHow I Shaved 187MB Off United Airline's 439mb iOS App\n\ngithublinkedintwitter\n\nTrevor Elkins\n\n\u2022\n\n\u00a9 2024\n\n", "frontpage": false}
