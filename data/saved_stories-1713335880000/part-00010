{"aid": "40055800", "title": "Overclocking the Original Xbox GPU to Play Halo 2 in HD", "url": "https://icode4.coffee/?p=738", "domain": "icode4.coffee", "votes": 1, "user": "grimdoomer", "posted_at": "2024-04-16 18:52:42", "comments": 0, "source_title": "Halo 2 in HD: Pushing the Original Xbox to the Limit", "source_text": "Halo 2 in HD: Pushing the Original Xbox to the Limit \u2013 I Code 4 Coffee\n\nI Code 4 Coffee\n\nWhere coffee turns into code!\n\nMenu\n\n  * Downloads\n  * Donate\n  * About Me\n\n### Recent Posts\n\n  * Halo 2 in HD: Pushing the Original Xbox to the Limit\n  * Light Gun Hacking Part 1: Using Namco light guns in Unity\n  * Diagnosing Precision Loss on NVIDIA Graphics Cards\n  * Fixing Rendering Bugs in Dead Rising PC\n  * Frogger\u2019s Adventure: The Rescue \u2013 Windows 7/10 Fix\n\n### github & socials\n\nBrowse: Home / Halo 2 in HD: Pushing the Original Xbox to the Limit\n\n## Halo 2 in HD: Pushing the Original Xbox to the Limit\n\nRyan Miceli / April 11, 2024 / Leave a comment / DirectX, Game Patch, Halo 2,\nXbox\n\nThis blog post goes over all of the work I\u2019ve done to add HD resolution\nsupport to the Original Xbox version of Halo 2. From patching the game to\nmodifying the hardware of the Xbox console to writing custom tools for\nperformance benchmarking, my goal with this project was to push the limits of\nboth and see how far I could go. I\u2019ve tried to keep this blog post as short as\nI could and only include the most technically interesting parts but even then\nit ended up quite long.\n\n## Prelude\n\nA long time friend who goes by the handle \u201cdoom\u201d has spent the past few years\nreverse engineering and researching the hardware and software on the original\nXbox. His end goal was to learn more about PC hardware and see how far he\ncould push the console. Some of his work includes swapping out the stock\nPentium 3 CPU running at 733Mhz for a variant of the Pentium 3 CPU running at\n1.4Ghz using a custom made CPU interposer board, and even being able to\noverclock it upwards of ~2Ghz.\n\nPentium 3 Tualatin on Doom\u2019s custom interposer\n\nDoom also wrote custom patches for the Xbox kernel in order to on-the-fly\npatch timing calculations for games so they ran properly with the faster CPU.\nCombined with a few other hardware upgrades such as additional RAM and an SSD,\ndoom started to refer to these as \u201cgod boxes\u201d. These god boxes were also\nrunning a custom kernel (or BIOS image) that doom made to support all of the\nhardware modifications and push the hardware and software as far as they could\ngo. One of his demos for his work was showing the opening sequence in Half-\nLife 2 which is notorious for abysmally slow loading times and poor\nperformance on the Xbox, running at a solid 30 FPS and loading in a matter of\nseconds. But there were still additional benefits to be had. Doom wanted\nsomeone to create a proper HD resolution patch for a popular game and really\nutilize the hardware upgrades he performed.\n\nOne night while talking over Discord doom asked if I would be interested in\ndeveloping an HD patch for Halo 2 and in exchange he would provide me with a\ngod box to develop it on. Halo 2 has a max supported video resolution of 480p\nand patching in support for 720p (and possibly 1080i) would get a lot of\nattention to demonstrate the benefits of all this work. We both knew that many\nof the community \u201cHD\u201d or \u201c720p\u201d game patches were not actually functioning\ncorrectly and that patching in HD resolution support for a game was more work\nthan just searching for 640/480 in a disassembler and changing the resolution.\nThese patches require a deep understanding of 3D graphics, DirectX APIs, and a\nlot of specific knowledge about the game and Xbox console. Having spent years\nreverse engineering the Xbox and Halo 2\u2019s game engine I had the perfect\nbackground to take on the task. As doom would put it \u201cthere\u2019s nobody more\nqualified than you to do it for halo 2 so that\u2019s why I asked\u201d. While it piqued\nmy interest (and I was pretty jealous of these god boxes and all the\nexperience he\u2019d gotten developing them), I made a request/requirement before I\nwould even entertain the idea.\n\nThe upgraded CPU has more than double the processing power compared to the\nstock CPU, however, the GPU was going to take on most of the increased\nprocessing load once the video resolution was increased. After all, each\nadditional pixel in the output image would result in more pixel shader\ncalculations which meant more work the GPU would have to do. If he could\nmanage to overclock the GPU I would do it, but at stock clock speeds it wasn\u2019t\nworth the time it would take to develop this patch just to have it fall over\non the GPU. He said he would look into it, and after a few weeks time he came\nback and said it was done. He managed to overclock the GPU by ~15%, and said\nhe had the \u201cGENESIS-3\u201d console ready for me (a nickname for the 3rd iteration\nof the \u201cgod box\u201d upgrades he\u2019d been working on).\n\n# Part 1: Rendering in HD\n\nHaving spent the past few years reverse engineering and re-implementing the\nHalo 2 rendering engine I already had a mental list of things I\u2019d need to\nchange to support higher video resolutions. The first thing that needed to be\nchanged was the size of the D3D front and back buffers. The setup for the D3D\ndevice has 3 functions that need to be modified in order to use the proper\nresolution for the current video mode. The first is\n_rasterizer_detect_video_mode which checks the video mode and sets some global\nvariables for widescreen and progressive video modes. Next is\n_rasterizer_init_screen_bounds which sets up the screen dimensions used for\ncreating the D3D device, view frustum, and a number of other things. Lastly is\nrasterizer_device_initialize which is responsible for setting up the D3D\ndevice. Below is a shortened version of these 3 functions with the lines of\ninterest highlighted. All of the code shown in this post has been reverse\nengineered from assembly back into C for ease of understanding.\n\nC\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465|\nvoid _rasterizer_detect_video_mode(){DWORD videoStandard =\nXGetVideoStandard();DWORD videoFlags = XGetVideoFlags();if (videoStandard ==\nXC_VIDEO_STANDARD_PAL_I)g_refresh_rate_hz = (videoFlags &\nXC_VIDEO_FLAGS_PAL_60Hz) != 0 ? 60 : 50;g_letterbox_enabled = (videoFlags &\nXC_VIDEO_FLAGS_LETTERBOX) != 0;g_widescreen_enabled = (videoFlags &\nXC_VIDEO_FLAGS_WIDESCREEN) != 0;g_progressive_scan_enabled = (videoFlags &\nXC_VIDEO_FLAGS_HDTV_480p) != 0;...}void _rasterizer_init_screen_bounds(int\nx_off, int y_off, float scale){float width = 640.0f * scale;float height =\n480.0f * scale;rasterizer_globals.screen_bounds.x0 =\n0;rasterizer_globals.screen_bounds.y0 = 0;rasterizer_globals.screen_bounds.x1\n= (int)width;rasterizer_globals.screen_bounds.y1 =\n(int)height;rasterizer_globals.frame_bounds.x0 =\nx_off;rasterizer_globals.frame_bounds.y0 =\ny_off;rasterizer_globals.frame_bounds.x1 = (int)width -\nx_off;rasterizer_globals.frame_bounds.y1 = (int)height - y_off;}bool\nrasterizer_device_initialize(){...D3DPRESENT_PARAMETERS PresentParams =\n{0};PresentParams.BackBufferWidth = rasterizer_globals.screen_bounds.x1 -\nrasterizer_globals.screen_bounds.x0;PresentParams.BackBufferHeight =\nrasterizer_globals.screen_bounds.y1 -\nrasterizer_globals.screen_bounds.y1;PresentParams.BackBufferFormat =\nD3DFMT_A8R8G8B8;PresentParams.EnableAutoDepthStencil =\nTRUE;PresentParams.AutoDepthStencilFormat = D3DFMT_D24S8;PresentParams.Flags =\nD3DPRESENTFLAG_LOCKABLE_BACKBUFFER;PresentParams.FullScreen_RefreshRateInHz =\ng_refresh_rate_hz;PresentParams.FullScreen_PresentationInterval =\nD3DPRESENT_INTERVAL_IMMEDIATE;switch (g_presentation_interval){case\n0:PresentParams.SwapEffect =\nD3DSWAPEFFECT_FLIP;PresentParams.FullScreen_PresentationInterval =\nD3DPRESENT_INTERVAL_IMMEDIATE;break;case 1:PresentParams.SwapEffect =\nD3DSWAPEFFECT_DISCARD;PresentParams.FullScreen_PresentationInterval |=\ng_present_immediately != 0 ? D3DPRESENT_INTERVAL_ONE : 0;break;case\n2:PresentParams.SwapEffect =\nD3DSWAPEFFECT_DISCARD;PresentParams.FullScreen_PresentationInterval |=\ng_present_immediately != 0 ? D3DPRESENT_INTERVAL_TWO :\n0;break;}g_pDirect3D->CreateDevice(0, D3DDEVTYPE_HAL, NULL,\nD3DCREATE_HARDWARE_VERTEXPROCESSING, &PresentParams, &g_pD3DDevice);...}  \n---|---  \n  \n#### Halo 2 already supports 480p, or does it...\n\nIf you\u2019ve ever looked at the back of the game case for Halo 2 you might have\nseen it supports 480p. However, looking at line 42 above, the\nD3DPRESENTFLAG_PROGRESSIVE flag is not being set on the present parameters.\nAnd, if we look at the call site for the _rasterizer_init_screen_bounds\nfunction we see this:\n\nCall site for _rasterizer_init_screen_bounds\n\nThe scale parameter is always set to 1.0f, which means the screen_bounds are\nalways set to 640\u00d7480 regardless of what the video mode is set to on the\nconsole. On the Original Xbox 480p is considered to be 720\u00d7480, which means\nthat Halo 2 does not render in 480p natively regardless of what the video\nsettings are set to. If you enable 480p mode on the console you\u2019ll get a 480p\nsignal out but that\u2019s because after the game is done drawing to the 640\u00d7480\nback buffer it\u2019ll get up-scaled to 720\u00d7480 by the GPU before being fed to the\nvideo encoder. I often get comments saying \u201cthat\u2019s not not a 16:9 resolution\u201d\nor \u201cthat\u2019s not real 480p\u201d, but \u201c480p\u201d encapsulates a range of resolutions and\naspect ratios and 720\u00d7480 is the resolution the Xbox considers to be 480p (so\ntake it up with Microsoft, not me...).\n\nIf you\u2019ve ever played Halo 2 in 480p mode with wide screen enabled you may\nhave noticed that things look a little weird. That\u2019s because when wide screen\nmode is enabled the game will use an anamorphic camera with an aspect ratio of\n1.33:1. That means it renders 1.3x the width into the same 640\u00d7480 surface as\nit would when wide screen mode is disabled. Here is a comparison showing the\neffect anamorphic scaling has on the Zanzibar wheel:\n\nHalo 2 in 480p with anamorphic scaling enabled\n\nHalo 2 in 480p with anamorphic scaling disabled\n\nI\u2019m not entirely sure why it does this and my only guess is if you set your TV\nto stretch mode it would \u201ccancel out\u201d the horizontal \u201csquish\u201d introduced by\nthe anamorphic scaling and look somewhat normal. However, I personally hate it\nand wanted the cleanest image I could get out of the console so I added an\noption to disable the anamorphic scaling entirely.\n\n#### Back to the back buffer...\n\nTo create the D3D front/back buffers with the right dimensions we\u2019ll need to\nchange g_progressive_scan_enabled to be set when 720p is enabled, set the\nscreen_bounds and frame_bounds variables based on the proper video resolution\nfor the video mode set, and finally set some additional flags on the D3D\npresent parameters depending on if the video mode is progressive or interlaced\n(1080i mode). The pseudo code for the modifications is shown below with the\nchanged lines highlighted. I ignored the scale variable in\n_rasterizer_init_screen_bounds because it\u2019s only ever set to 1.0 anyway.\n\nC\n\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384| void _rasterizer_detect_video_mode(){DWORD videoStandard = XGetVideoStandard();DWORD videoFlags = XGetVideoFlags();if (videoStandard == XC_VIDEO_STANDARD_PAL_I)g_refresh_rate_hz = (videoFlags & XC_VIDEO_FLAGS_PAL_60Hz) != 0 ? 60 : 50;g_letterbox_enabled = (videoFlags & XC_VIDEO_FLAGS_LETTERBOX) != 0;g_widescreen_enabled = (videoFlags & XC_VIDEO_FLAGS_WIDESCREEN) != 0;g_progressive_scan_enabled = (videoFlags & (XC_VIDEO_FLAGS_HDTV_480p | XC_VIDEO_FLAGS_HDTV_720p)) != 0;...}void _rasterizer_init_screen_bounds(int x_off, int y_off, float scale){// Set default resolution to 640x480.float width = 640.0f;float height = 480.0f;// Adjust resolution based on current video mode set.DWORD videoFlags = XGetVideoFlags();if ((videoFlags & XC_VIDEO_FLAGS_HDTV_1080i) != 0){width = 1920;height = 1080;}else if ((videoFlags & XC_VIDEO_FLAGS_HDTV_720p) != 0){width = 1280;height = 720;}else if ((videoFlags & XC_VIDEO_FLAGS_HDTV_480p) != 0){width = 720;}rasterizer_globals.screen_bounds.x0 = 0;rasterizer_globals.screen_bounds.y0 = 0;rasterizer_globals.screen_bounds.x1 = (int)width;rasterizer_globals.screen_bounds.y1 = (int)height;rasterizer_globals.frame_bounds.x0 = x_off;rasterizer_globals.frame_bounds.y0 = y_off;rasterizer_globals.frame_bounds.x1 = (int)width - x_off;rasterizer_globals.frame_bounds.y1 = (int)height - y_off;}bool rasterizer_device_initialize(){...D3DPRESENT_PARAMETERS PresentParams = {0};PresentParams.BackBufferWidth = rasterizer_globals.screen_bounds.x1 - rasterizer_globals.screen_bounds.x0;PresentParams.BackBufferHeight = rasterizer_globals.screen_bounds.y1 - rasterizer_globals.screen_bounds.y1;PresentParams.BackBufferFormat = D3DFMT_A8R8G8B8;PresentParams.EnableAutoDepthStencil = TRUE;PresentParams.AutoDepthStencilFormat = D3DFMT_D24S8;PresentParams.Flags = D3DPRESENTFLAG_LOCKABLE_BACKBUFFER;PresentParams.FullScreen_RefreshRateInHz = g_refresh_rate_hz;PresentParams.FullScreen_PresentationInterval = D3DPRESENT_INTERVAL_IMMEDIATE;...// Check if wide screen mode is enabled.if (g_widescreen_enabled != 0)PresentParams.Flags |= D3DPRESENTFLAG_WIDESCREEN;// Check if the video mode supports progressive scan.if (g_progressive_scan_enabled != 0)PresentParams.Flags |= D3DPRESENTFLAG_PROGRESSIVE;// Check the resolution width to see if 1080i is enabled.if (rasterizer_globals.screen_bounds.x1 == 1920){PresentParams.Flags &= ~D3DPRESENTFLAG_PROGRESSIVE;PresentParams.Flags |= D3DPRESENTFLAG_INTERLACED;}g_pDirect3D->CreateDevice(0, D3DDEVTYPE_HAL, NULL, D3DCREATE_HARDWARE_VERTEXPROCESSING, &PresentParams, &g_pD3DDevice);...}  \n---|---  \n  \nBooting up the game with these changes gives some less than pleasing results.\nLooking at the main menu the first thing we can see is the blue filter is now\ngone, and there\u2019s some repeating line pattern strewn across the screen.\nLooking a bit closer and we can see part of the water geometry is also cut\noff, suspiciously at where the old 640 width would be compared to the new\nwidth of 720.\n\nRendering issues in the main menu\n\n## Making efficient use of D3D memory\n\nThe Xbox uses a unified memory architecture meaning the CPU and GPU share the\nsame RAM. Unlike a PC there\u2019s no concept of creating a D3D allocation in VRAM\nand having the GPU manage it. On Xbox the CPU can create an allocation for\ntextures, render targets, vertex buffers, etc, and pass the allocation address\ndirectly to the GPU. This gives developers the ability to allocate one buffer\nand have multiple resource \u201cviews\u201d that utilize the memory. Consider the\nfollowing code which shows how to create a render target letting D3D do all\nthe work and how to create a render target by hand:\n\nC\n\n12345678910111213| // How to create a render target with\nD3D:IDirect3DSurface8* pRenderTarget =\nNULL;g_pD3DDevice->CreateRenderTarget(/* width */ 1024, /* height */ 1024, /*\nformat */ D3DFMT_A8R8G8B8, NULL, FALSE, &pRenderTarget);// How to create a\nrender target by hand:// Allocate and initialize the texture\nheader.IDirect3DSurface8* pRenderTarget =\n(IDirect3DSurface8*)malloc(sizeof(IDirect3DSurface8));DWORD textureSize =\nXGSetTextureHeader(/* width */ 1024, /* height */ 1024, /* levels */ 0, 0, /*\nformat */ D3DFMT_A8R8G8B8, 0, pRenderTarget, 0, 0);// Allocate memory for the\npixel buffer.void* pSurfaceBuffer = D3D_AllocContiguousMemory(/* size */\ntextureSize, /* alignment */\nD3DSURFACE_ALIGNMENT);pRenderTarget->Register(pSurfaceBuffer);  \n---|---  \n  \nWhile the latter looks more messy it provides greater control to the developer\nand is something Halo 2 makes great use of to conserve memory for all the\nrender targets it uses. In total Halo 2 has approximately 25 different render\ntargets it uses but there\u2019s only 4-5 unique buffers allocated for them which\nsaves a lot of memory. So what does this have to do with the issues we saw in\nthe main menu? Well if Halo 2 is creating render targets by hand it\u2019ll need to\nencode the width and height of the surface into the header of the render\ntarget structure. If it\u2019s hard coded to use 640\u00d7480 resolution it would cause\nissues that could result in cut off images or repeating line patterns as the\npitch of the surface would not match the pitch of the back buffer.\nEssentially, there\u2019s two different \u201cviews\u201d for the same memory but the views\nsee the memory as being of different widths which results in misplaced pixels\nwhen spanning each scan line.\n\nLooking around the D3D/raster initialization code I found a function I called\nrasterizer_primary_targets_initialize that does exactly this. It takes the\nback, front, and depth buffers created by D3D and creates additional render\ntargets and texture views from them, using hard coded dimensions of 640\u00d7480.\nHere is the C representation of the disassembly:\n\nC\n\n1234567891011121314151617181920212223242526272829303132333435| bool\nrasterizer_primary_targets_initialize(){// Get the back buffer, front buffer,\nand depth buffer surfaces.global_d3d_device->GetBackBuffer(0,\nD3DBACKBUFFER_TYPE_MONO,\n&global_d3d_surface_render_primary[0]);global_d3d_device->GetBackBuffer(-1,\nD3DBACKBUFFER_TYPE_MONO,\n&global_d3d_surface_render_primary[1]);global_d3d_device->GetDepthStencilSurface(&global_d3d_surface_render_primary_z);...global_d3d_texture_render_primary[0]\n=\n(IDirect3DTexture8*)malloc(sizeof(IDirect3DTexture8));global_d3d_texture_render_primary[1]\n= (IDirect3DTexture8*)malloc(sizeof(IDirect3DTexture8));// Setup texture views\nfor back/front buffers.for (int i = 0; i < 2; i++){XGSetTextureHeader(640,\n480, 1, 0, D3DFMT_LIN_A8R8G8B8, 0,global_d3d_texture_render_primary[i],\nglobal_d3d_surface_render_primary[i]->Data, 0);}// Create a render target\nsurface for the depth buffer that matches the size and format of the back\nbuffer.global_d3d_surface_z_as_target =\n(IDirect3DSurface8*)malloc(sizeof(IDirect3DSurface8));memcpy(global_d3d_surface_z_as_target,\nglobal_d3d_surface_render_primary,\nsizeof(IDirect3DSurface8));global_d3d_surface_z_as_target->Data =\nglobal_d3d_surface_render_primary_z->Data;// Create two textures for the depth\nbuffer, one in ARGB format and one in ABGR\nformat.global_d3d_texture_z_as_target[0] =\n(IDirect3DTexture8*)malloc(sizeof(IDirect3DTexture8));XGSetTextureHeader(640,\n480, 1, 0, D3DFMT_LIN_A8R8G8B8, 0,global_d3d_texture_z_as_target[0],\nglobal_d3d_surface_render_primary_z->Data,\n0);global_d3d_texture_z_as_target[1] =\n(IDirect3DTexture8*)malloc(sizeof(IDirect3DTexture8));XGSetTextureHeader(640,\n480, 1, 0, D3DFMT_LIN_A8B8G8R8, 0,global_d3d_texture_z_as_target[1],\nglobal_d3d_surface_render_primary_z->Data, 0);...}  \n---|---  \n  \nThis is relatively easy to fix, we simply need to hook this function, let it\nrun normally, and then fix up the dimensions of the textures/surfaces\nafterwards. The pseudo code for this hook can be seen below:\n\nC\n\n12345678910111213141516171819202122232425| bool\nHook_rasterizer_primary_targets_initialize(){// Call the trampoline and let\nthe real function complete.bool result =\nrasterizer_primary_targets_initialize_trampoline();// Update the dimensions of\nthe surface/textures created to match the resolution of the back\nbuffer.Hack_UpdateD3dPixelContainerForScreenResolution(global_d3d_texture_render_primary[0]);Hack_UpdateD3dPixelContainerForScreenResolution(global_d3d_texture_render_primary[1]);Hack_UpdateD3dPixelContainerForScreenResolution(global_d3d_texture_z_as_target[0]);Hack_UpdateD3dPixelContainerForScreenResolution(global_d3d_texture_z_as_target[1]);return\nresult;}void Hack_UpdateD3dPixelContainerForScreenResolution(D3DBaseTexture*\npResource){// Calculate the correct pitch for the texture with tiling enabled.\nThis can be different than the normal pitch// value and if set incorrectly\nwill cause a \"striping\" effect on the back buffer.DWORD format =\n(pResource->Format >> 8) & 0xFF;DWORD pitch = D3D_CalcTilePitch(/* width */\nrasterizer_globals.screen_bounds.x1, /* texture format */ format);// Set the\nnew dimensions of the texture using the size of the back\nbuffer.XGSetTextureHeader(/* width */ rasterizer_globals.screen_bounds.x1, /*\nheight */ rasterizer_globals.screen_bounds.y1,1, 0, format, 0, pResource,\npResource->Data, pitch);}  \n---|---  \n  \nThere\u2019s one additional thing to note here and it\u2019s that the memory used for\nthe back, front, and depth buffers is a special type of memory known as\n\u201ctiled\u201d memory. Tiled memory stores the pixel data in a way that\u2019s more\nefficient to read and write to based on the design of the actual RAM chip\u2019s\nmemory cells. Storing the pixel data in tiled memory decreases the overall\nbandwidth required when reading and writing these buffers. The gotcha here is\nthat the pitch value for the surface/texture is not always the same as it\nwould be for a texture in normal memory (width * bpp). This is why I call\nD3D_CalcTilePitch in the the Hack_UpdateD3dPixelContainerForScreenResolution\nhelper function. It will calculate the correct pitch for tiled memory based on\nthe width and bits per pixel for the texture format. If the pitch value is\ncalculated incorrectly (ex: by doing width * bpp) you\u2019ll end up getting a\n\u201cstriping\u201d effect on the back buffer (which affects 1080i video resolutions\nspecifically). If you\u2019re curious what tiled memory looks like if you don\u2019t\n\u201cun-tile\u201d it here you go:\n\nD3D back buffer of the main menu in tiled form\n\nThis is the main menu image from earlier (only in 720p) dumped straight from\nthe back buffer without un-tiling the data. If you squint hard enough you can\nalmost make out the Halo 2 logo in the center. That aside it\u2019s time to test\nthe new patches and see if the modifications to the surface dimensions fixed\nour issues. Loading up the game with this new set of modifications gives us\nthis:\n\nMain menu with some issues fixed\n\nOkay so the striping effect from using the incorrect pitch value in the\nback/front buffer surfaces is now fixed. However, the water geometry is still\ncutoff even after we changed the resolutions of all the render\ntargets/textures, right? Well we only updated the primary render targets, we\nstill need to update the intermediate render targets used by the game\u2019s\nrasterizer, and this is where having game engine specific knowledge comes in\nhandy.\n\n## Resizing the rasterizer targets\n\nAs I mentioned earlier there\u2019s ~25 render targets Halo 2 uses for different\npasses in the render loop such as detail texture blending, water, reflections,\nfog, shadows, etc. The game\u2019s rasterizer system allows for creating a render\ntarget with child render targets that utilize the same underlying memory. The\n25 render targets the game creates are backed by only 4-5 unique memory\nallocations and uses this parent/child relationship to make efficient use of\nthe memory. When one render target is no longer in use the others are free to\nuse that memory. While most render targets are smaller than the back buffer\n(ranging from 512\u00d7512 all the way down to 64\u00d764) there\u2019s one in particular\nthat needs to match the back buffer resolution which is the texture\naccumulator target, or taxaccum for short.\n\nThe DirectX implementation on Xbox only allows for sampling from 4 textures\nper pixel shader pass. If you want to render something that uses more than 4\ninput textures you\u2019ll need to do it in two or more passes. This is what the\ntexaccum layer is for. Objects in the game that use more than 4 textures will\nfirst render all the detail textures to the texaccum layer. When the texaccum\npass is completed the taxaccum render target will be fed into the lightmap\npass as an input and combined with any additional textures for the object\nalong with the lightmap texture to get the final output.\n\nTexaccum and lightmap shader passes\n\nHere\u2019s an example using the ground geometry in coagulation. In the texaccum\npass the detail textures for the ground geometry are blended together into the\ntexaccum render target. Then in the lightmap pass the texaccum render target\nis used as an input texture along with a bump map and lightmap texture to\ncreate the final image. The reason the water geometry in the main menu is cut\noff is because it\u2019s being rendered to the texaccum render target which has a\nhard coded size of 640\u00d7480. Now that we\u2019re rendering in larger video\nresolutions the dimensions of the texaccum target will need to be increased.\nLooking through the rasterizer initialization code we\u2019ll find a function I\ncalled rasterizer_targets_initialize that allocates buffers for the various\nrender targets and initializes them:\n\nC\n\n123456789101112131415161718192021222324252627| bool rasterizer_targets_initialize(){// Allocate and initialize the texaccum render target.if (!_rasterizer_alloc_and_create_render_target(1, 640, 480, 1, false))return false;...}bool _rasterizer_alloc_and_create_render_target(int target_index, int width, int height, int unk, bool z_surface){// Calculate the allocation size rounded up to the nearest page size.int allocationSize = ((((width + 63) & ~64) * height * 4) + 4095) & ~4096;// Allocate memory from the game's self-managed memory pool.void* pPhysicalAllocPtr = physical_memory_globals.hi_stage_address[physical_memory_globals.current_stage] - allocationSize;if (pPhysicalAllocPtr > physical_memory_globals.low_stage_address[physical_memory_globals.current_stage]){physical_memory_globals.hi_stage_address[physical_memory_globals.current_stage] = pPhysicalAllocPtr;// Mark the allocated memory as RW write-combine memory.pPhysicalAllocPtr |= PHYSICAL_MEM_ADDRESS_MASK;XPhysicalProtect(pPhysicalAllocPtr, allocationSize, PAGE_READWRITE | PAGE_WRITECOMBINE);}return _rasterizer_create_render_target(target_index, /* type */ 1, width, height, z_surface, /* linear */ true, true, pPhysicalAllocPtr);}  \n---|---  \n  \nTo fix the hard coded dimensions I simply hook the\n_rasterizer_alloc_and_create_render_target function, check the target_index\nparameter for the texaccum index, and change the dimensions to match the back\nbuffer size. The pseudo code for the hook looks like this:\n\nC\n\n12345678910111213| bool Hook__rasterizer_alloc_and_create_render_target(int\ntarget_index, int width, int height, int unk, bool z_surface){// Check the\nrasterizer target index and adjust the surface dimensions accordingly.if\n(target_index == 1){// Texaccum rasterizer target:width =\nrasterizer_globals.screen_bounds.x1;height =\nrasterizer_globals.screen_bounds.y1;}// Call the trampoline and create the\nrender target.return\n_rasterizer_alloc_and_create_render_target_trampoline(target_index, width,\nheight, unk, z_surface);}  \n---|---  \n  \nRunning the game with these modifications we can see the water geometry is no\nlonger cutoff, and loading into a map doesn\u2019t show any noticeable rendering\nissues:\n\nMain menu with the texaccum layer fixed\n\nThe game looks okay in 480p but the real goal of this work is to get the game\nplaying decently in 720p, and maybe booting in 1080p, even though it won\u2019t\nplay well at that resolution nor will the Xbox output a 1080p video signal\n(but I can still take some sweet screenshots!). We still need to fix the\nmissing blue filter on the main menu but in the interest of keeping this post\nas short as possible I\u2019m going to skip the blue filter fix as it\u2019s not very\ninteresting anyway (spoiler: it was just a simple size check that needed\nupdating). Changing the video settings on my console to 720p and booting the\ngame results in... well it results in the game crashing on startup. The\nreason? Due to the increased size of the front/back/depth buffers and\nrasterizer targets we\u2019re out of memory, or at least, out of memory that the\ngame is able to use.\n\n# Part 2: Memory Management and RAM Upgrades\n\nThe original Xbox had two different console types, the retail consoles that\nconsumers would buy with 64MB of RAM, and a development console (or dev\nkit/debug console) that was used by game developers with 128MB of RAM. The\nextra RAM on the development console helped developers debug their games and\nrun additional test code during the development process. The motherboard used\nby both console types is nearly identical with the main difference being the\nsoftware they run and the additional RAM chips on the dev kit motherboards\n(they also have a slightly different south bridge for security purposes but\nthat\u2019s not really important here). However, retail motherboards still had the\nplacements for the 4 additional RAM chips and over the years people found that\nthey could solder in the missing RAM chips and run a modified Xbox kernel to\ngive them access to the extra memory. Retail games won\u2019t make any use of that\nextra memory, but homebrew applications like Xbox Media Center will use it for\nthings like video decoding when watching movies or streaming media.\n\nI\u2019ve neglected to mention that up until this point the only way I was able to\nget the game to boot with the increased back buffer size is by running it on a\nconsole with 128MB of RAM and using an Xbox kernel with support for the\nadditional 64MB of RAM. As-is the game will not utilize any of the additional\nmemory, however, this kernel has additional logic to \u201cforce\u201d certain types of\nmemory allocations into the upper 64MB region to make space for allocations\nthat must be in the lower 64MB region. Going into this project I already knew\nthat the only way this game would boot in 720p would be with the RAM upgrade.\nIn fact, the only way to get it to boot in proper 480p resolution without the\nRAM upgrade was to steal some memory back from the game\u2019s in-memory texture\ncache which ends up causing additional texture pop-in. But all of this can be\nfixed by patching the game\u2019s memory allocator to support the additional 64MB\nof RAM.\n\n## Halo 2\u2019s memory management\n\nIt\u2019s quite common for game developers to write their own memory management\nsystem, especially on older hardware where the built-in memory allocator may\nbe slow or even buggy. Developers would use the built-in memory allocator to\nmake a couple large allocations that they\u2019d wrap in their own allocator to\nchunk it up and dish out as needed. At startup Halo 2 creates one large\nallocation that uses ~48.9MB of the available 64MB of RAM on the console,\nbasically, every last page of memory they could possibly get once you account\nfor the Xbox kernel and game executable. This region of memory is then chunked\nup for various subsystems in the game such as level metadata, texture,\ngeometry, animation, and sound caches, rasterizer targets, network and\nsimulation resources, etc.\n\nIn order to patch Halo 2\u2019s memory allocator I was going to need a way to\nvisualize memory usage so I could see where things are located and how much\nspace is being used. I spent a few nights working on a tool (GitHub:\nXboxImageGrabber) that would walk the page table entries for all the RAM on\nthe console and create a crude bitmap that color codes various chunks of data,\nallowing me to create a visualization of what memory looks like:\n\nMemory profile of Halo 2\n\nThis might look like pixel barf and be hard to interpret but it was really\nonly intended for my own use so I never bothered to make it pretty. The first\ncolumn on the left shows the memory usage by the Xbox OS. At the very\nbeginning is the Xbox kernel, down in the 0x83000000 region we have the Halo 2\nexecutable and some virtual memory allocations, and at 0x84000000 is the end\nof the 64MB retail RAM region. This was taken on a console with 128MB of\nmemory so everything after 0x84000000 is the \u201cdebug\u201d memory region. The center\ncolumn shows Halo 2\u2019s memory usage for runtime data and d3d resources. This\nparticular image doesn\u2019t have color coding enabled so you can get an idea of\nhow much memory the game reserves for this runtime data region. That blue\nblob? That\u2019s the ~49MB allocation the game makes on startup. The column on the\nright shows combined memory usage, basically what has been allocated and what\nis free with no further classification for what the memory is used for. We can\nsee that the stock version of the game uses almost every available page of\nmemory it can get, sparing only a few as a safety net.\n\nHalo 2 memory profile with data classification\n\nHere\u2019s the same memory profile image with the runtime data region color coded\nto show the various subsystem allocations. There\u2019s actually a few more not\npictured here but they aren\u2019t too important. The ones we\u2019re concerned with are\ngoing to be tag data, texture cache, geometry cache, and rasterizer buffer.\nThe runtime data allocation appearing immediately after the Xbox kernel is not\na coincidence, it\u2019s purposefully allocated at a hard coded address of\n0x80061000. The \u201ctag data\u201d region is actually all the metadata for every\nobject in a map file in the form of C-structs that have been serialized using\nthe predetermined base address of 0x80061000. The tag data system is designed\nto be as flexible and performant as possible, and, in my opinion the inner\nworkings are really a feat of engineering. I could write an entire blog post\nabout the inner workings of the tag data system and why I think it makes the\nBlam engine one of the most flexible engines ever made, but that isn\u2019t\nrelevant to this post. The key takeaway here is that this data needs to always\nbe at the same address or else the game won\u2019t work. But all of the other data\nin the runtime region can be moved around at will.\n\n#### Patching the memory allocator\n\nThe regions we\u2019ll want to move out of the runtime data buffer are the\nrasterizer targets (at least the ones we\u2019ll be increasing in size), and the\ntexture and geometry caches so we can increase their size to help reduce pop-\nin issues. We\u2019ll also want to reduce the size of the runtime data buffer to\naccount for the things we\u2019re removing so we don\u2019t waste any memory by not\nfilling it. The patches for the memory allocator will consist of 3 main\nchanges:\n\n  1. Hooking certain allocation calls and moving them to the debug memory region.\n  2. When these allocations are \u201creleased\u201d (ex: when loading a new level) we\u2019ll need to call the appropriate free function.\n  3. Adjusting the size of the runtime data region to reclaim memory that\u2019s no longer being used.\n\nI\u2019ve called the memory allocation function we\u2019ll need to hook\nphysical_memory_malloc, and it\u2019s unfortunately inlined by the compiler which\nmeans each \u201ccall site\u201d for it will need a unique patch, and the same is true\nfor when an allocation is free\u2019d. The pseudo code for the memory allocator\npatches looks like this:\n\nC\n\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758|\nstruct physical_memory_alloc_info{const char* name; // Name for the\nallocation, ex: \"texture cache\"unsigned int override_size; // If non-zero use\nthis size for the allocationvoid* address; // Allocation address};// Enum used\nto index into\nHack_PhysicalMemoryRegionInfoTableenum{PHYS_MEM_REGION_RASTERIZER_TEXACCUM_TARGET,PHYS_MEM_REGION_GEOMETRY_CACHE,PHYS_MEM_REGION_TEXTURE_CACHE,};//\nGlobal array of tracked allocations:physical_memory_alloc_info\nHack_PhysicalMemoryRegionInfoTable[] ={{ \"rasterizer texaccum target\", 0, NULL\n},{ \"geometry cache\", 0, NULL },{ \"texture cache\", 0, NULL },};void*\nHack_PhysicalMemoryAlloc(unsigned int regionIndex, unsigned int size, int\nprotect){// Get a pointer to the allocation info\nstructure.physical_memory_alloc_info* pAllocInfo =\n&Hack_PhysicalMemoryRegionInfoTable[regionIndex];// If the override size is\nspecified use it for the allocation.if (pAllocInfo->override_size != 0)size =\npAllocInfo->override_size;// Round the size up to the nearest page\ninterval.size = (size + PAGE_SIZE-1) & ~(PAGE_SIZE-1);// TODO: Allocate memory\nfrom the debug region...pAllocInfo->address = NULL;if (pAllocInfo->address ==\nNULL)DebugBreak();// Debug print the allocation\ninfo.DbgPrint(\"physical_memory_malloc %s %ld at 0x%08x\\n\", pAllocInfo->name,\nsize, pAllocInfo->address);return pAllocInfo->address;}void\nHack_PhysicalMemoryFree(unsigned int regionIndex){// Get a pointer to the\nallocation info structure.physical_memory_alloc_info* pAllocInfo =\n&Hack_PhysicalMemoryRegionInfoTable[regionIndex];// If the allocation is valid\nfree it.if (pAllocInfo->address != NULL){// TODO: Free the\nallocation...pAllocInfo->address = NULL;}}  \n---|---  \n  \nThis allows me to hook individual call sites where the physical_memory_malloc\nfunction is inlined using a patch like so:\n\nAssembly (x86)\n\n123456789| push 404h ; PAGE_WRITECOMBINE | PAGE_READWRITEpush ecx ; size, calculated earlier in functionpush PHYS_MEM_REGION_GEOMETRY_CACHE ; regionIndexmov eax, Hack_PhysicalMemoryAlloccall eax ; Call our helper function to perform the allocation; Jump over code we no longer need to execute.push 0012DA73hret  \n---|---  \n  \nNow you\u2019re probably wondering why the lines that perform the allocation and\nfree calls in the pseudo code above are labeled as \u201cTODO\u201d, and that\u2019s because\nallocating physical contiguous memory in the debug memory region is\nproblematic...\n\n## Xbox memory architecture\n\nEarlier I mentioned that the original Xbox uses a unified memory design\nallowing the CPU and GPU to share the same RAM. When the CPU provides a memory\naddress to the GPU (ex: address of a texture or vertex buffer) it must use a\nphysical memory address and the memory span must be contiguous (meaning the\npages backing the allocation are all consecutive with no gaps). This is\nbecause the GPU doesn\u2019t have any concept of page tables or virtual memory\naddresses so it\u2019s unable to translate virtual addresses to perform memory\naccesses. It simply treats the memory address as an offset from the start of\nRAM and reads data as needed starting from this offset. There\u2019s specific APIs\nfor allocating \u201cvideo\u201d or \u201cGPU\u201d memory but these are all wrappers for\nallocating memory that is physical and contiguous.\n\nThe Xbox kernel provides various functions for allocating memory but there\u2019s\ntwo main types of memory allocations that can be made. Physical memory which\nis also contiguous, and virtual memory which is not explicitly contiguous (it\ncan end up being contiguous by chance but it\u2019s virtual memory so it\u2019s not\nrequired to be contiguous). On an unmodified retail Xbox console there\u2019s only\n64MB of RAM and the entire 64MB region can be used to make physical or virtual\nallocations. When using a console with 128MB of RAM and kernel with extra RAM\nsupport only the first 64MB of RAM can be used for physical allocations, but\nvirtual allocations can be made anywhere in the 128MB region. If you try to\nmake a physical allocation and there\u2019s not enough free contiguous memory in\nthe first 64MB of RAM, the kernel will attempt to relocate virtual allocations\ninto the upper 64MB region to satisfy the allocation request.\n\nThis was done on purpose to provide a closer experience to the retail hardware\nfor developers to work with. The additional 64MB of \u201cdebug\u201d memory was to\nallow developers to run extra code and profiling tools that consumed memory\nwithout having to take away from the memory their game would normally have.\nThere\u2019s no benefit to allowing developers to allocate more \u201cvideo\u201d memory in\nthe debug region as it doesn\u2019t exist on retail hardware and can\u2019t be used in a\nfinal version of the game. However, this limits me in terms of how much\nadditional memory I can give Halo 2 for video allocations.\n\n## Hot patching the Xbox kernel\n\nLooking at the memory profile image above we can see the \u201cruntime data region\u201d\nconsumes most of the first 64MB of RAM. Not everything allocated in this\nregion is required to be \u201cvideo\u201d memory (and thus needs to be in physical\nmemory), so I could move as many things as possible out of that region and\ninto the upper 64MB of RAM as a virtual allocation. But this gets quite messy\nto track down all of the allocations being made and patch each call site, and\nit won\u2019t give us as much memory as we really need for additional performance\ntweaks later on. Rather than go for a sub-par solution I decided to take\nmatters (or memory) into my own hands and try something crazy.\n\nI ran some tests where I made a video memory allocation \u201cby hand\u201d and just\nstole some unused page table entries for the upper 64MB address space. Instead\nof asking the kernel to allocate the memory for me, I just \u201ccommandeered\u201d the\npage tables and did it myself. Feeding this address to the GPU for rendering\nworked just fine which meant that the limitation of only being able to\nallocate \u201cvideo\u201d memory in the lower 64MB of RAM is not a hardware limitation\nit\u2019s a software one. The only thing preventing me from making physical memory\nallocations in the upper 64MB of RAM is the kernel. After spending a few\nnights digging through the memory management functions in the Xbox kernel I\nfound the blocker that was preventing me from making physical allocations\npassed the 64MB mark:\n\nMax PFN check in MmAllocateContiguousMemoryEx\n\nThe MmAllocateContiguousMemoryEx function used to allocate contiguous physical\nmemory takes in two parameters that let the caller specify the lowest and\nhighest acceptable addresses for the memory allocation. This is how Halo 2\ngets the runtime data region to always be at the address 0x80061000, by\nspecifying the highest acceptable address as 0x61000 (the upper most bits are\nmasked out). The kernel takes both of these parameters and converts them into\npage frame numbers (basically an index for the page of memory that corresponds\nto that address), and checks they\u2019re less than or equal to this constant I\ncalled MAX_USABLE_PFN. The MAX_USABLE_PFN constant corresponds to the address\n0x83FE0000, which is equal to 64MB \u2013 128KB. What is the significance of this\nvalue? The top 128kb of RAM is always reserved with 64KB used as a \u201cscratch\u201d\nregion for the GPU and the other 64KB used for the CPU page tables. I believe\nthe GPU \u201cscratch\u201d region is used for storing data related to depth buffer\ncompression tags and possibly processed vertex data that is still passing\nthrough the shader pipeline, but I\u2019ve never actually confirmed this myself.\n\nThis check is our blocker for allocating physical memory in the upper 64MB of\nRAM. I changed this value at runtime after my test application loaded and\nconfirmed I was able to allocate memory in the upper 64MB of RAM using\nMmAllocateContiguousMemoryEx, and the GPU was able to use that memory just\nfine. So now all I needed to do is write a function to hot patch the Xbox\nkernel when the game boots, no big deal right? For this patch I\u2019ll first make\nsure the console has 128MB of RAM installed, then resolve the address of the\nMmAllocateContiguousMemoryEx function, search for the \u201cmov edx, 0x3FDF\u201d\ninstruction, and patch it to use a new \u201cMAX_USABLE_PFN\u201d value suitable for\n128MB RAM configuration. Here\u2019s the pseudo code for the patch:\n\nC\n\n1234567891011121314151617181920212223242526272829303132333435363738394041|\nbool PatchMaxPFN(){// Search for the max PFN value.BYTE* pPtr =\n(BYTE*)pMmAllocateContiguousMemoryEx;BYTE* pEndPtr =\n(BYTE*)pMmAllocateContiguousMemoryEx + 0x80;while (pPtr < pEndPtr){// Check\nfor the max PFN value.if (*(DWORD*)pPtr == 0x00003FDF){_asm{// Disable write\nprotect.pushfcli // Disable interruptsmov eax, cr0 // Get the control register\nvaluepush eax // Save it for laterand eax, 0xFFFEFFFF // Disable write-\nprotectmov cr0, eax// Update the max PFN to use the 128MB limit value.mov eax,\npPtrmov dword ptr [eax], 0x00007FCF// Re-enable write-protect.pop eaxmov cr0,\neax // Re-enable write-protectpopf}return true;}// Next round.pPtr++;}//\nFailed to patch max PFN value.return false;}  \n---|---  \n  \nNow that the memory allocation problems are solved we can fill in the two\nmissing lines from the Hack_PhysicalMemoryAlloc/Hack_PhysicalMemoryFree\nfunctions above to use MmAllocateContiguousMemoryEx and\nMmFreeContiguousMemory. Once we hot patch the kernel we can call\nMmAllocateContiguousMemoryEx using a lowest acceptable address of 0 and\nhighest acceptable address of 0xFFFFFFFF (which the function will override\nwith our new MAX_USABLE_PFN value). The kernel will walk the page tables in\nreverse starting from the highest acceptable page number and search for a span\nof free pages large enough to satisfy the allocation request. This will\nguarantee the upper 64MB of RAM will take preference during allocation but\nallows using any available space in all 128MB of RAM to satisfy the request.\n\nC\n\n123456789101112131415161718192021222324252627282930313233343536| void*\nHack_PhysicalMemoryAlloc(unsigned int regionIndex, unsigned int size, int\nprotect){// Get a pointer to the allocation info\nstructure.physical_memory_alloc_info* pAllocInfo =\n&Hack_PhysicalMemoryRegionInfoTable[regionIndex];// If the override size is\nspecified use it for the allocation.if (pAllocInfo->override_size != 0)size =\npAllocInfo->override_size;// Round the size up to the nearest page\ninterval.size = (size + PAGE_SIZE-1) & ~(PAGE_SIZE-1);// Allocate physical\ncontiguous memory (using the entire 128MB address space).pAllocInfo->address =\nMmAllocateContiguousMemoryEx(size, /* LowestAcceptableAddress */ 0, /*\nHighestAcceptableAddress */ 0xFFFFFFFF, /* Alignment */ PAGE_SIZE, /*\nPageAccess */ protect);if (pAllocInfo->address == NULL)DebugBreak();// Debug\nprint the allocation info.DbgPrint(\"physical_memory_malloc %s %ld at\n0x%08x\\n\", pAllocInfo->name, size, pAllocInfo->address);return\npAllocInfo->address;}void Hack_PhysicalMemoryFree(unsigned int regionIndex){//\nGet a pointer to the allocation info structure.physical_memory_alloc_info*\npAllocInfo = &Hack_PhysicalMemoryRegionInfoTable[regionIndex];// If the\nallocation is valid free it.if (pAllocInfo->address != NULL){// Free the\nallocation.MmFreeContiguousMemory(pAllocInfo->address);pAllocInfo->address =\nNULL;}}  \n---|---  \n  \n#### Visualizing the results\n\nThat was a lot of work but the results are well worth it. As I mentioned\nearlier the only way to get the game to run in 720p or higher is with a RAM\nupgrade. Even running the game in proper 480p on a console without the RAM\nupgrade requires stealing memory back from the game to offset the additional\nmemory requirements, which exacerbates the texture pop-in issues that are\nprevalent even in the game\u2019s unmodified form. I\u2019ve rambled on about memory\nmanagement enough, here\u2019s what the game looks like in 720p:\n\nZanzibar beach in 720p\n\nIt looks great! But it doesn\u2019t play great... The FPS is noticeably lower to\nthe point where it\u2019s dipping to 10 FPS or lower in heavy scenes. While I was\nexpecting a performance hit I wasn\u2019t expecting it to be this bad, but that\u2019s\nokay because there\u2019s things we can do to improve this quite a bit. Before\nthat, lets give 1080p a try and see what it looks like. Remember that while\nthe game is rendering natively in 1080p the Xbox console is only able to\noutput a 1080i video signal. However, by dumping the D3D back buffer directly\nI\u2019m able to get a proper 1080p screenshot before the GPU converts it into half\nframes for the video encoder to display on screen:\n\nZanzibar beach in 1080p\n\n#### Unforeseen consequences\n\nOkay so this kernel hot patching does have some undesirable side effects which\nis understandable since I just changed a pretty crucial aspect of how memory\nmanagement works mid-execution. Hot patching the kernel and letting Halo 2 run\nworks fine until you exit the game without cold rebooting the console. If you\ndo a warm reboot (returning to the dashboard, ejecting the dvd tray, etc) the\nconsole is basically \u201chosed\u201d and the next application/game to run will have\nsevere graphical artifacting, and the console will most likely crash shortly\nafter. This is likely because there\u2019s more changes required to expand the\nphysical memory region outside of the single change I made. I have some\ntheories as to what the remaining issues are but having spent a significant\namount of time on memory management patches I decided to take the cop out\nsolution here. To make this more \u201crobust\u201d I added additional patches that\nwould cold reboot the console (which reloads the kernel) whenever you exit the\ngame so all of the side effects of this hot patching are hidden from the end\nuser. This would prove useful later on as there\u2019s additional changes I make\nthat really should be reset after exiting the game and cold rebooting the\nconsole solves all of this.\n\n# Part 3: Performance Improvements and Overclocking\n\nNow that the game is rendering in 720p and 1080p it\u2019s time to address the\nperformance issues and make it playable, at least in 720p. Adding 1080p\nsupport is really just a bonus to get nice screenshots and I have no\nexpectations that the console will be able to run the game at that resolution\nand be \u201cplayable\u201d, regardless of what performance improvements I can make. The\nfirst step was to get some baseline performance measurements on a stock Xbox\nconsole and the god box that doom sent me. The god box also had two different\nBIOS images, one that overclocked just the CPU, and one that overclocked both\nCPU and GPU. This would let me get three different measurements: one for stock\nhardware (no overclocking), one for CPU overclocking, and one for CPU + GPU\noverclocking. From these measurements I could determine where the performance\nbottlenecks were and start from there.\n\nI found a particularly heavy area on Zanzibar that I\u2019ll refer to as the\n\u201czanzibar benchmark scene\u201d, which was a decent test case for performance\nbenchmarks. While collecting the performance measurements I immediately\nrealized that the FPS between all three setups was almost identical when under\nheavy load which was extremely suspicious. If overclocking the CPU and GPU\nshow no improvement in performance then the bottleneck was certainly\nelsewhere. My first thought was I might be maxing the memory bandwidth now\nthat the GPU has a lot more pixel calculations to do and thus a lot more\nmemory to read and write. However, after spending a few nights running tests\nand bouncing ideas off doom I realized I\u2019d overlooked something very obvious\nwhile staring at a performance graph.\n\nPerformance graph for stock console at 720p (double buffered)\n\nThis graph shows GPU use (yellow), CPU use (red), frames per second (blue),\nand swap stall rate (teal). Initially I didn\u2019t know what \u201cswap stall\u201d was and\nI couldn\u2019t find any documentation about it in the Xbox SDK docs. But after I\nrealized the game was running with vsync on it made perfect sense, swap stall\n= swap chain stall, the GPU was stalling because the swap chain was full and\nvsync was on.\n\n#### VSync and swap chains\n\nHalo 2 runs with vsync on and uses double buffering so it only has 2 buffers\nin the swap chain (one front buffer and one back buffer). The back buffer is\nused by the GPU to render the current frame while the front buffer is the\nprevious frame that was rendered and is now being displayed on screen. When\nthe GPU finishes drawing the current frame it needs to swap the back and front\nbuffers (or rotate the swap chain) so the newly completed frame can be drawn\non screen and the old one can be used by the GPU for the next frame. But when\nvsync is on the GPU can only rotate the swap chain at the start of a vertical\nblanking (vblank) period (when the TV retraces to the top and starts drawing\nthe image from the beginning). If you turn vsync off the GPU can rotate the\nswap chain at any time, but if the front buffer is only partially displayed on\nscreen when you rotate the swap chain it\u2019ll result in a \u201ctearing\u201d effect on\nscreen (hence why you want vsync on as it prevents this).\n\nThe swap stall line in the graph above is the rate at which the GPU had to\nstall and wait for a vblank period in order to rotate the swap chain.\nBasically, the GPU isn\u2019t able to render frames fast enough to keep up with the\nrefresh rate of the screen and it ends up having to wait until the next screen\nrefresh to rotate the swap chain. In hindsight this seems so obvious but at\nthe time I was preoccupied with all the hardware modifications I completely\nforgot about vsync.\n\n## From double to triple buffering\n\nThis is relative easy to fix as we can just increase the number of buffers in\nthe swap chain to 3 which allows us to queue a completed frame and immediately\nbegin processing the next frame, even if the GPU needs to wait for the next\nvblank before rotating the swap chain. Here\u2019s the updated pseudo code for the\nrasterizer_device_initialize hook:\n\nC\n\n12345678910111213141516171819202122232425262728293031323334353637383940| bool\nrasterizer_device_initialize(){...D3DPRESENT_PARAMETERS PresentParams =\n{0};PresentParams.BackBufferWidth = rasterizer_globals.screen_bounds.x1 -\nrasterizer_globals.screen_bounds.x0;PresentParams.BackBufferHeight =\nrasterizer_globals.screen_bounds.y1 -\nrasterizer_globals.screen_bounds.y1;PresentParams.BackBufferFormat =\nD3DFMT_A8R8G8B8;PresentParams.EnableAutoDepthStencil =\nTRUE;PresentParams.AutoDepthStencilFormat = D3DFMT_D24S8;PresentParams.Flags =\nD3DPRESENTFLAG_LOCKABLE_BACKBUFFER;PresentParams.FullScreen_RefreshRateInHz =\ng_refresh_rate_hz;PresentParams.FullScreen_PresentationInterval =\nD3DPRESENT_INTERVAL_IMMEDIATE;...// Setup back buffer count and swap effect\nfor triple buffering.PresentParams.BackBufferCount =\n2;PresentParams.SwapEffect =\nD3DSWAPEFFECT_DISCARD;PresentParams.PresentationInterval =\nD3DPRESENT_INTERVAL_ONE;// Check if wide screen mode is enabled.if\n(g_widescreen_enabled != 0)PresentParams.Flags |= D3DPRESENTFLAG_WIDESCREEN;//\nCheck if the video mode supports progressive scan.if\n(g_progressive_scan_enabled != 0)PresentParams.Flags |=\nD3DPRESENTFLAG_PROGRESSIVE;// Check the resolution width to see if 1080i is\nenabled.if (rasterizer_globals.screen_bounds.x1 == 1920){PresentParams.Flags\n&= ~D3DPRESENTFLAG_PROGRESSIVE;PresentParams.Flags |=\nD3DPRESENTFLAG_INTERLACED;}g_pDirect3D->CreateDevice(0, D3DDEVTYPE_HAL, NULL,\nD3DCREATE_HARDWARE_VERTEXPROCESSING, &PresentParams, &g_pD3DDevice);...}  \n---|---  \n  \nHere I\u2019ve increased the back buffer count to 2 (default is 1), and set the\nswap effect such that the swap chain will be rotated on each present call.\nThis will give us 3 buffers to work with (2 back and 1 front), but we\u2019ll need\nto make another modification to the game\u2019s rendering engine to account for\nthis additional buffer. Earlier when I was going through the process of\nresizing the game\u2019s render targets I showed some code for how the game sets up\ntexture views for the back and front buffers for use in rendering passes:\n\nC\n\n123456789101112131415161718192021| bool\nrasterizer_primary_targets_initialize(){// Get the back buffer, front buffer,\nand depth buffer surfaces.global_d3d_device->GetBackBuffer(0,\nD3DBACKBUFFER_TYPE_MONO,\n&global_d3d_surface_render_primary[0]);global_d3d_device->GetBackBuffer(-1,\nD3DBACKBUFFER_TYPE_MONO,\n&global_d3d_surface_render_primary[1]);global_d3d_device->GetDepthStencilSurface(&global_d3d_surface_render_primary_z);...global_d3d_texture_render_primary[0]\n=\n(IDirect3DTexture8*)malloc(sizeof(IDirect3DTexture8));global_d3d_texture_render_primary[1]\n= (IDirect3DTexture8*)malloc(sizeof(IDirect3DTexture8));// Setup texture views\nfor back/front buffers.for (int i = 0; i < 2; i++){XGSetTextureHeader(640,\n480, 1, 0, D3DFMT_LIN_A8R8G8B8, 0,global_d3d_texture_render_primary[i],\nglobal_d3d_surface_render_primary[i]->Data, 0);}...}  \n---|---  \n  \nEach frame after the game calls Present() it\u2019ll swap the Data field in\nglobal_d3d_surface_render_primary[0]/[1] and\nglobal_d3d_texture_render_primary[0]/[1] so they point to the correct memory\nfor the new back and front buffers. This works fine when the game is double\nbuffered but now that we introduced a third buffer into the swap chain we\u2019ll\nneed to account for this after the game calls Present(). We\u2019ll also need to\nupdate the rasterizer_primary_targets_initialize hook from earlier to\ninitialize these buffers correctly before the first frame is drawn. Here is\nthe pseudo code for these functions:\n\nC\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647|\nvoid Hook_IDirect3DDevice8_Swap(){// Call the trampoline and let the real\nfunction run.IDirect3DDevice8_Swap_trampoline();// Check if triple buffering\nis enable.if (Hack_TripleBufferingEnabled == false)return;// Release\nreferences to the old back\nbuffer.global_d3d_surface_render_primary[0]->Release();global_d3d_surface_render_primary[1]->Release();//\nGet the new back buffer and increment the reference count\ntwice.global_d3d_device->GetBackBuffer(0, D3DBACKBUFFER_TYPE_MONO,\n&global_d3d_surface_render_primary[0]);global_d3d_device->GetBackBuffer(0,\nD3DBACKBUFFER_TYPE_MONO, &global_d3d_surface_render_primary[1]);// Update the\nData field for the back buffer\ntextures.global_d3d_texture_render_primary[0]->Data =\nglobal_d3d_surface_render_primary[0]->Data;global_d3d_texture_render_primary[1]->Data\n= global_d3d_surface_render_primary[0]->Data;}bool\nHook_rasterizer_primary_targets_initialize(){// Call the trampoline and let\nthe real function complete.bool result =\nrasterizer_primary_targets_initialize_trampoline();// Check if triple\nbuffering is enabled.if (Hack_TripleBufferingEnabled != true){// Set both\nprimary render surfaces to point to the active back\nbuffer.global_d3d_device->GetBackBuffer(0, D3DBACKBUFFER_TYPE_MONO,\n&global_d3d_surface_render_primary[0]);global_d3d_device->GetBackBuffer(0,\nD3DBACKBUFFER_TYPE_MONO, &global_d3d_surface_render_primary[1]);// Update the\nData field for the back buffer\ntextures.global_d3d_texture_render_primary[0]->Data =\nglobal_d3d_surface_render_primary[0]->Data;global_d3d_texture_render_primary[1]->Data\n= global_d3d_surface_render_primary[0]->Data;}// Update the dimensions of the\nsurface/textures created to match the resolution of the back\nbuffer.Hack_UpdateD3dPixelContainerForScreenResolution(global_d3d_texture_render_primary[0]);Hack_UpdateD3dPixelContainerForScreenResolution(global_d3d_texture_render_primary[1]);Hack_UpdateD3dPixelContainerForScreenResolution(global_d3d_texture_z_as_target[0]);Hack_UpdateD3dPixelContainerForScreenResolution(global_d3d_texture_z_as_target[1]);return\nresult;}  \n---|---  \n  \nWith this change global_d3d_surface_render_primary[0]/[1] and\nglobal_d3d_texture_render_primary[0]/[1] will always reference the current\nback buffer. After the Swap hook returns the game will still swap\nglobal_d3d_surface_render_primary[0]/[1] and\nglobal_d3d_texture_render_primary[0]/[1] internally but this is basically a\nno-op since they point to the same underlying memory. Now, you might be\nthinking global_d3d_surface_render_primary[1] is supposed to point to the\nfront buffer per the game\u2019s original implementation, so what happens now that\nglobal_d3d_surface_render_primary[1] always points to the back buffer? And the\nanswer, is nothing. The game never used the front buffer because it can\u2019t do\nanything meaningful with it while it\u2019s being drawn to screen. It only held the\npointer so it could swap the surfaces every frame. With these changes in place\nI loaded up the Zanzibar benchmark scene and collected some new performance\nmeasurements:\n\nPerformance graph for stock console at 720p (triple buffered)\n\nAs we can see the swap stall line is gone and the FPS is sitting at ~22 which\nis +~3 FPS higher than before. You might be thinking that a 3 FPS increase\nisn\u2019t really much but when the game is capped at 30 FPS this is actually a 10%\nincrease which is pretty nice. Also remember that the main goal here was to\neliminate the swap stall which prevented the GPU from running as fast as it\ncould. Looking at the graph some more we can see the GPU is now maxed! This\nmight seem bad but we now know the GPU is the bottleneck. We\u2019re still running\non stock GPU clock speed and once we overclock the GPU the performance should\nincrease quite a bit.\n\n## Overclocking the GPU\n\nI spent a few nights digging through some PIX traces, running tests, and\ntrying to find any other low hanging fruit for cheap performance gains. I was\nable to get another +1-2 FPS by tiling the texaccum render target but it\nseemed like that was all I was going to get for cheap gains. There\u2019s one or\ntwo ideas I had that might get some performance increase but they required a\ndecent amount of changes and I wasn\u2019t sure if the end result would even get me\na 1 FPS increase, so I decided to leave it alone and maybe loop back on it\nanother day. With the changes to tile the texaccum render target the Zanzibar\nbenchmark scene was sitting at 23-24 FPS which was a solid improvement over\nthe original ~19 FPS. Now it was time to turn to overclocking, and running the\nZanzibar benchmark scene on the god box with overclocked GPU gave a solid\n27-28 FPS. Running around the map felt smooth and the FPS was typically\nholding at a steady 30 FPS, though there were still some areas (like the\nbenchmark scene) where the FPS would drop. Overall I considered it to be\nhighly playable and was relatively satisfied with the results.\n\nThe only problem is that the god box is running a one-off bespoke BIOS image\nthat doom made for it. While the GPU overclocking settings could be patched\ninto other community BIOS images it wouldn\u2019t be great if the requirement to\nrun this HD patch was \u201cpatch your BIOS image and reflash it to your console\u201d.\nLuckily I wouldn\u2019t have to resort to that because the GPU clock generator can\nbe controlled entirely by memory mapped IO registers. Using these registers\nyou can control the coefficients for the clock generator and change the clock\nspeed on the fly. So for this next patch I\u2019m going to have the game\ndynamically overclock the GPU on startup.\n\n#### Adjusting the clock speed\n\nThe clock signal for the GPU is calculated as follows:\n\nC\n\n12345678| NVPLL_COEFF (32 bits):Bits 0-7: MBits 8-15: NBits 16-18: PBASE_CLK =\n16.6667 Mhznvclk = (N * BASE_CLK / (1 << P) / M)  \n---|---  \n  \nThe M and P values are set to 1 by default, and BASE_CLK is always 16.6667 Mhz\nwhich is sourced from a crystal on the motherboard. So the formula can be\nshortened to: (N * 16.6667) / 2. We\u2019ll be modifying the N component which is\nset to 28 by default for a GPU clock speed of 233.33 Mhz. This will let us\nstep the clock speed in increments of ~8 Mhz which I made configurable via an\nini file that the patch loads on startup. The pseudo code for overclocking the\nGPU looks like this:\n\nC\n\n12345678910111213141516171819202122232425| void Util_OverclockGPU(int\nstep){/*NVPLL_COEFF (32 bits):Bits 0-7: MBits 8-15: NBits 16-18: PBASE_CLK =\n16.6667 Mhznvclk = (N * BASE_CLK / (1 << P) / M)*/// Read the current clock\nconfig from the NVPLL_COEFF register.DWORD clockConfig =\n*(DWORD*)(NV_GPU_BASE_ADDRESS + NVPLL_COEFF);// Mask out the old N\nvalue.clockConfig &= ~0xFF00;// Mask in the new N value.clockConfig |= ((step\n& 0xFF) << 8);// Write the new NVPLL_COEFF value.*(DWORD*)(NV_GPU_BASE_ADDRESS\n+ NVPLL_COEFF) = clockConfig;}  \n---|---  \n  \nThat\u2019s it, the GPU is now overclocked. Kind of lack luster I know, but you\u2019re\nprobably wondering how far can we overclock the GPU? And what does the new\nperformance graph look like?\n\nPerformance graph for 300Mhz GPU OC at 720p (triple buffered)\n\nWith the GPU overclocked to 300 Mhz (up from 233.33 Mhz stock) there\u2019s a solid\n3 FPS increase in performance in the Zanzibar benchmark scene compared to\nstock GPU clock speed. This doesn\u2019t seem very impressive but remember this is\nthe \u201cbenchmark\u201d test, it was chosen because it puts a massive load on the GPU.\nOutside of this area there\u2019s a noticeable increase in FPS and running around\nZanzibar the game stays at 30 FPS most of the time, dipping slightly in a few\nheavy areas. So how far can we push the GPU? More speed better performance,\nright?\n\nSemiconductor fabrication is not a perfect process and every chip has\nimperfections in it. While every GPU that made it into an Xbox console has\nminimum functional and quality requirements it had to meet, the maximum\ncapabilities of each chip varies greatly. A lot of the GPUs in the 1.0-1.4\nrevision consoles are on the weaker end and seem to cap out in the low 300 Mhz\nrange, while the GPUs in the 1.6 revision consoles have been able to go\nupwards of 400 Mhz stable. That\u2019s almost a 100% increase in clock speed which\nis very impressive, but this won\u2019t really improve the FPS much more (or so I\nthink). There\u2019s another bottleneck here, and one that can\u2019t easily be worked\naround.\n\n#### Another chip, another clock...\n\nI spent a large amount of time throughout this project wondering if part of\nthe bottleneck issue was memory bandwidth. There\u2019s a number of articles in the\nXbox SDK docs that go into great detail about the hardware in the console, the\nrendering pipeline, and all the gotchas you can hit that will hurt your game\u2019s\nperformance. There\u2019s a number of times that memory bandwidth is mentioned and\nit seems the engineers believed you could max the memory bus bandwidth fairly\neasily. The bus has a theoretical maximum throughput of 6.4GB/s but only about\n70% of that is usable in practice, for a practical max throughput of ~4.5GB/s.\nI captured a number of PIX traces on the game and the estimated memory usage\nfor a single frame was never higher than low 40MBs. No matter how I ran the\nnumbers I just could not see the memory bus bandwidth being maxed out. In my\nmost generous calculation I estimated max throughput of 4GB/s / 30 FPS =\n~135MB/frame. Even if we assume the CPU is consuming something like 50MBs that\nstill gives ~80MBs for GPU data. Yeah 1280\u00d7720 is a lot of pixels but this\nwould mean each frame is accessing more data than there is RAM on the console,\nand it was just hard to believe. However, I know very little in this area and\nit was very well possible that one of these numbers was off (perhaps PIX?).\nThe engineers certainly believed it was possible so I was most likely missing\nor misunderstanding something.\n\nDoom suggested I try increasing the RAM clock speed and see if FPS increases,\nwhich would indicate that memory is the likely bottleneck. The only problem is\nthe RAM is already clocked at the practical maximum frequency of 200Mhz so you\ncan only increase the speed by about ~10Mhz before it becomes unstable and the\nconsole crashes. After running some calculations I wrote the following snippet\nof code to change the memory clock speed:\n\nC\n\n1234567891011121314151617181920212223242526272829303132| void OverclockRAM(){DWORD MPLLCoeff = 0;// Read CR_CPU_MPLL_COEFFHalReadWritePCISpace(0, 0x60, 0x6C, &MPLLCoeff, sizeof(MPLLCoeff), 0);/*CR_CPU_MPLL_COEFFBits 0-7: MBits 8-15: NBits 16-19: FSB_PBits 20-23: MEM_PBASE_CLK = 16.6667 MhzVCOFreq = (BASE_CLK / M) * FSB_P * 2 * NMEMCLK = VCOFreq / (2 * MEM_P)*/// M/N values for 208 Mhz MEMCLK:DWORD M = 3;DWORD N = 25;// Update PLL coefficients.MPLLCoeff = (MPLLCoeff & ~0xFF) | (M & 0xFF);MPLLCoeff = (MPLLCoeff & ~0xFF00) | ((N & 0xFF) << 8);// Update PPL value.HalReadWritePCISpace(0, 0x60, 0x6C, &MPLLCoeff, sizeof(MPLLCoeff), 1);}  \n---|---  \n  \nThe M and N values above are chosen such that the resulting memory clock speed\nwill be ~208 Mhz. I could adjust them some more and get closer to 210 Mhz but\nthis was good enough to test. With these changes in place I booted up Halo 2,\nloaded up the Zanzibar benchmark scene and watched the perf monitor. I ran\nthis test a number of times with and without the memory overclocking and the\nresult was a solid 0.7 FPS increase when the memory overclocking was active.\nThese test results aren\u2019t conclusive but they\u2019re definitely compelling.\n\nThere\u2019s different RAM chips that work on the Xbox console and have a maximum\nclock speed of 250 Mhz. I searched around online and placed an order for some,\nbut at the time of writing this I haven\u2019t gotten to installing them or running\nany further tests. Doom has already tried using these memory chips and said he\nhad trouble getting them above ~230 Mhz while the GPU was overclocked, and\nthat there\u2019s likely another piece to the puzzle to get them running any\nhigher. I wanted to \u201cpush the console to the limits\u201d with this patch but I was\nnow 3 months into development of it and needed a break. Ultimately, even if I\ncould get these other RAM chips running close to 250 Mhz I\u2019d more or less be\nthe only person able to utilize it as they\u2019re hard to come by, quite costly,\nand require removing any existing RAM chips from the console motherboard\nbefore installing. With the chips on order I decided to save this experiment\nfor future me and continue on with finishing the patch.\n\n## Reducing pop-in\n\nHalo 2 had some notoriously bad pop-in issues with textures and geometry and\nthis issue has only been exacerbated on consoles that are still running the\noriginal mechanical HDDs from the early 2000s. But now that we have all this\nextra RAM this should be easy to solve. Earlier I talked about the game making\na single large memory allocation of ~48.9MB that I referred to as the \u201cruntime\ndata region\u201d. This memory region is divided up into smaller sections for\nvarious subsystems in the game such as network resources, geometry cache,\ntexture cache, sound cache, level data, etc.\n\nHalo 2 retail memory profile\n\nThe ones we\u2019re interested in are the texture cache and geometry cache. The\ngeometry cache is given 6.5MB of space for single player maps and 7MB for\nmultiplayer maps. The texture cache size varies and is given all the remaining\ndata after the \u201ctag data\u201d section and before the \u201clow detail texture cache\u201d.\nThe larger the map the smaller the texture cache will be and the more pressure\nthat\u2019ll be put on it (especially for single player maps). These caches are\n\u201cleast recently used\u201d data structures (or \u201clruv caches\u201d as the game refers to\nthem, not sure what the v is...), and work by evicting the least recently used\ndata after a certain time period has elapsed. Every 30 frames (~1 second) the\ngame will iterate through each cache and evict any data that hasn\u2019t been used\nin the last 30 frames to free up space. If a request is made to load in data\nand there\u2019s enough free space in the cache the data is loaded immediately\n(typically asynchronously, though it can block) and the request is satisfied\nonce the read completes. If the cache is full there\u2019s two code paths that can\nbe taken:\n\n  1. The caller can specify a parameter that indicates they want to force eviction on some other data. In this case the game will iterate through every entry in the cache and forcefully evict the least recently used items until there\u2019s enough free space to satisfy the load request. If those items are currently being displayed on screen they\u2019ll disappear in the next frame (and most likely submit new cache load requests).\n  2. The caller specifies they don\u2019t want to force eviction and the load request fails. The object will not appear on screen this frame and the game will try to load it again next frame.\n\nAlmost every call site for a load request falls down code path #2 with very\nfew locations falling down code path #1. This is the first cause of pop-in, a\nrequest to load data is made and fails resulting in the object not being\ndisplayed on screen at the proper time. When the data is successfully loaded\nit will \u201cpop\u201d on screen and typically be far enough into the players field of\nview that they notice it. In the case of texture loads the map file can have\nup to 3 different texture buffers for low, medium, and high level of detail\n(LOD) versions of the same image. This is not to be confused with mip maps\nbecause each texture LOD will have its own set of mip maps. When a request is\nmade to load in a texture the game will default to using the highest LOD\npossible, and if the load request fails it will try again using medium and low\nLOD buffers in hope that they require less memory and the load request may be\npossible to satisfy without waiting for memory to become available. If a load\nfor a lower LOD version of the texture succeeds the game will attempt to load\nthe highest LOD possible in the next few frames when more memory (hopefully)\nbecomes available. When this happens the texture will be visible immediately\nat lower detail and then \u201cpop\u201d to higher detail when it becomes available.\nThis is typically noticeable in cut-scenes which have the highest on-demand\nload requirements compared to normal game play.\n\nMaster chief texture popping from low to high LOD\n\n#### Using cache eviction to find super bounces\n\nOne additional note is that each map file also contains a \u201clow detail texture\ncache\u201d which contains an \u201cemergency\u201d version of almost every bitmap the map\nuses, in sizes from 2\u00d72 pixels to at largest 8\u00d78 pixels, which is always\nresident in memory while playing. This is used in cases where a model is\npresent in memory but the load request for the texture(s) failed at all LODs.\nIn this scenario there would normally be no textures to render the model with\nbut the emergency low detail texture cache can be used temporarily to get the\nmodel on screen until the normal texture can be loaded into memory. Back in\nthe Xbox Live days of Halo 2 there used to be a \u201cglitch\u201d where if you pulled\nup the Xbox Live friends menu and then closed it the level geometry would be\nrendered with extremely low detail textures. If you looked closely enough you\ncould see \u201ccracks\u201d in the geometry (really, just where non-co-planar triangles\nwere joined together) that you could try and use for super bounces. This\ntechnique was used to find suitable places for performing super bounces and I\neven remember finding a few myself using this method. It turns out this isn\u2019t\nactually a \u201cglitch\u201d but the game using the emergency low detail texture cache\nbecause the normal textures for geometry were evicted and the geometry needs\nto be rendered this frame.\n\nFoundation with low detail textures\n\n#### Visualizing cache usage\n\nWhen I first started adjusting the geometry and texture cache sizes I could\ndefinitely see pop-in was being reduced but I didn\u2019t really have any good\nindication of when the caches were large enough and further tweaks were just\nredundant. After scraping through every Halo 2 build I had along with the\nVista and MCC versions on PC, I was able to find enough info to recreate a\ndebugging feature that Bungie had implemented in their debug builds of the\ngame (this was such a pita). Using this graph visualization I could see\nexactly how much of the cache memory was being used at any given time which\nlet me fine tune the sizes to what I felt was a pretty good result.\n\nHalo 2 Outskirts stock texture cache\n\nOn the stock version of the game the campaign map Outskirts (old mombasa) has\na texture cache size of ~19MB. I chose this map as my test map because the\nopening cinematic had pretty noticeable pop-in and with the original HDD in\nthe console it could be comically bad at times. The image above shows the\ntexture cache graph visualization. The graph is broken up into pairs of 2\nlines. The first line indicates how the memory is being used: gray = free, red\n= in use high detail, purple = in use medium or lower detail (aka memory\npressure), pink = stolen. The second line indicates when the memory was last\nused: green = in use this frame, blue = in use the last 30 frames. As a side\nnote the game can steal memory from the texture cache for other purposes such\nas for rasterizer render targets that are only used in cinematic cutscenes,\nplaying the intro/attraction/credits videos, etc. As we can see in the image\nabove master chief is being rendered using the low detail texture cache\nbecause the normal texture cache is full and there\u2019s no memory to satisfy the\ntexture load request. Every single texture in the cache is either in use this\nframe or some time in the last 30 frames. So until enough textures age out and\nget evicted, master chief will be stuck in low detail.\n\nHalo 2 Outskirts stock texture cache\n\nThis scene with the sniper team is one of the heavier scenes in the opening\ncutscene and would often result in model and texture pop-in. We can see from\nthe texture cache graph that almost all of the memory is in use and there\u2019s\nquite a few textures that are being loaded at medium or lower detail (in\npurple) due to the memory pressure. I also implemented an almost identical\ngraph view for the geometry cache and using both of these I began to fine tune\nthe cache sizes until the pop-in issues were more or less gone.\n\n#### Increasing the cache sizes\n\nThe final result is the geometry cache being increased from 6.5/7MB to 20MB,\nand the texture cache increased to a static size of 30MB, nearly doubling both\ncaches in size from the stock version of the game. At these sizes I felt the\ncaches had adequate space and texture and model pop-in was more or less\nresolved.\n\nHalo 2 Outskirts upgraded texture cache\n\nAs we can see the scene where master chief would appear with low detail\ntextures now appears with high detail textures immediately (no more pop-in!)\nand there\u2019s even plenty of free space in the texture cache. For the sniper\nscene we can see that in the previous frames all of the cache memory was being\nutilized, but not all at the same time as there\u2019s plenty of chunks where the\ntexture data has aged out of the cache. However, there were still a few cases\nwhere things would pop-in even though there was free space in the caches. To\nfurther fix this I ended up adding support to increase the HDD transfer speed\nfrom the stock UDMA 2 speed (~33.3MB/s) to UDMA 3 (~44.4MB/s) or UDMA 5\n(~100MB/s) if your console had an 80 pin IDE cable. This provided a 10%\nincrease in transfer speeds for consoles running the stock IDE cable and up to\na 300% increase (theoretically, the actual transfer speeds depend greatly on\nthe size of data being transferred) for consoles with an upgraded IDE cable.\nThis not only helped with the remaining pop-in issues but greatly reduced\nloading times for the game as well. At this point I was pretty satisfied with\nthe result.\n\n#### The final memory profile\n\nSo after all these changes what does the final memory profile look like for\nHalo 2 in 720p on a console with 128MB of RAM?\n\nHalo 2 720p memory profile\n\nThe geometry and texture caches are now huge, and more than 75% of the\navailable 128MB of RAM has been utilized. For 1080p mode I actually had to\ndial the geometry and texture cache sizes back a bit as the memory used by the\nswap chain and rasterizer targets was so large there wasn\u2019t enough memory\nremaining for the increased caches, and more or less all 128MB of RAM was in\nuse.\n\n# Conclusion\n\nI wanna thank everyone that took the time to read all the way through this\nblog post. This is the longest post I\u2019ve written to date and I tried to keep\nit as short as possible and even cut a bunch of smaller, less interesting\nthings out. I also wanna give a huge thanks to Doom for encouraging me to do\nthis work, providing hardware for testing, and insight into some deep\ntechnical areas. This project was a ton of fun to work on and I learned a lot\nthroughout the process. I always wanted to work at Bungie on a game like Halo\nbut never got the chance to do so, and working on this project in some ways\nfelt like I actually got to work on the game. There\u2019s still room for\nimprovement with a lot of the performance and memory changes I made. But\noverall I feel this HD patch has pushed Halo 2 and the Xbox console to their\nlimits and I\u2019m satisfied with the results without trying to go any further.\n\nYou can find the download and source code for the Halo 2 HD patch here: GitHub\n\nI also made a video showing side-by-side comparisons of the stock game vs the\nHD patch, and performance metrics for each video resolution:\n\nYouTube video showing a comparison between stock game and HD patch\n\nTags: 720p, Halo 2, original xbox, xbox, xbox hd patch\n\n### Leave a Reply Click here to cancel reply.\n\n\u2190 Light Gun Hacking Part 1: Using Namco light guns in Unity\n\n### Random Image\n\nCopyright \u00a9 2024\n\nPowered by Oxygen Theme.\n\n", "frontpage": false}
