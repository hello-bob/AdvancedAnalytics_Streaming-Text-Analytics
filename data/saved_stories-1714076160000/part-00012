{"aid": "40157383", "title": "Cohere-toolkit: a collection of prebuilt components for RAG applications", "url": "https://github.com/cohere-ai/cohere-toolkit", "domain": "github.com/cohere-ai", "votes": 3, "user": "tosh", "posted_at": "2024-04-25 13:35:27", "comments": 0, "source_title": "GitHub - cohere-ai/cohere-toolkit: Toolkit is a collection of prebuilt components enabling users to quickly build and deploy RAG applications.", "source_text": "GitHub - cohere-ai/cohere-toolkit: Toolkit is a collection of prebuilt\ncomponents enabling users to quickly build and deploy RAG applications.\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\ncohere-ai / cohere-toolkit Public\n\n  * Notifications\n  * Fork 55\n  * Star 538\n\nToolkit is a collection of prebuilt components enabling users to quickly build\nand deploy RAG applications.\n\n### License\n\nMIT license\n\n538 stars 55 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# cohere-ai/cohere-toolkit\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n7 Branches\n\n1 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nGangGreenTemperTatumfix: fixup ci be pytest tests failing to grab env secrets\n(#47)Apr 25, 2024c009039 \u00b7 Apr 25, 2024Apr 25, 2024\n\n## History\n\n35 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| fix: fixup ci be pytest tests failing to grab env secrets (#47)| Apr 25,\n2024  \n  \n### cli\n\n|\n\n### cli\n\n| Use terrarium image for docker compose setup (#26)| Apr 24, 2024  \n  \n### docker_scripts\n\n|\n\n### docker_scripts\n\n| Use terrarium image for docker compose setup (#26)| Apr 24, 2024  \n  \n### docs\n\n|\n\n### docs\n\n| Azure one-click deployment - link fix (#39)| Apr 24, 2024  \n  \n### src\n\n|\n\n### src\n\n| Tests: rename command (#45)| Apr 25, 2024  \n  \n### .env-template\n\n|\n\n### .env-template\n\n| Langchain Multihop as an experimental feature (#35)| Apr 24, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Initial Commit (#1)| Apr 22, 2024  \n  \n### .pre-commit-config.yaml\n\n|\n\n### .pre-commit-config.yaml\n\n| Initial Commit (#1)| Apr 22, 2024  \n  \n### CODEOWNERS\n\n|\n\n### CODEOWNERS\n\n| Initial Commit (#1)| Apr 22, 2024  \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n| Docs: update how to contribute (#14)| Apr 24, 2024  \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n| frontend: move all the frontend code to interfaces folder (#3)| Apr 22, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Initial Commit (#1)| Apr 22, 2024  \n  \n### Makefile\n\n|\n\n### Makefile\n\n| Tests: rename command (#45)| Apr 25, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| Tests: rename command (#45)| Apr 25, 2024  \n  \n### app.json\n\n|\n\n### app.json\n\n| Initial Commit (#1)| Apr 22, 2024  \n  \n### azuredeploy.json\n\n|\n\n### azuredeploy.json\n\n| Initial Commit (#1)| Apr 22, 2024  \n  \n### azuredeploy.parameters.json\n\n|\n\n### azuredeploy.parameters.json\n\n| Initial Commit (#1)| Apr 22, 2024  \n  \n### banner.png\n\n|\n\n### banner.png\n\n| Initial Commit (#1)| Apr 22, 2024  \n  \n### cloudbuild.yaml\n\n|\n\n### cloudbuild.yaml\n\n| frontend: move all the frontend code to interfaces folder (#3)| Apr 22, 2024  \n  \n### docker-compose.yml\n\n|\n\n### docker-compose.yml\n\n| Use terrarium image for docker compose setup (#26)| Apr 24, 2024  \n  \n### ecs_service.json\n\n|\n\n### ecs_service.json\n\n| Initial Commit (#1)| Apr 22, 2024  \n  \n### gcp.backend.Dockerfile\n\n|\n\n### gcp.backend.Dockerfile\n\n| Initial Commit (#1)| Apr 22, 2024  \n  \n### gcp.frontend.Dockerfile\n\n|\n\n### gcp.frontend.Dockerfile\n\n| Initial Commit (#1)| Apr 22, 2024  \n  \n### poetry.lock\n\n|\n\n### poetry.lock\n\n| Make: use poetry to manage requirements (#20)| Apr 24, 2024  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| Make: use poetry to manage requirements (#20)| Apr 24, 2024  \n  \n### standalone.Dockerfile\n\n|\n\n### standalone.Dockerfile\n\n| Single Docker - use Terrarium public image (#31)| Apr 24, 2024  \n  \n## Repository files navigation\n\n# Cohere Toolkit\n\nToolkit is a collection of prebuilt components enabling users to quickly build\nand deploy RAG applications.\n\n  * Try Toolkit\n  * About Toolkit\n  * Deploy Toolkit\n  * Develop and troubleshoot\n  * Component Guides\n  * What's on our roadmap\n  * How to contribute\n  * Try Coral Showcase\n\n## Quick start\n\n### Deploying to Azure\n\nYou can deploy Toolkit with one click to Microsoft Azure Platform:\n\n### Building and running locally\n\nClone the repo and run\n\n    \n    \n    make setup\n\nFollow the instructions to configure the model - either AWS Sagemaker, Azure,\nor Cohere's platform. This can also be done by running make setup (See Option\n2 below), which will help generate a file for you, or by manually creating a\n.env file and copying the contents of the provided .env-template. Then\nreplacing the values with the correct ones.\n\n### Deploy locally\n\nOnce your environment variables are set, you're ready to deploy the Toolkit\nlocally! Pull the Docker images from Github Artifact registry or build files\nfrom source. See the Makefile for all available commands.\n\nRequirements:\n\n  * Docker\n  * Poetry\n  * Docker-compose >= 2.22\n\n#### Option 1 - Install locally with Docker:\n\nEnsure your shell is authenticated with GHCR.\n\nPull the Single Container Image from Github's Artifact Registry\n\n    \n    \n    docker pull ghcr.io/cohere-ai/cohere-toolkit:latest\n\nRun the images locally:\n\n    \n    \n    docker run --name=cohere-toolkit -itd -e COHERE_API_KEY='Your Cohere API key here' -p 8000:8000 -p 4000:4000 ghcr.io/cohere-ai/cohere-toolkit\n\n#### Option 2 - Build locally from scratch:\n\n##### Option 2.1 - Run everything at once\n\nRun make first-run to start the CLI, that will generate a .env file for you.\nThis will also run all the DB migrations and run the containers\n\n    \n    \n    make first-run\n\n##### Option 2.1 - Run each command separately\n\nRun make setup to start the CLI, that will generate a .env file for you:\n\n    \n    \n    make setup\n\nThen run:\n\n    \n    \n    make migrate make dev\n\nIf you did not change the default port, visit http://localhost:4000/ in your\nbrowser to chat with the model.\n\n## What is included in Toolkit?\n\nComponents in this repo include:\n\n  * src/interfaces/coral_web - A web app built in Next.js. Includes a simple SQL database out of the box to store conversation history in the app.\n  * src/backend - Contains preconfigured data sources and retrieval code to set up RAG on custom data sources (called \"Retrieval Chains\"). Users can also configure which model to use, selecting from Cohere's models hosted on either Cohere's platform, Azure, and AWS Sagemaker. By default, we have configured a Langchain data retriever to test RAG on Wikipedia and your own uploaded documents.\n\n## Deployment Guides\n\nLooking to deploy the Toolkit to your preferred cloud service provider? See\nour guides below:\n\n  * Single Container Setup: Useful as a quickstart to run the Toolkit, or deploy to AWS on an EC2 instance.\n  * AWS ECS Deployment: Deploy the Toolkit single container to AWS ECS(Fargate).\n  * Google Cloud Platform: Help setup your Cloud SQL instance, then build, push and deploy backend+frontend containers to Cloud Run.\n\n## Setup for Development\n\n### Setting up Poetry\n\nUse for configuring and adding new retrieval chains.\n\nInstall your dependencies:\n\n    \n    \n    poetry install\n\nRun linters:\n\n    \n    \n    poetry run black . poetry run isort .\n\n### Setting up Your Local Database\n\nThe docker-compose file should spin up a local db container with a PostgreSQL\nserver. The first time you setup this project, and whenever new migrations are\nadded, you will need to run:\n\n    \n    \n    make migrate\n\nThis will apply all existing database migrations and ensure your DB schema is\nup to date.\n\nIf ever you run into issues with Alembic, such as being out of sync and your\nDB does not contain any data you'd like to preserve, you can run:\n\n    \n    \n    make reset-db make migrate make dev\n\nThis will delete the existing db container volumes, restart the containers and\nreapply all migrations.\n\n### Testing the Toolkit\n\nRun:\n\n    \n    \n    make dev\n\nTo spin the test_db service for you. After, you can run:\n\n    \n    \n    make run-tests\n\n### Making Database Model Changes\n\nWhen making changes to any of the database models, such as adding new tables,\nmodifying or removing columns, you will need to create a new Alembic\nmigration. You can use the following Make command:\n\n    \n    \n    make migration\n\nImportant: If adding a new table, make sure to add the import to the\nmodel/__init__.py file! This will allow Alembic to import the models and\ngenerate migrations accordingly.\n\nThis should generate a migration on the Docker container and be copied to your\nlocal /alembic folder. Make sure the new migration gets created.\n\nThen you can migrate the changes to the PostgreSQL Docker instance using:\n\n    \n    \n    make migrate\n\n### Troubleshooting\n\n#### Multiple errors after running make dev for the first time\n\nMake sure you run the following command before running make dev:\n\n    \n    \n    make migrate\n\n#### Debugging locally\n\nTo debug any of the backend logic while the Docker containers are running, you\ncan run:\n\n    \n    \n    make dev\n\nThis will run the Docker containers with reloading enabled, then in a separate\nshell window, run:\n\n    \n    \n    make attach\n\nThis will attach an interactive shell to the backend running, now when your\nbackend code hits any\n\n    \n    \n    import pdb; pdb.set_trace()\n\nit will allow you to debug.\n\n## Component Guides\n\n### How to add your own model deployment\n\nA model deployment is a running version of one of the Cohere command models.\nThe Toolkit currently supports the model deployments:\n\n  * Cohere Platform (model_deployments/cohere_platform.py)\n\n    * This model deployment option call the Cohere Platform with the Cohere python SDK. You will need a Cohere API key. When you create an account with Cohere, we automatically create a trial API key for you. You can find it here.\n  * Azure (model_deployments/azure.py)\n\n    * This model deployment calls into your Azure deployment. To get an Azure deployment follow these steps. Once you have a model deployed you will need to get the endpoint URL and API key from the azure AI studio https://ai.azure.com/build/ -> Project -> Deployments -> Click your deployment -> You will see your URL and API Key. Note to use the Cohere SDK you need to add /v1 to the end of the url.\n  * SageMaker (model_deployments/sagemaker.py)\n\n    * This deployment option calls into your SageMaker deployment. To create a SageMaker endpoint follow the steps here, alternatively follow a command notebook here. Note your region and endpoint name when executing the notebook as these will be needed in the environment variables.\n  * To add your own deployment:\n\n    1. Create a deployment file, add it to /model_deployments folder, implement the function calls from BaseDeployment similar to the other deployments.\n    2. Add the deployment to src/backend/config/deployments.py\n    3. Add the option to cli/main.py and the environment variables required to the env template.\n  * To add a Cohere private deployment, use the steps above copying the cohere platform implementation changing the base_url for your private deployment and add in custom auth steps.\n\n### How to call the backend as an API\n\nIt is possible to just run the backend service, and call it in the same manner\nas the Cohere API. Note streaming and non streaming endpoints are split into\n'http://localhost:8000/chat-stream' and 'http://localhost:8000/chat' compared\nto the API. For example, to stream:\n\n    \n    \n    curl --location 'http://localhost:8000/chat-stream' \\ --header 'User-Id: me' \\ --header 'Content-Type: application/json' \\ --data '{ \"message\": \"Tell me about the aya model\" } '\n\n### How to add your own chat interface\n\nCurrently the core chat interface is the Coral frontend. To add your own\ninterface, take the steps above for call the backend as an API in your\nimplementation and add it alongside src/interfaces/coral_web.\n\n### How to add a connector to the Toolkit\n\nIf you have already created a connector, it can be used in the toolkit with\nConnectorRetriever. Add in your configuration and then add the definition in\nconfig/tools.py similar to Arxiv implementation with the category\nCategory.DataLoader. You can now use the Coral frontend and API with the\nconnector.\n\n### How to set up web search with the Toolkit\n\nTo use Coral with web search, simply use the Tavily_Internet_Search tool by\nadding your API key to the env file. Alternatively you can use any search\nprovider of your choosing, either with your own implementation or an\nintegration implementation (such as LangChain) by following these steps below.\n\n### How to set up PDF Upload with the Toolkit\n\nTo use Coral with document upload, simply use the File_Upload_LlamaIndex or\nFile_Upload_Langchain (this needs a cohere API key in the .env file) tool or\nby adding your API key to the env file. Alternatively you can use any document\nuploader of your choosing, either with your own implementation or an\nintegration implementation (such as LangChain) by following these steps below.\n\n### How to create your own tools and retrieval sources\n\nToolkit includes some sample tools that you can copy to configure your own\ndata sources:\n\n  * File loaders - Parses a PDF file and performs RAG. Enables users to upload PDF in Toolkit UI. Users have an option to use either Langchain or Llamaindex, whichever is preferred. Langchain is used by default.\n  * Data loaders - This tool queries a data source and then performs RAG on extracted documents. We used Langchain's Wikiretriever as the sample data source.\n  * Functions - Python interpreter and calculator tools.\n\nTo create your own tools or add custom data sources, see our guide: tools and\nretrieval sources overview\n\n## Experimental Features\n\nPlease note that these are experimental features.\n\n### Langchain Multihop\n\nChatting with multihop tool usage through Langchain is enabled by setting\nexperimental feature flag to True in .env.\n\n    \n    \n    USE_EXPERIMENTAL_LANGCHAIN=True\n\nBy setting this flag to true, only tools that have a Langchain implementation\ncan be utilized. These exist under LANGCHAIN_TOOLS and require a\nto_lanchain_tool() function on the tool implementation which returns a\nlangchain compatible tool. Python interpreter and Tavily Internet search are\nprovided in the toolkit by default once the environment is set up.\n\nExample API call:\n\n    \n    \n    curl --location 'http://localhost:8000/langchain-chat' \\ --header 'User-Id: me' \\ --header 'Content-Type: application/json' \\ --data '{ \"message\": \"Tell me about the aya model\", \"tools\": [{\"name\": \"Python_Interpreter\"},{\"name\": \"Internet Search\"},] }'\n\nCurrently, citations are not supported in lanchain multihop.\n\n## Roadmap\n\n  1. Set env variables in UI\n  2. Include citations for multi hop tools\n  3. Display images for python interpreter tool\n  4. Add a slack bot as an available interface\n  5. White labelling: Changing fonts, logos, and colours.\n  6. User management and authentication system: Toolkit is currently configured with one user role and no authentication.\n\n## Contributing\n\nContributions are what drive an open source community, any contributions made\nare greatly appreciated. To get started, check out our documentation.\n\n## About\n\nToolkit is a collection of prebuilt components enabling users to quickly build\nand deploy RAG applications.\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\nActivity\n\nCustom properties\n\n### Stars\n\n538 stars\n\n### Watchers\n\n13 watching\n\n### Forks\n\n55 forks\n\nReport repository\n\n## Releases 1\n\n2024-04-24 (v1.0.0) Latest\n\nApr 24, 2024\n\n## Packages 0\n\nNo packages published\n\n## Contributors 9\n\n## Languages\n\n  * TypeScript 58.0%\n  * Python 36.3%\n  * JavaScript 1.6%\n  * Dockerfile 1.5%\n  * Shell 1.2%\n  * CSS 1.2%\n  * Other 0.2%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
