{"aid": "40280032", "title": "Binary Banshees and Digital Demons (2021)", "url": "https://thephd.dev/binary-banshees-digital-demons-abi-c-c++-help-me-god-please", "domain": "thephd.dev", "votes": 1, "user": "agluszak", "posted_at": "2024-05-06 22:03:26", "comments": 0, "source_title": "Binary Banshees and Digital Demons", "source_text": "Binary Banshees and Digital Demons | The Pasture\n\nThe Pasture\n\n# Binary Banshees and Digital Demons\n\nSeptember 20, 2021\n\nThe Committee says these things do not exist. The Committee says these things\nare invisible, not our business, and not something we can or should talk\nabout.\n\nThey lie.\n\nThe standard is haunted. I know it is. Especially by that Three Letter Demon.\nI never really talked about how it has plagued me \u2014 plagued us all \u2014 with its\ninsidious presence. Always the looming and lurking danger of The Demon,\nfearing the rearing its ugly head. While lamenting its existence I could never\nface it head on to challenge it. It is only at the height of my isolation that\nI could no longer bear witness to the violence the Three Letter Demon did to\nour beloved programming community and, thusly, began to scheme to take it\ndown. But before we challenge it, dear reader, it stands to reason: what\nexactly is the Three Letter Demon? And why does The Demon matter to C and C++?\nLet\u2019s finally get through this, in full, with a little illustrative help from\nour favorite local cryptid, kismet! and Luna Sorcery.\n\n# Application Binary Interface\n\nOr, as it\u2019s more commonly known as, ABI. Before many of you reading this were\neven born, before many of you reading this even knew what a computer was, a\ncontract was forged in blood. It is not one you get to make for yourself; in\nfact, your consent or knowledge of its existence is not required, nor is it,\nfrankly, at all requested. Everyone relies on it, and yet even people who\nbuild their own C++(-alike) compilers from scratch are unsure that such a\ncontract exists, or that they\u2019re even playing by such rules:\n\n> C has an ABI to break?\n>\n> \u2014 Sean Baxter, Author of the Circle Compiler, July 19th, 2021\n\nIt stands to reason most would not know of it, because it is not an agreement\nmade between the code you write and the output you rely on or expect to see.\nThere is no binding words between your code and the language/library (which is\nthe Application Programming Interface, or API), but an exchange happens on\nyour behalf. Implementers, with other implementers, declare that if something\nis shaped like \u201cX\u201d, it will behave like \u201cX\u201d under \u201cY\u201d given conditions. It\nexists in the cracks and the nooks of an implementation where most language\ndesigners and code writers don\u2019t really think about:\n\nwhat, literally, needs to exist on my machine and happen for it to do the\nthings I want to do?\n\nHow a function calls another function, how the stack is set up, where\nvariables do and do not exist, how a data structure\u2019s very bits and bytes are\ntraversed. This is not a lamentation: nobody should have to think about such\nbanal details to get any amount of serious work done! But like all\nabstractions, these things end up leaking. And sometimes, those leaks can take\non a whole life of their own. Become alive. And that\u2019s where the old contract\ncomes up. Still, I should explain. What are some practical example of such a\ncontract?\n\nLet\u2019s take a look.\n\n## ABI: An Illustration\n\nTo understand how ABI can affect us in C and C++, we will take a very real\npatch filed by an implementer of a C++ Standard Library. It\u2019s about the\niterator for a type:\n\n> Defaulting the copy constructor on its first declaration made it change from\n> user-provided (and non-trivial) to implicitly-defined (and trivial). This\n> caused an ABI incompatibility between GCC 8 and GCC 9, where functions\n> taking a deque iterator disagree on the argument passing convention.\n>\n> \u2014 Jonathan Wakely, libstdc++ Mailing List, October 29th, 2019\n\nCan that really happen? Well, let\u2019s look at the assembly generated for 2\nhypothetical \u201citerators\u201d, that fit the above bug report description. We\u2019ll use\n2 structures with the same stuff inside, but with a user-provided constructor\nand one that is defaulted. It looks a bit like this:\n\n    \n    \n    struct deque_block; struct deque_iterator_one { deque_block* thing; int* current; deque_iterator_one() noexcept = default; deque_iterator_one(const deque_iterator_one&) noexcept = default; deque_iterator_one& operator=(const deque_iterator_one&) noexcept = default; }; struct deque_iterator_two { deque_block* thing; int* current; deque_iterator_two() noexcept = default; deque_iterator_two(const deque_iterator_two& other) noexcept : thing(other.thing), current(other.current) { } deque_iterator_two& operator=(const deque_iterator_two&) noexcept = default; }; extern int f_one(deque_iterator_one it); extern int f_two(deque_iterator_two it); int main () { deque_iterator_one d1{}; deque_iterator_two d2{}; f_one(d1); f_two(d2); return 0; }\n\nWe\u2019re not concerned with the actual implementations of f_one and f_two. It\u2019s\nin an external library somewhere, possibly compiled in a separate dynamically\nlinked library (.dll)/shared object (.so). This is how f_one gets called by\nGCC:\n\n    \n    \n    xor edi, edi xor esi, esi call _Z5f_one18deque_iterator_one ; f_one(deque_iterator_one)\n\nAlright, it uses 2 registers \u2014 edi and esi \u2014 and just passes the pointers on\nthrough to the function that way. (It xors the registers because it can detect\nat compile-time that the binary representation for the two pointers is all-\nzero nullptrs. A xor A is always 0.) What about f_two? Assuredly, the contents\nare the same, the compiler couldn\u2019t possibly agree to a different contra-\n\n    \n    \n    pxor xmm15, xmm15 mov rdi, rsp movaps XMMWORD PTR [rsp], xmm15 call _Z5f_two18deque_iterator_two ; f_two(deque_iterator_two)\n\nThat\u2019s... definitely not the same assembly. Despite having identical structure\nand content, changing the copy constructor changes how it\u2019s called. And not\neven changing the copy constructor in a way that truly matters: the behavior\nis identical in both forms: it does a bit-blasting copy operation! Right now,\nwe have the functions \u2014 f_one and f_two \u2014 with two distinct names, and two\ndistinct symbols in the final executable. But, you can imagine that if we had\na single deque_iterator type, and added that copy constructor, GCC would\nviolate the previously-established edi + esi register contract expected by the\ninternals of some call f and instead start messing around with rdi and xmm15.\nThis means that while the code compiles, links, and even runtime loads\nproperly, the actual running of the code has a separate by-the-bits\nexpectation. And when every single bit matters, it turns out everything else\nneeds to be extremely well-defined when it comes to how the world works out.\nArgument placement, data layout, even the amount of stack space used and where\nthings are kept changes based on making a fundamentally idempotent change to\nthe copy constructor.\n\n## ABI: Even Simpler\n\nLike the tweet above, some people think that ABI is explicitly a C++ problem.\nC is immune, after all, because it\u2019s so simple! Sure, structures change, but\nthere\u2019s no overloading! No member functions! No constructors or destructors or\nalphabet-spaghetti nonsense like \u201cRAII\u201d or \u201cSFINAE\u201d, whatever the hell those\nare. And yet, in all Kernighan and Ritchie\u2019s wisdom, we still have the same\nproblem. In fact, we have the problem even worse than C++ does.\n\nIf you remember the example from above, we get these really filthy mangled\nsymbols:\n\n    \n    \n    ... call _Z5f_two18deque_iterator_two ; f_two(deque_iterator_two) ... call _Z5f_one18deque_iterator_one ; f_one(deque_iterator_one)\n\nThis means that, even if we named both functions just f in our code, at the\nsymbol-level in our binaries it could tell apart a function meant for\ndeque_iterator_one and deque_iterator_two. Again, this is because it\u2019s grafted\nthe name of the type into the final symbol that shows up in our binary:\n\n    \n    \n    ... call _Z5f18deque_iterator_two ; f(deque_iterator_two) ... call _Z5f18deque_iterator_one ; f(deque_iterator_one)\n\nHow does this work in C? Ignoring the fact that you cannot name a function the\nsame thing twice in C, it turns out we can get into trouble. Take, for\nexample, a function that takes a long long and one that takes an __int128_t:\n\n    \n    \n    extern int fll (long long value); extern int fi128 (__int128_t value); int main () { fll(1); fi128(1); return 0; }\n\nOnce again, we inspect the assembly:\n\n    \n    \n    mov edi, 1 call fll mov edi, 1 xor esi, esi call fi128\n\nWe can see here that it uses 2 registers \u2014 edi and esi \u2014 for the __int128_t\ncase, but only one \u2014 edi \u2014 for the long long case. If someone worked with a\nheader file which used a typedef that changed in a function, we could end up\nwith breakage. For example, the header file with a typedef of typedef\n__int128_t chonky_integer; was changed to typedef long long chonky_integer;,\nand we had a function that looked like extern int f(chonky_integer value);, we\nmight end up in a situation where the compiled DLL/SO was expecting a\n__int128_t (both edi and esi should be populated) instead of a long long (just\nthe edi). That\u2019s a break, because if the function is expecting both edi and\nesi, and we only fill out the value for the edi register, who knows what\u2019s in\nesi? This kind of breakage would be supremely hard to track, and might result\nin quite a lot of heartbreak later down the line as random values in esi\nchange the way our program runs. The reverse situation is also terrible: if a\nDLL/SO was expecting a long long in edi, but we handed our value over in edi\nand esi, we\u2019ve ended up in a situation where it\u2019s impossible to use the full\n128 bits of our value. Random truncations, numbers that aren\u2019t signed being\nconsidered signed because they\u2019ve got a certain bit-pattern in edi, and more\nshenanigans could all follow in a way that\u2019s devastatingly hard to debug.\n\nNote that unlike C++, C has no built-in protection against this because of the\nway symbols get mangled. If you have a function f that, in one place, presents\nitself as taking a single __int128_t and another that takes a long long, it\ncan end up looking like this:\n\n    \n    \n    mov edi, 1 call f mov edi, 1 xor esi, esi call f\n\nThere is no \u201clong long\u201d or \u201c__int128_t\u201d baked into the names like there would\nbe for C++. You just get the function name, and good luck to you if you don\u2019t\ngive it the right arguments. Without a header file or reverse-engineering the\nbinary that f came from, you\u2019d never know what it was calling or what it was\nexpecting, which is genuinely terrifying. It also means that on an incredibly\nfundamental level - simple free functions! - C\u2019s ABI is even more brittle than\nC++\u2019s. The only reason people advertise C as having a \u201cstable ABI\u201d is because\nthey mean \u201cwe exported a single function name and then proceeded to never\ntouch it for a million years\u201d. Just because the name never changes, doesn\u2019t\nmean the functionality or the inputs never change: never having that reflected\nin the final symbol name means that C is more dangerous than C++ here.\nChanging a function signature in any way is a break: adding parameters,\nremoving parameters, return types or even what passed-in pointers actually\npoint to! All of these things can be done at the drop of a hat in C++, but\ntear C code in horrific ways.\n\n# Okay... But Why Does It Matter?\n\nWell, for C, it means that changing anything - literally anything - is an ABI\nbreak. Change your typedef to be a bigger integer? ABI break. Fix your time_t\nstructure to handle time with 64-bit numbers because Jesus Christ I Thought We\nAlready Have Been Through This Please Stop Using 32-bit Integers For Your Time\nStructures? ABI Break (and probably a security issue):\n\n> musl 1.2 is now available and changes time_t for 32-bit archs to a 64-bit\n> type. Before upgrading from 1.1.x, 32-bit users should read the time64\n> release notes.\n>\n> \u2014 musl libc, September 18th, 2021\n\nAnd so on, and so forth.\n\nFor C++, they can change types that go into functions, add overloads, etc.\nbecause the type names are mangled with the function. But for solving that\nproblem, they introduce a whole lot of new bits of fun that are just oh-so-\ndelightful to have to deal with. For example, back in 2009, a paper \u2014 N2994,\nwhen we still used \u201cN\u201d paper numbers! \u2014 was accepted into the C++ standard. It\nbasically went through and not only constexpr-ified many random bits in the\nC++ standard, but added the property that some iterators were trivially\ncopyable, copy constructible, and destructible in typical cases. This meant\nthat, effectively, these types would always be extraordinarily cheap to\ncopy/move (often just bit operations) or destroy for their respective\nplatforms. It went in. And then a strange e-mail popped up nearly 10 years\nlater:\n\n> [isocpp-lib] N2994 was an ABI-breaking change to istream_iterator\n\n... Huh? It had been 10 years: July 19th, 2019 is when this e-mail dropped\ninto my inbox. N2994 been approved a long time ago! How do you have an ABI\nbreak from a pre-C++11 paper? This was before even my time, before I was even\nthat into computers! And yet, this was exactly this case. It was similar to\nthe deque_iterator case, just like outlined above: hand-crafted constructors\nprevented it from being a trivial type.\n\nSome debate ensued. Thank God, we legitimately just had better things to do at\nthe time: this was ~2 meetings before the final C++20 Prague Meeting, which\nwas the last in-person meeting the C++ Standards Committee has had since (*\ngestures vaguely towards Outside *) happened. The thread ultimately fizzled\nout as other things were focused on, a Library Working Group (LWG) issue was\nnever filed, and std::istream_iterator<some-trivial-type> as far as Standard\nC++ is concerned remains std::is_trivially_copy_constructible_v. Of course,\nthis tiny detail has made it so some implementations - like GCC - just don\u2019t\nconform out of fear of the same bug that deque_iterator suffered from above.\n\nThe worrying part about this is how, retroactively, long-accepted work done on\nthe C++ Standard can be threatened if an implementation forgets to make a\nchange before they flip their ABI switch. In this case, we very much just\nhaven\u2019t done anything. Whether that was an intentional choice to just not\nbother, or an accident that I may unfortunately be roundabout-informing the\noriginal submitter that they can, in fact, grind this ABI axe with the C++\nCommittee if they remember to pick it up, is up to speculation. In my heart, I\nfeel like this current situation is the right choice: the Standard makes a\nguarantee and libstdc++ just can\u2019t meet it for legacy reasons. I do not want\nwhat happened to deque_iterator happening to istream_iterator, no thank you: I\nprefer my calling conventions cheap and my code lean, thank you very much! Of\ncourse, this is a situation where the ship has already sailed. But...\n\nwhat would happen if you weren\u2019t 10 years late to the party?\n\n# Building a Graveyard\n\nMost of the time I\u2019ve talked about ABI, it has usually been a casual mention,\nin the context of some other fight or some other larger problem. But here,\nwe\u2019re going to talk about strictly ABI. Specifically, what happens when the\nABI not only comes from the past, but also invades the present and future to\nstop us from doing things in C and C++.\n\n## From The Past\n\nThere are a lot of choices our forebears made that we are now eternally\nresponsible for when it comes to ABI. One of the biggest examples of such are\nthings like C\u2019s intmax_t, or C++\u2019s std::initializer_list and std::regex.\nBecause of implementation choices that are not at all mandated or even\nrequired by the C or C++ standard, we get bound to either a lesser quality of\nimplementation or get locked out of improvements the industry has long-since\nembraced, forcing us to keep things terrible.\n\n### C - intmax_t, strcpy, and Literally Everything Else\n\nI\u2019ve written about intmax_t, explaining how we\u2019re so unbelievably doomed when\nit comes to trying to upgrade intmax_t, and how that\u2019s tied to various parts\nof C and C++ processing. We can\u2019t have integer literals larger than intmax_t,\nand since that means we\u2019re stuck at long long for most architectures that\nmeans you can never write 128-bit or 256-bit literals. It means\nstd::numeric_limits<T> can never have implementation-defined integer types\nlike __int128_t work with them by-default because that\u2019s technically a\nviolation of the statutes, since every single integer type that is compatible\nwith std::numeric_limits<T> needs to have a size less than or equal to\nintmax_t.\n\nThe worst part is, it results in a LOT of wasted time:\n\nThis was from a presentation on the subject to the C Committee at the\nbeginning of September during a virtual meeting. We\u2019ve wasted no less than 5\npapers trying to (and failing to) solve this problem, and if we intend to\nsolve it there will be more papers that come along the way, some of them soon.\nSome parts of the intmax_t problem have been solved: for example, the Specific\nWidth Length Modifier was added to C to solve the problem of printing\narbitrarily-large-sized integers that the implementation can handle printing.\n\nThe status-quo remains, however: despite it being common practice amongst\nlibraries like musl libc and glibc to provide weak aliases and other forms of\nimplementation-specific indirection over functions to prevent ABI problems\n(and allow for safe overriding in select circumstances), the standard itself\nis bound by the simplest possible implementation of the C Standard Library.\nBecause there is no standard-mandated solution for name aliases / indirection\nin C, or ways to provide name-mangling on your own, someone can create a POSIX\nimplementation that takes all of the names in the C Standard very literally.\nAll of the names \u2014 strcpy, strcat, memset, gets_s, what have you \u2014 appears\nexactly in the system\u2019s globally shared symbol table. That means that even if\na specific application wanted to, say, request a printf that\u2019s capable of\nprinting int128_t or has special format modifiers for certain structs, that\nprintf has to be globally upgraded and agreed upon by every single program in\nthe system that uses the C library.\n\nYeah.\n\nDear reader, you can likely see why this becomes a problem when you have a\nsystem that becomes older than a few years, or you have a package manager\nrunning for said systems running for any length of time. Everybody has to\nagree in perpetuity, all the time, from the time someone settles that\nimplementation\u2019s global table onward. And that really means whoever gets there\nfirst wins, not whoever has the best idea or works the hardest to improve\ntheir runtime. This is why Victor Zverovich found it easy to kick the C and\nC++ standard libraries\u2019s butts:\n\n> Even formatting such simple things as hour:minute with format string\n> compilation in {fmt} can be almost 10x faster than ostringstream and ~2.5x\n> faster than printf =)\n>\n> Victor Zverovich, September 3rd, 2021\n\nIf we can never improve what we have without fear of binary break - on top of\nactual source-breaking changes - it doesn\u2019t matter how carefully people craft\ndesign, because someone can and will always be able to completely outstrip\nthat body of work, even if theoretically you could do better under the old\ndesign constraints. As the system becomes larger, bug-compatibility becomes\nmore important than performance or correctness, and serving your life up on\nthe altar of 50 year old design decisions becomes harder to resist with each\nprogressively larger system rolled on top of another.\n\nThe same thing happened with Nested Functions in C, too.\n\n### Nested Functions are an ABI Break?!\n\nUnfortunately, yes.\n\nNested Functions are a very pretty GCC extension that takes the natural form\nof a function definition and extends it to exist inside of other function\ncalls, allowing you to reference local data in callbacks:\n\n    \n    \n    int main () { int x = 1; int f (int y) { // a nested function! return x + y; }; return f(1); }\n\nNested Functions in GCC, if we were to standardize them, can result in an ABI\nbreak if we try to change their behavior or fix the potential security issue\nwith them. As I detailed in another article where I went into depth about the\nvarious ways to handle \u201cfunction + data\u201d in C-style APIs, Nested Functions are\nimplemented as a trampoline jump with an executable stack in the most general\ncase when no special optimizations can be taken. Executable stacks are a basic\nsecurity issue: for some people they\u2019re not that important, for other people\nit makes Nested Functions dead-on-arrival. Strangely enough, GCC supports\nother languages - like Ada - with Nested Functions that can and do perform the\nsame computations as their C and C++ forms. To do so, Ada uses an\nimplementation technique called Function Descriptors, which are inherently\nsafer and can handle all of the cases that Nested Functions need without\nmaking an executable stack. Unfortunately, differentiating between the\nexecutable stack technique and the function descriptor technique requires\nsetting a bit that is always off (0) in function pointers to instead be on\n(1). And you\u2019d think that would never matter,\n\nexcept it does.\n\nMartin Uecker tried his best to create a solution that allowed for general-\npurpose usage by following Ada\u2019s implementation technique:\n\n> ... You pass -fno-trampolines and it would use the lowest bit to\n> differentiate between a regular pointer and a descriptor (based on what Ada\n> does). It still has run-time overhead and ABI issues.\n>\n> Martin Uecker, July 17th, 2021\n\nUnfortunately, that\u2019s not how function pointers are expected to be called in\nC. Even if the bit was \u201calways zero\u201d before, there is an implicit, binary\nexpectation in every single C-derived program that you can just blindly\nreinterpret the function address bits as a function call, set up the stack\nwith the arguments, and jump right on over. Altering that bit means you may\nattempt to call a function at an improper alignment, resulting in All Hell\nBreaking Loose. So, you need to mask off the bottom bit - something no binary\nis currently doing in the wild - check if that bottom bit means you\u2019re doing\nSpecial Function Descriptor ThingsTM, and then proceed with the function call.\n\nSo, it\u2019s a binary break to do it the function descriptor way! \ud83e\udd73\n\nWhy is this a problem, though? After all, it\u2019s just GCC\u2019s extension with the\nsecurity issue! Well, as per usual, syntax means everything. Because GCC\n\u201cstole\u201d that syntax for its extension, if we standardize something with the\nsame syntax but different semantics, that\u2019s a behavioral break for GCC. And,\nit only gets better if we try to smooth the problems over! If we maintain all\nthe same semantics / behaviors, we then have to contend with the fact that GCC\nhas, for some ~23+ years, been shipping this syntax with an executable stack.\nEither we take it as GCC\u2019s done it into the C Standard and condemn the world\u2019s\nlargest/prolific C compiler to its executable stack and security failures\n(including that code not being allowed to run / load on multiple different\nplatforms from the get-go), or we demand they make an ABI break about the way\nthe world\u2019s most basic unit of reusable computation \u2014 the function call \u2014 is\ndone!\n\nYeah, I didn\u2019t think that was going to fly either. So, even if I like Nested\nFunctions and their syntax, thanks to what GCC has done, we have very little\nin the way of remedies for this. The ghosts of the past continue to haunt the\npresent and future of C, and continue to cause us undue harm to the language\u2019s\nevolution. C isn\u2019t the only one in its language and library to fundamentally\nruin present and future directions from past choices, though!\n\n### Regex\n\nA long time ago, C++ standardized what was effectively boost::regex with some\ntweaks. Support for it was spotty: at one point regex_match in GCC was just a\nfunction whose entire body was just return true;. Even after it was finally\nimplemented, std::regex has some of the poorest execution time, throughput,\nand compilation time known to mankind:\n\nNominally, many people have suggested changing std::regex in ways that would,\nat the very least, make it more useful. After all, maintaining a regex engine\nis basically its own full-time job: but, if someone\u2019s going to at least ship a\ndubiously correct implementation, it should at least be useful, right?\n\n... Right?\n\nThe problem with wanting some of that useful stuff is that the things done in\nthese poor implementations are ABI locked-in. Did you want to have a\nstd::regex::multiline constant in an updated C++17 implementation? That\u2019s an\nABI break. Did you want to have a new mode with specializations for handling\nUTF-8, UTF-16, and UTF-32 encoded text? That\u2019s an ABI break, even when you\ndeliberately avoid touching any existing template specializations like\nwregex_match. For example, MSVC uses the options flag and stores it in an\ninternal template parameter before exporting all of the interfaces into DLLs.\nAdding new options means changing the syntax_option_type value in that\ninternal template parameter, which gets mangled into the templated function\nnames of the secret implementation sauce. That means that making any changes\nto this syntax option breaks existing MSVC code when an older Standard Library\nis linked with newly built applications using upgraded standard library\nheaders. The secret implementation sauce is loaded but without a proper match\nfor any new values added to the option type, resulting in either load time\nfailures in end-user machines or more visceral schisms when pointers to\nspecific functions point to things that don\u2019t actually exist, just like in the\nsimpler examples above.\n\nSure, C++\u2019s std::regex is terrible. Having some ~4 different flavors of syntax\nand various options as part of the syntax_option_type is terrible design, and\nwe should never design something that way again. But the response to papers\nand proposals trying to steadily dig us out of this hole is to bring up ABI\nblockers and cite how much we don\u2019t like std::regex\u2019s design as a whole, while\npreparing to mark it for deprecation:\n\n> The SG16 poll in favor of deprecating std::regex was based on design and\n> evolution related concerns. Volunteers agreed to bring forward a deprecation\n> paper.\n\nYou\u2019ll note part of the magic words for doing this deprecation is \u201cDo we want\nto recommend deprecation of std::regex without guarantee of replacement?\u201d.\nThat means that, if we do deprecate it, there\u2019s no guarantee you\u2019re going to\nget a replacement regular expression library back in the Standard. Maybe\nsomeone like Hana Dus\u00edkov\u00e1 will bring a paper forward for something like CTRE.\nMaybe we can ask the author of P1844 \u2014 Nozomu Kat\u014d-san, a man we\u2019ve already\ndisappointed despite him doing the proper job of shipping and gaining usage\nand deployment experience with a standard-like regex library supporting\nUnicode-encoding-aware iteration \u2014 to just make something completely new. Or,\nwe can get absolutely nothing, and someone will bring a paper after a standard\nor two (3-6 years) to go ahead and remove std::regex from the Standard\nLibrary.\n\nThis becomes the everlasting problem in most Committee discussions when a\nproposal (might!) involve an ABI break. We could just deprecate std::regex and\npropose std::regex2, but the moment that proposal comes out everyone gets\nannoyed about the name and \u201cwhy can\u2019t we just fix regex?!\u201d and then the ABI\npeople pipe up and around and around the circle goes. It\u2019s never about what\nyou can and cannot have, at the end of the day: you can easily just fork the\nentire Standard Library into std2 and have a blast and fix all of your\nterrible inconsistent design choices at a nice and reasonable pace. No, the\nproblem is that we explicitly get in the way of such initiatives on principle\n(e.g., one of the previous LEWG Chairs considered their highest accomplishment\n\u201ckilling std2\u201d), which would be fine if we actually had a path forward for\nexisting designs. But for many things that are not purely additions, we run\ninto currently existing implementations,\n\nand it can block a lot of progress.\n\nRemember that at no point was Nozomu Kat\u014d-san in the wrong here. They did\neverything we normally ask of a person engaging with the C++ Committee: write\na proposal, submit it to be presented with a champion, have an existing\nimplementation with usage and deployment experience, and have technical\nwording that can be improved by wording experts to go into the C++ standard if\nit is not already good specification. There was no reason Kat\u014d-san failed\nother than the inability of the existing implementations to cope with ABI\ninstability or wanting to nitpick std::regex\u2019s existing design. For example,\nsome people complained that std::regex can work with any bidirectional\niterator, and \u201chonestly, who would do that or need that in this day and age?\nWho is going to iterate over a list<char>?\u201d. Unluckily for this person, that\ncriticism rings hollow in the face of existing practice in even modern C++\nimplementations of regular expressions. It\u2019s also utterly reductive: linked\nlists and growable arrays exist on two opposite ends of the data structure\nspectrum. There is plenty of room for other traversable data structures in-\nbetween, including ropes, gap buffers, and more.\n\nNevertheless, we, as the Committee:\n\n  * took the contributions of someone who was, perhaps, one of the only Japanese developers not affiliated with any company by the Japanese National Body or the C++ Committee in general;\n  * that, fixed something in the language that has long been exceptionally busted (Unicode encoding-aware regexen);\n  * and, effectively ran them into the ground;\n  * for, a sequence of concerns completely outside of their design auspice (std::regex\u2019s poor initial design) and implementation control (ABI concerns from implementers).\n\n... Nice?\n\nIt becomes harder and harder to defend a \u201cno improvements, ever\u201d model to the\nstandard as we continue to pile the bodies higher and higher of those who try\nin reasonable good faith to make this standard a better version of itself\nwithin the rules and confines we place on individuals.\n\nAnd somehow, we wonder why people spend their time proposing new\nfeatures/additions rather than fixes to old things! Like\nstd::initializer_list, for example, which has been its own quiet little blood\nbath.\n\n### You Shall Not Move\n\nC++11 introduced both std::move/move semantics, and std::initializer_list.\nUnfortunately, std::initializer_list was move-resistant: the backing memory of\nthe compiler-generated std::initialier_list data was always some fanciful,\nmagical const-qualified array of stuff. That meant that the data coming out\nfrom a std::initializer_list\u2019s iterators upon dereference were const T&, not\nT&. It is effectively illegal to move from that storage, even if you were to\ncast it, because sometimes compilers \u201coptimize\u201d the storage so that it only\ncreates it once, even if it\u2019s used multiple times in a loop. For example, this\ncode:\n\n    \n    \n    #include <string> #include <vector> #include <cstddef> int main () { std::vector<std::vector<std::string>> string_buckets; for (std::size_t i = 0; i < 24; ++i) { string_buckets.push_back({\"hello\", \"there\", \"friend\", \":)\"}); } return 0; }\n\nneed not create a fresh std::vector<std::string> on every iteration, to then\ncopy into the string_buckets. On the contrary, this is a viable compiler\ntransformation (done by hand to show what can happen):\n\n    \n    \n    #include <string> #include <vector> #include <cstddef> int main () { const std::vector<std::string> _MagicCompilerStorage[1]{ {\"hello\", \"there\", \"friend\", \":)\"} }; std::vector<std::vector<std::string>> string_buckets; for (std::size_t i = 0; i < 24; ++i) { std::initializer_list<std::vector<std::string>> _MagicCompilerInitList = _MagicCompilerInitializerList(_MagicCompilerStorage); string_buckets.push_back(_MagicCompilerInitList); } return 0; }\n\nThis is, of course, a huge problem if you want to initialize a container or\nother cool type with an initializer_list that would contain, for example,\nstd::unique_ptrs or similar. After all, it\u2019s read-only, const memory. You\ncan\u2019t move out of it; that\u2019s the whole point! There were several papers that\nattempted to fix the problem, from introducing specializations rules, trying\nto introduce special rules instead, to trying to find new types to use, to\nultimately - and most recently - just trying to fix std::initializer_list\nitself, directly. After all the early decisions to try and find a new type and\nmake it clear that it was not going to be accepted, and new rules weren\u2019t\ngoing to be allowed. Why not fix std::initializer_list itself-\n\n#### Hey, That\u2019s an ABI Break!\n\n...\n\nYep! Despite getting a handful of papers before C++11 shipped to fix the\nproblem, we did not in fact fix the problem. So when I took my na\u00efve self to\nrepresent the paper on behalf of Alex Christensen, and I was informed that\nmoving from the storage that was \u201choisted\u201d out of the loop by the compiler in\nan effort to save on space / constructions, I was initially like \u201coh, I\u2019ll\njust write a proposal for std::initializers!\u201d. That is, in fact, what I very\nfoolishly e-mailed the author:\n\n> Dear Alex Christensen,\n>\n> The current revision of this paper has hit an unfortunate, show-stopping\n> roadblock: ABI.\n>\n> c++23.cpp: (compiled with -std=c++2c or something)\n>  \n>  \n>     DLL_EXPORT void initializer_list_stuff (std::initializer_list<int> il) {\n> *il.begin() = 500; }\n>\n> c++17.cpp (compiled with -std=c++17)\n>  \n>  \n>     #include <c++23.hpp> int main () { std::initializer_list<int> kaboom{ 1,\n> 2, 3 }; // stored in const memory initializer_list_stuff(kaboom); //\n> modifies const memory :( }\n>\n> I see the way forward for this paper being that we create a completely new\n> type: std::initializers<T>. std::initializers<T> is non-const and does all\n> the change in this paper. std::initializer_list is left alone entirely.\n>\n> ...\n\nLittle did I know, that that was exactly what David Krauss and Rodrigo Castro\nCampos had already been trying to do in the first place, just they were doing\nit over 10 years ago. I was just walking back that idea, all over again, in\nthe exact same Committee, with almost all the same people who were there when\nKrauss\u2019s and Campos\u2019s ideas got shot down. Except now, it was about ABI! Even\nif I could make a convincing design argument (and I DID, which is why it\nalmost went to the next stage until the ABI concerns were brought up!), it\nwould always die because of ABI, plus whatever reasons prevented us from\nmaking movable_initializer_list<T> in the first place. Every time I talked\nabout these things in the Committee, every time I spoke with C++ experts\ninside of the Committee, it was always \u201cah, well, we just did not know any\nbetter and did not know how to combine the ideas at the time, a shame!\u201d.\nNobody ever admitted \u201coh, we knew, we just were not going to accept it in that\nform. :)\u201d. One of these explanations makes it seem like the Committee is just\na bumbling oaf who needs a little help, of which I was happy to supply. The\nother is far more deliberate and means I should not carefree-offer to champion\nsomeone else\u2019s (small) paper who is about to run headlong into a 16 year old\nintentionally-manufactured problem.\n\nBut then again, it\u2019s not the first time I\u2019ve run headfirst into WG21\u2019s ability\nto memory hole an explicit design decision.\n\nSomething something history, something something repetition!\n\n### std::polymorphic_allocator\n\nBy now, you\u2019ve got the gist of how this is going to go. It\u2019s another ABI\nbreak, but this time it\u2019s actually a little worse than the usual ABI break.\nThe worst part about this is not that somebody proposed something new: oh, no.\nWe just standardized something using the same design that, at the time of\nstandardization, we knew to be a terrible idea for extensibility. Here\u2019s\nstd::memory_resource\u2019s interface, private virtual and public functions:\n\nYou\u2019ll notice it does this funny thing: there\u2019s public member functions on the\nmemory_resource, but they call out to private virtual functions! That\u2019s kind\nof neat. And it allows various different kinds of std::pmr::memory_resource-\nderived types, like std::pmr::new_delete_resource. But... there\u2019s something\nabout this design which feels familiar. Have we seen this before? It was\nstandardized in C++17, but the design felt... old? Aged, in a w\u2014\n\n... Oh. My god.\n\nIt\u2019s std::moneypunct.\n\nstd::memory_resource \u2014 and, consequently, the top-level polymorphic allocator\ndesign \u2014 is based off of the C++98-era locale design! Now, you may be\nwondering why this is terrible. After all, even if locale (and its uses in\n<iostream>) are dated and a bit bad, if the shoe fits for memory_resource it\nworks out, right? Well, one of the BIG reasons we (try) not to put virtual\nfunctions into C++ interfaces anymore (at least not in standard library types\nat least!) is that virtual functions are one of those things that absolutely\nsolidify not just an API, but an ABI.\n\n#### Hard-Wired for Failure\n\nAs a quick primer, virtual functions generally create what\u2019s called a \u201cVirtual\nTable\u201d, or \u201cv-table\u201d for short. All of the virtual functions on a class are\nstored in that v-table. If you have a derived class with new virtual\nfunctions, those get tacked onto the v-table. That virtual table is kept with\neach instance of a (derived) class object, so that it can use some fancy\noffset magic to know how to call the right function when you call a given\nvirtual function. All good, right? Well, here\u2019s the big problem: each entry in\nthe v-table has an incredibly specific offset associated with it. When we\ntried to add new functions to std::moneypunct, and other locale facets\nassociated with famous things like std::money_get/std::get_money, what folks\nrealized is that developers had derived from things like std::moneypunct and\nadded their own virtual functions. That means they tacked new things on to the\nalready-existing v-tables from their C++ Standard Libraries. Those new things\nthey tacked on had an extremely specific offset in bits from the v-table\u2019s\nbase address.\n\nYou see it, right? Where this is going. If we, as a Standards Committee, add\nnew virtual functions to the base object of std::moneypunct or\nstd::memory_resource, we risk taking someone\u2019s derived v-table, and shoving\ntheir offsets down into later entries at later offsets. It\u2019s just how it is:\nthe base table needs to have more stuff in it (say, 6 virtual function\nimplementations instead of 4 virtual function implementations). So the base\ntable gets bigger, and it pushes some downstream developer\u2019s v-table a little\nbit further off. If someone compiles a new header with an older version of the\nstandard library, and the function is called, the entry at the wrong offset\nwill be accessed in the v-table and called, and...\n\nYeah, that was my face too. This is just how it is, because we cannot for the\nlife of us handle ABI breaks. We knew this to be a bad idea at the point it\nwas proposed, too, because by this time we had fully uncovered how\ninextensible and untouchable iostreams existing locale settings as a whole\nwere, especially std::moneypunct. But, more importantly, we also knew that our\nallocator API was incomplete. As far back as 2004, Howard Hinnant wrote\nproposal for both C (N1085) and C++ (N1953). This was followed-on by Ion\nGazta\u00f1aga with another C++ proposal (N2045), then Jonathan Wakely, and a few\nothers in-between these proposals that all indicated that the allocator model\nwe had adopted into the standard library was woefully incomplete for real\nworld work.\n\nBy standardizing virtual functions in std::polymorphic_allocator and\nstd::memory_resource, we effectively cut off those avenues of improvement from\nthe standard. Changing virtual functions is a hard ABI break, and no one has\nsuccessfully added more virtual functions to existing virtual functions once\nwe understood that there were consequential ABI breaks involved. To\nstandardize a known-bad interface and thereby lock out all improvements to\npolymorphic allocators was an avoidable, fundamental, and unfortunately recent\n(C++17!) mistake that we now have to just live with in perpetuity.\n\nAnd when I say in-perpetuity, I mean that in a very visceral and immediate\nsense.\n\n# Haunting the Present\n\nOne of the core problem with ABI is that it very much affects how the\nCommittee works and designs things. It also means that improvements often get\nsidelined or ignored because it can\u2019t be feasibly done without an ABI break.\nSometimes, there are fixes that can be done, but only partially. So, for\nexample, while the standard adds allocate_at_least(size_type n) to the current\nstd::allocator, nothing can be done for std::polymorphic_allocator because of\nthe reasons mentioned. From a proposal that actually has a chance of making it\ninto C++:\n\n> std::pmr::memory_resource is implemented using virtual functions. Adding new\n> methods, such as the proposed allocate API would require taking an ABI\n> break.\n>\n> \u2014 \u201cProviding size feedback in the Allocator interface\u201d, P0401r6\n\nAnd so... well, that\u2019s that. Even if std::polymorphic_allocator is giving\npeople huge gains in code \u2014 not because of the virtual interface, but because\nit comes with a few std:: available implementations for pre-created memory\nregions \u2014 it will never be able to realize any of the gains as we \u2014 finally \u2014\nbegin to add functionality called out by Howard Hinnant 17 years ago in\nproposals to C and C++. Even as allocate_at_least percolates through the\nCommittee, we also miss both in-place expand and shrink functions for\ncontainers which can dynamically grow/shrink memory in-place, without\nreallocation, which is an incredibly useful property for single-memory-blob\nallocators which tend to pull objects from a singular region of memory. And if\nwe ever properly propose expand,shrink, and potentially a reallocate function\nfor our allocator model, std::pmr::memory_resource will continue to miss out\non fixes, changes and optimizations. Which is likely what\u2019s so depressing\nabout me working up the courage to release my own ztd::vector and\nztd::allocator that realizes some of Howard Hinnant\u2019s vision, and what makes\nit doubly depressing to try and write a paper about it:\n\n\u201cYes, we can realize these gains. No, they can\u2019t work with\npolymorphic_allocator. No, I can\u2019t do anything about it unless every\nimplementation decides to break ABI at the same time. What do you mean my eyes\nare glassy and I have a far-off, broken look in them?\u201d\n\nIt\u2019s a demoralizing process, from start to finish, and almost makes a person\nfeel like it\u2019s better to abandon almost everything than stand there and fight\nwith implementers. Of course, it\u2019s not just allocators that get in the way of\nproposals. Even something as low-level as std::thread::attributes ends up\ngetting ABI flack!\n\n## ... Seriously? Attributes for Threads is an ABI Break??\n\nIn a very literal sense, no, no it\u2019s not. You can\u2019t break the ABI of something\nthat does not (yet) exist. For those wondering, a proposal got circulated\naround to fix a common problem spoken about by Bruce Dawson: he wanted to name\nhis threads so that he could keep track of them better, and std::thread didn\u2019t\nlet him do this. Corentin Jabot picked up the idea, and put it in a new paper\ncalled \u201cUsability improvements for std::thread\u201d (P2019). In it, it contains a\nsimple structure:\n\n    \n    \n    class thread::attributes { public: attributes() noexcept = default; attributes(const attributes&); attributes(attributes&& other) = default; attributes& stack_size(std::size_t size) noexcept; attributes& name(std::span<const char> name); attributes& name(std::span<const char8_t> name); implementation-defined __name; // exposition only std::size_t __size; // exposition only };\n\nWouldn\u2019t you know, the first complaints are about ABI. \u201cIf I implement this\nstructure to contain exactly a name and exactly a size, what happens if I need\nto add more things to it later?\u201d. Which is baffling to me, sincerely. YOU are\nthe implementer. You\u2019re the one that sets the tone here. If you expect pthread\nto add some new functionality, or WinThread gets a boost in features, or you\nwant to add implementer-specific functionality to this with a special macro to\n#ifdef on it\u2019s existence, you could easily make room for that. The actual\nmember variables are not even present from the paper\u2019s wording: they\u2019re\nexplicitly \u201cexposition only\u201d. That means you can layout the class however you\nlike, set whatever defaults you like, go nuts. Thread/core affinities and\nother attributes could easily be supported. At no point do you have to sit\ndown and take any guff from anyone, because you \u2014 the implementer \u2014 are in\ncontrol of the implementation!\n\nBut proposal authors are now responsible for maintaining the ABI of every\nsingle implementation out there when they decide to implement things in the\nmost future-incompatible way possible.\n\nEven the people designing Win32, POSIX, and Ethernet protocols had the wisdom\nto say \u201cyou know what? We might need some of these bits some day: let\u2019s mark\ncertain things reserved/unused in their values in the structure so we have\nsome room to work with here\u201d. Even if they never ended up using it, at least\nthey had some kind of plan.\n\nC++ implementers have no plan.\n\nEven when the wording isn\u2019t strict, even if we don\u2019t provide literal by-the-\nletter commandments, implementations are more than content to shoot themselves\nin the foot. Or, worse, they are content to threaten to shoot themselves in\nthe foot and make everybody else pay for it later. The natural consequences of\nthis is that instead of a normal struct with friendly builder syntax, we now\nhave to wait for a paper redesign where we do something silly instead. One of\nthe explored designs the paper author disclosed to me would be something like\nadding std::thread::name_attribute_t, std::thread::stack_size_attribute_t\ntypes, and then you have to pass an instance of the attribute type to the\nthread constructor, plus the actual value. Like some sort of unholy\namalgamation of named arguments:\n\n    \n    \n    #include <thread> #include <iostream> int main () { auto thread_function = []() { std::cout << \"Hello from thread!\" << std::endl; }; std::thread t( std::thread::name_attribute_t{}, \"my thread\", std::thread::stack_size_attribute_t{}, 1'024, thread_function ); t.join(); return 0; }\n\nCorentin Jabot may introduce std::thread::name_attribute as an inline\nconstexpr instance of the std::thread::name_attribute_t type, so that you\ndon\u2019t have to use {} to create an object every time. But this is ultimately\nthe kind of workarounds we have to engage in just to get away from things like\nABI. All because we can\u2019t even do things like add a member variable to a\nstructure without expecting the entire POSIX global table to collapse in on\nitself, or Microsoft to fail with its implementation and not make room for\nother variables in the structure.\n\n## Hey! That\u2019s Unfair to Microsoft\n\nYou might say that. Unfortunately, we have a lot of experience with Microsoft,\nin fact, doing exactly that! You would think that someone who came late to the\nABI game would be a little bit more prepared for what it means to take their\ntime to lock things in so they don\u2019t end up in the same situations as\nlibstdc++ or libc++. But Microsoft did not only fail with ABI, they did it in\na space where they had all of the right tools to make the right decisions.\n\nAnd somehow we still had a bit of a... kerfuffle, anyways.\n\n# A Brief History of fmt\n\nIf you\u2019ve been living under a rock, std::format is the biggest thing since\nsliced bread to come to the Standard Library. Victor Zverovich\u2019s proposal for\nstd::format was based on his wildly popular fmt library. With so much industry\nexperience and implementation experience, it was a clear candidate for a big\nC++ Standard Library feature that checked all the boxes. It also solved a\nlong-standing problem, which was that iostreams was kind of garbage. While\nVictor didn\u2019t solve the I/O part of iostreams, he did solve the formatting and\nprinting bit quite thoroughly and to basically everyone\u2019s satisfaction.\n\nfmt became std::format in C++20. Victor even changed the license of his code\nso standard library vendors could immediately pick up his code and use it, or\nat least just read it. This is quite frankly above and beyond how almost every\nsingle other proposal has gone into C++, with the exception of Boost utilities\n(wherein many standard libraries just hoisted the code right out of Boost).\nThere was, of course, one issue:\n\n## Chrono, and Locale\n\nOne of the things we noticed while preparing std::format for release is that\nmany time spans from std::chrono did not have formatters for them. A last-\nminute paper from Victor, Howard, and Daniela added chrono specifiers to\nstd::format. Victor implemented them, shipped them, and it was a good deal.\nThe only problem is it violated one of fmt\u2019s biggest tenets: no format\nspecifier would be locale-sensitive by default. You had to opt into it, and\nthe chrono formatters were NOT that. Which made for an interesting pie-on-the-\nface moment, because one of the National Body members complained about locale\nbeing used in fmt:\n\n> It\u2019s sad that the C++ SC decided to taint std::format with locale. 10 years\n> ago, I noticed the necessity of char8_t and they didn\u2019t listen, and now they\n> not only think the locale is not considered harmful, but they also think\n> locale helps localization. In reality, it\u2019s quite opposite, the locale\n> actively hinder the localization effort.\n>\n> \u2014 Ezoe Ryou-san, February 15th, 2020\n\nWe, as a Committee, very staunchly pushed back on them:\n\n> std::format does not use locale by default... It uses it only if you\n> explicitly provide one.\n>\n> \u2014 Fabio Fracassi, February 15th, 2020\n\nThis was one of some 4 or 5 comments saying that. And, well, it turns out...\n\nWe were lying. \ud83d\ude05\n\nOops! Now, we didn\u2019t know we were lying, it was very much a surprise when\nCorentin Jabot and several others figured out that the chrono specifiers were\nlocale-sensitive by default:\n\n> In 27.12 [time.format] it is specified:\n>\n\n>> Some of the conversion specifiers depend on the locale that is passed to\nthe formatting function if the latter takes one, or the global locale\notherwise.\n\n>\n> This is not consistent with the format design after the adoption of P1892...\n>\n> \u2014 Corentin Jabot, LWG Issue 3547, April 27th, 2021\n\nP2372 was written to fix it, since it was further revealed that the normal fmt\nlibrary was in fact locale-independent, and that it was a breaking change to\nswap between the way fmt was doing it and the way std::format was going to\nhandle chrono specifiers. But, well, we had standardized the inconsistent\nbehavior in C++20, and...\n\n## \u201cThis is Going to be an ABI Break\u201d\n\nWelcome to Hell, population us. You might wonder how a paper being worked on\nbarely a year after the release of C++20 can end up being an ABI break. This\nis where Microsoft and VC++ comes into play. See, Microsoft had very recently\nbeen guaranteeing ABI stability in their platform deployments. In years gone\nby, Microsoft would break ABI with every release and ship a new DLL. It was\nyour responsibility to sync things if it truly mattered: this let them fix a\nLOT of bugs in their implementation, at the risk of needing people to either\nrecompile or at least check things worked with an updated runtime. (Or to just\nkeep shipping the old VC++ DLLs. Remember all those VC Redistributable\nDownloaders for v2011 and v2012 and v2013 and v2015, anyone?). These days,\nhowever, they started locking things down in their ABIs pretty much\nimmediately. This is why a lot of bugs suddenly became no-fix, or were pushed\nback to a mythical and magical \u201cwhen we break ABI\u201d timeline. See, one of the\nthings Microsoft wanted to do was have std::format. And not only did they want\nto ship a version 0 of their own std::format,\n\nthey wanted to mark it ABI stable right off the bat.\n\n### Hubris?\n\nDear reader, let me tell you that even if you are a multibillion dollar\ncorporation, being so brave as to tell the world you\u2019re going to ship a brand\nnew API and on Day 0 mark it as \u201cstable, forever\u201d is the kind of stuff you\u2019d\nhear amongst developers after they all ate the specially-baked cookies &\nbrownies, and the hookahs came out.\n\nOf COURSE we don\u2019t lock in our version 0 implementations, especially not for a\nsits-beneath-all-libraries library whose sole constraint is \u201cstability, for\nthe rest of your f[CENSOR]ing existence\u201d! But Microsoft tried it. Oh, they\ntried it. When P2372 came out, everyone was freaked out because Microsoft\nstarted posturing that they were going to ship std::format, their first\niteration of its implementation, to the whole world and mark it ABI stable\nwhile following the C++20 wording to the letter. That meant they were going to\nactively enshrine the design mistake from the std::chrono formatters: locale\nwould be used by default, Ezoe-san would be completely within his rights to\nderide std::format, and we would be permanently made liars in the face of the\nentire C++ community while breaking Victor\u2019s own fmt library in behavior.\n\nThe amount of effort that went to save Microsoft from this decision was\nstaggering. We:\n\n  * Constantly applied pressure to Microsoft to tell them NOT TO DO THIS, YE GOD!!;\n  * Victor quickly applied fixes to std::format\u2019s implementation ([1] [2] [3]) in VC++ himself;\n  * I pointed out that I had an open report that would solve their issues of (compile-time) encoding conversions opened almost a year before they got into the mess with \u201chow do we translate our const char* string literals\u201d;\n  * Corentin, Victor, and several others went to bat over it inside and outside Committee channels.\n\nUltimately, we won the concession. When the new version of C++ released for\nMicrosoft, their release notes contained this bit:\n\n> ... you need to be compiling with /std:c++latest ...\n>\n> \u2014 Charlie Barto, <format> in Visual Studio 2019 v16.10 Release Notes\n\nThis is a very small bit of wording, but important: Microsoft keeps things\nthat are unstable out of its well-defined standards switches (such as\n/std:c++20). By only having it in the /std:c++latest switch, it meant they\neffectively agreed not to stabilize <format>\u2019s ABI forever.\n\nThank God; crisis averted! ... But yet, this left is a horrible taste in my\nmouth.\n\n# The Spooky Terror Behind the Actions\n\nThe ugly truth here is that we had to effectively convince a vendor not to do\nthe worst possible implementation and shoot themselves in their own foot.\nWhich is really quite remarkable! It\u2019s one thing when, say, IBM or Intel shows\nup and says \u201cwe have a private implementation of X, we\u2019d like to put it in the\nstandard library\u201d. It\u2019s understandable if people mess that up, because they\nonly hand us the interface and not the implementation. But this was a case\nwhere:\n\n  * Victor had published his library and had the correct behaviors in for years;\n  * Victor changed the license so vendors could not only look, but blindly copy-paste if they wanted to; and,\n  * Victor published several blog posts describing the implementation details and tradeoffs to be made.\n\nAt no point should anyone be stabilizing their implementation until they could\nprove it was at or better than Victor Zverovich\u2019s fmt lib. And yet, that\u2019s not\nwhat happened. Which begs the question: why did Victor spend all that time\nworking so hard on the proposal, its fixes, and its percolation through the\nC++ Committee? If you work that hard and make it across the finish line and\nget it into the C++ Standard, only to have implementations both ignore your\npublicly available implementation and threaten to ABI stabilize the worst\npossible one so that the rest of the ecosystem suffers indefinitely, what is\nthe point of standardizing a library feature in C++? Victor did everything\nright and completed the bonus material with flying colors. If Victor is one of\nthe greats, up there with Eric Niebler and Stepanov in their capacity to save\nC++ with their work,\n\nhow should everyone else feel about approaching the C++ standardization\nprocess?\n\nI must note that the really terrible part is that Committee members were\nwilling to block things like no-locale-by-default fixes for ABI reasons. This\nalso does not make any sense whatsoever: MSVC has been talking about how it\nhas an ABI-breaking release coming \u201cSoon\u201d, and that they will deploy it when\nthey\u2019re good and ready. If you know you have an ABI-breaking release of your\nlibrary coming soon, that means that ABI breaking changes aren\u2019t even as bad\nas Microsoft could claim, because Microsoft actually has a version coming\nwhere they can fix their mistakes. libstdc++ does not have a planned ABI\nbreak: their policy is ABI stability, for the rest of their lives. I can see\nwhy RedHat or similar implementations would lodge an ABI objection. But, for a\nvendor with a planned ABI break to object to an ABI breaking change? That\nmeans that they condemn their future release to be worse, because they act\nagainst the very standardization of the improvements their own next-generation\nrelease would make use of.\n\nThe absurdity is only eclipsed by how profoundly harmful this behavior is to\nthe whole of the C++ ecosystem.\n\n# Implementation Override\n\nI am terrified, dear reader.\n\nWe already have people who are finding inefficiencies in the allocator models,\nexception handling, object model, calling conventions, storage sizes for\nclasses, and ultimately the library implementations of C++. They\u2019re regularly\nexploiting that in their languages for better performance and, on occasion,\noutstripping both their C and C++ counterparts in performance and correctness\nwith readable code.\n\nIf implementations can do their worst to people\u2019s hard work when it finally\ncomes time to standardize it all, what was the point then? We have a\nNetworking TS where people want to put it into the C++ Standard Library. What\nhappens if libc++ phones their implementation in and does something bad? What\nhappens if there\u2019s a crippling security issue and it\u2019s time to patch your\nstandard library? What if we need to fix a longstanding design issue? Every\nimplementer has effectively total veto power in what\u2019s supposed to be a\nrepublic-ish system of representation, or at the very least can strongly\nthreaten to wreck you and your work because they don\u2019t feel like dealing with\ndoing things in a mildly not self-sabotaging way.\n\nDo you understand, the chains every proposal author is now bound by? The\ncontract we all sign with our blood, sweat, tears, and \u2014 penultimately \u2014 our\ntime? This is not even just one instance. Microsoft patently refused to honor\nthe standard [[no_unique_address]], citing ABI concerns. Despite the fact that\nit was (1) a new feature and the standard had not rolled out yet at the time\nof their implementation, and (2) is an explicit request from the user. By\nwillingly ignoring that attribute, they compromise everyone\u2019s expected\nsemantics and reduced what was one of the most important object-size-reduction\ntechniques from an implementation reality to, once more, being just a shoddy\nsuggestion. What\u2019s worse is that they did not even implement full support for\ntheir own implementation-specific no_unique_address, which they spell\n[[msvc::no_unique_address]]:\n\n    \n    \n    #if __has_cpp_attribute(no_unique_address) #define NO_UNIQUE_ADDRESS no_unique_address #else #if defined(_MSC_VER) #if !__has_cpp_attribute(msvc::no_unique_address) #error \"MSVC does not have no_unique_address\" #else #define NO_UNIQUE_ADDRESS msvc::no_unique_address #endif #endif #endif int main(int, char*[]) { return 0; }\n\nThis code errors with \u201cMSVC does not have no_unique_address\u201d on the latest\nrelease build of MSVC as of September 23rd, 2021. The one sole feature we have\nto test that MSVC \u2014 or any other implementation \u2014 does in fact have\nmsvc::no_unique_address (or any other attribute) is busted. That means I need\nto go back to relying on ancient techniques such as #if defined(_MSC_VER) &&\n_MSC_FULL_VER > 192930133 rather than just regular, standard techniques for\nchecking for attributes. This, from an implementation that wants to attempt to\nstandardize a known-poor implementation of <format> and then ship it to\ncustomers with an entirely straight face, while then turning around to\nchallenge the Standards Committee on ABI concerns and summon up that Three\nLetter Demon.\n\nIs this sustainable? Is this tractable, when every implementer can fuse\nthemselves together to beat the crap out of a proposal even if it fits the\ndesign criteria and preserves the API space? Are we just supposed to live in\nperpetual fear that one day someone made an Oopsie Kapoopsie in their\nstd::lock_guard implementation, and that there\u2019s no way to fix it from now\nuntil the end of days? That even if we can do better on our own platforms,\nbecause the Big Three don\u2019t want to be declared non-conforming, they can just\ncontinue to throw their weight around and complicate every proposal\u2019s\nlifespan? That every proposal author must tremble in fear of those three\nletters? That we have to shake in our boots because our implementers can\u2019t\nhandle versioning a struct that they have reason to suspect might change for\ntheir implementation??\n\nI am about to author one gigantic proposal for putting text in the Standard\nLibrary. I have authored no less than five videos describing the design,\nperformance, tradeoff, and motivation. I have a boatload of documentation.\n\nWhat happens when Microsoft decides that the worst possible implementation is\nwhat they should rush into their binaries and then declare it ABI-stable? What\nhappens if there\u2019s additional improvements that come beyond the initial\nproposal (of which there is a big chance, because this is for a fundamentally\nhuman aspect of programming, text!)? What happens if libc++ decides today is a\ngood day to phone it in with respect to performance and then vendors\nstandardize on their v0 implementation...? What if they decide to not read any\nof my documentation, as they had not read Victor\u2019s documentation? What if they\ndecide to ignore my videos, my lengthy design and performance explanations? Is\nwhat Victor went through what I\u2019m supposed to look forward to, as someone who\nwants to contribute a large body of important work to C++?\n\n# No.\n\nI refuse.\n\nYou cannot make me pay my blood for a contract with this insidious, ever-\npervasive amalgamation, I was not even alive to bear witness to. I will not\nsit in every meeting and be endlessly bullied by implementations that do not\nknow how to handle a problem they are the sole controller and proprietor for.\nIt\u2019s absolutely inane that even the most mundane of proposals can suddenly be\nran through like a train wreck because the pinnacle of C++ and C experts\ncannot answer the question \u201chow do I version something\u201d. I will have a good\nstandard library. It will meet my performance requirements. It will be\ncorrect. I do not care how many ghosts of the past there are. I do not care\nhow many implementations exist where a person programming for longer than I\nhave been alive made a sub-optimal choice one day and now we just have to live\nwith that, for the rest of eternity. I will not be made to suffer someone\nelse\u2019s mistakes in perpetuity, while they also continue to make the same\nmistakes in egregiously flagrant fashions now and into the future.\n\nI shouldn\u2019t even be held back by my own mistakes from yesterday, what kind of\nworld do we live in where we settle on a process so fundamentally against the\nhuman condition of learning and growing as an individual? Why would we\nprioritize a working process that at its deepest roots is so fundamentally\nagainst the living human being, and happier to dwell with the dead?\n\nThe binary banshees and digital demons of ABI will not overtake us. It will\nnot trample over me, over my implementation. I will not be bound by the\nmistakes of people who know not my name, nor the names of the people whose\nlife I aim to make better. The standard is for me too, not just Microsoft. Not\njust IBM. Not just Apple. I will not let ABI hold us perpetually at\nimplementation gunpoint. One way.\n\nOr another. \ud83d\udc9a\n\nP.S.: This ENTIRE article was because Luna Sorcery made a fun joke. kismet\nbrought the whole thing to life with their amazing artist skills: you should\ngo commission art from them, by the bucket load if you can!\n\n  * Share\n  * Share on Facebook\n  * Tweet\n  * Share on Tumblr\n  * Share on Reddit\n  * Share on LinkedIn\n  * Email\n\n  * Tags\n  * ABI\n\n  * C\n\n  * C++\n\n  * Help\n\n  * Me\n\n  * Standard\n\nPrevious post\n\nviews::split: The Final Frontier\n\nNext post\n\nC-ing the Improvement: Progress on C23\n\nCopyright \u00a9 2018-2022 ThePhD -- Powered by Jekyll with Type on Strap!\n\n", "frontpage": false}
