{"aid": "40162390", "title": "Learning from the brain to make AI more energy-efficient", "url": "https://www.humanbrainproject.eu/en/follow-hbp/news/2023/09/04/learning-brain-make-ai-more-energy-efficient/", "domain": "humanbrainproject.eu", "votes": 2, "user": "ibobev", "posted_at": "2024-04-25 20:10:58", "comments": 0, "source_title": "Learning from the brain to make AI more energy-efficient", "source_text": "Learning from the brain to make AI more energy-efficient\n\n  * Feature\n\n## Learning from the brain to make AI more energy-efficient\n\n04 September 2023\n\nEnergy consumption is one of the main problems facing modern computing. The\nHuman Brain Project has tackled the efficiency issue \u2013 potentially changing\nhow computers will be thought of and designed in the future.\n\nAs much as computing has progressed, a biological brain still vastly\noutperforms the fastest calculators in many ways, and with a fraction of the\nenergy consumption. While the demand for computing power is steadily\nincreasing, classical computers can only do so much to become more energy-\nefficient, due to the inherent principles of their design.\n\nIn contrast to power-hungry computers, brains have evolved to be energy-\nefficient. It is estimated that a human brain uses roughly 20 Watts to work \u2013\nthat is equivalent to the energy consumption of your computer monitor alone,\nin sleep mode. On this shoe-string budget, 80\u2013100 billion neurons are capable\nof performing trillions of operations that would require the power of a small\nhydroelectric plant if they were done artificially.\n\n##### Progress in neuromorphic technologies\n\nNeuromorphic technologies transfer insights about the brain to optimise AI,\ndeep learning, robotics and automation. Computing systems using this approach\nhave become increasingly refined and are in development worldwide. Like the\nbrain itself, neuromorphic computers hold the promise of processing\ninformation with high energy efficiency, fault tolerance and flexible learning\nability.\n\nIn the Human Brain Project, teams of engineers and theoretical neuroscientists\nare focused on the engineering and development of neuromorphic devices, which\nuse spiking artificial neurons to train neural networks to perform\ncalculations, and generally take inspiration from the way human brains\nfunction. They have built Europe\u2019s most powerful neuromorphic systems,\nBrainScaleS and SpiNNaker, which are both part of the HBP\u2019s open research\ninfrastructure EBRAINS.\n\nThe first system, BrainScaleS, is an experimental hardware that emulates the\nbehaviour of neurons using analog electrical circuits, omitting energy-hungry\ndigital calculations. It relies on individual events, called \u201cspikes\u201d, instead\nof a stream of continuous values used in most computer simulations. Neurons\nsending such electrical impulses sparsely to each other is a basic way of\nefficient signaling in the brain. Mimicking the way neurons calculate and\ntransmit information between each other allows the BrainScaleS chips, now\nalready in their second iteration, to perform very fast calculations while\nalso reducing data redundancy and energy consumption. The large-scale\nBrainScaleS system is based at Heidelberg University.\n\nClose-up view of a BrainScaleS-2 chip\n\nThe second system, SpiNNaker, is a massively parallel digital computer\ndesigned to support large scale models of brain regions in biological real\ntime. The SpiNNaker neuromorphic computer is based at the University of\nManchester. It runs spiking neural network algorithms through its 1,000,000\nprocessing cores that mimic the way the brain encodes information and can be\naccessed as a testing station for new brain-derived AI algorithms (Furber &\nBogdan 2022). At the same time, SpiNNaker has shown promise for developing\nsmall low-energy chips that can be used for robots and edge devices. In 2018,\nthe German state of Saxony pledged support of 8 million Euro for the next\ngeneration of SpiNNaker, SpiNNaker2, which has been developed in a\ncollaboration between the University of Manchester and TU Dresden within the\nHBP. SpiNNaker2 chips have since then gone into large-scale production with\nchip manufacturer GlobalFoundries.\n\nA SpiNNaker2 computer system with 70,000 chips and 10 Million processing cores\nwill be based at TU Dresden (also see p. 55). SpiNNaker2 has been chosen as\none of the pilot projects of Germany\u2019s Federal Agency for Disruptive\nInnovation, SPRIN-D. A first company for commercialisation, SpiNNcloud\nSystems, has been founded by the Dresden team.\n\nSpiNNaker2 circuit board\n\nWith the hardware advancing, software is learning from the brain as well. By\nnow, theoretical neuroscientists in the HBP have become highly proficient in\ndeveloping algorithms that resemble brain mechanisms to a far larger extent\nthan current AI.\n\nBrain research and AI have always shared connections. The earliest versions of\nartificial neural networks in the 1950s were already based on rudimentary\nknowledge about our nerve cells. Today, these AI systems have become\nubiquitous, but they still run into limitations: their training is extremely\nenergy-hungry, and what they learn can break down in unexpected ways.\n\nUsing new insights into biological brain networks, software modelers in the\nHBP have developed the next generation of brain-derived algorithms. These\nbrain algorithms with higher biological realism have recently proven in\npractice to massively bring down energy demand, especially when run on a\nneuromorphic system.\n\nAfter a series of high-level breakthroughs by several HBP teams (Cramer et al.\n2022, G\u00f6ltz et al. 2021, Bellec et al. 2020), in 2022, a collaboration of HBP\nresearchers at TU Graz together with Intel tested the power of algorithms to\nbring down energy demand using Intel\u2019s Loihi Chip (also see p. 56). The\nresults were an up to 16-fold decrease in energy demand compared to non-\nneuromorphic hardware (Rao et al. 2022).\n\n##### A positive feedback loop\n\nImportantly for the HBP and neuroscience in general, more powerful and\nefficient computing also accelerates brain research, generating a positive\nfeedback loop between highly neuro-inspired computers and detailed brain\nsimulations. In this way, mechanisms that have evolved in biological brains to\nmake them adaptable and capable of learning can be mimicked in a neuromorphic\ncomputer so that they can be studied and better understood. This is what a\nteam of HBP researchers at the University of Bern have achieved with so-called\n\u201cevolutionary algorithms\u201d (Jordan et al. 2021). The programmes they have\ndeveloped search for solutions to given problems by mimicking the process of\nbiological evolution through natural selection, promoting the ones most able\nto adapt. Traditional programming is a top-down affair; evolutionary\nalgorithms, instead, arise from the process on their own. This could provide\nus with further insights into biological learning principles, improve research\ninto synaptic plasticity and accelerate progress towards powerful artificial\nlearning machines.\n\nIn the last few years, impressive neuromorphic breakthroughs have made\ntangible what was previously only theorised regarding the advantages of the\ntechnology. As the limitations of traditional AI and classical computers\nbecome more and more obvious, learning from the brain has emerged as one of\nthe most powerful approaches for moving ahead.\n\nThis text was first published in the booklet \u2018Human Brain Project \u2013 A closer\nlook at scientific advances\u2019, which includes feature articles, interviews with\nleading researchers and spotlights on latest research and innovation. Read the\nfull booklet here.\n\nReferences\n\nBellec G, Scherr F, Subramoney A, Hajek E, Salaj D, Legenstein R, Maass W\n(2020). A solution to the learning dilemma for recurrent networks of spiking\nneurons. Nat. Commun. 11(1):3625. doi: 10.1038/s41467-020-17236-y\n\nCramer B, Billaudelle S, Kanya S, Leibfried A, Gr\u00fcbl A, Karasenko V, Pehle C,\nSchreiber K, Stradmann Y, Weis J, Schemmel J, Zenke F (2022). Surrogate\ngradients for analog neuromorphic computing. Proc. Natl. Acad. Sci. U. S. A.\n119(4):e2109194119. doi: 10.1073/pnas.2109194119\n\nFurber S, Bogdan P (eds.) (2020). SpiNNaker: A Spiking Neural Network\nArchitecture. Boston-Delft: now publishers. doi: 10.1561/9781680836523\n\nG\u00f6ltz J, Kriener L, Baumbach A, Billaudelle S, Breitwieser O, Cramer B, Dold\nD, Kungl AF, Senn W, Schemmel J, Meier K, Petrovici MA (2021). Fast and\nenergy-efficient neuromorphic deep learning with first-spike times. Nat. Mach.\nIntell. 3:823-835. doi: 10.1038/s42256-021-00388-x\n\nJordan J, Schmidt M, Senn W, Petrovici MA (2021). Evolving interpretable\nplasticity for spiking networks. eLife 10:e66273. doi: 10.7554/eLife.66273\n\nRao A, Plank P, Wild A, Maass W (2022). A Long Short-Term Memory for AI\nApplications in Spike-based Neuromorphic Hardware. Nat. Mach. Intell.\n4:467\u2013479. doi: 10.1038/s42256-022-00480-w\n\nCopyright \u00a9 2017-2023 humanbrainproject.eu and respective authors. All rights\nreserved.\n\n### Your browser is out-of-date!\n\nUpdate your browser to view this website correctly.\n\nUpdate my browser now\n\n\u00d7\n\n", "frontpage": false}
