{"aid": "40246785", "title": "Compressing LLMs: The Truth Is Rarely Pure and Never Simple", "url": "https://machinelearning.apple.com/research/compressing-llms", "domain": "machinelearning.apple.com", "votes": 2, "user": "zerojames", "posted_at": "2024-05-03 12:14:07", "comments": 0, "source_title": "Compressing LLMs: The Truth is Rarely Pure and Never Simple", "source_text": "Compressing LLMs: The Truth is Rarely Pure and Never Simple - Apple Machine\nLearning Research\n\nresearch areaSpeech and Natural Language Processing | conference ICLR\n\ncontent type paper | published May 2024\n\n# Compressing LLMs: The Truth is Rarely Pure and Never Simple\n\nAuthorsAjay Jaiswal, Zhe Gan, Xianzhi Du, Bowen Zhang, Zhangyang Wang, Yinfei\nYang\n\nView publication\n\nDespite their remarkable achievements, modern Large Language Models (LLMs)\nencounter exorbitant computational and memory footprints. Recently, several\nworks have shown significant success in training-free and data-free\ncompression (pruning and quantization) of LLMs achieving 50-60% sparsity and\nreducing the bit-width down to 3 or 4 bits per weight, with negligible\nperplexity degradation over the uncompressed baseline. As recent research\nefforts are focused on developing increasingly sophisticated compression\nmethods, our work takes a step back, and re-evaluates the effectiveness of\nexisting SoTA compression methods, which rely on a fairly simple and widely\nquestioned metric, perplexity (even for dense LLMs). We introduce Knowledge-\nIntensive Compressed LLM BenchmarK (LLM-KICK), a collection of carefully-\ncurated tasks to re-define the evaluation protocol for compressed LLMs, which\nhave significant alignment with their dense counterparts, and perplexity fail\nto capture subtle change in their true capabilities. LLM-KICK unveils many\nfavorable merits and unfortunate plights of current SoTA compression methods:\nall pruning methods suffer significant performance degradation, sometimes at\ntrivial sparsity ratios (e.g., 25-30%), and fail for N:M sparsity on\nknowledge-intensive tasks; current quantization methods are more successful\nthan pruning; yet, pruned LLMs even at 50% sparsity are robust in-context\nretrieval and summarization systems; among others. LLM-KICK is designed to\nholistically access compressed LLMs' ability for language understanding,\nreasoning, generation, in-context retrieval, in-context summarization, etc. We\nhope our study can foster the development of better LLM compression methods.\n\nFigure 1: True Merits of SoTA Compression. Top row indicates marginal increase\nin perplexity via using SoTA compression methods, when compared with simple\nmagnitude-based pruning. Bottom row indicates the failure of compressed\nVicuna-7B (via Magnitude, Wanda, SparseGPT, GPTQ) to respond correctly to\nknowledge-intensive factoid-based questions.\n\n## Related readings and updates.\n\n### Leveraging Large Language Models for Exploiting ASR Uncertainty\n\nWith the help of creative prompt engineering and in-context learning, large\nlanguage models (LLMs) are known to generalize well on a variety of text-based\nnatural language processing (NLP) tasks. However, for performing well on\nspoken language understanding (SLU) tasks, LLMs either need to be equipped\nwith in-built speech modality or they need to rely on speech-to-text\nconversion from an off-the-shelf automation speech recognition (ASR) system...\n\nSee paper details\n\n### Gender Bias in LLMs\n\nLarge Language Models (LLMs) have made substantial progress in the past\nseveral months, shattering state-of-the-art benchmarks in many domains. This\npaper investigates LLMs' behavior with respect to gender stereotypes, a known\nstumbling block for prior models. We propose a simple paradigm to test the\npresence of gender bias, building on but differing from WinoBias, a commonly\nused gender bias dataset which is likely to be included in the training...\n\nSee paper details\n\n## Discover opportunities in Machine Learning.\n\nOur research in machine learning breaks new ground every day.\n\nWork with us\n\nPrivacy Policy Terms of Use Legal\n\nCopyright \u00a9 2024 Apple Inc. All rights reserved.\n\n", "frontpage": false}
