{"aid": "40130399", "title": "Show HN: Streaming DataFrames\u2013a Pandas-like syntax for real-time data", "url": "https://github.com/quixio/quix-streams", "domain": "github.com/quixio", "votes": 5, "user": "cha0sengine", "posted_at": "2024-04-23 10:47:58", "comments": 0, "source_title": "GitHub - quixio/quix-streams: Quix Streams - A library for data streaming and Python Stream Processing", "source_text": "GitHub - quixio/quix-streams: Quix Streams - A library for data streaming and\nPython Stream Processing\n\n## Navigation Menu\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nquixio / quix-streams Public\n\n  * Notifications\n  * Fork 25\n  * Star 543\n\nQuix Streams - A library for data streaming and Python Stream Processing\n\n### License\n\nApache-2.0 license\n\n543 stars 25 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# quixio/quix-streams\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n64 Branches\n\n24 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\ntim-quixChore/quix topic create error (#337)Apr 22, 20248277c88 \u00b7 Apr 22,\n2024Apr 22, 2024\n\n## History\n\n262 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| Remove old SDK code (#243)| Nov 15, 2023  \n  \n### LICENSES\n\n|\n\n### LICENSES\n\n| Remove old SDK code (#243)| Nov 15, 2023  \n  \n### docs\n\n|\n\n### docs\n\n| [add] - quix streams install (#331)| Apr 9, 2024  \n  \n### examples\n\n|\n\n### examples\n\n| Do not override state input on each update (#310)| Mar 8, 2024  \n  \n### images\n\n|\n\n### images\n\n| update banner (#262)| Jan 9, 2024  \n  \n### quixstreams\n\n|\n\n### quixstreams\n\n| Chore/quix topic create error (#337)| Apr 22, 2024  \n  \n### tests\n\n|\n\n### tests\n\n| Chore/quix topic create error (#337)| Apr 22, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Chore/type fixing (#292)| Feb 27, 2024  \n  \n### .pre-commit-config.yaml\n\n|\n\n### .pre-commit-config.yaml\n\n| Update black formatter version (#316)| Apr 2, 2024  \n  \n### CODE_OF_CONDUCT.md\n\n|\n\n### CODE_OF_CONDUCT.md\n\n| Sentence casing titles and American spellings (#37)| Feb 13, 2023  \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n| Implement better handling for all broker down error (#264)| Jan 11, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| First version of Readme| Nov 22, 2022  \n  \n### README.md\n\n|\n\n### README.md\n\n| Update README (#332)| Apr 9, 2024  \n  \n### mkdocs.yml\n\n|\n\n### mkdocs.yml\n\n| New docs (#315)| Apr 3, 2024  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| Remove old SDK code (#243)| Nov 15, 2023  \n  \n### requirements-dev.txt\n\n|\n\n### requirements-dev.txt\n\n| Update black formatter version (#316)| Apr 2, 2024  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| Update confluent_kafka version (#244)| Nov 15, 2023  \n  \n### setup.cfg\n\n|\n\n### setup.cfg\n\n| Remove old SDK code (#243)| Nov 15, 2023  \n  \n### setup.py\n\n|\n\n### setup.py\n\n| Remove old SDK code (#243)| Nov 15, 2023  \n  \n## Repository files navigation\n\n# Quix Streams\n\nQuix Streams is a cloud native library for processing data in Kafka using pure\nPython. It\u2019s designed to give you the power of a distributed system in a\nlightweight library by combining the low-level scalability and resiliency\nfeatures of Kafka with an easy to use Python interface (to ease newcomers to\nstream processing).\n\nQuix Streams has the following benefits:\n\n  * Pure Python (no JVM, no wrappers, no cross-language debugging).\n  * No orchestrator, no server-side engine.\n  * Streaming DataFrame API (similar to pandas DataFrame) for tabular data transformations.\n  * Easily integrates with the entire Python ecosystem (pandas, scikit-learn, TensorFlow, PyTorch etc).\n  * Support for many serialization formats, including JSON (and Quix-specific).\n  * Support for stateful operations using RocksDB.\n  * Support for aggregations over tumbling and hopping time windows.\n  * \"At-least-once\" Kafka processing guarantees.\n  * Designed to run and scale resiliently via container orchestration (like Kubernetes).\n  * Easily runs locally and in Jupyter Notebook for convenient development and debugging.\n  * Seamless integration with the fully managed Quix Cloud platform.\n\nUse Quix Streams to build event-driven, machine learning/AI or physics-based\napplications that depend on real-time data from Kafka.\n\n## Getting started \ud83c\udfc4\n\n### Install Quix Streams\n\n    \n    \n    python -m pip install quixstreams\n\n#### Requirements\n\nPython 3.8+, Apache Kafka 0.10+\n\nSee requirements.txt for the full list of requirements\n\n## Documentation\n\nQuix Streams Docs\n\n### Example Application\n\nHere's an example of how to process data from a Kafka Topic with Quix Streams:\n\n    \n    \n    from quixstreams import Application, State # Define an application app = Application( broker_address=\"localhost:9092\", # Kafka broker address consumer_group=\"consumer-group-name\", # Kafka consumer group ) # Define the input and output topics. By default, \"json\" serialization will be used input_topic = app.topic(\"my_input_topic\") output_topic = app.topic(\"my_output_topic\") def count(data: dict, state: State): # Get a value from state for the current Kafka message key total = state.get('total', default=0) total += 1 # Set a value back to the state state.set('total', total) # Update your message data with a value from the state data['total'] = total # Create a StreamingDataFrame instance # StreamingDataFrame is a primary interface to define the message processing pipeline sdf = app.dataframe(topic=input_topic) # Print the incoming messages sdf = sdf.update(lambda value: print('Received a message:', value)) # Select fields from incoming messages sdf = sdf[[\"field_1\", \"field_2\", \"field_3\"]] # Filter only messages with \"field_0\" > 10 and \"field_2\" != \"test\" sdf = sdf[(sdf[\"field_1\"] > 10) & (sdf[\"field_2\"] != \"test\")] # Filter messages using custom functions sdf = sdf[sdf.apply(lambda value: 0 < (value['field_1'] + value['field_3']) < 1000)] # Generate a new value based on the current one sdf = sdf.apply(lambda value: {**value, 'new_field': 'new_value'}) # Update a value based on the entire message content sdf['field_4'] = sdf.apply(lambda value: value['field_1'] + value['field_3']) # Use a stateful function to persist data to the state store and update the value in place sdf = sdf.update(count, stateful=True) # Print the result before producing it sdf = sdf.update(lambda value, ctx: print('Producing a message:', value)) # Produce the result to the output topic sdf = sdf.to_topic(output_topic) if __name__ == \"__main__\": # Run the streaming application app.run(sdf)\n\n### How It Works\n\nThere are two primary components:\n\n  * StreamingDataFrame - a predefined declarative pipeline to process and transform incoming messages.\n  * Application - to manage the Kafka-related setup & teardown and message lifecycle (consuming, committing). It processes each message with the dataframe you provide it.\n\nUnder the hood, the Application will:\n\n  * Consume a message.\n  * Deserialize it.\n  * Process it with your StreamingDataFrame.\n  * Produce it to the output topic.\n  * Automatically commit the topic offset and state updates after the message is processed.\n  * React to Kafka rebalancing updates and manage the topic partitions.\n  * Manage the State store.\n  * Handle OS signals and gracefully exit the application.\n\n### Tutorials\n\nTo see Quix Streams in action, check out the Quickstart and Tutorials in the\ndocs:\n\n  * Quickstart\n  * Tutorial - Word Count\n  * Tutorial - Anomaly Detection\n  * Tutorial - Purchase Filtering\n\n### Using the Quix Cloud\n\nThis library doesn't have any dependency on any commercial products, but if\nyou use it together with Quix Cloud you will get some advantages out of the\nbox during your development process such as:\n\n  * Auto-configuration.\n  * Monitoring.\n  * Data explorer.\n  * Data persistence.\n  * Pipeline visualization.\n  * Metrics.\n\nand more.\n\nQuix Streams provides a seamless integration with Quix Cloud, and it can\nautomatically configure the Application using Quix SDK Token.\n\nPlease see the Connecting to Quix Cloud page to learn how to use Quix Streams\nand Quix Cloud together.\n\n### What's Next\n\nThis library is being actively developed.\n\nHere are some of the planned improvements:\n\n  * Windowed aggregations over Tumbling & Hopping windows\n  * State recovery based on Kafka changelog topics\n  * Windowed aggregations over Sliding windows\n  * Group-bys and joins (for merging topics/keys)\n  * Support for \"exactly-once\" Kafka processing (aka transactions)\n  * Support for Avro and Protobuf formats\n  * Schema Registry support\n\nTo find out when the next version is ready, make sure you watch this repo and\njoin our Quix Community on Slack!\n\n## Contribution Guide\n\nContributing is a great way to learn and we especially welcome those who\nhaven't contributed to an OSS project before. We're very open to any feedback\nor code contributions to this OSS project \u2764\ufe0f.\n\nBefore contributing, please read our Contributing file for how you can best\ngive feedback and contribute.\n\n## Need help?\n\nIf you run into any problems, please create an issue or ask in #quix-help in\nour Quix Community on Slack.\n\n## Community \ud83d\udc6d\n\nJoin other software engineers in The Stream, an online community of people\ninterested in all things data streaming. This is a space to both listen to and\nshare learnings.\n\n\ud83d\ude4c Join our Slack community!\n\n## License\n\nQuix Streams is licensed under the Apache 2.0 license. View a copy of the\nLicense file here.\n\n## Stay in touch \ud83d\udc4b\n\nYou can follow us on Twitter and Linkedin where we share our latest tutorials,\nforthcoming community events and the occasional meme.\n\nIf you have any questions or feedback - write to us at support@quix.io!\n\n## About\n\nQuix Streams - A library for data streaming and Python Stream Processing\n\n### Topics\n\npython kafka stream-processing apache-kafka\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\n### Code of conduct\n\nCode of conduct\n\nActivity\n\nCustom properties\n\n### Stars\n\n543 stars\n\n### Watchers\n\n11 watching\n\n### Forks\n\n25 forks\n\nReport repository\n\n## Releases 22\n\nv2.4.1 Latest\n\nApr 4, 2024\n\n\\+ 21 releases\n\n## Packages 0\n\nNo packages published\n\n## Contributors 16\n\n\\+ 2 contributors\n\n## Languages\n\n  * Python 100.0%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
