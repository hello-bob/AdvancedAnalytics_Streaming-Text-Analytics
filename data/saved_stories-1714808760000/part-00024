{"aid": "40253586", "title": "Simple Postgres to ClickHouse replication featuring MinIO", "url": "https://blog.peerdb.io/simple-postgres-to-clickhouse-replication-featuring-minio", "domain": "peerdb.io", "votes": 1, "user": "simonpure", "posted_at": "2024-05-03 23:52:11", "comments": 0, "source_title": "Simple Postgres to ClickHouse replication featuring MinIO", "source_text": "Simple Postgres to ClickHouse replication featuring MinIO\n\n# Simple Postgres to ClickHouse replication featuring MinIO\n\nSai Srirampur\n\n\u00b7May 2, 2024\n\nAt PeerDB, we provide a fast and cost-effective way to replicate data from\nPostgres to Data Warehouses such as Snowflake, BigQuery, ClickHouse, and\nqueues like Kafka, Red Panda and Google PubSub, among others.\n\nA few months ago, we added a ClickHouse connector for Postgres Change Data\nCapture (CDC). Surprisingly, this connector gained substantial traction and\nadoption within our community. This applies to both our fully managed service\n(PeerDB Cloud) and our Open Source offerings. Here is a customer story from\none of our customers who uses the ClickHouse connector.\n\n## The Problem\n\nHowever, there was one common piece of feedback from many of our Open Source\nusers. The ClickHouse connector required an S3 bucket as a prerequisite, which\nadded additional overhead for users. Non-AWS users and those without immediate\naccess to S3 could not use the ClickHouse connector. This wasn't a problem in\nour fully managed offering (PeerDB Cloud), as we abstracted away the S3 bucket\ncreation from our customers.\n\nThis blog describes how we solved this problem and made it extremely easy for\nour users replicating data from Postgres to ClickHouse. We used MinIO, the\nopen source S3 alternative, to stage the intermediary Avro files as part of\nthe Change Data Capture (CDC) from Postgres to ClickHouse.\n\n## Why does the ClickHouse connector need S3?\n\nUnder the hood, PeerDB uses the Avro format for data in transit while\nreplicating data from Postgres to Data Warehouses. Loading Avro files through\nGo wasn't trivial as the clickhouse-go driver didn't support Avro ingestion.\nAdditionally, ClickHouse has native integration for loading data from S3 and\nis very efficient at it, as it attempts to parallelize as much work as\npossible, processing files in a streaming fashion. Therefore, we chose to use\nS3 as an intermediary storage for Avro files before importing them into\nClickHouse.\n\nThis method has proven effective, allowing users to efficiently replicate data\nfrom Postgres to ClickHouse with latencies under 30 seconds and high\nthroughput rates.\n\n## MinIO helps make the PeerDB's ClickHouse Connector Seamless\n\nBy integrating MinIO container services into our Docker Compose files for our\nOpen Source offering, we've enabled an in-house S3-compatible storage solution\nthat launches seamlessly with PeerDB. PeerDB uses environment variables to\nmanage S3 bucket credentials, allowing for easy integration. Users can set\nthese variables to match the MinIO bucket parameters, or they can plug in\ntheir own S3 bucket details. These parameters default to the packaged MinIO\nbucket parameters, as a result, users no longer need to provide a separate\nbucket for PeerDB\u2019s ClickHouse integration, simplifying the setup process\nsignificantly.\n\nA huge shoutout to MinIO for building a solid product that serves as an open\nsource alternative to S3. Integrating MinIO's Docker container within PeerDB's\nDocker file was a one-week project. MinIO's APIs, being fully compatible with\nS3, allowed for seamless integration with PeerDB and ClickHouse.\n\n## Result: Even simpler Postgres to ClickHouse replication with PeerDB.\n\n### Simplifying ClickHouse Peer Creation with Optional S3 Configuration\n\nIntegrating the MinIO Docker Container in our Open Source offering eliminates\nthe need for users to specify S3 buckets to use our ClickHouse connector.\nWhile creating the ClickHouse Peer, adding S3 information is optional, as\nshown in the screenshot below.\n\n### Set Up a Postgres to ClickHouse Mirror in Under a Minute\n\nOnce the Postgres and ClickHouse Peers are created, users can create MIRRORs\nto replicate data from Postgres to ClickHouse within a minute. See below\nvideo:\n\nhttps://www.loom.com/share/fa1afec884724876a63aab522b40e445?sid=7d5383ed-0c51-4018-8920-3d8e95ad4c56\n\n### Use the MinIO Console for complete visibility into internal staging\n\nMinIO also comes with a sleek UI that helps you manage the internal Avro files\nPeerDB creates as part of the replication process.\n\nhttps://www.loom.com/share/b41d3ad81259407f9a99b7a74c8f1449?sid=2766cebd-20d9-493d-a95a-b8852c9c30b9\n\nWe hope you enjoyed reading the blog. If you're a ClickHouse user and wish to\nreplicate data from Postgres to ClickHouse using PeerDB, please check out the\nlinks below or reach out to us directly!\n\n  1. Docs on Postgres to ClickHouse Replication.\n\n  2. Try PeerDB Cloud for free.\n\n  3. Visit PeerDB's GitHub repository to Get Started.\n\n## Subscribe to our newsletter\n\nRead articles from PeerDB Blog directly inside your inbox. Subscribe to the\nnewsletter, and don't miss out.\n\nClickHousePostgreSQL#minioS3S3-bucketminiobucketETLreplicationOpen\nSourcechange data capturepostgres\n\n### Written by\n\n# Sai Srirampur\n\n### Published on\n\n# PeerDB Blog\n\nAt PeerDB, we are building a fast, simple and the most cost effective way to\nstream data from Postgres to Data Warehouses, Queues and Storage engines.\n\nAt PeerDB, we are building a fast, simple and the most cost effective way to\nstream data from Postgres to Data Warehouses, Queues and Storage engines.\n\nShare this\n\n### More articles\n\nKaushik Iska\n\n# PeerDB Launch Week\n\nIt will be almost 1 year since PeerDB started the YC Summer 23 program. To\ncelebrate this, we challe...\n\nSai Srirampur\n\n# How can we make pg_dump and pg_restore 5 times faster?\n\npg_dump and pg_restore are reliable tools for backing up and restoring\nPostgres databases. They're e...\n\nSai Srirampur\n\n# PeerDB raises $3.6 million seed funding to revolutionize data movement for\nPostgreSQL\n\nPeerDB offers a fast and cost-effective way to move data from PostgreSQL to\ndata warehouses, such as...\n\n\u00a92024 PeerDB Blog\n\nArchive\u00b7Privacy policy\u00b7Terms\n\nWrite on Hashnode\n\nPowered by Hashnode - Home for tech writers and readers\n\n", "frontpage": false}
