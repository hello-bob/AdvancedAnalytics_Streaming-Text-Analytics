{"aid": "40056175", "title": "Strategies to Deal with Data Challenges in RAG Systems", "url": "https://vectorize.io/triumph-over-data-obstacles-in-rag-8-expert-tips/", "domain": "vectorize.io", "votes": 2, "user": "bytearray", "posted_at": "2024-04-16 19:30:20", "comments": 0, "source_title": "Triumph Over Data Obstacles In RAG: 8 Expert Tips - Vectorize", "source_text": "Triumph Over Data Obstacles In RAG: 8 Expert Tips - Vectorize\n\nWe use essential cookies to make our site work. With your consent, we may also\nuse non-essential cookies to improve user experience, personalize content, and\nanalyze website traffic. For these reasons, we may share your site usage data\nwith our analytics partners. By clicking \u201cAccept,\u201d you agree to our website's\ncookie use as described in our Cookie Policy. You can change your cookie\nsettings at any time by clicking \u201cPreferences.\u201d\n\n  * Use Cases\n\n    * Question Answering Systems\n    * AI Copilots\n    * Call Center Automation\n    * Content Automation\n    * Hyper-personalization\n  * Blog\n  * About\n  * Learn\n\n    * Prompt Engineering\n    * Retrieval Augmented Generation (RAG)\n    * Vector Database Guide\n  * Contact\n\nContact Us\n\n#### Be on of the first to try Vectorize!\n\nEdit Content\n\nRAG\n\n# Triumph Over Data Obstacles In RAG: 8 Expert Tips\n\nApril 16, 2024 Hadi Azzouni No comments yet\n\n## Introduction\n\nRetrieval-Augmented Generation (RAG) has emerged as the de-facto architecture\nin building apps with LLMs. RAG enhances the LLM by integrating external data,\nenabling more comprehensive and accurate responses. However, to harness the\nfull potential of RAG systems, it\u2019s crucial to navigate and overcome some data\nchallenges that are inherent in this technology.\n\nIn the following sections, we will discuss some common data-related challenges\nwhen building LLM RAG applications, along with strategies to overcome them:\n\n## 1\\. Data Extraction\n\nChallenge: Parsing complex data structures, such as PDFs with embedded tables\nor images, can be difficult and require specialized techniques to accurately\nextract relevant information. As of today, OCR (Optical Character Recognition)\nis still largely an open problem, especially when dealing with scanned complex\ndocuments like invoices.\n\nStrategies:\n\n  * Start simple: start with a text only data pipeline whenever possible. If your RAG system cannot perform well on text data then chances are it will not perform well on images and audio.\n  * If your data contains PDF files, then invest in a good parsing tool. A very common document recognition method would be to segment the problem into subproblems of lower complexity. For example: if you are building a RAG to read medical invoices, then you may use an OCR tool for specific key fields like: total amount, tax amount etc and if needed use advanced visual models (GPT4 vision works great with complex PDF documents for examples).\n  * Worth noting that Microsoft Azure probably has the best pre-built document recognition/understanding tools for enterprises (product name: Document Intelligence).\n\n## 2\\. Handling Structured Data\n\nChallenge: LLMs are great at dealing with unstructured data, such as free-\nflowing text, but not that good at handling structured data, like tabular data\nfor example. Many issues arise when trying to use LLM over tabular data,\nincluding a high rate of hallucination. My advice is that you avoid using LLMs\non tabular data altogether whenever possible. If that\u2019s not a choice, then:\n\nStrategies:\n\n  * Transform tabular data to unstructured text. You have to be careful with:\n\n    * Numerical Representation: Traditional tokenization methods, such as Byte Pair Encoding (BPE), split numbers into non-aligned tokens, complicating arithmetic operations for LLMs. Newer models, like LLaMA, tokenize each digit separately, improving the understanding of symbolic and numerical data.\n    * Categorical Representation: Excessive columns in tabular data can lead to serialized input strings that exceed the context limit of LLMs, resulting in data pruning and performance issues. Poorly represented categorical features, such as nonsensical characters, can also hinder LLM processing and understanding.\n  * Employ techniques such as the chain-of-the-table approach, which combines table analysis with step-by-step information extraction strategies, enhancing tabular question-answering capabilities in RAG systems. https://blog.gopenai.com/enhancing-tabular-data-analysis-with-llms-78af1b7a6df9\n\n## 3\\. Choosing the Right Chunk Size and Chunking Strategy\n\nChallenges:\n\nDetermining the optimal chunk size for dividing documents into semantically\ndistinct parts while balancing the need for comprehensive context and fast\nretrieval. Longer contexts lead to longer inference time (try Gemini 1.5 pro\nwith 1M context tokens!), and smaller context chunks might lead to incomplete\nanswers.\n\nThe other major challenge around chunking is the chunking strategy, meaning\nshould you chunk based on sentences? paragraphs? word count? etc\n\nStrategies:\n\n  * Again, start simple and iterate: pick a simple chunking strategy first, run evals, measure everything, I talked more about chunking strategies in this newsletter post: https://heycloud.beehiiv.com/p/text-splitting-chunking-rag-applications\n  * Chunk size should follow the chunking strategy not the opposite, meaning: first you determine the strategy you want to follow, then you determine the chunk size considering both your strategy and the LLM context size. For example: if your data is a collection of news articles, then the paragraph-level chunking would likely work, and since the context size of most LLMs is larger than one paragraph, then you can afford a variable chunk size which is the size of a paragraph.\n\n## 4\\. Creating a Robust and Scalable Pipeline\n\nChallenge: Building a robust and scalable RAG pipeline to handle a large\nvolume of data and continuously index and store it in a vector database. Most\nRAG app builders have this part as an afterthought, which makes sense as your\nfirst goal is to make something that works. However, if you know you app will\neventually have to handle TBs of data per hour, then you may have to design\nthe whole app with that in mind.\n\nStrategies:\n\n  * Once again, start simple I think you got the memo by now!\n  * Try to estimate the scale of your app early on, even though you don\u2019t need to act on this information from the beginning.\n  * If needed, adopt a modular and distributed system approach, separating the pipeline into scalable units and employing distributed processing for parallel operation efficiency.\n  * Use battle-tested tools to deploy your app, like kubernetes. The good thing about Kubernetes is that you can scale up and down as needed. For example, if you need a periodic cron job to clean newly fetched data, then you can schedule it and be sure it will disappear after the job is done, saving you compute and money.\n\n## 5\\. Retrieved Data Not in Context\n\nChallenge: The RAG system may retrieve data that is not relevant or does not\nprovide the necessary context for accurate response generation. One of the\ncommon reasons for this is: bad embedding, bad user query, context truncating\netc\n\nStrategies:\n\n  * Use query augmentation/rewriting to enhance user queries with additional context or modifications, improving the relevancy of retrieved information. An excellent example of query rewriting is how Cursor.sh does it.\n\n  * Explore different retrieval strategies, such as small-to-big sentence window retrieval and semantic similarity scoring, to incorporate relevant information into the context.\n  * A more advanced trick would be to use generative UIs to clarify user intent. For example, you could reply to the user\u2019s query by asking to clarify it to ensure the retrieval engine retrieves the complete context to then answer the query. Morphic.sh is a good example of an answer engine using dynamically generated UIs for user query clarification.\n  * Invest in a monitoring solution to visualize prompts, chunks and responses.\n\n## 6\\. Task-Based Retrieval\n\nChallenge: RAG applications should be able to handle a wide range of user\nqueries, including those seeking summaries, comparisons, or specific facts.\nHence, handling all user queries with one retrieval prompt might not do the\njob.\n\nStrategy:\n\n  * Implement query routing to identify the appropriate subset of tools or sources based on the initial user query, ensuring adapted retrieval for different use cases. Routing usually involves creating multiple indexes and a classifier. The classifier could be a small and cheap LLM classifying the query and routing it into the corresponding index.\n\nSouce: https://mlnotes.substack.com/p/adaptive-query-routing-in-retrieval\n\n## 7\\. Data Freshness\n\nChallenge: Ensuring that the RAG app always uses the latest and most accurate\ninformation, especially when documents are updated.\n\nStrategies:\n\n  * Implement metadata filtering, which acts as a label to indicate if a document is new or changed, ensuring the app always uses the most recent information.\n  * Like in \u201cEnsuring data is in context\u201d, a more advanced trick would be to use generative UIs to clarify user intent around recency. For example, you could answer the user query by asking to clarify if the user is asking about recent events or general events etc.\n  * In some cases, LLMs confuse their internal learned information about dates and external data timestamps, hence it is important to be explicit in the prompt about which to use.\n\n## 8\\. Data Security\n\nChallenge: Ensuring the security and integrity of LLMs used in RAG\napplications, preventing sensitive information disclosure, and addressing\nethical and privacy considerations. I wrote here about security threats that\none should consider when building RAG applications. In summary:\n\nStrategies and considerations:\n\n  * Implementing multi-tenancy to keep user data private and secure is one of the most important mitigation strategies.\n  * Properly handle the user prompt to ensure it does not abuse the LLM.\n  * Analyze the RAG data for any signs of data poisoning.\n\n## Conclusion\n\nData is the central piece of any RAG system. Issues with the data may render\nyour RAG system unusable or even worse, expose your users to security threats.\nHence it is very important to be aware of the common challenges and the best\nstrategies to correctly handle your RAG data.In this article we attempt to\nexactly address those common issues, ranging from missing context to data\nsecurity etc.\n\nThis is a rapidly evolving field so we highly encourage the reader to keep an\neye on recent advances in LLMs and RAG techniques. A good way to that is to\nsubscribe below so you don\u2019t miss our next articles. Also, follow my subscribe\nto my newsletter: https://heycloud.beehiiv.com/p/attack-vectors-rag-\napplications. I frequently write about RAG techniques and my own experience\nbuilding RAG apps.\n\n## References\n\n  * https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1\n  * https://mlnotes.substack.com/p/adaptive-query-routing-in-retrieval\n  * https://arxiv.org/html/2402.17944v2\n  * https://www.hopsworks.ai/dictionary/retrieval-augmented-generation-llm\n  * https://humanloop.com/blog/optimizing-llms\n  * https://gretel.ai/blog/how-to-improve-rag-model-performance-with-synthetic-data\n  * https://www.rungalileo.io/blog/optimizing-llm-performance-rag-vs-finetune-vs-both\n  * https://heycloud.beehiiv.com/p/cheaper-faster-rag-sql-layer\n\n### Share this:\n\n  * Twitter\n  * LinkedIn\n  * Facebook\n  * Reddit\n  * Pinterest\n  * Threads\n  * X\n\n### Related\n\n### Leave a ReplyCancel reply\n\n#### Search\n\n#### Categories\n\n#### Recent posts\n\n  * Triumph Over Data Obstacles In RAG: 8 Expert Tips\n\n  * How to build a better RAG pipeline\n\n  * How to Get More from Your Pinecone Vector Database\n\n#### Tags\n\nRAG Retrieval Augmented Generation\n\nThe easiest, fastest way to connect your data to your LLMs.\n\n##### Resources\n\n  * Support center\n  * Documentation\n  * Community\n  * Hosting\n\n##### Company\n\n  * About us\n  * Latest news\n  * Contact us\n  * Resources\n\n\u00a9 Vectorize AI, Inc, All Rights Reserved.\n\n  * Terms & Conditions\n  * Privacy Policy\n\n## Discover more from Vectorize\n\nSubscribe now to keep reading and get access to the full archive.\n\nContinue reading\n\nLoading Comments...\n\n", "frontpage": false}
