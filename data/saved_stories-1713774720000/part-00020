{"aid": "40110740", "title": "C&C \u2013 Solving Recursive Equations", "url": "https://jozefg.bitbucket.io/posts/2015-08-14-solve-domains.html", "domain": "jozefg.bitbucket.io", "votes": 1, "user": "todsacerdoti", "posted_at": "2024-04-22 01:28:06", "comments": 0, "source_title": "C&C - Solving Recursive Equations", "source_text": "C&C - Solving Recursive Equations\n\nCode & Co.\n\nAbout Contact Blog RSS Feed\n\nThis website is out of date, please refer to the site on github.\n\n# Solving Recursive Equations\n\nPosted on August 14, 2015\n\nTags: types\n\nI wanted to write about something related to all the stuff I\u2019ve been reading\nfor research lately. I decided to talk about a super cool trick in a field\ncalled domain theory. It\u2019s a method of generating a solution to a large class\nof recursive equations.\n\nIn order to go through this idea we\u2019ve got some background to cover. I wanted\nto make this post readable even if you haven\u2019t read too much domain theory\n(you do need to know what a functor/colimit is though, nothing crazy though).\nWe\u2019ll start with a whirlwind tutorial of the math behind domain theory. From\nthere we\u2019ll transform the problem of finding a solution to an equation into\nsomething categorically tractable. Finally, I\u2019ll walk through the construction\nof a solution.\n\nI decided not to show an example of applying this technique to model a\nlanguage because that would warrant its own post, hopefully I\u2019ll write about\nthat soon :)\n\n## Basic Domain Theory\n\nThe basic idea with domain theory comes from a simple problem. Suppose we want\nto model the lambda calculus. We want a collection of mathematical objects D\nso that we can treat element of D as a function D -> D and each function D ->\nD as an element of D. To see why this is natural, remember that we want to\nturn each program E into d \u2208 D. If E = \u03bb x. E' then we need to turn the\nfunction e \u21a6 [e/x]E' into a term. This means D \u2192 D needs to be embeddable in\nD. On the other hand, we might have E = E' E'' in which case we need to turn\nE' into a function D \u2192 D so that we can apply it. This means we need to be\nable to embed D into D \u2192 D.\n\nAfter this we can turn a lambda calculus program into a specific element of D\nand reason about its properties using the ambient mathematical tools for D.\nThis is semantics, understanding programs by studying their meaning in some\nmathematical structure. In our specific case that structure is D with the\nisomorphism D \u2245 D \u2192 D. However, there\u2019s an issue! We know that D can\u2019t just be\na set because then there cannot be such an isomorphism! In the case where D \u2245\nN, then D \u2192 D \u2245 R and there\u2019s a nice proof by diagonalization that such an\nisomorphism cannot exist.\n\nSo what can we do? We know there are only countably many programs, but we\u2019re\ntrying to state that there exists an isomorphism between our programs\n(countable) and functions on them (uncountable). Well the issue is that we\ndon\u2019t really mean all functions on D, just the ones we can model as lambda\nterms. For example, the function which maps all divergent programs to 1 and\nall terminating ones to 0 need not be considered because there\u2019s no lambda\nterm for it! How do we consider \u201ccomputable\u201d functions though? It\u2019s not\nobvious since we define computable functions using the lambda calculus, what\nwe\u2019re trying to model here. Let\u2019s set aside this question for a moment.\n\nAnother question is how do we handle this program: (\u03bb x. x x) (\u03bb x. x x)? It\ndoesn\u2019t have a value after all! It doesn\u2019t behave like a normal mathematical\nfunction because applying it to something doesn\u2019t give us back a new term, it\njust runs forever! To handle this we do something really clever. We stop\nconsidering just a collection of terms and instead look at terms with an\nordering relation \u2291! The idea is that \u2291 represents definedness. A program\nwhich runs to a value is more defined than a program which just loops forever.\nSimilarly, two functions behave the same on all inputs except for 0 where one\nloops we could say one is more defined than the other. What we\u2019ll do is define\n\u2291 abstractly and then model programs into sets with such a relation defined\nupon them. In order to build up this theory we need a few definitions\n\nA partially ordered set (poset) is a set A and a binary relation \u2291 where\n\n  1. a \u2291 a\n  2. a \u2291 b and b \u2291 c implies a \u2291 c\n  3. a \u2291 b and b \u2291 a implies a = b\n\nWe often just denote the pair <A, \u2291> as A when the ordering is clear. With a\nposet A, of particular interest are chains in it. A chain is collection of\nelements ai so that ai \u2291 aj if i \u2264 j. For example, in the partial order of\nnatural numbers and \u2264, a chain is just a run of ascending numbers. Another\nfundamental concept is called a least upper bound (lub). A lub of a subset P \u2286\nA is an element of x \u2208 A so that y \u2208 P implies y \u2291 x and if this property\nholds for some z also in A, then x \u2291 z. So a least upper bound is just the\nsmallest thing bigger than the subset. This isn\u2019t always guaranteed to exist,\nfor example, in our poset of natural numbers N, the subset N has no upper\nbounds at all! When such a lub does exist, we denote it with \u2294P. Some partial\norders have an interesting property, all chains in them have least upper\nbounds. We call this posets complete partial orders or cpos.\n\nFor example while N isn\u2019t a cpo, \u03c9 (the natural numbers + an element greater\nthan all of them) is! As a quick puzzle, can you show that all finite partial\norders are in fact CPOs?\n\nWe can define a number of basic constructions on cpos. The most common is the\n\u201clifting\u201d operation which takes a cpo D and returns D\u22a5, a cpo with a least\nelement \u22a5. A cpo with such a least element is called \u201cpointed\u201d and I\u2019ll write\nthat as cppo (complete pointed partial order). Another common example, given\ntwo cppos, D and E, we can construct D \u2297 E. An element of this cppo is either\n\u22a5 or <l, r> where l \u2208 D - {\u22a5} and r \u2208 E - {\u22a5}. This is called the smash\nproduct because it \u201csmashes\u201d the \u22a5s out of the components. Similarly, there\u2019s\nsmash sums D \u2295 E.\n\nThe next question is the classic algebraic question to ask about a structure:\nwhat are the interesting functions on it? We\u2019ll in particular be interested in\nfunctions which preserve the \u2291 relation and the taking of lub\u2019s on chains. For\nthis we have two more definitions:\n\n  1. A function is monotone if x \u2291 y implies f(x) \u2291 f(y)\n  2. A function is continuous if it is monotone and for all chains C, \u2294 f(P) = f(\u2294 P).\n\nNotably, the collection of cppos and continuous functions form a category!\nThis is because clearly x \u21a6 x is continuous and the composition of two\ncontinuous functions is continuous. This category is called Cpo. It\u2019s here\nthat we\u2019re going to do most of our interesting constructions.\n\nFinally, we have to discuss one important construction on Cpo: D \u2192 E. This is\nthe set of continuous functions from D to E. The ordering on this is\npointwise, meaning that f \u2291 g if for all x \u2208 D, f(x) \u2291 g(x). This is a cppo\nwhere \u22a5 is x \u21a6 \u22a5 and all the lubs are determined pointwise.\n\nThis gives us most of the mathematics we need to do the constructions we\u2019re\ngoing to want, to demonstrate something cool here\u2019s a fun theorem which turns\nout to be incredibly useful: Any continuous function f : D \u2192 D on a cppo D has\na least fixed point.\n\nTo construct this least point we need to find an x so that x = f(x). To do\nthis, note first that x \u2291 f(x) by definition and by the monotonicity of f:\nf(x) \u2291 f(y) if x \u2286 y. This means that the collection of elements fi(\u22a5) forms a\nchain with the ith element being the ith iteration of f! Since D is a cppo,\nthis chain has an upper bound: \u2294 fi(\u22a5). Moreover, f(\u2294 fi(\u22a5)) = \u2294 f(fi(\u22a5)) by\nthe continuity of f, but \u2294 fi(\u22a5) = \u22a5 \u2294 (\u2294 f(fi(\u22a5))) = \u2294 f(fi(\u22a5)) so this is a\nfixed point! The proof that it\u2019s a least fixed point is elided because\ntypesetting in markdown is a bit of a bother.\n\nSo there you have it, very, very basic domain theory. I can now answer the\nquestion we weren\u2019t sure about before, the slogan is \u201ccomputable functions are\ncontinuous functions\u201d.\n\n## Solving Recursive Equations in Cpo\n\nSo now we can get to the result showing domain theory incredibly useful.\nRemember our problem before? We wanted to find a collection D so that\n\n    \n    \n    D \u2245 D \u2192 D\n\nHowever it wasn\u2019t clear how to do this due to size issues. In Cpo however, we\ncan absolutely solve this. This huge result was due to Dana Scott. First, we\nmake a small transformation to the problem that\u2019s very common in these\nscenarios. Instead of trying to solve this equation (something we don\u2019t have\nvery many tools for) we\u2019re going to instead look for the fixpoint of this\nfunctor\n\n    \n    \n    F(X) = X \u2192 X\n\nThe idea here is that we\u2019re going to prove that all well behaved endofunctors\non Cpo have fixpoints. By using this viewpoint we get all the powerful tools\nwe normally have for reasoning about functors in category theory. However,\nthere\u2019s a problem: the above isn\u2019t a functor! It has both positive and\nnegative occurrences of X so it\u2019s neither a co nor contravariant functor. To\nhandle this we apply another clever trick. Let\u2019s not look at endofunctors, but\nrather functors Cpoo \u00d7 Cpo \u2192 Cpo (I believe this should be attributed to\nFreyd). This is a binary functor which is covariant in the second argument and\ncontravariant in the first. We\u2019ll use the first argument everywhere there\u2019s a\nnegative occurrence of X and the second for every positive occurrence. Take\nnote: we need things to be contravariant in the first argument because we\u2019re\nusing that first argument negatively: if we didn\u2019t do that we wouldn\u2019t have a\nfunctor.\n\nNow we have\n\n    \n    \n    F(X\u2212, X+) = X\u2212 \u2192 X+\n\nThis is functorial. We can also always recover the original map simply by\ndiagonalizing: F(X) = F(X, X). We\u2019ll now look for an object D so that F(D, D)\n\u2245 D. Not quite a fixed point, but still equivalent to the equation we were\nlooking at earlier.\n\nFurthermore, we need one last critical property, we want F to be locally\ncontinuous. This means that the maps on morphisms determined by F should be\ncontinuous so F(\u2294 P, g) = \u2294 F(P, g) and vice-versa (here P is a set of\nfunctions). Note that such morphisms have an ordering because they belong to\nthe pointwise ordered cppo we talked about earlier.\n\nWe have one final thing to set up before this proof: what about if there\u2019s\nmultiple non-isomorphic solutions to F? We want a further coherence condition\nthat\u2019s going to provide us with 2 things\n\n  1. An ability to uniquely determine a solution\n  2. A powerful proof technique that isolates us from the particulars of the construction\n\nWhat we want is called minimal invariance. Suppose we have a D and an i : D \u2245\nF(D, D). This is the minimal invariant solution if and only if the least fixed\npoint of f(e) = i\u2212 \u2218 F(e, e) \u2218 i is id. In other words, we want it to be the\ncase that\n\n    \n    \n    d = \u2294x fx(\u22a5)(d) (d \u2208 D)\n\nI mentally picture this as saying that the isomorphism is set up so that for\nany particular d we choose, if we apply i, fmap over it, apply i again, repeat\nand repeat, eventually this process will halt and we\u2019ll run out of things to\nfmap over. It\u2019s a sort of a statement that each d \u2208 D is \u201cfinite\u201d in a very,\nvery handwavy sense. Don\u2019t worry if that didn\u2019t make much sense, it\u2019s helpful\nto me but it\u2019s just my intuition. This property has some interesting effects\nthough: it means that if we find such a D then (D, D) is going to be both the\ninitial algebra and final coalgebra of F.\n\nWithout further ado, let\u2019s prove that every locally continuous functor F. We\nstart by defining the following\n\n    \n    \n    D0 = {\u22a5} Di = F(Di\u22121, Di\u22121)\n\nThis gives us a chain of cppos that gradually get larger. How do we show that\nthey\u2019re getting larger? By defining an section from Di to Dj where j = i + 1.\nA section is a function f which is paired with a (unique) function f0 so that\nf0f = id and ff0 \u2291 id. In other words, f embeds its domain into the codomain\nand f0 tells us how to get it out. Putting something in and taking it out is a\nround trip. Since the codomain may be bigger though taking something out and\nputting it back only approximates a round trip. Our sections are defined\nthusly\n\n    \n    \n    s0 = x \u21a6 \u22a5 r0 = x \u21a6 \u22a5 si = F(ri\u22121, si\u22121) ri = F(ri\u22121, si\u22121)\n\nIt would be very instructive to work out that these definitions are actually\nsections and retractions. Since type-setting this subscripts is a little\nrough, if it\u2019s clear from context I\u2019ll just write r and s. Now we\u2019ve got this\nincreasing chain, we define an interesting object\n\n    \n    \n    D = {x \u2208 \u03a0i Di | x.(i-1) = r(x.i)}\n\nIn other words, D is the collection of infinitely large pairs. Each component\nif from one of those Dis above and they cohere with each other so using s and\nr to step up the chain takes you from one component to the next. Next we\ndefine a way to go from a single Di to a D: upi : Di \u2192 D where\n\n    \n    \n    upi(x).j = x if i = j | rd(x) if i - j = d > 0 | sd(x) if j - i = d > 0\n\nInterestingly, note that \u03c0i \u2218 upi = id (easy proof) and that upi \u2218 \u03c0i \u2291 id\n(slightly harder proof). This means that we\u2019ve got more sections lying around:\nevery Di can be fed into D. Consider the following diagram\n\n    \n    \n    s s s D0 \u2014\u2014> D1 \u2014\u2014> D2 \u2014\u2014> ...\n\nI claim that D is the colimit to this diagram where the collection of arrows\nmapping into it are given with upi. Seeing this is a colimit follows from the\nfact that \u03c0i \u2218 upi is just id. Specifically, suppose we have some object C and\na family of morphisms ci : Di \u2192 C which commute properly with s. We need to\nfind a unique morphism h so that ci = h \u2218 upi. Define h as \u2294i ci\u03c0i. Then\n\n    \n    \n    h \u2218 upj = (\u2294j<i cisjrj) \u2294 ci \u2294 (\u2294j>i cirjsj) = (\u2294j<i cisjrj) \u2294 ci\n\nThe last step follows from the fact that rjsj = id. Furthermore, sjrj \u2291 id so\ncisjrj \u2291 ci so that whole massive term just evaluates to ci as required. So we\nhave a colimit. Notice that if we apply F to each Di in the diagram we end up\nwith a new diagram.\n\n    \n    \n    s s s D1 \u2014\u2014> D2 \u2014\u2014> D3 \u2014\u2014> ...\n\nD is still the colimit (all we\u2019ve done is shift the diagram over by one) but\nby identical reasoning to D being a colimit, so is F(D, D). This means we have\na unique isomorphism i : D \u2245 F(D, D). The fact that i is the minimal invariant\nfollows from the properties we get from the fact that i comes from a colimit.\n\nWith this construction we can construct our model of the lambda calculus\nsimply by finding the minimal invariant of the locally continuous functor\nF(D\u2212, D+) = D\u2212 \u2192 D+ (it\u2019s worth proving it\u2019s locally continuous). Our\ndenotation is defined as [e]\u03c1 \u2208 D where e is a lambda term and \u03c1 is a map of\nthe free variables of e to other elements of D. This is inductively defined as\n\n    \n    \n    [\u03bbx. e]\u03c1 = i\u2212(d \u21a6 [e]\u03c1[x \u21a6 d]) [e e']\u03c1 = i([e]\u03c1)([e']\u03c1) [x]\u03c1 = \u03c1(x)\n\nNotice here that for the two main constructions we just use i and i\u2212 to fold\nand unfold the denotations to treat them as functions. We could go on to prove\nthat this denotation is sound and complete but that\u2019s something for another\npost.\n\n## Wrap Up\n\nThat\u2019s the main result I wanted to demonstrate. With this single proof we can\nactually model a very large class of programming languages into Cpo. Hopefully\nI\u2019ll get around to showing how we can pull a similar trick with a relational\nstructure on Cpo in order to prove full abstraction. This is nicely explained\nin Andrew Pitt\u2019s \u201cRelational Properties of Domains\u201d.\n\nIf you\u2019re interested in domain theory I learned from Gunter\u2019s \u201cSemantics of\nProgramming Languages\u201d book and recommend it.\n\nSite generated by Hakyll\n\n", "frontpage": false}
