{"aid": "40143663", "title": "Hayabusa: Sigma-based forensics timeline generator for Windows event logs", "url": "https://github.com/Yamato-Security/hayabusa", "domain": "github.com/yamato-security", "votes": 1, "user": "nateb2022", "posted_at": "2024-04-24 12:40:37", "comments": 0, "source_title": "GitHub - Yamato-Security/hayabusa: Hayabusa (\u96bc) is a sigma-based threat hunting and fast forensics timeline generator for Windows event logs.", "source_text": "GitHub - Yamato-Security/hayabusa: Hayabusa (\u96bc) is a sigma-based threat\nhunting and fast forensics timeline generator for Windows event logs.\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nYamato-Security / hayabusa Public\n\n  * Notifications\n  * Fork 166\n  * Star 1.9k\n\nHayabusa (\u96bc) is a sigma-based threat hunting and fast forensics timeline\ngenerator for Windows event logs.\n\n### License\n\nGPL-3.0 license\n\n1.9k stars 166 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# Yamato-Security/hayabusa\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n27 Branches\n\n45 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nYamatoSecurityMerge pull request #1331 from Yamato-Security/finalize-2.15.0Apr\n20, 202464baed7 \u00b7 Apr 20, 2024Apr 20, 2024\n\n## History\n\n3,996 Commits  \n  \n### .cargo\n\n|\n\n### .cargo\n\n| refactor: Remove unnecessary msvcrt.lib. related #777| Oct 24, 2022  \n  \n### .github\n\n|\n\n### .github\n\n| Disabled MacOS CI| Nov 14, 2023  \n  \n### art\n\n|\n\n### art\n\n| update logo| Mar 16, 2024  \n  \n### config\n\n|\n\n### config\n\n| update color levels| Feb 8, 2024  \n  \n### doc\n\n|\n\n### doc\n\n| add field data mapping to picture| Jul 19, 2023  \n  \n### logs\n\n|\n\n### logs\n\n| change readme| Dec 25, 2021  \n  \n### rules @ 0a43d71\n\n|\n\n### rules @ 0a43d71\n\n| update rules| Apr 20, 2024  \n  \n### screenshots\n\n|\n\n### screenshots\n\n| update screenshots| Mar 28, 2024  \n  \n### src\n\n|\n\n### src\n\n| finalize 2.15.0| Apr 20, 2024  \n  \n### test_files\n\n|\n\n### test_files\n\n| test(yaml): added test for include-category and exclude-category #1119| Jul\n3, 2023  \n  \n### .codecov.yml\n\n|\n\n### .codecov.yml\n\n| ci(codecov.yml): changed informational to codecov projects| Feb 4, 2023  \n  \n### .env.example\n\n|\n\n### .env.example\n\n| Feature/slack_notify#134 (#139)| Sep 30, 2021  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| update gitignore| May 3, 2023  \n  \n### .gitmodules\n\n|\n\n### .gitmodules\n\n| added update command #391 (#392)| Feb 26, 2022  \n  \n### CHANGELOG-Japanese.md\n\n|\n\n### CHANGELOG-Japanese.md\n\n| update changelog| Apr 20, 2024  \n  \n### CHANGELOG.md\n\n|\n\n### CHANGELOG.md\n\n| update changelog| Apr 20, 2024  \n  \n### Cargo.lock\n\n|\n\n### Cargo.lock\n\n| update dialoguer| Apr 20, 2024  \n  \n### Cargo.toml\n\n|\n\n### Cargo.toml\n\n| update dialoguer| Apr 20, 2024  \n  \n### LICENSE.txt\n\n|\n\n### LICENSE.txt\n\n| adjust GPL v3 #305| Dec 19, 2021  \n  \n### README-Japanese.md\n\n|\n\n### README-Japanese.md\n\n| update readme| Mar 28, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| update readme| Mar 28, 2024  \n  \n### contributors.txt\n\n|\n\n### contributors.txt\n\n| feat(detection): fixed missing Details field in JSON output when splu...|\nFeb 28, 2024  \n  \n### logo.png\n\n|\n\n### logo.png\n\n| update html report logo| Oct 12, 2022  \n  \n## Repository files navigation\n\n[ English ] | [\u65e5\u672c\u8a9e]\n\n# About Hayabusa\n\nHayabusa is a Windows event log fast forensics timeline generator and threat\nhunting tool created by the Yamato Security group in Japan. Hayabusa means\n\"peregrine falcon\" in Japanese and was chosen as peregrine falcons are the\nfastest animal in the world, great at hunting and highly trainable. It is\nwritten in Rust and supports multi-threading in order to be as fast as\npossible. We have provided a tool to convert Sigma rules into Hayabusa rule\nformat. The Sigma-compatible Hayabusa detection rules are written in YML in\norder to be as easily customizable and extensible as possible. Hayabusa can be\nrun either on single running systems for live analysis, by gathering logs from\nsingle or multiple systems for offline analysis, or by running the Hayabusa\nartifact with Velociraptor for enterprise-wide threat hunting and incident\nresponse. The output will be consolidated into a single CSV timeline for easy\nanalysis in LibreOffice, Timeline Explorer, Elastic Stack, Timesketch, etc...\n\n# Companion Projects\n\n  * EnableWindowsLogSettings - Documentation and scripts to properly enable Windows event logs.\n  * Hayabusa Rules - Detection rules for hayabusa.\n  * Hayabusa Sample EVTXs - Sample evtx files to use for testing hayabusa/sigma detection rules.\n  * Takajo - An analyzer for hayabusa results.\n  * WELA (Windows Event Log Analyzer) - An analyzer for Windows event logs written in PowerShell.\n\n## Table of Contents\n\n  * About Hayabusa\n  * Companion Projects\n\n    * Table of Contents\n    * Main Goals\n\n      * Threat Hunting and Enterprise-wide DFIR\n      * Fast Forensics Timeline Generation\n  * Screenshots\n\n    * Startup\n    * DFIR Timeline Terminal Output\n    * Keyword Search Results\n    * Detection Fequency Timeline (-T option)\n    * Results Summary\n    * HTML Results Summary (-H option)\n    * DFIR Timeline Analysis in LibreOffice (-M Multiline Output)\n    * DFIR Timeline Analysis in Timeline Explorer\n    * Critical Alert Filtering and Computer Grouping in Timeline Explorer\n    * Analysis with the Elastic Stack Dashboard\n    * Analysis in Timesketch\n  * Importing and Analyzing Timeline Results\n  * Analyzing JSON-formatted results with JQ\n  * Features\n  * Downloads\n  * Git Cloning\n  * Advanced: Compiling From Source (Optional)\n\n    * Updating Rust Packages\n    * Cross-compiling 32-bit Windows Binaries\n    * macOS Compiling Notes\n    * Linux Compiling Notes\n    * Cross-compiling Linux MUSL Binaries\n  * Running Hayabusa\n\n    * Scan Wizard\n\n      * Core Rules\n      * Core+ Rules\n      * Core++ Rules\n      * Emerging Threats (ET) Add-On Rules\n      * Threat Hunting (TH) Add-On Rules\n    * Caution: Anti-Virus/EDR Warnings and Slow Runtimes\n    * Windows\n\n      * Error when trying to scan a file or directory with a space in the path\n    * Linux\n    * macOS\n  * Command List\n\n    * Analysis Commands:\n    * DFIR Timeline Commands:\n    * General Commands:\n  * Command Usage\n\n    * Analysis Commands\n\n      * computer-metrics command\n\n        * computer-metrics command examples\n        * computer-metrics screenshot\n      * eid-metrics command\n\n        * eid-metrics command examples\n        * eid-metrics command config file\n        * eid-metrics screenshot\n      * logon-summary command\n\n        * logon-summary command examples\n        * logon-summary screenshots\n      * pivot-keywords-list command\n\n        * pivot-keywords-list command examples\n        * pivot-keywords-list config file\n      * search command\n\n        * search command examples\n        * search command config files\n    * DFIR Timeline Commands\n\n      * csv-timeline command\n\n        * csv-timeline command examples\n        * Advanced - GeoIP Log Enrichment\n\n          * GeoIP config file\n          * Automatic updates of GeoIP databases\n        * csv-timeline command config files\n      * json-timeline command\n\n        * json-timeline command examples and config files\n      * level-tuning command\n\n        * level-tuning command examples\n        * level-tuning config file\n      * list-profiles command\n      * set-default-profile command\n\n        * set-default-profile command examples\n      * update-rules command\n\n        * update-rules command example\n  * Timeline Output\n\n    * Output Profiles\n\n      * 1\\. minimal profile output\n      * 2\\. standard profile output\n      * 3\\. verbose profile output\n      * 4\\. all-field-info profile output\n      * 5\\. all-field-info-verbose profile output\n      * 6\\. super-verbose profile output\n      * 7\\. timesketch-minimal profile output\n      * 8\\. timesketch-verbose profile output\n      * Profile Comparison\n      * Profile Field Aliases\n\n        * Extra Profile Field Aliases\n    * Level Abbrevations\n    * MITRE ATT&CK Tactics Abbreviations\n    * Channel Abbreviations\n    * Other Abbreviations\n    * Progress Bar\n    * Color Output\n    * Results Summary\n\n      * Detection Fequency Timeline\n  * Hayabusa Rules\n\n    * Sigma v.s. Hayabusa (Built-in Sigma Compatible) Rules\n  * Other Windows Event Log Analyzers and Related Resources\n  * Windows Logging Recommendations\n  * Sysmon Related Projects\n  * Community Documentation\n\n    * English\n    * Japanese\n  * Contribution\n  * Bug Submission\n  * License\n  * Twitter\n\n## Main Goals\n\n### Threat Hunting and Enterprise-wide DFIR\n\nHayabusa currently has over 4000 Sigma rules and over 170 Hayabusa built-in\ndetection rules with more rules being added regularly. It can be used for\nenterprise-wide proactive threat hunting as well as DFIR (Digital Forensics\nand Incident Response) for free with Velociraptor's Hayabusa artifact. By\ncombining these two open-source tools, you can essentially retroactively\nreproduce a SIEM when there is no SIEM setup in the environment. You can learn\nabout how to do this by watching Eric Capuano's Velociraptor walkthrough here.\n\n### Fast Forensics Timeline Generation\n\nWindows event log analysis has traditionally been a very long and tedious\nprocess because Windows event logs are 1) in a data format that is hard to\nanalyze and 2) the majority of data is noise and not useful for\ninvestigations. Hayabusa's goal is to extract out only useful data and present\nit in a concise as possible easy-to-read format that is usable not only by\nprofessionally trained analysts but any Windows system administrator. Hayabusa\nhopes to let analysts get 80% of their work done in 20% of the time when\ncompared to traditional Windows event log analysis.\n\n# Screenshots\n\n## Startup\n\n## DFIR Timeline Terminal Output\n\n## Keyword Search Results\n\n## Detection Fequency Timeline (-T option)\n\n## Results Summary\n\n## HTML Results Summary (-H option)\n\n## DFIR Timeline Analysis in LibreOffice (-M Multiline Output)\n\n## DFIR Timeline Analysis in Timeline Explorer\n\n## Critical Alert Filtering and Computer Grouping in Timeline Explorer\n\n## Analysis with the Elastic Stack Dashboard\n\n## Analysis in Timesketch\n\n# Importing and Analyzing Timeline Results\n\nYou can learn how to analyze CSV timelines in Excel and Timeline Explorer\nhere.\n\nYou can learn how to import CSV files into Elastic Stack here.\n\nYou can learn how to import CSV files into Timesketch here.\n\n# Analyzing JSON-formatted results with JQ\n\nYou can learn how to analyze JSON-formatted results with jq here.\n\n# Features\n\n  * Cross-platform support: Windows, Linux, macOS.\n  * Developed in Rust to be memory safe and fast.\n  * Multi-thread support delivering up to a 5x speed improvement.\n  * Creates single easy-to-analyze timelines for forensic investigations and incident response.\n  * Threat hunting based on IoC signatures written in easy to read/create/edit YML based hayabusa rules.\n  * Sigma rule support to convert sigma rules to hayabusa rules.\n  * Currently it supports the most sigma rules compared to other similar tools and even supports count rules and new aggregators such as |equalsfield and |endswithfield.\n  * Computer metrics. (Useful for filtering on/out certain computers with a large amount of events.)\n  * Event ID metrics. (Useful for getting a picture of what types of events there are and for tuning your log settings.)\n  * Rule tuning configuration by excluding unneeded or noisy rules.\n  * MITRE ATT&CK mapping of tactics.\n  * Rule level tuning.\n  * Create a list of unique pivot keywords to quickly identify abnormal users, hostnames, processes, etc... as well as correlate events.\n  * Output all fields for more thorough investigations.\n  * Successful and failed logon summary.\n  * Enterprise-wide threat hunting and DFIR on all endpoints with Velociraptor.\n  * Output to CSV, JSON/JSONL and HTML Summary Reports.\n  * Daily Sigma rule updates.\n  * Support for JSON-formatted log input.\n  * Log field normalization. (Converting multiple fields with different naming conventions into the same field name.)\n  * Log enrichment by adding GeoIP (ASN, city, country) information to IP addresses.\n  * Search all events for keywords or regular expressions.\n  * Field data mapping. (Ex: 0xc0000234 -> ACCOUNT LOCKED)\n  * Evtx record carving from evtx slack space.\n  * Event de-duplication when outputting. (Useful when recovery records is enabled or when you include backed up evtx files, evtx files from VSS, etc...)\n  * Scan setting wizard to help choose which rules to enable easier. (In order to reduce false positives, etc...)\n  * PowerShell classic log field parsing and extraction.\n  * Low memory mode. (Note: this is possible by not sorting results. Good for running on agents or big data.)\n\n# Downloads\n\nPlease download the latest stable version of Hayabusa with compiled binaries\nor compile the source code from the Releases page.\n\n# Git Cloning\n\nYou can git clone the repository with the following command and compile binary\nfrom source code:\n\nWarning: The main branch of the repository is for development purposes so you\nmay be able to access new features not yet officially released, however, there\nmay be bugs so consider it unstable.\n\n    \n    \n    git clone https://github.com/Yamato-Security/hayabusa.git --recursive\n\n> Note: If you forget to use --recursive option, the rules folder, which is\n> managed as a git submodule, will not be cloned.\n\nYou can sync the rules folder and get latest Hayabusa rules with git pull\n--recurse-submodules or use the following command:\n\n    \n    \n    hayabusa.exe update-rules\n\nIf the update fails, you may need to rename the rules folder and try again.\n\n> > Caution: When updating, rules and config files in the rules folder are\n> replaced with the latest rules and config files in the hayabusa-rules\n> repository. Any changes you make to existing files will be overwritten, so\n> we recommend that you make backups of any files that you edit before\n> updating. If you are performing level tuning with level-tuning, please re-\n> tune your rule files after each update. If you add new rules inside of the\n> rules folder, they will not be overwritten or deleted when updating.\n\n# Advanced: Compiling From Source (Optional)\n\nIf you have Rust installed, you can compile from source with the following\ncommand:\n\nNote: To compile, you usually need the latest version of Rust.\n\n    \n    \n    cargo build --release\n\nYou can download the latest unstable version from the main branch or the\nlatest stable version from the Releases page.\n\nBe sure to periodically update Rust with:\n\n    \n    \n    rustup update stable\n\nThe compiled binary will be outputted in the ./target/release folder.\n\n## Updating Rust Packages\n\nYou can update to the latest Rust crates before compiling:\n\n    \n    \n    cargo update\n\n> Please let us know if anything breaks after you update.\n\n## Cross-compiling 32-bit Windows Binaries\n\nYou can create 32-bit binaries on 64-bit Windows systems with the following:\n\n    \n    \n    rustup install stable-i686-pc-windows-msvc rustup target add i686-pc-windows-msvc rustup run stable-i686-pc-windows-msvc cargo build --release\n\n> Warning: Be sure to run rustup install stable-i686-pc-windows-msvc whenever\n> there is a new stable version of Rust as rustup update stable will not\n> update the compiler for cross compiling and you may receive build errors.\n\n## macOS Compiling Notes\n\nIf you receive compile errors about openssl, you will need to install Homebrew\nand then install the following packages:\n\n    \n    \n    brew install pkg-config brew install openssl\n\n## Linux Compiling Notes\n\nIf you receive compile errors about openssl, you will need to install the\nfollowing package.\n\nUbuntu-based distros:\n\n    \n    \n    sudo apt install libssl-dev\n\nFedora-based distros:\n\n    \n    \n    sudo yum install openssl-devel\n\n## Cross-compiling Linux MUSL Binaries\n\nOn a Linux OS, first install the target.\n\n    \n    \n    rustup install stable-x86_64-unknown-linux-musl rustup target add x86_64-unknown-linux-musl\n\nCompile with:\n\n    \n    \n    cargo build --release --target=x86_64-unknown-linux-musl\n\n> Warning: Be sure to run rustup install stable-x86_64-unknown-linux-musl\n> whenever there is a new stable version of Rust as rustup update stable will\n> not update the compiler for cross compiling and you may receive build\n> errors.\n\nThe MUSL binary will be created in the ./target/x86_64-unknown-linux-\nmusl/release/ directory. MUSL binaries are are about 15% slower than the GNU\nbinaries, however, they are more portable accross different versions and\ndistributions of linux.\n\n# Running Hayabusa\n\n## Scan Wizard\n\nCommands like csv-timeline and json-timeline now have a scan wizard enabled by\ndefault. This is intended to help users easily choose which detection rules\nthey want to enable according to their needs and preferences. The sets of\ndetections rules to load are based off of the official lists in the Sigma\nproject. Details are explained in this blog post. You can easily turn off the\nwizard and use Hayabusa in its traditional way by adding the -w, --no-wizard\noption.\n\n### Core Rules\n\nThe core rule set enables rules that have a status of test or stable and a\nlevel of high or critical. These are high quality rules of high confidence and\nrelevance and should not produce many false positives. The rule status is test\nor stable which means no false positives were reported for over 6 months.\nRules will match on attacker techniques, generic suspicious activity, or\nmalicious behavior. It is the same as using the --exclude-status\ndeprecated,unsupported,experimental --min-level high options.\n\n### Core+ Rules\n\nThe core+ rule set enables rules that have a status of test or stable and a\nlevel of medium or higher. medium rules most often need additional tuning as\ncertain applications, legitimate user behavior or scripts of an organization\nmight be matched. It is the same as using the --exclude-status\ndeprecated,unsupported,experimental --min-level medium options.\n\n### Core++ Rules\n\nThe core++ rule set enables rules that have a status of experimental, test or\nstable and a level of medium or higher. These rules are bleeding edge. They\nare validated against the baseline evtx files available at the SigmaHQ project\nand reviewed by multiple detection engineers. Other than that they are pretty\nmuch untested at first. Use these if you want to be able to detect threats as\nearly as possible at the cost of managing a higher threshold of false\npositives. It is the same as using the --exclude-status deprecated,unsupported\n--min-level medium options.\n\n### Emerging Threats (ET) Add-On Rules\n\nThe Emerging Threats (ET) rule set enables rules that have a tag of\ndetection.emerging_threats. These rules target specific threats and are\nespecially useful for current threats where not much information is available\nyet. These rules should not have many false positives but will decrease in\nrelevance over time. When these rules are not enabled, it is the same as using\nthe --exclude-tag detection.emerging_threats option. When running Hayabusa\ntraditionally without the wizard, these rules will be included by default.\n\n### Threat Hunting (TH) Add-On Rules\n\nThe Threat Hunting (TH) rule set enables rules that have a tag of\ndetection.threat_hunting. These rules may detect unknown malicious activity,\nhowever, will typicially have more false positives. When these rules are not\nenabled, it is the same as using the --exclude-tag detection.threat_hunting\noption. When running Hayabusa traditionally without the wizard, these rules\nwill be included by default.\n\n## Caution: Anti-Virus/EDR Warnings and Slow Runtimes\n\nYou may receive an alert from anti-virus or EDR products when trying to run\nhayabusa or even just when downloading the .yml rules as there will be\nkeywords like mimikatz and suspicious PowerShell commands in the detection\nsignature. These are false positives so will need to configure exclusions in\nyour security products to allow hayabusa to run. If you are worried about\nmalware or supply chain attacks, please check the hayabusa source code and\ncompile the binaries yourself.\n\nYou may experience slow runtime especially on the first run after a reboot due\nto the real-time protection of Windows Defender. You can avoid this by\ntemporarily turning real-time protection off or adding an exclusion to the\nhayabusa runtime directory. (Please take into consideration the security risks\nbefore doing these.)\n\n## Windows\n\nIn a Command/PowerShell Prompt or Windows Terminal, just run the appropriate\n32-bit or 64-bit Windows binary.\n\n### Error when trying to scan a file or directory with a space in the path\n\nWhen using the built-in Command or PowerShell prompt in Windows, you may\nreceive an error that Hayabusa was not able to load any .evtx files if there\nis a space in your file or directory path. In order to load the .evtx files\nproperly, be sure to do the following:\n\n  1. Enclose the file or directory path with double quotes.\n  2. If it is a directory path, make sure that you do not include a backslash for the last character.\n\n## Linux\n\nYou first need to make the binary executable.\n\n    \n    \n    chmod +x ./hayabusa\n\nThen run it from the Hayabusa root directory:\n\n    \n    \n    ./hayabusa\n\n## macOS\n\nFrom Terminal or iTerm2, you first need to make the binary executable.\n\n    \n    \n    chmod +x ./hayabusa\n\nThen, try to run it from the Hayabusa root directory:\n\n    \n    \n    ./hayabusa\n\nOn the latest version of macOS, you may receive the following security error\nwhen you try to run it:\n\nClick \"Cancel\" and then from System Preferences, open \"Security & Privacy\" and\nfrom the General tab, click \"Allow Anyway\".\n\nAfter that, try to run it again.\n\n    \n    \n    ./hayabusa\n\nThe following warning will pop up, so please click \"Open\".\n\nYou should now be able to run hayabusa.\n\n# Command List\n\n## Analysis Commands:\n\n  * computer-metrics: Print the number of events based on computer names.\n  * eid-metrics: Print the number and percentage of events based on Event ID.\n  * logon-summary: Print a summary of logon events.\n  * pivot-keywords-list: Print a list of suspicious keywords to pivot on.\n  * search: Search all events by keyword(s) or regular expressions\n\n## DFIR Timeline Commands:\n\n  * csv-timeline: Save the timeline in CSV format.\n  * json-timeline: Save the timeline in JSON/JSONL format.\n  * level-tuning: Custom tune the alerts' level.\n  * list-profiles: List the available output profiles.\n  * set-default-profile: Change the default profile.\n  * update-rules: Sync the rules to the latest rules in the hayabusa-rules GitHub repository.\n\n## General Commands:\n\n  * help: Print this message or the help of the given subcommand(s)\n  * list-contributors: Print the list of contributors\n\n# Command Usage\n\n## Analysis Commands\n\n### computer-metrics command\n\nYou can use the computer-metrics command to check how many events there are\naccording to each computer defined in the <System><Computer> field. Be aware\nthat you cannot completely rely on the Computer field for separating events by\ntheir original computer. Windows 11 will sometimes use completely different\nComputer names when saving to event logs. Also, Windows 10 will sometimes\nrecord the Computer name in all lowercase. This command does not use any\ndetection rules so will analyze all events. This is a good command to run to\nquickly see which computers have the most logs. With this information, you can\nthen use the --include-computer or --exclude-computer options when creating\nyour timelines to make your timeline generation more efficient by creating\nmultiple timelines according to computer or exclude events from certain\ncomputers.\n\n    \n    \n    Usage: computer-metrics <INPUT> [OPTIONS] Input: -d, --directory <DIR> Directory of multiple .evtx files -f, --file <FILE> File path to one .evtx file -l, --live-analysis Analyze the local C:\\Windows\\System32\\winevt\\Logs folder General Options: -C, --clobber Overwrite files when saving -h, --help Show the help menu -J, --JSON-input Scan JSON formatted logs instead of .evtx (.json or .jsonl) -Q, --quiet-errors Quiet errors mode: do not save error logs -x, --recover-records Carve evtx records from slack space (default: disabled) -c, --rules-config <DIR> Specify custom rule config directory (default: ./rules/config) --target-file-ext <FILE-EXT...> Specify additional evtx file extensions (ex: evtx_data) -t, --threads <NUMBER> Number of threads (default: optimal number for performance) Filtering: --timeline-offset <OFFSET> Scan recent events based on an offset (ex: 1y, 3M, 30d, 24h, 30m) Output: -o, --output <FILE> Save the results in CSV format (ex: computer-metrics.csv) Display Settings: --no-color Disable color output -q, --quiet Quiet mode: do not display the launch banner -v, --verbose Output verbose information\n\n#### computer-metrics command examples\n\n  * Print computer name metrics from a directory: hayabusa.exe computer-metrics -d ../logs\n  * Save results to a CSV file: hayabusa.exe computer-metrics -d ../logs -o computer-metrics.csv\n\n#### computer-metrics screenshot\n\n### eid-metrics command\n\nYou can use the eid-metrics command to print out the total number and\npercentage of event IDs (<System><EventID> field) seperated by channels. This\ncommand does not use any detection rules so will scan all events.\n\n    \n    \n    Usage: eid-metrics <INPUT> [OPTIONS] Input: -d, --directory <DIR> Directory of multiple .evtx files -f, --file <FILE> File path to one .evtx file -l, --live-analysis Analyze the local C:\\Windows\\System32\\winevt\\Logs folder General Options: -C, --clobber Overwrite files when saving -h, --help Show the help menu -J, --JSON-input Scan JSON formatted logs instead of .evtx (.json or .jsonl) -Q, --quiet-errors Quiet errors mode: do not save error logs -x, --recover-records Carve evtx records from slack space (default: disabled) -c, --rules-config <DIR> Specify custom rule config directory (default: ./rules/config) --target-file-ext <FILE-EXT...> Specify additional evtx file extensions (ex: evtx_data) -t, --threads <NUMBER> Number of threads (default: optimal number for performance) Filtering: --exclude-computer <COMPUTER...> Do not scan specified computer names (ex: ComputerA) (ex: ComputerA,ComputerB) --include-computer <COMPUTER...> Scan only specified computer names (ex: ComputerA) (ex: ComputerA,ComputerB) --timeline-offset <OFFSET> Scan recent events based on an offset (ex: 1y, 3M, 30d, 24h, 30m) Output: -o, --output <FILE> Save the Metrics in CSV format (ex: metrics.csv) Display Settings: --no-color Disable color output -q, --quiet Quiet mode: do not display the launch banner -v, --verbose Output verbose information Time Format: --European-time Output timestamp in European time format (ex: 22-02-2022 22:00:00.123 +02:00) --ISO-8601 Output timestamp in ISO-8601 format (ex: 2022-02-22T10:10:10.1234567Z) (Always UTC) --RFC-2822 Output timestamp in RFC 2822 format (ex: Fri, 22 Feb 2022 22:00:00 -0600) --RFC-3339 Output timestamp in RFC 3339 format (ex: 2022-02-22 22:00:00.123456-06:00) --US-military-time Output timestamp in US military time format (ex: 02-22-2022 22:00:00.123 -06:00) --US-time Output timestamp in US time format (ex: 02-22-2022 10:00:00.123 PM -06:00) -U, --UTC Output time in UTC format (default: local time)\n\n#### eid-metrics command examples\n\n  * Print Event ID metrics from a single file: hayabusa.exe eid-metrics -f Security.evtx\n  * Print Event ID metrics from a directory: hayabusa.exe eid-metrics -d ../logs\n  * Save results to a CSV file: hayabusa.exe eid-metrics -f Security.evtx -o eid-metrics.csv\n\n#### eid-metrics command config file\n\nThe channel, event IDs and titles of the events are defined in\nrules/config/channel_eid_info.txt.\n\nExample:\n\n    \n    \n    Channel,EventID,EventTitle Microsoft-Windows-Sysmon/Operational,1,Process Creation. Microsoft-Windows-Sysmon/Operational,2,File Creation Timestamp Changed. (Possible Timestomping) Microsoft-Windows-Sysmon/Operational,3,Network Connection. Microsoft-Windows-Sysmon/Operational,4,Sysmon Service State Changed.\n\n#### eid-metrics screenshot\n\n### logon-summary command\n\nYou can use the logon-summary command to output logon information summary\n(logon usernames and successful and failed logon count). You can display the\nlogon information for one evtx file with -f or multiple evtx files with the -d\noption.\n\n    \n    \n    Usage: logon-summary <INPUT> [OPTIONS] Input: -d, --directory <DIR> Directory of multiple .evtx files -f, --file <FILE> File path to one .evtx file -l, --live-analysis Analyze the local C:\\Windows\\System32\\winevt\\Logs folder General Options: -C, --clobber Overwrite files when saving -h, --help Show the help menu -J, --JSON-input Scan JSON formatted logs instead of .evtx (.json or .jsonl) -Q, --quiet-errors Quiet errors mode: do not save error logs -x, --recover-records Carve evtx records from slack space (default: disabled) -c, --rules-config <DIR> Specify custom rule config directory (default: ./rules/config) --target-file-ext <FILE-EXT...> Specify additional evtx file extensions (ex: evtx_data) -t, --threads <NUMBER> Number of threads (default: optimal number for performance) Filtering: --exclude-computer <COMPUTER...> Do not scan specified computer names (ex: ComputerA) (ex: ComputerA,ComputerB) --include-computer <COMPUTER...> Scan only specified computer names (ex: ComputerA) (ex: ComputerA,ComputerB) --timeline-end <DATE> End time of the event logs to load (ex: \"2022-02-22 23:59:59 +09:00\") --timeline-offset <OFFSET> Scan recent events based on an offset (ex: 1y, 3M, 30d, 24h, 30m) --timeline-start <DATE> Start time of the event logs to load (ex: \"2020-02-22 00:00:00 +09:00\") Output: -o, --output <FILENAME-PREFIX> Save the logon summary to two CSV files (ex: -o logon-summary) Display Settings: --no-color Disable color output -q, --quiet Quiet mode: do not display the launch banner -v, --verbose Output verbose information Time Format: --European-time Output timestamp in European time format (ex: 22-02-2022 22:00:00.123 +02:00) --ISO-8601 Output timestamp in ISO-8601 format (ex: 2022-02-22T10:10:10.1234567Z) (Always UTC) --RFC-2822 Output timestamp in RFC 2822 format (ex: Fri, 22 Feb 2022 22:00:00 -0600) --RFC-3339 Output timestamp in RFC 3339 format (ex: 2022-02-22 22:00:00.123456-06:00) --US-military-time Output timestamp in US military time format (ex: 02-22-2022 22:00:00.123 -06:00) --US-time Output timestamp in US time format (ex: 02-22-2022 10:00:00.123 PM -06:00) -U, --UTC Output time in UTC format (default: local time)\n\n#### logon-summary command examples\n\n  * Print logon summary: hayabusa.exe logon-summary -f Security.evtx\n  * Save logon summary results: hayabusa.exe logon-summary -d ../logs -o logon-summary.csv\n\n#### logon-summary screenshots\n\n### pivot-keywords-list command\n\nYou can use the pivot-keywords-list command to create a list of unique pivot\nkeywords to quickly identify abnormal users, hostnames, processes, etc... as\nwell as correlate events.\n\nImportant: by default, hayabusa will return results from all events\n(informational and higher) so we highly recommend combining the pivot-\nkeywords-list command with the -m, --min-level option. For example, start off\nwith only creating keywords from critical alerts with -m critical and then\ncontinue with -m high, -m medium, etc... There will most likely be common\nkeywords in your results that will match on many normal events, so after\nmanually checking the results and creating a list of unique keywords in a\nsingle file, you can then create a narrowed down timeline of suspicious\nactivity with a command like grep -f keywords.txt timeline.csv.\n\n    \n    \n    Usage: pivot-keywords-list <INPUT> [OPTIONS] Input: -d, --directory <DIR> Directory of multiple .evtx files -f, --file <FILE> File path to one .evtx file -l, --live-analysis Analyze the local C:\\Windows\\System32\\winevt\\Logs folder General Options: -C, --clobber Overwrite files when saving -h, --help Show the help menu -J, --JSON-input Scan JSON formatted logs instead of .evtx (.json or .jsonl) -w, --no-wizard Do not ask questions. Scan for all events and alerts -Q, --quiet-errors Quiet errors mode: do not save error logs -x, --recover-records Carve evtx records from slack space (default: disabled) -c, --rules-config <DIR> Specify custom rule config directory (default: ./rules/config) --target-file-ext <FILE-EXT...> Specify additional evtx file extensions (ex: evtx_data) -t, --threads <NUMBER> Number of threads (default: optimal number for performance) Filtering: -E, --EID-filter Scan only common EIDs for faster speed (./rules/config/target_event_IDs.txt) -D, --enable-deprecated-rules Enable rules with a status of deprecated -n, --enable-noisy-rules Enable rules set to noisy (./rules/config/noisy_rules.txt) -u, --enable-unsupported-rules Enable rules with a status of unsupported -e, --exact-level <LEVEL> Only load rules with a specific level (informational, low, medium, high, critical) --exclude-computer <COMPUTER...> Do not scan specified computer names (ex: ComputerA) (ex: ComputerA,ComputerB) --exclude-eid <EID...> Do not scan specific EIDs for faster speed (ex: 1) (ex: 1,4688) --exclude-status <STATUS...> Do not load rules according to status (ex: experimental) (ex: stable,test) --exclude-tag <TAG...> Do not load rules with specific tags (ex: sysmon) --include-computer <COMPUTER...> Scan only specified computer names (ex: ComputerA) (ex: ComputerA,ComputerB) --include-eid <EID...> Scan only specified EIDs for faster speed (ex: 1) (ex: 1,4688) --include-status <STATUS...> Only load rules with specific status (ex: experimental) (ex: stable,test) --include-tag <TAG...> Only load rules with specific tags (ex: attack.execution,attack.discovery) -m, --min-level <LEVEL> Minimum level for rules to load (default: informational) --timeline-end <DATE> End time of the event logs to load (ex: \"2022-02-22 23:59:59 +09:00\") --timeline-offset <OFFSET> Scan recent events based on an offset (ex: 1y, 3M, 30d, 24h, 30m) --timeline-start <DATE> Start time of the event logs to load (ex: \"2020-02-22 00:00:00 +09:00\") Output: -o, --output <FILENAME-PREFIX> Save pivot words to separate files (ex: PivotKeywords) Display Settings: --no-color Disable color output -q, --quiet Quiet mode: do not display the launch banner -v, --verbose Output verbose information\n\n#### pivot-keywords-list command examples\n\n  * Output pivot keywords to screen: hayabusa.exe pivot-keywords-list -d ../logs -m critical\n  * Create a list of pivot keywords from critical alerts and save the results. (Results will be saved to keywords-Ip Addresses.txt, keywords-Users.txt, etc...):\n\n    \n    \n    hayabusa.exe pivot-keywords-list -d ../logs -m critical -o keywords`\n\n#### pivot-keywords-list config file\n\nYou can customize what keywords you want to search for by editing\n./rules/config/pivot_keywords.txt. This page is the default setting.\n\nThe format is KeywordName.FieldName. For example, when creating the list of\nUsers, hayabusa will list up all the values in the SubjectUserName,\nTargetUserName and User fields.\n\n### search command\n\nThe search command will let you keyword search on all events. (Not just\nHayabusa detection results.) This is useful to determine if there is any\nevidence in events that are not detected by Hayabusa.\n\n    \n    \n    Usage: hayabusa.exe search <INPUT> <--keywords \"<KEYWORDS>\" OR --regex \"<REGEX>\"> [OPTIONS] Display Settings: --no-color Disable color output -q, --quiet Quiet mode: do not display the launch banner -v, --verbose Output verbose information General Options: -C, --clobber Overwrite files when saving -h, --help Show the help menu -Q, --quiet-errors Quiet errors mode: do not save error logs -x, --recover-records Carve evtx records from slack space (default: disabled) -c, --rules-config <DIR> Specify custom rule config directory (default: ./rules/config) --target-file-ext <FILE-EXT...> Specify additional evtx file extensions (ex: evtx_data) -t, --threads <NUMBER> Number of threads (default: optimal number for performance) Input: -d, --directory <DIR> Directory of multiple .evtx files -f, --file <FILE> File path to one .evtx file -l, --live-analysis Analyze the local C:\\Windows\\System32\\winevt\\Logs folder Filtering: -a, --and-logic Search keywords with AND logic (default: OR) -F, --filter <FILTER...> Filter by specific field(s) -i, --ignore-case Case-insensitive keyword search -k, --keyword <KEYWORD...> Search by keyword(s) -r, --regex <REGEX> Search by regular expression --timeline-offset <OFFSET> Scan recent events based on an offset (ex: 1y, 3M, 30d, 24h, 30m) Output: -J, --JSON-output Save the search results in JSON format (ex: -J -o results.json) -L, --JSONL-output Save the search results in JSONL format (ex: -L -o results.jsonl) -M, --multiline Output event field information in multiple rows for CSV output -o, --output <FILE> Save the search results in CSV format (ex: search.csv) Time Format: --European-time Output timestamp in European time format (ex: 22-02-2022 22:00:00.123 +02:00) --ISO-8601 Output timestamp in ISO-8601 format (ex: 2022-02-22T10:10:10.1234567Z) (Always UTC) --RFC-2822 Output timestamp in RFC 2822 format (ex: Fri, 22 Feb 2022 22:00:00 -0600) --RFC-3339 Output timestamp in RFC 3339 format (ex: 2022-02-22 22:00:00.123456-06:00) --US-military-time Output timestamp in US military time format (ex: 02-22-2022 22:00:00.123 -06:00) --US-time Output timestamp in US time format (ex: 02-22-2022 10:00:00.123 PM -06:00) -U, --UTC Output time in UTC format (default: local time)\n\n#### search command examples\n\n  * Search the ../hayabusa-sample-evtx directory for the keyword mimikatz:\n\n    \n    \n    hayabusa.exe search -d ../hayabusa-sample-evtx -k \"mimikatz\"\n\n> Note: The keyword will match if mimikatz is found anywhere in the data. It\n> is not an exact match.\n\n  * Search the ../hayabusa-sample-evtx directory for the keywords mimikatz or kali:\n\n    \n    \n    hayabusa.exe search -d ../hayabusa-sample-evtx -k \"mimikatz\" -k \"kali\"\n\n  * Search the ../hayabusa-sample-evtx directory for the keyword mimikatz and ignore case:\n\n    \n    \n    hayabusa.exe search -d ../hayabusa-sample-evtx -k \"mimikatz\" -i\n\n  * Search the ../hayabusa-sample-evtx directory for IP addresses using regular expressions:\n\n    \n    \n    hayabusa.exe search -d ../hayabusa-sample-evtx -r \"(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\"\n\n  * Search the ../hayabusa-sample-evtx directory and show all events where the WorkstationName field is kali:\n\n    \n    \n    hayabusa.exe search -d ../hayabusa-sample-evtx -r \".*\" -F WorkstationName:\"kali\"\n\n> Note: .* is the regular expression to match on every event.\n\n#### search command config files\n\n./rules/config/channel_abbreviations.txt: Mappings of channel names and their\nabbreviations.\n\n## DFIR Timeline Commands\n\n### csv-timeline command\n\nThe csv-timeline command will create a forensics timeline of events in CSV\nformat.\n\n    \n    \n    Usage: csv-timeline <INPUT> [OPTIONS] Input: -d, --directory <DIR> Directory of multiple .evtx files -f, --file <FILE> File path to one .evtx file -l, --live-analysis Analyze the local C:\\Windows\\System32\\winevt\\Logs folder General Options: -C, --clobber Overwrite files when saving -h, --help Show the help menu -J, --JSON-input Scan JSON formatted logs instead of .evtx (.json or .jsonl) -s, --low-memory-mode Scan with the minimal amount of memory by not sorting events -w, --no-wizard Do not ask questions. Scan for all events and alerts -Q, --quiet-errors Quiet errors mode: do not save error logs -x, --recover-records Carve evtx records from slack space (default: disabled) -r, --rules <DIR/FILE> Specify a custom rule directory or file (default: ./rules) -c, --rules-config <DIR> Specify custom rule config directory (default: ./rules/config) --target-file-ext <FILE-EXT...> Specify additional evtx file extensions (ex: evtx_data) -t, --threads <NUMBER> Number of threads (default: optimal number for performance) Filtering: -E, --EID-filter Scan only common EIDs for faster speed (./rules/config/target_event_IDs.txt) -D, --enable-deprecated-rules Enable rules with a status of deprecated -n, --enable-noisy-rules Enable rules set to noisy (./rules/config/noisy_rules.txt) -u, --enable-unsupported-rules Enable rules with a status of unsupported -e, --exact-level <LEVEL> Only load rules with a specific level (informational, low, medium, high, critical) --exclude-category <CATEGORY...> Do not load rules with specified logsource categories (ex: process_creation,pipe_created) --exclude-computer <COMPUTER...> Do not scan specified computer names (ex: ComputerA) (ex: ComputerA,ComputerB) --exclude-eid <EID...> Do not scan specific EIDs for faster speed (ex: 1) (ex: 1,4688) --exclude-status <STATUS...> Do not load rules according to status (ex: experimental) (ex: stable,test) --exclude-tag <TAG...> Do not load rules with specific tags (ex: sysmon) --include-category <CATEGORY...> Only load rules with specified logsource categories (ex: process_creation,pipe_created) --include-computer <COMPUTER...> Scan only specified computer names (ex: ComputerA) (ex: ComputerA,ComputerB) --include-eid <EID...> Scan only specified EIDs for faster speed (ex: 1) (ex: 1,4688) --include-status <STATUS...> Only load rules with specific status (ex: experimental) (ex: stable,test) --include-tag <TAG...> Only load rules with specific tags (ex: attack.execution,attack.discovery) -m, --min-level <LEVEL> Minimum level for rules to load (default: informational) -P, --proven-rules Scan with only proven rules for faster speed (./rules/config/proven_rules.txt) --timeline-end <DATE> End time of the event logs to load (ex: \"2022-02-22 23:59:59 +09:00\") --timeline-offset <OFFSET> Scan recent events based on an offset (ex: 1y, 3M, 30d, 24h, 30m) --timeline-start <DATE> Start time of the event logs to load (ex: \"2020-02-22 00:00:00 +09:00\") Output: -G, --GeoIP <MAXMIND-DB-DIR> Add GeoIP (ASN, city, country) info to IP addresses -H, --HTML-report <FILE> Save Results Summary details to an HTML report (ex: results.html) -M, --multiline Output event field information in multiple rows -F, --no-field-data-mapping Disable field data mapping --no-pwsh-field-extraction Disable field extraction of PowerShell classic logs -o, --output <FILE> Save the timeline in CSV format (ex: results.csv) -p, --profile <PROFILE> Specify output profile -R, --remove-duplicate-data Duplicate field data will be replaced with \"DUP\" -X, --remove-duplicate-detections Remove duplicate detections (default: disabled) Display Settings: --no-color Disable color output -N, --no-summary Do not display Results Summary for faster speed -q, --quiet Quiet mode: do not display the launch banner -v, --verbose Output verbose information -T, --visualize-timeline Output event frequency timeline (terminal needs to support unicode) Time Format: --European-time Output timestamp in European time format (ex: 22-02-2022 22:00:00.123 +02:00) --ISO-8601 Output timestamp in ISO-8601 format (ex: 2022-02-22T10:10:10.1234567Z) (Always UTC) --RFC-2822 Output timestamp in RFC 2822 format (ex: Fri, 22 Feb 2022 22:00:00 -0600) --RFC-3339 Output timestamp in RFC 3339 format (ex: 2022-02-22 22:00:00.123456-06:00) --US-military-time Output timestamp in US military time format (ex: 02-22-2022 22:00:00.123 -06:00) --US-time Output timestamp in US time format (ex: 02-22-2022 10:00:00.123 PM -06:00) -U, --UTC Output time in UTC format (default: local time)\n\n#### csv-timeline command examples\n\n  * Run hayabusa against one Windows event log file with default standard profile and --low-memory-mode:\n\n> Note: Results will not be sorted when using -s, --low-memory-mode. This is\n> because the results are outputted to screen or saved to a file as soon as\n> they are detected and then memory for the detection is freed. This results\n> in a significant reduction of memory (up to 95%) and is useful when running\n> Hayabusa as an agent or scanning large amounts of data. However, because\n> results are not saved in memory, it is not possible to use -R, --remove-\n> duplicate-data or -X, --remove-duplicate-detections when enabling low memory\n> mode.\n    \n    \n    hayabusa.exe csv-timeline -f eventlog.evtx --low-memory-mode\n\n  * Run hayabusa against the sample-evtx directory with multiple Windows event log files with the verbose profile:\n\n    \n    \n    hayabusa.exe csv-timeline -d .\\hayabusa-sample-evtx -p verbose\n\n  * Export to a single CSV file for further analysis with LibreOffice, Timeline Explorer, Elastic Stack, etc... and include all field information (Warning: your file output size will become much larger with the super-verbose profile!):\n\n    \n    \n    hayabusa.exe csv-timeline -d .\\hayabusa-sample-evtx -o results.csv -p super-verbose\n\n  * Enable the EID (Event ID) filter:\n\n> Note: Enabling the EID filter will speed up the analysis by about 10-15% in\n> our tests but there is a possibility of missing alerts.\n    \n    \n    hayabusa.exe csv-timeline -E -d .\\hayabusa-sample-evtx -o results.csv\n\n  * Only run hayabusa rules (the default is to run all the rules in -r .\\rules):\n\n    \n    \n    hayabusa.exe csv-timeline -d .\\hayabusa-sample-evtx -r .\\rules\\hayabusa -o results.csv -w\n\n  * Only run hayabusa rules for logs that are enabled by default on Windows:\n\n    \n    \n    hayabusa.exe csv-timeline -d .\\hayabusa-sample-evtx -r .\\rules\\hayabusa\\builtin -o results.csv -w\n\n  * Only run hayabusa rules for sysmon logs:\n\n    \n    \n    hayabusa.exe csv-timeline -d .\\hayabusa-sample-evtx -r .\\rules\\hayabusa\\sysmon -o results.csv -w\n\n  * Only run sigma rules:\n\n    \n    \n    hayabusa.exe csv-timeline -d .\\hayabusa-sample-evtx -r .\\rules\\sigma -o results.csv -w\n\n  * Enable deprecated rules (those with status marked as deprecated) and noisy rules (those whose rule ID is listed in .\\rules\\config\\noisy_rules.txt):\n\n> Note: Recently, deprecated rules are now located in a separate directory in\n> the sigma repository so are not included by default anymore in Hayabusa.\n> Therefore, you probably have no need to enable deprecated rules.\n    \n    \n    hayabusa.exe csv-timeline -d .\\hayabusa-sample-evtx --enable-noisy-rules --enable-deprecated-rules -o results.csv -w\n\n  * Only run rules to analyze logons and output in the UTC timezone:\n\n    \n    \n    hayabusa.exe csv-timeline -d .\\hayabusa-sample-evtx -r .\\rules\\hayabusa\\builtin\\Security\\LogonLogoff\\Logon -U -o results.csv -w\n\n  * Run on a live Windows machine (requires Administrator privileges) and only detect alerts (potentially malicious behavior):\n\n    \n    \n    hayabusa.exe csv-timeline -l -m low\n\n  * Print verbose information (useful for determining which files take long to process, parsing errors, etc...):\n\n    \n    \n    hayabusa.exe csv-timeline -d .\\hayabusa-sample-evtx -v\n\n  * Verbose output example:\n\nLoading rules:\n\n    \n    \n    Loaded rule: rules/sigma/builtin/deprecated/proc_creation_win_susp_run_folder.yml Loaded rule: rules/sigma/builtin/deprecated/proc_creation_win_execution_mssql_xp_cmdshell_stored_procedure.yml Loaded rule: rules/sigma/builtin/deprecated/proc_creation_win_susp_squirrel_lolbin.yml Loaded rule: rules/sigma/builtin/win_alert_mimikatz_keywords.yml\n\nErrors during the scan:\n\n    \n    \n    [ERROR] Failed to parse event file. EventFile: ../logs/Microsoft-Rdms-UI%4Operational.evtx Error: Failed to parse record number 58471 [ERROR] Failed to parse event file. EventFile: ../logs/Microsoft-Rdms-UI%4Operational.evtx Error: Failed to parse record number 58470 [ERROR] Failed to parse event file. EventFile: ../logs/Microsoft-Windows-AppxPackaging%4Operational.evtx Error: An error occurred while trying to serialize binary xml to output.\n\n  * Output to a CSV format compatible to import into Timesketch:\n\n    \n    \n    hayabusa.exe csv-timeline -d ../hayabusa-sample-evtx --RFC-3339 -o timesketch-import.csv -p timesketch -U\n\n  * Quiet error mode: By default, hayabusa will save error messages to error log files. If you do not want to save error messages, please add -Q.\n\n#### Advanced - GeoIP Log Enrichment\n\nYou can add GeoIP (ASN organization, city and country) information to SrcIP\n(source IP) fields and TgtIP (target IP) fields with the free GeoLite2\ngeolocation data.\n\nSteps:\n\n  1. First sign up for a MaxMind account here.\n  2. Download the three .mmdb files from the download page and save them to a directory. The filenames should be called GeoLite2-ASN.mmdb, GeoLite2-City.mmdb and GeoLite2-Country.mmdb.\n  3. When running the csv-timeline or json-timeline commands, add the -G option followed by the directory with the MaxMind databases.\n\n  * When csv-timeline is used, the following 6 columns will be additionally outputted: SrcASN, SrcCity, SrcCountry, TgtASN, TgtCity, TgtCountry.\n\n  * When json-timeline is used, the same SrcASN, SrcCity, SrcCountry, TgtASN, TgtCity, TgtCountry fields will be added to the Details object, but only if they contain information.\n\n  * When SrcIP or TgtIP is localhost (127.0.0.1, ::1, etc...), SrcASN or TgtASN will be outputted as Local.\n\n  * When SrcIP or TgtIP is a private IP address (10.0.0.0/8, fe80::/10, etc...), SrcASN or TgtASN will be outputted as Private.\n\n##### GeoIP config file\n\nThe field names that contain source and target IP addresses that get looked up\nin the GeoIP databases are defined in rules/config/geoip_field_mapping.yaml.\nYou can add to this list if necessary. There is also a filter section in this\nfile that determines what events to extract IP address information from.\n\n##### Automatic updates of GeoIP databases\n\nMaxMind GeoIP databases are updated every 2 weeks. You can install the MaxMind\ngeoipupdate tool here in order to automatically update these databases.\n\nSteps on macOS:\n\n  1. brew install geoipupdate\n  2. Edit /usr/local/etc/GeoIP.conf: Put in your AccountID and LicenseKey you create after logging into the MaxMind website. Make sure the EditionIDs line says EditionIDs GeoLite2-ASN GeoLite2-City GeoLite2-Country.\n  3. Run geoipupdate.\n  4. Add -G /usr/local/var/GeoIP when you want to add GeoIP information.\n\nSteps on Windows:\n\n  1. Download the latest Windows binary (Ex: geoipupdate_4.10.0_windows_amd64.zip) from the Releases page.\n  2. Edit \\ProgramData\\MaxMind/GeoIPUpdate\\GeoIP.conf: Put in your AccountID and LicenseKey you create after logging into the MaxMind website. Make sure the EditionIDs line says EditionIDs GeoLite2-ASN GeoLite2-City GeoLite2-Country.\n  3. Run the geoipupdate executable.\n\n#### csv-timeline command config files\n\n./rules/config/channel_abbreviations.txt: Mappings of channel names and their\nabbreviations.\n\n./rules/config/default_details.txt: The configuration file for what default\nfield information (%Details% field) should be outputted if no details: line is\nspecified in a rule. This is based on provider name and event IDs.\n\n./rules/config/eventkey_alias.txt: This file has the mappings of short name\naliases for fields and their original longer field names.\n\nExample:\n\n    \n    \n    InstanceID,Event.UserData.UMDFHostDeviceArrivalBegin.InstanceId IntegrityLevel,Event.EventData.IntegrityLevel IpAddress,Event.EventData.IpAddress\n\nIf a field is not defined here, Hayabusa will automatically check under\nEvent.EventData for the field.\n\n./rules/config/exclude_rules.txt: This file has a list of rule IDs that will\nbe excluded from use. Usually this is because one rule has replaced another or\nthe rule cannot be used in the first place. Like firewalls and IDSes, any\nsignature-based tool will require some tuning to fit your environment so you\nmay need to permanently or temporarily exclude certain rules. You can add a\nrule ID (Example: 4fe151c2-ecf9-4fae-95ae-b88ec9c2fca6) to\n./rules/config/exclude_rules.txt in order to ignore any rule that you do not\nneed or cannot be used.\n\n./rules/config/noisy_rules.txt: This file a list of rule IDs that are disabled\nby default but can be enabled by enabling noisy rules with the -n, --enable-\nnoisy-rules option. These rules are usually noisy by nature or due to false\npositives.\n\n./rules/config/target_event_IDs.txt: Only the event IDs specified in this file\nwill be scanned if the EID filter is enabled. By default, Hayabusa will scan\nall events, but if you want to improve performance, please use the -E, --EID-\nfilter option. This usually results in a 10~25% speed improvement.\n\n### json-timeline command\n\nThe json-timeline command will create a forensics timeline of events in JSON\nor JSONL format. Outputting to JSONL will be faster and smaller file size than\nJSON so is good if you are going to just import the results into another tool\nlike Elastic Stack. JSON is better if you are going to manually analyze the\nresults with a text editor. CSV output is good for importing smaller timelines\n(usually less than 2GB) into tools like LibreOffice or Timeline Explorer. JSON\nis best for more detailed analysis of data (including large results files)\nwith tools like jq as the Details fields are separated for easier analysis.\n(In the CSV output, all of the event log fields are in one big Details column\nmaking sorting of data, etc... more difficult.)\n\n    \n    \n    Usage: json-timeline <INPUT> [OPTIONS] Input: -d, --directory <DIR> Directory of multiple .evtx files -f, --file <FILE> File path to one .evtx file -l, --live-analysis Analyze the local C:\\Windows\\System32\\winevt\\Logs folder General Options: -C, --clobber Overwrite files when saving -h, --help Show the help menu -J, --JSON-input Scan JSON formatted logs instead of .evtx (.json or .jsonl) -s, --low-memory-mode Scan with the minimal amount of memory by not sorting events -w, --no-wizard Do not ask questions. Scan for all events and alerts -Q, --quiet-errors Quiet errors mode: do not save error logs -x, --recover-records Carve evtx records from slack space (default: disabled) -r, --rules <DIR/FILE> Specify a custom rule directory or file (default: ./rules) -c, --rules-config <DIR> Specify custom rule config directory (default: ./rules/config) --target-file-ext <FILE-EXT...> Specify additional evtx file extensions (ex: evtx_data) -t, --threads <NUMBER> Number of threads (default: optimal number for performance) Filtering: -E, --EID-filter Scan only common EIDs for faster speed (./rules/config/target_event_IDs.txt) -D, --enable-deprecated-rules Enable rules with a status of deprecated -n, --enable-noisy-rules Enable rules set to noisy (./rules/config/noisy_rules.txt) -u, --enable-unsupported-rules Enable rules with a status of unsupported -e, --exact-level <LEVEL> Only load rules with a specific level (informational, low, medium, high, critical) --exclude-category <CATEGORY...> Do not load rules with specified logsource categories (ex: process_creation,pipe_created) --exclude-computer <COMPUTER...> Do not scan specified computer names (ex: ComputerA) (ex: ComputerA,ComputerB) --exclude-eid <EID...> Do not scan specific EIDs for faster speed (ex: 1) (ex: 1,4688) --exclude-status <STATUS...> Do not load rules according to status (ex: experimental) (ex: stable,test) --exclude-tag <TAG...> Do not load rules with specific tags (ex: sysmon) --include-category <CATEGORY...> Only load rules with specified logsource categories (ex: process_creation,pipe_created) --include-computer <COMPUTER...> Scan only specified computer names (ex: ComputerA) (ex: ComputerA,ComputerB) --include-eid <EID...> Scan only specified EIDs for faster speed (ex: 1) (ex: 1,4688) --include-status <STATUS...> Only load rules with specific status (ex: experimental) (ex: stable,test) --include-tag <TAG...> Only load rules with specific tags (ex: attack.execution,attack.discovery) -m, --min-level <LEVEL> Minimum level for rules to load (default: informational) -P, --proven-rules Scan with only proven rules for faster speed (./rules/config/proven_rules.txt) --timeline-end <DATE> End time of the event logs to load (ex: \"2022-02-22 23:59:59 +09:00\") --timeline-offset <OFFSET> Scan recent events based on an offset (ex: 1y, 3M, 30d, 24h, 30m) --timeline-start <DATE> Start time of the event logs to load (ex: \"2020-02-22 00:00:00 +09:00\") Output: -G, --GeoIP <MAXMIND-DB-DIR> Add GeoIP (ASN, city, country) info to IP addresses -H, --HTML-report <FILE> Save Results Summary details to an HTML report (ex: results.html) -L, --JSONL-output Save the timeline in JSONL format (ex: -L -o results.jsonl) -F, --no-field-data-mapping Disable field data mapping --no-pwsh-field-extraction Disable field extraction of PowerShell classic logs -o, --output <FILE> Save the timeline in JSON format (ex: results.json) -p, --profile <PROFILE> Specify output profile -R, --remove-duplicate-data Duplicate field data will be replaced with \"DUP\" -X, --remove-duplicate-detections Remove duplicate detections (default: disabled) Display Settings: --no-color Disable color output -N, --no-summary Do not display Results Summary for faster speed -q, --quiet Quiet mode: do not display the launch banner -v, --verbose Output verbose information -T, --visualize-timeline Output event frequency timeline (terminal needs to support unicode) Time Format: --European-time Output timestamp in European time format (ex: 22-02-2022 22:00:00.123 +02:00) --ISO-8601 Output timestamp in ISO-8601 format (ex: 2022-02-22T10:10:10.1234567Z) (Always UTC) --RFC-2822 Output timestamp in RFC 2822 format (ex: Fri, 22 Feb 2022 22:00:00 -0600) --RFC-3339 Output timestamp in RFC 3339 format (ex: 2022-02-22 22:00:00.123456-06:00) --US-military-time Output timestamp in US military time format (ex: 02-22-2022 22:00:00.123 -06:00) --US-time Output timestamp in US time format (ex: 02-22-2022 10:00:00.123 PM -06:00) -U, --UTC Output time in UTC format (default: local time)\n\n#### json-timeline command examples and config files\n\nThe options and config files for json-timeline are the same as csv-timeline\nbut one extra option -L, --JSONL-output for outputting to JSONL format.\n\n### level-tuning command\n\nThe level-tuning command will let you tune the alert levels for rules, either\nraising or decreasing the risk level according to your environment.\n\n    \n    \n    Usage: level-tuning [OPTIONS] Display Settings: --no-color Disable color output -q, --quiet Quiet mode: do not display the launch banner General Options: -f, --file <FILE> Tune alert levels (default: ./rules/config/level_tuning.txt)\n\n#### level-tuning command examples\n\n  * Normal usage: hayabusa.exe level-tuning\n  * Tune rule alert levels based on your custom config file: hayabusa.exe level-tuning -f my_level_tuning.txt\n\n#### level-tuning config file\n\nHayabusa and Sigma rule authors will determine the risk level of the alert\nwhen writing their rules. However, the actual risk level may differ according\nto the environment. You can tune the risk level of the rules by adding them to\n./rules/config/level_tuning.txt and executing hayabusa.exe level-tuning which\nwill update the level line in the rule file. Please note that the rule file\nwill be updated directly.\n\n> Warning: Anytime you run update-rules, the original alert level will\n> overwrite any settings you have changed, so you will need to run the level-\n> tuning command after every time you run update-rules if you want to change\n> the levels.\n\n./rules/config/level_tuning.txt sample line:\n\n    \n    \n    id,new_level 00000000-0000-0000-0000-000000000000,informational # sample level tuning line\n\nIn this case, the risk level of the rule with an id of\n00000000-0000-0000-0000-000000000000 in the rules directory will have its\nlevel rewritten to informational. The possible levels to set are critical,\nhigh, medium, low and informational.\n\n### list-profiles command\n\n    \n    \n    Usage: list-profiles [OPTIONS] Display Settings: --no-color Disable color output -q, --quiet Quiet mode: do not display the launch banner\n\n### set-default-profile command\n\n    \n    \n    Usage: set-default-profile [OPTIONS] Display Settings: --no-color Disable color output -q, --quiet Quiet mode: do not display the launch banner General Options: -p, --profile <PROFILE> Specify output profile\n\n#### set-default-profile command examples\n\n  * Set the default profile to minimal: hayabusa.exe set-default-profile minimal\n  * Set the default profile to super-verbose: hayabusa.exe set-default-profile super-verbose\n\n### update-rules command\n\nThe update-rules command will sync the rules folder with the Hayabusa rules\ngithub repository, updating the rules and config files.\n\n    \n    \n    Usage: update-rules [OPTIONS] Display Settings: --no-color Disable color output -q, --quiet Quiet mode: do not display the launch banner General Options: -r, --rules <DIR/FILE> Specify a custom rule directory or file (default: ./rules)\n\n#### update-rules command example\n\nYou will normally just execute this: hayabusa.exe update-rules\n\n# Timeline Output\n\n## Output Profiles\n\nHayabusa has 5 pre-defined output profiles to use in config/profiles.yaml:\n\n  1. minimal\n  2. standard (default)\n  3. verbose\n  4. all-field-info\n  5. all-field-info-verbose\n  6. super-verbose\n  7. timesketch-minimal\n  8. timesketch-verbose\n\nYou can easily customize or add your own profiles by editing this file. You\ncan also easily change the default profile with set-default-profile --profile\n<profile>. Use the list-profiles command to show the available profiles and\ntheir field information.\n\n### 1\\. minimal profile output\n\n%Timestamp%, %Computer%, %Channel%, %EventID%, %Level%, %RecordID%,\n%RuleTitle%, %Details%\n\n### 2\\. standard profile output\n\n%Timestamp%, %Computer%, %Channel%, %EventID%, %Level%, %RecordID%,\n%RuleTitle%, %Details%, %ExtraFieldInfo%\n\n### 3\\. verbose profile output\n\n%Timestamp%, %Computer%, %Channel%, %EventID%, %Level%, %MitreTactics%,\n%MitreTags%, %OtherTags%, %RecordID%, %RuleTitle%, %Details%,\n%ExtraFieldInfo%, %RuleFile%, %EvtxFile%\n\n### 4\\. all-field-info profile output\n\nInstead of outputting the minimal details information, all field information\nin the EventData and UserData sections will be outputted along with their\noriginal field names.\n\n%Timestamp%, %Computer%, %Channel%, %EventID%, %Level%, %RecordID%,\n%RuleTitle%, %AllFieldInfo%, %RuleFile%, %EvtxFile%\n\n### 5\\. all-field-info-verbose profile output\n\n%Timestamp%, %Computer%, %Channel%, %EventID%, %Level%, %MitreTactics%,\n%MitreTags%, %OtherTags%, %RecordID%, %RuleTitle%, %AllFieldInfo%, %RuleFile%,\n%EvtxFile%\n\n### 6\\. super-verbose profile output\n\n%Timestamp%, %Computer%, %Channel%, %EventID%, %Level%, %RuleTitle%,\n%RuleAuthor%, %RuleModifiedDate%, %Status%, %RecordID%, %Details%,\n%ExtraFieldInfo%, %MitreTactics%, %MitreTags%, %OtherTags%, %Provider%,\n%RuleCreationDate%, %RuleFile%, %EvtxFile%\n\n### 7\\. timesketch-minimal profile output\n\nOutput to a format compatible with importing into Timesketch.\n\n%Timestamp%, hayabusa, %RuleTitle%, %Computer%, %Channel%, %EventID%, %Level%,\n%MitreTactics%, %MitreTags%, %OtherTags%, %RecordID%, %Details%, %RuleFile%,\n%EvtxFile%\n\n### 8\\. timesketch-verbose profile output\n\n%Timestamp%, hayabusa, %RuleTitle%, %Computer%, %Channel%, %EventID%, %Level%,\n%MitreTactics%, %MitreTags%, %OtherTags%, %RecordID%, %Details%,\n%ExtraFieldInfo%, %RuleFile%, %EvtxFile%\n\n### Profile Comparison\n\nThe following benchmarks were conducted on a 2018 Lenovo P51 (Xeon 4 Core CPU\n/ 64GB RAM) with 3GB of evtx data and 3891 rules enabled. (2023/06/01)\n\nProfile| Processing Time| Output Filesize| Filesize Increase  \n---|---|---|---  \nminimal| 8 minutes 50 seconds| 770 MB| -30%  \nstandard (default)| 9 minutes 00 seconds| 1.1 GB| None  \nverbose| 9 minutes 10 seconds| 1.3 GB| +20%  \nall-field-info| 9 minutes 3 seconds| 1.2 GB| +10%  \nall-field-info-verbose| 9 minutes 10 seconds| 1.3 GB| +20%  \nsuper-verbose| 9 minutes 12 seconds| 1.5 GB| +35%  \n  \n### Profile Field Aliases\n\nThe following information can be outputted with built-in output profiles:\n\nAlias name| Hayabusa output information  \n---|---  \n%AllFieldInfo%| All field information.  \n%Channel%| The name of log. <Event><System><Channel> field.  \n%Computer%| The <Event><System><Computer> field.  \n%Details%| The details field in the YML detection rule, however, only hayabusa\nrules have this field. This field gives extra information about the alert or\nevent and can extract useful data from the fields in event logs. For example,\nusernames, command line information, process information, etc... When a\nplaceholder points to a field that does not exist or there is an incorrect\nalias mapping, it will be outputted as n/a (not available). If the details\nfield is not specified (i.e. sigma rules), default details messages to extract\nfields defined in ./rules/config/default_details.txt will be outputted. You\ncan add more default details messages by adding the Provider Name, EventID and\ndetails message you want to output in default_details.txt. When no details\nfield is defined in a rule nor in default_details.txt, all fields will be\noutputted to the details column.  \n%ExtraFieldInfo%| Print the field information that was not outputted in\n%Details%.  \n%EventID%| The <Event><System><EventID> field.  \n%EvtxFile%| The evtx filename that caused the alert or event.  \n%Level%| The level field in the YML detection rule. (informational, low,\nmedium, high, critical)  \n%MitreTactics%| MITRE ATT&CK tactics (Ex: Initial Access, Lateral Movement,\netc...).  \n%MitreTags%| MITRE ATT&CK Group ID, Technique ID and Software ID.  \n%OtherTags%| Any keyword in the tags field in a YML detection rule which is\nnot included in MitreTactics or MitreTags.  \n%Provider%| The Name attribute in <Event><System><Provider> field.  \n%RecordID%| The Event Record ID from <Event><System><EventRecordID> field.  \n%RuleAuthor%| The author field in the YML detection rule.  \n%RuleCreationDate%| The date field in the YML detection rule.  \n%RuleFile%| The filename of the detection rule that generated the alert or\nevent.  \n%RuleModifiedDate%| The modified field in the YML detection rule.  \n%RuleTitle%| The title field in the YML detection rule.  \n%Status%| The status field in the YML detection rule.  \n%Timestamp%| Default is YYYY-MM-DD HH:mm:ss.sss +hh:mm format.\n<Event><System><TimeCreated SystemTime> field in the event log. The default\ntimezone will be the local timezone but you can change the timezone to UTC\nwith the --UTC option.  \n  \n#### Extra Profile Field Aliases\n\nYou can also add these extra aliases to your output profile if you need them:\n\nAlias name| Hayabusa output information  \n---|---  \n%RenderedMessage%| The <Event><RenderingInfo><Message> field in WEC forwarded\nlogs.  \n%RuleID%| The id field in the YML detection rule.  \n  \nNote: these are not included in any built in profiles so you will need to\nmanually edit the config/default_profile.yaml file and add the following\nlines:\n\n    \n    \n    Message: \"%RenderedMessage%\" RuleID: \"%RuleID%\"\n\nYou can also define event key aliases to output other fields.\n\n## Level Abbrevations\n\nIn order to save space, we use the following abbrevations when displaying the\nalert level.\n\n  * crit: critical\n  * high: high\n  * med : medium\n  * low : low\n  * info: informational\n\n## MITRE ATT&CK Tactics Abbreviations\n\nIn order to save space, we use the following abbreviations when displaying\nMITRE ATT&CK tactic tags. You can freely edit these abbreviations in the\n./config/mitre_tactics.txt configuration file.\n\n  * Recon : Reconnaissance\n  * ResDev : Resource Development\n  * InitAccess : Initial Access\n  * Exec : Execution\n  * Persis : Persistence\n  * PrivEsc : Privilege Escalation\n  * Evas : Defense Evasion\n  * CredAccess : Credential Access\n  * Disc : Discovery\n  * LatMov : Lateral Movement\n  * Collect : Collection\n  * C2 : Command and Control\n  * Exfil : Exfiltration\n  * Impact : Impact\n\n## Channel Abbreviations\n\nIn order to save space, we use the following abbreviations when displaying\nChannel. You can freely edit these abbreviations in the\n./rules/config/channel_abbreviations.txt configuration file.\n\n  * App : Application\n  * AppLocker : Microsoft-Windows-AppLocker/*\n  * BitsCli : Microsoft-Windows-Bits-Client/Operational\n  * CodeInteg : Microsoft-Windows-CodeIntegrity/Operational\n  * Defender : Microsoft-Windows-Windows Defender/Operational\n  * DHCP-Svr : Microsoft-Windows-DHCP-Server/Operational\n  * DNS-Svr : DNS Server\n  * DvrFmwk : Microsoft-Windows-DriverFrameworks-UserMode/Operational\n  * Exchange : MSExchange Management\n  * Firewall : Microsoft-Windows-Windows Firewall With Advanced Security/Firewall\n  * KeyMgtSvc : Key Management Service\n  * LDAP-Cli : Microsoft-Windows-LDAP-Client/Debug\n  * NTLM Microsoft-Windows-NTLM/Operational\n  * OpenSSH : OpenSSH/Operational\n  * PrintAdm : Microsoft-Windows-PrintService/Admin\n  * PrintOp : Microsoft-Windows-PrintService/Operational\n  * PwSh : Microsoft-Windows-PowerShell/Operational\n  * PwShClassic : Windows PowerShell\n  * RDP-Client : Microsoft-Windows-TerminalServices-RDPClient/Operational\n  * Sec : Security\n  * SecMitig : Microsoft-Windows-Security-Mitigations/*\n  * SmbCliSec : Microsoft-Windows-SmbClient/Security\n  * SvcBusCli : Microsoft-ServiceBus-Client\n  * Sys : System\n  * Sysmon : Microsoft-Windows-Sysmon/Operational\n  * TaskSch : Microsoft-Windows-TaskScheduler/Operational\n  * WinRM : Microsoft-Windows-WinRM/Operational\n  * WMI : Microsoft-Windows-WMI-Activity/Operational\n\n## Other Abbreviations\n\nThe following abbreviations are used in rules in order to make the output as\nconcise as possible:\n\n  * Acct -> Account\n  * Addr -> Address\n  * Auth -> Authentication\n  * Cli -> Client\n  * Chan -> Channel\n  * Cmd -> Command\n  * Cnt -> Count\n  * Comp -> Computer\n  * Conn -> Connection/Connected\n  * Creds -> Credentials\n  * Crit -> Critical\n  * Disconn -> Disconnection/Disconnected\n  * Dir -> Directory\n  * Drv -> Driver\n  * Dst -> Destination\n  * EID -> Event ID\n  * Err -> Error\n  * Exec -> Execution\n  * FW -> Firewall\n  * Grp -> Group\n  * Img -> Image\n  * Inj -> Injection\n  * Krb -> Kerberos\n  * LID -> Logon ID\n  * Med -> Medium\n  * Net -> Network\n  * Obj -> Object\n  * Op -> Operational/Operation\n  * Proto -> Protocol\n  * PW -> Password\n  * Reconn -> Reconnection\n  * Req -> Request\n  * Rsp -> Response\n  * Sess -> Session\n  * Sig -> Signature\n  * Susp -> Suspicious\n  * Src -> Source\n  * Svc -> Service\n  * Svr -> Server\n  * Temp -> Temporary\n  * Term -> Termination/Terminated\n  * Tkt -> Ticket\n  * Tgt -> Target\n  * Unkwn -> Unknown\n  * Usr -> User\n  * Perm -> Permament\n  * Pkg -> Package\n  * Priv -> Privilege\n  * Proc -> Process\n  * PID -> Process ID\n  * PGUID -> Process GUID (Global Unique ID)\n  * Ver -> Version\n\n## Progress Bar\n\nThe progress bar will only work with multiple evtx files. It will display in\nreal time the number and percent of evtx files that it has finished analyzing.\n\n## Color Output\n\nThe alerts will be outputted in color based on the alert level. You can change\nthe default colors in the config file at ./config/level_color.txt in the\nformat of level,(RGB 6-digit ColorHex). If you want to disable color output,\nyou can use --no-color option.\n\n## Results Summary\n\nTotal events, the number of events with hits, data reduction metrics, total\nand unique detections, dates with the most detections, top computers with\ndetections and top alerts are displayed after every scan.\n\n### Detection Fequency Timeline\n\nIf you add the -T, --visualize-timeline option, the Event Frequency Timeline\nfeature displays a sparkline frequency timeline of detected events. Note:\nThere needs to be more than 5 events. Also, the characters will not render\ncorrectly on the default Command Prompt or PowerShell Prompt, so please use a\nterminal like Windows Terminal, iTerm2, etc...\n\n# Hayabusa Rules\n\nHayabusa detection rules are written in a sigma-like YML format and are\nlocated in the rules folder. The rules are hosted at\nhttps://github.com/Yamato-Security/hayabusa-rules so please send any issues\nand pull requests for rules there instead of the main Hayabusa repository.\n\nPlease read the hayabusa-rules repository README to understand about the rule\nformat and how to create rules.\n\nAll of the rules from the hayabusa-rules repository should be placed in the\nrules folder. informational level rules are considered events, while anything\nwith a level of low and higher are considered alerts.\n\nThe hayabusa rule directory structure is separated into 2 directories:\n\n  * builtin: logs that can be generated by Windows built-in functionality.\n  * sysmon: logs that are generated by sysmon.\n\nRules are further seperated into directories by log type (Example: Security,\nSystem, etc...) and are named in the following format:\n\nPlease check out the current rules to use as a template in creating new ones\nor for checking the detection logic.\n\n## Sigma v.s. Hayabusa (Built-in Sigma Compatible) Rules\n\nHayabusa supports Sigma rules natively with a single exception of handling the\nlogsource fields internally. In order to reduce false positives, , Sigma rules\nshould be run through our convertor explained here. This will add the proper\nChannel and EventID, and perform field mapping for certain categories like\nprocess_creation.\n\nAlmost all Hayabusa rules are compatible with the Sigma format so you can use\nthem just like Sigma rules to convert to other SIEM formats. Hayabusa rules\nare designed solely for Windows event log analysis and have the following\nbenefits:\n\n  1. An extra details field to display additional information taken from only the useful fields in the log.\n  2. They are all tested against sample logs and are known to work.\n  3. Extra aggregators not found in sigma, such as |equalsfield and |endswithfield.\n\nTo our knowledge, hayabusa provides the greatest native support for sigma\nrules out of any open source Windows event log analysis tool.\n\n# Other Windows Event Log Analyzers and Related Resources\n\n  * AllthingsTimesketch - A NodeRED workflow that imports Plaso and Hayabusa results into Timesketch.\n  * APT-Hunter - Attack detection tool written in Python.\n  * Awesome Event IDs - Collection of Event ID resources useful for Digital Forensics and Incident Response\n  * Chainsaw - Another sigma-based attack detection tool written in Rust.\n  * DeepBlueCLI - Attack detection tool written in Powershell by Eric Conrad.\n  * Epagneul - Graph visualization for Windows event logs.\n  * EventList - Map security baseline event IDs to MITRE ATT&CK by Miriam Wiesner.\n  * Mapping MITRE ATT&CK with Window Event Log IDs - by Michel de CREVOISIER\n  * EvtxECmd - Evtx parser by Eric Zimmerman.\n  * EVTXtract - Recover EVTX log files from unallocated space and memory images.\n  * EvtxToElk - Python tool to send Evtx data to Elastic Stack.\n  * EVTX ATTACK Samples - EVTX attack sample event log files by SBousseaden.\n  * EVTX-to-MITRE-Attack - EVTX attack sample event log files mapped to ATT&CK by Michel de CREVOISIER\n  * EVTX parser - the Rust evtx library we use written by @OBenamram.\n  * Grafiki - Sysmon and PowerShell log visualizer.\n  * LogonTracer - A graphical interface to visualize logons to detect lateral movement by JPCERTCC.\n  * NSA Windows Event Monitoring Guidance - NSA's guide on what to monitor for.\n  * RustyBlue - Rust port of DeepBlueCLI by Yamato Security.\n  * Sigma - Community based generic SIEM rules.\n  * SOF-ELK - A pre-packaged VM with Elastic Stack to import data for DFIR analysis by Phil Hagen\n  * so-import-evtx - Import evtx files into Security Onion.\n  * SysmonTools - Configuration and off-line log visualization tool for Sysmon.\n  * Timeline Explorer - The best CSV timeline analyzer by Eric Zimmerman.\n  * Windows Event Log Analysis - Analyst Reference - by Forward Defense's Steve Anson.\n  * WELA (Windows Event Log Analyzer) - The swiff-army knife for Windows event logs by Yamato Security\n  * Zircolite - Sigma-based attack detection tool written in Python.\n\n# Windows Logging Recommendations\n\nIn order to properly detect malicious activity on Windows machines, you will\nneed to improve the default log settings. We have created a seperate project\nto document what log settings need to be enabled as well as scripts to\nautomatically enable the proper settings at https://github.com/Yamato-\nSecurity/EnableWindowsLogSettings.\n\nWe also recommend the following sites for guidance:\n\n  * JSCU-NL (Joint Sigint Cyber Unit Netherlands) Logging Essentials\n  * ACSC (Australian Cyber Security Centre) Logging and Fowarding Guide\n  * Malware Archaeology Cheat Sheets\n\n# Sysmon Related Projects\n\nTo create the most forensic evidence and detect with the highest accuracy, you\nneed to install sysmon. We recommend the following sites and config files:\n\n  * TrustedSec Sysmon Community Guide\n  * Sysmon Modular\n  * SwiftOnSecurity Sysmon Config\n  * SwiftOnSecurity Sysmon Config fork by Neo23x0\n  * SwiftOnSecurity Sysmon Config fork by ion-storm\n\n# Community Documentation\n\n## English\n\n  * 2023/12/11 Unleashing the Hayabusa Feathers: My Top Features Revealed! by Christian Henriksen\n  * 2023/10/16 Incident response and threat hunting using hayabusa tool by Md. Mahim Bin Firoj\n  * 2023/03/21 Find Threats in Event Logs with Hayabusa by Eric Capuano\n  * 2023/03/14 Rust Performance Guide for Hayabusa Developers by Fukusuke Takahashi\n  * 2022/06/19 Velociraptor Walkthrough and Hayabusa Integration by Eric Capuano\n  * 2022/01/24 Graphing Hayabusa results in neo4j by Matthew Seyer (@forensic_matt)\n\n## Japanese\n\n  * 2024/01/24 LME \u00d7 Hayabusa - Windows\u30a4\u30d9\u30f3\u30c8\u30ed\u30b0\u306e\u96c6\u7d04\u3068\u89e3\u6790\u306e\u52b9\u7387\u5316 by NEC Security Blog\n  * 2023/09/29 Fast Forensics with Hayabusa and Splunk by NEC Security Blog\n  * 2023/09/13 Windows Event Log Analysis with Hayabusa by FFRI\n  * 2022/03/14 Rust Performance Guide for Hayabusa Developers by Fukusuke Takahashi\n  * 2022/01/22 Visualizing Hayabusa results in Elastic Stack by @kzzzzo2\n  * 2021/12/31 Intro to Hayabusa by itiB (@itiB_S144)\n  * 2021/12/27 Hayabusa internals by Kazuminn (@k47_um1n)\n\n# Contribution\n\nWe would love any form of contribution. Pull requests, rule creation and\nsample evtx logs are the best but feature requests, notifying us of bugs,\netc... are also very welcome.\n\nAt the least, if you like our tool then please give us a star on GitHub and\nshow your support!\n\n# Bug Submission\n\nPlease submit any bugs you find here. This project is currently actively\nmaintained and we are happy to fix any bugs reported.\n\nIf you find any issues (false positives, bugs, etc...) with Hayabusa rules,\nplease report them to the hayabusa-rules GitHub issues page here.\n\nIf you find any issues (false positives, bugs, etc...) with Sigma rules,\nplease report them to the upstream SigmaHQ GitHub issues page here.\n\n# License\n\nHayabusa is released under GPLv3 and all rules are released under the\nDetection Rule License (DRL) 1.1.\n\nHayabusa uses GeoLite2 data created by MaxMind, available from\nhttps://www.maxmind.com.\n\n# Twitter\n\nYou can recieve the latest news about Hayabusa, rule updates, other Yamato\nSecurity tools, etc... by following us on Twitter at @SecurityYamato.\n\n## About\n\nHayabusa (\u96bc) is a sigma-based threat hunting and fast forensics timeline\ngenerator for Windows event logs.\n\n### Topics\n\nwindows rust security attack detection incident-response logs event threat\nforensics dfir cybersecurity response threat-hunting hunting sigma incident\nsecurity-automation yamato hayabusa\n\n### Resources\n\nReadme\n\n### License\n\nGPL-3.0 license\n\nActivity\n\nCustom properties\n\n### Stars\n\n1.9k stars\n\n### Watchers\n\n42 watching\n\n### Forks\n\n166 forks\n\nReport repository\n\n## Releases 45\n\nv2.15.0 \ud83e\udd85 Latest\n\nApr 20, 2024\n\n\\+ 44 releases\n\n## Packages 0\n\nNo packages published\n\n## Contributors 15\n\n## Languages\n\n  * Rust 100.0%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
