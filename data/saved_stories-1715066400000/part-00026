{"aid": "40281062", "title": "Why Full Text Search Is Hard", "url": "https://transactional.blog/blog/2023-why-full-text-search-is-hard", "domain": "transactional.blog", "votes": 3, "user": "thunderbong", "posted_at": "2024-05-07 00:34:19", "comments": 0, "source_title": "Why Full Text Search is Hard", "source_text": "Why Full Text Search is Hard\n\n\u21a4 S3-Compatible Cloud Storage Costs \u2191 Blog \u2191 dbdiag: ophistory \u21a6\n\n# Why Full Text Search is Hard\n\nPosted 2023-09-20\n\nIt\u2019s easy to find documents containing \"large\" and \"elephant\". It\u2019s hard to\nfind documents in German which have \"large\" and \"elephant\" together in a\nsentence, or words with similar meanings to large, and provide only the 10\nmost relevant documents.\n\n## Full Text Search\n\nFull text search comprises three things:\n\n  1. Tokenizing\n\n  2. Searching\n\n  3. Ranking\n\nAnd the sense that full-text search should be easy often stems from fixating\non the middle part of \"What\u2019s so hard about implementing an inverted index?\"\nand it\u2019s not. If the use-case is happy with the query being a set of words,\nand only documents with exact matches being returned, then that is a very\ntractable problem domain. It\u2019s all the challenges outside of that which are\nhard.\n\n## Tokenizing\n\nWhen a user searches for \"car wash\", should documents with \"washing cars\" in\nthem? If so, a stemming algorithm is now required to understand how to\nnormalize declined and conjugated words to a standard searchable form. Except\nnot all users speak English and not all documents are in English, so a stemmer\nper language is required. And each language introduces their own language-\nspecific challenges. Chinese, Japanese, and Korean don\u2019t have whitespace for\nword separation, so one needs a completely different way of identifying words\nthere (a \"CJK tokenizer\"). Don\u2019t forget that Thai doesn\u2019t use spaces around\nwords, but instead uses them to separate phrases or sentences. German well\nknown for its compound words, so those need to be split those apart. Russian\nis highly conjugated/declined and highly irregular. Hebrew needs normalization\nas letters can change based on position. Indian languages get written in\ninformal English phonetics rather than the \"proper\" e.g. telugu script.\nSupporting a global service for searches means supporting many languages, and\nthat\u2019s hard.\n\nEven within one language, should \"car washing\" return documents with \"car\ncleaning\" in them? Now an understanding of synonyms in a language is needed.\nShould \"the red cat\" return documents with \"the\" in it? Now an understanding\nof what words don\u2019t carry meaning (stop words) is needed. (And again, remember\nthat this is per language!)\n\n## Searching\n\nNow the set of words to search for have been determined. Each supplied search\nterm is treated as a conjunction in a filter, which means that there\u2019s\noptimization potential to use the most selective search terms first when\nconsulting the inverted index of terms. But being able to determine a good\norder requires statistics about frequencies of words before consulting the\nindex. Disjunction is the most frequently requested subsequent feature, so\nthat one can express term1 AND (term2 OR term3). This further complicates\ncalculating an optimal search term order. Proximity is often desired, so that\nif one searches for \"large elephant\", it\u2019s possible to express that those two\nwords should be closely related (ie. in the same sentence), but still support\nsome tolerance so that \"large, wild elephant\" matches. This pushes a strong\ndesire for having not just the document ID in the inverted index, but the\nposition of the word in the text as well. (I think legal search engines seem\nreasonably well known for providing a good set of features. Each additional\nsearch feature supported impacts on how the full text search solution will\nwant to try and index the data for those queries, and presents opportunities\nfor query optimization to try and evaluate complex queries optimally.\n\n## Ranking\n\nAfter retrieving all the matching documents from the index, you\u2019re then going\nto want to display them to the user according to some order. In the simplest\ncase, one could be like GMail and just have a simple \"more recent first\". Or\none could try to determine how relevant each document is to the user\u2019s query.\nClassically, BM25 was the most often used ranking algorithm, and often the\nimplementation would offer weights one could tweak to optimize the final\nranking. (Was the match in the title? Give it a 2x!) I\u2019ve been hearing of more\nand more cases of ranking instead utilizing machine learning techniques, as\nthen one is able to mine more detailed features out of each document and\nsignals from users as to what they consider to be relevant, to try to get\ncloser to what a human subjectively considers important. Training a ranking\nand relevancy model is not a simple matter.\n\n## Scale\n\nThe rest of the difficulty is just around how many documents are being\nsearched. If all documents fit within one postgres instance, then it\u2019s\noperationally straightforward. If the goal is to search the whole web, and\nresults should be returned in under 100ms, then that\u2019s significantly more\ndistributed systems and databases work to do.\n\n## Resources\n\nThe porter stemmer is a well known stemmer for English, and there\u2019s some nice\nexplanations of how it works. There\u2019s a number of lectures on Information\nRetrieval which provide a good explanation of inverted indexes. Elasticsearch\nhas a nice breakdown of what the bm25 formula means.\n\nIf you\u2019re interested in a comprehensive treatment of the topic, I\u2019ll suggest\nModern Information Retrieval as the definitive textbook.\n\n\u21a4 S3-Compatible Cloud Storage Costs \u2191 Blog \u2191 dbdiag: ophistory \u21a6\n\nSee discussion of this page on Reddit, HN, and lobsters.\n\n", "frontpage": false}
