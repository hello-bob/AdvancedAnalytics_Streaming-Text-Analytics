{"aid": "40204388", "title": "Reconciling Effective Altruism and E/acc", "url": "https://eriktorenberg.substack.com/p/reconciling-effective-altruism-and", "domain": "eriktorenberg.substack.com", "votes": 1, "user": "paulpauper", "posted_at": "2024-04-29 21:34:16", "comments": 0, "source_title": "Reconciling Effective Altruism and E/acc", "source_text": "Reconciling Effective Altruism and E/acc\n\n# Erik Torenberg\n\nShare this post\n\n#### Reconciling Effective Altruism and E/acc\n\neriktorenberg.substack.com\n\n#### Discover more from Erik Torenberg\n\nExplorations and inquiries into my curiosities: culture, politics, tech,\nbusiness, and human nature\n\nOver 12,000 subscribers\n\nContinue reading\n\nSign in\n\n# Reconciling Effective Altruism and E/acc\n\n### Uniting against the AI ethics tribe\n\nErik Torenberg\n\nApr 29, 2024\n\n3\n\nShare this post\n\n#### Reconciling Effective Altruism and E/acc\n\neriktorenberg.substack.com\n\n3\n\nShare\n\nHousekeeping: To honor Turpentine\u2019s ~1-year anniversary, we\u2019re releasing our\n1-pager master plan. Check it out here and subscribe to Turpentine company\nupdates here.\n\nI discussed EA and E/acc on Bankless this past week and thought I\u2019d write out\nmy thoughts in more long-form.\n\nEpistemic status: speculative, not my area of expertise\n\nEffective Altruism\u2019s reputation has taken a massive hit in the last two years.\nFairly or unfairly, the combination of SBF and the Open AI debacle made EA the\nbutt of all jokes and the supposed root of all problems. If SBF didn\u2019t kill EA\noutright, it seems like the Open AI debacle put the nail in the coffin,\nsomehow making Sam Altman look like an E/acc hero in the process, even though\nhe was previously criticized by E/accs for purportedly wanting regulatory\ncapture.\n\nAs a refresher, SBF was one of the main funders (and thus faces) of EA. While\nEA tried to distance itself from SBF after news of his fraud emerged, SBF was\nas EA as EA gets. It was as if EA bred him in a lab. He had been a loyal EA\nfollower since 2012, and he had dedicated his life to EA causes. Crypto was\njust a way for SBF to fund his EA goals. And he made money in the most EA way\npossible: arbitrage. EA is all about arbitraging philanthropically \u2014 if giving\none dollar can save 100 lives in Africa whereas only one in America, then it\u2019s\nworth redirecting that money to Africa. And so it\u2019s no coincidence SBF made\nhis initial money by arbitraging the price of bitcoin in Japan.\n\nEA\u2019s arbitrage as it relates to philanthropy, in my opinion, is one of its\nbiggest accomplishments. The trillions of dollars spent in philanthropy and\nthe non-profit sector is so emotionally driven that its outcomes are terrible.\nAnd EA in many ways has delivered the goods on the philanthropic front. While\nmany people criticize EA, it\u2019s also worth acknowledging its wins: Like saving\n200,000 lives. Or ending the torture of hundreds of millions of animals. Or\npreventing future pandemics.\n\nEA did this by deploying a \u2018Moneyball\u2019 approach to charity \u2014 evaluating\nphilanthropy the same way you\u2019d evaluate business investments.\n\nEA basically then scales that idea up and says can you apply that philosophy\nto all of humanity. And this is where we get EA\u2019s other major contribution:\nlong termism. It\u2019s not enough to think about a person's life in America vs a\npersons\u2019 life in Africa. We should also think about future people too, and\nvalue these unborn future people as much as we value people living today. And\nmake decisions with that calculus in mind.\n\nThe critique of that has always been the same as the critique of\nutilitarianism, which is that you get into a level of abstraction where you\nbasically start to play God. And you start to think that you can put things in\na spreadsheet that extrapolate out hundreds of years in the future with huge\nnumbers of variables. You start to think that you can re-engineer society on\nthat basis.\n\nAnd SBF is a famous example of where this utilitarianism goes wrong\u2014and he was\nshowing the extremity of his philosophy in broad daylight. There\u2019s this famous\nTyler Cowen interview with SBF where Tyler says, suppose you could roll the\ndice and with 51 percent odds, you\u2019d get another earth. But with 49 percent\nprobability, you would lose the one earth that you have \u2014 do you roll the\ndice? And Sam\u2019s like, from an EV perspective, of course you roll the dice. And\nthen Tyler\u2019s next question is, do you roll the dice again? And SBF says of\ncourse, you keep rolling the dice as long as it makes sense from an EV\nperspective. And so SBF literally applies this EV philosophy to running a\ncrypto exchange. He kept rolling the dice, even when it became incredibly\nrisky (and fraudulent) to do so. He was trying to optimize the future of all\nhumanity by trying to make a trillion dollars so that he would end up being\nable to solve all the world\u2019s problems. He almost did it, too! But alas, it\ndidn\u2019t quite work out in the end. Caroline, that snitch! Just kidding.\n\nSBF isn\u2019t the only person affiliated with EA who got in trouble for taking\nutilitarianism to its most extreme logical conclusion. Eliezer Yudkowsky has\nalso shared some repugnant conclusions of his own:\n\nThe problem with ethics by Excel spreadsheet, to paraphrase Antonio Garcia\nMartinez, is that at some point you need the moral infinities that you put\ninto the spreadsheet. Why don't you dice up newborns and harvest them for\norgans? Well, because Christianity says they're made in the image of God. Or\nsecular liberalism says they have human rights. Which is two different ways of\nsaying the exact same thing: humans are special in ways that the math can\u2019t\naccount for. And we can't just rob them of life, even if the math works out.\n\nUtilitarianism isn\u2019t a catch-all because the simple math tradeoffs only apply\nto the most trivial of problems. The real problems\u2014do we not have lockdowns\nand suffer old people dying so the young maybe go to school?\u2014aren't soluble\nvia 'hedon' calculations a la Bentham.\n\nAnother critique of EA is that it insists on making everything legible \u2014 EA\nviews illegibility as a problem to be solved, not as a fundamental condition\nof the universe. Of course, as we know from Goodhart\u2019s law, once a measure\nbecomes a target, it ceases to be a good measure.\n\nRelatedly, a lot of innovation can\u2019t be identified in advance. You can\u2019t\ncentrally plan it for the same reasons you can\u2019t centrally plan an economy.\nMichael Nielsen explained this well:\n\n> If you'd been an effective altruist in the 1660s trying to decide whether or\n> not to fund Isaac Newton, the theologian and astrologer and alchemist, he\n> had no legible project at all. It would have looked just very strange. You\n> would have had no way of making any sense of what he was doing in terms of\n> sort of an EV point of view, you know, he was laying the foundations for a\n> worldview that would enable the industrial revolution and a complete\n> transformation in what humanity was about.\n>\n> That's true for a lot of the things that have been the most impactful things\n> only made sense. After they were done, sometimes a long time after they were\n> done, we didn't understand the printing press until after it was done. We\n> certainly didn't understand writing or the alphabet, what those things meant\n> until a long time after I don't think I'm making much sense based on the\n> expression on your on your face, I'm trying to say, I think of expected\n> value calculations as things that you do when you understand your state\n> space really well and when, but most of the things which have mattered the\n> most.\n\nOf course, there are large numbers of examples where central planners thought\nthey were making the world a better place, and -- surprise surprise -- they\nweren't. We\u2019ve spent trillions of dollars in the last 60 years trying to\nreduce inequality with welfare, and it\u2019s been a disaster: The family formation\nrate has gotten significantly worse, we have a massive prison problem, and\ndisparities haven\u2019t been reduced. It\u2019s like the Seeing Like a State concept:\nWe've tried to mess with a complex system, not understanding how it operates,\nand instead introduced new second order effects that are even worse than the\noriginal problem.\n\nAnd EA is often about top-down central planning and rule by committee. Imagine\ntrying to argue for a new radical risky project on Less Wrong or Reddit. All\nof the Rational Discussion and Debate is just a thinly veiled rule by\ncommittee\u2014and nothing great was ever built by a committee.\n\nAnother critique is EA\u2019s insistence on impartiality. Implicit in the moral\narbitrage we mentioned earlier, where one dollar can more greatly improve an\nAfrican person\u2019s life vs an American person's life, is an assumption that we\nshould be impartial across geographic space and time. People living across the\nworld, the logic goes, shouldn\u2019t be any less important than people living next\ndoor. Or even people who aren\u2019t even born yet.\n\nThis of course is highly unnatural. We were raised in families and small\ntribes. It makes sense we would care about our tribe more than someone we\u2019ve\nnever met. But you can make a practical argument for localism too: The reason\nyou should give locally isn't only because you care more about your kid than\nyou do about the kid in the poor country who needs the bed net. It's also\nbecause you can actually find out what the effect is of your intervention. You\ncan see whether your kid's happy. You can see whether your intervention is\nworking. A bottoms up emergence utilizes local knowledge in a way that tops-\ndown planning can never do because it doesn\u2019t have access to all the\ninformation. It\u2019s Hayek\u2019s market theory applied to philanthropy.\n\nTyler Cowen explains the tension with impartiality well:\n\n> Let me just give you a simple example. I gave this to Will McCaskill in my\n> podcast with him, and I don't think he had any good answer to my question.\n> And I said to Will, well, Will, let's say aliens were invading the earth and\n> they were going to take us over, in some way enslave us or kill us and turn\n> over all of our resources to their own ends. I said, would you fight on our\n> side or would you first sit down and make a calculation as to whether the\n> aliens would be happier using those resources than we would be? Now, Will, I\n> think, didn't actually have an answer to this question. As an actual\n> psychological fact, virtually all of us would fight on the side of the\n> humans, even assuming we knew nothing about the aliens or even if we somehow\n> knew, well, they would be happier ruling over and enslaved planet earth than\n> we would be happy doing whatever we would do with planet earth. But there's\n> simply in our moral decisions some inescapable partiality.\n>\n> And let me bring this back to a very well-known philosophic conundrum taken\n> from Derek Parfit, namely the repugnant conclusion. Now Parfit's repugnant\n> conclusion asks the question, which I think you're all familiar with, like\n> should we prefer a world of 200 billion individuals who have lives as rich\n> as Goethe, Beethoven, whoever your exemplars might be, or should we prefer a\n> world of many, many trillions, make it as asymptotically large as you need\n> to be, many, many trillions of people, but living at the barest of levels\n> that make life worth living, Parfit referred to them as lives of musak and\n> potatoes. So in Parfit's vision of these lives, you wake up when you're\n> born, you hear a little bit of musak, maybe it's slightly above average\n> musak, they feed you a spoonful of potatoes, which you enjoy, and then you\n> perish. Now most people, because of Parfit's mere addition principle, would\n> admit there's some value in having this life of musak and potatoes compared\n> to no life at all, but if you think through mathematics, if you add up\n> enough of those lives, it would seem a sufficiently large number of those\n> lives is a better world than like the 200 billion people living like Goethe.\n>\n> I think the so-called answer, if you would call it that, some would call it\n> a non-answer, but it's Hume's observation that we cannot help but be\n> somewhat partial and prefer the lives of the recognizably human entities,\n> the 200 billion Goethes. We side against the repugnant conclusion. There's\n> not actually some formally correct utility calculation that should push us\n> in the opposite direction.\n\nIt\u2019s these kinds of repugnant conclusions that contribute to EA taking so much\nhate \u2014 and in so many contradictory ways. While no one can seem to agree on\nwhy they hate EA, everyone can agree that they hate it. Hating EA is a\nrallying and uniting force. It gets the people going. From a Scott Alexander\npiece:\n\n> \u201cSearch \u201ceffective altruism\u201d on social media right now, and it\u2019s pretty\n> grim.\n>\n> Socialists think we\u2019re sociopathic Randroid money-obsessed Silicon Valley\n> hypercapitalists.\n>\n> But Silicon Valley thinks we\u2019re all overregulation-loving authoritarian\n> communist bureaucrats.\n>\n> The right thinks we\u2019re all woke SJW extremists.\n>\n> But the left thinks we\u2019re all fascist white supremacists.\n>\n> The anti-AI people think we\u2019re the PR arm of AI companies, helping hype\n> their products by saying they\u2019re superintelligent at this very moment.\n>\n> But the pro-AI people think we want to ban all AI research forever and\n> nationalize all tech companies.\n>\n> The hippies think we\u2019re a totalizing ideology so hyper-obsessed with ethics\n> that we never have fun or live normal human lives.\n>\n> But the zealots think we\u2019re a grift who only pretend to care about about\n> charity, while we really spend all of our time feasting in castles.\n>\n> The bigshots think we\u2019re naive children who fall apart at our first contact\n> with real-world politics.\n>\n> But the journalists think we\u2019re a sinister conspiracy that has \u201ctaken over\n> Washington\u201d and have the whole Democratic Party in our pocket.\n\nEA is indeed a punching bag. I think it\u2019s because it lets itself be. EA people\ndon\u2019t defend themselves with the urgency to justify being treated any other\nway. They\u2019re just not built for it. They don\u2019t have that dawg in them. Their\nswag is insufficiently differentiated. Their smoke isn\u2019t tough enough. The\nvibes are off. You get the idea: EA people are incredibly bright, curious,\npolymathic, first-principled, into alternative lifestyles, high openness,\npsychedelics, etc, but also beta and cucked and not up for a fight and easy\npickings for attackers. Like libertarians before them, EAs just want to make\narguments, they don\u2019t actually want to do the dirty work of self-defense.\n\nAnd this is where E/acc comes in, because they are the foils to EA in many\nways, including their approach to public relations, though it\u2019s first worth\nmentioning that EA and E/acc agree on....almost everything. Like E/accs, EAs\nare also accelerationist on nearly everything other than AI safety \u2014 self-\ndriving cars, longevity, nuclear power \u2014 they\u2019re basically transhumanists.\nIronically, Effective Altruists are the ones that have have been criticized\nthe past decade for being too accelerationist, for thinking that everything\ncan be solved by technology and economic growth\n\nEAs and E/accs mostly just disagree on the topic of AI safety (which I\u2019ll\nfurther flesh out in a future post). Now, AI safety is a big topic, it\u2019s THE\ntopic of the moment, but it's still worth noting that there\u2019s agreement on\nnearly everything else. Calling EAs doomers or decels is effective in\ndestroying their reputation, but it belies the fact that EAs are mostly\ntechno-optimists and tech accelerationists.\n\nBUT there is one other thing they disagree on but they both don\u2019t want to say\nit. EA is, in practice, a democratic party affiliated movement. It\u2019s an Anti-\nTrump movement. Most EAs would scoff at this, given that they are supposed to\nbe first principled. And they\u2019re mostly libertarian. But there are no open\nTrump EAs that I can see. While they don\u2019t love Biden either, they\u2019ll vote for\nhim. Out of the many thousands of EAs, you\u2019d expect some intellectual\ndiversity? Most EAs are not politically tribal, but none will publicly say\nthey vote for Trump. And EA funders are very large democrat donors. Richard\nHanania wrote about how EA is woke. Another EA wrote about how EA sunk $200M\ndown the drain for \u2018prison reform\u2019 only to maybe make things worse.\n\nTo quote Antonio again, \u201cIt's shocking how the math always works out to\nactually support the average midwit liberal Democrats view....Somehow the math\nalways works out to support what is pretty normie Democratic Party beliefs.\nIt\u2019s amazing how the math just works out that way, right? \u201c\n\nE/acc by contrast is a (implicit) right-coded movement. It\u2019s a way for techies\nto code as right wing without conceding that they affiliate with Trump or the\nproles that support him. Elon will explicitly not say he\u2019s right wing, but the\nissues he draws attention to \u2014 immigration concerns, voter fraud, trans/social\nissues, anti-DEI \u2014 are all at least right-coded.\n\nAs mentioned, E/acc\u2019s approach to public relations is radically different than\nEA\u2019s approach. EA says \u201clet\u2019s have a polite debate\u201d. E/acc says \u201cfuck you,\nlet\u2019s build\u201d. E/acc offers unequivocal defenses of tech. EA hears someone call\nthem a tech bro and tries to prove that they\u2019re not like the tech bro\nstereotype. Nat Friedman gets the same critique and says \u201cShut the fuck up\u201d.\nThis difference illuminates a broader vibe shift in tech. After Facebook got\ncritiqued in 2016 post-Trump, Zuck apologized for things Facebook didn\u2019t even\ndo. He did a cross country tour and tried to apologize his way into\npopularity. It didn\u2019t work. After trying the beta way, he tried the alpha way.\nHe got jacked, he got into Brazilian Jiu Jitsu, and he challenged Elon to a\nfight.\n\nE/acc gets critiqued for being just about \u201cvibes\u201d, but there is some substance\nthere too. If EA is more around tops-down planning and legibility, E/acc is\nabout bottoms up, market-based adversarial competition as a check on\ncentralized control.\n\nE/acc is basically an impassioned plea to not have artificial monopolies\neither via the government or corporations through regulatory capture.\nVitalik\u2019s idea of D/acc is basically a fusion of E/acc and EA. It takes the\nE/acc approach of maximizing decentralization with the EA point of taking AI\nsafety seriously.\n\nIt\u2019s worth separating EA and E/acc from the AI ethics people who are concerned\nabout what they see as the problems of capitalism: broader inequality and\nperpetuation of group disparities they don\u2019t like. This is why Google Gemini\ndidn\u2019t show white people and why Open AI can\u2019t say positive things about Trump\nor can\u2019t even acknowledge that some people are more beautiful than others. AI\nEthics people are concerned about misinformation and hate speech and the\nproblems of capitalism. EAs and E/accs are not concerned about these problems.\nWhich is why I think EAs and E/accs should band together and fight the AI\nethics people, who\u2019s concerns are much better appreciated by the regulators\nmost likely to set strangling AI regulation. Instead, EA ends up being the\nbaptists to AI ethics\u2019 bootleggers. This of course won\u2019t help the people who\ntruly want to pause AI -- they\u2019re happy with AI being paused even if for the\nwrong reasons. This is only for the AI safetyists who believe we can figure\nout alignment and don\u2019t want to pause AI \u2014the people working at Open AI,\nAnthropic, and the like.\n\nIt is my belief that EA and E/acc need to reconcile with each other since they\nboth need each other to fight the AI ethics people. EA needs someone to defend\nit since it won\u2019t defend itself. E/acc needs EA because it needs to be able to\nself-critique/self-regulate until it can figure out alignment. Both of them\nalso need each other because they\u2019re both easy prey on their own.\n\nMe against my brother, me and my brother against my cousin \u2014 EA and E/acc\nagainst AI Ethics. Agree on 95% publicly to present a united front in\ndenouncing other concerns that could prematurely strangle AI development (e.g.\n\u201cbias\u201d), disagree on the 5% privately so we can hash out the best approach to\nAI alignment. This is the way.\n\n### Subscribe to Erik Torenberg\n\nLaunched 4 years ago\n\nExplorations and inquiries into my curiosities: culture, politics, tech,\nbusiness, and human nature\n\n3 Likes\n\n3\n\nShare this post\n\n#### Reconciling Effective Altruism and E/acc\n\neriktorenberg.substack.com\n\n3\n\nShare\n\n3 Comments\n\nMax MoreExtropic Thoughts4 hrs agoA really good piece. However, I found this\nbaffling: \"Like libertarians before them, EAs just want to make arguments,\nthey don\u2019t actually want to do the dirty work of self-defense.\" Libertarians\nare famously argumentative and not softies. Despite small numbers, they also\nengage in practice self-defense by funding and organizing policy foundations.\nThey are limited in their means of retaliation and opposition because they\noppose coercion. But I would hardly say they don't want to do the work of\nself-defense. If you mean that they don't push hard to take over academia and\neducation, fair enough, but that's just as true of Republicans. And\nlibertarians are such a small fraction of the population that such a move is\nunrealistic.Expand full commentLikeReplyShare  \n---  \n  \nAdham Bishr4 hrs agoI think this is a more legitimate criticism of e/acc -\nhttps://thezvi.substack.com/p/based-beff-jezos-and-the-accelerationistsCan we\nlive in a world with the burden of proof being on AI regulation but being\nthoughtful about the harm technology can do? As one critic of utilitarianism\npointed out \"What's the use of use?\" Are we accelerating just for the sake of\naccelerating?Always a fan of your writing.Expand full commentLikeReplyShare  \n---  \n  \n1 more comment...\n\nBuild Personal Moats\n\nMy favorite career advice\n\nSep 20, 2020 \u2022\n\nErik Torenberg\n\n145\n\nShare this post\n\n#### Build Personal Moats\n\neriktorenberg.substack.com\n\n18\n\nThe Hypocrisy of Elites\n\nEgalitarianism for thee, Elitism for me\n\nJul 16, 2022 \u2022\n\nErik Torenberg\n\n133\n\nShare this post\n\n#### The Hypocrisy of Elites\n\neriktorenberg.substack.com\n\n14\n\nOn Solitude\n\nOver 15 years ago, I took my first device-free, silent, solitude experience.\n15 years and 100s of \u201csolos\u201d later, I can say the following with...\n\nSep 26, 2021 \u2022\n\nErik Torenberg\n\n90\n\nShare this post\n\n#### On Solitude\n\neriktorenberg.substack.com\n\n9\n\nReady for more?\n\n\u00a9 2024 Erik Torenberg\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}
