{"aid": "40162915", "title": "Why AI is failing at giving good advice", "url": "https://maximzubarev.com/why-ai-is-failing-at-giving-good-advice", "domain": "maximzubarev.com", "votes": 4, "user": "mxmzb", "posted_at": "2024-04-25 20:56:24", "comments": 0, "source_title": "Why AI is failing at giving good advice", "source_text": "Maxim Zubarev\n\n# Why AI is failing at giving good advice\n\nPublished April 25th, 2024 \u2022 \u2615 4 min read\n\nTLDR: ChatGPT generates responses based on the highest mathematical\nprobabilities derived from existing texts on the internet. Popular advice (for\nvarious reasons) is seldomly good, nor (by definition) uniquely applicable,\nnor (mostly) founded on actual experience. You are probably better off taking\nadvice from a real person who can empathize and knows what they are talking\nabout.\n\nWhen you ask ChatGPT a question, something highly interesting happens:\n\nChatGPT, which has previously consumed half or more of the internet to build\nits language model, will translate your question into a mathematical\nrepresentation of numbers (e.g., a vector).\n\nI don't know in detail how they do it, and I am sure there are some layers in\nbetween and around that serve some specific purpose, but I understand that if\nyou google the phrase \"How are you?\", you can statistically expect a certain\nrange of words and sentences in the results around it. Most sentences\nfollowing the question will probably sound like \"I'm good, thanks\" or \"Doing\ngreat, how about you?\". Whereas if you search the internet for all occurrences\nof \"Integrated circuit\", you will usually find a very distinct set of words\nand sentences nearby, like \"silicon semiconductor,\" \"MOS transistor,\" or \"the\nvoltage requirement is 0.6V\".\n\nWith so much base data, you can assign a mathematical value (or direction) to\nevery word, change it when it appears together with other words (context), and\ncompute an entire, unique direction for a continuous piece of text.\n\nRealize the following (exemplified): Anyone who ever had success on the\ninternet writing articles (or anything else) in the broader sense of the\nuniverse just pressed a particular combination of buttons on their keyboard,\nand then more biological masses in the world started reading the outcome than\nother produced texts.\n\nIn a strange but very scientific way, when you ask ChatGPT a question, it\ntries to compute the exact combination of letters, words, and sentences based\non their previously computed values that it thinks you are looking for.\nAstonishingly enough, that is often a highly useful response in the real\nworld.\n\nBut this approach has problems, especially when you try to give someone good,\nspecific advice:\n\nThe outcome is, by definition, mathematical. It's probability, applied to man-\nmade text. The most propagated (related) text on the internet will likely be\nrepurposed in its own words to answer anything that you ask. Essentially, that\nmeans it might give you a mashed answer as you would get from the X first\nresults on Google, but it will fill in contextual gaps from other places and\nmake it more applicable to your specific input.\n\nIf most internet texts said the sky was yellow, ChatGPT would say so, too.\nSimilarly, suppose you ask ChatGPT the infamous question, \"How can I make\nmoney online quickly?\". In that case, you will get a shallow, unhelpful\nresponse (that will often stay unhelpful even if you drill down into\nspecifics).\n\nThis is not to say that everything is particularly \"wrong\" (although some\npoints are, according to most people's experience); it is just paraphrasing\nthose online bubbles of drop shippers, BuzzFeed listicles, and affiliate\nboards.\n\nFor example, almost everyone who has succeeded with YouTube or affiliate\nmarketing will tell you neither is quick. It takes years of work, dedication,\nand a fair pinch of scientific user analysis.\n\nEven if you ask it to walk you through making money step by step, it fails: In\nMarch 2023 (2 days after the release of version 4), a tweet caught fire that\ndocumented the usage of ChatGPT as a business owner, giving precise directions\nto make money (starting with $100):\n\n> I gave GPT-4 a budget of $100 and told it to make as much money as possible.\n>\n> I'm acting as its human liaison, buying anything it says to.\n>\n> Do you think it'll be able to make smart investments and build an online\n> business?\n>\n> Follow along \ud83d\udc40 pic.twitter.com/zu4nvgibiK\n>\n> \u2014 Jazz Fall (@JazzFall) March 15, 2023\n\nIt did make some money, but with millions and millions of views and even\nmainstream news covering the endeavor, I am hesitant to attribute the\ngenerated income to ChatGPT. The updates died out quickly, and two weeks\nlater, the official confirmation was posted that the project (and apparently,\nthe site) was sunsetted. It's not what a successful attempt to make money\nlooks like in my world.\n\nA Large Language Model can provide accurate answers if fed the correct base\ncontext (superseding the general knowledge base) and if you ask the right\nquestions. But even then, you need to find that respective chatbot and the\nquestions you must ask to get helpful answers (although the latter may apply\nto many human conversations, too).\n\nAt the current state of the internet, there is almost any educational\ninformation and advice already out there in some form, freely accessible to\neverybody, more than anyone could ever take action on in their lifetime.\nToday, the value of providing information is about more than just delivering\nit; it's about delivering the right information to the right people the right\nway. And LLMs fail at the former.\n\nThe bottom line is that AI is not yet capable of what a good teacher or mentor\ncan do: giving actually good, uniquely applicable, empathizing advice. It's\nmuch better at explaining things.\n\nPS.: This article was peer-reviewed and approved by ChatGPT. I ignored its\nsuggestion to add examples where it gave helpful advice because that's against\nmy agenda statistically, with enough advice given, you will just randomly run\ninto occasions where it gave good advice.\n\nPPS.: A big discourse was recently sparked by Pieter Levels, who built a\nmental therapist Telegram bot with AI. This article has been sitting in my\ndrafts for almost a year now and has absolutely nothing to do with that (I\nfeel that discussion is more ethic-, accountability-, and risk-based anyway,\nas opposed to this article's core message). The timing of this article's\npublication just after his tweet is coincidental.\n\nA personal publication by Maxim Zubarev. I use software as a leverage for\nbusiness.\n\nRSS\n\n", "frontpage": true}
