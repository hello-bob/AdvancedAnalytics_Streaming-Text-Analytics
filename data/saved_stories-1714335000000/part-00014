{"aid": "40188435", "title": "Malleable Software in the Age of LLMs (2023)", "url": "https://www.geoffreylitt.com/2023/03/25/llm-end-user-programming", "domain": "geoffreylitt.com", "votes": 2, "user": "danecjensen", "posted_at": "2024-04-28 13:28:28", "comments": 0, "source_title": "Malleable software in the age of LLMs", "source_text": "Malleable software in the age of LLMs\n\n### March 2023\n\n# Malleable software in the age of LLMs\n\nAll computer users may soon have the ability to author small bits of code.\nWhat structural changes does this imply for the production and distribution of\nsoftware?\n\nIt\u2019s been a wild few weeks for large language models. OpenAI released GPT-4,\nwhich shows impressive gains on a variety of capabilities including coding.\nMicrosoft Research released a paper showing how GPT-4 was able to produce\nquite sophisticated code like a 3D video game without much prompting at all.\nOpenAI also released plugins for ChatGPT, which are a productized version of\nthe ReAct tool usage pattern I played around with in my previous post about\nquerying NBA statistics using GPT.\n\nAmid all this chaos, many people are naturally wondering: how will LLMs affect\nthe creation of software?\n\nOne answer to that question is that LLMs will make skilled professional\ndevelopers more productive. This is a safe bet since GitHub Copilot has\nalready shown it\u2019s viable. It\u2019s also a comforting thought, because developers\ncan feel secure in their future job prospects, and it doesn\u2019t suggest\nstructural upheaval in the way software is produced or distributed \ud83d\ude09\n\nHowever, I suspect this won\u2019t be the whole picture. While I\u2019m confident that\nLLMs will become useful tools for professional programmers, I also think\nfocusing too much on that narrow use risks missing the potential for bigger\nchanges ahead.\n\nHere\u2019s why: I think it\u2019s likely that soon all computer users will have the\nability to develop small software tools from scratch, and to describe\nmodifications they\u2019d like made to software they\u2019re already using. In other\nwords, LLMs will represent a step change in tool support for end-user\nprogramming: the ability of normal people to fully harness the general power\nof computers without resorting to the complexity of normal programming. Until\nnow, that vision has been bottlenecked on turning fuzzy informal intent into\nformal, executable code; now that bottleneck is rapidly opening up thanks to\nLLMs.\n\nIf this hypothesis indeed comes true, we might start to see some surprising\nchanges in the way people use software:\n\n  * One-off scripts: Normal computer users have their AI create and execute scripts dozens of times a day, to perform tasks like data analysis, video editing, or automating tedious tasks.\n  * One-off GUIs: People use AI to create entire GUI applications just for performing a single specific task\u2014containing just the features they need, no bloat.\n  * Build don\u2019t buy: Businesses develop more software in-house that meets their custom needs, rather than buying SaaS off the shelf, since it\u2019s now cheaper to get software tailored to the use case.\n  * Modding/extensions: Consumers and businesses demand the ability to extend and mod their existing software, since it\u2019s now easier to specify a new feature or a tweak to match a user\u2019s workflow.\n  * Recombination: Take the best parts of the different applications you like best, and create a new hybrid that composes them together.\n\nAll of these changes would go beyond just making our current software\nproduction process faster. They would be changing when software gets created,\nby whom, for what purpose.\n\n## LLMs + malleable software: a series\n\nPhew, there\u2019s a lot to unpack here. \ud83d\ude05\n\nIn a series of posts starting with this one, I\u2019ll dig in and explore these\nkinds of broad changes LLMs might enable in the creation and distribution of\nsoftware, and even more generally in the way people interact with software.\nSome of the questions I\u2019ll cover include:\n\n  * Interaction models: Which interaction model will make sense for which tasks? When will people want a chatbot, a one-off script, or a custom throwaway GUI?\n  * Software customization: How might LLMs enable malleable software that can be taken apart, recombined, and extended by users?\n  * Intent specification: How will end-users work interactively with LLMs to specify their intent?\n  * Fuzzy translators: How might the fuzzy data translation capabilities of LLMs enable shared data substrates which weren\u2019t possible before?\n  * User empowerment: How should we think about empowerment and agency vs delegation and automation in the age of LLMs?\n\nIf you want to subscribe to get future posts about these ideas, you can sign\nup for my email newsletter or subscribe via RSS. Posts should be fairly\ninfrequent, monthly at most.\n\n## When to chatbot, when to not?\n\nToday, we\u2019ll start with a basic question: how will user interaction models\nevolve in the LLM era? In particular, what kinds of tasks might be taken over\nby chatbots? I think the answer matters a lot when we consider different ways\nto empower end-users.\n\nAs a preview of where this post is headed: I\u2019ll argue that, while ChatGPT is\nfar more capable than Siri, there are many tasks which aren\u2019t well-served by a\nchat UI, for which we still need graphical user interfaces. Then I\u2019ll discuss\nhybrid interaction models where LLMs help us construct UIs.\n\nBy the end, we\u2019ll arrive at a point in the design space I find intriguing:\nopen-ended computational media, directly learnable and moldable by users, with\nLLMs as collaborators within that media. And at that point this weird diagram\nwill make sense \ud83d\ude43:\n\nOne disclaimer before diving in: expect a lot of speculation and uncertainty.\nI\u2019m not even trying to predict how fast these changes will happen, since I\nhave no idea. The point is to imagine how a reasonable extrapolation from\ncurrent AI might support new kinds of interactions with computers, and how we\nmight apply this new technology to maximally empower end-users.\n\n## Opening up the programming bottleneck\n\nWhy might LLMs be a big deal for empowering users with computation?\n\nFor decades, pioneers of computing have been reaching towards a vision of end-\nuser programming: normal people harnessing the full, general power of\ncomputers, not just using prefabricated applications handed down to them by\nthe programmer elite. As Alan Kay wrote in 1984: \u201cWe now want to edit our\ntools as we have previously edited our documents.\u201d\n\nThere are many manifestations of this idea. Modern examples of end-user\nprogramming systems you may have used include spreadsheets, Airtable, Glide,\nor iOS Shortcuts. Older examples include HyperCard, Smalltalk, and Yahoo\nPipes. (See this excellent overview by my collaborators at Ink & Switch for a\nhistorical deep dive)\n\nAlthough some of these efforts have been quite successful, until now they\u2019ve\nalso been limited by a fundamental challenge: it\u2019s really hard to help people\nturn their rough ideas into formal executable code. System designers have\ntried super-high-level languages, friendly visual editors and better syntax,\nlayered levels of complexity, and automatically generating simple code from\nexamples. But it\u2019s proven hard to get past a certain ceiling of complexity\nwith these techniques.\n\nHere\u2019s one example of the programming bottleneck in my own work. A few years\nago, I developed an end-user programming system called Wildcard which would\nlet people customize any website through a spreadsheet interface. For example,\nin this short demo you can see a user sorting articles on Hacker News in a\ndifferent order, and then adding read times to the articles in the page, all\nby manipulating a spreadsheet synced with the webpage.\n\nNeat demo, right?\n\nBut if you look closely, there are two slightly awkward programming\nbottlenecks in this system. First, the user needs to be able to write small\nspreadsheet formulas to express computations. This is a lot easier than\nlearning a full-fledged programming language, but it\u2019s still a barrier to\ninitial usage. Second, behind the scenes, Wildcard requires site-specific\nscraping code (excerpt shown below) to connect the spreadsheet to the website.\nIn theory these adapters could be written and maintained by developers and\nshared among a community of end-users, but that\u2019s a lot of work.\n\nNow, with LLMs, these kinds of programming bottlenecks are less of a limiting\nfactor. Turning a natural language specification into web scraping code or a\nlittle spreadsheet formula is exactly the kind of code synthesis that current\nLLMs can already achieve. We could imagine having the LLM help with scraping\ncode and generating formulas, making it possible to achieve the demo above\nwithout anyone writing manual code. When I made Wildcard, this kind of program\nsynthesis was just a fantasy, and now it\u2019s rapidly becoming a reality.\n\nThis example also suggests a deeper question, though. If we have LLMs that can\nmodify a website for us, why bother with the Wildcard UI at all? Couldn\u2019t we\njust ask ChatGPT to re-sort the website for us and add read times?\n\nI don\u2019t think the answer is that clear cut. There\u2019s a lot of value to seeing\nthe spreadsheet as an alternate view of the underlying data of the website,\nwhich we can directly look at and manipulate. Clicking around in a table and\nsorting by column headers feels good, and is faster than typing \u201csort by\ncolumn X\u201d. Having spreadsheet formulas that the user can directly see and edit\ngives them more control.\n\nThe basic point here is that user interfaces still matter. We can imagine\nspecific, targeted roles for LLMs that help empower users to customize and\nbuild software, without carelessly throwing decades of interaction design out\nthe window.\n\nNext we\u2019ll dive deeper into this question of user interfaces vs. chatbots. But\nfirst let\u2019s briefly go on a tangent and ask: can GPT really code?\n\n## Cmon, can it really code though?\n\nHow good is GPT-4\u2019s coding ability today? It\u2019s hard to summarize in general\nterms. The best way to understand the current capabilities is to see many\npositive and negative examples to develop some fuzzy intuition, and ideally to\ntry it yourself.\n\nIt\u2019s not hard to find impressive examples. Personally, I\u2019ve had success using\nGPT-4 to write one-off Python code for data processing, and I watched my wife\nuse ChatGPT to write some Python code for scraping data from a website. A\nrecent paper from Microsoft Research found GPT-4 could generate a\nsophisticated 3D game running in the browser, with a zero-shot prompt (shown\nbelow).\n\nIt\u2019s also not hard to find failures. In my experience, GPT-4 still gets\nconfused when solving relatively simple algorithms problems. I tried to use it\nthe other day to make a React application for performing some simple video\nediting tasks, and it got 90% of the way there but couldn\u2019t get some\ndragging/resizing interactions quite right. It\u2019s very far from perfect. In\ngeneral, GPT-4 feels like a junior developer who is very fast at typing and\nknows about a lot of libraries, but is careless and easily confused.\n\nDepending on your perspective, this summary might seem miraculous or\nunderwhelming. If you\u2019re skeptical, I want to point out a couple reasons for\noptimism which weren\u2019t immediately obvious to me.\n\nFirst, iteration is a natural part of the process with LLMs. When the code\ndoesn\u2019t work the first time, you can simply paste in the error message you\ngot, or describe the unexpected behavior, and GPT will adjust. For one\nexample, see this Twitter thread where a designer (who can\u2019t write game code)\ncreates a video game over many iterations. There were also some examples of\niterating with error messages in the GPT-4 developer livestream. When you\nthink about it, this mirrors the way humans write code; it doesn\u2019t always work\non the first try.\n\nA joke that comes up often among AI-skeptical programmers goes something like\nthis: \u201cGreat, now no one will have to write code, they\u2019ll only have to write\nexact, precise specifications of computer behavior...\u201d (implied: oh wait, that\nis code!) I suspect we\u2019ll look back on this view as short-sighted. LLMs can\niteratively work with users and ask them questions to develop their\nspecifications, and can also fill in underspecified details using common\nsense. This doesn\u2019t mean those are trivial challenges, but I expect to see\nprogress on those fronts. I\u2019ve already had success prompting GPT-4 to ask me\nclarifying questions about my specifications.\n\nAnother important point: GPT-4 seems to be a lot better than GPT-3 at coding,\nper the MSR paper and my own limited experiments. The trend line is steep. If\nwe\u2019re not plateauing yet, then it\u2019s very plausible that the next generation of\nmodels will be significantly better once again.\n\nCoding difficulty varies by context, and we might expect to see differences\nbetween professional software engineering and end-user programming. On the one\nhand, one might expect end-user programming to be easier than professional\ncoding, because lots of tasks can be achieved with simple coding that mostly\ninvolves gluing together libraries, and doesn\u2019t require novel algorithmic\ninnovation.\n\nOn the other hand, failures are more consequential when a novice end-user is\ndriving the process than when a skilled programmer is wielding control. The\nskilled programmer can laugh off the LLM\u2019s silly suggestion, write their own\ncode, or apply their own skill to work with the LLM to debug. An end-user is\nmore likely to get confused or not even notice problems in the first place.\nThese are real problems, but I don\u2019t think they\u2019re intractable. End-users\nalready write messy buggy spreadsheet programs all the time, and yet we\nsomehow muddle through\u2014even if that seems offensive or perhaps even immoral to\na correctness-minded professional software developer.\n\n## Chat is an essentially limited interaction\n\nNow, with those preliminaries out of the way, let\u2019s move on to the main topic\nof this post: how will interaction models evolve in this new age of computing?\nWe\u2019ll start by assessing chat as an interaction mode. Is the future of\ncomputing just talking to our computers in natural language?\n\nTo think clearly about this question, I think it\u2019s important to notice that\nchatbots are frustrating for two distinct reasons. First, it\u2019s annoying when\nthe chatbot is narrow in its capabilities (looking at you Siri) and can\u2019t do\nthe thing you want it to do. But more fundamentally than that, chat is an\nessentially limited interaction mode, regardless of the quality of the bot.\n\nTo show why, let\u2019s pick on a specific example: this tweet from OpenAI\u2019s Greg\nBrockman during the ChatGPT Plugins launch this week, where he uses ChatGPT to\ntrim the first 5 seconds of a video using natural language:\n\n> Plugins for processing a video clip, no ffmpeg wizardry required. Actual\n> use-case from today\u2019s launch. pic.twitter.com/Q3r2Z8fRS5\n>\n> \u2014 Greg Brockman (@gdb) March 23, 2023\n\nOn the one hand, this is an extremely impressive demo for anyone who knows how\ncomputers work, and I\u2019m excited about all the possibilities it implies.\n\nAnd yet... in another sense, this is also a silly demo, because we already\nhave direct manipulation user interfaces for trimming videos, with rich\ninteractive feedback. For example, consider the iPhone UI for trimming videos,\nwhich offers rich feedback and fine control over exactly where to trim. This\nis much better than going back and forth over chat saying \u201cactually trim just\n4.8 seconds please\u201d!\n\nNow, I get that the point of Greg\u2019s demo wasn\u2019t just to trim a video, it was\nto gesture at an expanse of possibilities. But there\u2019s still something\nimportant to notice here: a chat interface is not only quite slow and\nimprecise, but also requires conscious awareness of your thought process.\n\nWhen we use a good tool\u2014a hammer, a paintbrush, a pair of skis, or a car\nsteering wheel\u2014we become one with the tool in a subconscious way. We can enter\na flow state, apply muscle memory, achieve fine control, and maybe even\nproduce creative or artistic output. Chat will never feel like driving a car,\nno matter how good the bot is. In their 1986 book Understanding Computers and\nCognition, Terry Winograd and Fernando Flores elaborate on this point:\n\n> In driving a car, the control interaction is normally transparent. You do\n> not think \u201cHow far should I turn the steering wheel to go around that\n> curve?\u201d In fact, you are not even aware (unless something intrudes) of using\n> a steering wheel...The long evolution of the design of automobiles has led\n> to this readiness-to-hand. It is not achieved by having a car communicate\n> like a person, but by providing the right coupling between the driver and\n> action in the relevant domain (motion down the road).\n\n## Consultants vs apps\n\nLet\u2019s zoom out a bit on this question of chat vs direct manipulation. One way\nto think about it is to reflect on what it\u2019s like to interact with a team of\nhuman consultants over Slack, vs. just using an app to get the job done. Then\nwe\u2019ll see how LLMs might play in to that picture.\n\nSo, imagine you want to get some metrics about your business, maybe a sales\nforecast for next quarter. How do you do it?\n\nOne approach is to ask your skilled team of business analysts. You can send\nthem a message asking your question. It probably takes hours to get a response\nbecause they\u2019re busy, and it\u2019s expensive because you\u2019re paying for people\u2019s\ntime. Seems like overkill for a simple task, but the key benefit is\nflexibility: you\u2019re hoping that the consultants have a broad, general\nintelligence and can perform lots of different tasks that you ask of them.\n\nIn contrast, another option is to use a self-serve analytics platform where\nyou can click around in some dashboards. When this works, it\u2019s way faster and\ncheaper than bothering the analysts. The dashboards offer you powerful direct\nmanipulation interactions like sorting, filtering, and zooming. You can\nquickly think through the problem yourself.\n\nSo what\u2019s the downside? Using the app is less flexible than working with the\nbespoke consultants. The moment you want to perform a task which this\nanalytics platform doesn\u2019t support, you\u2019re stuck asking for help or switching\nto a different tool. You can try sending an email to the developers of the\nanalysis platform, but usually nothing will come of it. You don\u2019t have a\nmeaningful feedback loop with the developers; you\u2019re left wishing software\nwere more flexible.\n\nNow with that baseline comparison established, let\u2019s imagine how LLMs might\nfit in.\n\nAssume that we could replace our human analyst team with ChatGPT for the tasks\nwe have in mind, while preserving the same degree of flexibility. (This isn\u2019t\ntrue of today\u2019s models, but will become increasingly true to some\napproximation.) How would that change the picture? Well, for one thing, the\nLLM is a lot cheaper to run than the humans. It\u2019s also a lot faster at\nresponding since it\u2019s not busy taking a coffee break. These are major\nadvantages. But still, dialogue back and forth with it takes seconds, if not\nminutes, of conscious thought\u2014much slower than feedback loops you have with a\nGUI or a steering wheel.\n\nNext, consider LLMs applied to the app model. What if we started with an\ninteractive analytics application, but this time we had a team of LLM\ndevelopers at our disposal? As a start, we could ask the LLM questions about\nhow to use the application, which could be easier than reading documentation.\n\nBut more profoundly than that, the LLM developers could go beyond that and\nupdate the application. When we give feedback about adding a new feature, our\nrequest wouldn\u2019t get lost in an infinite queue. They would respond\nimmediately, and we\u2019d have some back and forth to get the feature implemented.\nOf course, the new functionality doesn\u2019t need to be shipped to everyone; it\ncan just be enabled for our team. This is economically viable now because\nwe\u2019re not relying on a centralized team of human developers to make the\nchange.\n\nNote that this is just a rough vision at this point. We\u2019re missing a lot of\ndetails about how this model might be made real. A lot of the specifics of how\nsoftware is built today make these kinds of on-the-fly customizations quite\nchallenging.\n\nThe important thing, though, is that we\u2019ve now established two loops in the\ninteraction. On the inner loop, we can become one with the tool, using fast\ndirect manipulation interfaces. On the outer loop, when we hit limits of the\nexisting application, we can consciously offer feedback to the LLM developers\nand get new features built. This preserves the benefits of UIs, while adding\nmore flexibility.\n\n## From apps to computational media\n\nDoes this double interaction loop remind you of anything?\n\nThink about how a spreadsheet works. If you have a financial model in a\nspreadsheet, you can try changing a number in a cell to assess a scenario\u2014this\nis the inner loop of direct manipulation at work.\n\nBut, you can also edit the formulas! A spreadsheet isn\u2019t just an \u201capp\u201d focused\non a specific task; it\u2019s closer to a general computational medium which lets\nyou flexibly express many kinds of tasks. The \u201cplatform developers\"\u2014the\ncreators of the spreadsheet\u2014have given you a set of general primitives that\ncan be used to make many tools.\n\nWe might draw the double loop of the spreadsheet interaction like this. You\ncan edit numbers in the spreadsheet, but you can also edit formulas, which\nedits the tool:\n\nSo far, I\u2019ve labeled the spreadsheet in the above diagram as \"kinda\u201d flexible.\nWhy? Well, when any individual user is working with a spreadsheet, it\u2019s easy\nfor them to hit the limits of their knowledge. In real life, spreadsheets are\nactually way more flexible than this. The reason is that this diagram is\nmissing a critical component of spreadsheet usage: collaboration.\n\n## Collaboration with local developers\n\nMost teams have a mix of domain experts and technical experts, who work\ntogether to put together a spreadsheet. And, importantly, the people building\na spreadsheet together have a very different relationship than a typical\n\u201cdeveloper\u201d and \u201cend-user\u201d. Bonnie Nardi and James Miller explain in their\n1990 paper on collaborative spreadsheet development, imagining Betty, a CFO\nwho knows finance, and Buzz, an expert in programming spreadsheets:\n\n> Betty and Buzz seem to be the stereotypical end-user/developer pair, and it\n> is easy to imagine their development of a spreadsheet to be equally\n> stereotypical: Betty specifies what the spreadsheet should do based on her\n> knowledge of the domain, and Buzz implements it.\n>\n> This is not the case. Their cooperative spreadsheet development departs from\n> this scenario in two important ways:\n>\n> (1) Betty constructs her basic spreadsheets without assistance from Buzz.\n> She programs the parameters, data values and formulas into her models. In\n> addition, Betty is completely responsible for the design and implementation\n> of the user interface. She makes effective use of color, shading, fonts,\n> outlines, and blank cells to structure and highlight the information in her\n> spreadsheets.\n>\n> (2) When Buzz helps Betty with a complex part of the spreadsheet such as\n> graphing or a complex formula, his work is expressed in terms of Betty\u2019s\n> original work. He adds small, more advanced pieces of code to Betty\u2019s basic\n> spreadsheet; Betty is the main developer and he plays an adjunct role as\n> consultant.\n>\n> This is an important shift in the responsibility of system design and\n> implementation. Non-programmers can be responsible for most of the\n> development of a spreadsheet, implementing large applications that they\n> would not undertake if they had to use conventional programming techniques.\n> Non-programmers may never learn to program recursive functions and nested\n> loops, but they can be extremely productive with spreadsheets. Because less\n> experienced spreadsheet users become engaged and involved with their\n> spreadsheets, they are motivated to reach out to more experienced users when\n> they find themselves approaching the limits of their understanding of, or\n> interest in, more sophisticated programming techniques.\n\nSo, a more accurate diagram of spreadsheet usage includes \u201clocal developers\u201d\nlike Buzz, who provide another outer layer of iteration, where the user can\nget help molding their tools. Because they\u2019re on the same team as the user,\nit\u2019s a lot easier to get help than appealing to third-party application or\nplatform developers. And most importantly, over time, the user naturally\nlearns to use more features of spreadsheets on their own, since they\u2019re\ninvolved in the development process.\n\nIn general, the local developer makes the spreadsheet more flexible, although\nthey also introduce cost, because now you have a human technical expert in the\nmix. What if you don\u2019t have a local spreadsheet expert handy, perhaps because\nyou can\u2019t afford to hire that person? Then you\u2019re back to doing web searches\nfor complex spreadsheet programming...\n\nIn those cases, what if you had an LLM play the role of the local developer?\nThat is, the user mainly drives the creation of the spreadsheet, but asks for\ntechnical help with some of the formulas when needed? The LLM wouldn\u2019t just\ncreate an entire solution, it would also teach the user how to create the\nsolution themselves next time.\n\nThis picture shows a world that I find pretty compelling. There\u2019s an inner\ninteraction loop that takes advantage of the full power of direct\nmanipulation. There\u2019s an outer loop where the user can also more deeply edit\ntheir tools within an open-ended medium. They can get AI support for making\ntool edits, and grow their own capacity to work in the medium. Over time, they\ncan learn things like the basics of formulas, or how a VLOOKUP works. This\nstructural knowledge helps the user think of possible use cases for the tool,\nand also helps them audit the output from the LLMs.\n\nIn a ChatGPT world, the user is left entirely dependent on the AI, without any\nunderstanding of its inner mechanism. In a computational medium with AI as\nassistant, the user\u2019s reliance on the AI gently decreases over time as they\nbecome more comfortable in the medium.\n\nIf you like this diagram too, then it suggests an interesting opportunity.\nUntil now, the design of open-ended computational media has been restricted by\nthe programming bottleneck problem. LLMs seem to offer a promising way to more\nflexibly turn natural language into code, which then raises the question: what\nkinds of powerful computational media might be a good fit for this new\nsituation?\n\n## Demos of on-the-fly UI\n\nUpdate 3/31: In the days after I originally posted this essay, I found a few\nneat demos on Twitter from people exploring ideas in this space; I\u2019ve added\nthem here.\n\nOK, enough diagrams, what might on-the-fly UI generation actually feel like to\nuse?\n\nHere\u2019s Sean Grove demonstrating on-the-fly generation of an interactive table\nview, a map view with a lat/long output, and a simple video editing UI:\n\n> \ud83d\ude80Future of UI dev\ud83d\udd2e: ~10% fixed UIs built by hand like today ~40% replaced by\n> conversational UIs ~50% long-tail, on-the-fly UIs generated for specific\n> tasks, used once, then vanish\n>\n> Combined with ChatGPT plugins to read/write from the world\n> \ud83e\udd2fhttps://t.co/mIFrCyzW8N\n>\n> \u2014 Sean Grove (@sgrove) March 27, 2023\n\nAnd here\u2019s Vasek Mlejnsky showing an IDE that can create a form for submitting\nserver requests:\n\n> I present to you: GPT-4 powered IDE that creates UI on demand so it fits\n> your exact development needs.\n>\n> Need UI for making server requests? No problem. Just ask for it.\n> pic.twitter.com/2oDKTuWM0e\n>\n> \u2014 Vasek Mlejnsky (@mlejva) March 29, 2023\n\nFinally, here\u2019s a little video mockup I made of GPT answering a question by\nreturning an interactive spreadsheet. Note how I can tweak numbers and get\nimmediate feedback. I can also inspect the underlying formulas and ask the\nmodel to explain them to me to level up my spreadsheet knowledge. (GPT\nactually did generate this spreadsheet data, I just copied the raw data into\nExcel to demonstrate the interactive element.)\n\n> what if a chat produced a spreadsheet as the answer, so you could instantly\n> tweak numbers and see the result? pic.twitter.com/FNKz0kLH7L\n>\n> \u2014 Geoffrey Litt (@geoffreylitt) March 29, 2023\n\nI think these demos nicely illustrate the general promise of on-the-fly UI,\nbut there\u2019s still a ton of work ahead. One particular challenge: interesting\nUIs usually can\u2019t be generated in a single shot; there has to be an iterative\nprocess with the user. In my experience, that iteration process can still\noften be very rough at the moment.\n\n## Next time: extensible software\n\nThat\u2019s it for now. There are a lot of questions in the space that we still\nhaven\u2019t covered.\n\nNext time I plan to discuss the architectural foundations required to make GUI\napplications extensible and composable by people using LLMs.\n\nIf you\u2019re interested in that, you can sign up for my email newsletter or\nsubscribe via RSS.\n\n## Related reading\n\nQuick reads:\n\n  * LLM Powered Assistants for Complex Interfaces by Nick Arner\n  * \u201cThe fact that they generate text is not the point\u201d by @thesephist\n  * \u201cGPT-3 as a universal coupling\u201d by Matt Webb\n  * \u201ctools vs machines\u201d and \u201cinterpreter vs compiler\u201d\n\nDeep, deep dives:\n\nDesigning and Programming Malleable Software: Philip Tchernavskij\u2019s 2019 PhD\nthesis, which coined the term Malleable Software, and brilliantly motivates\nand defines the problem. \u201cMalleable software aims to increase the power of\nexisting adaptation behaviors by allowing users to pull apart and re-combine\ntheir interfaces at the granularity of individual UI elements\u201d\n\nThe State of the Art in End-User Software Engineering: an academic paper from\n2011 that illustrates many of the challenges ahead for supporting normal\npeople in building software. \u201cAlthough these end-user programmers may not have\nthe same goals as professional developers, they do face many of the same\nsoftware engineering challenges, including understanding their requirements,\nas well as making decisions about design, reuse, integration, testing, and\ndebugging.\u201d\n\nThe Malleable Systems Catalog, a list of projects exploring user-editable\nsoftware, curated by J. Ryan Stinnett and co.\n\n#### Subscribe\n\nI periodically write about programming tools, end-user programming, and other\nsoftware topics. To get updates about new posts:\n\nJoin my email newsletter Follow me on Twitter Subscribe via RSS\n\n", "frontpage": false}
