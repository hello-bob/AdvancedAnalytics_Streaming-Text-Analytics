{"aid": "40285390", "title": "Hardware is the new vendor lock-in", "url": "https://qdrant.tech/blog/are-you-vendor-locked/", "domain": "qdrant.tech", "votes": 2, "user": "andre-z", "posted_at": "2024-05-07 13:46:25", "comments": 0, "source_title": "Are You Vendor Locked? - Qdrant", "source_text": "Are You Vendor Locked? - Qdrant\n\n# Are You Vendor Locked?\n\nMay 05, 2024 \u00b7 David Myriel\n\nShare\n\nWe all are.\n\n> \u201cThere is no use fighting it. Pick a vendor and go all in. Everything else\n> is a mirage.\u201d The last words of a seasoned IT professional\n\nAs long as we are using any product, our solution\u2019s infrastructure will depend\non its vendors. Many say that building custom infrastructure will hurt\nvelocity. Is this true in the age of AI?\n\nIt depends on where your company is at. Most startups don\u2019t survive more than\nfive years, so putting too much effort into infrastructure is not the best use\nof their resources. You first need to survive and demonstrate product\nviability.\n\nSometimes you may pick the right vendors and still fail.\n\nWe have all started to see the results of the AI hardware bottleneck. Running\nLLMs is expensive and smaller operations might fold to high costs. How will\nthis affect large enterprises?\n\n> If you are an established corporation, being dependent on a specific\n> supplier can make or break a solid business case. For large-scale GenAI\n> solutions, costs are essential to maintenance and dictate the long-term\n> viability of such projects. In the short run, enterprises may afford high\n> costs, but when the prices drop - then it\u2019s time to adjust.\n\nUnfortunately, the long run goal of scalability and flexibility may be\ncountered by vendor lock-in. Shifting operations from one host to another\nrequires expertise and compatibility adjustments. Should businesses become\ndependent on a single cloud service provider, they open themselves to risks\nranging from soaring costs to stifled innovation.\n\nFinding the best vendor is key; but it\u2019s crucial to stay mobile.\n\n## Hardware is the New Vendor Lock\n\n> \u201cWe\u2019re so short on GPUs, the less people that use the tool [ChatGPT], the\n> better.\u201d OpenAI CEO, Sam Altman\n\nWhen GPU hosting becomes too expensive, large and exciting Gen AI projects\nlose their luster. If moving clouds becomes too costly or difficulty to\nimplement - you are vendor-locked. This used to be common with software. Now,\nhardware is the new dependency.\n\nEnterprises have many reasons to stay provider agnostic - but cost is the main\none.\n\nAppenzeller, Bornstein & Casado from Andreessen Horowitz point to growing\ncosts of AI compute. It is still a vendor\u2019s market for A100 hourly GPUs,\nlargely due to supply constraints. Furthermore, the price differences between\nAWS, GCP and Azure are dynamic enough to justify extensive cost-benefit\nanalysis from prospective customers.\n\nSource: Andreessen Horowitz\n\nSure, your competitors can brag about all the features they can access - but\nare they willing to admit how much their company has lost to convenience and\nincreasing costs?\n\nAs an enterprise customer, one shouldn\u2019t expect a vendor to stay consistent in\nthis market.\n\n## How Does This Affect Qdrant?\n\nAs an open source vector database, Qdrant is completely risk-free.\nFurthermore, cost savings is one of the many reasons companies use it to\naugment the LLM. You won\u2019t need to burn through GPU cash for training or\ninference. A basic instance with a CPU and RAM can easily manage indexing and\nretrieval.\n\n> However, we find that many of our customers want to host Qdrant in the same\n> place as the rest of their infrastructure, such as the LLM or other data\n> engineering infra. This can be for practical reasons, due to corporate\n> security policies, or even global political reasons.\n\nOne day, they might find this infrastructure too costly. Although vector\nsearch will remain cheap, their training, inference and embedding costs will\ngrow. Then, they will want to switch vendors.\n\nWhat could interfere with the switch? Compatibility? Technologies? Lack of\nexpertise?\n\nIn terms of features, cloud service standardization is difficult due to\nvarying features between cloud providers. This leads to custom solutions and\nvendor lock-in, hindering migration and cost reduction efforts, as seen with\nSnapchat and Twitter.\n\n## Fear, Uncertainty and Doubt\n\nYou spend months setting up the infrastructure, but your competitor goes all\nin with a cheaper alternative and has a competing product out in one month?\nDoes avoiding the lock-in matter if your company will be out of business while\nyou try to setup a fully agnostic platform?\n\nProblem: If you\u2019re not locked into a vendor, you\u2019re locked into managing a\nmuch larger team of engineers. The build vs buy tradeoff is real and it comes\nwith its own set of risks and costs.\n\nAcknowledgement: Any organization that processes vast amounts of data with AI\nneeds custom infrastructure and dedicated resources, no matter the industry.\nHaving to work with expensive services such as A100 GPUs justifies the\nexistence of in-house DevOps crew. Any enterprise that scales up needs to\nemploy vigilant operatives if it wants to manage costs.\n\n> There is no need for Fear, Uncertainty and Doubt. Vendor lock is not a\n> futile cause - so let\u2019s dispel the sentiment that all vendors are\n> adversaries. You just need to work with a company that is willing to\n> accommodate flexible use of products.\n\nThe Solution is Kubernetes: Decoupling your infrastructure from a specific\ncloud host is currently the best way of staying risk-free. Any component of\nyour solution that runs on Kubernetes can integrate seamlessly with other\ncompatible infrastructure.\n\nThis is how you stay dynamic and move vendors whenever it suits you best.\n\n## What About Hybrid Cloud?\n\nThe key to freedom is to building your applications and infrastructure to run\non any cloud. By leveraging containerization and service abstraction using\nKubernetes or Docker, software vendors can exercise good faith in helping\ntheir customers transition to other cloud providers.\n\nWe designed the architecture of Qdrant Hybrid Cloud to meet the evolving needs\nof businesses seeking unparalleled flexibility, control, and privacy.\n\nThis technology integrates Kubernetes clusters from any setting - cloud, on-\npremises, or edge - into a unified, enterprise-grade managed service.\n\n#### Take a look. It\u2019s completely yours. We\u2019ll help you manage it.\n\nQdrant Hybrid Cloud marks a significant advancement in vector databases,\noffering the most flexible way to implement vector search.\n\nYou can test out Qdrant Hybrid Cloud today. Sign up or log into your Qdrant\nCloud account and get started in the Hybrid Cloud section.\n\nAlso, to learn more about Qdrant Hybrid Cloud read our Official Release Blog\nor our Qdrant Hybrid Cloud website. For additional technical insights, please\nread our documentation.\n\n#### Try it out!\n\n## Related Posts\n\nView all blog posts\n\n### Qdrant 1.9.0 - Heighten Your Security With Role-Based Access Control\nSupport\n\nNew access control options for RBAC, a much faster shard transfer procedure,\nand direct support for byte embeddings.\n\nBy David Myriel \u00b7 April 24, 2024\n\n### Qdrant's Trusted Partners for Hybrid Cloud Deployment\n\nWith the launch of Qdrant Hybrid Cloud we provide developers the ability to\ndeploy Qdrant as a managed vector database in any desired environment.\n\nBy Manuel Meyer \u00b7 April 15, 2024\n\n### Qdrant Hybrid Cloud: the First Managed Vector Database You Can Run\nAnywhere\n\nBy Andre Zayarni, CEO & Co-Founder \u00b7 April 15, 2024\n\n## Stay updated with Qdrant\n\nWe will update you on new features and news regarding Qdrant and Vector\nSimilarity Search.\n\n#### Product\n\n  * Use cases\n  * Solutions\n  * Benchmarks\n  * Demos\n  * Pricing\n\n#### Community\n\n  * Github\n  * Discord\n  * Twitter\n  * Newsletter\n  * Contact us\n\n#### Company\n\n  * Jobs\n  * Privacy Policy\n  * Terms\n  * Impressum\n  * Credits\n\n#### Latest Publications\n\n#### What is RAG?\n\n#### Faster sparse vectors.Optimized indexation. Optional CPU resource\nmanagement.\n\n#### Why are vector databases needed for RAG? We debunk claims of increased\nLLM accuracy and look into drawbacks of large context windows.\n\n\u00a9 2024 Qdrant. All Rights Reserved\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features\nand news regarding Qdrant.\n\nLike what we are doing? Consider giving us a \u2b50 on Github.\n\nWe use cookies to learn more about you. At any time you can delete or block\ncookies through your browser settings.\n\nLearn moreI accept\n\n", "frontpage": false}
