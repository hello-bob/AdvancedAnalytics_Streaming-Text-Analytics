{"aid": "40272346", "title": "Google's medical AI destroys GPT's benchmark and outperforms doctors", "url": "https://newatlas.com/technology/google-med-gemini-ai/", "domain": "newatlas.com", "votes": 1, "user": "hochmartinez", "posted_at": "2024-05-06 08:10:25", "comments": 0, "source_title": "Google's medical AI destroys GPT's benchmark and outperforms doctors", "source_text": "Google's medical AI destroys GPT's benchmark and outperforms doctors\n\n\u00a9 2024 New Atlas\n\nTechnology\n\n# Google's medical AI destroys GPT's benchmark and outperforms doctors\n\nBy Paul McClure\n\nMay 06, 2024\n\n  * Facebook\n  * Twitter\n  * Flipboard\n  * LinkedIn\n\nGoogle's medical AI destroys GPT's benchmark and outperforms doctors\n\nGoogle's Med-Gemini is an AI specialized in medicine\n\nDepositphotos\n\nView 5 Images\n\n1/5\n\nGoogle's Med-Gemini is an AI specialized in medicine\n\nDepositphotos\n\n2/5\n\nHow the self-training and web search tools work in Med-Gemini\n\nSaab et al.\n\n3/5\n\nExample of Med-Gemini's long-context capabilities\n\nSaab et al.\n\n4/5\n\nExample of Med-Gemini's diagnostic dialogue in a dermatological setting\n\nSaab et al.\n\n5/5\n\nMed-Gemini's diagnostic dialogue assistance in a radiological setting\n\nSaab et al.\n\nView gallery - 5 images\n\n## Google Research and Google\u2019s AI research lab, DeepMind, have detailed the\nimpressive reach of Med-Gemini, a family of advanced AI models specialized in\nmedicine. It's a huge advancement in clinical diagnostics with massive real-\nworld potential.\n\nDoctors treat a multitude of patients daily, with needs ranging from simple to\nvery complex. To deliver effective care, they must be familiar with each\npatient\u2019s health record and keep up-to-date with the newest procedures and\ntreatments. And then there\u2019s the all-important doctor-patient relationship,\nbuilt on empathy, trust, and communication. For an AI to come close to\nemulating a real-world doctor, it needs to be able to do all of these things.\n\nThe intersection of AI and medicine has really taken off. In the last six\nmonths, New Atlas has reported on AI models that aid less experienced doctors\nin identifying the precursors of colon cancer, diagnose childhood autism from\neye images, and predict in real-time whether a surgeon has removed all\ncancerous tissue during breast cancer surgery. But Med-Gemini is something\nelse.\n\nMore Stories\n\nRobotics\n\nForest walker robot takes a brutal beating and keeps marching\n\nTechnology\n\nBrain implants are becoming obsolete, like old phones. What happens next?\n\nGoogle\u2019s Gemini models are a new generation of multimodal AI models, meaning\nthat they can process information from different modalities, including text,\nimages, videos, and audio. The models are adept at language and conversation,\nunderstanding the diverse information they\u2019re trained on, and what\u2019s called\n\u2018long-context reasoning,\u2019 or reasoning from large amounts of data such as\nhours of video or tens of hours of audio.\n\nMed-Gemini has all of the advantages of the foundational Gemini models but has\nfine-tuned them. The researchers tested these medicine-focused tweaks and\nincluded their results in the paper. There\u2019s a lot in the 58-page paper; we\u2019ve\nselected the most impressive bits.\n\n## Self-training and web search capabilities\n\nArriving at a diagnosis and formulating a treatment plan requires doctors to\ncombine their own medical knowledge with a raft of other relevant information:\npatient symptoms, medical, surgical and social history, lab results and the\nresults of other investigative tests, and the patient\u2019s response to prior\ntreatment. Treatments are a \u2018movable feast,\u2019 with existing ones being updated\nand new ones being introduced. All these things influence a doctor\u2019s clinical\nreasoning.\n\nThat\u2019s why, with Med-Gemini, Google included access to web-based searching to\nenable more advanced clinical reasoning. Like many medicine-focused large\nlanguage models (LLMs), Med-Gemini was trained on MedQA, multiple-choice\nquestions representative of US Medical License Exam (USMLE) questions designed\nto test medical knowledge and reasoning across diverse scenarios.\n\nHow the self-training and web search tools work in Med-Gemini\n\nSaab et al.\n\nHowever, Google also developed two novel datasets for their model. The first,\nMedQA-R (Reasoning), extends MedQA with synthetically generated reasoning\nexplanations called \u2018Chain-of-Thoughts\u2019 (CoTs). The second, MedQA-RS\n(Reasoning and Search), provides the model with instructions to use web search\nresults as additional context to improve answer accuracy. If a medical\nquestion leads to an uncertain answer, the model is prompted to undertake a\nweb search to obtain further information to resolve the uncertainty.\n\nMed-Gemini was tested on 14 medical benchmarks and established a new state-of-\nthe-art (SoTA) performance on 10, surpassing the GPT-4 model family on every\nbenchmark where a comparison could be made. On the MedQA (USMLE) benchmark,\nMed-Gemini achieved 91.1% accuracy using its uncertainty-guided search\nstrategy, outperforming Google\u2019s previous medical LLM, Med-PaLM 2, by 4.5%.\n\nOn seven multimodal benchmarks, including the New England Journal of Medicine\n(NEJM) image challenge (images of challenging clinical cases from which a\ndiagnosis is made from a list of 10), Med-Gemini performed better than GPT-4\nby an average relative margin of 44.5%.\n\n\u201cWhile the results ... are promising, significant further research is needed,\u201d\nthe researchers said. \u201cFor example, we haven\u2019t considered restricting the\nsearch results to more authoritative medical sources, using multimodal search\nretrieval or performed analysis on accuracy and relevance of search results\nand the quality of the citations. Further, it remains to be seen if smaller\nLLMs can also be taught to make use of web search. We leave these explorations\nto future work.\u201d\n\n## Retrieving specific information from lengthy electronic health records\n\nElectronic health records (EHRs) can be long, but doctors need to be aware of\nwhat they contain. To complicate matters, they typically contain textual\nsimilarities (\u201cdiabetes mellitus\u201d vs. \u201cdiabetic nephropathy\u201d), misspellings,\nacronyms (\u201cRx\u201d vs. \u201cprescription\u201d), and synonyms (\u201ccerebrovascular accident\u201d\nvs. \u201cstroke\u201d) \u2013 things that can pose a challenge to AI.\n\nTo test Med-Gemini\u2019s ability to understand and reason from long-context\nmedical information, the researchers ran a so-called \u2018needle-in-a-haystack\ntask\u2019 using a large, publicly available database, the Medical Information Mart\nfor Intensive Care or MIMIC-III, containing de-identified health data of\npatients admitted to intensive care.\n\nThe goal was for the model to retrieve the relevant mention of a rare and\nsubtle medical condition, symptom, or procedure (the \u2018needle\u2019) over a large\ncollection of clinical notes in the EHR (\u2018the haystack).\n\nTwo hundred examples were curated, and each example consisted of a collection\nof de-identified EHR notes from 44 ICU patients with long medical histories.\nThey had to have the following criteria:\n\n  * More than 100 medical notes, with the length of each example ranging from 200,000 to 700,000 words\n  * In each example, the condition was only mentioned once\n  * Each sample had a single condition of interest\n\nThere were two steps to the needle-in-a-haystack task. First, Med-Gemini had\nto retrieve all mentions of the specified medical problem from the extensive\nrecords. Second, the model had to evaluate the relevance of all mentions,\ncategorize them, and conclude whether the patient had a history of that\nproblem, providing clear reasoning for its decision.\n\nExample of Med-Gemini's long-context capabilities\n\nSaab et al.\n\nCompared to the SoTA method, Med-Gemini performed well on the needle-in-a-\nhaystack task. It rated 0.77 on precision compared to the SoTA method (0.85)\nand outdid the SoTA method on recall: 0.76 vs. 0.73.\n\n\u201cPerhaps the most notable aspect of Med-Gemini is the long-context processing\ncapabilities because they open up new performance frontiers and novel,\npreviously infeasible application possibilities for medical AI systems,\u201d said\nthe researchers. \u201cThis \u2018needle-in-a-haystack\u2019 retrieval task reflects a real-\nworld challenge faced by clinicians and Med-Gemini-M 1.5\u2019s performance\ndemonstrates its potential to significantly reduce cognitive load and augment\nclinicians\u2019 capabilities by efficiently extracting and analyzing information\nfrom vast amounts of patient data.\u201d\n\nFor an easy-to-understand discussion of these key research points, and an\nupdate on the mud-slinging between Google and Microsoft, check out AI\nExplained\u2019s video from 13:38 onwards.\n\nNew OpenAI Model 'Imminent' and AI Stakes Get Raised (plus Med Gemini, GPT 2\nChatbot and Scale AI)\n\n## Conversations with Med-Gemini\n\nIn a test of real-world usefulness, Med-Gemini was asked about an itchy skin\nlump by a patient user. After asking for an image, the model asked appropriate\nfollow-up questions and correctly diagnosed the rare lesion, recommending what\nthe user should do next.\n\nExample of Med-Gemini's diagnostic dialogue in a dermatological setting\n\nSaab et al.\n\nMed-Gemini was also asked to interpret a chest X-ray for a physician while\nthey were waiting for a formal radiologist\u2019s report and formulate a plain\nEnglish version of the report that could be provided to the patient.\n\nMed-Gemini's diagnostic dialogue assistance in a radiological setting\n\nSaab et al.\n\n\u201cThe multimodal conversation capabilities of Med-Gemini-M 1.5 are promising\ngiven they are attained without any specific medical dialogue fine-tuning,\u201d\nthe researchers said. \u201cSuch capabilities allow for seamless and natural\ninteractions between people, clinicians, and AI systems.\u201d\n\nHowever, the researchers recognize that further work is needed.\n\n\u201cThis capability has significant potential for helpful real-world\napplications, including assisting clinicians and patients, but of course also\nentails highly significant risks,\u201d they said. \u201cWhile highlighting the\npotential for future research in this domain, we have not rigorously\nbenchmarked capabilities for clinical conversation in this work as previously\nexplored by others in dedicated research towards conversational diagnostic\nAI.\u201d\n\n## Visions of the future\n\nWhere to from here? The researchers admit that there is much more work to be\ndone, but the Med-Gemini model's initial capabilities are certainly promising.\nImportantly, they plan to incorporate responsible AI principles, including\nprivacy and fairness, throughout the model development process.\n\n\u201cPrivacy considerations in particular need to be rooted in existing healthcare\npolicies and regulations governing and safeguarding patient information,\u201d the\nresearchers said. \u201cFairness is another area that may require attention, as\nthere is a risk that AI systems in healthcare may unintentionally reflect or\namplify historical biases and inequities, potentially leading to disparate\nmodel performance and harmful outcomes for marginalized groups.\u201d\n\nBut, ultimately, Med-Gemini is seen as a tool for good.\n\n\u201cLarge multimodal language models are ushering in a new era of possibilities\nfor health and medicine,\u201d the researchers said. \u201cThe capabilities demonstrated\nby Gemini and Med-Gemini suggest a significant leap forward in the depth and\nbreadth of opportunities to accelerate biomedical discoveries and assist in\nhealthcare delivery and experiences. However, it is paramount that\nadvancements in model capabilities are accompanied by meticulous attention to\nthe reliability and safety of these systems. By prioritizing both aspects, we\ncan responsibly envision a future where the capabilities of AI systems are\nmeaningful and safe accelerators of both scientific progress and care in\nmedicine.\u201d\n\nThe study can be accessed via the pre-print website arXiv.\n\nView gallery - 5 images\n\n## Tags\n\nTechnologyArtificial IntelligenceHealthLLM (Large Language\nModel)Google.orgGoogle DeepMindclinicDiagnostic devices\n\n  * Facebook\n  * Twitter\n  * Flipboard\n  * LinkedIn\n\nNo comments\n\nPaul McClure\n\nBefore realizing his writing passion, Paul worked as an intensive care nurse\nand a criminal defense lawyer for many years. He has a keen interest in mental\nhealth and addiction, chronic illness, and medical technology. After\ngraduating with a Bachelor of Arts in journalism and creative writing in 2022,\nPaul joined New Atlas in 2023. Before starting with New Atlas, Paul had\nwritten for several online publications in the areas of health and well-being,\nparenting, entertainment, and popular culture.\n\n## Most Viewed\n\n  * Energy\n\n### Lithium-free sodium batteries exit the lab and enter US production\n\n  * Aircraft\n\n### $190,000 eVTOL deliveries begin July \u2013 no license required\n\n  * Robotics\n\n### Video: Iron-shelled robo-snails swarm together for off-road tasks\n\nLoad More\n\nby Taboolaby Taboola\n\nSponsored LinksSponsored Links\n\nPromoted LinksPromoted Links\n\nYou May Like\n\nVor 1987 geboren? Sie haben Anspruch auf diese VersicherungPro Verbraucher\n\nUndo\n\nRentner in Riesa: So kosten Treppenlifte fast nichtsTreppenlift-Vergleich\n\nUndo\n\nHandsauger: Erfindung aus Deutschland erobert gerade ganz DeutschlandHydrip\n\nUndo\n\nDiese Solardach-F\u00f6rdergelder sind vielen Hausbesitzen v\u00f6llig neu.Checkfox\n\nUndo\n\n0 comments\n\nSign in to post a comment. Please keep comments to less than 150 words. No\nabusive material or spam will be published.\n\nThere are no comments. Be the first!\n\n## GET OUR NEWSLETTER\n\nOver 220,000 people receive our email newsletter. Get your daily dose of\nextraordinary ideas!\n\nRegister\n\nFollow Us\n\n  * twitter\n  * instagram\n  * pinterest\n  * flipboard\n  * facebook\n  * linkedin\n\n\u00a9 2024 New Atlas\n\n# Notice\n\nWe and selected third parties use cookies or similar technologies for\ntechnical purposes and, with your consent, for functionality, experience,\nmeasurement and marketing (personalized ads) as specified in the cookie\npolicy.\n\nWith respect to advertising, we and 856 selected , may use precise geolocation\ndata, and identification through device scanning in order to store and/or\naccess information on a device and process personal data like your usage data\nfor the following : personalised advertising and content, advertising and\ncontent measurement, audience research and services development.\n\nYou can freely give, deny, or withdraw your consent at any time by accessing\nthe preferences panel. If you give consent, it will be valid only in this\ndomain. Denying consent may make related features unavailable.\n\nUse the \u201cAccept\u201d button to consent. Use the \u201cReject\u201d button to continue\nwithout accepting.\n\nPress again to continue 0/2\n\n", "frontpage": false}
