{"aid": "40247568", "title": "Network reconstruction via the minimum description length principle", "url": "https://arxiv.org/abs/2405.01015", "domain": "arxiv.org", "votes": 1, "user": "Anon84", "posted_at": "2024-05-03 13:41:31", "comments": 0, "source_title": "Network reconstruction via the minimum description length principle", "source_text": "[2405.01015] Network reconstruction via the minimum description length\nprinciple\n\nSkip to main content\n\nWe gratefully acknowledge support from the Simons Foundation, member\ninstitutions, and all contributors. Donate\n\n> stat > arXiv:2405.01015\n\n# Statistics > Machine Learning\n\narXiv:2405.01015 (stat)\n\n[Submitted on 2 May 2024]\n\n# Title:Network reconstruction via the minimum description length principle\n\nAuthors:Tiago P. Peixoto\n\nView a PDF of the paper titled Network reconstruction via the minimum\ndescription length principle, by Tiago P. Peixoto\n\nView PDF HTML (experimental)\n\n> Abstract:A fundamental problem associated with the task of network\n> reconstruction from dynamical or behavioral data consists in determining the\n> most appropriate model complexity in a manner that prevents overfitting, and\n> produces an inferred network with a statistically justifiable number of\n> edges. The status quo in this context is based on L_{1} regularization\n> combined with cross-validation. As we demonstrate, besides its high\n> computational cost, this commonplace approach unnecessarily ties the\n> promotion of sparsity with weight \"shrinkage\". This combination forces a\n> trade-off between the bias introduced by shrinkage and the network sparsity,\n> which often results in substantial overfitting even after cross-validation.\n> In this work, we propose an alternative nonparametric regularization scheme\n> based on hierarchical Bayesian inference and weight quantization, which does\n> not rely on weight shrinkage to promote sparsity. Our approach follows the\n> minimum description length (MDL) principle, and uncovers the weight\n> distribution that allows for the most compression of the data, thus avoiding\n> overfitting without requiring cross-validation. The latter property renders\n> our approach substantially faster to employ, as it requires a single fit to\n> the complete data. As a result, we have a principled and efficient inference\n> scheme that can be used with a large variety of generative models, without\n> requiring the number of edges to be known in advance. We also demonstrate\n> that our scheme yields systematically increased accuracy in the\n> reconstruction of both artificial and empirical networks. We highlight the\n> use of our method with the reconstruction of interaction networks between\n> microbial communities from large-scale abundance samples involving in the\n> order of 10^{4} to 10^{5} species, and demonstrate how the inferred model\n> can be used to predict the outcome of interventions in the system.\n\nComments:| 17 pages, 10 figures  \n---|---  \nSubjects:| Machine Learning (stat.ML); Machine Learning (cs.LG); Social and\nInformation Networks (cs.SI); Data Analysis, Statistics and Probability\n(physics.data-an); Populations and Evolution (q-bio.PE)  \nCite as:| arXiv:2405.01015 [stat.ML]  \n(or arXiv:2405.01015v1 [stat.ML] for this version)  \nhttps://doi.org/10.48550/arXiv.2405.01015arXiv-issued DOI via DataCite  \n  \n## Submission history\n\nFrom: Tiago Peixoto [view email] [v1] Thu, 2 May 2024 05:35:09 UTC (19,343 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Network reconstruction via the minimum\ndescription length principle, by Tiago P. Peixoto\n\n  * View PDF\n  * HTML (experimental)\n  * TeX Source\n  * Other Formats\n\nview license\n\nCurrent browse context:\n\nstat.ML\n\n< prev | next >\n\nnew | recent | 2405\n\nChange to browse by:\n\ncs cs.LG cs.SI physics physics.data-an q-bio q-bio.PE stat\n\n### References & Citations\n\n  * INSPIRE HEP\n  * NASA ADS\n  * Google Scholar\n  * Semantic Scholar\n\na export BibTeX citation Loading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer (What is the Explorer?)\n\nLitmaps (What is Litmaps?)\n\nscite Smart Citations (What are Smart Citations?)\n\n# Code, Data and Media Associated with this Article\n\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\n\nDagsHub (What is DagsHub?)\n\nGotit.pub (What is GotitPub?)\n\nPapers with Code (What is Papers with Code?)\n\nScienceCast (What is ScienceCast?)\n\n# Demos\n\nReplicate (What is Replicate?)\n\nHugging Face Spaces (What is Spaces?)\n\nTXYZ.AI (What is TXYZ.AI?)\n\n# Recommenders and Search Tools\n\nInfluence Flower (What are Influence Flowers?)\n\nConnected Papers (What is Connected Papers?)\n\nCORE Recommender (What is CORE?)\n\n  * Author\n  * Venue\n  * Institution\n  * Topic\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new\narXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and\naccepted our values of openness, community, excellence, and user data privacy.\narXiv is committed to these values and only works with partners that adhere to\nthem.\n\nHave an idea for a project that will add value for arXiv's community? Learn\nmore about arXivLabs.\n\nWhich authors of this paper are endorsers? | Disable MathJax (What is MathJax?)\n\n  * About\n  * Help\n\n  * Contact\n  * Subscribe\n\n  * Copyright\n  * Privacy Policy\n\n  * Web Accessibility Assistance\n  * arXiv Operational Status Get status notifications via email or slack\n\n", "frontpage": false}
