{"aid": "40183749", "title": "How to Think Real Good", "url": "https://metarationality.com/how-to-think", "domain": "metarationality.com", "votes": 1, "user": "agarren", "posted_at": "2024-04-27 21:31:02", "comments": 0, "source_title": "How To Think Real Good | Meta-rationality", "source_text": "How To Think Real Good | Meta-rationality\n\nMeta-rationality Essay\n\nLeveling up technical work with context and purpose\n\n# How To Think Real Good\n\n## Thinking about thinking\n\nI enjoy thinking about thinking. That\u2019s one reason I spent a dozen years in\nartificial intelligence research. To make a computer think, you\u2019d need to\nunderstand how you think. So AI research is a way of thinking about thinking\nthat forces you to be specific. It calls your bluff if you think you\nunderstand thinking, but don\u2019t.\n\nI thought a lot about how to do AI. ^1 In 1988, I put together \u201cHow to do\nresearch at the MIT AI Lab,\u201d a guide for graduate students. Although I edited\nit, it was a collaboration of many people. There are now many similar guides,\nsome of them better, but this was the first. Most of its advice was not\nspecific to AI or MIT, and for many years after I got emails with thanks from\nresearchers in all sorts of different fields.\n\nSoon after, I realized that AI was a dead end, and left the field. Although my\nwork in AI was influential, it seemed worthless in retrospect. I had a\npersonal crisis: what should I do instead? The feedback on \u201cHow to do\nresearch\u201d suggested that my thoughts about how to think would be useful more\nwidely. And, I had worked in various fields besides AI, which had their own\nways of thinking. My perspective was uncommonly broad.\n\nMaybe the most useful thing I could do would be to write a book about how to\nthink? I began. My jokey placeholder title was \u201cHow To Think Real Good.\u201d^2 I\nhad a lot of ideas and some sketchy notes, but wound up abandoning the\nproject.\n\n### LessWrong\n\nThis post was prompted by discussions about Bayesianism and the LessWrong\nrationalist community. \u201cHow To Do AI,\u201d like LW, was a broad collaboration.\n\u201cHow To Think Real Good\u201d would probably also have become a community effort.\nAll three projects were about how to think, with an emphasis on technical\nmethods.\n\nMy fascination and frustration with LW comes from my long-standing interest in\nthe same general project, plus liking much of what LW does, plus disliking\nsome of it, plus the sense that LW simply overlooks most of what goes into\neffective, accurate thinking. LW suggests (sometimes, not always) that\nBayesian probability is the main tool for effective, accurate thinking. I\nthink it is only a small part of what you need.\n\nI\u2019ve been making myself obnoxious by griping about this, without explaining\nmost of what my beef is. Several clarifying dialogues with LW community\nmembers have resulted. One question has come up repeatedly:\n\n> If not Bayesianism, then what?\n\nThe implicit assumption is that the problem Bayesianism solves is most of\nrationality, and if I\u2019m unimpressed with Bayesianism, I must advocate some\nother solution to that problem. I do have technical doubts about Bayesianism,\nbut that\u2019s not my point. Rather, I think that the problem Bayesianism\naddresses is a small and easy one.\n\n  * Bayesianism is a theory of probability.\n  * Probability is only a small part of epistemology.\n  * Probability is only a small part of rationality.\n  * Probability is a solved problem. It\u2019s easy. The remaining controversies in the field are arcane and rarely have any practical consequence.\n\nMy answer to \u201cIf not Bayesianism, then what?\u201d is: all of human intellectual\neffort. Figuring out how things work, what\u2019s true or false, what\u2019s effective\nor useless, is \u201chuman complete.\u201d In other words, it\u2019s unboundedly difficult,\nand every human intellectual faculty must be brought to bear.^3 We could call\nthe study of that enterprise \u201cepistemology\u201d; and \u201crationality\u201d is a collection\nof methods for it.^4\n\nMostly, we have no idea how people figure things out. The answer is certainly\nnot going to be some simple bit of math like Bayes\u2019 Rule. We\u2019re not going to\nget a complete story any time soon. What we can do\u2014what I was hoping to do\nwith \u201cHow to think real good\u201d\u2014is find heuristics; rules of thumb that often\nwork in particular sorts of situations.\n\n### Like what?\n\nIn response to which, some LessWrong contributors rightly replied:\n\n> Like what? Be specific!\n\nA proper answer would be a book (which would require suitable collaborators,\nand many more years of thinking about thinking with them).\n\nWhat follows below is, I\u2019m afraid, an off-the-cuff brain dump. I haven\u2019t\nthought about \u201cHow to think real good\u201d in 20 years, and have forgotten\nwhatever I\u2019d worked out then. [Update, years later: This whole web site, and\nthe book it puts online, are a return to that project, and a vast expansion of\nthis 2013 post.]\n\nTo be specific, I\u2019ll tell some anecdotes about thinking. These concentrate on\nthe application of formal methods of thought, mostly because that\u2019s LW\u2019s\norientation. This is probably a wrong emphasis; most insights result from\ninformal reasoning and observation, not technical rationality.\n\nUnderstanding informal reasoning is probably more important than understanding\ntechnical methods.\n\nThat\u2019s an anvilicious moral\u2014an unsubtle take-away message. It\u2019s rude to point\nthese out so boldly, but I thought it might be useful to create a set of\ntopics that a broader discussion of effective thinking could expand on. The\nlist is totally unsystematic and certainly not exhaustive. Mostly I\u2019ll provide\nno evidence or even explanation for these morals. And, they are probably\nannoyingly non-specific. Each one could expand into a book.\n\nThe anecdotes concern academic research, because that\u2019s what \u201cHow to think\nreal good\u201d was going to be about. Nowadays, I\u2019m more interested in the\neveryday understanding of non-academics. That\u2019s the subject of Meaningness,\nand largely of LW too.\n\nThe anecdotes also concern research projects that I took part in, not because\nthose are particularly good examples, but because they come easily to mind. We\ncould do a better job by studying diverse examples of technical progress, but\nI don\u2019t have time for that now.\n\nBefore the anecdotes, I\u2019ll talk in general about problem formulation, because\nthat\u2019s an aspect of epistemology and rationality that I find particularly\nimportant, and that the Bayesian framework entirely ignores.\n\nIt happens that I\u2019m not especially good at solving problems (at least, not as\ncompared with other MIT PhDs). I\u2019m unusually good at selecting and formulating\nthem. So, I\u2019m biased.\n\n## Problem formulation\n\nMany of the heuristics I collected for \u201cHow to think real good\u201d were about how\nto take an unstructured, vague problem domain and get it to the point where\nformal methods become applicable.\n\nFormal methods all require a formal specification of the problem. For example,\nbefore you can apply Bayesian methods, you have to specify what all the\nhypotheses are, what sorts of events constitute \u201cevidence,\u201d how you can\nrecognize one of those events, and (in a decision theoretic framework) what\nthe possible actions are. Bayesianism takes these as given, and has nothing to\nsay about how you choose them. Once you have chosen them, applying the\nBayesian framework is trivial. (It\u2019s just arithmetic, for godssakes!)\n\nFinding a good formulation for a problem is often most of the work of solving\nit.\n\nA bewildered Bayesian might respond:\n\n> You should consider all hypotheses and types of evidence! Omitting some\n> means you might get the wrong answer!\n\nUnfortunately, there are too many. Suppose you want to understand the cause of\nmanic depression. For every grain of sand in the universe, there is the\nhypothesis that this particular grain of sand is the sole cause of manic\ndepression. Finding evidence to rule out each one individually is impractical.\n\n> But, obviously, all grains of sand are equivalent as far as manic depression\n> is concerned! And anyway, sand obviously has nothing to do with manic\n> depression.\n\nYes; but this is not logically necessary. It\u2019s something we can reasonably\nsuppose. But how do we do that? It requires intelligent background\nunderstanding.\n\nThis is something we have to do without explicit thought. We could consider\nand reject sand as a possible cause, but there is an infinite list of other\nlogically possible causes. (Variations in the density of the letter \u201ct\u201d in\nAustrian government documents; chemical reactions that occur only above 873\nkelvin; creatures that, at a distance, resemble flies, or are drawn with a\nvery fine camel hair brush.) We can\u2019t even imagine them all, much less\nevaluate the evidence for them.\n\nSo:\n\nBefore applying any technical method, you have to already have a pretty good\nidea of what the form of the answer will be.\n\nPart of a \u201cpretty good idea\u201d is a vocabulary for describing relevant factors.\nAny situation can be described in infinitely many ways. For example, my\nthinking right now could be described as an elementary particle configuration,\nas molecules in motion, as neurons firing, as sentences, as part of a\nconversation, as primate signaling behavior, as a point in world intellectual\nhistory, and so on.\n\nChoosing a good vocabulary, at the right level of description, is usually key\nto understanding.\n\nA good vocabulary has to do two things. Let\u2019s make them anvils:\n\n1\\. A successful problem formulation has to make the distinctions that are\nused in the problem solution.\n\nSo it mustn\u2019t categorize together things that are relevantly different. Trying\nto find an explanation of manic depression stated only in terms of emotions is\nunlikely to work, because emotions, though relevant, are \u201ctoo big\u201d as\ncategories. \u201cSadness\u201d is probably a complex phenomenon with many different\naspects that get collapsed together in that word.\n\n2\\. A successful problem formulation has to make the problem small enough that\nit\u2019s easy to solve.\n\nTrying to find an explanation of manic depression in terms of brain state\nvectors in which each element is the membrane potential of an individual\nneuron probably won\u2019t work. That description is much too complicated. It makes\nbillions of distinctions that are almost certainly irrelevant. It doesn\u2019t\ncollapse the state space enough; the categories are too small and therefore\ntoo numerous.\n\nIt\u2019s important to understand that problem formulations are never right or\nwrong.\n\nTruth does not apply to problem formulations; what matters is usefulness.\n\nIn fact,\n\nAll problem formulations are \u201cfalse,\u201d because they abstract away details of\nreality.\n\nAny vocabulary pretends that the world is made of objectively separable\n\u201cobjects\u201d (molecules, neurons, emotions, brains, conversations), with well-\ndefined properties. But there are no objects in the real world.^5\n\nThis is going to be a major point in Meaningness; I\u2019ve just begun to discuss\nit here. Since I haven\u2019t had time yet to explain, let me quote Richard Feynman\ninstead:\n\n> Consider an object... What is an object? Philosophers are always saying,\n> \u201cWell, just take a chair for example.\u201d The moment they say that, you know\n> that they do not know what they are talking about. Atoms are evaporating\n> from it from time to time; dirt falls on it and gets dissolved in the paint;\n> so to define a chair precisely, to say exactly which atoms are chair, and\n> which atoms are air, or which atoms are dirt, or which atoms are paint is\n> impossible...\n>\n> There are not any single, left-alone objects in the world\u2014every object is a\n> mixture of a lot of things, so we can deal with it only as a series of\n> approximations and idealizations.\n>\n> The trick is the idealizations. One may prefer a mathematical definition;\n> but those can never work in the real world. A mathematical definition will\n> be good for mathematics, in which all the logic can be followed out\n> completely, but the physical world is [too] complex. When we try to isolate\n> pieces of it, to talk about one mass, the wine and the glass, how can we\n> know which is which, when one dissolves in the other?\n>\n> A system of discourse about the real world must involve approximations of\n> some kind. This is quite unlike the case of mathematics, in which everything\n> can be defined.\n>\n> \u2014The Feynman Lectures on Physics, Vol. 1: p. 12-2; some phrases omitted for\n> concision.\n\nActually, I should probably just shut up and quote Feynman! His books are full\nof insights into thinking, and how formal methods work in practice.^6\n\nAnyway, the trick is the idealizations\u2014the ways you simplify and abstract away\nfrom reality to create a conceptual framework within which you can work on the\nproblem. There\u2019s no such thing as a correct idealization; what you need is one\nthat\u2019s good for a particular job.\n\nThere\u2019s an obvious difficulty here: if you don\u2019t know the solution to a\nproblem, how do you know whether your vocabulary makes the distinctions it\nneeds? The answer is: you can\u2019t be sure; but there are many heuristics that\nmake finding a good formulation more likely. Here are two very general ones:\n\nWork through several specific examples before trying to solve the general\ncase. Looking at specific real-world details often gives an intuitive sense\nfor what the relevant distinctions are.\n\nProblem formulation and problem solution are mutually-recursive processes.\n\nYou need to go back and forth between trying to formulate the problem and\ntrying to solve it. A \u201cwaterfall\u201d approach, in which you take the formulation\nas set in stone and just try to solve it, is rarely effective.\n\nThe difficulty then is that you have to recognize incremental progress in both\nthe formulation and the solution. It\u2019s rare that you can use formal methods to\nevaluate that progress. So a planned major topic in \u201cHow to think real good\u201d\nwas informal, or intuitive, ways to evaluate progress.\n\nHeuristics for evaluating progress are critical not only during problem\nsolving, but also during problem formulation.\n\nA highly general one:\n\nSolve a simplified version of the problem first. If you can\u2019t do even that,\nyou\u2019re in trouble.\n\nA medium-specificity heuristic, applicable mainly in computer science:\n\nIf you are having a hard time, make sure you aren\u2019t trying to solve an NP-\ncomplete problem. If you are, go back and look for additional sources of\nconstraint in the real-world domain.\n\n## Rationality without probability\n\nWhen I say \u201cBayesian methods are a tiny fraction of rationality,\u201d somehow\npeople don\u2019t get it. So let\u2019s look at an example, taken from my Master\u2019s\nthesis.\n\nI was interested in \u201cclassical planning,\u201d a technical problem in robotics\nresearch. Let\u2019s say you have a robot that can only do one thing at a time, and\nyou want to get it to make several things true at once. The classic example\nis: suppose there are three children\u2019s blocks sitting on a table: red, green,\nand blue. The robot can pick up one block at a time and put it on another\nblock. You want a stack with the red block on the green block, and the green\nblock on the blue block. That\u2019s two things (red on green, green on blue) you\nwant to be true simultaneously. The robot could put the red block on the green\nblock, accomplishing the first condition, but then it would be stuck, because\nthe green block has to go on the blue block, and it can only move one block.\n\nApparently, the robot has to plan ahead. It needs to figure out that it has to\nmove the green block first. More generally, classical planning means finding\nan ordered sequence of actions that accomplish several goals at once. Once\nyou\u2019ve got that, you can execute the plan mindlessly, like running a program.\n\nBefore my Master\u2019s work, dozens of researchers had tackled the problem, and\nbuilt complex heuristic planning systems that no one understood well, and that\ndidn\u2019t always work. I produced a simple planning algorithm that I proved\nalways worked (and so definitively solved the problem). This involved a year\nof agony and false starts and half-right attempts. It might be interesting to\ngo back through my lab notebook of the time to analyze how I eventually\nsucceeded.\n\nHowever, part of the process is reflected in my solution, and I intend to draw\nsome anvilicious morals from it. (This analysis is quite technical. You can\nskip ahead to the morals if you like.)\n\nThe algorithm constructs a plan incrementally as a partial order on actions.\nWhen it discovers a constraint on what has to happen before what, it adds an\narc to the time-order digraph.\n\nThe key insight is a modal extension of temporal logic to partial time orders.\nThe \u201cnecessary\u201d operator corresponds to a proposition holding in all\ntotalizations of the partial order; \u201cpossibly\u201d corresponds to a proposition\nholding in some totalization. The algorithm depends on a model theory that\nmakes it possible to compute possible and necessary truth in polynomial time.\n\nGiven this logic, proving that the planner is complete (it can always find a\nplan if there is one) and correct (its claimed plans always work) corresponds\nclosely to demonstrating the completeness and soundness of a proof theory.\n\nMorals?\n\nYou can never know enough mathematics.\n\nI wasn\u2019t smarter than the other people who worked on this problem. (Gerry\nSussman\u2019s PhD thesis was one of the major previous works.) I happened to have\ntaken several advanced courses in mathematical logic (due to my interest in\nrationality), and it happened to be the case that the classical planning\nproblem was easy once it was recast in logical terms. Probably none of the\nprevious researchers in the field happened to have that background.\n\nPut another way,\n\nAn education in math is a better preparation for a career in intellectual\nfield X than an education in X.\n\nI thought Paul Graham said that, but I can\u2019t find it on his web site. The\nclosest I can find is:\n\n> Suppose you\u2019re a college freshman deciding whether to major in math or\n> economics. Well, math will give you more options: you can go into almost any\n> field from math. If you major in math it will be easy to get into grad\n> school in economics, but if you major in economics it will be hard to get\n> into grad school in math.\n\n[Update, three years later: I\u2019ve found it! It was Gian-Carlo Rota: \u201cWhen an\nundergraduate asks me whether he or she should major in mathematics rather\nthan in another field that I will simply call X, my answer is the following:\n\u2018If you major in mathematics, you can switch to X anytime you want to, but not\nthe other way around\u2019.\u201d]\n\nIt was mostly dumb luck that modal logic and model theory turned out to be\nrelevant to classical planning. If other people had realized they were\nrelevant, they could have solved the problem years earlier. So:\n\nYou should learn as many different kinds of math as possible. It\u2019s difficult\nto predict what sort will be relevant to a problem.\n\nThere are heuristics for guessing what formal methods will be relevant,\nthough. I\u2019ll mention some later.\n\n### Look, Ma, no Bayes!\n\nBefore moving on: observations about Bayesianism and rationality, at two\nlevels.\n\nFirst, the classical planning problem is definitely a problem of rationality.\nPutting the red block on the green block first is irrational; putting the\ngreen block on the blue block first is rational. This is a problem Bayes won\u2019t\nhelp with at all.\n\nMy solution was also surely an example of formal rationality; mathematical\nlogic is the standard for that. But it involves no probability theory of any\nsort.\n\nAt the meta level: the year of hard thinking I did to solve the classical\nplanning problem involved huge uncertainties. Was a general solution even\npossible? What sort of approach would work? Was I on the right track, as I\npursued various alternatives? But none of these uncertainties could usefully\nbe modeled with probabilities, I think. The issues were way too amorphous for\nthat.\n\nAt any rate, I certainly wasn\u2019t aware of using probabilistic reasoning. It\u2019s\npossible that I used it unconsciously.\n\nI find it problematic, though, when Bayesians posit unconscious probabilistic\nreasoning as an explanation for rationality in cases where there is no\nevidence. This is dangerously close to \u201cthe God of the gaps\u201d:\n\n> You have no other explanation for the Big Bang (consciousness, ethics,\n> whatever), therefore God did it.\n\nLikewise:\n\n> You don\u2019t know quite how you solved that problem, therefore you used Bayes.\n\n## Reformulating rational action\n\nMy next example comes from work with Phil Agre, which led to both our PhD\ntheses. Phil had an extraordinary series of insights into how effective action\nis possible (with some contributions from me).\n\nIn my Master\u2019s thesis, I had proven that there can be no efficient solution to\nthe classical planning problem. (Formally, it\u2019s NP-complete.) Since people\nobviously do act rationally, this seemed a paradox.\n\nOne of Agre\u2019s insights was that the problem formulation was wrong. That is,\nthe classical planning problem is dissimilar to most actual situations in\nwhich people act rationally.\n\nIf a problem seems too hard, the formulation is probably wrong. Drop your\nformal problem statement, go back to reality, and observe what is going on.\n\nPhil and I spent a couple years in careful observation, recording, and\nanalysis of people actually doing things. From that, we developed an entirely\ndifferent way of thinking about action\u2014both what the problem is, and how to\naddress it.\n\nWe applied as many different intellectual tools as we could find. In the end,\nethnomethodology, an anthropological approach to describing action, was the\nsingle most useful. We also drew on (among others) Gibson\u2019s perceptual\npsychology and Heidegger\u2019s phenomenology of tool use. Each of these fields is\nhighly \u201ctechnical\u201d in the sense of having elaborate, non-obvious methods, but\nnone is \u201cformal\u201d in a mathematical sense.\n\nLearn from fields very different from your own. They each have ways of\nthinking that can be useful at surprising times. Just learning to think like\nan anthropologist, a psychologist, and a philosopher will beneficially stretch\nyour mind.\n\nOne key idea came from a cookbook. Fear of Cooking emphasizes \u201cthe IRIFOY\nprinciple\u201d: it\u2019s right in front of you. You know what scrambled eggs are\nsupposed to be like; you can see what is happening in the pan; so you know\nwhat you need to do next. You don\u2019t need to make a detailed plan ahead of\ntime.\n\nIRIFOY doesn\u2019t always work; sometimes you paint yourself in a corner if you\ndon\u2019t think ahead. But mostly that doesn\u2019t happen; and Phil developed a deep\ntheory of why it doesn\u2019t. One aspect is: we can\u2019t solve NP-complete problems,\nso we organize our lives (and our physical environments) so we don\u2019t have to.\n\n### Dealing effectively with uncertainty without using probability\n\nThe classical formulation was unrealistically hard in some ways, but also\nartificially easy. It did not allow for any sort of uncertainty, for instance.\nWe implemented a series of AI programs that were effective in complex,\nuncertain domains, where the planning approach failed. These domains involved\nboth inherently random events and limited sensory access to relevant factors.\n\nOur programs dealt competently with uncertainty despite not representing it at\nall. A Bayesian approach would have been overwhelmed by computational\ncomplexity; and belief probabilities wouldn\u2019t have contributed to effective\naction anyway. This was the IRIFOY principle again: when our programs needed\nto make decisions, they could actively investigate to see what they needed to\nknow. Most of the facts about their worlds were unknowable, but they could\nfind out enough of what mattered, and ignored the rest.\n\nIt\u2019s possible to attribute unconscious Bayesian reasoning to me, but\ndefinitely not to our programs. Anyone could look at the code and verify a\ntotal absence of probabilities.\n\nIf all you have is a hammer, everything looks like an anvil. If you only know\none formal method of reasoning, you\u2019ll try to apply it in places it doesn\u2019t\nwork.\n\nProbability theory is sometimes an excellent way of dealing with uncertainty,\nbut it\u2019s not the only way, and sometimes it\u2019s a terrible way. One reason is\nthat it collapses together many different sources of uncertainty. For example:\n\n  * inherent effective randomness, due to dynamical chaos\n  * physical inaccessibility of relevant events\n  * time-varying causes (so samples are drawn from different distributions)\n  * sensing/measurement error/noise\n  * model/abstraction approximations (as Feynman explained)\n  * one\u2019s own cognitive/computational limitations\n\nEach of these can be complex, and often they need to be dealt with in quite\ndifferent ways. Summing them up in one number is unhelpful.\n\n### How far will that go?\n\nThe work Phil and I did was highly influential for a while, and we could have\nturned that into tenured professorships at top universities. But we both\nwalked away instead. We recognized that our approach could generate five or so\nyears of further work, but would then fizzle out.\n\nEvaluate the prospects for your field frequently. Be prepared to switch if it\nlooks like it is approaching its inherent end-point.\n\nOne of Feynman\u2019s books has a memorable ranty letter to his wife, written from\na gravity conference, in which he complains that the field is dying, and he\u2019s\nbored stiff, but somehow the oblivious gravity theorists are still taking it\nseriously:\n\n> I am not getting anything out of the meeting. I am learning nothing. Because\n> there are no experiments this field is not an active one, so few of the best\n> men are doing work in it. The result is that there are hosts of dopes here\n> and it is not good for my blood pressure... There is great deal of \u201cactivity\n> in the field\u201d these days, but this \u201cactivity\u201d is mainly in showing that the\n> previous \u201cactivity\u201d of somebody else resulted in an error or in nothing\n> useful or in nothing promising.\n\nI had his advice in mind when I left AI.\n\n## An AI model of problem formulation\n\nLeslie Kaelbling, working with Stan Rosenschein, independently developed a\ntheory of action similar to Agre\u2019s and mine; and then independently recognized\nthe same limitations we did. Around 1990, she and I hoped these limitations\ncould be overcome using machine learning techniques, and we did many\nexperiments on that, independently and in collaboration.\n\n\u201cMachine learning\u201d is basically a collection of statistical techniques. As\nwith other formal methods, they can work well when a problem is framed in\nterms that expose relevant features. They don\u2019t work if your formalization of\nthe problem is not good enough. That is fine if you view them as tools a\nscientist can use to help understand a problem; but our interest was in making\nminds, autonomous creatures that could figure out how to act effectively by\nthemselves.\n\nWe considered a reinforcement learning problem. A creature is thrown into a\ncomplicated world, and at times given a reward (cookies, or maybe utilons).\nInitially, it has no idea what conditions cause it to be rewarded, and no idea\nhow to act to bring about those conditions. Through trial and error, can it\nlearn to act effectively in order to maximize its utility?\n\nThe relevant framework was temporal difference methods. Those worked well if\nthe experimenter abstracted the world into a handful of input values whose\nstatistical relationship with reward was fairly obvious.\n\nBut what we wanted was for the creature to figure out the abstraction itself.\nWe didn\u2019t want to have to formulate the problem; we wanted our program to find\nits own formulation.\n\nMost sensory information is irrelevant to a task, and should be ignored. (It\u2019s\nnoise, relative to action and reinforcement.) But which are the relevant\ninputs? Without knowing that, the then-best available method would be\ninstantly overwhelmed by the combinatorics of a realistically broad flow of\nsense data.\n\nOur idea was that the creature could incrementally construct a formulation of\nthe problem it faced by recognizing inputs that behaved statistically\ndifferently relative to action and reinforcement. Only those were relevant,\nand should be taken into consideration in figuring out an action policy.\n\nWith various refinements, this worked on problems that previous methods\ncouldn\u2019t handle.\n\n### A little math goes a long way\n\nWhen we did this research, neither of us knew much about statistics. In\nparticular, we\u2019d never heard of Student\u2019s t-test, a basic statistical tool.\n\nHowever, we did know enough about what statistics is about, and its\nvocabulary, that we could formulate one of our sub-problems statistically:\n\n> Given two sets of samples drawn from distributions D_1 and D_2, do we have\n> enough data to know whether the two distributions are actually the same or\n> different?\n\nThis was basically the test for whether a sensory input was relevant to\naction. And, having described it that way, it took half an hour of flipping\nthrough Leslie\u2019s stats text together to find out that Student\u2019s t was the tool\nfor the job.\n\nIt\u2019s more important to know what a branch of math is about than to know the\ndetails. You can look those up, if you realize that you need them.\n\nCombined with the earlier moral that it\u2019s good to know many kinds of math,\nthis suggests:\n\nGet a superficial understanding of as many kinds of math as possible. That can\nbe enough that you will recognize when one applies, even if you don\u2019t know how\nto use it.\n\nQuite possibly the t-test was actually the \u201cwrong\u201d tool for the job. Someone\nwho actually knows statistics might say \u201cOh, no! You should use Teacher\u2019s\nu-test, because blah blah.\u201d And they\u2019d be \u201cright\u201d; that might work better, or\nbe more \u201ccorrect.\u201d But the t-test solved the problem for us: the program\nworked.\n\nMath only has to be \u201ccorrect\u201d enough to get the job done.\n\nOne reason for this is that there are often other, larger sources of error\nthan mathematical details. Approximations are fine in engineering, and even in\nphysics (as Feynman pointed out above). Mathematics never perfectly describes\nthe real world.^7 Quoting \u201cHow to do research\u201d:\n\nYou should be able to prove theorems and you should harbor doubts about\nwhether theorems prove anything.\n\nOf course, it\u2019s often good to go on to figure out the \u201cright\u201d answer; it might\nbe important for other, related jobs. Or it might just be interesting for its\nown sake.\n\n## Surface thinking\n\nAfter I decided that \u201cstrong\u201d AI research (making minds) was going nowhere,\nand after the \u201cwhat should I do with my life!?!\u201d existential crisis, I figured\nI\u2019d apply what I knew to something actually useful. Pharmaceutical drug\ndiscovery (finding new medicines) seemed the best bet.\n\nDrugs work by fitting into slots in proteins. This is called the \u201clock and\nkey\u201d model: a particular protein slot has a very specific shape, and how well\na molecule works depends on how nearly it fills the hole.^8 If you know the\nshape of the slot, you can design molecules to fit. But often you don\u2019t know.\nInstead, you have a collection of molecules that don\u2019t fit very well, and some\nthat don\u2019t fit at all, and you want to find ones that fit better.\n\nActually making and testing new molecules is expensive\u2014and the number of\npossible molecules is infinite. What you\u2019d like is a statistical method that\nwould take as input a set of molecules with known degrees of fit, and could\npredict how well a hypothetical new molecule would fit.\n\nI worked on this problem in a team in the early \u201890s. Many of our conceptual\nadvances were due to Ajay Jain, who is perhaps the best problem solver I\u2019ve\ncollaborated with. I learned a lot from him.\n\nI\u2019ve found that pretty smart people are all smart in pretty much the same way,\nbut extremely smart people have unique cognitive styles, which are their\nspecial \u201cedge.\u201d\n\nTry to figure out how people smarter than you think.\n\nFigure out what your own cognitive style is. Embrace and develop it as your\nsecret weapon; but try to learn and appreciate other styles as well.\n\nWhat I observed about Ajay is that he always went for the simplest, most\nobvious, least interesting approach, and made it work. That is not my style at\nall; I\u2019m addicted to \u201cinteresting\u201d approaches. Those usually wind up as\nbaroque failures. Maybe I\u2019m less prone to that after watching Ajay cut through\ncomplexity.\n\nThere\u2019s a quote I\u2019d like to include here that goes something like this:\n\n> Every supposed genius has a bag of tricks\u2014a list of obscure technical\n> methods that hardly anyone knows about, that they have mastered. Every time\n> they hear about a problem, they go through the list mentally, to see if one\n> of the tricks might work. They hardly ever do, but once every year or two,\n> you get a match, and then you look brilliant, like you\u2019ve had some\n> staggering insight. But actually all you did was notice that percolation\n> theory is applicable, or something.\n\n(I thought Feynman said this, or maybe Gian-Carlo Rota, but I can\u2019t find it.)\nPercolation theory was actually one of Danny Hillis\u2019 tricks. I never saw him\nuse it, but we used to compare our lists, and that one came up a couple of\ntimes. It stuck in my mind, and I\u2019ve been hoping to find an application ever\nsince.\n\nRota\u2019s best trick was a method for solving a class of elliptic integrals that\nno one else could crack. These happened to come up a lot in hydrogen bomb\ndesign, so once every few months he\u2019d fly to Los Alamos on a military jet and\nbe locked in a room with some top-secret equations. He wasn\u2019t allowed to take\nthem away, of course, but he also refused to explain his method. He\u2019d solve\nthem entirely in his head and just write down the answers. He was paid well\nfor this... I think I may have wandered off-topic.\n\nCollect your bag of tricks.\n\nRota was the only professor I had who would actually explain how math works\nand how to do it. For some reason, mathematicians find that extremely\nembarrassing, like talking about their bowel movements or something, and they\nabsolutely refuse to discuss it.\n\n...Wait a minute! I\u2019ve just found Rota\u2019s \u201cTen lessons I wish I had been\ntaught,\u201d which includes the \u201cbag of tricks\u201d idea. It\u2019s very funny, and has\nsome good advice. (And it was Feynman, by the way! Except Feynman did it the\nother way around: keep a list of unsolved problems, and check them against any\nnew technique you learn about.)\n\nFind a teacher who is willing to go meta and explain how a field works,\ninstead of lecturing you on its subject matter.^9\n\nSo anyway, back to drugs. Medicinal chemists think about a molecule in terms\nof its connectivity graph: its atoms and covalent bonds. That is entirely\nirrelevant to whether or not it fits into a hole. So, naturally, medicinal\nchemists are bad at predicting whether a molecule will work, and that is one\nof many reasons that pharmaceutical research is unbelievably inefficient.\n\nComputational chemists had developed predictive models that also depended on\nthe connectivity graph, and naturally didn\u2019t work either. This despite the\nfact that everyone knew that what actually matters is the 3D shape.\n\nThis is an example of problem formulation failure. Thinking about molecular\nfit in terms of connectivity was doomed from the outset, because that\nvocabulary does not capture the relevant distinctions (shapes), and makes a\nlot of irrelevant distinctions (graph topologies).\n\nPart of the difficulty was that no one had a good idea about how to represent\nshape. One academic group had developed a prediction method based on shape,\nbut it worked only barely better than the connectivity-based methods. It used\na Cartesian occupancy grid to represent shape. In other words, it had a large\nnumber of voxels, checked each to see whether it was inside or outside the\nmolecule, and used that as the input to the statistical method. This didn\u2019t\nwork well. If the grid was fine enough to discriminate shape accurately\nenough, the number of voxels was so large that it would cause statistical\noverfitting.\n\nAjay invented a much better shape representation, blindingly obvious in\nretrospect. (This was an instance of his trying the simplest thing first, and\nfinding it worked.) It simply consisted of the distances from each of a set of\nfixed reference points to the nearest point on molecule\u2019s surface.\n\nOne reason this worked (dramatically well, we showed) was that every\nmeasurement was directly relevant to what matters: the shape of the surface.\nIn the voxel grid representation, nearly every measurement either tells you\n\u201cthis voxel is not part of the molecule\u201d (in which case you don\u2019t care) or\n\u201cthis voxel is somewhere inside the molecule\u201d (but probably not on the\nsurface, so again it doesn\u2019t matter).\n\nSo this is another instance of the principle that a good problem formulation\nis one that exposes the information relevant to the solution, and eliminates\ninformation that is irrelevant and results in meaningless complexity.\n\n## Conclusions\n\nViolating my main advice, this rambling brain dump included lots of irrelevant\ndetails (like how drugs work), and also failed to expose most of the key\ninformation you\u2019d want (like interestingly specific heuristics for figuring\nstuff out).\n\nIn an attempt to salvage some value, let me try and make some of the main\npoints again, concisely:\n\n  * Figuring stuff out is way hard.\n  * There is no general method.\n  * Selecting and formulating problems is as important as solving them; these each require different cognitive skills.\n  * Problem formulation (vocabulary selection) requires careful, non-formal observation of the real world.\n  * A good problem formulation includes the relevant distinctions, and abstracts away irrelevant ones. This makes problem solution easy.\n  * Little formal tricks (like Bayesian statistics) may be useful, but any one of them is only a tiny part of what you need.\n  * Progress usually requires applying several methods. Learn as many different ones as possible.\n  * Meta-level knowledge of how a field works\u2014which methods to apply to which sorts of problems, and how and why\u2014is critical (and harder to get).\n\nIf I had more time, I could do better. But, figuring out how to figure stuff\nout is even way harder. This is where the LessWrong internet collaborative\napproach shines brilliantly. It really needs to be a community effort.\n\nMaybe we could start in the comment stream for this page?\n\nHow do you think about thinking? What heuristics have you found useful?\n\n77 Comments\n\n  1. 1.That was thinking about thinking about thinking. \u201cAnything you can do, I can do meta,\u201d AI folks often say. But I can do it meta meta!\n  2. 2.My dissertation advisor wrote a book that got translated into Russian, and then translated back into English with the title \u201cHow To Hack Lisp Real Good\u201d. He thought that was very funny and posted it on his office door.\n  3. 3.The analogy is with NP-completeness.\n  4. 4.Neither term is well-defined. The Stanford Encyclopedia of Philosophy gives two definitions for epistemology. The narrow definition is the study of \u201cjustified true belief\u201d\u2014an impoverished and unworkable framework. The wide definition is \u201cissues in the creation and dissemination of knowledge in particular areas of inquiry.\u201d \u201cRationality\u201d is even less well defined, but often involves the use of formal, mathematical tools. This post is mostly about that.\n  5. 5.Not above the level of elementary particles, anyway.\n  6. 6.And he was the most important physicist of the mid-20th century, which makes him harder to argue with than me!\n  7. 7.A unified field theory would, but only at a level that is useless for nearly all practical purposes.\n  8. 8.And on charge distribution, and other factors; I\u2019m simplifying this story because otherwise it will take forever, and you don\u2019t care.\n  9. 9.This is why I am a student of Ngak\u2019chang Rinpoche, who is the only Buddhist teacher I\u2019ve met who can do that.\n\n### Essay\n\nThis web page is a standalone essay, not part of the book, dated August 9th,\n2013.\n\nCopyright \u00a9 2011-2024 David Chapman. Some links are part of the Amazon\nAssociates Program.\n\n", "frontpage": false}
