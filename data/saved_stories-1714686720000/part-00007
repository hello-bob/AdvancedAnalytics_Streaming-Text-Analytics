{"aid": "40236913", "title": "Nvidia Criticizes AI PCs", "url": "https://www.tomshardware.com/tech-industry/artificial-intelligence/nvidia-criticizes-ai-pcs-says-microsofts-45-tops-requirement-is-only-good-enough-for-basic-ai-tasks", "domain": "tomshardware.com", "votes": 4, "user": "DeathArrow", "posted_at": "2024-05-02 14:46:00", "comments": 0, "source_title": "Nvidia criticizes AI PCs, says Microsoft's 45 TOPS requirement is only good enough for 'basic' AI tasks", "source_text": "Nvidia criticizes AI PCs, says Microsoft's 45 TOPS requirement is only good enough for 'basic' AI tasks | Tom's Hardware\n\nSkip to main content\n\nWhen you purchase through links on our site, we may earn an affiliate\ncommission. Here\u2019s how it works.\n\n# Nvidia criticizes AI PCs, says Microsoft's 45 TOPS requirement is only good\nenough for 'basic' AI tasks\n\nNews\n\nBy Aaron Klotz\n\npublished 6 hours ago\n\nNvidia says its GPUs provide substantially better AI-performance than today's\nbleeding edge NPUs.\n\n(Image credit: Nvidia)\n\nNvidia recently showcased the capabilities of its RTX consumer GPUs at a press\nevent, according to Benchlife.Info. The company pointed out how its GPUs are\nbetter than regular NPU-equipped PCs at handling AI tasks. It also presented\nseveral benchmarks, which showed its GPUs outperforming competing notebooks\nwith AI-hardware acceleration including the MacBook Pro featuring Apple's top-\nof-the-line M3 Max chip.\n\nThe entire event was centered around how Nvidia's RTX GPUs outperform modern-\nday \"AI PCs\" equipped with NPUs. According to Nvidia, the 10\u201345 TOPS\nperformance rating found in modern Intel, AMD, Apple, and Qualcomm processors\nis only enough for \"basic\" AI workloads. The company gave several examples,\nincluding photo editing, image generation, image upscaling, and enhanced\ncoding assistance through AI, which it claimed NPU-equipped AI PCs are either\nincapable of handling or are only capable of executing at a very basic level.\nNvidia's GPUs, on the other hand, can handle all AI tasks and execute them\nwith better performance and/or quality, naturally.\n\nImage 1 of 5\n\n(Image credit: Nvidia)\n\n(Image credit: Nvidia)\n\n(Image credit: Nvidia)\n\n(Image credit: Nvidia)\n\n(Image credit: Nvidia)\n\nNvidia stated that its RTX GPUs are much more performant than NPUs and can\nachieve anywhere between 100 to 1300+ TOPS, depending on the GPU. The Nvidia\nevent went so far as to categorize its RTX GPUs as \"Premium AI\" equipment,\nwhile regulating NPUs to a lower \"Basic AI\" equipment category. (Nvidia also\nadded another category, cloud computing, which it categorized as \"Heavy AI\"\nequipment boasting thousands of TOPS of performance, no doubt a nod to its\nH100 and B200 Blackwell enterprise GPUs.)\n\nNvidia shared several AI-focused benchmarks, which compared the latest RTX\n40-series GPUs against some of its competitors. For content creation, Nvidia\nshowed a benchmark comparing the RTX 4090 Laptop GPU, the RTX 4050 Laptop GPU,\nand the Apple Macbook Pro M3 Max in several content creation applications that\nuse AI \u2014 featuring Stable Diffusion, Arnold, Blender, Chaos V-ray, Octane,\nAdobe Premier Pro Enhance Speech, DaVinci Resolve, and ON1 Resize AI. The\nbenchmark showed the RTX 4090 Laptop GPU outperforming the M3 Max-equipped\nMacbook Pro by over 7x in the most extreme cases, and the RTX 4050 Laptop GPU\noutperforming the same Macbook Pro by over 2x. On average, the mobile RTX 4090\noutperformed the M3 Max by 5x while the RTX 4050 LT outperformed it by 50\u2013100\npercent.\n\nAnother benchmark Nvidia showed encompassed large language models (LLMs),\nutilizing a Llama 2 7B int4 LLM workload. Nvidia pitted the mobile RTX 4090\nagainst the M3 Max and the mobile RTX 4050 against Apple's baseline M3 chip.\nThe RTX 4090 was 42% faster than the M3 Max, but with a batch size of eight,\nthe chip was 90% faster. Similarly, the mobile RTX 4050 was 48% faster than\nthe Apple M3, but with a batch size of eight, the RTX 4050 was 90% quicker.\nBatch size changes are an optimization that can improve AI performance,\ndepending on the architecture.\n\nNvidia showed a third benchmark using UL Procyon Stable Diffusion 1.5 against\nAMD. For this test, Nvidia pitted its entire RTX 40-series desktop GPU lineup\nagainst AMD's Radeon RX 7900 XTX. Every Nvidia GPU, starting from the RTX 4070\nSuper and higher, outperformed AMD's flagship \u2014 and the RTX 4090 outperformed\nit by 2.8x. The RTX 4060 Ti and RTX 4060 were noticeably slower, however. The\ntakeaway is that Nvidia's flagship GPU is substantially quicker than the\nequivalent AMD GPU, at least in this specific workload. (Our own Stable\nDiffusion benchmarks tell a similar story, with the 4090 beating the 7900 XTX\nby 2.75X at 768x768 generation and 2.86X with 512x512 image generation.)\n\nWith the spotlight on NPU-equipped AI laptops and AI PCs this year, Nvidia is\nreminding everyone that its RTX GPUs are already far more potent alternatives.\nNot only are they very powerful, there are substantially more RTX GPUs out in\nthe wild today than there are NPU-equipped PCs \u2014 meaning many existing laptops\nand PCs with RTX cards are already AI-ready.\n\nNvidia does make a good point: Its RTX GPUs do provide more performance\ncompared to the latest NPUs seen on Qualcomm's Snapdragon X Elite and AMD's\nRyzen 8040 series counterparts. However, we have yet to see Nvidia RTX GPUs\nbecome a crucial part of AI PCs. Microsoft's official definition for AI PCs\nrequires the addition of an NPU alongside the CPU/GPU \u2014 meaning most RTX-\nequipped systems are still \"unqualified\" as most do not have built-in NPUs.\n\nMicrosoft is also clearly looking at not just raw computational power, but on\nthe efficiency of doing the work. That an RTX 4090 Laptop GPU can pummel\nintegrated NPUs shouldn't surprise everyone. But the mobile 4090 is also rated\nto draw 80W to 150W of power, roughly 2X to 5X more than what many of these\nmobile processors require.\n\nIt will be interesting to see if Microsoft changes its mind on the definition\nof an AI PC in the future \u2014 or more specifically, when it will change the\ndefinition and in what ways. 45 TOPS as a baseline level of performance, via\nan energy efficient NPU, will bring AI acceleration to mainstream consumers.\nIn fact, Microsoft even insists that its Copilot software run on the NPU\ninstead of the GPU, to improve battery life. But it's inevitable that at some\npoint we'll have AI tools that need far more than this initial 45 TOPS of\ncompute, and dedicated GPUs are already far down that path.\n\n## Stay on the Cutting Edge\n\nJoin the experts who read Tom's Hardware for the inside track on enthusiast PC\ntech news \u2014 and have for over 25 years. We'll send breaking news and in-depth\nreviews of CPUs, GPUs, AI, maker hardware and more straight to your inbox.\n\nBy submitting your information you agree to the Terms & Conditions and Privacy\nPolicy and are aged 16 or over.\n\nAaron Klotz\n\nFreelance News Writer\n\nAaron Klotz is a freelance writer for Tom\u2019s Hardware US, covering news topics\nrelated to computer hardware such as CPUs, and graphics cards.\n\nMore about artificial intelligence\n\nAMD uses Ryzen AI to upscale old 40th Anniversary special featuring Nvidia CEO\nJensen Huang\n\nNvidia's ChatRTX chatbot receives major update \u2014 better photo search, AI\nspeech recognition, and more LLM options\n\nLatest\n\nHBM supply from SK hynix and Micron sold out until late 2025\n\nSee more latest \u25ba\n\n10 Comments Comment from the forums\n\n  * usertests\n\nThe point is energy efficiency. There have been a lot of ARM chips out there\nwith around 1-10 TOPS accelerators (such as the RK3566 or MediaTek Genio\n1200). These can be useful, and now similar but even more powerful\ncapabilities are coming to the x86/ Windows (Snapdragon) ecosystem.\n\nIf laptops or desktops are plugged in all the time, it's probably better to\nhave a discrete GPU with much higher performance.\n\nIn the long run, INT4/INT8/BF16/etc. accelerators will become standard in all\ndesktop PCs and consoles, with performance of 100 TOPS or higher, and they\nwill get used instead of the GPU if the GPU's performance isn't needed. That\ncould become relevant to gaming... in the 2030s.\n\nReply\n\n  * Notton\n\nI understand what nvidia is trying to do here. Crypto went bust, so they want\nAI to replace that void in \"gaming\" GPU sales. Thusly, they are pitching TOPS\nperformance to the formerly-crypto-formerly-blockchain-now-AI crowd.\n\nI hope their arrogance comes to bite them in the butt this time around.\n\nReply\n\n  * leoneo.x64\n\nWhy don't they put a CPU / GPU toggle and let users decide? Battery life and\npower consumption hit less than the cost of acquiring new platform for NPU\nbased CPUs. 45 TOPs certainly looks paltry when you add in the cost of\nacquiring new CPUs and therefore a new platform for some users. On the\ncontrary, GPU based AI PC will make it truly flourish\n\nand Intel should not talk about power efficiency after releasing power hogs\nfor decades now. A frugal chip on a power guzzling monster CPU is marketing\nfacade. Laughable Gelsinger strategy\n\nReply\n\n  * edzieba\n\n> usertests said:\n>\n> The point is energy efficiency. There have been a lot of ARM chips out there\n> with around 1-10 TOPS accelerators (such as the RK3566 or MediaTek Genio\n> 1200). These can be useful, and now similar but even more powerful\n> capabilities are coming to the x86/ Windows (Snapdragon) ecosystem.\n\nThe question is, if accelerators of single/double-digit TOPS are actually of\nany value. Are there really any tasks of that scale that can be appreciably\naccelerated with such a minimal performance FFB? With 1000 TOPS of a dedicated\nGPU you can bring a task of hours or minutes down to seconds, which makes it\nan attractive user-oriented \"press button, get result\" feature. If your little\non-die accelerator is just taking a task that takes hours and reducing it to a\nsingle hour, then that's just going to end up being a feature nobody uses.\n\n> Notton said:\n>\n> I understand what nvidia is trying to do here. Crypto went bust, so they\n> want AI to replace that void in \"gaming\" GPU sales. Thusly, they are\n> pitching TOPS performance to the formerly-crypto-formerly-blockchain-now-AI\n> crowd.\n>\n> I hope their arrogance comes to bite them in the butt this time around.\n\n\"Tryng to do\"? Nvidia have for the last several years been building said AI\naccelerator cards, revenue for which dwarfs gaming card (and the entire client\ncard market) revenue and has for quite some time. There isn't any \"trying to\ndo\", this is what they have already done, through a decade of investment in\nCUDA, adding Tensor cores to all their cards, etc.\n\nReply\n\n  * hotaru251\n\nNPU vs Nvidia GPU performance vs energy consumption.\n\nThats the point of NPU.\n\n> Notton said:\n>\n> Crypto went bust, so they want AI to replace that void in \"gaming\" GPU\n> sales.\n\nbad take.\n\nCrypto busting doesnt harm them. they sell more GPU for ai than they ever did\nfor crypto.\n\ni doubt gaming sales are even over 15% of their profit.\n\nWhen you have companies like tesla buying massive amounts of ur ai focused\ngpu's that cost like 10 grand a pop....\n\nJensen already said Nvidia is not a gpu company anymore its an ai company they\njust havent changed name.\n\nWant to do ai stuff? Nvidia is basically ur best option atm (and they know it\nhence their attitude) if you dont care about anything but end result.\n\nnow if u aren't that type of customer (which most arent)? NPU are cheaper &\nmore effective at a lower energy cost. Most people who use \"ai pcs\" arent\nneeding the power from a 4090+ tier of gpu. They are fine w/ a small npu.\n\nNvidias benefit has always been others made their stuff work with nvidia\nfeatures. (mainly cuda) Some are now trying to stop that and make stuff more\nopen source but if it works long term nobody knows.\n\nand if NPU's show as being the future over ur gpu doing it? You can bet nvidia\nwill be there as they have a bunch of really smart people who can make it.\n\nReply\n\n  * Amdlova\n\nOnly thing I want IA do is help with my torrents\n\nReply\n\n  * usertests\n\n> Amdlova said:\n>\n> Only thing I want IA do is help with my torrents\n\nLike what? Maybe future versions of the Tribler torrent client?\nhttps://torrentfreak.com/researchers-showcase-decentralized-ai-powered-\ntorrent-search-engine-240425/\n\n> edzieba said:\n>\n> The question is, if accelerators of single/double-digit TOPS are actually of\n> any value. Are there really any tasks of that scale that can be appreciably\n> accelerated with such a minimal performance FFB? With 1000 TOPS of a\n> dedicated GPU you can bring a task of hours or minutes down to seconds,\n> which makes it an attractive user-oriented \"press button, get result\"\n> feature. If your little on-die accelerator is just taking a task that takes\n> hours and reducing it to a single hour, then that's just going to end up\n> being a feature nobody uses.\n\nProbably some lighter use cases like image recognition/real-time filtering,\nsmall LLMs (Copilot), Stable Diffusion, etc. are fine with the upcoming\nbaseline of ~40-50 TOPS.\n\nQNAP TS-133 1-bay NAS leverages Rockchip RK3566 AI capabilities for object and\nface recognition\n\n> We\u2019ve seen several hardware devices based on Rockchip RK3566 AIoT SoC that\n> do not make use of the key features of the processor. But QNAP TS-133 1-bay\n> NAS is different, since it relies on the native SATA and Gigabit Ethernet\n> interfaces for network storage, and the built-in NPU is leveraged to\n> accelerate object and face recognition by up to 6 times.\n\nThat's using the ~0.8 TOPS NPU in the RK3566. \"Up to 6 times\" the performance\nis probably in relation to either the relatively slow quad-core Cortex-A55, or\nthe Mali-G52 iGPU.\n\nI'm not too keen on the 9-16 TOPS NPUs found in Meteor Lake, Phoenix, and Hawk\nPoint, since they can be outperformed by the accompanying iGPU. That should\nchange this year once we see around 50 TOPS XDNA2 in Strix Point. Future\nversions of these NPUs are likely to hit at least low triple digit TOPS.\n\nReply\n\n  * Neilbob\n\n> edzieba said:\n>\n> If your little on-die accelerator is just taking a task that takes hours and\n> reducing it to a single hour, then that's just going to end up being a\n> feature nobody uses.\n\nI know I sound completely ignorant here, and I am well aware I'm almost\nblindly cynical and skeptical about the Ayy-Eye jiggery-pokery, but please\ntell me exactly what task/s.\n\nWhat are the tasks that will be so ubiquitous that such a large number of\nconsumers (I can't stress that word enough) will require Nvidia's rather\npricey version of TOPS (whatever the heck they are)? What might I need to do\nthat could take hours?\n\nIf I need to 'generate' some kind of image, I can imagine I'd only do it a\ncouple of times out of curiosity and then never bother again. I'm just not\nseeing what all the fuss is meant to be about for someone like me in everyday-\nworld. Please educate me.\n\nReply\n\n  * ivan_vy\n\nsome of us don't need 4090 IA power, we need better videocalling, noise filter\nfor audio and video, light photoediting like color correction and background\nremoval, we live in MS Office world, for everything else we can use the cloud\nservices, power users, researchers and cutting edge content creators they will\neventually go to Nvidia, that's until open source options make a better cost\nbenefit ratio. for gaming would be nice to have AI lighting (RT or PT are to\nHW demanding) and buttery smooth framerates...it looks like where P5Pro is\naiming to go.\n\nReply\n\n  * Eximo\n\nI think the key is that software developers will be encouraged to improve\nbattery life and use the appropriate silicon to maximize that. Generally it\nwould be seamless to the user.\n\nI could also see local processing for things like predictive text, search, or\naction prediction. For instance, loading up the appropriate code into memory\nanticipating the user's next actions. Makes the user experience better, and\nreports up to the big AI on your use habits of course.\n\nReply\n\n##### Most Popular\n\nTesla's wafer-sized Dojo processor is in production \u2014 25 chips combined into\none\n\nUser claims RTX 4090 16-pin power connector melted on both GPU and PSU side,\ndespite running at 75% power\n\nMicrosoft confirms recent Windows security update breaks VPNs, no fix yet\n\nAMD's gaming revenue nosedives 48%, not expected to recover until 2025 \u2014 lack\nof interest in RDNA 3 coupled with fewer console sales\n\nAMD's elusive Ryzen 7 8700F hits Amazon for $299.99 \u2014 pricier than the better-\nperforming 7700X\n\nDev hopes to save legendary Z80 chip with open source clone \u2014 resurrects\niconic Zilog chip with drop-in Z80 replacement\n\nXbox 360 Store to close July 29, 2024 \u2014 But you can still play games without\nissue\n\nChina-made server exports to US plummet \u2014 Taiwan, Mexico remain top server\nimport suppliers\n\nNvidia's ChatRTX chatbot receives major update \u2014 better photo search, AI\nspeech recognition, and more LLM options\n\nA keyboard enthusiast built a $3,400 electro-capacitive keyboard that\nsupposedly gets rid of stabilizer noise\n\nFor sale: Cheyenne supercomputer with 8,064 Xeon CPUs and 306TB of DDR4 memory\n\u2014 some assembly and maintenance required\n\nTom's Hardware is part of Future US Inc, an international media group and\nleading digital publisher. Visit our corporate site.\n\n\u00a9 Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York, NY 10036.\n\n", "frontpage": false}
