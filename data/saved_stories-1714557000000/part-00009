{"aid": "40218095", "title": "Aboriginal Linux", "url": "https://landley.net/aboriginal/about.html", "domain": "landley.net", "votes": 5, "user": "swatson741", "posted_at": "2024-05-01 00:22:06", "comments": 3, "source_title": "Ab Origine - Latin, \"From the beginning\".", "source_text": "Ab Origine - Latin, \"From the beginning\".\n\n|\n\n# Aboriginal Linux  \n  \n---  \n|\n\n  * New to the project? Read About Aboriginal Linux.\n  * Current release: (version 1.4.4, November 11, 2015): build scripts, prebuilt binaries.\n  * Development version: git repository, rss commit feed, snapshot tarball, mailing list.\n\n  \n---  \n| News\n\n  * News\n\nDocumentation\n\n  * About\n  * README\n  * Build Stages\n  * Prebuilt Binaries\n  * Screenshots\n  * FAQ\n  * Presentation (html PDF text)\n\nDownload\n\n  * Source Tarballs\n  * Prebuilt Binaries Current Older\n\nDevelopment\n\n  * Mailing List\n  * Maintainer's Blog\n  * Git Repository\n  * Snapshot Tarball\n  * Commits RSS\n  * Releases RSS\n  * IRC #toybox on freenode.net\n\nControl Images\n\n  * Build Control Images\n\n  \n---  \n  \n# Ab Origine - Latin, \"From the beginning\".\n\n|\n\n  * Build the simplest linux system capable of compiling itself.\n  * Cross compile it to every target supported by QEMU.\n  * Boot it under QEMU (or real hardware).\n  * Build/test everything else natively on target.\n\n  \n---  \n  \n# What is Aboriginal Linux?\n\n## Creating system images.\n\nAboriginal Linux is a shell script that builds the smallest/simplest linux\nsystem capable of rebuilding itself from source code. This currently requires\nseven packages: linux, busybox, uClibc, binutils, gcc, make, and bash. The\nresults are packaged into a system image with shell scripts to boot it under\nQEMU. (It works fine on real hardware too.)\n\nThe build supports most architectures QEMU can emulate (x86, arm, powerpc,\nmips, sh4, sparc...). The build runs as a normal user (no root access\nrequired) and should run on any reasonably current distro, downloading and\ncompiling its own prerequisites from source (including cross compilers).\n\nThe build is modular; each section can be bypassed or replaced if desired. The\nbuild offers a number of configuration options, but if you don't want to run\nthe build yourself you can download binary system images to play with, built\nfor each target with the default options.\n\n(Note: the goal of the 2.0 release is to migrate from busybox, uClibc, and\ngcc/binutils to toybox, musl-libc, and lvm/lld.)\n\n## Using system images.\n\nEach system image tarball contains a wrapper script ./run-emulator.sh which\nboots it to shell prompt. (This requires the emulator QEMU to be installed on\nthe host.) The emulated system's /dev/console is routed to stdin and stdout of\nthe qemu process, so you can just type at it and log the output with \"tee\".\nExiting the shell causes the emulator to shut down and exit.\n\nThe wrapper script ./dev-environment.sh calls run-emulator.sh with extra\noptions to tell QEMU to allocate more memory, attach 2 gigabytes of persistent\nstorage to /home in the emulated system, and to hook distcc up to the cross\ncompiler to move the heavy lifting of compilation outside the emulator (if\ndistccd and the appropriate cross compiler are available on the host system).\n\nThe wrapper script ./native-build.sh calls dev-environment.sh with a build\ncontrol image attached to /mnt in the emulated system, allowing the init\nscript to run /mnt/init instead of launching a shell prompt, providing fully\nautomated native builds. The \"static tools\" (dropbear, strace) and \"linux from\nscratch\" (a chroot tarball) builds are run each release as part of testing,\nwith the results uploaded to the website.\n\nFor more information, see Getting Started or the presentation slides\nDeveloping for non-x86 Targets using QEMU.\n\n# Downloading Aboriginal Linux\n\nPrebuilt binary images are available for each target, based on the current\nAboriginal Linux release. This includes cross compilers, native compilers,\nroot filesystems suitable for chroot, and system images for use with QEMU.  \n---  \n  \nThe binary README describes each tarball. The release notes explain recent\nchanges.\n\nEven if you plan to build your own images from source code, you should\nprobably start by familiarizing yourself with the (known working) binary\nreleases.\n\n# Development\n\nTo build a system image for a target, download the Aboriginal Linux source\ncode and run \"./build.sh\" with the name of the target to build (or with no\narguments to list available targets). See the \"config\" file in the source for\nvarious environment variables you can export to control the build. See the\nsource README for additional usage instructions, and the release notes for\nrecent changes.  \n---  \n  \nAboriginal Linux is a build system for creating bootable system images, which\ncan be configured to run either on real hardware or under emulators (such as\nQEMU). It is intended to reduce or even eliminate the need for further cross\ncompiling, by doing all the cross compiling necessary to bootstrap native\ndevelopment on a given target. (That said, most of what the build does is\ncreate and use cross compilers: we cross compile so you don't have to.)\n\nThe build system is implemented as a series of bash scripts which run to\ncreate the various binary images. The \"build.sh\" script invokes the other\nstages in the correct order, but the stages are designed to run individually.\n(Nothing build.sh itself does is actually important.)\n\nAboriginal Linux is designed as a series of orthogonal layers (the stages\ncalled by build.sh), to increase flexibility and minimize undocumented\ndependencies. Each layer can be either omitted or replaced with something\nelse. The list of layers is in the source README.\n\nThe project maintains a development repository using the Mercurial source\ncontrol system. This includes RSS feeds for each checkin and for new releases.\n\nQuestions about Aboriginal Linux should be addressed to the project's mailing\nlist, or to the maintainer (rob at landley dot net) who has a blog that often\nincludes notes about ongoing Aboriginal Linux development.\n\n# Design goals\n\nIn addition to implementing the above, Aboriginal Linux tries to support a\nnumber of use cases:\n\n  * Eliminate the need for cross compiling\n  * Allow package maintainers to reproduce/fix bugs on more architectures\n  * Automated cross-platform regression testing and portability auditing.\n  * Use current vanilla packages, even on obscure targets.\n  * Provide a minimal self-hosting development environment.\n  * Cleanly separate layers\n  * Document how to put together a development environment.\n\n  \n---  \n  \n  * Eliminate the need for cross compiling\n\nWe cross compile so you don't have to: Moore's Law has made native compiling\nunder emulation a reasonable approach to cross-platform support.\n\nIf you need to scale up development, Aboriginal Linux lets you throw hardware\nat the scalability problem instead of engineering time, using distcc\nacceleration and distributed package build clusters to compile entire\ndistribution repositories on racks of cheap x86 cloud servers.\n\nBut using distcc to call outside the emulator to a cross compiler still acts\nlike a native build. It does not reintroduce the complexities of cross\ncompiling, such as keeping multiple compiler/header/library combinations\nstraight, or preventing configure from confusing the system you build on with\nthe system you deploy on.\n\n  * Allow package developers and maintainers to reproduce and fix bugs on architectures they don't have access to or experience with.\n\nBug reports can include a link to a system image and a reproduction sequence\n(wget source, build, run this test). This provides the maintainer both a way\nto demonstrate the issue, and a native development environment in which to\nbuild and test their fix.\n\nNo special hardware is required for this, just an open source emulator\n(generally QEMU) and a system image to run under it. Use wget to fetch your\nsource, configure and make your package as normal using standard tool names\n(strip, ld, as, etc), even build and test on a laptop in an airplane without\ninternet access (10.0.2.2 is qemu's alias for the host's 127.0.0.1.).\n\n  * Automated cross-platform regression testing and portability auditing.\n\nAboriginal Linux lets you build the same package across multiple\narchitectures, and run the result immediately inside the emulator. You can\neven set up a cron job to build and test regular repository snapshots of a\npackage's development version automatically, and report regressions when\nthey're fresh, when the developers remember what they did, and when there are\nfew recent changes that may have introduced the bug.\n\n  * Use current vanilla packages, even on obscure targets.\n\nNonstandard hardware often receives less testing than common desktop and\nserver platforms, so regressions accumulate. This can lead to a vicious cycle\nwhere everybody sticks with private forks of old versions because making the\nnew ones work is too much trouble, and the new ones don't work because\nnobody's testing and fixing them. The farther you fall behind, the harder it\nis to catch up again, but only the most recent version accepts new patches, so\neven the existing fixes don't go upstream. Worst of all, working in private\nforks becomes the accepted norm, and developers stop even trying to get their\npatches upstream.\n\nAboriginal Linux uses the same (current) package versions across all\narchitectures, in as similar a configuration as possible, and with as few\npatches as we can get away with. We (intentionally) can't upgrade a package\nfor one target without upgrading it for all of them, so we can't put off\ndealing with less-interesting targets.\n\nThis means any supported target stays up to date with current packages in\nunmodified \"vanilla\" form, providing an easy upgrade path to the next version\nand the ability to push your own changes upstream relatively easily.\n\n  * Provide a minimal self-hosting development environment.\n\n> Perfection is achieved, not when there is nothing more to add, but when\n> there is nothing left to take away.\" - Antoine de Saint Exupery\n\nMost build environments provide dozens of packages, ignoring the questions \"do\nyou actually need that?\" and \"what's it for?\" in favor of offering rich\nfunctionality.\n\nAboriginal Linux provides the smallest, simplest starting point capable of\nrebuilding itself under itself, and of bootstrapping up to build arbitrarily\ncomplex environments (such as Linux From Scratch) by building and installing\nadditional packages. (The one package we add which is not strictly required\nfor this, distcc, is installed it in its own subdirectory which is only\noptionally added to the $PATH.)\n\nThis minimalist approach makes it possible to regression test for\nenvironmental dependencies. Sometimes new releases of packages simply won't\nwork without perl, or zlib, or some other dependency that previous versions\ndidn't have, not because they meant to but because they were never tested in a\nbuild environment that didn't have them, so the dependency leaked in.\n\nBy providing a build environment that contains only the bare essentials\n(relying on you to build and install whatever else you need), Aboriginal Linux\nlets you document exactly what dependencies packages actually require, figure\nout what functionality the additional packages provide, and measure the costs\nand benefits of the extra code.\n\n(Note: the command logging wrapper record-commands.sh can actually show which\ncommands were used out of the $PATH when building any package.)\n\n  * Cleanly separate layers.\n\nThe entire build is designed to let you use only the parts of it you want, and\nskip or replace the rest. The top level \"build.sh\" script calls other scripts\nin sequence, each of which is designed to work independently.\n\nThe only place package versions are mentioned is \"download.sh\", the rest of\nthe build is version-agnostic. All it does is populate the \"packages\"\ndirectory, and if you want to provide your own you never need to run this\nscript.\n\nThe \"host-tools.sh\" script protects the build from variations in the host\nsystem, both by building known versions of command line tools (in build/host)\nand adjusting the $PATH to point only to that directory, and by unsetting all\nenvironment variables that aren't in a whitelist. If you want to use the host\nsystem's unfiltered environment instead, just skip running host-tool.sh.\n\nIf you supply your own cross compilers in the $PATH (with the prefixes the\ngiven target expects), you can skip the simple-cross-compiler.sh command.\nSimilarly you can provide your own simple root filesystem, your own native\ncompiler, or your own kernel image. You can use your own script to package\nthem if you like.\n\n  * Document how to put together a development environment.\n\nThe build system is designed to be readable. That's why it's written in Bash\n(rather than something more powerful like Python): so it can act as\ndocumentation. Each shell script collects the series of commands you need to\nrun in order to configure, build, and install the appropriate packages, in the\norder you need to install them in to satisfy their dependencies.\n\nThe build is organized as a series of orthogonal stages. These are called in\norder from build.sh, but may be run (and understood) independently.\nDependencies between them are kept to a minimum, and stages which depend on\nthe output of previous stages document this at the start of the file.\n\nThe scripts are also extensively commented to explain why they do what they\ndo, and there's design documentation on the website.\n\n# What's next?\n\nNow that the 1.0 release is out, what are the project's new goals?\n\n  * Move from busybox, uclibc, and gcc/binutils to toybox, musl, and llvm.\n  * Untangle distro build build system hairballs into distinct layers.\n  * Make Android self-hosting\n\n  \n---  \n  \n## Move from busybox, uclibc, and gcc/binutils to toybox, musl, and llvm (then\nqcc).\n\nNow that we've got a simple development environment working, we can make it\nsimpler by moving to better packages. Most of this project's new development\neffort is going into the upstream versions of those packages until they're\nready for use here. In the meantime we're maintaining what works, but only\nreally upgrading the kernel version and slowly switching from busybox to\ntoybox one command at a time.)\n\nuClibc: The uClibc project's chronic development problems resulted in multiple\nyear-long gaps between releases, and after the may 2012 release more than\nthree years went by without a release during which time musl-libc went from\n\"git init\" to a 1.0 release. At this point it doesn't matter if uClibc did get\nanother release out, it's over, musl is the more interesting project. (Its\nlimitations are lack of target support, but it's easy to port musl to new\ntargets and very hard to clean up the mess uClibc has become.)\n\ntoybox: The maintainer of Aboriginal Linux used to maintain busybox, but left\nthat project and went on to create toybox for reasons explained at length\nelsewhere (video, outline, merged into Android).\n\nThe toybox 1.0 release should include a shell capable of replacing bash, and\nmay include a make implementation (or in qcc, below). This would eliminate two\nmore packages currently used by Aboriginal Linux.\n\nllvm: When gcc and binutils went GPLv3, Aboriginal Linux froze on the last\nGPLv2 releases, essentially maintaining its own fork of those projects.\nSeveral other projects did the same but most of those have since switched to\nllvm.\n\nUnfortunately, configuring and building llvm is unnecessarily hard (among\nother things because it's not just implemented in C++ but the 2013 C++ spec,\nso you need gcc 4.7 or newer to bootstrap it), and nobody seems to have worked\nout how to canadian cross native compilers out of it yet. But other\nalternatives like pcc or tinycc are both less capable and less actively\ndeveloped; since the FSF fell on its sword with GPLv3, the new emerging\nstandard is LLVM.\n\nqcc: In the long run, we'd like to put together a new compiler, qcc, but won't\nhave development effort to spare for it before toybox's 1.0 release. Its goal\nis to combine tinycc and QEMU's Tiny Code Generator into a single multicall\nbinary toolchain (cc, ld, as, strip and so on in a single executable replacing\nboth the gcc and binutils packages) that supports all the output formats QEMU\ncan emulate. (As a single-pass compiler with no intermediate format it\nwouldn't optimize well, but could bootstrap a native compiler that would.)\n\nAdditional goals for qcc would be to absorb ccwrap.c, grow built-in distcc\nequivalent functionality, and an updated rewrite of cfront to compile C++ code\n(and thus natively bootstrap LLVM).\n\nFinishing the full development slate would bring the total number of\nAboriginal Linux packages down to four: linux, toybox, musl, and qcc.\n\n(Yes, reducing dependency on GPL software and avoiding GPLv3 entirely is a\ncommon theme of the above package switches, there's a reason for that: audio,\noutline, see also Android self-hosting below.)\n\n## Untangle distro build system hairballs into distinct layers.\n\nThe goal here is to separate what packages you can build from where and how\nyou can build them.\n\nFor years, Red Hat only built under Red Hat, Debian only built under Debian,\neven Gentoo assumed it was building under Gentoo. Building their packages\nrequired using their root filesystem, and the only way to get their root\nfilesystem was by installing their package binaries built under their root\nfilesystem. The circular nature of this process meant that porting an existing\ndistribution to a new architecture, or making it use a new C library, was\nextremely difficult at best.\n\nThis led cross compilng build systems to add their own package builds (\"the\nbuildroot trap\"), and wind up maintaining their own repository of package\nbuild recipes, configurations, and dependencies. Their few hundred packages\nnever approached the tens of thousands in full distribution repositories, but\nthe effort of maintaining and upgrading packages would come to dominate the\nproject's development effort until developers left to form new projects and\nstart the cycle over again.\n\nThis massive and perpetual reinventing of wheels is wasteful. The\nproliferation of build systems (buildroot, openembedded, yocto/meego/tizen,\nand many more) each has its own set of supported boards and its own half-assed\npackage repository, with no ability to mix and match.\n\nThe proper way to deal with this is to separate the layers so you can mix and\nmatch. Choice of toolchain (and C library), \"board support\" (kernel\nconfiguration, device tree, module selection), and package repository (which\nexisting distro you want to use), all must become independent. Until these are\nproperly separated, your choice of cross compiler limits what boards you can\nboot the result on (even if the binaries you're building would run in a chroot\non that hardware), and either of those choices limit what packages you can\ninstall into the resulting system.\n\nThis means Aboriginal Linux needs to be able to build _just_ toolchains and\nprovide them to other projects (done), and to accept external toolchains\n(implemented but not well tested; most other projects produce cross compilers\nbut not native compilers).\n\nIt also needs build control images to automatically bootstrap a Debian,\nFedora, or Gentoo chroot starting from the minimal development enviornment\nAboriginal Linux creates (possibly through an intermediate Linux From Scratch\nbuild, followed by fixups to make debian/fedora/gentoo happy with the chroot).\nIt must be able to do this on an arbitrary host, using the existing toolchain\nand C library in an architecture-agnostic way. (If the existing system is a\nmusl libc built for a microblaze processor, the new chroot should be too.)\n\nNone of these distributions make it easy: it's not documented, and it breaks.\nSome distributions didn't think things through: Gentoo hardwires the list of\nsupported architectures into every package in the repository, for no apparent\nreason. Adding a new architecture requires touching every package's metadata.\nOthers are outright lazy; building the an allnoconfig Red Hat Enterprise 6.2\nkernel under SLES11p2 is kind of hilariously bad: \"make clean\" spits out an\nerror because the code it added to detect compiler version (something upstream\ndoesn't need) gets confused by \"gcc 4.3\", which has no .0 on the end so the\npatchlevel variable is blank. Even under Red Hat's own filesystem, \"make\nallnoconfig\" breaks on the first C file, and requires almost two dozen config\nsymbols to be switched on to finish the compilation, becuase they never tested\nanything but the config they ship. Making something like that work on a\nHexagon processor, or making their root filesystem work with a vanilla kernel,\nis a daunting task.\n\n## Make Android self-hosting (musl, toybox, qcc).\n\nSmartphones are replacing the PC, and if Android doesn't become self-hosting\nwe may be stuck with locked down iPhone derivatives in the next generation.\n\n> Mainframe -> minicomputer -> microcomputer (PC) -> smartphone\n\nMainframes were replaced by minicomputers, which were replaced by\nmicrocomputers, which are being replaced by smartphones. (Nobody needed to\nstand in line to pick up a printout when they could sign up for a timeslot at\na terminal down the hall. Nobody needed the terminal down the hall when they\nhad a computer on their desk. Now nobody needs the computer on their desk when\nthey have one in their pocket.)\n\nEach time the previous generation got kicked up into the \"server space\", only\naccessed through the newer machines. (This time around kicking the PC up into\nthe server space is called \"the cloud\".)\n\nSmartphones have USB ports, which charge the phone and transfer data. Using a\nsmartphone as a development workstation involves plugging it into a USB hub,\nadding a USB keyboard, USB mouse, and USB to HDMI converter to plug it into a\ntelevision. The rest is software.\n\nThe smartphone needs to \"grow up and become a real computer\" the same way the\nPC did. The PC originally booted into \"ROM Basic\" just like today's Android\nboots into Dalvik Java: as the platform matures it must outgrow this to run\nnative code written in all sorts of languages. PC software was once cross\ncompiled from minicomputers, but as it matured it grew to host its own\ndevelopment tools, powerful enough to rebuild the entire operating system.\n\nTo grow up, Android phones need to become usable as development workstations,\nmeaning the OS needs a self-hosting native development environment. This has\nfour parts:\n\n  * Kernel (we're good)\n  * C library (bionic->musl, not uclibc)\n  * Posix command line (toolbox->toybox, not busybox)\n  * Compiler (qcc, llvm, open64, pcc...)\n\nThe Android kernel is a Linux derivative that adds features without removing\nany, so it's already good enough for now. Convergence to vanilla linux is\nimportant for long-term sustainability, but not time critical. (It's not part\nof \"beating iPhone\".)\n\nAndroid's \"no GPL in userspace\" policy precludes it from shipping many\nexisting Linux packages as part of the base install: no BusyBox or GNU tools,\nno glibc or uClibc, and no gcc or binutils. All those are all excluded from\nthe Android base install, meaning they will never come bundled with the base\noperating system or preinstalled on devices, so we must find alternatives.\n\nAndroid's libc is called \"bionic\", and is a minimal stub sufficient to run\nDalvik, and not much more. Its command line is called \"toolbox\" and is also a\nminimal stub providing little functionality. Part of this is intentional:\nGoogle is shipping a billion broadband-connected unix machines, none of which\nare administered by a competent sysadmin. So for security reasons, Android is\nlocked down with minimal functionality outside the Java VM sandbox, providing\nless of an attack surface for viruses and trojans. In theory the Linux\nContainers infrastructure may eventually provide a solution for sandboxing\napplications, but the base OS needs to be pretty bulletproof if a billion\npeople are going to run code they don't deeply understand connected to\nbroadband internet 24/7.\n\nThus replacement packages for the C library and posix command line should be\nclean simple code easy to audit for security concerns. But it must also\nprovide functionality that bionic and toolbox do not attempt, and do not\nprovide a good base for. The musl libc and toybox command line package should\nbe able to satisfy these requirements.\n\nThe toolchain is a harder problem. The leading contender (LLVM) is sponsored\nby Apple for use in Mac OSX and the iPhone's iOS. The iPhone is ahead of\nAndroid here, and although Android can use this it has other problems\n(implemented in C++ so significantly more complicated from a system dependency\nstandpoint, making it difficult to bootstrap and impossible to audit).\n\nThe simplest option would be to combine the TinyCC project with QEMU's Tiny\nCode Generator (TCG). The licensing of the current TinyCC is incompatible with\nAndroid's userspace but permission has been obtained from Fabrice Bellard to\nBSD-license his original TinyCC code as used in Rob's TinyCC fork. This could\nbe used to implement a \"qcc\" capable of producing code for every platform qemu\nsupports. The result would be simple and auditable, and compatably licensed\nwith android userspace. Unfortunately, such a project is understaffed, and\nwouldn't get properly started until after the 1.0 release of Toybox.\n\nOther potential compiler projects include Open64 and PCC. Neither of these has\nbuilt a bootable the Linux kernel, without which a self-bootstrapping system\nis impossible. (This is a good smoketest for a mature compiler: if it can't\nbuild the kernel, it probably can't build userspace packages of the complexity\npeople actually write.)\n\nWhy does this matter?\n\nThis is time critical due to network effects, which create positive feedback\nloops benefiting the most successful entrant and creating natural \"standards\"\n(which become self-defending monopolies if owned by a single player.)\nWhichever platform has the most users attracts the most development effort,\nbecause it has the most potential customers. The platform all the software\nships on first (often only) is the one everybody wants to have. Other benefits\nto being biggest include the large start-up costs and much lower incremental\ncosts of electronics manufacturing: higher unit volume makes devices cheaper\nto produce. Amortizing research and development budgets over a larger user\nbase means the technology may actually advance faster (more effort, anyway)...\n\nTechnological transitions produce \"S curves\", where a gradual increase gives\nway to exponential increase (the line can go nearly vertical on a graph) and\nthen eventually flattens out again producing a sort of S shape. During the\nsteep part of the S-curve acquiring new customers dominates. Back in the early\nminicomputer days a lot more people had no computer than had an Atari 800 or\nCommodore 64 or Apple II or IBM PC, so each vendor focused on selling to the\ncomputerless than converting customers from other vendors. Once the pool of\n\"people who haven't got the kind of computer we're selling today but would\nlike one if they did\" was exhausted (even if only temporarily, waiting for\ncomputers to get more powerful and easier to use), the largest players starved\nthe smaller ones of new sales, until only the PC and Macintosh were left. (And\nthe Macintosh switched over to PC hardware components to survive, offering\ndifferent software and more attractive packaging of the same basic\ncomponents.)\n\nThe same smartphone transition is inevitable as the pool of \"people with no\nsmartphone, but who would like one if they had it\" runs out. At that point,\nthe largest platform will suck users away from smaller platforms. If the\nwinner is android we can open up the hardware and software. If the winner is\niPhone, we're stuck with decades of microsoft-like monopoly except this time\nthe vendor isn't hamstrung by their own technical incompetence.\n\nThe PC lasted over 30 years from its 1981 introduction until smartphones\nseriously started displacing it. Smartphones themselves will probably last\nabout as long. Once the new standard \"clicks\", we're stuck with it for a long\ntime. Now is when we can influence this decision. Linux's 15 consecutive \"year\nof the linux desktop\" announcements (spanning the period of Microsoft Bob,\nWindows Millennium, and windows Vista) show how hard displacing an entrenched\nstandard held in place by network effects actually is.\n\nWhy not extend vanilla Linux to smartphones instead?\n\nSeveral reasons.\n\n  * It's probably too late for another entrant. Microsoft muscling in with Lumia is like IBM muscling in with OS/2. And Ubuntu on the phone is like Coherent Unix on the PC, unlikely to even register. We have two clear leaders and the rest are noise (\"Coke, Pepsi, and everybody else\"). Possibly they could still gain ground by being categorically better, but \"Categorically better than the newest iPhone/iPad\" is a hard bar to clear.\n\n  * During the minicomputer->PC switch, various big iron vendors tried to shoehorn their products down into the minicomputer space. The results were laughable. (Look up the \"microvax\" sometime.)\n\nThe successful tablets are big phones, not small PCs. Teaching a PC to be a\ngood phone is actually harder than teaching a phone to be a good PC, we\nunderstand the old problem space much better. (It's not that it's less\ndemanding, but the ways in which it is demanding are old hat and long solved.\nBeing a good phone is still tricky.)\n\n  * Deployment requires vendor partnerships which are difficult and slow. Apple exclusively partnered with AT&T for years to build market share, and had much less competition at the time. Google eventually wound up buying Motorola to defend itself from the dysfunctional patent environment. Microsoft hijacked Nokia by installing one of their own people as CEO, and it's done them about as much good as a similiar CEO-installation at SGI did to get Microsoft into the supercomputer market. (Taking out SGI did reduce Microsoft's competition in graphics workstations, but that was a market they already had traction in.)\n\n  * Finally, Linux has had almost 2 decades of annual \"Linux on the Desktop\" pushes that universally failed, and there's a reason for this. Open source development can't do good user interfaces for the same reason wikipedia can't write a novel with a coherent plot. The limitations of the development model do not allow for this. The old adage \"too many cooks spoil the soup\" is not a warning about lack of nutrition, it's a warning that aesthetic issues do not survive committees. Peer review does not produce blockbuster movies, hit songs, or masterpiece paintings. It finds scientific facts, not beauty.\n\nAny time \"shut up and show me the code\" is not the correct response to the\nproblem at hand, open source development melts down into one of three distinct\nfailure modes:\n\n1) Endless discussion that never results in actual code, because nobody can\nagree on a single course of action.\n\n2) The project forks itself to death: everybody goes off and codes up their\npreferred solution, but it's no easier to agree on a single approach after the\ncode exists so the forks never get merged.\n\n3) Delegating the problem to nobody, either by A) separating engine from\ninterface and focusing on the engine in hopes that some glorious day somebody\nwill write an interface worth using, or B) making the interface so\nconfigurable that the fact it takes hours to figure out what your options are\nand still has no sane defaults is now somehow the end user's fault.\n\nOpen source development defeats Brooks' Law by leveraging empirical tests.\nIntegrating the results of decoupled development efforts is made possible by\nthe ability to unequivocally determine which approaches are best (trusted\nengineers break ties, but it has to be pretty close and the arguments go back\nand forth). Even changing the design and repeatedly ripping out existing\nimplementations is doable if everyone can at least retroactively agree that\nwhat we have now is better that what we used to have, and we should stop\nfighting to go back to the old way.\n\nIn the absence of empirical tests, this doesn't work. By their nature,\naesthetic issues do not have emprical tests for \"better\" or \"worse\". Chinese\nfood is not \"better\" than mexican food. But if you can't decide what you're\ndoing (if one chef insists on adding ketchup and another bacon and a third ice\ncream) the end result is an incoherent mess. (At best you get beige and the\nDMV. Navigable with enough effort, but not appealing.)\n\nThe way around this is to a have a single author with a clear vision in charge\nof the user interface, who can make aesthetic decisions that are coherent\nrather than \"correct\". Unfortunately when this does happen, the open source\ncommunity pressures the developer of a successful project to give over control\nof the project to a committee. So the Gecko engine was buried in the unusable\nMozilla browser, then Galleon forked off from that and Mozilla rebased itself\non the Galleon fork. Then Firefox forked off of that and the Mozilla\nfoundation took over Firefox...\n\nPart of the success of Android is that its user experience is NOT community\ndeveloped. (This isn't just desktop, this is \"if the whole thing pauses for\ntwo seconds while somebody's typing in a phone number, that's unacceptable\".\nAll the way down to the bare metal, the OS serves the task of being a handheld\ninteractive touch screen device running off of battery power first, being\nanything else it _could_ be doing second.)\n\n  \nCopyright 2002, 2011 Rob Landley <rob@landley.net>  \n---\n\n", "frontpage": true}
