{"aid": "40113945", "title": "Gusto's Gradual Modularization Destination", "url": "https://engineering.gusto.com/gusto-gradual-modularization-destination/", "domain": "gusto.com", "votes": 1, "user": "mooreds", "posted_at": "2024-04-22 13:01:06", "comments": 0, "source_title": "Gusto's Gradual Modularization Destination", "source_text": "Gusto's Gradual Modularization Destination\n\n08 April 2024\n\n6 min read\n\n# Gusto's Gradual Modularization Destination\n\nGradual Modularization Modular Monolith\n\nWhen talking to developers about gradual modularization, one of the questions\nis, \u201cSo... where are we headed?\u201d That is, what is the destination of a\nmodularization journey? These developers all work in a large, monolithic\ncodebase\u2013the large application that backs much of Gusto\u2019s functionality. Based\non discussions with our peers at different organizations, we know there are a\nwhole bunch of companies in similar situations. These companies all have one\nthing in common, we\u2019re using Ruby and Rails as a significant part of their\nbackend systems.\n\nWe believe there is a juncture that all of these companies should strive to\nmove their packages towards. This realization is based on working on\ncomponent-based application design for over a decade and building the gradual\nmodularization and package-based ecosystem for the last couple of years (if\nyou are looking for an intro to these, check out Laying the Cultural and\nTechnical Foundation for Big Rails and A How-to Guide to Ruby Packs, Gusto's\nGem Ecosystem for Modularizing Ruby Applications). This juncture is this:\n\nGradually modularize packages towards extractable applications and libraries.\n\nA forking path in a forest\n\nLet\u2019s take the two parts of the destination in turn: 1/ What do we mean by\napplications and libraries, and why are they the target? and 2/ What is\nextractability, and why is it a target?\n\n## What we mean by applications and libraries\n\nWe want to use the term application here as software that is run to do\nwhatever it was designed to do. This can, for example, be a desktop\napplication, a web server, or a lambda function. Anything that, in an\noperating environment, can be started and then do its thing. In this broad\nsense, all software we see the effects of or interact with is applications.\nWhat we casually call a \u201cRails app\u201d is an application in this sense.\n\nLibraries are pieces of software that have a packaging and distribution\nmechanism and that are included in applications, extending their runtime\ncapabilities with the functionality offered by the library. In Ruby, gems are\noften libraries in this sense.\n\nThere are technical constraints in how we can combine applications and\nlibraries:\n\n  * Applications can interact with other applications by calling their exposed functionality.\n  * Applications can use libraries by including them.\n  * Libraries can compose functionality by including other libraries.\n\nThere is nuance here that we will largely gloss over for the sake of length:\nthere are libraries that have application characteristics, e.g., gems\nincluding rake tasks that execute like applications, gems that are\napplications like visualize_packs.\n\nAll software is either an application or a library in the sense described\nabove.\n\n## Applications and libraries\n\nIf we go back to the context in which developers ask themselves whether they\nshould use something like the tooling offered by RubyAtScale, we go back to\nthe fact that folks work in monoliths. It is a bummer that \u201cmonolith\u201d is the\nterm the industry landed on because it emphasizes that there is one\n(structure) but fails to emphasize that folks tend not to believe that it is\nof uniform structure - that it represents one thing. Quite the opposite: we\ntend to use it for software that has multitudes in it\u2014multitudes of\nresponsibilities, domains, teams, and, by extension, could have a multitude of\napplications and libraries in it.\n\nFor monoliths that use the RubyAtScale ecosystem, we divide up the application\ncode of a Rails app into packages. If we ask every package whether it wants to\nbe an application or a library, here are the possible answers:\n\n  1. A given package wants to be an application\n  2. A given package wants to be a library\n  3. A given package wants to be... \u201cwell, we\u2019re not sure yet.\u201d\n  4. A given package wants to be both\n\nIf the answer is #1 or #2 for the given package, we can turn to the question\nof what extractable means and how to pursue it. The other two options require\nmore interrogation. If the answer is #3, we need to learn more before\nproceeding. One way to do this by giving ourselves more time: Work on other\npackages where the answer is not #3 and let that both increase our experience\nand clarify more parts of the rest of the application. If the answer is #4,\nyou have just found a package that is a monolith, and you should consider\nsplitting it apart.\n\n## What, in principle, makes a package extractable?\n\nWe use the term extractable for packages that would work on their own when\nextracted from the monolith. A specific practical implementation of this\nnotion of extraction could be the following:\n\n  * The tests of the codebase pass even after deleting all other packages from the application.\n\nIf a package has dependencies on other packages, this might change to:\n\n  * The tests of the codebase pass even after deleting all packages from the application that are not direct or transitive dependencies (via accepted dependencies or violations) of the package.\n\nNote that this second, more general statement doesn\u2019t prove anything for a\nsingle package but rather the remaining group of packages.\n\n## What makes a library extractable?\n\nFor libraries, let\u2019s assume that they enforce a package dependency structure.\nTo test the extractability of a package that wants to be a library, take one\nthat has no more dependencies (or violations) on other packages and do the\nfollowing:\n\n  * Move package code (production code and test code) into a new repository,\n  * Run the tests and fix the visible error. Repeat.\n  * Profit!\n\nWith these \u201clists of three,\u201d expect the core problem to be in the middle. In a\ndiscussion about Shopify\u2019s recent article \"A Packwerk Retrospective,\" one of\nthe authors said that when they did this kind of process, even though they had\nremoved all packwerk violations for a package, only 40% of the tests passed\nwhen they initially extracted in. That is expected because while packwerk is a\ntool that aids in the process of getting toward extractability, it doesn\u2019t\nsupport every part of that process.\n\nHere is a list of some of the things that will likely cause errors when doing\nthe above:\n\n  * Shared test configuration that needs to be carried over (or tests need to be adapted)\n  * Shared test helpers\n\n    * Shared test helpers that hid the fact that entanglements were still present from packwerk via meta-programming (factory_bot)\n  * Shared application configuration that changed default behavior (like initializers)\n  * Product-code metaprogramming that packwerk cannot detect.\n\n## What makes an application extractable?\n\nFor applications to analyze extractability, many more preconditions must be\nmet before we reach extractability.\n\n  * They enforce Public APIs\n  * The Public APIs take and return primitive types (and compositions) only, not function-laden objects.\n  * There are no privacy violations.\n  * The DB is separate.\n\nThese are just the ones applying to the application and the other applications\nit collaborates with. There is one more precondition for the whole system, and\nit is a doozy:\n\n  * The ability to turn any package public API that takes and returns primitive types into an application-external API, e.g., via tools like GRPC, REST, or GraphQL\n\nIf you actually want to run an extracted application separately, you must turn\nthe needed APIs from internal, packwerk-public APIs to externally available\nones.\n\nOnce done, the steps to test extractability are the same as for libraries:\n\n  * Move package code (production code and test code) into a new repository,\n  * Run the tests and fix the visible error. Repeat.\n  * Profit!\n\nIn addition to the list we had for libraries, there will be the following\nthings to fix:\n\n  * Replace calls to now unknown constants with the equivalent public API on the original application.\n  * Get the data of the extracted application into the right state.\n\nNote, in large applications, you may think of groups of packages as wanting to\nbecome an application together. In these cases, the description of this\nsection still works, but some of the ways of doing it change.\n\n## How to extract\n\nIn both cases, when we get to the \u201cprofit\u201d step, the work involved in that\nstep goes something like this:\n\n  * Create the repo,\n  * Make it a gem or an application,\n  * Share it with the org (via an internal gem server or by deploying the app),\n  * Add the dependency/interaction to the original host application,\n  * Remove the package\u2019s code from the original application and rely on the implementation.\n\nAn extraction creates the value of complete separation at the cost of having\nto maintain that separation and the resulting artifacts.\n\n## Where to start? Where to stop?\n\nThe starting point for all of this work, going back to the beginning of this\npost, is the lack of extractable parts of the codebase and not a lack of\nextracted parts. The decision on how far to go with extractability and whether\nto extract is a tradeoff decision of impact and work involved.\n\nWe can depict this choice with a continuum between the three points.\n\nAn arrow going from \"not extractable\" to \"extractable\" and \"extracted\".\n\nWe said above that the juncture is this:\n\nGradually modularize packages towards extractable applications and libraries.\n\nIn this lies the last nuance to the goal of gradual modularization: You decide\nhow far to push along the continuum for each package. This will give you many\noptions for what to pick and optimize for different aspects while on the\njourney:\n\n  * Pick a small, relatively unentangled package to learn or teach the process.\n  * Pick a package responsible for a core part of the business if it lacks stability.\n  * Pick a package that feels auxiliary to the application\u2019s core to protect the core from getting bloated.\n\nSo... when you look over your packages... Do you know what they want to be?\n\nStephan Hagemann\n\n  * Colorado, USA\n\nHead of Product Infrastructure at Gusto\n\nSee all posts by Stephan Hagemann\n\nPrevious Post\n\nEngineering\n\n01 April 2024\n\n# \ud83c\udf4cThe Banana Rule \ud83c\udf4c\n\nSoftware engineers have endless opinions about code line length rules. Instead\nof a rigid numeric limit, consider adopting the delicious fruit-based Banana\nRule.\n\nGraeme Smith\n\n\u2014 TOPIC \u2014\n\n### Gradual Modularization\n\n  * Spaghetti Model Part 4: Safely Remove ActiveRecord Associations and Scopes\n  * The 80% abstraction\n  * A How-to Guide to Ruby Packs, Gusto's Gem Ecosystem for Modularizing Ruby Applications\n\nSee all 5 posts \u2192\n\nGusto Engineering \u00a9 2024 Privacy Do Not Sell/Share Limit Sensitive Info\n\nThe Official Gusto Engineering Blog. We are re-imagining payroll, benefits and\nHR for modern companies.\n\n", "frontpage": false}
