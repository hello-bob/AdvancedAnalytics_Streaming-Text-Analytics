{"aid": "40063019", "title": "Reasons to strive for better disclosure processes", "url": "https://blog.trailofbits.com/2024/04/15/5-reasons-to-strive-for-better-disclosure-processes/", "domain": "trailofbits.com", "votes": 1, "user": "tatersolid", "posted_at": "2024-04-17 11:23:00", "comments": 0, "source_title": "5 reasons to strive for better disclosure processes", "source_text": "5 reasons to strive for better disclosure processes | Trail of Bits Blog\n\n# Trail of Bits Blog\n\n# 5 reasons to strive for better disclosure processes\n\n  * Post\n  * April 15, 2024\n  * Leave a comment\n\nBy Max Ammann\n\nThis blog showcases five examples of real-world vulnerabilities that we\u2019ve\ndisclosed in the past year (but have not publicly disclosed before). We also\nshare the frustrations we faced in disclosing them to illustrate the need for\neffective disclosure processes.\n\nHere are the five bugs:\n\n  * Undefined behavior in the borsh-rs Rust library\n  * Denial-of-service (DoS) vector in Rust libraries for parsing the Ethereum ABI\n  * Missing limit on authentication tag length in Expo\n  * DoS vector in the num-bigint Rust library\n  * Insertion of MMKV database encryption key into Android system log with react-native-mmkv\n\nDiscovering a vulnerability in an open-source project necessitates a careful\napproach, as publicly reporting it (also known as full disclosure) can alert\nattackers before a fix is ready. Coordinated vulnerability disclosure (CVD)\nuses a safer, structured reporting framework to minimize risks. Our five\nexample cases demonstrate how the lack of a CVD process unnecessarily\ncomplicated reporting these bugs and ensuring their remediation in a timely\nmanner.\n\nIn the Takeaways section, we show you how to set up your project for success\nby providing a basic security policy you can use and walking you through a\nstreamlined disclosure process called GitHub private reporting. GitHub\u2019s\nfeature has several benefits:\n\n  * Discreet and secure alerts to developers: no need for PGP-encrypted emails\n  * Streamlined process: no playing hide-and-seek with company email addresses\n  * Simple CVE issuance: no need to file a CVE form at MITRE\n\nTime for action: If you own well-known projects on GitHub, use private\nreporting today! Read more on Configuring private vulnerability reporting for\na repository, or skip to the Takeaways section of this post.\n\n## Case 1: Undefined behavior in borsh-rs Rust library\n\nThe first case, and reason for implementing a thorough security policy,\nconcerned a bug in a cryptographic serialization library called borsh-rs that\nwas not fixed for two years.\n\nDuring an audit, I discovered unsafe Rust code that could cause undefined\nbehavior if used with zero-sized types that don\u2019t implement the Copy trait.\nEven though somebody else reported this bug previously, it was left unfixed\nbecause it was unclear to the developers how to avoid the undefined behavior\nin the code and keep the same properties (e.g., resistance against a DoS\nattack). During that time, the library\u2019s users were not informed about the\nbug.\n\nThe whole process could have been streamlined using GitHub\u2019s private reporting\nfeature. If project developers cannot address a vulnerability when it is\nreported privately, they can still notify Dependabot users about it with a\nsingle click. Releasing an actual fix is optional when reporting\nvulnerabilities privately on GitHub.\n\nI reached out to the borsh-rs developers about notifying users while there was\nno fix available. The developers decided that it was best to notify users\nbecause only certain uses of the library caused undefined behavior. We filed\nthe notification RUSTSEC-2023-0033, which created a GitHub advisory. A few\nmonths later, the developers fixed the bug, and the major release 1.0.0 was\npublished. I then updated the RustSec advisory to reflect that it was fixed.\n\nThe following code contained the bug that caused undefined behavior:\n\n    \n    \n    impl<T> BorshDeserialize for Vec<T> where T: BorshDeserialize, { #[inline] fn deserialize<R: Read>(reader: &mut R) -> Result<Self, Error> { let len = u32::deserialize(reader)?; if size_of::<T>() == 0 { let mut result = Vec::new(); result.push(T::deserialize(reader)?); let p = result.as_mut_ptr(); unsafe { forget(result); let len = len as usize; let result = Vec::from_raw_parts(p, len, len); Ok(result) } } else { // TODO(16): return capacity allocation when we can safely do that. let mut result = Vec::with_capacity(hint::cautious::<T>(len)); for _ in 0..len { result.push(T::deserialize(reader)?); } Ok(result) } } }\n\nFigure 1: Use of unsafe Rust (borsh-rs/borsh-rs/borsh/src/de/mod.rs#123\u2013150)\n\nThe code in figure 1 deserializes bytes to a vector of some generic data type\nT. If the type T is a zero-sized type, then unsafe Rust code is executed. The\ncode first reads the requested length for the vector as u32. After that, the\ncode allocates an empty Vec type. Then it pushes a single instance of T into\nit. Later, it temporarily leaks the memory of the just-allocated Vec by\ncalling the forget function and reconstructs it by setting the length and\ncapacity of Vec to the requested length. As a result, the unsafe Rust code\nassumes that T is copyable.\n\nThe unsafe Rust code protects against a DoS attack where the deserialized in-\nmemory representation is significantly larger than the serialized on-disk\nrepresentation. The attack works by setting the vector length to a large\nnumber and using zero-sized types. An instance of this bug is described in our\nblog post Billion times emptiness.\n\n## Case 2: DoS vector in Rust libraries for parsing the Ethereum ABI\n\nIn July, I disclosed multiple DoS vulnerabilities in four Ethereum API\u2013parsing\nlibraries, which were difficult to report because I had to reach out to\nmultiple parties.\n\nThe bug affected four GitHub-hosted projects. Only the Python project eth_abi\nhad GitHub private reporting enabled. For the other three projects (ethabi,\nalloy-rs, and ethereumjs-abi), I had to research who was maintaining them,\nwhich can be error-prone. For instance, I had to resort to the trick of\ngetting email addresses from maintainers by appending the suffix .patch to\nGitHub commit URLs. The following link shows the non-work email address I used\nfor committing:\n\nhttps://github.com/trailofbits/publications/commit/a2ab5a1cab59b52c4fa\n71b40dae1f597bc063bdf.patch\n\nIn summary, as the group of affected vendors grows, the burden on the reporter\ngrows as well. Because you typically need to synchronize between vendors, the\neffort does not grow linearly but exponentially. Having more projects use the\nGitHub private reporting feature, a security policy with contact information,\nor simply an email in the README file would streamline communication and\nreduce effort.\n\nRead more about the technical details of this bug in the blog post Billion\ntimes emptiness.\n\n## Case 3: Missing limit on authentication tag length in Expo\n\nIn late 2022, Joop van de Pol, a security engineer at Trail of Bits,\ndiscovered a cryptographic vulnerability in expo-secure-store. In this case,\nthe vendor, Expo, failed to follow up with us about whether they acknowledged\nor had fixed the bug, which left us in the dark. Even worse, trying to follow\nup with the vendor consumed a lot of time that could have been spent finding\nmore bugs in open-source software.\n\nWhen we initially emailed Expo about the vulnerability through the email\naddress listed on its GitHub, secure@expo.io, an Expo employee responded\nwithin one day and confirmed that they would forward the report to their\ntechnical team. However, after that response, we never heard back from Expo\ndespite two gentle reminders over the course of a year.\n\nUnfortunately, Expo did not allow private reporting through GitHub, so the\nemail was the only contact address we had.\n\nNow to the specifics of the bug: on Android above API level 23, SecureStore\nuses AES-GCM keys from the KeyStore to encrypt stored values. During\nencryption, the tag length and initialization vector (IV) are generated by the\nunderlying Java crypto library as part of the Cipher class and are stored with\nthe ciphertext:\n\n    \n    \n    /* package */ JSONObject createEncryptedItem(Promise promise, String plaintextValue, Cipher cipher, GCMParameterSpec gcmSpec, PostEncryptionCallback postEncryptionCallback) throws GeneralSecurityException, JSONException { byte[] plaintextBytes = plaintextValue.getBytes(StandardCharsets.UTF_8); byte[] ciphertextBytes = cipher.doFinal(plaintextBytes); String ciphertext = Base64.encodeToString(ciphertextBytes, Base64.NO_WRAP); String ivString = Base64.encodeToString(gcmSpec.getIV(), Base64.NO_WRAP); int authenticationTagLength = gcmSpec.getTLen(); JSONObject result = new JSONObject() .put(CIPHERTEXT_PROPERTY, ciphertext) .put(IV_PROPERTY, ivString) .put(GCM_AUTHENTICATION_TAG_LENGTH_PROPERTY, authenticationTagLength); postEncryptionCallback.run(promise, result); return result; }\n\nFigure 2: Code for encrypting an item in the store, where the tag length is\nstored next to the cipher text (SecureStoreModule.java)\n\nFor decryption, the ciphertext, tag length, and IV are read and then decrypted\nusing the AES-GCM key from the KeyStore.\n\nAn attacker with access to the storage can change an existing AES-GCM\nciphertext to have a shorter authentication tag. Depending on the underlying\nJava cryptographic service provider implementation, the minimum tag length is\n32 bits in the best case (this is the minimum allowed by the NIST\nspecification), but it could be even lower (e.g., 8 bits or even 1 bit) in the\nworst case. So in the best case, the attacker has a small but non-negligible\nprobability that the same tag will be accepted for a modified ciphertext, but\nin the worst case, this probability can be substantial. In either case, the\nsuccess probability grows depending on the number of ciphertext blocks. Also,\nboth repeated decryption failures and successes will eventually disclose the\nauthentication key. For details on how this attack may be performed, see\nAuthentication weaknesses in GCM from NIST.\n\nFrom a cryptographic point of view, this is an issue. However, due to the\nrequired storage access, it may be difficult to exploit this issue in\npractice. Based on our findings, we recommended fixing the tag length to 128\nbits instead of writing it to storage and reading it from there.\n\nThe story would have ended here since we didn\u2019t receive any responses from\nExpo after the initial exchange. But in our second email reminder, we\nmentioned that we were going to publicly disclose this issue. One week later,\nthe bug was silently fixed by limiting the minimum tag length to 96 bits.\nPractically, 96 bits offers sufficient security. However, there is also no\nreason not to go with the higher 128 bits.\n\nThe fix was created exactly one week after our last reminder. We suspect that\nour previous email reminder led to the fix, but we don\u2019t know for sure.\nUnfortunately, we were never credited appropriately.\n\n## Case 4: DoS vector in the num-bigint Rust library\n\nIn July 2023, Sam Moelius, a security engineer at Trail of Bits, encountered a\nDoS vector in the well-known num-bigint Rust library. Even though the\ndisclosure through email worked very well, users were never informed about\nthis bug through, for example, a GitHub advisory or CVE.\n\nThe num-bigint project is hosted on GitHub, but GitHub private reporting is\nnot set up, so there was no quick way for the library author or us to create\nan advisory. Sam reported this bug to the developer of num-bigint by sending\nan email. But finding the developer\u2019s email is error-prone and takes time.\nInstead of sending the bug report directly, you must first confirm that you\u2019ve\nreached the correct person via email and only then send out the bug details.\nWith GitHub private reporting or a security policy in the repository, the\nchannel to send vulnerabilities through would be clear.\n\nBut now let\u2019s discuss the vulnerability itself. The library implements very\nlarge integers that no longer fit into primitive data types like i128. On top\nof that, the library can also serialize and deserialize those data types. The\nvulnerability Sam discovered was hidden in that serialization feature.\nSpecifically, the library can crash due to large memory consumption or if the\nrequested memory allocation is too large and fails.\n\nThe num-bigint types implement traits from Serde. This means that any type in\nthe crate can be serialized and deserialized using an arbitrary file format\nlike JSON or the binary format used by the bincode crate. The following\nexample program shows how to use this deserialization feature:\n\n    \n    \n    use num_bigint::BigUint; use std::io::Read; fn main() -> std::io::Result<()> { let mut buf = Vec::new(); let _ = std::io::stdin().read_to_end(&mut buf)?; let _: BigUint = bincode::deserialize(&buf).unwrap_or_default(); Ok(()) }\n\nFigure 3: Example deserialization format\n\nIt turns out that certain inputs cause the above program to crash. This is\nbecause implementing the Visitor trait uses untrusted user input to allocate a\nspecific vector capacity. The following figure shows the lines that can cause\nthe program to crash with the message memory allocation of 2893606913523067072\nbytes failed.\n\n    \n    \n    impl<'de> Visitor<'de> for U32Visitor { type Value = BigUint; {...omitted for brevity...} #[cfg(not(u64_digit))] fn visit_seq<S>(self, mut seq: S) -> Result<Self::Value, S::Error> where S: SeqAccess<'de>, { let len = seq.size_hint().unwrap_or(0); let mut data = Vec::with_capacity(len); {...omitted for brevity...} } #[cfg(u64_digit)] fn visit_seq<S>(self, mut seq: S) -> Result<Self::Value, S::Error> where S: SeqAccess<'de>, { use crate::big_digit::BigDigit; use num_integer::Integer; let u32_len = seq.size_hint().unwrap_or(0); let len = Integer::div_ceil(&u32_len, &2); let mut data = Vec::with_capacity(len); {...omitted for brevity...} } }\n\nFigure 4: Code that allocates memory based on user input (num-\nbigint/src/biguint/serde.rs#61\u2013108)\n\nWe initially contacted the author on July 20, 2023, and the bug was fixed in\ncommit 44c87c1 on August 22, 2023. The fixed version was released the next day\nas 0.4.4.\n\n## Case 5: Insertion of MMKV database encryption key into Android system log\nwith react-native-mmkv\n\nThe last case concerns the disclosure of a plaintext encryption key in the\nreact-native-mmkv library, which was fixed in September 2023. During a secure\ncode review for a client, I discovered a commit that fixed an untracked\nvulnerability in a critical dependency. Because there was no security advisory\nor CVE ID, neither I nor the client were informed about the vulnerability. The\nlack of vulnerability management caused a situation where attackers knew about\na vulnerability, but users were left in the dark.\n\nDuring the client engagement, I wanted to validate how the encryption key was\nused and handled. The commit fix: Don\u2019t leak encryption key in logs in the\nreact-native-mmkv library caught my attention. The following code shows the\nproblematic log statement:\n\n    \n    \n    MmkvHostObject::MmkvHostObject(const std::string& instanceId, std::string path, std::string cryptKey) { __android_log_print(ANDROID_LOG_INFO, \"RNMMKV\", \"Creating MMKV instance \\\"%s\\\"... (Path: %s, Encryption-Key: %s)\", instanceId.c_str(), path.c_str(), cryptKey.c_str()); std::string* pathPtr = path.size() > 0 ? &path : nullptr; {...omitted for brevity...}\n\nFigure 5: Code that initializes MMKV and also logs the encryption key\n\nBefore that fix, the encryption key I was investigating was printed in\nplaintext to the Android system log. This breaks the threat model because this\nencryption key should not be extractable from the device, even with Android\ndebugging features enabled.\n\nWith the client\u2019s agreement, I notified the author of react-native-mmkv, and\nthe author and I concluded that the library users should be informed about the\nvulnerability. So the author enabled private reporting and together we\npublished a GitHub advisory. The ID CVE-2024-21668 was assigned to the bug.\nThe advisory now alerts developers if they use a vulnerable version of react-\nnative-mmkv when running npm audit or npm install.\n\nThis case highlights that there is basically no way around GitHub advisories\nwhen it comes to npm packages. The only way to feed the output of the npm\naudit command is to create a GitHub advisory. Using private reporting\nstreamlines that process.\n\n## Takeaways\n\nGitHub\u2019s private reporting feature contributes to securing the software\necosystem. If used correctly, the feature saves time for vulnerability\nreporters and software maintainers. The biggest impact of private reporting is\nthat it is linked to the GitHub advisory database\u2014a link that is missing, for\nexample, when using confidential issues in GitLab. With GitHub\u2019s private\nreporting feature, there is now a process for security researchers to publish\nto that database (with the approval of the repository maintainers).\n\nThe disclosure process also becomes clearer with a private report on GitHub.\nWhen using email, it is unclear whether you should encrypt the email and who\nyou should send it to. If you\u2019ve ever encrypted an email, you know that there\nare endless pitfalls.\n\nHowever, you may still want to send an email notification to developers or a\nsecurity contact, as maintainers might miss GitHub notifications. A basic\nemail with a link to the created advisory is usually enough to raise\nawareness.\n\n### Step 1: Add a security policy\n\nPublishing a security policy is the first step towards owning a vulnerability\nreporting process. To avoid confusion, a good policy clearly defines what to\ndo if you find a vulnerability.\n\nGitHub has two ways to publish a security policy. Either you can create a\nSECURITY.md file in the repository root, or you can create a user- or\norganization-wide policy by creating a .github repository and putting a\nSECURITY.md file in its root.\n\nWe recommend starting with a policy generated using the Policymaker by\ndisclose.io (see this example), but replace the Official Channels section with\nthe following:\n\nWe have multiple channels for receiving reports:\n\n* If you discover any security-related issues with a specific GitHub project, click the *Report a vulnerability* button on the *Security* tab in the relevant GitHub project: https://github.com/%5BYOUR_ORG%5D/%5BYOUR_PROJECT%5D. * Send an email to security@example.com\n\nAlways make sure to include at least two points of contact. If one fails, the\nreporter still has another option before falling back to messaging developers\ndirectly.\n\n### Step 2: Enable private reporting\n\nNow that the security policy is set up, check out the referenced GitHub\nprivate reporting feature, a tool that allows discreet communication of\nvulnerabilities to maintainers so they can fix the issue before it\u2019s publicly\ndisclosed. It also notifies the broader community, such as npm, Crates.io, or\nGo users, about potential security issues in their dependencies.\n\nEnabling and using the feature is easy and requires almost no maintenance. The\nonly key is to make sure that you set up GitHub notifications correctly.\nReports get sent via email only if you configure email notifications. The\nreason it\u2019s not enabled by default is that this feature requires active\nmonitoring of your GitHub notifications, or else reports may not get the\nattention they require.\n\nAfter configuring the notifications, go to the \u201cSecurity\u201d tab of your\nrepository and click \u201cEnable vulnerability reporting\u201d:\n\nEmails about reported vulnerabilities have the subject line \u201c(org/repo)\nSummary (GHSA-0000-0000-0000).\u201d If you use the website notifications, you will\nget one like this:\n\nIf you want to enable private reporting for your whole organization, then\ncheck out this documentation.\n\nA benefit of using private reporting is that vulnerabilities are published in\nthe GitHub advisory database (see the GitHub documentation for more\ninformation). If dependent repositories have Dependabot enabled, then\ndependencies to your project are updated automatically.\n\nOn top of that, GitHub can also automatically issue a CVE ID that can be used\nto reference the bug outside of GitHub.\n\nThis private reporting feature is still officially in beta on GitHub. We\nencountered minor issues like the lack of message templates and the inability\nof reporters to add collaborators. We reported the latter as a bug to GitHub,\nbut they claimed that this was by design.\n\n### Step 3: Get notifications via webhooks\n\nIf you want notifications in a messaging platform of your choice, such as\nSlack, you can create a repository- or organization-wide webhook on GitHub.\nJust enable the following event type:\n\nAfter creating the webhook, repository_advisory events will be sent to the set\nwebhook URL. The event includes the summary and description of the reported\nvulnerability.\n\n## How to make security researchers happy\n\nIf you want to increase your chances of getting high-quality vulnerability\nreports from security researchers and are already using GitHub, then set up a\nsecurity policy and enable private reporting. Simplifying the process of\nreporting security bugs is important for the security of your software. It\nalso helps avoid researchers becoming annoyed and deciding not to report a bug\nor, even worse, deciding to turn the vulnerability into an exploit or release\nit as a 0-day.\n\nIf you use GitHub, this is your call to action to prioritize security, protect\nthe public software ecosystem\u2019s security, and foster a safer development\nenvironment for everyone by setting up a basic security policy and enabling\nprivate reporting.\n\nIf you\u2019re not a GitHub user, similar features also exist on other issue-\ntracking systems, such as confidential issues in GitLab. However, not all\nsystems have this option; for instance, Gitea is missing such a feature. The\nreason we focused on GitHub in this post is because the platform is in a\nunique position due to its advisory database, which feeds into, for example,\nthe npm package repository. But regardless of which platform you use, make\nsure that you have a visible security policy and reliable channels set up.\n\n### Share this:\n\n  * Twitter\n  * LinkedIn\n  * Reddit\n  * Telegram\n  * Facebook\n  * Pocket\n  * Email\n  * Print\n\n### Like this:\n\nLike Loading...\n\n### Related\n\nBillion times emptinessDecember 29, 2023In \"Blockchain\"\n\nChaos Communication Congress (37C3) recapFebruary 2, 2024In \"Conferences\"\n\nWrite Rust lints without forking ClippyNovember 9, 2021Similar post\n\nBy Trail of Bits\n\nPosted in Uncategorized\n\n### Leave a ReplyCancel reply\n\n# About Us\n\nSince 2012, Trail of Bits has helped secure some of the world\u2019s most targeted\norganizations and products. We combine high-end security research with a real\nworld attacker mentality to reduce risk and fortify code.\n\nRead more at www.trailofbits.com\n\n# Subscribe via RSS\n\nRSS - Posts\n\n# Recent Posts\n\n  * 5 reasons to strive for better disclosure processes\n  * Introducing Ruzzy, a coverage-guided Ruby fuzzer\n  * Why fuzzing over formal verification?\n  * Streamline your static analysis triage with SARIF Explorer\n  * Read code like a pro with our weAudit VSCode extension\n  * Releasing the Attacknet: A new tool for finding bugs in blockchain nodes using chaos testing\n  * Secure your blockchain project from the start\n  * DARPA awards $1 million to Trail of Bits for AI Cyber Challenge\n  * Out of the kernel, into the tokens\n  * Cryptographic design review of Ockam\n  * Relishing new Fickling features for securing ML systems\n  * How we applied advanced fuzzing techniques to cURL\n  * When try, try, try again leads to out-of-order execution bugs\n  * Our response to the US Army\u2019s RFI on developing AIBOM tools\n  * Circomspect has been integrated into the Sindri CLI\n\n# Yearly Archive\n\n  * 2023\n  * 2022\n  * 2021\n  * 2020\n  * 2019\n  * 2018\n  * 2017\n  * 2016\n  * 2015\n  * 2014\n  * 2013\n  * 2012\n\n# Categories\n\n  * AIxCC (3)\n  * Apple (13)\n  * Application Security (6)\n  * Attacks (13)\n  * Audits (10)\n  * Authentication (6)\n  * Binary Ninja (14)\n  * Blockchain (65)\n  * C/C++ (1)\n  * Capture the Flag (11)\n  * Careers (2)\n  * CodeQL (6)\n  * Compilers (27)\n  * Conferences (31)\n  * Confidential Computing (1)\n  * Containers (3)\n  * Cryptography (57)\n  * Crytic (4)\n  * Cyber Grand Challenge (8)\n  * DARPA (24)\n  * Design Review (1)\n  * Dynamic Analysis (14)\n  * Ecosystem Security (5)\n  * Education (17)\n  * Empire Hacking (7)\n  * Engineering Practice (16)\n  * Events (8)\n  * Exploits (30)\n  * Fuzzing (40)\n  * Go (7)\n  * Guides (15)\n  * Internship Projects (36)\n  * iVerify (5)\n  * Kubernetes (3)\n  * Linux (7)\n  * LLVM (1)\n  * Machine Learning (17)\n  * Malware (7)\n  * Manticore (17)\n  * McSema (11)\n  * Memory Safety (1)\n  * Meta (12)\n  * Mitigations (11)\n  * MLIR (2)\n  * Open Source (11)\n  * osquery (23)\n  * Paper Review (11)\n  * People (6)\n  * Podcast (1)\n  * Policy (9)\n  * Press Release (29)\n  * Privacy (9)\n  * Products (8)\n  * Program Analysis (18)\n  * Recruitment (1)\n  * Remote Work (1)\n  * Research Practice (23)\n  * Reversing (16)\n  * Rust (7)\n  * SafeDocs (1)\n  * Semgrep (7)\n  * Sinter (1)\n  * Slither (4)\n  * Sponsorships (12)\n  * Static Analysis (34)\n  * Supply Chain (3)\n  * Symbolic Execution (18)\n  * Testing Handbook (3)\n  * Threshold Signatures (1)\n  * Tool Release (4)\n  * Training (2)\n  * Uncategorized (35)\n  * VAST (2)\n  * Vulnerability Disclosure (19)\n  * Windows (3)\n  * Working at Trail of Bits (2)\n  * Year in Review (6)\n  * Zero Knowledge (11)\n\nMy Tweets\n\n## Discover more from Trail of Bits Blog\n\nSubscribe now to keep reading and get access to the full archive.\n\nContinue reading\n\nLoading Comments...\n\n%d\n\n", "frontpage": false}
