{"aid": "40129737", "title": "Scc: A fast code counter with complexity calculations and COCOMO estimates", "url": "https://github.com/boyter/scc", "domain": "github.com/boyter", "votes": 1, "user": "mooreds", "posted_at": "2024-04-23 08:25:00", "comments": 0, "source_title": "GitHub - boyter/scc: Sloc, Cloc and Code: scc is a very fast accurate code counter with complexity calculations and COCOMO estimates written in pure Go", "source_text": "GitHub - boyter/scc: Sloc, Cloc and Code: scc is a very fast accurate code\ncounter with complexity calculations and COCOMO estimates written in pure Go\n\n## Navigation Menu\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nboyter / scc Public\n\n  * Sponsor\n  * Notifications\n  * Fork 236\n  * Star 6k\n\nSloc, Cloc and Code: scc is a very fast accurate code counter with complexity\ncalculations and COCOMO estimates written in pure Go\n\n### License\n\n6k stars 236 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# boyter/scc\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n12 Branches\n\n35 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\ngoodactivechore: remove repetitive words (#449)Apr 20, 2024c4900ef \u00b7 Apr 20,\n2024Apr 20, 2024\n\n## History\n\n1,277 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| ci: add arm64 build| Feb 1, 2024  \n  \n### cmd/badges\n\n|\n\n### cmd/badges\n\n| ensure 32 bit works| Nov 29, 2023  \n  \n### examples\n\n|\n\n### examples\n\n| feat: add support for jsonnet (#448)| Apr 19, 2024  \n  \n### packages\n\n|\n\n### packages\n\n| Fix maintainer and remove workflow| Jan 6, 2020  \n  \n### processor\n\n|\n\n### processor\n\n| chore: remove repetitive words (#449)| Apr 20, 2024  \n  \n### scripts\n\n|\n\n### scripts\n\n| remove deprecated functions| Mar 29, 2023  \n  \n### vendor\n\n|\n\n### vendor\n\n| continue to improve badges| Aug 3, 2023  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| clean for 3.1.0 release| Sep 20, 2022  \n  \n### .goreleaser.yml\n\n|\n\n### .goreleaser.yml\n\n| update to latest goreleaser format| Nov 27, 2023  \n  \n### .ignore\n\n|\n\n### .ignore\n\n| Add addtional tests and files for ignore tests| Jul 29, 2019  \n  \n### .travis.yml\n\n|\n\n### .travis.yml\n\n| chanage back to go 1.13 to see if build resolves| Jun 2, 2020  \n  \n### CODE_OF_CONDUCT.md\n\n|\n\n### CODE_OF_CONDUCT.md\n\n| Normalize all the line endings| Jun 5, 2018  \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n| Normalize all the line endings| Jun 5, 2018  \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n| fix: dockerimage configuration| Feb 1, 2024  \n  \n### LANGUAGES.md\n\n|\n\n### LANGUAGES.md\n\n| feat: add support for jsonnet (#448)| Apr 19, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Update LICENSE| Jan 24, 2021  \n  \n### README.md\n\n|\n\n### README.md\n\n| chore: remove repetitive word in README.md (#446)| Apr 12, 2024  \n  \n### SCC-OUTPUT-REPORT.html\n\n|\n\n### SCC-OUTPUT-REPORT.html\n\n| Add https://pkl-lang.org/ support| Feb 13, 2024  \n  \n### UNLICENSE\n\n|\n\n### UNLICENSE\n\n| Normalize all the line endings| Jun 5, 2018  \n  \n### benchmark.sh\n\n|\n\n### benchmark.sh\n\n| Update benchamrks| Sep 20, 2022  \n  \n### go.mod\n\n|\n\n### go.mod\n\n| continue to improve badges| Aug 3, 2023  \n  \n### go.sum\n\n|\n\n### go.sum\n\n| continue to improve badges| Aug 3, 2023  \n  \n### languages.json\n\n|\n\n### languages.json\n\n| feat: add support for jsonnet (#448)| Apr 19, 2024  \n  \n### main.go\n\n|\n\n### main.go\n\n| add ability to remove files matching names| Oct 11, 2022  \n  \n### performance-over-time.png\n\n|\n\n### performance-over-time.png\n\n| Update benchamrks| Sep 20, 2022  \n  \n### scc.jpg\n\n|\n\n### scc.jpg\n\n| Add image :)| Aug 1, 2019  \n  \n### test-all.sh\n\n|\n\n### test-all.sh\n\n| Add https://pkl-lang.org/ support| Feb 13, 2024  \n  \n## Repository files navigation\n\n## Sloc Cloc and Code (scc)\n\nA tool similar to cloc, sloccount and tokei. For counting the lines of code,\nblank lines, comment lines, and physical lines of source code in many\nprogramming languages.\n\nGoal is to be the fastest code counter possible, but also perform COCOMO\ncalculation like sloccount and to estimate code complexity similar to\ncyclomatic complexity calculators. In short one tool to rule them all.\n\nAlso it has a very short name which is easy to type scc.\n\nIf you don't like sloc cloc and code feel free to use the name Succinct Code\nCounter.\n\nDual-licensed under MIT or the UNLICENSE.\n\n### Support\n\nUsing scc commercially? If you want priority support for scc you can purchase\na years worth https://boyter.gumroad.com/l/kgenuv which entitles you to\npriority direct email support from the developer.\n\n### Install\n\n#### Go Get\n\nIf you are comfortable using Go and have >= 1.17 installed:\n\ngo install github.com/boyter/scc/v3@latest\n\nor bleeding edge with\n\ngo install github.com/boyter/scc@master\n\n#### Snap\n\nA snap install exists thanks to Ricardo.\n\n$ sudo snap install scc\n\nNB Snap installed applications cannot run outside of /home\nhttps://askubuntu.com/questions/930437/permission-denied-error-when-running-\napps-installed-as-snap-packages-ubuntu-17 so you may encounter issues if you\nuse snap and attempt to run outside this directory.\n\n#### Homebrew\n\nOr if you have homebrew installed\n\n$ brew install scc\n\n#### MacPorts\n\nOn macOS, you can also install via MacPorts\n\n$ sudo port install scc\n\n#### Scoop\n\nOr if you are using Scoop on Windows\n\n$ scoop install scc\n\n#### Chocolatey\n\nOr if you are using Chocolatey on Windows\n\n$ choco install scc\n\n#### FreeBSD\n\nOn FreeBSD, scc is available as a package\n\n$ pkg install scc\n\nOr, if you prefer to build from source, you can use the ports tree\n\n$ cd /usr/ports/devel/scc && make install clean\n\n### Run in Docker\n\nGo to the directory you want to run scc from.\n\nRun the command below to run the latest release of scc on your current working\ndirectory:\n\n    \n    \n    docker run --rm -it -v \"$PWD:/pwd\" ghcr.io/lhoupert/scc:master scc /pwd\n\n#### Manual\n\nBinaries for Windows, GNU/Linux and macOS for both i386 and x86_64 machines\nare available from the releases page.\n\n#### GitHub Action workflow\n\nhttps://github.com/marketplace/actions/scc-docker-action\nhttps://github.com/iRyanBell/scc-docker-action\n\n.github/workflows/main.yml\n\n    \n    \n    on: [push] jobs: scc_job: runs-on: ubuntu-latest name: A job to count the lines of code. steps: - name: Checkout uses: actions/checkout@v3 - name: Get the lines of code. id: scc uses: iryanbell/scc-docker-action@v1.0.2 with: args: ${{ env.workspace }} -i js,go,html,css\n\n#### GitLab\n\nhttps://about.gitlab.com/blog/2023/02/15/code-counting-in-gitlab/\n\n#### Other\n\nIf you would like to assist with getting scc added into apt/chocolatey/etc...\nplease submit a PR or at least raise an issue with instructions.\n\n### Background\n\nRead all about how it came to be along with performance benchmarks,\n\n  * https://boyter.org/posts/sloc-cloc-code/\n  * https://boyter.org/posts/why-count-lines-of-code/\n  * https://boyter.org/posts/sloc-cloc-code-revisited/\n  * https://boyter.org/posts/sloc-cloc-code-performance/\n  * https://boyter.org/posts/sloc-cloc-code-performance-update/\n\nSome reviews of scc\n\n  * https://nickmchardy.com/2018/10/counting-lines-of-code-in-koi-cms.html\n  * https://www.feliciano.tech/blog/determine-source-code-size-and-complexity-with-scc/\n  * https://metaredux.com/posts/2019/12/13/counting-lines.html\n\nA talk given at the first GopherCon AU about scc (press S to see speaker\nnotes)\n\n  * https://boyter.org/static/gophercon-syd-presentation/\n  * https://www.youtube.com/watch?v=jd-sjoy3GZo\n\nFor performance see the Performance section\n\nOther similar projects,\n\n  * SLOCCount the original sloc counter\n  * cloc, inspired by SLOCCount; implemented in Perl for portability\n  * gocloc a sloc counter in Go inspired by tokei\n  * loc rust implementation similar to tokei but often faster\n  * loccount Go implementation written and maintained by ESR\n  * ployglot ATS sloc counter\n  * tokei fast, accurate and written in rust\n  * sloc coffeescript code counter\n\nInteresting reading about other code counting projects tokei, loc, polyglot\nand loccount\n\n  * https://www.reddit.com/r/rust/comments/59bm3t/a_fast_cloc_replacement_in_rust/\n  * https://www.reddit.com/r/rust/comments/82k9iy/loc_count_lines_of_code_quickly/\n  * http://blog.vmchale.com/article/polyglot-comparisons\n  * http://esr.ibiblio.org/?p=8270\n\nFurther reading about processing files on the disk performance\n\n  * https://blog.burntsushi.net/ripgrep/\n\nUsing scc to process 40 TB of files from Github/Bitbucket/Gitlab\n\n  * https://boyter.org/posts/an-informal-survey-of-10-million-github-bitbucket-gitlab-projects/\n\n### Pitch\n\nWhy use scc?\n\n  * It is very fast and gets faster the more CPU you throw at it\n  * Accurate\n  * Works very well across multiple platforms without slowdown (Windows, Linux, macOS)\n  * Large language support\n  * Can ignore duplicate files\n  * Has complexity estimations\n  * You need to tell the difference between Coq and Verilog in the same directory\n  * cloc yaml output support so potentially a drop in replacement for some users\n  * Can identify or ignore minified files\n  * Able to identify many #! files ADVANCED! #115\n  * Can ignore large files by lines or bytes\n\nWhy not use scc?\n\n  * You don't like Go for some reason\n  * It cannot count D source with different nested multi-line comments correctly #27\n\n### Differences\n\nThere are some important differences between scc and other tools that are out\nthere. Here are a few important ones for you to consider.\n\nBlank lines inside comments are counted as comments. While the line is\ntechnically blank the decision was made that once in a comment everything\nthere should be considered a comment until that comment is ended. As such the\nfollowing,\n\n    \n    \n    /* blank lines follow */\n\nWould be counted as 4 lines of comments. This is noticeable when comparing\nscc's output to other tools on large repositories.\n\nscc is able to count verbatim strings correctly. For example in C# the\nfollowing,\n\n    \n    \n    private const string BasePath = @\"a:\\\"; // The below is returned to the user as a version private const string Version = \"1.0.0\";\n\nBecause of the prefixed @ this string ends at the trailing \" by ignoring the\nescape character \\ and as such should be counted as 2 code lines and 1\ncomment. Some tools are unable to deal with this and instead count up to the\n\"1.0.0\" as a string which can cause the middle comment to be counted as code\nrather than a comment.\n\nscc will also tell you the number of bytes it has processed (for most output\nformats) allowing you to estimate the cost of running some static analysis\ntools.\n\n### Usage\n\nCommand line usage of scc is designed to be as simple as possible. Full\ndetails can be found in scc --help or scc -h. Note that the below reflects the\nstate of master not a release, as such features listed below may be missing\nfrom your installation.\n\n    \n    \n    $ scc -h Sloc, Cloc and Code. Count lines of code in a directory with complexity estimation. Version 3.2.0 Ben Boyter <ben@boyter.org> + Contributors Usage: scc [flags] [files or directories] Flags: --avg-wage int average wage value used for basic COCOMO calculation (default 56286) --binary disable binary file detection --by-file display output for every file --ci enable CI output settings where stdout is ASCII --cocomo-project-type string change COCOMO model type [organic, semi-detached, embedded, \"custom,1,1,1,1\"] (default \"organic\") --count-as string count extension as language [e.g. jsp:htm,chead:\"C Header\" maps extension jsp to html and chead to C Header] --currency-symbol string set currency symbol (default \"$\") --debug enable debug output --eaf float the effort adjustment factor derived from the cost drivers (1.0 if rated nominal) (default 1) --exclude-dir strings directories to exclude (default [.git,.hg,.svn]) -x, --exclude-ext strings ignore file extensions (overrides include-ext) [comma separated list: e.g. go,java,js] --file-gc-count int number of files to parse before turning the GC on (default 10000) -f, --format string set output format [tabular, wide, json, csv, csv-stream, cloc-yaml, html, html-table, sql, sql-insert, openmetrics] (default \"tabular\") --format-multi string have multiple format output overriding --format [e.g. tabular:stdout,csv:file.csv,json:file.json] --gen identify generated files --generated-markers strings string markers in head of generated files (default [do not edit,<auto-generated />]) -h, --help help for scc -i, --include-ext strings limit to file extensions [comma separated list: e.g. go,java,js] --include-symlinks if set will count symlink files -l, --languages print supported languages and extensions --large-byte-count int number of bytes a file can contain before being removed from output (default 1000000) --large-line-count int number of lines a file can contain before being removed from output (default 40000) --min identify minified files -z, --min-gen identify minified or generated files --min-gen-line-length int number of bytes per average line for file to be considered minified or generated (default 255) --no-cocomo remove COCOMO calculation output -c, --no-complexity skip calculation of code complexity -d, --no-duplicates remove duplicate files from stats and output --no-gen ignore generated files in output (implies --gen) --no-gitignore disables .gitignore file logic --no-ignore disables .ignore file logic --no-large ignore files over certain byte and line size set by max-line-count and max-byte-count --no-min ignore minified files in output (implies --min) --no-min-gen ignore minified or generated files in output (implies --min-gen) --no-size remove size calculation output -M, --not-match stringArray ignore files and directories matching regular expression -o, --output string output filename (default stdout) --overhead float set the overhead multiplier for corporate overhead (facilities, equipment, accounting, etc.) (default 2.4) --remap-all string inspect every file and remap by checking for a string and remapping the language [e.g. \"-*- C++ -*-\":\"C Header\"] --remap-unknown string inspect files of unknown type and remap by checking for a string and remapping the language [e.g. \"-*- C++ -*-\":\"C Header\"] --size-unit string set size unit [si, binary, mixed, xkcd-kb, xkcd-kelly, xkcd-imaginary, xkcd-intel, xkcd-drive, xkcd-bakers] (default \"si\") --sloccount-format print a more SLOCCount like COCOMO calculation -s, --sort string column to sort by [files, name, lines, blanks, code, comments, complexity] (default \"files\") --sql-project string use supplied name as the project identifier for the current run. Only valid with the --format sql or sql-insert option -t, --trace enable trace output (not recommended when processing multiple files) -v, --verbose verbose output --version version for scc -w, --wide wider output with additional statistics (implies --complexity)\n\nOutput should look something like the below for the redis project\n\n    \n    \n    $ scc redis \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Language Files Lines Blanks Comments Code Complexity \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 C 296 180267 20367 31679 128221 32548 C Header 215 32362 3624 6968 21770 1636 TCL 143 28959 3130 1784 24045 2340 Shell 44 1658 222 326 1110 187 Autoconf 22 10871 1038 1326 8507 953 Lua 20 525 68 70 387 65 Markdown 16 2595 683 0 1912 0 Makefile 11 1363 262 125 976 59 Ruby 10 795 78 78 639 116 gitignore 10 162 16 0 146 0 YAML 6 711 46 8 657 0 HTML 5 9658 2928 12 6718 0 C++ 4 286 48 14 224 31 License 4 100 20 0 80 0 Plain Text 3 185 26 0 159 0 CMake 2 214 43 3 168 4 CSS 2 107 16 0 91 0 Python 2 219 12 6 201 34 Systemd 2 80 6 0 74 0 BASH 1 118 14 5 99 31 Batch 1 28 2 0 26 3 C++ Header 1 9 1 3 5 0 Extensible Styleshe... 1 10 0 0 10 0 Smarty Template 1 44 1 0 43 5 m4 1 562 116 53 393 0 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Total 823 271888 32767 42460 196661 38012 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Estimated Cost to Develop (organic) $6,918,301 Estimated Schedule Effort (organic) 28.682292 months Estimated People Required (organic) 21.428982 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Processed 9425137 bytes, 9.425 megabytes (SI) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nNote that you don't have to specify the directory you want to run against.\nRunning scc will assume you want to run against the current directory.\n\nYou can also run against multiple files or directories scc directory1\ndirectory2 file1 file2 with the results aggregated in the output.\n\n### Ignore Files\n\nscc mostly supports .ignore files inside directories that it scans. This is\nsimilar to how ripgrep, ag and tokei work. .ignore files are 100% the same as\n.gitignore files with the same syntax, and as such scc will ignore files and\ndirectories listed in them. You can add .ignore files to ignore things like\nvendored dependency checked in files and such. The idea is allowing you to add\na file or folder to git and have ignored in the count.\n\n### Interesting Use Cases\n\nUsed inside Intel Nemu Hypervisor to track code changes between revisions\nhttps://github.com/intel/nemu/blob/topic/virt-x86/tools/cloc-change.sh#L9\nAppears to also be used inside both http://codescoop.com/\nhttps://pinpoint.com/ https://github.com/chaoss/grimoirelab-graal\n\nIt also is used to count code and guess language types in\nhttps://searchcode.com/ which makes it one of the most frequently run code\ncounters in the world.\n\nYou can also hook scc into your gitlab pipeline https://gitlab.com/guided-\nexplorations/ci-cd-plugin-extensions/ci-cd-plugin-extension-scc\n\nAlso used by CodeQL #317 and Scaleway\nhttps://twitter.com/Scaleway/status/1488087029476995074?s=20&t=N2-z6O-ISDdDzULg4o4uVQ\n\n### Features\n\nscc uses a small state machine in order to determine what state the code is\nwhen it reaches a newline \\n. As such it is aware of and able to count\n\n  * Single Line Comments\n  * Multi Line Comments\n  * Strings\n  * Multi Line Strings\n  * Blank lines\n\nBecause of this it is able to accurately determine if a comment is in a string\nor is actually a comment.\n\nIt also attempts to count the complexity of code. This is done by checking for\nbranching operations in the code. For example, each of the following for if\nswitch while else || && != == if encountered in Java would increment that\nfiles complexity by one.\n\n### Complexity Estimates\n\nLets take a minute to discuss the complexity estimate itself.\n\nThe complexity estimate is really just a number that is only comparable to\nfiles in the same language. It should not be used to compare languages\ndirectly without weighting them. The reason for this is that its calculated by\nlooking for branch and loop statements in the code and incrementing a counter\nfor that file.\n\nBecause some languages don't have loops and instead use recursion they can\nhave a lower complexity count. Does this mean they are less complex? Probably\nnot, but the tool cannot see this because it does not build an AST of the code\nas it only scans through it.\n\nGenerally though the complexity there is to help estimate between projects\nwritten in the same language, or for finding the most complex file in a\nproject scc --by-file -s complexity which can be useful when you are\nestimating on how hard something is to maintain, or when looking for those\nfiles that should probably be refactored.\n\nAs for how it works.\n\nIt's my own definition, but tries to be an approximation of cyclomatic\ncomplexity https://en.wikipedia.org/wiki/Cyclomatic_complexity although done\nonly on a file level.\n\nThe reason it's an approximation is that it's calculated almost for free from\na CPU point of view (since its a cheap lookup when counting), whereas a real\ncyclomatic complexity count would need to parse the code. It gives a\nreasonable guess in practice though even if it fails to identify recursive\nmethods. The goal was never for it to be exact.\n\nIn short when scc is looking through what it has identified as code if it\nnotices what are usually branch conditions it will increment a counter.\n\nThe conditions it looks for are compiled into the code and you can get an idea\nfor them by looking at the JSON inside the repository. See\nhttps://github.com/boyter/scc/blob/master/languages.json#L3524 for an example\nof what it's looking at for a file that's Java.\n\nThe increment happens for each of the matching conditions and produces the\nnumber you see.\n\n### COCOMO\n\nThe COCOMO statistics displayed at the bottom of any command line run can be\nconfigured as needed.\n\n    \n    \n    Estimated Cost to Develop (organic) $664,081 Estimated Schedule Effort (organic) 11.772217 months Estimated People Required (organic) 5.011633\n\nTo change the COCOMO parameters, you can either use one of the default COCOMO\nmodels.\n\n    \n    \n    scc --cocomo-project-type organic scc --cocomo-project-type semi-detached scc --cocomo-project-type embedded\n\nYou can also supply your own parameters if you are familiar with COCOMO as\nfollows,\n\n    \n    \n    scc --cocomo-project-type \"custom,1,1,1,1\"\n\nSee below for details about how the model choices, and the parameters they\nuse.\n\nOrganic \u2013 A software project is said to be an organic type if the team size\nrequired is adequately small, the problem is well understood and has been\nsolved in the past and also the team members have a nominal experience\nregarding the problem.\n\nscc --cocomo-project-type \"organic,2.4,1.05,2.5,0.38\"\n\nSemi-detached \u2013 A software project is said to be a Semi-detached type if the\nvital characteristics such as team-size, experience, knowledge of the various\nprogramming environment lie in between that of organic and Embedded. The\nprojects classified as Semi-Detached are comparatively less familiar and\ndifficult to develop compared to the organic ones and require more experience\nand better guidance and creativity. Eg: Compilers or different Embedded\nSystems can be considered of Semi-Detached type.\n\nscc --cocomo-project-type \"semi-detached,3.0,1.12,2.5,0.35\"\n\nEmbedded \u2013 A software project with requiring the highest level of complexity,\ncreativity, and experience requirement fall under this category. Such software\nrequires a larger team size than the other two models and also the developers\nneed to be sufficiently experienced and creative to develop such complex\nmodels.\n\nscc --cocomo-project-type \"embedded,3.6,1.20,2.5,0.32\"\n\n### Large File Detection\n\nYou can have scc exclude large files from the output.\n\nThe option to do so is --no-large which by default will exclude files over\n1,000,000 bytes or 40,000 lines.\n\nYou can control the size of either value using --large-byte-count or --large-\nline-count.\n\nFor example to exclude files over 1,000 lines and 50kb you could use the\nfollowing,\n\nscc --no-large --large-byte-count 50000 --large-line-count 1000\n\n### Minified/Generated File Detection\n\nYou can have scc identify and optionally remove files identified as being\nminified or generated from the output.\n\nYou can do so by enabling the -z flag like so scc -z which will identify any\nfile with an average line byte size >= 255 (by default) as being minified.\n\nMinified files appear like so in the output.\n\n    \n    \n    $ scc --no-cocomo -z ./examples/minified/jquery-3.1.1.min.js \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Language Files Lines Blanks Comments Code Complexity \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 JavaScript (min) 1 4 0 1 3 17 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Total 1 4 0 1 3 17 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Processed 86709 bytes, 0.087 megabytes (SI) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nMinified files are indicated with the text (min) after the language name.\n\nGenerated files are indicated with the text (gen) after the language name.\n\nYou can control the average line byte size using --min-gen-line-length such as\nscc -z --min-gen-line-length 1. Please note you need -z as modifying this\nvalue does not imply minified detection.\n\nYou can exclude minified files from the count totally using the flag --no-min-\ngen. Files which match the minified check will be excluded from the output.\n\n### Remapping\n\nSome files may not have an extension. They will be checked to see if they are\na #! file. If they are then the language will be remapped to the correct\nlanguage. Otherwise, it will not process.\n\nHowever, you may have the situation where you want to remap such files based\non a string inside it. To do so you can use --remap-unknown\n\n    \n    \n    scc --remap-unknown \"-*- C++ -*-\":\"C Header\"\n\nThe above will inspect any file with no extension looking for the string -*-\nC++ -*- and if found remap the file to be counted using the C Header rules.\nYou can have multiple remap rules if required,\n\n    \n    \n    scc --remap-unknown \"-*- C++ -*-\":\"C Header\",\"other\":\"Java\"\n\nThere is also the --remap-all parameter which will remap all files.\n\nNote that in all cases if the remap rule does not apply normal #! rules will\napply.\n\n### Output Formats\n\nBy default scc will output to the console. However you can produce output in\nother formats if you require.\n\nThe different options are tabular, wide, json, csv, csv-stream, cloc-yaml,\nhtml, html-table, sql, sql-insert, openmetrics.\n\nNote that you can write scc output to disk using the -o, --output option. This\nallows you to specify a file to write your output to. For example scc -f html\n-o output.html will run scc against the current directory, and output the\nresults in html to the file output.html.\n\nYou can also write to multiple output files, or multiple types to stdout if\nyou want using the --format-multi option. This is most useful when working in\nCI/CD systems where you want HTML reports as an artefact while also displaying\nthe counts in stdout.\n\n    \n    \n    scc --format-multi \"tabular:stdout,html:output.html,csv:output.csv\"\n\nThe above will run against the current directory, outputting to standard\noutput the default output, as well as writing to output.html and output.csv\nwith the appropriate formats.\n\n#### Tabular\n\nThis is the default output format when scc is run.\n\n#### Wide\n\nWide produces some additional information which is the complexity/lines\nmetric. This can be useful when trying to identify the most complex file\ninside a project based on the complexity estimate.\n\n#### JSON\n\nJSON produces JSON output. Mostly designed to allow scc to feed into other\nprograms.\n\nNote that this format will give you the byte size of every file scc reads\nallowing you to get a breakdown of the number of bytes processed.\n\n#### CSV\n\nCSV as an option is good for importing into a spreadsheet for analysis.\n\nNote that this format will give you the byte size of every file scc reads\nallowing you to get a breakdown of the number of bytes processed. Also note\nthat CSV respects --by-file and as such will return a summary by default.\n\n#### CSV-Stream\n\ncsv-stream is an option useful for processing very large repositories where\nyou are likely to run into memory issues. It's output format is 100% the same\nas CSV.\n\nNote that you should not use this with the format-multi option as it will\nalways print to standard output, and because of how it works will negate the\nmemory saving it normally gains. savings that this option provides. Note that\nthere is no sort applied with this option.\n\n#### cloc-yaml\n\nIs a drop in replacement for cloc using its yaml output option. This is quite\noften used for passing into other build systems and can help with replacing\ncloc if required.\n\n    \n    \n    $ scc -f cloc-yml processor # https://github.com/boyter/scc/ header: url: https://github.com/boyter/scc/ version: 2.11.0 elapsed_seconds: 0.008 n_files: 21 n_lines: 6562 files_per_second: 2625 lines_per_second: 820250 Go: name: Go code: 5186 comment: 273 blank: 1103 nFiles: 21 SUM: code: 5186 comment: 273 blank: 1103 nFiles: 21 $ cloc --yaml processor 21 text files. 21 unique files. 0 files ignored. --- # http://cloc.sourceforge.net header : cloc_url : http://cloc.sourceforge.net cloc_version : 1.60 elapsed_seconds : 0.196972846984863 n_files : 21 n_lines : 6562 files_per_second : 106.613679608407 lines_per_second : 33314.2364566841 Go: nFiles: 21 blank: 1137 comment: 606 code: 4819 SUM: blank: 1137 code: 4819 comment: 606 nFiles: 21\n\n#### HTML and HTML-TABLE\n\nThe HTML output options produce a minimal html report using a table that is\neither standalone html or as just a table html-table which can be injected\ninto your own HTML pages. The only difference between the two is that the html\noption includes html head and body tags with minimal styling.\n\nThe markup is designed to allow your own custom styles to be applied. An\nexample report is here to view.\n\nNote that the HTML options follow the command line options, so you can use scc\n--by-file -f html to produce a report with every file and not just the\nsummary.\n\nNote that this format if it has the --by-file option will give you the byte\nsize of every file scc reads allowing you to get a breakdown of the number of\nbytes processed.\n\n#### SQL and SQL-Insert\n\nThe SQL output format \"mostly\" compatible with cloc's SQL output format\nhttps://github.com/AlDanial/cloc#sql-\n\nWhile all queries on the cloc documentation should work as expected, you will\nnot be able to append output from scc and cloc into the same database. This is\nbecause the table format is slightly different to account for scc including\ncomplexity counts and bytes.\n\nThe difference between sql and sql-insert is that sql will include table\ncreation while the latter will only have the insert commands.\n\nUsage is 100% the same as any other scc command but sql output will always\ncontain per file details. You can compute totals yourself using SQL.\n\nThe below will run scc against the current directory, name the output as the\nproject scc and then pipe the output to sqlite to put into the database\ncode.db\n\n    \n    \n    scc --format sql --sql-project scc . | sqlite3 code.db\n\nAssuming you then wanted to append another project\n\n    \n    \n    scc --format sql-insert --sql-project redis . | sqlite3 code.db\n\nYou could then run SQL against the database,\n\n    \n    \n    sqlite3 code.db 'select project,file,max(nCode) as nL from t group by project order by nL desc;'\n\nSee the cloc documentation for more examples.\n\n#### OpenMetrics\n\nOpenMetrics is a metric reporting format specification extending the\nPrometheus exposition text format.\n\nThe produced output is natively supported by Prometheus and GitLab CI\n\nNote that OpenMetrics respects --by-file and as such will return a summary by\ndefault.\n\nThe output includes a metadata header containing definitions of the returned\nmetrics:\n\n    \n    \n    # TYPE scc_files count # HELP scc_files Number of sourcecode files. # TYPE scc_lines count # UNIT scc_lines lines # HELP scc_lines Number of lines. # TYPE scc_code count # HELP scc_code Number of lines of actual code. # TYPE scc_comments count # HELP scc_comments Number of comments. # TYPE scc_blanks count # HELP scc_blanks Number of blank lines. # TYPE scc_complexity count # HELP scc_complexity Code complexity. # TYPE scc_bytes count # UNIT scc_bytes bytes # HELP scc_bytes Size in bytes.\n\nThe header is followed by the metric data in either language summary form:\n\n    \n    \n    scc_files{language=\"Go\"} 1 scc_lines{language=\"Go\"} 1000 scc_code{language=\"Go\"} 1000 scc_comments{language=\"Go\"} 1000 scc_blanks{language=\"Go\"} 1000 scc_complexity{language=\"Go\"} 1000 scc_bytes{language=\"Go\"} 1000\n\nor, if --by-file is present, in per file form:\n\n    \n    \n    scc_lines{language=\"Go\",file=\"./bbbb.go\"} 1000 scc_code{language=\"Go\",file=\"./bbbb.go\"} 1000 scc_comments{language=\"Go\",file=\"./bbbb.go\"} 1000 scc_blanks{language=\"Go\",file=\"./bbbb.go\"} 1000 scc_complexity{language=\"Go\",file=\"./bbbb.go\"} 1000 scc_bytes{language=\"Go\",file=\"./bbbb.go\"} 1000\n\n### Performance\n\nGenerally scc will the fastest code counter compared to any I am aware of and\nhave compared against. The below comparisons are taken from the fastest\nalternative counters. See Other similar projects above to see all of the other\ncode counters compared against. It is designed to scale to as many CPU's cores\nas you can provide.\n\nHowever if you want greater performance and you have RAM to spare you can\ndisable the garbage collector like the following on linux GOGC=-1 scc . which\nshould speed things up considerably. For some repositories turning off the\ncode complexity calculation via -c can reduce runtime as well.\n\nBenchmarks are run on fresh 32 Core CPU Optimised Digital Ocean Virtual\nMachine 2022/09/20 all done using hyperfine with 3 warm-up runs and 10 timed\nruns.\n\n    \n    \n    scc v3.1.0 tokei v12.1.2 loc v0.5.0 polyglot v0.5.29\n\nSee https://github.com/boyter/scc/blob/master/benchmark.sh to see how the\nbenchmarks are run.\n\n#### Redis https://github.com/antirez/redis/\n\n    \n    \n    Benchmark 1: scc redis Time (mean \u00b1 \u03c3): 20.2 ms \u00b1 1.7 ms [User: 127.1 ms, System: 47.0 ms] Range (min ... max): 16.8 ms ... 25.8 ms 132 runs Benchmark 2: scc -c redis Time (mean \u00b1 \u03c3): 17.0 ms \u00b1 1.4 ms [User: 91.6 ms, System: 32.7 ms] Range (min ... max): 14.3 ms ... 21.6 ms 169 runs Benchmark 3: tokei redis Time (mean \u00b1 \u03c3): 33.7 ms \u00b1 5.0 ms [User: 246.4 ms, System: 55.0 ms] Range (min ... max): 24.2 ms ... 47.5 ms 76 runs Benchmark 4: loc redis Time (mean \u00b1 \u03c3): 36.9 ms \u00b1 30.6 ms [User: 756.5 ms, System: 20.7 ms] Range (min ... max): 9.9 ms ... 123.9 ms 71 runs Benchmark 5: polyglot redis Time (mean \u00b1 \u03c3): 21.8 ms \u00b1 0.9 ms [User: 32.1 ms, System: 46.3 ms] Range (min ... max): 20.0 ms ... 28.4 ms 138 runs Summary 'scc -c redis' ran 1.19 \u00b1 0.14 times faster than 'scc redis' 1.28 \u00b1 0.12 times faster than 'polyglot redis' 1.98 \u00b1 0.33 times faster than 'tokei redis' 2.17 \u00b1 1.81 times faster than 'loc redis'\n\n#### CPython https://github.com/python/cpython\n\n    \n    \n    Benchmark 1: scc cpython Time (mean \u00b1 \u03c3): 52.6 ms \u00b1 3.8 ms [User: 624.3 ms, System: 121.5 ms] Range (min ... max): 45.3 ms ... 62.3 ms 47 runs Benchmark 2: scc -c cpython Time (mean \u00b1 \u03c3): 46.0 ms \u00b1 3.8 ms [User: 468.0 ms, System: 111.2 ms] Range (min ... max): 40.0 ms ... 58.0 ms 67 runs Benchmark 3: tokei cpython Time (mean \u00b1 \u03c3): 110.4 ms \u00b1 6.6 ms [User: 1239.8 ms, System: 114.5 ms] Range (min ... max): 98.3 ms ... 123.6 ms 26 runs Benchmark 4: loc cpython Time (mean \u00b1 \u03c3): 52.9 ms \u00b1 25.2 ms [User: 1103.0 ms, System: 57.4 ms] Range (min ... max): 30.0 ms ... 118.9 ms 49 runs Benchmark 5: polyglot cpython Time (mean \u00b1 \u03c3): 82.4 ms \u00b1 3.0 ms [User: 153.3 ms, System: 168.8 ms] Range (min ... max): 74.8 ms ... 88.7 ms 36 runs Summary 'scc -c cpython' ran 1.14 \u00b1 0.13 times faster than 'scc cpython' 1.15 \u00b1 0.56 times faster than 'loc cpython' 1.79 \u00b1 0.16 times faster than 'polyglot cpython' 2.40 \u00b1 0.24 times faster than 'tokei cpython'\n\n#### Linux Kernel https://github.com/torvalds/linux\n\n    \n    \n    Benchmark 1: scc linux Time (mean \u00b1 \u03c3): 743.0 ms \u00b1 18.8 ms [User: 17133.4 ms, System: 1280.2 ms] Range (min ... max): 709.4 ms ... 778.8 ms 10 runs Benchmark 2: scc -c linux Time (mean \u00b1 \u03c3): 528.8 ms \u00b1 11.8 ms [User: 10272.0 ms, System: 1236.9 ms] Range (min ... max): 508.9 ms ... 543.1 ms 10 runs Benchmark 3: tokei linux Time (mean \u00b1 \u03c3): 736.5 ms \u00b1 18.2 ms [User: 13098.3 ms, System: 2276.0 ms] Range (min ... max): 699.3 ms ... 760.8 ms 10 runs Benchmark 4: loc linux Time (mean \u00b1 \u03c3): 567.1 ms \u00b1 113.4 ms [User: 15984.5 ms, System: 1037.0 ms] Range (min ... max): 381.8 ms ... 656.3 ms 10 runs Benchmark 5: polyglot linux Time (mean \u00b1 \u03c3): 1.241 s \u00b1 0.027 s [User: 2.973 s, System: 2.636 s] Range (min ... max): 1.196 s ... 1.299 s 10 runs Summary 'scc -c linux' ran 1.07 \u00b1 0.22 times faster than 'loc linux' 1.39 \u00b1 0.05 times faster than 'tokei linux' 1.41 \u00b1 0.05 times faster than 'scc linux' 2.35 \u00b1 0.07 times faster than 'polyglot linux'\n\nIf you enable duplicate detection expect performance to fall by about 20% in\nscc.\n\nPerformance is tracked over each release and presented below. Currently, the\nmost recent release 3.1.0 is the fastest version.\n\nhttps://jsfiddle.net/m1w7kgqv/\n\n### CI/CD Support\n\nSome CI/CD systems which will remain nameless do not work very well with the\nbox-lines used by scc. To support those systems better there is an option --ci\nwhich will change the default output to ASCII only.\n\n    \n    \n    $ scc --ci main.go ------------------------------------------------------------------------------- Language Files Lines Blanks Comments Code Complexity ------------------------------------------------------------------------------- Go 1 272 7 6 259 4 ------------------------------------------------------------------------------- Total 1 272 7 6 259 4 ------------------------------------------------------------------------------- Estimated Cost to Develop $6,539 Estimated Schedule Effort 2.268839 months Estimated People Required 0.341437 ------------------------------------------------------------------------------- Processed 5674 bytes, 0.006 megabytes (SI) -------------------------------------------------------------------------------\n\nThe --format-multi option is especially useful in CI/CD where you want to get\nmultiple output formats useful for storage or reporting.\n\n### Development\n\nIf you want to hack away feel free! PR's are accepted. Some things to keep in\nmind. If you want to change a language definition you need to update\nlanguages.json and then run go generate which will convert it into the\nprocessor/constants.go file.\n\nFor all other changes ensure you run all tests before submitting. You can do\nso using go test ./.... However for maximum coverage please run test-all.sh\nwhich will run gofmt, unit tests, race detector and then all of the\nintegration tests. All of those must pass to ensure a stable release.\n\n### API Support\n\nThe core part of scc which is the counting engine is exposed publicly to be\nintegrated into other Go applications. See https://github.com/pinpt/ripsrc for\nan example of how to do this.\n\nIt also powers all of the code calculations displayed in\nhttps://searchcode.com/ such as https://searchcode.com/file/169350674/main.go/\nmaking it one of the more used code counters in the world.\n\nHowever as a quick start consider the following,\n\nNote that you must pass in the number of bytes in the content in order to\nensure it is counted!\n\n    \n    \n    package main import ( \"fmt\" \"io/ioutil\" \"github.com/boyter/scc/v3/processor\" ) type statsProcessor struct{} func (p *statsProcessor) ProcessLine(job *processor.FileJob, currentLine int64, lineType processor.LineType) bool { switch lineType { case processor.LINE_BLANK: fmt.Println(currentLine, \"lineType\", \"BLANK\") case processor.LINE_CODE: fmt.Println(currentLine, \"lineType\", \"CODE\") case processor.LINE_COMMENT: fmt.Println(currentLine, \"lineType\", \"COMMENT\") } return true } func main() { bts, _ := ioutil.ReadFile(\"somefile.go\") t := &statsProcessor{} filejob := &processor.FileJob{ Filename: \"test.go\", Language: \"Go\", Content: bts, Callback: t, Bytes: int64(len(bts)), } processor.ProcessConstants() // Required to load the language information and need only be done once processor.CountStats(filejob) }\n\n### Adding/Modifying Languages\n\nTo add or modify a language you will need to edit the languages.json file in\nthe root of the project, and then run go generate to build it into the\napplication. You can then go install or go build as normal to produce the\nbinary with your modifications.\n\n### Issues\n\nIts possible that you may see the counts vary between runs. This usually means\none of two things. Either something is changing or locking the files under\nscc, or that you are hitting ulimit restrictions. To change the ulimit see the\nfollowing links.\n\n  * https://superuser.com/questions/261023/how-to-change-default-ulimit-values-in-mac-os-x-10-6#306555\n  * https://unix.stackexchange.com/questions/108174/how-to-persistently-control-maximum-system-resource-consumption-on-mac/221988#221988\n  * https://access.redhat.com/solutions/61334\n  * https://serverfault.com/questions/356962/where-are-the-default-ulimit-values-set-linux-centos\n  * https://www.tecmint.com/increase-set-open-file-limits-in-linux/\n\nTo help identify this issue run scc like so scc -v . and look for the message\ntoo many open files in the output. If it is there you can rectify it by\nsetting your ulimit to a higher value.\n\n### Low Memory\n\nIf you are running scc in a low memory environment < 512 MB of RAM you may\nneed to set --file-gc-count to a lower value such as 0 to force the garbage\ncollector to be on at all times.\n\nA sign that this is required will be scc crashing with panic errors.\n\n### Tests\n\nscc is pretty well tested with many unit, integration and benchmarks to ensure\nthat it is fast and complete.\n\n### Package\n\nPackaging as of version v3.1.0 is done through https://goreleaser.com/\n\n### Containers\n\nNote if you plan to run scc in Alpine containers you will need to build with\nCGO_ENABLED=0.\n\nSee the below dockerfile as an example on how to achieve this based on this\nissue #208\n\n    \n    \n    FROM golang as scc-get ENV GOOS=linux \\ GOARCH=amd64 \\ CGO_ENABLED=0 ARG VERSION RUN git clone --branch $VERSION --depth 1 https://github.com/boyter/scc WORKDIR /go/scc RUN go build -ldflags=\"-s -w\" FROM alpine COPY --from=scc-get /go/scc/scc /bin/ ENTRYPOINT [\"scc\"]\n\n### Badges (beta)\n\nYou can use scc to provide badges on your github/bitbucket/gitlab/sr.ht open\nrepositories. For example, The format to do so is,\n\nhttps://sloc.xyz/PROVIDER/USER/REPO\n\nAn example of the badge for scc is included below, and is used on this page.\n\n    \n    \n    [![Scc Count Badge](https://sloc.xyz/github/boyter/scc/)](https://github.com/boyter/scc/)\n\nBy default the badge will show the repo's lines count. You can also specify\nfor it to show a different category, by using the ?category= query string.\n\nValid values include code, blanks, lines, comments, cocomo and examples of the\nappearance are included below.\n\nFor cocomo you can also set the avg-wage value similar to scc itself. For\nexample,\n\nhttps://sloc.xyz/github/boyter/scc/?category=cocomo&avg-wage=1\nhttps://sloc.xyz/github/boyter/scc/?category=cocomo&avg-wage=100000\n\nNote that the avg-wage value must be a positive integer otherwise it will\nrevert back to the default value of 56286.\n\nNB it may not work for VERY large repositories (has been tested on Apache\nhadoop/spark without issue).\n\nYou can find the source code for badges in the repository at\nhttps://github.com/boyter/scc/blob/master/cmd/badges/main.go\n\n#### A example for each supported provider\n\n  * github - https://sloc.xyz/github/boyter/scc/\n  * sr.ht - https://sloc.xyz/sr.ht/~nektro/magnolia-desktop/\n  * bitbucket - https://sloc.xyz/bitbucket/boyter/decodingcaptchas\n  * gitlab - https://sloc.xyz/gitlab/esr/loccount\n\n### Languages\n\nList of supported languages. The master version of scc supports 239 languages\nat last count. Note that this is always assumed that you built from master,\nand it might trail behind what is actually supported. To see what your version\nof scc supports run scc --languages\n\nClick here to view all languages supported by master\n\n## About\n\nSloc, Cloc and Code: scc is a very fast accurate code counter with complexity\ncalculations and COCOMO estimates written in pure Go\n\n### Topics\n\nwindows macos linux cli golang statistics code complexity tokei cloc sloc\nsloccount\n\n### Resources\n\nReadme\n\n### License\n\n### Code of conduct\n\nCode of conduct\n\nActivity\n\n### Stars\n\n6k stars\n\n### Watchers\n\n35 watching\n\n### Forks\n\n236 forks\n\nReport repository\n\n## Releases 34\n\nv3.2.0 Latest\n\nNov 27, 2023\n\n\\+ 33 releases\n\n## Sponsor this project\n\nboyter Ben Boyter\n\nSponsor\n\nLearn more about GitHub Sponsors\n\n## Packages 1\n\n  * scc\n\n## Contributors 90\n\n\\+ 76 contributors\n\n## Languages\n\n  * Go 84.1%\n  * Shell 8.8%\n  * PowerShell 2.9%\n  * HTML 2.4%\n  * Python 1.7%\n  * Dockerfile 0.1%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
