{"aid": "40049330", "title": "Containerize Node.js applications at the edge on RHEL and Fedora", "url": "https://developers.redhat.com/articles/2024/04/16/containerize-nodejs-applications-edge-rhel-and-fedora", "domain": "redhat.com", "votes": 1, "user": "unripe_syntax", "posted_at": "2024-04-16 07:39:06", "comments": 0, "source_title": "Containerize Node.js applications at the edge on RHEL and Fedora | Red Hat Developer", "source_text": "Containerize Node.js applications at the edge on RHEL and Fedora | Red Hat Developer\n\nSkip to main content\n\n## Quick links: redhat.com, Customer Portal, Red Hat's developer site, Red\nHat's partner site.\n\n  * You are here\n\n### Red Hat\n\nLearn about our open source products, services, and company.\n\n  * You are here\n\n### Red Hat Customer Portal\n\nGet product support and knowledge from the open source experts.\n\n  * You are here\n\n### Red Hat Developer\n\nRead developer tutorials and download Red Hat software for cloud application\ndevelopment.\n\n  * You are here\n\n### Red Hat Partner Connect\n\nGet training, subscriptions, certifications, and more for partners to build,\nsell, and support customer solutions.\n\n## Products & tools\n\n  * ### Ansible.com\n\nLearn about and try our IT automation product.\n\n  * ### Red Hat Ecosystem Catalog\n\nFind hardware, software, and cloud providers\u2015and download container\nimages\u2015certified to perform with Red Hat technologies.\n\n## Try, buy, & sell\n\n  * ### Red Hat Hybrid Cloud Console\n\nAccess technical how-tos, tutorials, and learning paths focused on Red Hat\u2019s\nhybrid cloud managed services.\n\n  * ### Red Hat Store\n\nBuy select Red Hat products and services online.\n\n  * ### Red Hat Marketplace\n\nTry, buy, sell, and manage certified enterprise software for container-based\nenvironments.\n\n## Events\n\n  * ### Red Hat Summit and AnsibleFest\n\nRegister for and learn about our annual open source IT industry event.\n\nArticle\n\n# Containerize Node.js applications at the edge on RHEL and Fedora\n\nApril 16, 2024\n\nEdgeInternet of ThingsLinuxNode.js\n\nMichael Dawson\n\nNode.js lead for Red Hat and IBM\n\n  * A quick reminder of the example from part 1\n  * The application\n  * Containerizing the application\n  * Getting the container onto the Raspberry Pi\n  * Passing devices to the container\n  * A fully configured edge device\n  * Updating the application\n  * Wrapping up\n\nThis is part 2 in our series on running Node.js applications on the edge with\nRed Hat Enterprise Linux (RHEL) and Fedora. In the first part, we introduced\nyou to the hardware and software for our Node.js based edge example as well as\nsome of the details on laying the foundation for deploying the application by\nbuilding and installing the operating system using Fedora IoT.\n\nIn this part we\u2019ll dive a bit deeper into the application itself and how to\nbuild, bundle, deploy, and update it using Podman and containers. Along the\nway, we\u2019ll explain why we recommend this approach versus using rpm-ostree to\nmanage the deployment of your applications.\n\nA quick reminder of the example from part 1\n\n## A quick reminder of the example from part 1\n\nThe hardware/software outlined in the example in part 1 monitors the\nunderground gas tank at a gas station showing the current temperature and the\nstatus of the tank lids. The hardware is based on a Raspberry Pi 4 with a\ntemperature sensor and lid switches. The software is a Next.js based\napplication that displays the status of those sensors. Figure 1 shows the\nhardware while Figure 2 shows the UI.\n\nFigure 1: Hardware for the example.Figure 2 - UI for the exampleFigure 2 - UI\nfor the example\n\nThe application\n\n## The application\n\nPart 1 gave a good introduction to the hardware, but we left a more detailed\nlook at the application to this part of the series.\n\nThe application is a simple Next.js based application that we initially\ngenerated following the basic Create a Next.js app documentation.\n\nThe full source code is available in https://github.com/mhdawson/gas-station.\nFigure 3 shows an overview.\n\nFigure 3 - GitHub project for exampleFigure 3 - GitHub project for example\n\nIt\u2019s a pretty standard React/Next.js application with two components:\n\n  * Thermometer, derived from https://github.com/DavidBanksNZ/d3-thermometer\n  * GasTank\n\nWhich are displayed in a simple layout:\n\n    \n    \n    return ( <div > <div style={{ paddingLeft: '10px', paddingTop: '10px', height:'250px', width:'100%'}}> <table style={{ border: '3px solid black' }}> <tbody> <tr><td colSpan='2' style={{textAlign: 'center'}}>Gas Station Dashboard</td></tr> <tr><td><Thermometer data={currentTemp}/></td> <td><GasTank data={{Left: topLeft, Right: topRight}}/></td></tr> </tbody> </table> </div> </div> )\n\nCopy snippet\n\nThe components use D3 to draw an SVG picture for the thermometer and gas tank.\n\nWebsockets through socket.io are used to communicate with a back end\nmicroservice to get the current sensor data and update the UI.\n\n    \n    \n    const [currentTemp, setTemp] = useState(10); const [topLeft, setLeft] = useState(false); const [topRight, setRight] = useState(false); React.useEffect(() => { // Create a socket connection const socket = io({ path: '/api/socket.io'}); // Listen for incoming messages socket.on('message', (message) => { if (message.temp) setTemp(message.temp); if (message.topLeft !== undefined) setLeft(message.topLeft); if (message.topRight !== undefined) setRight(message.topRight); }); // Clean up the socket connection on unmount return () => { socket.disconnect(); }; }, []);\n\nCopy snippet\n\nThe core of the back end microservice simply reads the sensors every\nPOLL_INTERVAL milliseconds and publishes the data to both the front end and a\nMQTT server.\n\n    \n    \n    setInterval(() => { const temp = readTemp(tempSensorFile); readGpio(TOP_LEFT_PIN, (left) => { readGpio(TOP_RIGHT_PIN, (right) => { io.emit('message', {temp: temp, topLeft: left, topRight: right}); mqttClient.publish(TEMP_TOPIC, temp.toString()); mqttClient.publish(TOP_LEFT_TOPIC, left.toString()); mqttClient.publish(TOP_RIGHT_TOPIC, right.toString()); }); }); } , POLL_INTERVAL);\n\nCopy snippet\n\nThe sensor data is read through a kernel module for the temperature sensor and\nwith the gpioget utility for the gpio pins connected to the lid switches. You\ncan take a look at the code to see exactly how the hardware is set up and how\nthe values for the temperature and switches are read.\n\nContainerizing the application\n\n## Containerizing the application\n\nIn part 1 we built the application by hand, transferred over the files to the\ndevice, and started the application manually. Of course that\u2019s not what we\nwant to do for a real product. We need to automate the process of building the\napplication and bundling it with the operating system so that once the SD card\nis installed we can boot the Raspberry Pi 4 and the application starts\nautomatically.\n\nAs discussed in part 1, we could build the application, package it into an rpm\nand then bundle it with the operating system using RHEL image builder and rpm-\nostree. If you are a typical Node.js developer, I bet you\u2019ve never done that\nbefore, and it sounds complicated.\n\nUnless your application only needs to be updated in sync with the operating\nsystem, there a number of reasons we don\u2019t want to package the application\nwith rpm and rpm-ostree beyond it not being something we are familiar with:\n\n  * It requires a different development workflow from how typical hybrid cloud applications are delivered.\n  * It results in a tight binding to operating system components, versions and dependencies, beyond those needed by the code integrating the devices.\n  * It introduces potential conflicts between different pieces of an application in terms of operating system component versions.\n  * A reboot would be required each time the application was updated.\n\nInstead we want to use existing hybrid cloud development workflows which\nalready have tools and approaches for building applications, selecting only\nthe required assets needed for deployment and bundling those into a nice self\ncontained package: a container.\n\n### Containerfile\n\nIn order to build a container, the first step is to create a Containerfile. We\nadapted the standard Vercel example for dockerizing Next.js applications.\nBuilding on that, we applied some small changes needed for our application.\nThe end result looks like this:\n\n    \n    \n    # Install dependencies only when needed FROM registry.access.redhat.com/ubi8/nodejs-20 AS deps USER 0 WORKDIR /app # Install dependencies based on the preferred package manager COPY package.json yarn.lock* package-lock.json* pnpm-lock.yaml* ./ RUN \\ if [ -f yarn.lock ]; then yarn --frozen-lockfile; \\ elif [ -f package-lock.json ]; then npm ci; \\ elif [ -f pnpm-lock.yaml ]; then yarn global add pnpm && pnpm i; \\ else echo \"Lockfile not found.\" && exit 1; \\ fi # Rebuild the source code only when needed FROM registry.access.redhat.com/ubi8/nodejs-20 AS builder USER 0 WORKDIR /app COPY --from=deps /app/node_modules ./node_modules COPY . . # Next.js collects completely anonymous telemetry data about general usage. # Learn more here: https://nextjs.org/telemetry # Uncomment the following line in case you want to disable telemetry during the build. ENV NEXT_TELEMETRY_DISABLED 1 # If using yarn uncomment out and comment out npm below # RUN yarn build # If using npm comment out above and use below instead RUN npm run build # Production image, copy all the files and run next FROM registry.access.redhat.com/ubi8/nodejs-20-minimal AS runner USER 0 WORKDIR /app ENV NODE_ENV production # Uncomment the following line in case you want to enable telemetry during runtime. ENV NEXT_TELEMETRY_DISABLED 1 COPY --from=builder /app/public ./public # Set the correct permission for prerender cache RUN mkdir .next RUN chown 1001:1001 .next # Automatically leverage output traces to reduce image size # https://nextjs.org/docs/advanced-features/output-file-tracing COPY --from=builder --chown=1001:1001 /app/.next/standalone ./ COPY --from=builder --chown=1001:1001 /app/.next/static ./.next/static # add in libpiod for access to Raspberry PI IO pins RUN rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm RUN microdnf install libgpiod-utils USER 1001 EXPOSE 3000 ENV PORT 3000 CMD [\"node\", \"server\"]\n\nCopy snippet\n\nThe first change is that we use ubi8/nodejs-20 as the base image to build the\napplication and the ubi8/nodejs-20-minimal as the base image to package the\napplication. This is because we want to use the supported Red Hat Node.js\nimages.\n\n    \n    \n    # Install dependencies only when needed FROM registry.access.redhat.com/ubi8/nodejs-20 AS deps . . . # Production image, copy all the files and run next FROM registry.access.redhat.com/ubi8/nodejs-20-minimal AS runner . . .\n\nCopy snippet\n\nThe second change is that we add the commands needed to install the gpio\nutilities the application uses to read the switches (gpioget as mentioned\nearlier):\n\n    \n    \n    # add in libpiod for access to Raspberry PI IO pins RUN rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm RUN microdnf install libgpiod-utils\n\nCopy snippet\n\nOther than that, it is pretty much a standard Next.js container build. If you\nwant to dive deeper into what each section of the Containerfile is doing,\ncheck out How to deploy Next.js applications to Red Hat OpenShift, which\nexplains each section.\n\n### Building the container\n\nNow that we have the Containerfile, the next step is to build the container.\nWe did that by running:\n\n    \n    \n    podman build . -t gas-station:latest\n\nCopy snippet\n\nNote: we have used the tag latest here, but that is not something you would\nwant to do in a real deployment. You will want to consider your tagging\nstrategy carefully to ensure that what's running in the device updates/does\nnot update as planned. Docker Tagging: Best practices for tagging and\nversioning docker images provides some insight into the pluses and minuses of\nsome of the alternatives ways to managed tags.\n\nIf you want to try building the container yourself, make sure you have Podman\n(a free and open source alternative to Docker) installed, clone the gas-\nstation repository, and run the same command. Some Linux distributions come\nwith Podman installed. If you are on a platform where it is not already\navailable, Podman Desktop lets you run Podman on Windows, macOS, or Linux.\nIt\u2019s free and a great way to build, run and manage your containers.\n\nWhile you can build the container on any type of host, building one that will\nrun on the Raspberry Pi takes a bit more care. The fastest way to do it is to\nrun the podman build command on a Raspberry Pi. That is what we did initially\nto test out the container.\n\nThe great news, though, is that you can use Podman to build a container that\nwill run on the Raspberry Pi on your local desktop or existing infrastructure,\nyou just need to tell Podman what the target architecture is:\n\n    \n    \n    podman build . --arch=arm64 -t gas-station:latest\n\nCopy snippet\n\nIt may be a bit slower to build because building for an architecture that does\nnot match the host machine uses emulation, but it\u2019s a great option to have,\nparticularly for CI where the build time might not matter as much as being\nable to reuse existing infrastructure.\n\nOnce the build is complete we should have a container in the local registry:\n\n    \n    \n    [user1@localhost gas-station]$ podman images |grep gas-station localhost/gas-station latest 30ded1b2fcb5 2 hours ago 295 MB\n\nCopy snippet\n\nTypically you might iterate for development by building on the Raspberry Pi,\nbut once updates are pushed to version control (e.g., GitHub), the production\nbuild could use existing CI infrastructure leveraging existing technologies\nlike Tekton pipelines or OpenShift BuildConfigs.\n\nGetting the container onto the Raspberry Pi\n\n## Getting the container onto the Raspberry Pi\n\nOk, now we have a container. How do we get it to the Raspberry Pi? The easiest\nway is to push it to a registry like quay.io. We did that as follows:\n\n    \n    \n    podman tag 30ded1b2fcb5 quay.io/midawson/gas-station:latest podman push quay.io/midawson/gas-station:latest\n\nCopy snippet\n\nWhere 30ded1b2fcb5 is the hash for the container we built earlier.\n\nOn the Raspberry Pi we can now run:\n\n    \n    \n    podman pull quay.io/midawson/gas-station:latest podman run -d -p 3000:3000 quay.io/midawson/gas-station:latest\n\nCopy snippet\n\nAnd our application will be up and running on the Raspberry Pi. Yay!\n\nFor our example we used a public repository, but for edge devices within a\nbusiness, it\u2019s more likely you\u2019ll use an internal repository or repositories\nwhich are private to your organization. Either way, updates to the application\nare now as easy as pushing a new version of the container, pulling that\ncontainer on the edge device and then starting the container.\n\nThat flow is a lot easier and faster than building an rpm and deploying with\nrpm-ostree. We also have used tools and processes that are a common part of\nthe development of existing hybrid cloud applications.\n\nOf course we don\u2019t want to have to log onto the device to manually pull and\nstart containers for a real deployment. We\u2019ll show how to automate that in a\nlater section.\n\nUnfortunately if we experiment a bit we\u2019ll find that the application is not\nresponding to the tank switches. With the right tank top removed, the tank\nshould be red! Figure 4 shows the tank with one cap removed, but the UI is\ngreen, as shown in Figure 5.\n\nFigure 4: Tank simulator with one tank cap removed.Figure 4- UI showing both\ntank caps closed.Figure 5: UI showing both tank caps closed.\n\nThat\u2019s because the application is now running in a container. This means that\nit does not necessarily have access to the devices on the host. We\u2019ll cover\nhow to fix that in the next section.\n\nPassing devices to the container\n\n## Passing devices to the container\n\nA container provides an isolated environment that the application runs in.\nThat means that devices on the host are not necessarily available in the\ncontainer. When we first ran the application we discovered that the device for\nthe temperature sensor was available, while the device for the switches was\nnot.\n\nThe good news is that Podman allows devices to be passed through to a\ncontainer using the --device option. We added the following to our command to\nstart the container:\n\n    \n    \n    podman run --device=/dev/gpiochip0 -d -p 3000:3000 quay.io/midawson/gas-station:latest\n\nCopy snippet\n\nFrom the application code you can see that the device used to read the\nswitches is /dev/gipochip0. In Linux, devices are most often exposed as a file\nunder /dev and you can use the --device or --volume to map the device into the\ncontainer.\n\nUnfortunately even after this change the switches could still not be read\nproperly. This is because Podman runs the container rootless and simply\nmapping it in does not result in the correct rw attributes for it to be\naccessed. There are different ways to address this but we chose to add the\noption --group-add keep-groups which ensured groups were mapped in a way that\nallowed the device to be accessed (provided we had set the privileges to rw on\n/dev/gpiochip0 as outlined in part 1). You can read more about the issue in\n\u201cUsing files and devices in Podman rootless containers\u201d. The resulting command\nwas:\n\n    \n    \n    podman run --group-add keep-groups --device=/dev/gpiochip0 -d -p 3000:3000 quay.io/midawson/gas-station:latest.\n\nCopy snippet\n\nWith that we confirmed that the device could read and access the devices. Now\nFigure 6 shows the tank with one cap removed, and the UI is red as expected\n(Figure 7.)\n\nFigure 6 - Tank simulator with one tank cap removed.Figure 6: Tank simulator\nwith one tank cap removed.Figure 7: Example UI showing one tank cap open and\ntank is red.\n\nYou may be wondering why the temperature sensor was available without any\nadditional configuration. This is because containers share the kernel and any\nloaded kernel modules with the host. Since the temperature sensor was\nsupported through a kernel module as outlined in part 1 it was automatically\navailable in the container.\n\nA fully configured edge device\n\n## A fully configured edge device\n\nNow we know how we can easily build the container, get it to the device and\nstart the container. Doing that manually for development and testing is okay,\nbut for deployment it is not feasible in most cases. This is where image\nbuilder can help us define and automate a flow that will generate an SD card\nwhich can be installed into a new device and when the device boots it will\nstart the current version of the application.\n\n### Starting at boot\n\nThe first piece of the puzzle is the support in Podman called Podman Quadlet.\nIt lets us add a file that will result in Podman running (and downloading if\nnecessary) a container as part of the systemd startup of Fedora. In our case\nwe added a file called:\n\n    \n    \n    /etc/containers/systemd/gas-station.container\n\nCopy snippet\n\nWith the following contents:\n\n    \n    \n    [Service] Restart=always ExecStartPre=chmod 666 /dev/gpiochip0 ExecStartPre=modprobe w1-therm ExecStartPre=/bin/sleep 30 [Container] ContainerName=gas-station Environment=STATION_TOPIC_PATH=gas_station/ottawa/bank-street Image=quay.io/midawson/gas-station:latest Label=\"io.containers.autoupdate=image\" PublishPort=3000:3000 AddDevice=/dev/gpiochip0 PodmanArgs=--group-add keep-groups [Install] WantedBy=multi-user.target\n\nCopy snippet\n\nIn the [Service] section we indicated that we want the container to restart if\nit stops running for some reason, and have a few ExecStartPre commands which\nare run before the container is started. These commands set the required rw\naccess on the device we access the switches through and load the w1-therm\nkernel module that lets us access the temperature sensor. They also wait for\n30 seconds after boot to start the container so that any other required system\nsetup is complete.\n\nIn the [Container] section, we provide the arguments needed to replicate the\nPodman command we used earlier to start the application container. If you look\nclosely, you\u2019ll notice that there are two additional arguments. The\nEnvironment command is used to set the MQTT topic on which the application\nposts messages. We externalized this so that we can set it differently for\neach station and have multiple gas stations publishing back to the shared MQTT\nserver. Figure 8 shows the application publishing to the configured topic.\n\nFigure 8 - MQTT client showing messages published to topic configured for the\nedge deviceFigure 8: MQTT client showing messages published to topic\nconfigured for the edge device.\n\nThe other new option in the [Container] section,\nLabel=\"io.containers.autoupdate=image\", we\u2019ll talk about in the section on\nupdating the application.\n\nThe [Install] section indicates that we want to start the container once the\nsystem is ready to run applications after boot.\n\nAfter adding the gas-station.container file, the container will now be\ndownloaded from the registry if necessary and started when the system boots.\nThe container will also be restarted if it ever stops so we know it will\nalways be running, which is what we want for our edge device. If you log into\nthe Raspberry PI you can also start/stop/restart the container with the\nfollowing commands:\n\n    \n    \n    systemctl stop gas-station systemctl start gas-station systemctl restart gas-station\n\nCopy snippet\n\nWe can also get the current status with:\n\n    \n    \n    bash-5.2# systemctl status gas-station \u25cf gas-station.service Loaded: loaded (/etc/containers/systemd/gas-station.container; generated) Drop-In: /usr/lib/systemd/system/service.d \u2514\u250010-timeout-abort.conf Active: active (running) since Fri 2024-03-22 19:47:21 UTC; 15min ago Process: 29720 ExecStartPre=chmod 666 /dev/gpiochip0 (code=exited, status=0/SUCCESS) Process: 29722 ExecStartPre=modprobe w1-therm (code=exited, status=0/SUCCESS) Process: 29723 ExecStartPre=/bin/sleep 30 (code=exited, status=0/SUCCESS) Main PID: 29857 (conmon) Tasks: 12 (limit: 8976) Memory: 55.2M CPU: 22.441s CGroup: /system.slice/gas-station.service \u251c\u2500libpod-payload-484377384e684b45377a90e3f5d220684145d81f1c8bfafb66efabd4d340f108 \u2502 \u2514\u250029859 next-server \u2514\u2500runtime \u2514\u250029857 /usr/bin/conmon --api-version 1 -c 484377384e684b45377a90e3f5d220684145d81f1c8bfafb66efabd4d340f108 -u 484377384e684b45377a90e3f5d220684145d81f1c8bfafb66efabd4d340f108 -r /usr/bin/> Mar 22 19:47:21 localhost.localdomain podman[29774]: 2024-03-22 19:47:21.289284965 +0000 UTC m=+0.844523639 container init 484377384e684b45377a90e3f5d220684145d81f1c8bfafb66efabd4d340f108 (image=quay.io/> Mar 22 19:47:21 localhost.localdomain podman[29774]: 2024-03-22 19:47:21.298479267 +0000 UTC m=+0.853717866 container start 484377384e684b45377a90e3f5d220684145d81f1c8bfafb66efabd4d340f108 (image=quay.io> Mar 22 19:47:21 localhost.localdomain systemd[1]: Started gas-station.service. Mar 22 19:47:21 localhost.localdomain gas-station[29774]: 484377384e684b45377a90e3f5d220684145d81f1c8bfafb66efabd4d340f108 Mar 22 19:47:22 localhost.localdomain gas-station[29857]: \u25b2 Next.js 14.0.3 Mar 22 19:47:22 localhost.localdomain gas-station[29857]: - Local: http://484377384e68:3000 Mar 22 19:47:22 localhost.localdomain gas-station[29857]: - Network: http://10.88.0.7:3000 Mar 22 19:47:22 localhost.localdomain gas-station[29857]: Mar 22 19:47:22 localhost.localdomain gas-station[29857]: \u2713 Ready in 231ms Mar 22 19:47:23 localhost.localdomain gas-station[29857]: Socket is initializing\n\nCopy snippet\n\nWhich lets us confirm that Podman ran successfully to start the application\ncontainer.\n\n### Building a fully configured SD Card\n\nIt\u2019s great to be able to configure the Raspberry PI to start the container on\nboot but we don\u2019t want to have to do that manually for each device and we\ndon\u2019t want to have to do that if we need to send an updated SD Card to a gas\nstation in the field.\n\nThis is where image builder comes in. By extending the blueprints we\nintroduced in part 1 we can build an SD card which includes all of the\nconfiguration required so that we can just plug in a new SD card and the\nRaspberry PI will boot up, pull the latest version of the application\ncontainer and start it running.\n\nNote that this does mean that connectivity to the image registry will be\nrequired when the device starts the first time, otherwise it will not have any\nversion of the application to run. If need to handle the case where there may\nnot be connectivity on first installation, you might consider extending the\nblueprint to build in a container that has an initial version of the\napplication.\n\nIf you replace the fedora-base blueprint outlined in part one with the\nfollowing blueprint (fedora-base-container) and follow the instructions from\npart 1 it will build an SD card with the required configuration:\n\n    \n    \n    name = \"fedora-base-container\" description = \"base container launch template for Node.js edge example\" version = \"0.0.1\" modules = [] groups = [] distro = \"\" [[packages]] name = \"podman\" [[packages]] name = \"kernel-modules-extra\" [customizations] [customizations.timezone] [customizations.locale] [customizations.firewall] ports = [\"3000:tcp\"] [customizations.firewall.services] enabled = [\"http\", \"https\", \"ntp\", \"dhcp\", \"ssh\"] disabled = [\"telnet\"] [customizations.services] enabled = [\"sshd\"] [[customizations.files]] path = \"/etc/containers/systemd/gas-station.container\" user = \"root\" group = \"root\" mode = \"644\" data = \"[Service]\\nRestart=always\\nExecStartPre=chmod 666 /dev/gpiochip0\\nExecStartPre=modprobe w1-therm\\nExecStartPre=/bin/sleep 30\\n\\n[Container]\\nContainerName=gas-station\\nEnvironment=STATION_TOPIC_PATH=gas_station/ottawa/bank-street\\nImage=quay.io/midawson/gas-station:latest\\nLabel=\\\"io.containers.autoupdate=image\\\"\\nPublishPort=3000:3000\\nAddDevice=/dev/gpiochip0\\nPodmanArgs=--group-add keep-groups\\n\\n[Install]\\nWantedBy=multi-user.target\\n\"\n\nCopy snippet\n\nThe two main additions are the kernel-modules-extra which installs the kernel\nmodule for the temperature sensor, and the [[customizations.files]] second\nwhich adds the gas-station.container file described in the previous section\n(the format is a bit hard to read because newlines are not allowed in the data\nvariable).\n\nI should have said that using this new template \u201calmost\u201d let us build an SD\ncard that could be inserted and would boot and run the container. We did have\nto add one more step. After the SD card is created using the arm-image-\ninstaller, we need to mount the first partition with:\n\n    \n    \n    mkdir /mnt/rpi1 mount /dev/sdb1 /mnt/rpi1 (first partition in my case)\n\nCopy snippet\n\nAnd then edit /mnt/rpi1/config.txt to add:\n\n    \n    \n    dtoverlay=w1-gpio\n\nCopy snippet\n\n...at the end. This results in dtoverlay=w1-gpio being in /boot/efi/config.txt\nwhen the Raspberry PI boots which was needed to access the gpio as discussed\nin part 1.\n\nWith this approach we can manage configuration of individual devices through\nthe template configured when building the image by adding options to the\nenvironment like STATION_TOPIC_PATH, or even better we might have the device\nquery for its configuration on boot so that a single image can be shared\nacross all devices. What\u2019s important is that we\u2019ve shown how to use image\nbuilder to create images in a way that can be automated using the image\nbuilder command line interface, and with all of the configuration files\nmanaged through version control.\n\nAt the same time the management of the version of the application itself is\nhandled separately through containers in the registry allowing the application\nto be more easily updated. In the next section we\u2019ll talk about updating the\napplication.\n\nUpdating the application\n\n## Updating the application\n\nWith the approach outlined so far, we can update the application by:\n\n  1. Building a new version of the application and pushing it to the registry with:\n\n    \n    \n    podman push quay.io/midawson/gas-station:latest\n\nCopy snippet\n\n  2. Logging into the device and running:\n\n    \n    \n    podman pull quay.io/midawson/gas-station:latest systemctl restart gas-station\n\nCopy snippet\n\nFigure 9 shows the UI before having pushed an updated version of the\napplication and Figure 10 shows the UI for application after the push.\n\nFigure 9 - UI before pushing updateFigure 9: UI before pushing update.Figure\n10 - UI after update pushedFigure 10: UI after update pushed.\n\nWe can just as easily revert to the old version of the application by tagging\nthe older container with the latest again and then pushing and restarting on\nthe Raspberry PI.\n\nThis is still a bit manual though, having to log into the device to pull the\nupdated container and restart the service with systemctl. Earlier, we\u2019d\nmentioned the additional Podman option that we added in gas-station.container\n- Label=\"io.containers.autoupdate=image\". By default that makes Podman check\nat midnight for an updated image in the registry, pull down the update if\nnecessary and restart the container. This means we already have an auto-\nupdating application. If we push a new version of the application container\nall of the devices will start using that version of the application the next\nday.\n\nWhile the auto update illustrates a simple way to update the application\nautomatically at a certain interval (which can be configured), many\norganizations will want more control over how and when the application is\nupdated. You can likely already think of a few ways you can build scripts to\nprovide more flexibility; we\u2019ll dive into that in the third part in the\nseries, which will cover advanced container management at the edge for Node.js\napplications.\n\nWrapping up\n\n## Wrapping up\n\nIn this installment of the 3-part series, we have:\n\n  * Provided a bit more detail on our example Node.js based application.\n  * Showed you how to use containers to build and deploy your Node.js/Next.js application to an edge device.\n  * Demonstrated how you can use RHEL image builder to create a fully configured image that once installed in a Raspberry Pi will boot, pull your application container image and start running your application.\n\nNow that we know more about the application and how to build it into a\ncontainer, in the next installment we will dive deeper in how you can better\nmanage the Node.js application containers deployed to the edge.\n\nIf you would like to learn more about what the Red Hat Node.js team is up to\nwhile you wait for the next installment, you can check out the Node.js topic\npage, and the Node.js Reference Architecture.\n\n## Recent Articles\n\n  * ### Containerize Node.js applications at the edge on RHEL and Fedora\n\n  * ### How to monitor OpenShift using the Datadog Operator\n\n  * ### Red Hat build of Keycloak high availability: A simplified approach\n\n  * ### Patch updates on RHEL servers with Ansible Automation Platform 2.4\n\n  * ### Modernization - A reference appraoch, where to begin and how\n\n## Related Content\n\n### Run Node.js applications on the edge with RHEL and Fedora\n\n### Get started with Node.js 14 on Red Hat OpenShift\n\n### Deploying serverless Node.js applications on Red Hat OpenShift, Part 1\n\n### Edge computing: From 30 tons to 30 grams\n\n### Bring your Kubernetes workloads to the edge\n\n### Deliver your applications to edge and IoT devices in rootless containers\n\n## What\u2019s up next?\n\nRun secure and efficient Node.js applications on OpenShift and other container\nenvironments. This cheat sheet rounds up 10 tips to help you learn best\npractices and get up to speed quickly.\n\nGet the cheat sheet\n\nLinkedIn YouTube Twitter Facebook\n\n### Products\n\n  * Red Hat Enterprise Linux\n  * Red Hat OpenShift\n  * Red Hat Ansible Automation Platform\n  * See all products\n  * See all technologies\n\n### Build\n\n  * Developer Sandbox\n  * Developer Tools\n  * Interactive Tutorials\n  * API Catalog\n  * Operators Marketplace\n\n### Quicklinks\n\n  * Learning Resources\n  * E-books\n  * Cheat Sheets\n  * Blog\n  * Events\n\n### Communicate\n\n  * About us\n  * Contact sales\n  * Find a partner\n  * Report a website issue\n  * Site Status Dashboard\n  * Report a security problem\n\n### RED HAT DEVELOPER\n\nBuild here. Go anywhere.\n\nWe serve the builders. The problem solvers who create careers with code.\n\nJoin us if you\u2019re a developer, software engineer, web designer, front-end\ndesigner, UX designer, computer scientist, architect, tester, product manager,\nproject manager or team lead.\n\nSign me up\n\n### Red Hat legal and privacy links\n\n  * About Red Hat\n  * Jobs\n  * Events\n  * Locations\n  * Contact Red Hat\n  * Red Hat Blog\n  * Diversity, equity, and inclusion\n  * Cool Stuff Store\n  * Red Hat Summit\n\n### Red Hat legal and privacy links\n\n  * Privacy statement\n  * Terms of use\n  * All policies and guidelines\n  * Digital accessibility\n  * Cookie preferences\n\n\u2713\n\nThanks for sharing!\n\nAddToAny\n\nMore...\n\n## Report a website issue\n\n", "frontpage": false}
