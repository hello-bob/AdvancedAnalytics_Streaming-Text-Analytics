{"aid": "40291241", "title": "Eugene is a CLI tool for reviewing Postgres SQL migration scripts", "url": "https://kaveland.no/careful-with-that-lock-eugene-part-2.html", "domain": "kaveland.no", "votes": 3, "user": "rkaveland", "posted_at": "2024-05-07 20:44:48", "comments": 0, "source_title": "Careful with That Lock, Eugene: Part 2", "source_text": "Robin's blog \u2013 Careful with That Lock, Eugene: Part 2\n\n# Robin K\u00e5veland\n\nSoftware engineer\n\n# Careful with That Lock, Eugene: Part 2\n\nPosted on 2024-05-06 in postgres\n\nA while back, I wrote Careful with That Lock,Eugene about an idea for how to\ncheck if a database migration is likely to disturb production. That post came\nabout after having an inspiring chat with a colleague about the advantages of\ntransactional migration scripts and the ability to check the postgres system\ncatalog views before committing a transaction.\n\nOver the past few weeks, I've been experimenting with this idea to test if I\ncan use it to build valuable safety checks for DDL migrations. Kind of like\nshellcheck, but for database DDL migrations.\n\nAt this point, I've made enough progress to share some results. I've been\nworking on a Rust project that compiles a command line tool named eugene and\npublished it to crates.io and ghcr.io/kaaveland/eugene. The code lives in\nkaaveland/eugene and there's a hacker news thread here.\n\nThis post is about what eugene can do, how it is implemented, and what I hope\nto achieve with it in the future.\n\n# Demo: eugene trace report\n\nSuppose I have a migration script named alter_column_not_null.sql that looks\nlike this:\n\n    \n    \n    -- alter_column_not_null.sql -- create table books(id serial primary key, title text); -- fix: the title column should be not null alter table books alter column title set not null; -- fix: the title column should be unique alter table books add constraint title_unique unique (title);\n\nThere exists some table books already, and we want to enforce both that the\ntitle column is not null and that it is unique. Suppose you commit this to a\nbranch and make a pull request, then a minute later, the pull request is\nupdated with a comment generated by eugene trace -f markdown\nalter_column_not_null.sql that looks like this:\n\n## Statement number 1 for 10 ms\n\n### SQL\n\n    \n    \n    alter table books alter column title set not null;\n\n### Locks at start\n\nNo locks held at the start of this statement.\n\n### New locks taken\n\nSchema| Object| Mode| Relkind| OID| Safe  \n---|---|---|---|---|---  \npublic| books| AccessExclusiveLock| Table| 1| \u274c  \n  \n### Hints\n\n#### Validating table with a new NOT NULL column\n\nID: make_column_not_nullable_with_lock\n\nA column was changed from NULL to NOT NULL. This blocks all table access until\nall rows are validated. A safer way is: Add a CHECK constraint as NOT VALID,\nvalidate it later, then make the column NOT NULL.\n\nThe column title in the table public.books was changed to NOT NULL. If there\nis a CHECK (title IS NOT NULL) constraint on public.books, this is safe.\nSplitting this kind of change into 3 steps can make it safe:\n\n  1. Add a CHECK (title IS NOT NULL) NOT VALID; constraint on public.books.\n  2. Validate the constraint in a later transaction, with ALTER TABLE public.books VALIDATE CONSTRAINT ....\n  3. Make the column NOT NULL\n\n#### Taking dangerous lock without timeout\n\nID: dangerous_lock_without_timeout\n\nA lock that would block many common operations was taken without a timeout.\nThis can block all other operations on the table indefinitely if any other\ntransaction holds a conflicting lock while idle in transaction or active. A\nsafer way is: Run SET lock_timeout = '2s'; before the statement and retry the\nmigration if necessary.\n\nThe statement took AccessExclusiveLock on the Table public.books without a\ntimeout. It blocks SELECT, FOR UPDATE, FOR NO KEY UPDATE, FOR SHARE, FOR KEY\nSHARE, UPDATE, DELETE, INSERT, MERGE while waiting to acquire the lock.\n\n## Statement number 2 for 10 ms\n\n### SQL\n\n    \n    \n    alter table books add constraint title_unique unique (title);\n\n### Locks at start\n\nSchema| Object| Mode| Relkind| OID| Safe  \n---|---|---|---|---|---  \npublic| books| AccessExclusiveLock| Table| 1| \u274c  \n  \n### New locks taken\n\nSchema| Object| Mode| Relkind| OID| Safe  \n---|---|---|---|---|---  \npublic| books| ShareLock| Table| 1| \u274c  \n  \n### Hints\n\n#### Running more statements after taking AccessExclusiveLock\n\nID: holding_access_exclusive\n\nA transaction that holds an AccessExclusiveLock started a new statement. This\nblocks all access to the table for the duration of this statement. A safer way\nis: Run this statement in a new transaction.\n\nThe statement is running while holding an AccessExclusiveLock on the Table\npublic.books, blocking all other transactions from accessing it.\n\n#### Creating a new index on an existing table\n\nID: new_index_on_existing_table_is_nonconcurrent\n\nA new index was created on an existing table without the CONCURRENTLY keyword.\nThis blocks all writes to the table while the index is being created. A safer\nway is: Run CREATE INDEX CONCURRENTLY instead of CREATE INDEX.\n\nA new index was created on the table public.books. The index\npublic.title_unique was created non-concurrently, which blocks all writes to\nthe table. Use CREATE INDEX CONCURRENTLY to avoid blocking writes.\n\n#### Creating a new unique constraint\n\nID: new_unique_constraint_created_index\n\nFound a new unique constraint and a new index. This blocks all writes to the\ntable while the index is being created and validated. A safer way is: CREATE\nUNIQUE INDEX CONCURRENTLY, then add the constraint using the index.\n\nA new unique constraint title_unique was added to the table public.books. This\nconstraint creates a unique index on the table, and blocks all writes.\nConsider creating the index concurrently in a separate transaction, then\nadding the unique constraint by using the index: ALTER TABLE public.books ADD\nCONSTRAINT title_unique UNIQUE USING INDEX public.title_unique;\n\n#### Taking dangerous lock without timeout\n\nID: dangerous_lock_without_timeout\n\nA lock that would block many common operations was taken without a timeout.\nThis can block all other operations on the table indefinitely if any other\ntransaction holds a conflicting lock while idle in transaction or active. A\nsafer way is: Run SET lock_timeout = '2s'; before the statement and retry the\nmigration if necessary.\n\nThe statement took ShareLock on the Table public.books without a timeout. It\nblocks UPDATE, DELETE, INSERT, MERGE while waiting to acquire the lock.\n\n# How to perform this change safely\n\neugene has some concrete suggestions for changes we could do to make this\nmigration safer. We should always use lock_timeout when taking locks, and\nhere's a way to perform this migration in more steps that causes less time\nwith dangerous locks held overall. The hints give us a strategy to perform the\nmigration in several more steps:\n\n## Step 1: Add a CHECK constraint that is NOT VALID\n\nThis still takes the AccessExclusiveLock on books, but it no longer needs to\nvalidate all the rows, so the lock should be held for a shorter time. All\ninserts or updates on books will only allow title to be not null.\n\n    \n    \n    set lock_timeout = '2s'; alter table books add constraint title_not_null check (title is not null) not valid;\n\n## Step 2: Validate the constraint\n\nThis will take a ShareUpdateExclusiveLock on books, which is less restrictive\nthan the AccessExclusiveLock. This is possible, because only \"old rows\" could\npossibly be null, so there's no need to guard against inserts or updates with\na lock.\n\n    \n    \n    set lock_timeout = '2s'; alter table books validate constraint title_not_null;\n\n## Step 3: Make the column not null\n\nAt this point, postgres already knows that title is not null, so the\nAccessExclusiveLock is only necessary for updating the catalog, which is\ninstant:\n\n    \n    \n    set lock_timeout = '2s'; alter table books alter column title set not null;\n\n## Step 4: Add the unique constraint concurrently\n\nThis returns immediately, and postgres will build up the index and validate\nthe constraint in its own time, generally without blocking other operations:\n\n    \n    \n    create unique index concurrently title_unique_idx on books(title);\n\n## Step 5: Add the unique constraint using the index\n\nThis is also instant now, since the index is already built and postgres knows\nthat title is unique. The AccessExclusiveLock is again only necessary for\nupdating the catalog:\n\n    \n    \n    set lock_timeout = '2s'; alter table books add constraint title_unique unique using index title_unique_idx;\n\n## Summary\n\nIn this instance, eugene was able to provide some valuable hints about how to\nmake migrations that achieve the same result, but is much less likely to cause\ndisturbances in the database.\n\nThere are many example migration scripts and reports like this in the examples\ndirectory of the repository.\n\n## When do you need a tool like eugene?\n\nBreaking small database changes into this many steps isn't for everyone. I\nhave worked on many systems where we did migrations all the time without using\nsafeguards like this, and most of the time, it was fine. In many cases, some\namount of downtime was acceptable and we could stop the application prior to\nrunning DDL. In many other cases, lock_timeout alone would have saved us from\nissues with slow concurrent transactions and lock queues.\n\nThere is a lot of value in simplicity and simple migration scripts if you can\nafford it. Here are some things you may need to deal with if you use the safer\napproach recommended by eugene:\n\n  * If your statements are unable to take their locks in 2 seconds, your script crashes. You may need retries around your migration deployment.\n  * Creating indexes concurrently can take a long time. The statement returns right away and you need to wait for it to finish before you can run the next migration. You must be prepared to handle a deadlock or unique violation that makes it unable to complete the index.\n  * Invariably, working like this is going to make you create a lot more migration scripts than you otherwise would have.\n\nBut if you'd like to learn more about how postgres locking works, and how to\navoid common pitfalls when doing migrations, eugene can be a valuable tool. If\nyou're working on a system where some tables are very large, or have a lot of\nconcurrent transactions where some are slow, eugene could help you avoid\n\"stopping the world\" in production when you're executing migrations.\n\nOn the whole, I've certainly learned a lot about how postgres works while\nmaking eugene, and I hope that I can impart some of that learning on others by\nseeing the tool adopted.\n\n# How does eugene trace work?\n\neugene has a lot of static data built into it. For example:\n\n  * It knows about which lock modes that conflict with each other, I've lifted this from the excellent postgres documentation about locks.\n  * It has lots of helpful text snippets that can be used to generate hints. I've lifted many of these from the awesome strong_migrations README.\n\nBut the primary mechanism that it uses is to break down the SQL script into\nindividual statements, that are then run in a transaction. Before and after\neach statement, important database state is saved in memory, which enables us\nto calculate the effect that the statement had on several important system\nviews in the database:\n\n  * pg_class helps eugene figure out which database objects that are visible to other transactions (and maybe in the future, which objects that have been rewritten).\n  * pg_locks helps eugene figure out which locks that it owns\n  * pg_attribute helps eugene figure out which schema changes that were made to tables\n  * pg_constraint helps eugene figure out which constraints that were added, altered or removed\n\nThis means that there's a lot of knowledge that eugene does not need to have,\nfor example, it does not need a very good SQL parser, or keep track of which\nversions of postgres that exhibits what behaviour. If postgres 17 will be able\nto add constraints with lesser locks, eugene will be able to figure that out.\n\nRunning the transaction, then optionally committing it results in a big data\nstructure that essentially is a layered diff of database state. eugene trace\n-f json can emit this structure, so that it could be used by tools like jq, or\neugene trace -f md can generate a markdown report like the one above. Both of\nthese are essentially just views of this layered diff.\n\n## How are hints implemented?\n\nIt is easy to add new hints to eugene. They consist of a lot of static text,\nand then a rule that checks a statement level diff for certain conditions. If\nthe conditions are met, the hint is emitted. Here's an example of a hint rule\nfor the running_statement_while_holding_access_exclusive hint:\n\n    \n    \n    fn running_statement_while_holding_access_exclusive( sql_statement_trace: &FullSqlStatementLockTrace, ) -> Option<String> { let lock = sql_statement_trace .locks_at_start .iter() .find(|lock| lock.mode == \"AccessExclusiveLock\")?; let help = format!( \"The statement is running while holding an `AccessExclusiveLock` on the {} `{}.{}`, \\ blocking all other transactions from accessing it.\", lock.relkind, lock.schema, lock.object_name, ); Some(help) }\n\nHere's another one for discovering columns that changed from NULL to NOT NULL:\n\n    \n    \n    fn make_column_not_nullable_help( sql_statement_trace: &FullSqlStatementLockTrace, ) -> Option<String> { let column = sql_statement_trace .altered_columns .iter() .find(|column| !column.new.nullable && column.old.nullable)?; let table_name = format!(\"{}.{}\", column.new.schema_name, column.new.table_name); let col_name = column.new.column_name.as_str(); let help = format!( \"The column `{col_name}` in the table `{table_name}` was changed to `NOT NULL`. \\ If there is a `CHECK ({col_name} IS NOT NULL)` constraint on `{table_name}`, this is safe. \\ Splitting this kind of change into 3 steps can make it safe:\\n\\n\\ 1. Add a `CHECK ({col_name} IS NOT NULL) NOT VALID;` constraint on `{table_name}`.\\n\\ 2. Validate the constraint in a later transaction, with `ALTER TABLE {table_name} VALIDATE CONSTRAINT ...`.\\n\\ 3. Make the column `NOT NULL`\\n\", ); Some(help) }\n\nI am hoping for some help to add many more to hints.rs in the future, I am\ncertain that there are many kinds of migration patterns that I do not know\nabout. If you install the tool, you can run eugene hints to display general\ninformation about the hints that it knows about, for example:\n\n    \n    \n    { \"hints\": [ { \"id\": \"validate_constraint_with_lock\", \"name\": \"Validating table with a new constraint\", \"condition\": \"A new constraint was added and it is already `VALID`\", \"effect\": \"This blocks all table access until all rows are validated\", \"workaround\": \"Add the constraint as `NOT VALID` and validate it with `ALTER TABLE ... VALIDATE CONSTRAINT` later\" } // and many more ] }\n\n# Where to get eugene\n\nYou can install eugene from crates.io using cargo install eugene --bin, or you\ncan use the docker image ghcr.io/kaaveland/eugene to run the tool. I have been\ntrying to document it well in the github repository. If you want to play\naround with it, I suggest you clone the repository. There is a docker-\ncompose.yml that boots up a postgres database which is compatible with the\nexample migrations in examples/, so this should get you started:\n\n    \n    \n    docker-compose up -d # boots postgres on 5432 cargo run trace -f markdown examples/alter_column_not_null.sql \\ glow # glow renders markdown in the terminal beautifully\n\nIf you make any changes to the source code, you can run cargo test to run the\ntests, and see the diff on all of the markdown files in examples/ to see the\neffect of your change.\n\nThe test setup is using another neat postgres trick from this blog to make\nsure that the tests can run DDL changes in parallel without conflicting with\neach other or causing deadlocks.\n\nOnce you're satisfied with your changes, you can run cargo install --path .\n--bin to install the the tool to your system and try it out on your own\nmigrations.\n\n# Future work\n\nI have a lot of ideas for how to improve eugene. Here are some of them:\n\n  * Add more hints. I am hoping for ideas on the issue tracker\n  * Read and parse pg_stat_statements to find out which queries that could conflict with migrations.\n  * Add a eugene ci command that is suitable for integration with CI/CD pipelines, like pull requests so that you can run eugene ci on a branch and get a report on the pull request.\n  * Adding mechanisms to make eugene work like a linter, so it can optionally \"fail the build\".\n  * Add detection of table and index rewrites, so eugene can tell you if a migration could take an unexpectedly long time.\n  * Automatically generate safer migration scripts where it is possible to do this in a deterministic manner.\n\nI am hoping to get some feedback on the tool, and I would love some\nsuggestions on the issue tracker for where to go from here.\n\npostgres rust\n\n\u00a9\n\nBuilt with Pelican using Flex theme\n\n", "frontpage": false}
