{"aid": "40208876", "title": "Asynchronous Programming in C#", "url": "https://github.com/davidfowl/AspNetCoreDiagnosticScenarios/blob/master/AsyncGuidance.md", "domain": "github.com/davidfowl", "votes": 19, "user": "dtquad", "posted_at": "2024-04-30 09:23:16", "comments": 0, "source_title": "AspNetCoreDiagnosticScenarios/AsyncGuidance.md at master \u00b7 davidfowl/AspNetCoreDiagnosticScenarios", "source_text": "AspNetCoreDiagnosticScenarios/AsyncGuidance.md at master \u00b7\ndavidfowl/AspNetCoreDiagnosticScenarios \u00b7 GitHub\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\ndavidfowl / AspNetCoreDiagnosticScenarios Public\n\n  * Notifications\n  * Fork 725\n  * Star 7.4k\n\n/\n\n# AsyncGuidance.md\n\n## Latest commit\n\nsungam3r\n\nFix copy-pasted description (#114)\n\nMar 20, 2024\n\nbbf00bf \u00b7 Mar 20, 2024Mar 20, 2024\n\n## History\n\nHistory\n\n1486 lines (1143 loc) \u00b7 52.5 KB\n\n/\n\n# AsyncGuidance.md\n\n## File metadata and controls\n\n1486 lines (1143 loc) \u00b7 52.5 KB\n\nRaw\n\n# Table of contents\n\n  * Asynchronous Programming\n\n    * Asynchrony is viral\n    * Async void\n    * Prefer Task.FromResult over Task.Run for pre-computed or trivially computed data\n    * Avoid using Task.Run for long-running work that blocks the thread\n    * Avoid using Task.Result and Task.Wait\n    * Prefer await over ContinueWith\n    * Always create TaskCompletionSource<T> with TaskCreationOptions.RunContinuationsAsynchronously\n    * Always dispose CancellationTokenSource(s) used for timeouts\n    * Always flow CancellationToken(s) to APIs that take a CancellationToken\n    * Cancelling uncancellable operations\n    * Always call FlushAsync on StreamWriter(s) or Stream(s) before calling Dispose\n    * Prefer async/await over directly returning Task\n    * AsyncLocal<T>\n    * ConfigureAwait\n    * Scenarios\n    * Timer callbacks\n    * Implicit async void delegates\n    * ConcurrentDictionary.GetOrAdd\n    * Constructors\n    * WindowsIdentity.RunImpersonated\n\n# Asynchronous Programming\n\nAsynchronous programming has been around for several years on the .NET\nplatform but has historically been very difficult to do well. Since the\nintroduction of async/await in C# 5 asynchronous programming has become\nmainstream. Modern frameworks (like ASP.NET Core) are fully asynchronous and\nit's very hard to avoid the async keyword when writing web services. As a\nresult, there's been lots of confusion on the best practices for async and how\nto use it properly. This section will try to lay out some guidance with\nexamples of bad and good patterns of how to write asynchronous code.\n\n## Asynchrony is viral\n\nOnce you go async, all of your callers SHOULD be async, since efforts to be\nasync amount to nothing unless the entire call stack is async. In many cases,\nbeing partially asynchronous can be worse than being entirely synchronous.\nTherefore it is best to go all in, and make everything async at once.\n\n\u274c BAD This example uses the Task.Result and as a result blocks the current\nthread to wait for the result. This is an example of sync over async.\n\n    \n    \n    public int DoSomethingAsync() { var result = CallDependencyAsync().Result; return result + 1; }\n\n\u2705 GOOD This example uses the await keyword to get the result from\nCallDependencyAsync.\n\n    \n    \n    public async Task<int> DoSomethingAsync() { var result = await CallDependencyAsync(); return result + 1; }\n\n## Async void\n\nThe use of async void in ASP.NET Core applications is ALWAYS bad. Avoid it,\nnever do it. Typically, it's used when developers are trying to implement\nfire-and-forget patterns triggered by a controller action. Async void methods\nwill crash the process if an exception is thrown. We'll look at more of the\npatterns that cause developers to do this in ASP.NET Core applications but\nhere's a simple example:\n\n\u274c BAD Async void methods can't be tracked and therefore unhandled exceptions\ncan result in application crashes.\n\n    \n    \n    public class MyController : Controller { [HttpPost(\"/start\")] public IActionResult Post() { BackgroundOperationAsync(); return Accepted(); } public async void BackgroundOperationAsync() { var result = await CallDependencyAsync(); DoSomething(result); } }\n\n\u2705 GOOD Task-returning methods are better since unhandled exceptions trigger\nthe TaskScheduler.UnobservedTaskException.\n\n    \n    \n    public class MyController : Controller { [HttpPost(\"/start\")] public IActionResult Post() { Task.Run(BackgroundOperationAsync); return Accepted(); } public async Task BackgroundOperationAsync() { var result = await CallDependencyAsync(); DoSomething(result); } }\n\n## Prefer Task.FromResult over Task.Run for pre-computed or trivially computed\ndata\n\nFor pre-computed results, there's no need to call Task.Run, which will end up\nqueuing a work item to the thread pool that will immediately complete with the\npre-computed value. Instead, use Task.FromResult, to create a task wrapping\nalready computed data.\n\n\u274c BAD This example wastes a thread-pool thread to return a trivially computed\nvalue.\n\n    \n    \n    public class MyLibrary { public Task<int> AddAsync(int a, int b) { return Task.Run(() => a + b); } }\n\n\u2705 GOOD This example uses Task.FromResult to return the trivially computed\nvalue. It does not use any extra threads as a result.\n\n    \n    \n    public class MyLibrary { public Task<int> AddAsync(int a, int b) { return Task.FromResult(a + b); } }\n\n\ud83d\udca1NOTE: Using Task.FromResult will result in a Task allocation. Using\nValueTask<T> can completely remove that allocation.\n\n\u2705 GOOD This example uses a ValueTask<int> to return the trivially computed\nvalue. It does not use any extra threads as a result. It also does not\nallocate an object on the managed heap.\n\n    \n    \n    public class MyLibrary { public ValueTask<int> AddAsync(int a, int b) { return new ValueTask<int>(a + b); } }\n\n## Avoid using Task.Run for long-running work that blocks the thread\n\nLong-running work in this context refers to a thread that's running for the\nlifetime of the application doing background work (like processing queue\nitems, or sleeping and waking up to process some data). Task.Run will queue a\nwork item to the thread pool. The assumption is that that work will finish\nquickly (or quickly enough to allow reusing that thread within some reasonable\ntimeframe). Stealing a thread-pool thread for long-running work is bad since\nit takes that thread away from other work that could be done (timer callbacks,\ntask continuations, etc). Instead, spawn a new thread manually to do long-\nrunning blocking work.\n\n\ud83d\udca1 NOTE: The thread pool grows if you block threads but it's bad practice to do\nso.\n\n\ud83d\udca1 NOTE:Task.Factory.StartNew has an option TaskCreationOptions.LongRunning\nthat under the covers creates a new thread and returns a Task that represents\nthe execution. Using this properly requires several non-obvious parameters to\nbe passed in to get the right behavior on all platforms.\n\n\ud83d\udca1 NOTE: Don't use TaskCreationOptions.LongRunning with async code as this will\ncreate a new thread which will be destroyed after first await.\n\n\u274c BAD This example steals a thread-pool thread forever, to execute queued work\non a BlockingCollection<T>.\n\n    \n    \n    public class QueueProcessor { private readonly BlockingCollection<Message> _messageQueue = new BlockingCollection<Message>(); public void StartProcessing() { Task.Run(ProcessQueue); } public void Enqueue(Message message) { _messageQueue.Add(message); } private void ProcessQueue() { foreach (var item in _messageQueue.GetConsumingEnumerable()) { ProcessItem(item); } } private void ProcessItem(Message message) { } }\n\n\u2705 GOOD This example uses a dedicated thread to process the message queue\ninstead of a thread-pool thread.\n\n    \n    \n    public class QueueProcessor { private readonly BlockingCollection<Message> _messageQueue = new BlockingCollection<Message>(); public void StartProcessing() { var thread = new Thread(ProcessQueue) { // This is important as it allows the process to exit while this thread is running IsBackground = true }; thread.Start(); } public void Enqueue(Message message) { _messageQueue.Add(message); } private void ProcessQueue() { foreach (var item in _messageQueue.GetConsumingEnumerable()) { ProcessItem(item); } } private void ProcessItem(Message message) { } }\n\n\u2705 GOOD This example utilizes a TaskFactory with\nTaskCreationOptions.LongRunning to process the message queue instead of\ncreating a thread manually.\n\n    \n    \n    public class QueueProcessor { private readonly BlockingCollection<Message> _messageQueue = new BlockingCollection<Message>(); public Task StartProcessing() => Task.Factory.StartNew(ProcessQueue, TaskCreationOptions.LongRunning); public void Enqueue(Message message) { _messageQueue.Add(message); } private void ProcessQueue() { foreach (var item in _messageQueue.GetConsumingEnumerable()) { ProcessItem(item); } } private void ProcessItem(Message message) { } }\n\nUtilizing TaskCreationOptions.LongRunning introduces several advantages in\ncomparison with manual thread creation:\n\n  * It can be easily combined with await and TPL APIs, such as Task.WhenAll, amongst others.\n  * It provides a superior exception-handling mechanism. For instance, in the event of an unhandled exception in a manually created thread, the application will crash (unless handled via AppDomain.CurrentDomain.UnhandledException), but with .LongRunning, it will be wrapped into a Task as an AggregateException.\n\n\ud83d\udca1 NOTE: The TaskCreationOptions.LongRunning option is essentially a\nrecommendation to the TaskScheduler, which may interpret it differently in\ncustom TaskScheduler applications or runtimes, or future updates to the .NET\nruntime libraries. If your primary goal is to spawn a new dedicated thread,\nthen you might consider using the manual thread creation approach discussed\npreviously.\n\n## Avoid using Task.Result and Task.Wait\n\nThere are very few ways to use Task.Result and Task.Wait correctly so the\ngeneral advice is to completely avoid using them in your code.\n\n### \u26a0\ufe0f Sync over async\n\nUsing Task.Result or Task.Wait to block waiting on an asynchronous operation\nto complete is MUCH worse than calling a truly synchronous API to block. This\nphenomenon is dubbed \"Sync over async\". Here is what happens at a very high\nlevel:\n\n  * An asynchronous operation is kicked off.\n  * The calling thread is blocked waiting for that operation to complete.\n  * When the asynchronous operation completes, it unblocks the code waiting on that operation. This takes place on another thread.\n\nThe result is that we need to use 2 threads instead of 1 to complete\nsynchronous operations. This usually leads to thread-pool starvation and\nresults in service outages.\n\n### \u26a0\ufe0f Deadlocks\n\nThe SynchronizationContext is an abstraction that gives application models a\nchance to control where asynchronous continuations run. ASP.NET (non-core),\nWPF, and Windows Forms each have an implementation that will result in a\ndeadlock if Task.Wait or Task.Result is used on the main thread. This behavior\nhas led to a bunch of \"clever\" code snippets that show the \"right\" way to\nblock waiting for a Task. The truth is, there's no good way to block waiting\nfor a Task to complete.\n\n\ud83d\udca1NOTE: ASP.NET Core does not have a SynchronizationContext and is not prone to\nthe deadlock problem.\n\n\u274c BAD The below are all examples that are, in one way or another, trying to\navoid the deadlock situation but still succumb to \"sync over async\" problems.\n\n    \n    \n    public string DoOperationBlocking() { // Bad - Blocking the thread that enters. // DoAsyncOperation will be scheduled on the default task scheduler, and remove the risk of deadlocking. // In the case of an exception, this method will throw an AggregateException wrapping the original exception. return Task.Run(() => DoAsyncOperation()).Result; } public string DoOperationBlocking2() { // Bad - Blocking the thread that enters. // DoAsyncOperation will be scheduled on the default task scheduler, and remove the risk of deadlocking. // In the case of an exception, this method will throw the exception without wrapping it in an AggregateException. return Task.Run(() => DoAsyncOperation()).GetAwaiter().GetResult(); } public string DoOperationBlocking3() { // Bad - Blocking the thread that enters, and blocking the threadpool thread inside. // In the case of an exception, this method will throw an AggregateException containing another AggregateException, containing the original exception. return Task.Run(() => DoAsyncOperation().Result).Result; } public string DoOperationBlocking4() { // Bad - Blocking the thread that enters, and blocking the threadpool thread inside. return Task.Run(() => DoAsyncOperation().GetAwaiter().GetResult()).GetAwaiter().GetResult(); } public string DoOperationBlocking5() { // Bad - Blocking the thread that enters. // Bad - No effort has been made to prevent a present SynchonizationContext from becoming deadlocked. // In the case of an exception, this method will throw an AggregateException wrapping the original exception. return DoAsyncOperation().Result; } public string DoOperationBlocking6() { // Bad - Blocking the thread that enters. // Bad - No effort has been made to prevent a present SynchonizationContext from becoming deadlocked. return DoAsyncOperation().GetAwaiter().GetResult(); } public string DoOperationBlocking7() { // Bad - Blocking the thread that enters. // Bad - No effort has been made to prevent a present SynchonizationContext from becoming deadlocked. var task = DoAsyncOperation(); task.Wait(); return task.GetAwaiter().GetResult(); }\n\n## Prefer await over ContinueWith\n\nTask existed before the async/await keywords were introduced and as such\nprovided ways to execute continuations without relying on the language.\nAlthough these methods are still valid to use, we generally recommend that you\nprefer async/await to using ContinueWith. ContinueWith also does not capture\nthe SynchronizationContext and as a result is actually semantically different\nto async/await.\n\n\u274c BAD The example uses ContinueWith instead of async\n\n    \n    \n    public Task<int> DoSomethingAsync() { return CallDependencyAsync().ContinueWith(task => { return task.Result + 1; }); }\n\n\u2705 GOOD This example uses the await keyword to get the result from\nCallDependencyAsync.\n\n    \n    \n    public async Task<int> DoSomethingAsync() { var result = await CallDependencyAsync(); return result + 1; }\n\n## Always create TaskCompletionSource<T> with\nTaskCreationOptions.RunContinuationsAsynchronously\n\nTaskCompletionSource<T> is an important building block for libraries trying to\nadapt things that are not inherently awaitable to be awaitable via a Task. It\nis also commonly used to build higher-level operations (such as batching and\nother combinators) on top of existing asynchronous APIs. By default, Task\ncontinuations will run inline on the same thread that calls\nTry/Set(Result/Exception/Canceled). As a library author, this means having to\nunderstand that calling code can resume directly on your thread. This is\nextremely dangerous and can result in deadlocks, thread-pool starvation,\ncorruption of state (if code runs unexpectedly) and more.\n\nAlways use TaskCreationOptions.RunContinuationsAsynchronously when creating\nthe TaskCompletionSource<T>. This will dispatch the continuation onto the\nthread pool instead of executing it inline.\n\n\u274c BAD This example does not use\nTaskCreationOptions.RunContinuationsAsynchronously when creating the\nTaskCompletionSource<T>.\n\n    \n    \n    public Task<int> DoSomethingAsync() { var tcs = new TaskCompletionSource<int>(); var operation = new LegacyAsyncOperation(); operation.Completed += result => { // Code awaiting on this task will resume on this thread! tcs.SetResult(result); }; return tcs.Task; }\n\n\u2705 GOOD This example uses TaskCreationOptions.RunContinuationsAsynchronously\nwhen creating the TaskCompletionSource<T>.\n\n    \n    \n    public Task<int> DoSomethingAsync() { var tcs = new TaskCompletionSource<int>(TaskCreationOptions.RunContinuationsAsynchronously); var operation = new LegacyAsyncOperation(); operation.Completed += result => { // Code awaiting on this task will resume on a different thread-pool thread tcs.SetResult(result); }; return tcs.Task; }\n\n\ud83d\udca1NOTE: There are 2 enums that look alike.\nTaskCreationOptions.RunContinuationsAsynchronously and\nTaskContinuationOptions.RunContinuationsAsynchronously. Be careful not to\nconfuse their usage.\n\n## Always dispose CancellationTokenSource(s) used for timeouts\n\nCancellationTokenSource objects that are used for timeouts (are created with\ntimers or use the CancelAfter method), can put pressure on the timer queue if\nnot disposed.\n\n\u274c BAD This example does not dispose of the CancellationTokenSource and as a\nresult, the timer stays in the queue for 10 seconds after each request is\nmade.\n\n    \n    \n    public async Task<Stream> HttpClientAsyncWithCancellationBad() { var cts = new CancellationTokenSource(TimeSpan.FromSeconds(10)); using (var client = _httpClientFactory.CreateClient()) { var response = await client.GetAsync(\"http://backend/api/1\", cts.Token); return await response.Content.ReadAsStreamAsync(); } }\n\n\u2705 GOOD This example disposes of the CancellationTokenSource and properly\nremoves the timer from the queue.\n\n    \n    \n    public async Task<Stream> HttpClientAsyncWithCancellationGood() { using (var cts = new CancellationTokenSource(TimeSpan.FromSeconds(10))) { using (var client = _httpClientFactory.CreateClient()) { var response = await client.GetAsync(\"http://backend/api/1\", cts.Token); return await response.Content.ReadAsStreamAsync(); } } }\n\n## Always flow CancellationToken(s) to APIs that take a CancellationToken\n\nCancellation is cooperative in .NET. Everything in the call chain has to be\nexplicitly passed the CancellationToken in order for it to work well. This\nmeans you need to explicitly pass the token into other APIs that take a token\nif you want cancellation to be most effective.\n\n\u274c BAD This example neglects to pass the CancellationToken to Stream.ReadAsync\nmaking the operation effectively not cancellable.\n\n    \n    \n    public async Task<string> DoAsyncThing(CancellationToken cancellationToken = default) { byte[] buffer = new byte[1024]; // We forgot to pass flow cancellationToken to ReadAsync int read = await _stream.ReadAsync(buffer, 0, buffer.Length); return Encoding.UTF8.GetString(buffer, 0, read); }\n\n\u2705 GOOD This example passes the CancellationToken into Stream.ReadAsync.\n\n    \n    \n    public async Task<string> DoAsyncThing(CancellationToken cancellationToken = default) { byte[] buffer = new byte[1024]; // This properly flows cancellationToken to ReadAsync int read = await _stream.ReadAsync(buffer, 0, buffer.Length, cancellationToken); return Encoding.UTF8.GetString(buffer, 0, read); }\n\n## Cancelling uncancellable operations\n\nOne of the coding patterns that appears when doing asynchronous programming is\ncanceling an uncancellable operation. This usually means creating another task\nthat completes when a timeout or CancellationToken fires, and then using\nTask.WhenAny to detect a complete or cancelled operation.\n\n### Using CancellationTokens\n\n\u274c BAD This example uses Task.Delay(-1, token) to create a Task that completes\nwhen the CancellationToken fires, but if it doesn't fire, there's no way to\ndispose of the CancellationTokenRegistration created inside of Task.Delay.\nThis can lead to a memory leak.\n\n    \n    \n    public static async Task<T> WithCancellation<T>(this Task<T> task, CancellationToken cancellationToken) { // There's no way to dispose of the registration var delayTask = Task.Delay(-1, cancellationToken); var resultTask = await Task.WhenAny(task, delayTask); if (resultTask == delayTask) { // Operation cancelled throw new OperationCanceledException(); } return await task; }\n\n\u2705 GOOD This example disposes of the CancellationTokenRegistration when one of\nthe Task(s) is complete.\n\n    \n    \n    public static async Task<T> WithCancellation<T>(this Task<T> task, CancellationToken cancellationToken) { var tcs = new TaskCompletionSource<object>(TaskCreationOptions.RunContinuationsAsynchronously); // This disposes the registration as soon as one of the tasks trigger using (cancellationToken.Register(state => { ((TaskCompletionSource<object>)state).TrySetResult(null); }, tcs)) { var resultTask = await Task.WhenAny(task, tcs.Task); if (resultTask == tcs.Task) { // Operation cancelled throw new OperationCanceledException(cancellationToken); } return await task; } }\n\n\u2705 GOOD Prefer Task.WaitAsync on .NET >= 6;\n\n### Using a timeout\n\n\u274c BAD This example does not cancel the timer even if the operation\nsuccessfully completes. This means you could end up with lots of timers, which\ncan flood the timer queue.\n\n    \n    \n    public static async Task<T> TimeoutAfter<T>(this Task<T> task, TimeSpan timeout) { var delayTask = Task.Delay(timeout); var resultTask = await Task.WhenAny(task, delayTask); if (resultTask == delayTask) { // Operation cancelled throw new OperationCanceledException(); } return await task; }\n\n\u2705 GOOD This example cancels the timer if the operation successfully completes.\n\n    \n    \n    public static async Task<T> TimeoutAfter<T>(this Task<T> task, TimeSpan timeout) { using (var cts = new CancellationTokenSource()) { var delayTask = Task.Delay(timeout, cts.Token); var resultTask = await Task.WhenAny(task, delayTask); if (resultTask == delayTask) { // Operation cancelled throw new OperationCanceledException(); } else { // Cancel the timer task so that it does not fire cts.Cancel(); } return await task; } }\n\n\u2705 GOOD Prefer Task.WaitAsync on .NET >= 6;\n\n## Always call FlushAsync on StreamWriter(s) or Stream(s) before calling\nDispose\n\nWhen writing to a Stream or StreamWriter, even if the asynchronous overloads\nare used for writing, the underlying data might be buffered. When data is\nbuffered, disposing the Stream or StreamWriter via the Dispose method will\nsynchronously write/flush, which results in blocking the thread and could lead\nto thread-pool starvation. Either use the asynchronous DisposeAsync method\n(for example via await using) or call FlushAsync before calling Dispose.\n\n\ud83d\udca1NOTE: This is only problematic if the underlying subsystem does IO.\n\n\u274c BAD This example ends up blocking the request by writing synchronously to\nthe HTTP-response body.\n\n    \n    \n    app.Run(async context => { // The implicit Dispose call will synchronously write to the response body using (var streamWriter = new StreamWriter(context.Response.Body)) { await streamWriter.WriteAsync(\"Hello World\"); } });\n\n\u2705 GOOD This example asynchronously flushes any buffered data while disposing\nthe StreamWriter.\n\n    \n    \n    app.Run(async context => { // The implicit AsyncDispose call will flush asynchronously await using (var streamWriter = new StreamWriter(context.Response.Body)) { await streamWriter.WriteAsync(\"Hello World\"); } });\n\n\u2705 GOOD This example asynchronously flushes any buffered data before disposing\nthe StreamWriter.\n\n    \n    \n    app.Run(async context => { using (var streamWriter = new StreamWriter(context.Response.Body)) { await streamWriter.WriteAsync(\"Hello World\"); // Force an asynchronous flush await streamWriter.FlushAsync(); } });\n\n## Prefer async/await over directly returning Task\n\nThere are benefits to using the async/await keyword instead of directly\nreturning the Task:\n\n  * Asynchronous and synchronous exceptions are normalized to always be asynchronous.\n  * The code is easier to modify (consider adding a using, for example).\n  * Diagnostics of asynchronous methods are easier (debugging hangs etc).\n  * Exceptions thrown will be automatically wrapped in the returned Task instead of surprising the caller with an actual exception.\n  * Async locals will not leak out of async methods. If you set an async local in a non-async method, it will \"leak\" out of that call.\n\n\u274c BAD This example directly returns the Task to the caller.\n\n    \n    \n    public Task<int> DoSomethingAsync() { return CallDependencyAsync(); }\n\n\u2705 GOOD This example uses async/await instead of directly returning the Task.\n\n    \n    \n    public async Task<int> DoSomethingAsync() { return await CallDependencyAsync(); }\n\n\ud83d\udca1NOTE: There are performance considerations when using an async state machine\nover directly returning the Task. It's always faster to directly return the\nTask since it does less work but you end up changing the behavior and\npotentially losing some of the benefits of the async state machine.\n\n## AsyncLocal<T>\n\nAsync locals are a way to store/retrieve ambient state throughout an\napplication. This can be a very useful alternative to flowing explicit state\neverywhere, especially through call sites that you do not have much control\nover. While it is powerful, it is also dangerous if used incorrectly. Async\nlocals are attached to the execution context which flows everywhere\nimplicitly. Disabling execution context flow requires the use of advanced APIs\n(typically prefixed with the Unsafe name). As such, there's very little\ncontrol over what code will attempt to access these values.\n\n### Creating an AsyncLocal<T>\n\nIf you can avoid async locals, do so by explicitly passing state around or\nusing techniques like inversion of control.\n\nIf you cannot avoid it, it's best to make sure that anything put into an async\nlocal is:\n\n  1. Not disposable\n  2. Immutable/read-only/thread-safe\n\nLet's look at 2 examples:\n\n  1. \u274c BAD A disposable object stored in an async local\n\n    \n    \n    using (var thing = new DisposableThing()) { // Make the disposable object available ambiently DisposableThing.Current = thing; Dispatch(); // We're about to dispose the object so make sure nobody else captures this instance DisposableThing.Current = null; } void Dispatch() { // Task.Run will capture the current execution context (which means async locals are captured in the callback) _ = Task.Run(async () => { // Delay for a second then log await Task.Delay(1000); Log(); }); } void Log() { try { // Get the current value and make sure it's not null before reading the value var thing = DisposableThing.Current; if (thing is not null) { Console.WriteLine($\"Logging ambient value {thing.Value}\"); } } catch (Exception ex) { Console.WriteLine(ex); } } Console.ReadLine(); class DisposableThing : IDisposable { private static readonly AsyncLocal<DisposableThing?> _current = new(); private bool _disposed; public static DisposableThing? Current { get => _current.Value; set { _current.Value = value; } } public int Value { get { if (_disposed) throw new ObjectDisposedException(GetType().FullName); return 1; } } public void Dispose() { _disposed = true; } }\n\nThis above example will always result in an ObjectDisposedException being\nthrown. Even though the Log method defensively checks for null before logging\nthe value, it has a reference to the disposed of DisposableThing. Setting the\nAsyncLocal<DisposableThing> to null does not affect the code inside of Log,\nthis is because the execution context is copy on write. This means that all\nfuture reads DisposableThing.Current will be null, but it won't affect any of\nthe previous reads.\n\nWhen we set DisposableThing.Current = null; we are making a new execution\ncontext, not mutating the one that was captured by Task.Run. To get a better\nunderstanding of this run the following code:\n\n    \n    \n    DisposableThing.Current = new DisposableThing(); Console.WriteLine(\"After setting thing \" + ExecutionContext.Capture().GetHashCode()); DisposableThing.Current = null; Console.WriteLine(\"After setting Current to null \" + ExecutionContext.Capture().GetHashCode());\n\nThe hash code of the execution context is different each time we set a new\nvalue.\n\n\u26a0\ufe0f It might be tempting to update the logic in DisposableThing.Current to\nmutate the original execution context instead of setting the async local\ndirectly (StrongBox<T> is a reference type that stores the underlying T in a\nmutable field):\n\n    \n    \n    class DisposableThing : IDisposable { private static readonly AsyncLocal<StrongBox<DisposableThing?>> _current = new(); private bool _disposed; public static DisposableThing? Current { get => _current.Value?.Value; set { var box = _current.Value; if (box is not null) { // Mutate the value in any execution context that was copied box.Value = null; } if (value is not null) { _current.Value = new StrongBox<DisposableThing?>(value); } } } public int Value { get { if (_disposed) throw new ObjectDisposedException(GetType().FullName); return 1; } } public void Dispose() { _disposed = true; } }\n\nThis will have the desired effect and will set the value to null in any\nexecution context that references this async local value.\n\n    \n    \n    DisposableThing.Current = new DisposableThing(); Console.WriteLine(\"After setting thing \" + ExecutionContext.Capture().GetHashCode()); DisposableThing.Current = null; Console.WriteLine(\"After setting Current to null \" + ExecutionContext.Capture().GetHashCode());\n\n\u26a0\ufe0f While this looks attractive, the reference to DisposableThing.Current might\nhave still been captured before the value was set to null:\n\n    \n    \n    void Dispatch() { // Task.Run will capture the current execution context (which means async locals are captured in the callback) _ = Task.Run(async () => { // Get the current reference var current = DisposableThing.Current; // Delay for a second then log await Task.Delay(1000); Log(current); }); } void Log(DisposableThing thing) { try { Console.WriteLine($\"Logging ambient value {thing.Value}\"); } catch (Exception ex) { Console.WriteLine(ex); } }\n\nThere's a race condition between the capture of the DisposableThing, the\ndisposal of DisposableThing and setting DisposableThing.Current it to null. In\nthe end, the code is unreliable and may fail at random. Don't store disposable\nobjects in async locals.\n\n  2. \u274c BAD A non-thread-safe object stored in an async local\n\n    \n    \n    AmbientValues.Current = new Dictionary<int, string>(); Parallel.For(0, 10, i => { AmbientValues.Current[i] = \"processing\"; LogCurrentValues(); AmbientValues.Current[i] = \"done\"; }); void LogCurrentValues() { foreach (var pair in AmbientValues.Current) { Console.WriteLine(pair); } } class AmbientValues { private static readonly AsyncLocal<Dictionary<int, string>> _current = new(); public static Dictionary<int, string> Current { get => _current.Value!; set => _current.Value = value; } }\n\nThe above example stores a normal Dictionary<int, string> in an async local\nand does some parallel processing on it. While this may be obvious from the\nabove example, async locals allow arbitrary code on arbitrary threads to\naccess the execution context and thus any async locals associated with said\ncontext. As a result, it is important to assume that data can be accessed\nconcurrently and should be made thread-safe as a result.\n\n    \n    \n    class AmbientValues { private static readonly AsyncLocal<ConcurrentDictionary<int, string>> _current = new(); public static ConcurrentDictionary<int, string> Current { get => _current.Value!; set => _current.Value = value; } }\n\n\u2705 GOOD The above uses a ConcurrentDictionary<int, string> which is thread\nsafe.\n\n### Don't leak your AsyncLocal<T>\n\nAsync locals flow across awaits automatically and can be captured by any API\nthat explicitly calls ExecutionContext.Capture. The latter can lead to memory\nleaks in certain situations.\n\n#### Common APIs that capture the ExecutionContext\n\nAPIs that run user callbacks usually capture the current execution context in\norder to preserve async locals between callback registration and execution.\nHere are examples of some APIs that do this:\n\n  * Timer\n  * CancellationToken.Register\n  * new FileSystemWatcher\n  * SocketAsyncEventArgs\n  * Task.Run\n  * ThreadPool.QueueUserWorkItem\n\n\u274c BAD Here's an example of an execution context leak that causes memory\npressure because of a lifetime mismatch between the API capturing the\nexecution context, and the lifetime of the data stored in the async local.\n\n    \n    \n    using System.Collections.Concurrent; // Singleton cache var cache = new NumberCache(TimeSpan.FromHours(1)); var executionContext = ExecutionContext.Capture(); // Simulate 10000 concurrent requests Parallel.For(0, 10000, i => { // Restore the initial ExecutionContext per \"request\" ExecutionContext.Restore(executionContext!); ChunkyObject.Current = new ChunkyObject(); cache.Add(i); }); Console.WriteLine(\"Before GC: \" + BytesAsString(GC.GetGCMemoryInfo().HeapSizeBytes)); Console.ReadLine(); GC.Collect(); GC.WaitForPendingFinalizers(); Console.WriteLine(\"After GC: \" + BytesAsString(GC.GetGCMemoryInfo().HeapSizeBytes)); Console.ReadLine(); static string BytesAsString(long bytes) { string[] suffix = { \"B\", \"KB\", \"MB\", \"GB\", \"TB\" }; int i; double doubleBytes = 0; for (i = 0; bytes / 1024 > 0; i++, bytes /= 1024) { doubleBytes = bytes / 1024.0; } return string.Format(\"{0:0.00} {1}\", doubleBytes, suffix[i]); } public class NumberCache { private readonly ConcurrentDictionary<int, CancellationTokenSource> _cache = new ConcurrentDictionary<int, CancellationTokenSource>(); private TimeSpan _timeSpan; public NumberCache(TimeSpan timeSpan) { _timeSpan = timeSpan; } public void Add(int key) { var cts = _cache.GetOrAdd(key, _ => new CancellationTokenSource()); // Delete entry on expiration cts.Token.Register((_, _) => _cache.TryRemove(key, out _), null); // Start count down cts.CancelAfter(_timeSpan); } } class ChunkyObject { private static readonly AsyncLocal<ChunkyObject?> _current = new(); // Stores lots of data (but it should be gen0) private readonly string _data = new string('A', 1024 * 32); public static ChunkyObject? Current { get => _current.Value; set => _current.Value = value; } public string Data => _data; }\n\nThe above example has a singleton NumberCache that stores numbers for an hour.\nWe have a ChunkyObject which stores a 32K string in a field, and has an async\nlocal so that any code running may access the current ChunkyObject. This\nobject should be collected when the GC runs, but instead, we're implicitly\ncapturing the ChunkyObject in the NumberCache via CancellationToken.Register.\n\nInstead of just caching the number and a CancellationTokenSource, we're\nimplicitly capturing and storing all async locals attached to the current\nexecution context for an hour!\n\nTry running the sample locally. Running this on my machine reports numbers\nlike this:\n\n    \n    \n    Before GC: 654.65 MB After GC: 659.68 MB\n\nHere's a look at the heap with those objects. You can see we have stored\n10,000 ChunkyObjects, strings rooted by those chunky objects. The object graph\nlooks like CancellationTokenSource -> ExecutionContext -> AsyncLocalValueMap\n-> ChunkObject -> string.\n\nWith one small tweak to this code, we can avoid the implicit execution context\ncapture.\n\n\u2705 GOOD Use CancellationToken.UnsafeRegister to avoid capturing the execution\ncontext and any async locals as part of the NumberCache:\n\n    \n    \n    public class NumberCache { private readonly ConcurrentDictionary<int, CancellationTokenSource> _cache = new ConcurrentDictionary<int, CancellationTokenSource>(); private TimeSpan _timeSpan; public NumberCache(TimeSpan timeSpan) { _timeSpan = timeSpan; } public void Add(int key) { var cts = _cache.GetOrAdd(key, _ => new CancellationTokenSource()); // Delete entry on expiration cts.Token.UnsafeRegister((_, _) => _cache.TryRemove(key, out _), null); // Start count down cts.CancelAfter(_timeSpan); } }\n\nThe GC numbers after this change:\n\n    \n    \n    Before GC: 10.32 MB After GC: 5.10 MB\n\nThe heap looks like we'd expect. There's no execution context capture, so the\nChunkyObject isn't stored.\n\n\ud83d\udca1 NOTE: You have NO control over how APIs decide to store the execution\ncontext, but with this understanding, you should be able to minimize memory\nleaks by clearing the memory using the technique described in Creating an\nAsyncLocal<T> section.\n\n    \n    \n    using System.Collections.Concurrent; // Singleton cache var cache = new NumberCache(TimeSpan.FromHours(1)); var executionContext = ExecutionContext.Capture(); // Simulate 10000 concurrent requests Parallel.For(0, 10000, i => { // Restore the initial ExecutionContext per \"request\" ExecutionContext.Restore(executionContext!); ChunkyObject.Current = new ChunkyObject(); cache.Add(i); // Null out the chunky object so the GC can release the memory ChunkyObject.Current = default; }); class ChunkyObject { private static readonly AsyncLocal<StrongBox<ChunkyObject?>> _current = new(); // Stores lots of data (but it should be gen0) private readonly string _data = new string('A', 1024 * 32); public static ChunkyObject? Current { get => _current.Value?.Value; set { var box = _current.Value; if (box is not null) { // Mutate the value in any execution context that was copied box.Value = null; } if (value is not null) { _current.Value = new StrongBox<ChunkyObject?>(value); } } } public string Data => _data; }\n\nThis technique reduces the heap memory significantly:\n\n    \n    \n    Before GC: 7.91 MB After GC: 5.66 MB\n\nThe execution context is storing StrongBox<ChunkyObject> with a null reference\nto the ChunkyObject. This is technically still a \"leak\" but we've reduced the\nimpact significantly. Here's a look at the memory profile showing objects with\n10,000 allocations (the number of requests we created). You can see the GC has\ncollected ChunkObject instances but there are still 10,000 references to\nStrongBox<ChunkyObject>.\n\n### Avoid setting AsyncLocal<T> values outside of async methods\n\nAsync methods have a special behavior for async locals that makes sure values\ndo not propagate outside of the async method.\n\n\u274c BAD Avoid setting async local values outside of async methods:\n\n    \n    \n    var local = new AsyncLocal<int>(); MethodA(); Console.WriteLine(local.Value); void MethodA() { local.Value = 1; MethodB(); Console.WriteLine(local.Value); } void MethodB() { local.Value = 2; Console.WriteLine(local.Value); }\n\nThe above prints 2, 2, 2. The execution context mutations are being propagated\noutside of the method. This can lead to extremely confusing behavior and hard-\nto-track down bugs.\n\n\u2705 GOOD Set async locals in async methods:\n\n    \n    \n    var local = new AsyncLocal<int>(); await MethodA(); Console.WriteLine(local.Value); async Task MethodA() { local.Value = 1; await MethodB(); Console.WriteLine(local.Value); } async Task MethodB() { local.Value = 2; Console.WriteLine(local.Value); }\n\nThe above will print 2, 1, 0. This is because the async method restores the\noriginal execution context on exit.\n\n## ConfigureAwait\n\nTBD\n\n# Scenarios\n\nThe above tries to distill general guidance but doesn't do justice to the\nkinds of real-world situations that cause code like this to be written in the\nfirst place (bad code). This section tries to take concrete examples from real\napplications and turn them into something simple to help you relate these\nproblems to existing codebases.\n\n## Timer callbacks\n\n\u274c BAD The Timer callback is void-returning and we have asynchronous work to\nexecute. This example uses async void to accomplish it and as a result, can\ncrash the process if an exception occurs.\n\n    \n    \n    public class Pinger { private readonly Timer _timer; private readonly HttpClient _client; public Pinger(HttpClient client) { _client = client; _timer = new Timer(Heartbeat, null, 1000, 1000); } public async void Heartbeat(object state) { await _client.GetAsync(\"http://mybackend/api/ping\"); } }\n\n\u274c BAD This attempts to block the Timer callback. This may result in thread-\npool starvation and is an example of sync over async\n\n    \n    \n    public class Pinger { private readonly Timer _timer; private readonly HttpClient _client; public Pinger(HttpClient client) { _client = client; _timer = new Timer(Heartbeat, null, 1000, 1000); } public void Heartbeat(object state) { _client.GetAsync(\"http://mybackend/api/ping\").GetAwaiter().GetResult(); } }\n\n\u2705 GOOD This example uses an async Task-based method and discards the Task in\nthe Timer callback. If this method fails, it will not crash the process.\nInstead, it will fire the TaskScheduler.UnobservedTaskException event.\n\n    \n    \n    public class Pinger { private readonly Timer _timer; private readonly HttpClient _client; public Pinger(HttpClient client) { _client = client; _timer = new Timer(Heartbeat, null, 1000, 1000); } public void Heartbeat(object state) { // Discard the result _ = DoAsyncPing(); } private async Task DoAsyncPing() { await _client.GetAsync(\"http://mybackend/api/ping\"); } }\n\n\u2705 GOOD This example uses the new PeriodicTimer introduced in .NET 6:\n\n    \n    \n    public class Pinger : IDisposable { private readonly PeriodicTimer _timer; private readonly HttpClient _client; public Pinger(HttpClient client) { _client = client; _timer = new PeriodicTimer(TimeSpan.FromSeconds(1)); _ = Task.Run(DoAsyncPings); } public void Dispose() { _timer.Dispose(); } private async Task DoAsyncPings() { while (await _timer.WaitForNextTickAsync()) { // TODO: Handle exceptions await _client.GetAsync(\"http://mybackend/api/ping\"); } } }\n\n## Implicit async void delegates\n\nImagine a BackgroundQueue with a FireAndForget that takes a callback. This\nmethod will execute the callback at some time in the future.\n\n\u274c BAD This will force callers to either block in the callback or use an async\nvoid delegate.\n\n    \n    \n    public class BackgroundQueue { public static void FireAndForget(Action action) { } }\n\n\u274c BAD This calling code is creating an async void method implicitly. The\ncompiler fully supports this today.\n\n    \n    \n    public class Program { public void Main(string[] args) { var httpClient = new HttpClient(); BackgroundQueue.FireAndForget(async () => { await httpClient.GetAsync(\"http://pinger/api/1\"); }); Console.ReadLine(); } }\n\n\u2705 GOOD This BackgroundQueue implementation offers both sync and async callback\noverloads.\n\n    \n    \n    public class BackgroundQueue { public static void FireAndForget(Action action) { } public static void FireAndForget(Func<Task> action) { } }\n\n## ConcurrentDictionary.GetOrAdd\n\nIt's pretty common to cache the result of an asynchronous operation and\nConcurrentDictionary is a good data structure for doing that. GetOrAdd is a\nconvenience API for trying to get an item if it's already there or adding it\nif it isn't. The callback is synchronous so it's tempting to write code that\nuses Task.Result to produce the value of an asynchronous process but that can\nlead to thread-pool starvation.\n\n\u274c BAD This may result in thread-pool starvation since we're blocking the\nrequest thread if the person data is not cached.\n\n    \n    \n    public class PersonController : Controller { private AppDbContext _db; // This cache needs expiration private static ConcurrentDictionary<int, Person> _cache = new ConcurrentDictionary<int, Person>(); public PersonController(AppDbContext db) { _db = db; } public IActionResult Get(int id) { var person = _cache.GetOrAdd(id, (key) => _db.People.FindAsync(key).Result); return Ok(person); } }\n\n\u2705 GOOD This implementation won't result in thread-pool starvation since we're\nstoring a task instead of the result itself.\n\n\u26a0\ufe0f ConcurrentDictionary.GetOrAdd, when accessed concurrently, may run the\nvalue-constructing delegate multiple times. This can result in needlessly\nkicking off the same potentially expensive computation multiple times.\n\n    \n    \n    public class PersonController : Controller { private AppDbContext _db; // This cache needs expiration private static ConcurrentDictionary<int, Task<Person>> _cache = new ConcurrentDictionary<int, Task<Person>>(); public PersonController(AppDbContext db) { _db = db; } public async Task<IActionResult> Get(int id) { var person = await _cache.GetOrAdd(id, (key) => _db.People.FindAsync(key)); return Ok(person); } }\n\n\u2705 GOOD This implementation prevents the delegate from being executed multiple\ntimes, by using the async lazy pattern: even if construction of the AsyncLazy\ninstance happens multiple times (\"cheap\" operation), the delegate will be\ncalled only once.\n\n    \n    \n    public class PersonController : Controller { private AppDbContext _db; // This cache needs expiration private static ConcurrentDictionary<int, AsyncLazy<Person>> _cache = new ConcurrentDictionary<int, AsyncLazy<Person>>(); public PersonController(AppDbContext db) { _db = db; } public async Task<IActionResult> Get(int id) { var person = await _cache.GetOrAdd(id, (key) => new AsyncLazy<Person>(() => _db.People.FindAsync(key))).Value; return Ok(person); } private class AsyncLazy<T> : Lazy<Task<T>> { public AsyncLazy(Func<Task<T>> valueFactory) : base(valueFactory) { } } }\n\n## Constructors\n\nConstructors are synchronous. If you need to initialize some logic that may be\nasynchronous, there are a couple of patterns for dealing with this.\n\nHere's an example of using a client API that needs to connect asynchronously\nbefore use.\n\n    \n    \n    public interface IRemoteConnectionFactory { Task<IRemoteConnection> ConnectAsync(); } public interface IRemoteConnection { Task PublishAsync(string channel, string message); Task DisposeAsync(); }\n\n\u274c BAD This example uses Task.Result to get the connection in the constructor.\nThis could lead to thread-pool starvation and deadlocks.\n\n    \n    \n    public class Service : IService { private readonly IRemoteConnection _connection; public Service(IRemoteConnectionFactory connectionFactory) { _connection = connectionFactory.ConnectAsync().Result; } }\n\n\u2705 GOOD This implementation uses a static factory pattern in order to allow\nasynchronous construction:\n\n    \n    \n    public class Service : IService { private readonly IRemoteConnection _connection; private Service(IRemoteConnection connection) { _connection = connection; } public static async Task<Service> CreateAsync(IRemoteConnectionFactory connectionFactory) { return new Service(await connectionFactory.ConnectAsync()); } }\n\n## WindowsIdentity.RunImpersonated\n\nThis API runs the specified action as the impersonated Windows identity. An\nasynchronous version of the callback was introduced in .NET 5.0.\n\n\u274c BAD This example tries to execute the query asynchronously, and then wait\nfor it outside of the call to RunImpersonated. This will throw because the\nquery might be executing outside of the impersonation context.\n\n    \n    \n    public async Task<IEnumerable<Product>> GetDataImpersonatedAsync(SafeAccessTokenHandle safeAccessTokenHandle) { Task<IEnumerable<Product>> products = null; WindowsIdentity.RunImpersonated( safeAccessTokenHandle, context => { products = _db.QueryAsync(\"SELECT Name from Products\"); }); return await products; }\n\n\u274c BAD This example uses Task.Result to execute the query synchronously (sync\nover async). This could lead to thread-pool starvation and deadlocks.\n\n    \n    \n    public IEnumerable<Product> GetDataImpersonated(SafeAccessTokenHandle safeAccessTokenHandle) { return WindowsIdentity.RunImpersonated( safeAccessTokenHandle, context => _db.QueryAsync(\"SELECT Name from Products\").Result); }\n\n\u2705 GOOD This example awaits the result of RunImpersonated (the delegate is\nFunc<Task<IEnumerable<Product>>> in this case). It is the recommended practice\nin frameworks earlier than .NET 5.0.\n\n    \n    \n    public async Task<IEnumerable<Product>> GetDataImpersonatedAsync(SafeAccessTokenHandle safeAccessTokenHandle) { return await WindowsIdentity.RunImpersonated( safeAccessTokenHandle, context => _db.QueryAsync(\"SELECT Name from Products\")); }\n\n\u2705 GOOD This example uses the asynchronous RunImpersonatedAsync function and\nawaits its result. It is available in .NET 5.0 or newer.\n\n    \n    \n    public async Task<IEnumerable<Product>> GetDataImpersonatedAsync(SafeAccessTokenHandle safeAccessTokenHandle) { return await WindowsIdentity.RunImpersonatedAsync( safeAccessTokenHandle, context => _db.QueryAsync(\"SELECT Name from Products\")); }\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": true}
