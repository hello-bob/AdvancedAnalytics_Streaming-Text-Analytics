{"aid": "40070743", "title": "The State of Artificial Intelligence 2024: AI Index Report", "url": "https://exoswan.com/state-of-ai-2024", "domain": "exoswan.com", "votes": 1, "user": "muchtolearn", "posted_at": "2024-04-17 22:29:05", "comments": 0, "source_title": "The State of Artificial Intelligence 2024: AI Index Report", "source_text": "The State of Artificial Intelligence 2024: AI Index Report\n\nSkip to content\n\nMenu\n\n# The State of Artificial Intelligence 2024: AI Index Report\n\nCould an AI design a better medicine to fight cancer, solve math problems that\nbaffle the best human minds, or help us find answers for a cleaner planet? We\nmay not be there yet, but AI is rapidly getting better at solving complex\nproblems. It\u2019s also creating exciting possibilities \u2013 and unexpected risks.\nThe year 2023 was a turning point for AI, and changes are coming even faster\nin 2024. Drawing on Stanford\u2019s 2024 AI Index Report, we\u2019ll examine the\ncutting-edge of AI, the economic changes it\u2019s bringing, and the serious\nquestions it raises about its use.\n\nNote: Keep in mind that these are our (decidedly human) interpretations and\nkey takeaways. While we\u2019re cautiously excited about the transformative\npotential of technologies like AI, our company\u2019s mission is to help everyday\nhumans not only survive, but prosper in an uncertain future.\n\nCredit: NicoElNino/Adobe\n\n## Who\u2019s leading the AI race?\n\nThe race to create groundbreaking AI is no longer just between researchers at\ntop universities \u2013 it\u2019s now dominated by the deep pockets and vast resources\nof industry players. In 2023, industry released a staggering 51 notable\nmachine learning models, more than triple the 15 produced by academia. There\nwere also 21 models released through industry-academia collaborations, a new\nhigh, demonstrating that some of the field\u2019s top talent is drawn to the\nresources big tech offers.\n\nThis dominance comes at a literal cost. OpenAI\u2019s GPT-4 system is estimated to\nhave used $78 million worth of compute power during training, while Google\u2019s\nGemini Ultra cost a jaw-dropping $191 million. These are not investments most\nuniversities can match, leaving them at a disadvantage.\n\nThe foundation of recent AI progress lies in \u201cfoundation models.\u201d Foundation\nmodels are large, complex AI systems that are trained on vast amounts of data,\nenabling them to be adapted for a wide range of tasks. These models serve as a\n\u201cfoundation\u201d for creating more specialized AI applications.\n\nIn 2023, the number of foundation models released globally more than doubled\nto 149. Importantly, the trend towards open-source models continued, with\n65.7% of newly released models being open to the public. This allows smaller\ncompanies and researchers access to the technology, even if the best-\nperforming models remain closed-source within large corporations.\n\nKey Takeaways:\n\n  * Industry Dominance in AI Research: In 2023, industry released 51 notable machine learning models, compared to just 15 from academia and 21 collaboration. This trend reflects the vast resources big tech can dedicate to AI research and development.\n  * Soaring Costs of Top-Tier Models: Training costs for top AI models are skyrocketing. OpenAI\u2019s GPT-4 system is estimated at $78 million, while Google\u2019s Gemini Ultra reached a staggering $191 million. These figures highlight the financial barriers for universities and smaller players in the field.\n  * Rise of Foundation Models: Foundation models, trained on massive datasets for diverse applications, are a driving force behind recent AI advancements. The number of foundation models doubled in 2023 to 149 globally.\n  * Open-Source Movement in AI: There\u2019s a growing trend towards open-source foundation models, with 65.7% of new models being publicly accessible. This allows wider participation in AI development beyond the confines of big tech companies.\n  * US Leads in AI Models: The United States remains the global leader in AI models, outpacing China, the EU, and the UK. This dominance could impact future AI development and intellectual property.\n\nThe United States still leads in ML model development. Credit: 2024 AI\nIndex/Epoch\n\n## What\u2019s AI now capable of?\n\nThe year 2023 saw impressive leaps in AI capabilities, but also reminders of\nlingering limitations. One major advancement is the rise of multimodal AI.\nSystems like Google\u2019s Gemini and OpenAI\u2019s GPT-4 demonstrate remarkable\nflexibility in handling both text and images, and in some instances, even\naudio. This opens up possibilities for AI assistants that can not only\ncomprehend your question, but illustrate the answer, or systems capable of\ngenerating original visuals based on textual descriptions.\n\nDespite these exciting developments, AI systems still face significant\nperformance hurdles. While exceeding human levels on image classification and\nsome language understanding tasks, AI struggles with complex reasoning,\nmathematical problems, and demonstrating true \u201ccommon sense.\u201d\n\nProgress on harder tasks is being made using an intriguing approach: AI-\ngenerated data. Systems like SegmentAnything can generate specialized data for\ncomplex tasks like image segmentation and 3D reconstruction. This AI-created\ndata offers a new avenue to improve performance in areas where acquiring\nhuman-labeled datasets is costly or time-consuming.\n\nOne other important development is the rise of human evaluations in\nbenchmarking. As AI systems can now produce compelling text, images, and more,\nmeasuring their output is increasingly difficult for computers alone.\nInitiatives like the Chatbot Arena Leaderboard are a step towards more nuanced\nassessment.\n\nKey Takeaways:\n\n  * Rise of Multimodal AI: Systems like Gemini and GPT-4 demonstrate remarkable abilities to process both text and images, potentially leading to new kinds of AI assistants and creative image generation tools.\n  * AI Performance on Benchmarks: While exceeding humans on established benchmarks like image classification, AI still struggles with complex reasoning, advanced math, and common-sense understanding.\n  * Closed AI Models Outperform Open Ones: Closed models outperformed open ones on 10 LLM benchmarks, by a median advantage of 24.2%. This carries important implications for AI policy debates.\n  * AI-Generated Training Data: Techniques like SegmentAnything show promise in AI generating specialized training data for complex tasks. This is particularly useful for image segmentation and 3D reconstruction where human-labeled data can be expensive or slow to acquire.\n  * Shift Towards Human Evaluation: The increasing sophistication of AI output, especially in text and image generation, necessitates more nuanced evaluation methods. Initiatives like the Chatbot Arena Leaderboard highlight the rise of human evaluators in AI benchmarking.\n\nMachine AI benchmarks are getting replaced by human evaluation. Credit:\nExoswan/LMSYS\n\n## Can we trust AI to be responsible?\n\nThe lack of standardized evaluation for responsible AI is a major obstacle.\nLeading developers like OpenAI, Google, and Anthropic primarily rely on their\nown internal testing, each using different benchmarks. This lack of\nconsistency makes it difficult to systematically analyze potential risks and\ncompare the limitations of different top AI models.\n\nThe threat of political deepfakes is escalating. Deepfakes are synthetic\nmedia, such as videos or images, that have been manipulated or generated using\nAI algorithms to make them appear realistic. Deepfakes can be used to create\nfake videos of people saying or doing things they never actually said or did,\nwhich can be used for malicious purposes like spreading disinformation or\nharming reputations.\n\nAI tools capable of generating highly realistic fake videos and audio of\nindividuals are becoming increasingly accessible and difficult to detect.\nResearch has revealed that even current AI deepfake detection methods often\nperform with variable accuracy, leaving them unreliable. This technology has\nthe potential to erode public trust, undermine elections, and spread harmful\ndisinformation.\n\nBeyond these immediate threats, AI poses other risks. Studies show that AI\nsystems can generate outputs that contain copyrighted material, such as scenes\nfrom popular movies. Whether this constitutes copyright infringement is an\nemerging legal concern that has yet to be fully resolved.\n\nBusinesses are increasingly concerned about responsible AI. A global survey on\nresponsible AI reveals that privacy, data security, and reliability are among\nthe top AI-related concerns for companies. Despite this awareness, most\norganizations have only taken small steps towards mitigating these risks\nglobally.\n\nKey Takeaways:\n\n  * Lack of Standardization in Responsible AI: Leading AI developers like OpenAI, Google, and Anthropic use their own internal benchmarks to assess the safety and bias of their models, creating a lack of consistency that hinders comparisons and risk analysis across the field.\n  * Threat of Political Deepfakes: AI tools can now generate highly realistic fake videos and audio, and existing detection methods often have unreliable accuracy, raising concerns about potential manipulation of elections and spread of disinformation.\n  * Emerging Legal Issues with AI-Generated Content: AI models can inadvertently generate outputs containing copyrighted material, raising questions about potential copyright infringement in creative content.\n  * Business Concerns Regarding AI Risk: A global survey found that data security, privacy, and model reliability are among the top concerns for businesses when it comes to AI. However, despite this awareness, many companies are still in the early stages of implementing mitigation measures.\n\nAI-generated images are becoming increasingly realistic. Credit: 2024 AI\nIndex/Midjourney\n\n## How is AI transforming the economy?\n\nThe growth of AI is already transforming the economy, and that transformation\nis accelerating. Despite a recent slowdown in overall AI investment, spending\non the powerful new field of generative AI skyrocketed in 2023, nearly 8X from\nthe previous year to reach $25.2 billion. Big players like OpenAI, Anthropic,\nHugging Face, and Inflection reported substantial fundraising rounds,\nindicating massive investor confidence in the potential of this technology.\n\nThe economic impact of AI isn\u2019t just about investments. New research shows\ncompanies using AI (including generative AI) are achieving significant\nproductivity gains. In a 2023 McKinsey survey, 42% of companies reported lower\ncosts through AI, while 59% experienced revenue increases.\n\nThe job market is complex. While the number of AI-related job postings\ndeclined in the U.S. in 2023, other studies show that workers using AI\nactually complete tasks faster and produce better work, with the potential to\nbridge skill gaps across industries. Still, caution is warranted: Studies warn\nthat AI without proper oversight can also hurt worker performance.\n\nLastly, 2023 saw a surge in mentions of AI, especially generative AI, in\nearnings calls by Fortune 500 companies. This signifies a growing\nprioritization and implementation of AI across various business sectors,\npotentially leading to even wider adoption in the near future. The true\neconomic transformation driven by AI is still in its early stages.\n\nKey Takeaways:\n\n  * Generative AI Investment Boom: Investment in generative AI surged in 2023, reaching $25.2 billion, an almost eightfold increase from the previous year. This highlights the significant investor confidence in this new field of AI.\n  * Productivity Gains with AI: Businesses that use AI, including generative AI, report substantial productivity gains. A 2023 McKinsey survey found 42% of companies lowered costs through AI adoption, while 59% experienced revenue increases.\n  * AI\u2019s Impact on Jobs: AI has the potential to both boost productivity and displace workers. Studies show AI can help workers complete tasks faster and better, but could also displace a large number of jobs. It\u2019s essential to manage its integration to avoid catastrophic scenarios .\n  * AI Adoption by Major Companies: Mentions of AI, particularly generative AI, skyrocketed in Fortune 500 company earnings calls during 2023. This signifies a growing prioritization and implementation of AI across various business sectors, potentially leading to even wider adoption in the near future.\n\nMost workers are apprehensive about AI\u2019s impact on their jobs. Credit: 2024 AI\nIndex/Ipsos\n\n## Can policy keep pace with innovation?\n\nAs AI becomes more powerful, governments worldwide are taking action. The past\nyear saw a dramatic increase in AI-focused legislation and policy initiatives.\nIn the United States alone, the number of AI-related regulations jumped to 25\nin 2023, from just a single regulation in 2016. Meanwhile, both the European\nUnion and the United States took major steps towards comprehensive AI policy.\nThe EU reached an agreement on the landmark AI Act, and President Biden signed\nan Executive Order on AI \u2013 the most significant U.S. AI policy action that\nyear.\n\nThe legislative focus on AI is truly global. In 2023, mentions of AI in policy\ndebates and proceedings nearly doubled. Lawmakers from 49 countries discussed\nAI, with at least one country across every continent addressing the topic.\nThis highlights the rapidly growing awareness of AI\u2019s impact, and a drive to\nformulate policies across the world.\n\nAn increasing number of U.S. regulatory agencies are turning their attention\nto AI. The number of agencies issuing AI regulations rose to 21 in 2023. This\nbroadening regulatory landscape includes agencies like the Department of\nTransportation and the Department of Energy, signaling concern about AI\u2019s\nimpact across diverse sectors of society.\n\nKey Takeaways:\n\n  * Sharp Rise in AI Regulations: AI regulation is surging, with the U.S. witnessing a jump from having only 1 AI-related regulation in 2016 to a staggering 25 by 2023. This reflects a growing focus on AI governance across the globe.\n  * Major AI Policy Initiatives: The European Union enacted its landmark AI Act in 2023, while the U.S. saw President Biden sign a significant Executive Order on Safe, Secure, and Trustworthy AI. These represent significant steps towards comprehensive policy frameworks for AI.\n  * Global Discussions on AI Policy: Mentions of AI in policy debates and proceedings nearly doubled in 2023, spanning lawmaking bodies from 49 countries. This highlights the international reach and urgency of establishing AI governance.\n  * Expanding US Regulatory Landscape: The number of U.S. regulatory agencies involved in AI oversight jumped to 21 in 2023. This includes agencies like the Department of Transportation and the Department of Energy, reflecting concerns about AI\u2019s impact across diverse sectors.\n\nThe number of AI patents has grown massively. Credit: 2024 AI Index/CSET\n\n## Will the public embrace AI, or fear it?\n\nAs AI becomes more integrated into daily life, the public is paying attention.\nGlobal research shows people are increasingly aware of AI technologies and\ntheir potential impact. However, this growing awareness comes with a mix of\nexcitement and nervousness. A 2023 survey found 52% of Americans are more\nconcerned than excited about AI in their everyday lives, a significant\nincrease from 38% in 2022.\n\nThis cautious sentiment is echoed across several developed nations. Despite\nacknowledging the potential benefits of AI products and services, citizens in\nGermany, the Netherlands, Australia, Belgium, Canada, and the U.S. were among\nthe least positive about AI in 2022. However, there\u2019s been a gradual increase\nin AI acceptance in each of these countries since then.\n\nWhen it comes to AI\u2019s impact on the economy, people remain skeptical. An Ipsos\nsurvey showed that globally, only 37% of people believe AI will improve their\njobs, 34% expect it to boost the economy, and even fewer (32%) believe it will\nenhance the job market.\n\nThere are signs of demographic differences in AI optimism. Younger\ngenerations, especially Gen Z, tend to be more positive about AI\u2019s potential\nto improve entertainment, health, and the economy. Additionally, those with\nhigher incomes and levels of education typically express less anxiety about AI\ntaking over jobs than their lower-income and less-educated counterparts.\n\nKey Takeaways\n\n  * Public Awareness and Cautious Optimism: Global awareness of AI is on the rise, but public sentiment is a mix of interest and concern. A 2023 survey found 52% of Americans are more concerned than excited about AI in daily life, compared to just 10% who are more excited.\n  * Global Cautiousness with Gradual Acceptance: While acknowledging potential benefits of AI products and services, citizens in developed nations like Germany, the Netherlands, and Australia expressed cautiousness in 2022. However, a gradual increase in acceptance has been noted since then.\n  * Skepticism Regarding AI\u2019s Economic Impact: Public skepticism prevails regarding AI\u2019s positive impact on the economy and jobs. An Ipsos survey found only 37% globally believe AI will improve their jobs, and 34% expect it to boost the economy in general.\n  * Demographic Differences in AI Optimism: Younger generations, particularly Gen Z, tend to be more optimistic about AI\u2019s potential for entertainment, healthcare, and economic benefits. Additionally, individuals with higher income and education levels generally express less anxiety about AI job displacement compared to their lower-income or less-educated counterparts.\n\nIndustry and commercial uses of AI are far outpacing academic. Credit: 2024 AI\nIndex/Epoch\n\n## What will the future of AI bring?\n\nArtificial intelligence has progressed from a niche academic field into a\nforce shaping businesses, policies, and our daily lives. This transformation\nis only going to accelerate. The rise of generative AI, capable of creating\neverything from realistic images to persuasive essays, is driving both\ninvestment surges and public apprehension. The lack of universal standards for\nresponsible AI and the growing threat of deepfakes underscore the very real\nrisks this technology poses alongside its potential benefits.\n\nThis is just the beginning. As AI advances, we face even greater societal\nchanges and complex ethical questions. For example, as self-driving cars\nbecome a reality, AI systems will increasingly face life-or-death decisions no\nhuman wants to program. We\u2019ll be forced to grapple with the ethics of machine\ndecision-making. Governments globally are working towards comprehensive AI\npolicies, but whether regulation can keep up with the pace of innovation is an\nopen question. Public opinion, too, will shape the future of AI adoption.\n\nWhat is certain is this: The world of 2025 won\u2019t look the same as the one in\n2024. AI will continue to transform industries, create new ethical dilemmas,\nand quite probably, surprise us in ways we can\u2019t yet imagine. Will it be\nprimarily a force for bettering lives, or will its risks outweigh its promise?\nThe next few years hold many of the answers.\n\nNote: Data and insights for this article are based on Stanford\u2019s 2024 AI Index\nReport.\n\n#### Read Next\n\nTop 10 Generative AI Applications: Engines of Creation\n\nGenerative AI Explained: Giving a Voice to Machines\n\nArtificial Intelligence Explained: Can We Outsource the Brain?\n\n#### Table of Contents\n\n  1. Who\u2019s leading the AI race?\n\n  2. What\u2019s AI now capable of?\n\n  3. Can we trust AI to be responsible?\n\n  4. How is AI transforming the economy?\n\n  5. Can policy keep pace with innovation?\n\n  6. Will the public embrace AI, or fear it?\n\n  7. What will the future of AI bring?\n\nThe information provided in our videos, website, and accompanying material is\nfor informational purposes only. It should not be considered legal or\nfinancial advice. You should consult with an attorney, financial advisor, or\nother professional to determine what may be best for your individual needs.\n\n\u00a9 2024 Exoswan.com \u00b7 All Rights Reserved\n\n", "frontpage": false}
