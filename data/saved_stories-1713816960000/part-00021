{"aid": "40113762", "title": "Multi-lab test of facial feedback hypothesis by the Many Smiles Collaboration", "url": "https://www.nature.com/articles/s41562-022-01458-9", "domain": "nature.com", "votes": 1, "user": "bookofjoe", "posted_at": "2024-04-22 12:37:12", "comments": 0, "source_title": "A multi-lab test of the facial feedback hypothesis by the Many Smiles Collaboration", "source_text": "A multi-lab test of the facial feedback hypothesis by the Many Smiles Collaboration | Nature Human Behaviour\n\nSkip to main content\n\nThank you for visiting nature.com. You are using a browser version with\nlimited support for CSS. To obtain the best experience, we recommend you use a\nmore up to date browser (or turn off compatibility mode in Internet Explorer).\nIn the meantime, to ensure continued support, we are displaying the site\nwithout styles and JavaScript.\n\nAdvertisement\n\n  * View all journals\n  * Search\n\n## Search\n\nAdvanced search\n\n### Quick links\n\n    * Explore articles by subject\n    * Find a job\n    * Guide to authors\n    * Editorial policies\n\n  * Log in\n\n  * Explore content\n  * About the journal\n  * Publish with us\n\n  * Sign up for alerts\n  * RSS feed\n\nA multi-lab test of the facial feedback hypothesis by the Many Smiles\nCollaboration\n\nDownload PDF\n\nDownload PDF\n\n  * Registered Report\n  * Published: 20 October 2022\n\n# A multi-lab test of the facial feedback hypothesis by the Many Smiles\nCollaboration\n\n  * Nicholas A. Coles ORCID: orcid.org/0000-0001-8583-5610^1,\n  * David S. March ORCID: orcid.org/0000-0002-9874-7967^2,\n  * Fernando Marmolejo-Ramos ORCID: orcid.org/0000-0003-4680-1287^3,\n  * Jeff T. Larsen^4,\n  * Nwadiogo C. Arinze ORCID: orcid.org/0000-0002-2531-6250^5,\n  * Izuchukwu L. G. Ndukaihe ORCID: orcid.org/0000-0003-3714-6946^5,\n  * Megan L. Willis ORCID: orcid.org/0000-0002-2310-0018^6,\n  * Francesco Foroni ORCID: orcid.org/0000-0002-4702-3678^6,\n  * Niv Reggev ORCID: orcid.org/0000-0002-5734-7457^7,8,\n  * Aviv Mokady ORCID: orcid.org/0000-0003-4475-0332^7,\n  * Patrick S. Forscher ORCID: orcid.org/0000-0002-7763-3565^9,\n  * John F. Hunter ORCID: orcid.org/0000-0001-9119-2674^10,\n  * Gwena\u00ebl Kaminski ORCID: orcid.org/0000-0001-5300-5655^11,\n  * Elif Y\u00fcvr\u00fck ORCID: orcid.org/0000-0001-7150-4060^12,\n  * Aycan Kapucu^12,\n  * Tam\u00e1s Nagy ORCID: orcid.org/0000-0001-5244-0356^13,\n  * Nandor Hajdu^13,\n  * Julian Tejada ORCID: orcid.org/0000-0003-0275-3578^14,\n  * Raquel M. K. Freitag ORCID: orcid.org/0000-0002-4972-4320^15,\n  * Danilo Zambrano ORCID: orcid.org/0000-0003-1527-6088^16,\n  * Bidisha Som ORCID: orcid.org/0000-0003-1942-1828^17,\n  * Balazs Aczel ORCID: orcid.org/0000-0001-9364-4988^13,\n  * Krystian Barzykowski ORCID: orcid.org/0000-0003-4016-3966^18,\n  * Sylwia Adamus ORCID: orcid.org/0000-0002-7399-8735^18,\n  * Katarzyna Filip ORCID: orcid.org/0000-0002-6181-0731^18,\n  * Yuki Yamada ORCID: orcid.org/0000-0003-1431-568X^19,\n  * Ayumi Ikeda ORCID: orcid.org/0000-0002-1688-2875^20,\n  * Daniel L. Eaves ORCID: orcid.org/0000-0003-2436-7694^21,22,\n  * Carmel A. Levitan ORCID: orcid.org/0000-0001-5403-444X^23,\n  * Sydney Leiweke^23,\n  * Michal Parzuchowski ORCID: orcid.org/0000-0002-8960-0277^24,\n  * Natalie Butcher ORCID: orcid.org/0000-0002-0154-0530^25,\n  * Gerit Pfuhl ORCID: orcid.org/0000-0002-3271-6447^26,\n  * Dana M. Basnight-Brown ORCID: orcid.org/0000-0002-7200-6976^27,\n  * Jos\u00e9 A. Hinojosa ORCID: orcid.org/0000-0002-7482-9503^28,29,\n  * Pedro R. Montoro ORCID: orcid.org/0000-0002-5665-8587^30,\n  * Lady G. Javela D ORCID: orcid.org/0000-0002-9202-4354^31,\n  * Kevin Vezirian^32,\n  * Hans IJzerman ORCID: orcid.org/0000-0002-0990-2276^32,33,\n  * Natalia Trujillo ORCID: orcid.org/0000-0001-7507-1856^34,\n  * Sarah D. Pressman^35,\n  * Pascal M. Gygax ORCID: orcid.org/0000-0003-4151-8255^36,\n  * Asil A. \u00d6zdo\u011fru ORCID: orcid.org/0000-0002-4273-9394^37,\n  * Susana Ruiz-Fernandez ORCID: orcid.org/0000-0002-1709-1506^38,39,\n  * Phoebe C. Ellsworth ORCID: orcid.org/0000-0002-8973-4232^40,\n  * Lowell Gaertner^4,\n  * Fritz Strack^41,\n  * Marco Marozzi ORCID: orcid.org/0000-0001-9538-0955^42 &\n  * ...\n  * Marco Tullio Liuzza ORCID: orcid.org/0000-0001-6708-1253^43\n\nNature Human Behaviour volume 6, pages 1731\u20131742 (2022)Cite this article\n\n  * 37k Accesses\n\n  * 29 Citations\n\n  * 1570 Altmetric\n\n  * Metrics details\n\n## Abstract\n\nFollowing theories of emotional embodiment, the facial feedback hypothesis\nsuggests that individuals\u2019 subjective experiences of emotion are influenced by\ntheir facial expressions. However, evidence for this hypothesis has been\nmixed. We thus formed a global adversarial collaboration and carried out a\npreregistered, multicentre study designed to specify and test the conditions\nthat should most reliably produce facial feedback effects. Data from n = 3,878\nparticipants spanning 19 countries indicated that a facial mimicry and\nvoluntary facial action task could both amplify and initiate feelings of\nhappiness. However, evidence of facial feedback effects was less conclusive\nwhen facial feedback was manipulated unobtrusively via a pen-in-mouth task.\n\n### Similar content being viewed by others\n\n### Face masks influence emotion judgments of facial expressions: a\ndrift\u2013diffusion model\n\nArticle Open access 31 May 2023\n\nW. Craig Williams, Eisha Haque, ... Vinod Venkatraman\n\n### Professional actors demonstrate variability, not stereotypical\nexpressions, when portraying emotional states in photographs\n\nArticle Open access 19 August 2021\n\nTuan Le Mau, Katie Hoemann, ... Lisa Feldman Barrett\n\n### Perception of Discrete Emotions in Others: Evidence for Distinct Facial\nMimicry Patterns\n\nArticle Open access 13 March 2020\n\nTanja S. H. Wingenbach, Mark Brosnan, ... Chris Ashwin\n\n## Main\n\nThe facial feedback hypothesis suggests that individuals\u2019 emotional\nexperiences are influenced by their facial expressions. For example, smiling\nshould typically make individuals feel happier, and frowning should make them\nfeel sadder. Researchers suggest that these effects emerge because facial\nexpressions provide sensorimotor feedback that contributes to the sensation of\nan emotion^1,2, serves as a cue that individuals use to make sense of ongoing\nemotional feelings^3,4, influences other emotion-related bodily responses^5,6\nand/or influences the processing of emotional stimuli^7,8. This facial\nfeedback hypothesis is notable because it supports broader theories that\ncontend emotional experience is influenced by feedback from the peripheral\nnervous system^9,10,11, as opposed to experience and bodily sensations being\nindependent components of an emotion response^12,13,14. Furthermore, this\nhypothesis supports claims that facial feedback interventions\u2014for example,\nsmiling more or frowning less\u2014can help manage distress^15,16, improve well-\nbeing^17,18 and reduce\ndepression^19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39.\n\nRecently, a collaboration involving 17 independent teams consistently failed\nto replicate a seminal demonstration of facial feedback effects^40. In the\noriginal study, the participants viewed humorous cartoons while holding a pen\nin their mouth in a manner that either elicited smiling (pen held in teeth) or\nprevented smiling (pen held by lips)^41. Consistent with the facial feedback\nhypothesis, smiling participants reported feeling more amused by the cartoons.\nThis finding was influential because previous studies often explicitly\ninstructed participants to pose a facial expression, raising concerns about\ndemand characteristics^42,43,44. Furthermore, theorists disagreed about\nwhether these effects could occur outside of awareness^45,46,47. Because the\nparticipants in this pen-in-mouth study were presumably unaware that they were\nsmiling, the authors concluded that facial feedback effects were not driven by\ndemand characteristics and could occur outside of awareness.\n\nWhat implications does the failure to replicate have for the facial feedback\nhypothesis? One possibility is that the facial feedback hypothesis is false.\nHowever, this conclusion is unwarranted because this direct replication was\nlimited to a specific test of the facial feedback hypothesis. Indeed, the\nreplicators stated that their findings \u201cdo not invalidate the more general\nfacial feedback hypothesis\u201d^40. Similarly, while arguing that the pen-in-mouth\neffect is unreliable, some researchers conceded that \u201cother paradigms may\nproduce replicable results\u201d^48.\n\nA second possibility is that both the facial feedback hypothesis and the\noriginal pen-in-mouth effect are true. If this is the case, researchers must\ndetermine why others were unable to replicate the pen-in-mouth effect. One\nsuggestion is that the replicators did not perform a true direct replication\nbecause they deviated from the original study by overtly recording the\nparticipants (per the advice of an expert reviewer)^49. According to this\nexplanation, awareness of video recording may induce a self-focus that\ninterferes with participants\u2019 internal experiences and emotional\nbehaviour^49,50.\n\nA third possibility is that the facial feedback hypothesis is true, but not in\nthe context examined in the original pen-in-mouth study. Perhaps facial\nfeedback effects occur only when participants are aware that they are posing a\nfacial expression^45,46, a mechanism that the pen-in-mouth task was designed\nto eliminate. Alternatively, perhaps the pen-in-mouth task is not a reliable\nmanipulation of facial feedback. Some theorists predict that facial feedback\neffects will emerge only when facial movement patterns resemble a prototypical\nemotional facial expression^5,51,52,53,54,55, and previous research indicates\nthat the pen-in-mouth task does not reliably produce prototypical expressions\nof happiness^56. Last, perhaps facial feedback influences only certain types\nof emotional experiences. Some researchers distinguish between self-focused\nand world-focused emotional experiences, and facial feedback theories have\ntraditionally emphasized self-focused emotional experience^57,58. However, in\nthe original pen-in-mouth study, the participants were asked how amused a\nseries of cartoons made them feel, which may have induced a world-focused\nemotional experience.\n\nAmid the uncertainty created by the failure to replicate, a meta-analysis was\nperformed on 286 effect sizes from 137 studies testing the effects of various\nfacial feedback manipulations on emotional experience^59. The results\nindicated that facial feedback has a small but highly varied effect on\nemotional experience. Notably, this effect could not be explained by\npublication bias. Published and unpublished studies yielded effects of similar\nmagnitude, analyses failed to uncover significant evidence of publication bias\nand bias-corrected overall effect size estimates were significant. However,\nthis meta-analysis did not explain why facial feedback effects were not\nobserved in the pen-in-mouth replication study. Inconsistent with preliminary\nevidence that video-recording awareness interferes with facial feedback\neffects^50, the meta-analysis revealed significant facial feedback effects\nregardless of whether studies used overt video recording^59.\n\nAlthough the meta-analysis suggests that the facial feedback hypothesis is\nvalid, there are at least three limitations that could undermine this\nconclusion. First, since publication bias analyses often have low\npower^60,61,62, it is possible that seemingly robust facial feedback effects\nare driven by studies with undetected questionable research practices. Second,\nit is possible that the overall effect size estimates in this literature are\ndriven by low-quality studies^63. Third, even relatively similar subsets of\nfacial feedback studies varied beyond what would be expected from sampling\nerror alone, meaning that moderator analyses had lower power and potentially\ncontained unidentified confounds. Consequently, the meta-analysis could not\nreliably identify moderators that may help explain why some researchers fail\nto observe facial feedback effects.\n\nBoth the failure to replicate the pen-in-mouth study and the meta-analysis\nhave a unique set of limitations that make it difficult to resolve the debate\nregarding whether the facial feedback hypothesis is valid. We therefore came\ntogether to form the Many Smiles Collaboration. We are an international group\nof researchers\u2014some advocates of the facial feedback hypothesis, some critics\nand some without strong beliefs\u2014who collaborated to (1) specify our beliefs\nregarding when facial feedback effects, if real, should most reliably emerge;\n(2) determine the best way(s) to test those beliefs; and (3) use this\ninformation to design and execute an international multi-lab experiment.\n\nWe agreed that one of the simplest necessary conditions for facial feedback\neffects to emerge is that participants pose an emotional facial expression and\nsubsequently self-report the degree to which they are experiencing the\nassociated emotional state. Therefore, our main research question was whether\nparticipants would report feeling happier when posing happy versus neutral\nexpressions. On the basis of outstanding theoretical disagreements in the\nfacial feedback literature, we also questioned (1) whether happy facial poses\nonly influence feelings of happiness if they resemble a natural expression of\nhappiness, (2) whether facial poses can initiate emotional experience in\notherwise neutral scenarios or only amplify ongoing emotional experiences, and\n(3) whether facial feedback effects are eliminated when controlling for\nawareness of the experimental hypothesis. These disagreements ultimately\ninformed the final experimental design: a 2 (Pose: happy or neutral) \u00d7 3\n(Facial Movement Task: facial mimicry, voluntary facial action or pen-in-\nmouth) \u00d7 2 (Stimuli Presence: present or absent) design, with Pose manipulated\nwithin participants and Facial Movement Task and Stimuli Presence manipulated\nbetween participants (Supplementary Fig. 1).\n\nTo provide an easy-to-follow task that would produce more prototypical facial\nexpressions, we used a facial mimicry paradigm, wherein the participants were\nasked to mimic images of actors displaying prototypical expressions of\nhappiness^64. To produce less prototypical facial expressions, some\nparticipants completed the voluntary facial action task^65, wherein they were\nasked to move some\u2014but not all\u2014facial muscles associated with prototypical\nexpressions of happiness^56. We also added the pen-in-mouth task after Stage 1\nreviewer feedback, wherein the participants held a pen in their mouth in a\nmanner that either elicited smiling (pen held in teeth) or prevented smiling\n(pen held by lips)^41. While engaging in the facial feedback tasks, half of\nthe participants viewed a series of positive images^57,58.\n\nWe hypothesized that participants would report experiencing more happiness\nwhen posing happy versus neutral facial expressions. Furthermore, we\nhypothesized that the magnitude of this effect would be similar across tasks\nthat produce less (the voluntary facial action and pen-in-mouth tasks) versus\nmore (the mimicry task) prototypical expressions of happiness. We also\nexpected that facial feedback effects would be smaller in the absence than in\nthe presence of positive stimuli. Last, we expected to observe facial feedback\neffects even when limiting our analyses to participants who were completely\nunaware of our hypothesis. Two pilot studies (n = 206; Supplementary\nInformation) confirmed these predictions. A third pilot study conducted after\ninitial Stage 1 acceptance (n = 119; Supplementary Information) provided\npreliminary evidence in favour of some\u2014but not all\u2014of our predictions. These\npilot results led to minor refinements to the methodology but did not change\nour final set of predictions. Our research questions and hypotheses are\nsummarized in Table 1.\n\nTable 1 Research questions and associated hypotheses\n\nFull size table\n\n## Results\n\nWe conducted all analyses using R (v.4.1.2)^66. For the frequentist analyses,\nwe fit mixed-effect models using the lme4 package^67. Some of these models\ncontained random slopes and thus have smaller degrees of freedom. For tests of\nmain effects, simple effects and interactions, we used the lmerTest package to\nderive analysis-of-variance-like F values with Satterthwaite degrees of\nfreedom^68. When we observed higher-order interactions, we used the emmeans\npackage to decompose them using simple effect tests and pairwise contrasts^69.\nWe used model-derived mean difference estimates as our effect size of\ninterest. However, we also report semi-standardized mean difference estimates,\nwherein the model-derived mean difference is divided by the total range of the\nmeasured dependent variable.\n\nFor the Bayesian re-analysis of the hypotheses in Table 1, we used the\nBayesFactor package to fit models using medium Cauchy priors (r scale, 1/2) on\nthe alternative hypotheses and the default Markov chain Monte Carlo\nsettings^70. We also performed sensitivity analyses with wide (r scale, \u221a2/2)\nand ultrawide (r scale, 1) priors, and we thus report a range of Bayes factors\n(BFs). For tests of main effects, interactions and simple effects, we computed\nBFs by comparing models containing versus excluding the terms representing the\ntested effect.\n\n### Participants\n\nWe made two minor deviations from the preregistered sampling plan. First, due\nto constraints created by COVID-19, no research group collected data in\nperson. We were thus unable to test whether our pattern of results differed by\nin-person versus online data collection. Second, we had 80 fewer participants\nthan we initially planned for our primary analyses.\n\nDepending on the research site, the participants completed the study on a\ncompletely volunteer basis, for partial course credit, for extra credit, for\nentrance into a lottery (for example, for a gift box), for a prize (for\nexample, a pen) or for money (US$0.75\u2013US$5). We stopped data collection when\nat least 22 research groups had each collected at least 105 participants,\ntotalling 3,878 participants from 26 groups (Fig. 1; mean age (M_age), 26.6;\ns.d._age, 10.6; 71% women, 28% men, 1% other). For the primary analyses, we\nexcluded participants if they failed an attention check (17% fail rate),\ncompleted the study on a mobile device (3%), reported deviating from the pose\ninstructions (1%), reported that their posed expression did not match an image\nof an actor completing the task correctly (3%), indicated that they were very\ndistracted (3%) or exhibited any awareness of the study hypothesis (46%). (For\nthe country-specific exclusion criteria rates, see the Supplementary\nInformation.) An unexpectedly large number of participants were excluded for\nexhibiting awareness of the study hypothesis\u2014but this may reflect an unusually\nstrict classification scheme (that is, that two coders must judge the\nparticipant as being completely unaware). This left 1,504 participants for the\nprimary analyses.\n\nFig. 1: Country-specific sample sizes.\n\nData were collected from 3,878 participants in 19 countries. Darker shades of\nred denote larger country-specific sample sizes.\n\nSource data\n\nFull size image\n\n### Primary analyses\n\nWe hypothesized that participants would report higher levels of happiness (1)\nin the presence versus absence of emotional stimuli and (2) after posing happy\nversus neutral facial expressions. We also predicted that the effect of posed\nexpressions on happiness would be larger in the presence than in the absence\nof positive stimuli. Following the study design (Supplementary Fig. 1), we\nmodelled happiness reports with (1) Pose (happy or neutral), Facial Movement\nTask (facial mimicry, voluntary facial action or pen-in-mouth) and Stimuli\nPresence (present or absent) entered as effect-coded factors; (2) all higher-\norder interactions; (3) random intercepts for participants and research\ngroups; and (4) random slopes for research groups.\n\nParticipants reported higher levels of happiness in the presence than in the\nabsence of positive images (M_diff = 0.30; 95% confidence interval (CI),\n(0.12, 0.48); 5% scale range; F(1, 22.65) = 10.67; P = 0.003). However, the\nBayesian analyses were inconclusive (BF_10 = 0.71\u20131.25). Participants also\nreported more happiness after posing happy versus neutral expressions (M_diff\n= 0.31; 95% CI, (0.21, 0.40); 5.17% scale range; F(1, 24.34) = 39.86; P <\n0.001; BF_10 = 61.06\u2013102.63. Contrary to our hypothesis, the Pose effect was\nnot significantly larger in the presence than in the absence of positive\nstimuli (F(1, 29.50) = 1.33, P = 0.26, BF_10 = 0.06\u20130.13).\n\nUnexpectedly, there was an interaction between Pose and Facial Movement Task\n(F(2, 32.95) = 17.11, P < 0.001, BF_10 = 34.13\u2013100.14, Fig. 2). The effect of\nPose on self-reported happiness was the largest in the facial mimicry task\n(M_diff = 0.49; 95% CI, (0.36, 0.61); 8.17% scale range; F(1, 28.62) = 57.55;\nP < 0.001; BF_10 > 100) and the voluntary facial action task (M_diff = 0.40;\n95% CI, (0.23, 0.56); 6.67% scale range; F(1, 25.48) = 22.93; P < 0.001; BF_10\n= 25.20\u201339.26). There was moderate support for the null hypothesis in the pen-\nin-mouth condition (M_diff = 0.04; 95% CI, (\u22120.07, 0.15); 0.67% scale range;\nF(1, 24.74) = 0.57; P = 0.46; BF_10 = 0.11\u20130.17.\n\nFig. 2: Effects of facial expression poses and filler tasks on self-reported\nhappiness in each study condition.\n\nSelf-reported happiness (1 = \u2018not at all\u2019 to 7 = \u2018an extreme amount\u2019) after\nthe participants posed happy facial expressions, posed neutral facial\nexpressions or completed filler tasks. The panel columns indicate whether the\nparticipants completed the facial mimicry, voluntary facial action or pen-in-\nmouth task. The panel rows indicate whether positive images were absent or\npresent during the facial pose tasks. The grey points represent jittered\nparticipant observations. The blue error bars represent mean \u00b1 1 standard\nerror. Condition-specific sample sizes, means and standard deviations are\nreported.\n\nSource data\n\nFull size image\n\n### Secondary analyses\n\nOur secondary analyses were designed to further probe the nature of facial\nfeedback effects.\n\n#### Potential aversion to the neutral expression posing task\n\nThe primary analyses suggest that posing happy versus natural expressions can\nincrease feelings of happiness. However, an alternative explanation is that\nthese effects are driven by hypothesis-irrelevant decreases in happiness after\nneutral poses (for example, as a result of boredom)^71. To test this, we refit\nthe primary analysis model with an effect-coded Pose factor that compared\nhappy pose with filler trials that the participants completed. We focused on\nparticipants who were not exposed to positive images because these images were\nshown only during the facial posing trials (thus confounding their comparison\nwith the filler trials). Nevertheless, similar results were observed in\nanalyses that included participants who viewed positive images (Fig. 2).\n\nLike the primary analyses, there was an interaction between Pose and Facial\nMovement Task (F(2, 18.02) = 20.47, P < 0.001). Participants reported higher\nlevels of happiness after posing happy expressions versus completing filler\ntasks in both the facial mimicry task (M_diff = 0.48; 95% CI, (0.29, 0.67); 8%\nscale range; t(22.4) = 5.23; P < 0.001) and the voluntary facial action task\n(M_diff = 0.20; 95% CI, (0.05, 0.36); 3.33% scale range; t(19.6) = 2.69; P =\n0.01. In the pen-in-mouth task, participants reported less happiness after\ncompleting the happy versus filler task (M_diff = \u22120.15; 95% CI, (\u22120.28,\n0.02); 2.5% scale range; t(31.5) = 2.39; P = 0.02).\n\n#### Moderating role of pose quality\n\nWe next examined the moderating role of three indicators of the quality of\nposed expressions: the participants\u2019 reports of the extent to which they\nfollowed pose instructions (compliance ratings), felt that their self-\nmonitored expression matched an image of an actor successfully completing the\ntask (similarity ratings) and felt that their posed expression resembled a\ngenuine expression of happiness (genuineness ratings). For each quality\nindicator, we refit the primary analysis model with (1) the indicator entered\nmean-centred and (2) a term denoting its interaction with Pose. For each\nquality indicator, there was an interaction with Pose (Fig. 3). The effect of\nfacial poses on happiness was larger among participants with higher compliance\n(\u03b2 = 0.08; 95% CI, (0.05, 0.12); t(1,482.63) = 4.33; P < 0.001), similarity (\u03b2\n= 0.03; 95% CI, (0.01, 0.06); t(1,358.62) = 3.37; P < 0.001) and genuineness\nratings (\u03b2 = 0.08; 95% CI, (0.06, 0.09); t(1,420.95) = 10.57; P < 0.001).\n\nFig. 3: Potential moderators of facial feedback effects.\n\nThe change in happiness (y axis) when the participants posed happy versus\nneutral expressions was moderated by compliance, similarity, genuineness and\nhypothesis awareness ratings, but not body awareness ratings (x axes). The\ngrey points represent jittered participant observations. The blue lines\nrepresent the estimated linear relationships.\n\nSource data\n\nFull size image\n\n#### Pose quality in different facial movement tasks\n\nTo examine whether pose quality varied between facial movement tasks, we used\ndata from all 3,878 participants and modelled each quality indicator with (1)\nFacial Movement Task and Stimuli Presence entered as effect-coded factors, (2)\nrandom intercepts for research groups and (3) random slopes for research\ngroups.\n\nCompliance ratings varied by Facial Movement Task (F(2, 18.18) = 10.50, P <\n0.001), but not Stimuli Presence (M_diff = 0.03; 95% CI, (\u22120.05, 0.11); 0.5%\nscale range; F(1, 37.63) = 0.60; P = 0.44). Compliance ratings were high\nacross all tasks, but slightly lower in the facial mimicry task (M = 6.45,\ns.d. = 1.07) than in the voluntary facial action (M = 6.57; s.d. = 0.93;\nM_diff = \u22120.15; 95% CI, (\u22120.28, \u22120.02); 2.5% scale range; t(23.5) = \u22122.47; P =\n0.02) and pen-in-mouth tasks (M = 6.68; s.d. = 1.01; M_diff = \u22120.25; 95% CI,\n(\u22120.37, \u22120.14); 4.17% scale range; t(22.8) = \u22124.49; P < 0.001). Compliance\nratings were also slightly higher in the pen-in-mouth task than in the\nvoluntary facial action task (M_diff = 0.10; 95% CI, (\u22120.01, 0.21); 1.67%\nscale range; t(21.9) = 1.96; P = 0.06).\n\nLikewise, similarity ratings varied by Facial Movement Task (F(2, 40.12) =\n7.35, P = 0.002), but not Stimuli Presence (M_diff = \u22120.12; 95% CI, (\u22120.25,\n0.02); 2% scale range; F(1, 19.18) = 3.15; P = 0.09). Similarity ratings were\nhigh across all tasks but higher in the facial mimicry task (M = 5.30, s.d. =\n1.36) than in the voluntary facial action (M = 5.09; s.d. = 1.73; M_diff =\n0.23; 95% CI, (0.03, 0.43); 3.83% scale range; t(22.7) = 2.43; P = 0.02) and\npen-in-mouth tasks (M = 5.07; s.d. = 1.61; M_diff = 0.24; 95% CI, (0.11,\n0.36); 4% scale range; t(194) = 3.63; P < 0.001).\n\nGenuineness ratings strongly varied by Facial Movement Task (F(2, 13.69) =\n82.56, P < 0.001). Genuineness ratings were substantially lower in the pen-in-\nmouth task (M = 2.98, s.d. = 1.89) than in the facial mimicry (M = 4.15; s.d.\n= 1.92; M_diff = \u22121.15; 95% CI, (\u22121.34, \u22120.97); 19.17% scale range; t(23.85) =\n12.85; P < 0.001) and voluntary facial action tasks (M = 3.91; s.d. = 2.00;\nM_diff = \u22120.89; 95% CI, (\u22121.12, \u22120.66); 14.83% scale range; t(24.92) = 8.00; P\n< 0.001). Genuineness ratings were also lower in the voluntary facial action\ntask than in the facial mimicry task (M_diff = \u22120.26; 95% CI, (\u22120.48, \u22120.05);\n4.33% scale range; t(6.67) = \u22122.90; P = 0.02). Participants also reported\nhigher genuineness ratings in the presence (M = 3.78, s.d. = 2.00) than in the\nabsence (M = 3.57, s.d. = 2.00) of positive images (M_diff = 0.23; 95% CI,\n(0.11, 0.34); 3.83% scale range; F(1, 1,538.52) = 13.66; P < 0.001).\n\n#### Awareness of the study purpose\n\nTo examine whether some facial feedback tasks lead participants to be more\naware of the study purpose, we used data from all 3,878 participants and\nmodelled coder ratings of the extent to which they were aware with (1) Facial\nMovement Task and Stimuli Presence entered as effect-coded factors, (2) random\nintercepts for research groups and (3) random slopes for research groups.\nAwareness scores varied by Facial Movement Task (F(2, 19.70) = 13.54, P <\n0.001), with participants being less aware in the pen-in-mouth task (M = 1.75,\ns.d. = 1.41) than in the voluntary facial action task (M = 2.28; s.d. = 1.78;\nM_diff = \u22120.48; 95% CI, (\u22120.67, \u22120.29); 8.02% scale range; t(24) = \u22125.19; P <\n0.001) and the facial mimicry task (M = 2.05; s.d. = 1.52; M_diff = \u22120.27; 95%\nCI, (\u22120.43, \u22120.11); 4.48% scale range; t(15.4) = \u22123.66; P < 0.05).\nParticipants were also less aware in the facial mimicry task than in the\nvoluntary facial action task (M_diff = \u22120.21; 95% CI, (\u22120.36, \u22120.07); 3.53%\nscale range; t(39.4) = \u22122.97; P = 0.005).\n\nTo test whether facial feedback effects are amplified by awareness of the\nstudy purpose, we modelled happiness reports with (1) Pose, Facial Movement\nTask and Stimuli Presence entered as effect-coded factors; (2) awareness\nscores entered mean-centred; (3) a higher-order interaction term for Pose and\nawareness scores; (4) random intercepts for participants and research groups;\nand (5) research group random slopes for all terms other than awareness\nscores. The results indicated that the Pose effect was larger among\nparticipants who were more aware of the study hypothesis (\u03b2 = 0.08; 95% CI,\n(0.06, 0.10); t(22.74) = 7.55; P < 0.001) (Fig. 3).\n\n#### Body awareness\n\nTo examine the moderating role of body awareness, we re-ran our primary\nanalysis model with (1) participants\u2019 responses on a body awareness measure\nentered mean-centred and (2) a higher-order interaction term for Pose and\nawareness. No moderating role of body awareness was detected (\u03b2 = 0.00; 95%\nCI, (\u22120.03, 0.03); t(9.87) = 0.02; P = 0.99) (Fig. 3).\n\n#### Between-condition differences in other inclusion criteria\n\nNext, we examined whether there were between-condition differences in the\nextent to which participants used an incorrect device to complete the study\n(for example, a phone) or failed attention checks. We separately modelled the\nprobability that participants failed to meet each inclusion criterion using\nlogistic mixed-effect regression with (1) Facial Movement Task and Stimuli\nPresence entered as effect-coded factors, (2) random intercepts for research\ngroups and (3) random slopes for research groups.\n\nThe probability that participants used the incorrect device did not vary by\nFacial Movement Task (96%, 97% and 97% pass rates in the facial mimicry,\nvoluntary facial action and pen-in-mouth tasks; \u03c7^2(2) = 3.06; P = 0.22) or\nStimuli Presence (97% pass rate in the absence and presence of positive\nstimuli; \u03c7^2(1) = 0.11; P = 0.74). Likewise, the probability that participants\nfailed attention checks did not vary by Facial Movement Task (84%, 82% and 83%\npass rates in the facial mimicry, voluntary facial action and pen-in-mouth\ntasks; \u03c7^2(2) = 1.28; P = 0.53) or Stimuli Presence (84% and 82% pass rates in\nthe absence and presence of positive stimuli; \u03c7^2(1) = 2.54; P = 0.11).\n\nWe also tested for between-condition differences in coder ratings of the\nextent to which participants were distracted using linear mixed-effect\nregression with (1) Facial Movement Task and Stimuli Presence entered as\neffect-coded factors, (2) random intercepts for research groups and (3) random\nslopes for research groups. Distraction scores did not significantly vary\nbetween the facial mimicry (M = 2.01, s.d. = 1.17), voluntary facial action (M\n= 1.92, s.d. = 1.14) and pen-in-mouth (M = 1.92, s.d. = 1.14) tasks (F(2,\n18.57) = 2.45, P = 0.11). Distraction scores also did not vary in the absence\n(M = 1.94, s.d. = 1.15) versus presence (M = 1.96, s.d. = 1.16) of positive\nstimuli (F(1, 900.52) = 0.02, P = 0.90).\n\n#### Anger and anxiety\n\nWe next examined whether posed happy expressions decreased self-reported\nnegative emotions and whether some facial movement tasks were more frustrating\nand anxiety-provoking than others. To do so, we separately re-ran our primary\nanalyses with anxiety and anger reports as the dependent variables.\n\nHappy versus neutral facial expression poses did not significantly decrease\nfeelings of anger (M_diff = \u22120.02; 95% CI, (\u22120.07, 0.03); 0.33% scale range;\nF(1, 20.71) = 0.85; P = 0.37) or anxiety (M_diff = \u22120.01; 95% CI, (\u22120.06,\n0.04); 0.17% scale range; F(1, 25.36) = 0.32; P = 0.57). However, feelings of\nanger (F(2, 27.46) = 4.30, P = 0.02) and anxiety (F(2, 58.20) = 5.18, P =\n0.008) did differ by Facial Movement Task. Participants reported higher levels\nof anger in the pen-in-mouth task than in the facial mimicry task (M_diff =\n0.14; 95% CI, (0.03, 0.24); 2.33% scale range; t(24.2) = 2.64; P = 0.01) and\nthe voluntary facial action task (M_diff = 0.12; 95% CI, (0.02, 0.21); 2%\nscale range; t(31.6) = 2.40; P = 0.02). Similarly, participants reported more\nanxiety in the pen-in-mouth task than in the facial mimicry task (M_diff =\n0.13; 95% CI, (0.02, 0.24); 2.17% scale range; t(51.6) = 2.35; P = 0.02) and\nthe voluntary facial action task (M_diff = 0.17; 95% CI, (0.06, 0.28); 2.83%\nscale range; t(79) = 3.00; P = 0.004). Nonetheless, follow-up exploratory\nanalyses did not indicate that these increases in anxiety obfuscated facial\nfeedback effects (Supplementary Information).\n\n### Exploratory analyses\n\nFor all analyses, we preregistered plans to model random slopes for research\ngroups. However, random slopes often led to singular fit and convergence\nwarnings, which is indicative of overfit models with potentially unreliable\nestimates^72. Sensitivity analyses without (versus with) random slopes\ngenerally yielded identical inferences, except for the simple effect of Pose\nin the pen-in-mouth task. After we removed random slopes, the two-sided test\nof the effect of Pose was not significant (M_diff = 0.08; 95% CI, (\u22120.01,\n0.16); 1.33% scale range; F(1, 1,498) = 2.78; P = 0.095), but an exploratory\none-sided test was (one-sided P < 0.05). However, the Bayesian analyses were\ninconclusive (BF_10 = 0.46\u20130.96). Nonetheless, when we relaxed our inclusion\ncriteria in a subsequent sensitivity analysis, we found extremely strong\nevidence of a Pose effect in the pen-in-mouth task (M_diff = 0.14; 95% CI,\n(0.07, 0.21); 2.33% scale range; F(1, 3,872) = 16.37; P < 0.001; BF_10 > 100).\n\n## Discussion\n\nOur project brought together a large adversarial team to design and conduct an\nexperiment that best tested and clarified our disagreements about the facial\nfeedback hypothesis. We designed our experiment not to provide close\nreplications of any existing study but rather to provide informative tests of\nthe facial feedback hypothesis. For example, our pen-in-mouth task was\ninspired by the original pen-in-mouth study that some, but not all^49,\nresearchers have had difficulty replicating^40. Nevertheless, our methodology\ndiffered in many ways from the original pen-in-mouth study. For example, we\nran our study online (versus in person), focused on feelings of happiness\n(versus amusement), used a different cover story, had the participants pose\nexpressions for a relatively short duration (five seconds) and did not\ninstruct the participants to maintain the poses while they completed emotion\nratings.\n\nOur primary analyses replicated the pilot studies that informed the design of\nthis study, albeit with more stringent inclusion criteria and a much larger\nand more culturally diverse sample (see Supplementary Fig. 2 for the country-\nspecific effect size estimates). Contrary to theories that characterize\nperipheral nervous system activity and emotional experience as independent\ncomponents of an emotion response^12,13,14, our results suggest that facial\nfeedback can impact feelings of happiness when using the facial mimicry and\nvoluntary facial action tasks. Furthermore, these effects emerge in both the\npresence and absence of emotional stimuli\u2014although, contrary to our\nprediction, the effect was not larger in the presence of emotional stimuli.\nConsistent with a previous meta-analysis, these results suggest that facial\nfeedback can not only amplify ongoing feelings of happiness but also initiate\nfeelings of happiness in otherwise neutral contexts^59.\n\nSecondary analyses revealed that the observed facial feedback effects could\nnot be explained by participants\u2019 aversion to the relatively inactive neutral\npose task or demand characteristics. Even compared with relatively active\nfiller trials, participants reported the most happiness after posing happy\nexpressions. Furthermore, although facial feedback effects were larger among\nparticipants who were rated as more aware of the purpose of the study, we\nobserved facial feedback effects among participants who did not exhibit such\nawareness. These results are consistent with recent experimental work\ndemonstrating that demand characteristics can moderate, but do not fully\naccount for, facial feedback effects^73.\n\nConsistent with our predictions and a previous meta-analysis^59, facial\nfeedback effects, when present, were small (see Supplementary Fig. 3 for the\ndistribution of mean difference scores). Nonetheless, these effects were\nsimilar in size to the effect of mildly positive photos on happiness\u2014that is,\nfacial feedback was just as impactful as the external emotional context.\nObserving small effects is inconsistent with extreme claims that facial\nfeedback is the primary determinant of emotional experience^2,74. However,\nthey support less extreme theories that characterize facial feedback as one of\nmany components of the peripheral nervous system that contribute to emotional\nexperience^47,75,76.\n\nThese results have implications for discussions about whether facial feedback\ninterventions\u2014such as those that might ask people to simply smile in the\nmirror for five seconds every morning\u2014can be leveraged to manage\ndistress^15,16, improve well-being^17,18 and reduce\ndepression^19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39. It\nis possible that relatively small facial feedback effects could accumulate\ninto meaningful changes in well-being over time^77. However, given that the\nsimilar-sized effect of positive images on happiness has not emerged as a\nserious well-being intervention, many (but not all) authors of this paper find\nit unlikely that facial feedback interventions will either.\n\nContrary to our predictions, the effect of posed facial expressions on\nhappiness varied depending on the facial movement task. There was strong\nevidence of facial feedback effects in the facial mimicry and voluntary facial\naction tasks, but the evidence was less clear in the pen-in-mouth task. (This\nwas despite avoiding video recording participants, which some^50\u2014but not\nall^59\u2014researchers argue interferes with facial feedback effects.) Our\npreregistered model with random slopes did not provide significant evidence of\na simple effect of Pose in the pen-in-mouth condition, and Bayesian analyses\nprovided moderate support for the null hypothesis. An exploratory one-sided\ntest of this effect was significant when we removed random slopes from the\nmodel, but Bayesian analyses characterized the evidence as inconclusive.\nHowever, when we relaxed our inclusion criteria, both frequentist and Bayesian\nanalyses provided strong evidence of a facial feedback effect in the pen-in-\nmouth task. Nonetheless, we preregistered that this would be considered a less\nstringent test of the facial feedback hypothesis.\n\nAlthough it is less clear whether the pen-in-mouth task had a non-zero effect\non feelings of happiness, the effect is clearly smaller than that produced by\nthe facial mimicry and voluntary facial action tasks. This may suggest that\ndifferent mechanisms underlie the effects produced by each task. Researchers\ndo not agree on which mechanisms underlie facial feedback effects^73, but they\nmay involve both inferential processes (for example, people inferring they are\nhappy because they are smiling)^45,46 and non-inferential processes (for\nexample, smiling automatically activating other physiological components of\nemotion)^5,54. Unlike other facial feedback tasks, the pen-in-mouth task was\ndesigned to limit the role of inferential process by manipulating facial\nexpressions covertly^41. Consistent with this goal, participants in the pen-\nin-mouth condition were less likely to report that the posed happy expression\nfelt genuine. This may mean that inferential processes were minimized in this\ntask, thus reducing the size of the facial feedback effect. Contrary to this\nexplanation, though, we did not find that facial feedback effects were\nmoderated by self-report measures of general attentiveness to non-emotional\nbodily process. (See the Supplementary Information for similar results from\npilot studies using a multifaceted self-report of body awareness.)\n\nAlternatively, the pen-in-mouth task may have created a less prototypical\nexpression of happiness\u2014which, regardless of the role of inferential\nprocesses, may attenuate facial feedback effects^51,52,53. Specifically,\nfacial feedback effects may be amplified when the task activates muscles\ntypically associated with an emotional state and attenuated when the task\nactivates muscles not typically associated with an emotional state. In\nretrospect, the pen-in-mouth task we used may simultaneously activate muscles\nassociated with biting, which may attenuate its effect on happiness reports.\nFurthermore, a robust pen-in-mouth effect may emerge if one uses a variant of\nthe task that better activates the orbicularis oculi muscles, which is\nassociated with genuine expressions of happiness^56. However, our results\nprovide mixed support for these predictions. On one hand, facial feedback\neffects did not differ between the other two tasks, which were designed to\nproduce less prototypical (voluntary facial action task) and more prototypical\n(facial mimicry task) expressions of happiness. On the other hand, facial\nfeedback effects were larger when participants reported posing higher-quality\nexpressions. Future research can further investigate this issue by more\ndirectly measuring muscle activity using facial action coding^78,\nelectromyography^79, sonography^80 or thermography^81.\n\nTo conclude, our adversarial collaboration was partly inspired by conflicting\nnarratives about the validity of the facial feedback hypothesis. We began the\ncollaboration after a large team of researchers failed to replicate a seminal\ndemonstration of facial feedback effects using a pen-in-mouth task^40, but a\nmeta-analysis indicated that facial feedback has a small but significant\neffect on emotional experience^59. Our results do not provide unequivocal\nevidence of a pen-in-mouth effect. Nonetheless, they do provide strong\nevidence that other tasks designed to produce partial or full recreations of\nhappy expressions can both modulate and initiate feelings of happiness. It has\nbeen nearly 100 years since researchers began famously debating whether\nperipheral nervous system activity is merely a by-product of emotion\nprocesses. Consistent with theories positing that peripheral nervous system\nactivity impacts emotional experience, our results a century later provide\nstrong evidence of facial feedback effects. With this foundation strengthened,\nfuture researchers can turn their attention to answering new questions about\nwhen and why these effects occur.\n\n## Methods\n\n### Ethics\n\nEach research group received approval from their local Ethics Committee or\nInstitutional Review Board to conduct the study (for example, University of\nTennessee IRB-19-05313-XM), indicated that their institution does not require\napproval for the researchers to conduct this type of research or indicated\nthat the current study is covered by a pre-existing approval. At the time of\nStage 1 submission, 22 research groups had ethics approval to collect data,\nbut additional sites with pending ethics approval joined the project later.\nAll participants provided informed consent.\n\n### Procedure\n\nThe experiment was presented via Qualtrics. Due to constraints created by\nCOVID-19, we planned for data collection to primarily occur online. However,\nresearch groups were allowed to collect data in the laboratory if they\nindicated they could do so safely. Before beginning the study, the\nparticipants were asked to confirm that they had a clean pen or pencil nearby\nthat they were willing to place in their mouths, were completing the study on\na desktop computer or laptop (details regarding the participants\u2019 operating\nsystems were automatically recorded to confirm) and were in a setting with\nminimal distractions.\n\nThe participants were told that the study was investigating how physical\nmovements and cognitive distractors influence mathematical speed and accuracy\nand that they would complete four simple movement tasks and math problems. The\nfirst and last tasks were randomly presented filler trials that helped ensure\nthe cover story was believable (\u201cPlace your left hand behind your head and\nblink your eyes once per second for 5 seconds\u201d and \u201cTap your left leg with\nyour right-hand index finger once per second for 5 seconds\u201d). In the two\ncritical tasks, the participants were asked to pose happy and neutral facial\nexpressions in randomized order through the facial mimicry, voluntary facial\naction or pen-in-mouth procedure. While posing these expressions, some\nparticipants were randomly assigned to view positive images. To reinforce the\ncover story, the participants were provided with an on-screen timer during all\ntasks.\n\nAfter each task (including the filler tasks), the participants completed a\nsimple filler arithmetic problem and the Discrete Emotions Questionnaire\u2019s\nfour-item happiness subscale, which asked the participants to indicate the\ndegree to which they experienced happiness, satisfaction, liking and enjoyment\nduring the preceding task (1 = \u2018not at all\u2019 to 7 = \u2018an extreme amount\u2019)^82.\nThe participants also completed two items measuring anxiety (worry and\nnervous). To further obscure the purpose of the study, the participants also\ncompleted one anger, tiredness and confusion filler item. All emotion items\nwere presented in random order. By not referencing the emotional stimuli, this\nquestionnaire better captured self-focused, as opposed to world-focused,\nemotional experience^57,58. Afterwards, the participants rated how much they\nliked the task and how difficult they found the task and arithmetic problem.\nIn the non-filler tasks, an attention check item asking the participants to\nchoose a specific response option was randomly inserted in the questions\nregarding the task and arithmetic problem difficulty.\n\nIn the facial mimicry condition, the participants were shown a 2 \u00d7 2 image\nmatrix of actors posing happy expressions. The participants were then\ninstructed to either mimic these expressions (happy condition) or maintain a\nblank expression (neutral condition). Importantly, having the participants\nview the happy expression matrix before both the happy and neutral trials\nensured that any potentially confounding effects that images of smiling people\nhave on emotional experience were constant across the mimicry trials. The\nexpression matrix was displayed for at least five seconds, and the\nparticipants indicated when they were ready to perform the task. In the\nvoluntary facial action condition, the participants were instructed to either\nmove the corners of their lips up towards their ears and elevate their cheeks\nusing only the muscles in their face (happy condition) or maintain a blank\nfacial posture (neutral condition). In the pen-in-mouth condition, the\nparticipants received video instructions regarding the correct way to hold the\npen in their teeth (happy condition) or lips (neutral condition). During all\nfacial pose tasks, the participants were instructed to maintain the poses for\nfive seconds, the approximate duration of spontaneous happiness\nexpressions^83.\n\nAfter completing the five movement tasks, the participants answered a variety\nof open-ended questions regarding their beliefs about the purpose of the\nexperiment via Qualtrics. Each research group recruited two independent,\nresults-blind coders to review the open-ended responses. The coders were\nprovided a written description of the study purpose and methods and\nsubsequently reviewed the participants\u2019 open-ended responses in randomized\norder. On the basis of the open-ended responses, the coders rated the degree\nto which each participant was aware of the true purpose of the experiment (1 =\n\u2018not at all aware\u2019 to 7 = \u2018completely aware\u2019).\n\nAfter answering questions about their beliefs regarding the purpose of the\nexperiment, the participants completed a short demographic form and the Body\nAwareness Questionnaire^84. The participants then answered several questions\nrelated to the quality of their data. First, the participants were re-\npresented with their assigned happy pose instructions and asked to\nretrospectively rate how well they followed the instructions earlier in the\nstudy (1 = \u2018not at all\u2019 to 7 = \u2018exactly\u2019). Second, the participants were asked\nto repeat the task and rate the degree to which it felt like they were\nexpressing happiness (1 = \u2018not at all\u2019 to 7 = \u2018exactly\u2019). Third, the\nparticipants were asked to watch themselves repeat the task (for example, via\na mirror or camera phone) and indicate the degree to which their expression\nmatched an image of an individual completing the task correctly (1 = \u2018not at\nall\u2019 to 7 = \u2018exactly\u2019). Fourth, the participants were asked to describe any\nissues that may have compromised the quality of their data (such as\ndistractions). The two coders from each research group reviewed the responses\nto this last question and rated the degree to which each participant was\ndistracted (1 = \u2018not at all distracted\u2019 to 7 = \u2018completely distracted\u2019). The\nparticipants were told that there would not be a penalty for indicating that\nthey did not complete the task correctly or that there were issues with the\nquality of their data.\n\nIdeally, the quality of the participants\u2019 posed expressions would have been\nassessed via video recordings or participant-submitted photos. However, many\nmembers of our collaboration expressed doubts about receiving ethical approval\nto collect and share images or recordings. Participants in many of our data\ncollection regions may also have lacked a web camera. Furthermore, researchers\nare still debating whether awareness of overt video recording interferes with\nfacial feedback effects^49,50,59,85. Nevertheless, pilot study recordings and\nself-reports confirmed that almost all participants successfully posed the\ntarget facial expressions (Supplementary Information).\n\n### Materials\n\nIn the facial mimicry task, the participants all viewed the same 2 \u00d7 2 image\nmatrix of actors posing happy facial expressions from the Extended Cohn\u2013Kanade\nDataset^86. All four actors posed prototypical facial expressions of\nhappiness, as confirmed by coders trained in the Facial Action Coding\nSystem^78. An image matrix of actors, as opposed to a single image, was used\nso that the participants had multiple examples of the movement and were\nprovided with more options for a suitable facial model. In the pen-in-mouth\ntask, the instructional videos were adopted from Wagenmakers and colleagues\u2019\nreplication materials^40.\n\nDuring the two facial expression pose tasks, one group of participants viewed\nan array of four positive photos (for example, photos of dogs, flowers,\nkittens and rainbows). Multiple photos (as opposed to a single photo) were\nused to increase the probability that the participants found at least one of\nthe photos emotionally evocative. All photos were drawn from a database\ncomprising 100 images from the internet and the International Affective\nPicture System^87 that were separately rated on how good and bad they were^88.\nThe results from the three pilot studies confirmed that these images\nsuccessfully elicited feelings of happiness (Supplementary Information). Due\nto potential cross-cultural differences in what types of photos elicit\nhappiness (for example, dog photos can be expected to elicit happiness in many\nWestern cultures but not in all African cultures), each lab was permitted to\nreplace photos with more culturally appropriate positive photos. For non-\nEnglish-speaking data collection sites, the experiment materials were\ntranslated into the local language.\n\n### Primary analyses\n\nDue to the nested nature of the data (for example, ratings nested within\nindividuals, which were nested within research groups), we used linear\nmultilevel modelling. More specifically, happiness reports were modelled with\n(1) Pose, Facial Movement Task and Stimuli Presence entered as factors; (2)\nrandom intercepts for research groups and participants; and (3) random slopes\nfor research groups. All hypotheses in Table 1 were examined using both null\nhypothesis significance testing and Bayesian alternatives.\n\nParticipants were excluded from the primary analyses if they (1) exhibited any\nawareness of the facial feedback hypothesis (that is, received an awareness\nscore over 1 from two independent coders), (2) disclosed that they were very\ndistracted during the study (that is, received an average distraction score\nabove 5 from two independent coders), (3) did not complete the study on a\ndesktop computer or laptop, (4) indicated that they did not follow the pose\ninstructions, (5) indicated that their expression during the happy pose task\ndid not at all match the image of an actor completing the task correctly, or\n(6) failed attention checks. These stringent exclusion criteria were added\nafter we failed to observe the pen-in-mouth effect in pilot study 3.\n\n### Secondary analyses\n\nAlthough our primary analyses were run with the aforementioned exclusion\ncriteria, we also re-ran these analyses to examine whether the exclusion\ncriteria interact with Pose to influence happiness reports. We also examined\nwhether these exclusion criterion variables varied as a function of Facial\nMovement Task and Stimuli Presence.\n\nTo examine the alternative explanation that doing something (for example,\nposing a happy facial expression) may simply be more enjoyable than doing\nnothing (for example, posing a neutral facial expression), we also re-ran our\nprimary analyses with a factor contrasting the happy pose and filler trials.\n\nAlthough previous research has indicated that many psychology studies yield\nsimilar effect sizes when completed online versus in a lab^89, we recorded the\nmode of data collection and planned to re-run our primary analyses with the\ndata collection mode included as a moderator. However, we noted that this\nanalysis may be confounded by (1) whether the research group is a proponent or\na critic of the facial feedback hypothesis (that is, proponents may be more\nlikely to collect data in the laboratory) and (2) the region of data\ncollection (that is, research groups in regions with fewer COVID-19 cases may\nbe more likely to collect data in the laboratory).\n\nAlthough we did not anticipate a Pose by Facial Movement Task interaction, we\nnoted that the pen-in-mouth condition may lead to heightened levels of anxiety\nin the midst and/or aftermath of COVID-19. Although this is speculative,\nheightened levels of anxiety may interfere with facial feedback effects.\nConsequently, as an exploratory analysis, we examined whether anxiety ratings\ndiffer as a function of Facial Movement Task.\n\n### Power simulation\n\nPower analysis was performed via a linear multilevel modelling simulation. We\nrandomly generated normally distributed data for 96 participants from 22\nresearch groups. Effect size estimates for the hypothesized effects of Pose (d\n= 0.39), Stimuli Presence (d = 0.68) and the Pose by Stimuli Presence\ninteraction (d = 0.29) were estimated from pilot studies 1 and 2\n(Supplementary Information). All other effects were set to zero. Pilot study 3\nwas run after initial in-principle acceptance was granted and yielded somewhat\ndifferent effect size estimates. However, this pilot study led to minor\nrefinements in the exclusion criteria that left our original predictions\nunchanged.\n\nOn the basis of two pilot studies, we simulated random intercepts for\nparticipants with s.d. = 0.70. We did not simulate random slopes for\nparticipants since there are only two observations within each participant,\nwhich would probably lead to convergence issues. Random slopes for research\ngroups were simulated on the basis of the values from the previous many-lab\nfailure to replicate^40. For the hypothesized effects, we specified\nconservative random slope estimates on the basis of the standard deviation of\ntheir meta-analytic effect size from the previous many-lab failure to\nreplicate (s.d. = 0.28). For the effects we expected to be zero, we specified\nrandom slopes on the basis of the random slope from the previous many-lab\nfailure to replicate (\u03c4^2 \u2248 0). However, due to convergence issues, the\nresearch groups random slope for the facial feedback task factor was removed.\nResidual variance was set to 0.60 on the basis of the estimates from pilot\nstudies 1 and 2.\n\nThe results from this power simulation indicated that over 95% power for all\nour hypothesized effects could be obtained with at least 1,584 participants.\nHowever, on the basis of pilot study 3, we estimated that 44% of the\nparticipants would not meet our strict inclusion criteria, leading to a\ndesired sample of 2,281. We therefore planned to stop collecting data once one\nof the following conditions was met: (1) 22 labs had collected 105\nparticipants each or (2) at least six months had elapsed since the start of\ndata collection and we had at least 2,281 participants. We planned for a\nminimum of 22 labs to collect data for this project, although additional labs\nwith pending ethics approval were allowed to join the project later.\n\n### Reporting summary\n\nFurther information on research design is available in the Nature Research\nReporting Summary linked to this article.\n\n## Data availability\n\nThe full data are publicly available at https://osf.io/ac3t2/. Source data are\nprovided with this paper.\n\n## Code availability\n\nThe full analysis code is publicly available at https://osf.io/ac3t2/.\n\n## References\n\n  1. Zajonc, R. B. The primacy of affect. Am. Psychol. 40, 849\u2013850 (1985).\n\nArticle Google Scholar\n\n  2. Tomkins, S. Affect Imagery Consciousness: The Positive Affects Vol. 1 (Springer, 1962).\n\n  3. Laird, J. D. & Crosby, M. in Thought and Feeling: Cognitive Alteration of Feeling States (eds London, H. & Nisbett, R. E.) 44\u201359 (Transaction, 1974).\n\n  4. Allport, F. H. A physiological\u2013genetic theory of feeling and emotion. Psychol. Rev. 29, 132\u2013139 (1922).\n\nArticle Google Scholar\n\n  5. Levenson, R. W., Ekman, P. & Friesen, W. V. Voluntary facial action generates emotion-specific autonomic nervous system activity. Psychophysiology 27, 363\u2013384 (1990).\n\nArticle CAS Google Scholar\n\n  6. Coan, J. A., Allen, J. J. B. & Harmon-Jones, E. Voluntary facial expression and hemispheric asymmetry over the frontal cortex. Psychophysiology 38, 912\u2013925 (2001).\n\nArticle CAS Google Scholar\n\n  7. Scherer, K. R. & Moors, A. The emotion process: event appraisal and component differentiation. Annu. Rev. Psychol. 70, 719\u2013745 (2019).\n\nArticle Google Scholar\n\n  8. Stepper, S. & Strack, F. Proprioceptive determinants of emotional and nonemotional feelings. J. Pers. Soc. Psychol. 64, 211\u2013220 (1993).\n\nArticle Google Scholar\n\n  9. Friedman, B. H. Feelings and the body: the Jamesian perspective on autonomic specificity of emotion. Biol. Psychol. 84, 383\u2013393 (2010).\n\nArticle Google Scholar\n\n  10. James, W. Discussion: the physical basis of emotion. Psychol. Rev. 1, 516\u2013529 (1894).\n\nArticle Google Scholar\n\n  11. Lange, C. G. Om Sindsbevaegelser; Et Psyko-Fysiologisk Studie (Lund, 1885).\n\n  12. Cannon, W. The James\u2013Lange theory of emotions: a critical examination and an alternative theory. Am. J. Psychol. 39, 106\u2013124 (1927).\n\nArticle Google Scholar\n\n  13. Cannon, W. Bodily Changes in Pain, Hunger, Fear and Rage (D. Appleton, 1915).\n\n  14. Sherrington, C. S. Experiments on the value of vascular and visceral factors for the genesis of emotion. Proc. R. Soc. Lond. 66, 390\u2013403 (1899).\n\nGoogle Scholar\n\n  15. Ansfield, M. E. Smiling when distressed: when a smile is a frown turned upside down. Pers. Soc. Psychol. Bull. 33, 763\u2013775 (2007).\n\nArticle Google Scholar\n\n  16. Kraft, T. L. & Pressman, S. D. Grin and bear it: the influence of manipulated facial expression on the stress response. Psychol. Sci. 23, 1372\u20131378 (2012).\n\nArticle Google Scholar\n\n  17. Schmitz, B. Art-of-Living: A Concept to Enhance Happiness (Springer Cham, 2016).\n\n  18. Lyubomirsky, S. The How of Happiness: A Scientific Approach to Getting the Life You Want (Penguin Group, 2008).\n\n  19. Alam, M., Barrett, K. C., Hodapp, R. M. & Arndt, K. A. Botulinum toxin and the facial feedback hypothesis: can looking better make you feel happier? J. Am. Acad. Dermatol. 58, 1061\u20131072 (2008).\n\nArticle Google Scholar\n\n  20. Alves, M. C., Sobreira, G., Aleixo, M. A. & Oliveira, J. M. Facing depression with botulinum toxin: literature review. Eur. Psychiatry 335, 5290\u20135643 (2016).\n\nGoogle Scholar\n\n  21. Chugh, S., Chhabria, A., Jung, S., Kruger, T. H. C. & Wollmer, M. A. Botulinum toxin as a treatment for depression in a real-world setting. J. Psychiatr. Pract. 24, 15\u201320 (2018).\n\nArticle Google Scholar\n\n  22. Finzi, E. Update: botulinum toxin for depression: more than skin deep. Dermatol. Surg. 44, 1363\u20131365 (2018).\n\nArticle CAS Google Scholar\n\n  23. Finzi, E. & Rosenthal, N. E. Emotional proprioception: treatment of depression with afferent facial feedback. J. Psychiatr. Res. 80, 93\u201396 (2016).\n\nArticle Google Scholar\n\n  24. Finzi, E. & Rosenthal, N. E. Treatment of depression with onabotulinumtoxinA: a randomized, double-blind, placebo controlled trial. J. Psychiatr. Res. 52, 1\u20136 (2014).\n\nArticle Google Scholar\n\n  25. Finzi, E. & Wasserman, E. Treatment of depression with botulinum toxin A: a case series. Dermatol. Surg. 32, 645\u2013649 (2006).\n\nCAS Google Scholar\n\n  26. Fromage, G. Exploring the effects of botulinum toxin type A injections on depression. Aesthet. Nurs. 7, 315\u2013317 (2018).\n\nArticle Google Scholar\n\n  27. Hexsel, D. et al. Evaluation of self-esteem and depression symptoms in depressed and nondepressed subjects treated with onabotulinumtoxinA for glabellar lines. Dermatol. Surg. 39, 1088\u20131096 (2013).\n\nArticle CAS Google Scholar\n\n  28. Kr\u00fcger, T. H. C., Jung, S. & Wollmer, M. A. Botulinumtoxin\u2014ein neuer wirkstoff in der psychopharmakotherapie? Psychopharmakotherapie 23, 2\u20137 (2016).\n\nGoogle Scholar\n\n  29. Lewis, M. B. & Bowler, P. J. Botulinum toxin cosmetic therapy correlates with a more positive mood. J. Cosmet. Dermatol. 8, 24\u201326 (2009).\n\nArticle Google Scholar\n\n  30. Magid, M. et al. Treating depression with botulinum toxin: a pooled analysis of randomized controlled trials. Pharmacopsychiatry 48, 205\u2013210 (2015).\n\nArticle CAS Google Scholar\n\n  31. Magid, M. & Reichenberg, J. S. Botulinum toxin for depression? An idea that\u2019s raising some eyebrows. Curr. Psychiatr. 14, 43\u201356 (2015).\n\nGoogle Scholar\n\n  32. Magid, M. et al. Treatment of major depressive disorder using botulinum toxin A: a 24-week randomized, double-blind, placebo-controlled study. J. Clin. Psychiatry 75, 837\u2013844 (2014).\n\nArticle CAS Google Scholar\n\n  33. Parsaik, A. K. et al. Role of botulinum toxin in depression. J. Psychiatr. Pract. 22, 99\u2013110 (2016).\n\nArticle Google Scholar\n\n  34. Reichenberg, J. S. et al. Botulinum toxin for depression: does patient appearance matter? J. Am. Acad. Dermatol. 74, 171\u2013173 (2016).\n\nArticle Google Scholar\n\n  35. Wollmer, M. A., Magid, M. & Kruger, T. H. C. in Practical Psychodermatology (eds Bewley, A. et al.) 216\u2013219 (John Wiley & Sons, 2014).\n\n  36. Wollmer, M. A. et al. Agitation predicts response of depression to botulinum toxin treatment in a randomized controlled trial. Front. Psychiatry 5, 36 (2014).\n\nArticle Google Scholar\n\n  37. Wollmer, M. A. et al. Facing depression with botulinum toxin: a randomized controlled trial. J. Psychiatr. Res. 46, 574\u2013581 (2012).\n\nArticle Google Scholar\n\n  38. Zamanian, A., Jolfaei, A. G., Mehran, G. & Azizian, Z. Efficacy of Botox versus placebo for treatment of patients with major depression. Iran. J. Public Health 46, 982\u2013984 (2017).\n\nGoogle Scholar\n\n  39. Finzi, E. The Face of Emotion: How Botox Affects Our Moods and Relationships (St. Martin\u2019s, 2013).\n\n  40. Wagenmakers, E.-J. et al. Registered replication report: Strack, Martin, & Stepper (1988). Perspect. Psychol. Sci. 11, 917\u2013928 (2016).\n\nArticle Google Scholar\n\n  41. Strack, F., Martin, L. L. & Stepper, S. Inhibiting and facilitating conditions of the human smile: a nonobtrusive test of the facial feedback hypothesis. J. Pers. Soc. Psychol. 54, 768\u2013777 (1988).\n\nArticle CAS Google Scholar\n\n  42. Buck, R. Nonverbal behavior and the theory of emotion: the facial feedback hypothesis. J. Pers. Soc. Psychol. 38, 811\u2013824 (1980).\n\nArticle CAS Google Scholar\n\n  43. Zuckerman, M., Klorman, R., Larrance, D. T. & Spiegel, N. H. Facial, autonomic, and subjective components of emotion: the facial feedback hypothesis versus externalizer\u2013internalizer distinction. J. Pers. Soc. Psychol. 41, 929\u2013944 (1981).\n\nArticle CAS Google Scholar\n\n  44. Ekman, P. & Oster, H. Facial expressions of emotion. Annu. Rev. Psychol. 30, 527\u2013554 (1979).\n\nArticle Google Scholar\n\n  45. Laird, J. D. Self-attribution of emotion: the effects of expressive behavior on the quality of emotional experience. J. Pers. Soc. Psychol. 29, 475\u2013486 (1974).\n\nArticle CAS Google Scholar\n\n  46. Laird, J. D. & Bresler, C. in Review of Personality and Social Psychology: Emotion (ed. Clark, M. S.) 213\u2013234 (Sage, 1992).\n\n  47. Ekman, P. in Anthropology of the Body (ed. Blacking, J.) 34\u201338 (Routledge, 1979).\n\n  48. Schimmack, U. & Chen, Y. The power of the pen paradigm: a replicability analysis. Replicability-Index https://replicationindex.com/2017/09/04/the-power-of-the-pen-paradigm-a-replicability-analysis/ (2017).\n\n  49. Strack, F. Reflection on the Smiling Registered Replication Report. Perspect. Psychol. Sci. 11, 929\u2013930 (2016).\n\nArticle Google Scholar\n\n  50. Noah, T., Schul, Y. & Mayo, R. When both the original study and its failed replication are correct: feeling observed eliminates the facial-feedback effect. J. Pers. Soc. Psychol. 114, 657\u2013664 (2018).\n\nArticle Google Scholar\n\n  51. Hager, J. C. & Ekman, P. Methodological problems in Tourangeau and Ellsworth\u2019s study of facial expression and experience of emotion. J. Pers. Soc. Psychol. 40, 358\u2013362 (1981).\n\nArticle Google Scholar\n\n  52. Tomkins, S. The role of facial response in the experience of emotion: a reply to Tourangeau and Ellsworth. J. Pers. Soc. Psychol. 37, 1519\u20131531 (1981).\n\nGoogle Scholar\n\n  53. Matsumoto, D. The role of facial response in the experience of emotion: more methodological problems and a meta-analysis. J. Pers. Soc. Psychol. 52, 769\u2013774 (1987).\n\nArticle CAS Google Scholar\n\n  54. Levenson, R. W., Ekman, P., Heider, K. & Friesen, W. V. Emotion and autonomic nervous system activity in the Minangkabau of West Sumatra. J. Pers. Soc. Psychol. 62, 972\u2013988 (1992).\n\nArticle CAS Google Scholar\n\n  55. Ekman, P. Facial expression and emotion. Am. Psychol. 48, 384\u2013392 (1993).\n\nArticle CAS Google Scholar\n\n  56. Soussignan, R. Duchenne smile, emotional experience, and autonomic reactivity: a test of the facial feedback hypothesis. Emotion 2, 52\u201374 (2002).\n\nArticle Google Scholar\n\n  57. Lambie, J. A. & Marcel, A. J. Consciousness and the varieties of emotion experience: a theoretical framework. Psychol. Rev. 109, 219\u2013259 (2002).\n\nArticle Google Scholar\n\n  58. Frijda, N. H. Emotion experience. Cogn. Emot. 194, 473\u2013497 (2010).\n\nGoogle Scholar\n\n  59. Coles, N. A., Larsen, J. T. & Lench, H. C. A meta-analysis of the facial feedback literature: effects of facial feedback on emotional experience are small and variable. Psychol. Bull. 145, 610\u2013651 (2019).\n\nArticle Google Scholar\n\n  60. Carter, E. C., Sch\u00f6nbrodt, F. D., Gervais, W. M. & Hilgard, J. Correcting for bias in psychology: a comparison of meta-analytic methods. Adv. Methods Pract. Psychol. Sci. 2, 115\u2013144 (2019).\n\nArticle Google Scholar\n\n  61. Macaskill, P., Walter, S. D. & Irwig, L. A comparison of methods to detect publication bias in meta-analysis. Stat. Med. 20, 641\u2013654 (2001).\n\nArticle CAS Google Scholar\n\n  62. Stanley, T. D. Limitations of PET-PEESE and other meta-analysis methods. Soc. Psychol. Pers. Sci. 8, 581\u2013591 (2017).\n\nArticle Google Scholar\n\n  63. Eysenck, H. J. An exercise in mega-silliness. Am. Psychol. 33, 517 (1978).\n\nArticle Google Scholar\n\n  64. Kleinke, C. L., Peterson, T. R. & Rutledge, T. R. Effects of self-generated facial expressions on mood. J. Pers. Soc. Psychol. 74, 272\u2013279 (1998).\n\nArticle Google Scholar\n\n  65. Dimberg, U. & S\u00f6derkvist, S. The voluntary facial action technique: a method to test the facial feedback hypothesis. J. Nonverbal Behav. 35, 17\u201333 (2011).\n\nArticle Google Scholar\n\n  66. R Core Team. R: A Language and Environment for Statistical Computing v.4.1.2 https://www.Rproject.org/ (R Foundation for Statistical Computing, 2021).\n\n  67. Bates, D., M\u00e4chler, M., Bolker, B. & Walker, S. Fitting linear mixed-effects models using lme4: mixed-effects modeling with R. J. Stat. Softw. 67, 1\u201348 (2015).\n\nArticle Google Scholar\n\n  68. Kuznetsova, A., Brockhoff, P. B. & Christensen, R. H. B. lmerTest package: tests in linear mixed effects models. J. Stat. Softw. 82, 1\u201326 (2017).\n\nArticle Google Scholar\n\n  69. Lenth, R. V. emmeans: Estimated marginal means, aka least-squares means. R package version 1.7.2 (2022).\n\n  70. Morey, R. D. & Rouder, J. N. BayesFactor: Computation of Bayes factors for common designs. R package version 0.9.12-4.3 (2021).\n\n  71. Wilson, T. D. et al. Just think: the challenges of the disengaged mind. Science 345, 75\u201377 (2014).\n\nArticle CAS Google Scholar\n\n  72. Brown, V. A. An introduction to linear mixed-effects modeling in R. Adv. Methods Pract. Psychol. Sci. 4, 1\u201319 (2021).\n\nGoogle Scholar\n\n  73. Coles, N. A., Gaertner, L., Frohlich, B., Larsen, J. T. & Basnight-Brown, D. Fact or artifact? Methodological artifacts moderate, but do not fully account for, the effects of facial feedback on emotional experience. J. Pers. Soc. Psychol. 1\u201324 (2022).\n\n  74. Izard, C. E. The Face of Emotion (Appleton-Century-Crofts, 1971).\n\n  75. James, W. What is an emotion? Mind 9, 188\u2013205 (1884).\n\nArticle Google Scholar\n\n  76. Laird, J. D. & Lacasse, K. Bodily influences on emotional feelings: accumulating evidence and extensions of William James\u2019s theory of emotion. Emot. Rev. 6, 27\u201334 (2014).\n\nArticle Google Scholar\n\n  77. Funder, D. C. & Ozer, D. J. Evaluating effect size in psychological research: sense and nonsense. Adv. Methods Pract. Psychol. Sci. 2, 156\u2013168 (2019).\n\nArticle Google Scholar\n\n  78. Ekman, P. & Rosenberg, E. L. What the Face Reveals: Basic and Applied Studies of Spontaneous Expression Using the Facial Action Coding System (FACS) (Oxford Univ. Press, 1997).\n\n  79. Larsen, J. T., Norris, C. J. & Cacioppo, J. T. Effects of positive and negative affect on electromyographic activity over zygomaticus major and corrugator supercilii. Psychophysiology 40, 776\u2013785 (2003).\n\nArticle Google Scholar\n\n  80. Alfen, N. Van, Gilhuis, H. J., Keijzers, J. P., Pillen, S. & Van Dijk, J. P. Quantitative facial muscle ultrasound: feasibility and reproducibility. Muscle Nerve 48, 375\u2013380 (2013).\n\nArticle Google Scholar\n\n  81. Clay-Warner, J. & Robinson, D. T. Infrared thermography as a measure of emotion response. Emot. Rev. 7, 157\u2013162 (2014).\n\nArticle Google Scholar\n\n  82. Harmon-Jones, C., Bastian, B. & Harmon-Jones, E. The Discrete Emotions Questionnaire: a new tool for measuring state self-reported emotions. PLoS ONE 11, e0159915 (2016).\n\nArticle Google Scholar\n\n  83. Ekman, P. Darwin, deception, and facial expression. Ann. N. Y. Acad. Sci. 1000, 205\u2013221 (2003).\n\nArticle Google Scholar\n\n  84. Shields, S. A., Mallory, M. E. & Simon, A. The body awareness questionnaire: reliability and validity. J. Pers. Assess. 53, 802\u2013815 (1989).\n\nArticle Google Scholar\n\n  85. Marsh, A. A., Rhoads, S. A. & Ryan, R. M. A multi-semester classroom demonstration yields evidence in support of the facial feedback effect. Emotion 19, 1500\u20131504 (2019).\n\nArticle Google Scholar\n\n  86. Lucey, P. et al. The Extended Cohn\u2013Kanade Dataset (CK+): a complete dataset for action unit and emotion-specified expression. In Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. 94\u2013101 (IEEE, 2010).\n\n  87. Lang, P. & Bradley, M. M. in Handbook of Emotion Elicitation and Assessment (eds Coan, J. A. & Allen, J. J. B.) 29\u201346 (Oxford Univ. Press, 2007).\n\n  88. March, D. S., Gaertner, L. & Olson, M. A. In harm\u2019s way: on preferential response to threatening stimuli. Pers. Soc. Psychol. Bull. 43, 1519\u20131529 (2017).\n\nArticle Google Scholar\n\n  89. Klein, R. A. et al. Many Labs 2: investigating variation in replicability across samples and settings. Adv. Methods Pract. Psychol. Sci. 1, 443\u2013490 (2018).\n\nArticle Google Scholar\n\nDownload references\n\n## Acknowledgements\n\nThis work was financially supported by B. Stastny, who generously donated\nfunds for this research in memory of his father, Bill Stastny (J.T.L.). The\nwork was also supported by the National Science Centre, Poland (grant no.\n2019/35/B/HS6/00528; K.B.), JSPS KAKENHI (grant nos 16H03079, 17H00875,\n18K12015, 20H04581 and 21H03784; Y.Y.), the National Council for Scientific\nand Technological Development (CNPq; R.M.K.F.), the Polish National Science\nCenter (M.P.), the DFG Beethoven grant no. 2016/23/G/HS6/01775 (M.P.), the\nNational Science Foundation Graduate Research Fellowship (grant no.\nR010138018; N.A.C.), the Ministerio de Ciencia, Innovaci\u00f3n y Universidades\n(grant no. PGC2018-098558-B-I00; J.A.H.), the Comunidad de Madrid (grant no.\nH2019/HUM-5705; J.A.H.), Teesside University (N.B.) and the Occidental College\nAcademic Student Project Award (S.L.). The funders had no role in study\ndesign, data collection and analysis, decision to publish or preparation of\nthe manuscript. We also thank C. Scavo and A. Bidani for help with translating\nthe study materials, L. Pullano and R. Giorgini for help with coding, and E.\nTolomeo and L. Pane for help with data collection.\n\n## Author information\n\n### Authors and Affiliations\n\n  1. Center for the Study of Language and Information, Stanford University, Palo Alto, CA, USA\n\nNicholas A. Coles\n\n  2. Department of Psychology, Florida State University, Tallahassee, FL, USA\n\nDavid S. March\n\n  3. Center for Change and Complexity in Learning, University of South Australia, Adelaide, South Australia, Australia\n\nFernando Marmolejo-Ramos\n\n  4. Department of Psychology, University of Tennessee, Knoxville, TN, USA\n\nJeff T. Larsen & Lowell Gaertner\n\n  5. Department of Psychology, Alex Ekwueme Federal University Ndufu-Alike, Abakaliki, Nigeria\n\nNwadiogo C. Arinze & Izuchukwu L. G. Ndukaihe\n\n  6. School of Behavioural and Health Sciences, Australian Catholic University, Strathfield, New South Wales, Australia\n\nMegan L. Willis & Francesco Foroni\n\n  7. Department of Psychology, Ben-Gurion University, Be\u2019er Sheva, Israel\n\nNiv Reggev & Aviv Mokady\n\n  8. Zlotowski Center for Neuroscience, Ben-Gurion University, Be\u2019er Sheva, Israel\n\nNiv Reggev\n\n  9. Busara Center for Behavioral Economics, Nairobi, Kenya\n\nPatrick S. Forscher\n\n  10. Chapman University, Orange, CA, USA\n\nJohn F. Hunter\n\n  11. CLLE, Universit\u00e9 de Toulouse, Toulouse, France\n\nGwena\u00ebl Kaminski\n\n  12. Department of Psychology, Ege University, Izmir, Turkey\n\nElif Y\u00fcvr\u00fck & Aycan Kapucu\n\n  13. Institute of Psychology, ELTE E\u00f6tv\u00f6s Lor\u00e1nd University, Budapest, Hungary\n\nTam\u00e1s Nagy, Nandor Hajdu & Balazs Aczel\n\n  14. Department of Psychology, Federal University of Sergipe, S\u00e3o Crist\u00f3v\u00e3o, Brazil\n\nJulian Tejada\n\n  15. Vernacular Languages Department, Federal University of Sergipe, S\u00e3o Crist\u00f3v\u00e3o, Brazil\n\nRaquel M. K. Freitag\n\n  16. Fundaci\u00f3n para el Avance de la Psicolog\u00eda, Bogot\u00e1, Colombia\n\nDanilo Zambrano\n\n  17. Department of Humanities and Social Sciences, Indian Institute of Technology Guwahati, Guwahati, India\n\nBidisha Som\n\n  18. Institute of Psychology, Jagiellonian University, Krak\u00f3w, Poland\n\nKrystian Barzykowski, Sylwia Adamus & Katarzyna Filip\n\n  19. Faculty of Arts and Science, Kyushu University, Fukuoka, Japan\n\nYuki Yamada\n\n  20. Graduate School of Human-Environment Studies, Kyushu University, Fukuoka, Japan\n\nAyumi Ikeda\n\n  21. School of Biomedical, Nutritional and Sport Sciences, Newcastle University, Newcastle upon Tyne, UK\n\nDaniel L. Eaves\n\n  22. School of Health and Life Sciences, Teesside University, Middlesbrough, UK\n\nDaniel L. Eaves\n\n  23. Occidental College, Los Angeles, CA, USA\n\nCarmel A. Levitan & Sydney Leiweke\n\n  24. Center of Research on Cognition and Behavior, SWPS University of Social Sciences and Humanities, Warsaw, Poland\n\nMichal Parzuchowski\n\n  25. Department of Psychology, Teesside University, Middlesbrough, UK\n\nNatalie Butcher\n\n  26. Department of Psychology, UiT The Arctic University of Norway, Troms\u00f8, Norway\n\nGerit Pfuhl\n\n  27. Department of Psychology, United States International University\u2014Africa, Nairobi, Kenya\n\nDana M. Basnight-Brown\n\n  28. Universidad Complutense, Madrid, Spain\n\nJos\u00e9 A. Hinojosa\n\n  29. Universidad Nebrija, Madrid, Spain\n\nJos\u00e9 A. Hinojosa\n\n  30. Departamento de Psicolog\u00eda B\u00e1sica 1, Universidad Nacional de Educaci\u00f3n a Distancia (UNED), Madrid, Spain\n\nPedro R. Montoro\n\n  31. Programa de Psicolog\u00eda, Universidad del Rosario, Bogot\u00e1, Colombia\n\nLady G. Javela D\n\n  32. LIP/PC2s, Universit\u00e9 Grenoble Alpes, Grenoble, France\n\nKevin Vezirian & Hans IJzerman\n\n  33. Institut Universitaire de France, Paris, France\n\nHans IJzerman\n\n  34. University of Antioquia-UDEA, Medell\u00edn, Colombia\n\nNatalia Trujillo\n\n  35. Department of Psychological Science, University of California, Irvine, CA, USA\n\nSarah D. Pressman\n\n  36. Department of Psychology, University of Fribourg, Fribourg, Switzerland\n\nPascal M. Gygax\n\n  37. Department of Psychology, \u00dcsk\u00fcdar University, \u0130stanbul, Turkey\n\nAsil A. \u00d6zdo\u011fru\n\n  38. FOM University of Applied Sciences, Essen, Germany\n\nSusana Ruiz-Fernandez\n\n  39. Leibniz-Institut f\u00fcr Wissensmedien, T\u00fcbingen, Germany\n\nSusana Ruiz-Fernandez\n\n  40. Department of Psychology, University of Michigan, Ann Arbor, MI, USA\n\nPhoebe C. Ellsworth\n\n  41. Department of Psychology, University of W\u00fcrzburg, W\u00fcrzburg, Germany\n\nFritz Strack\n\n  42. Department of Environmental Sciences, Informatics and Statistics, Ca\u2019 Foscari University of Venice, Venice, Italy\n\nMarco Marozzi\n\n  43. Department of Medical and Surgical Sciences, \u2018Magna Graecia\u2019 University of Catanzaro, Catanzaro, Italy\n\nMarco Tullio Liuzza\n\nAuthors\n\n  1. Nicholas A. Coles\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  2. David S. March\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  3. Fernando Marmolejo-Ramos\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  4. Jeff T. Larsen\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  5. Nwadiogo C. Arinze\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  6. Izuchukwu L. G. Ndukaihe\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  7. Megan L. Willis\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  8. Francesco Foroni\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  9. Niv Reggev\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  10. Aviv Mokady\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  11. Patrick S. Forscher\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  12. John F. Hunter\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  13. Gwena\u00ebl Kaminski\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  14. Elif Y\u00fcvr\u00fck\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  15. Aycan Kapucu\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  16. Tam\u00e1s Nagy\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  17. Nandor Hajdu\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  18. Julian Tejada\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  19. Raquel M. K. Freitag\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  20. Danilo Zambrano\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  21. Bidisha Som\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  22. Balazs Aczel\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  23. Krystian Barzykowski\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  24. Sylwia Adamus\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  25. Katarzyna Filip\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  26. Yuki Yamada\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  27. Ayumi Ikeda\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  28. Daniel L. Eaves\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  29. Carmel A. Levitan\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  30. Sydney Leiweke\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  31. Michal Parzuchowski\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  32. Natalie Butcher\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  33. Gerit Pfuhl\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  34. Dana M. Basnight-Brown\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  35. Jos\u00e9 A. Hinojosa\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  36. Pedro R. Montoro\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  37. Lady G. Javela D\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  38. Kevin Vezirian\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  39. Hans IJzerman\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  40. Natalia Trujillo\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  41. Sarah D. Pressman\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  42. Pascal M. Gygax\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  43. Asil A. \u00d6zdo\u011fru\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  44. Susana Ruiz-Fernandez\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  45. Phoebe C. Ellsworth\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  46. Lowell Gaertner\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  47. Fritz Strack\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  48. Marco Marozzi\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  49. Marco Tullio Liuzza\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n### Contributions\n\nConceptualization: N.A.C., D.S.M., F.M.-R., J.T.L., J.F.H., P.M.G., P.C.E.,\nL.G. and F.S. Data curation: N.A.C., B.S., Y.Y. and S.R.-F. Formal analysis:\nN.A.C., L.G., M.M. and M.T.L. Funding acquisition: N.A.C., Y.Y. and N.B.\nInvestigation: N.A.C., D.S.M., J.T.L., N.C.A., I.L.G.N., M.L.W., F.F., N.R.,\nA.M., J.F.H., G.K., E.Y., A.K., N.H., J.T., R.M.K.F., D.Z., B.A., K.B., S.A.,\nK.F., Y.Y., A.I., D.L.E., C.A.L., S.L., M.P., N.B., G.P., D.M.B.-B., J.A.H.,\nP.R.M., L.G.J.D., K.V., H.IJ., N.T., S.D.P., P.M.G., A.A.\u00d6., S.R.-F. and\nM.T.L. Methodology: N.A.C., D.S.M., F.M.-R., P.S.F., J.F.H., G.K., K.B.,\nD.L.E., S.R.-F., P.C.E. and L.G. Project administration: N.A.C., M.L.W., F.F.,\nP.S.F., J.F.H., J.T., K.B., K.F., D.L.E., M.P., H.IJ., S.D.P. and A.A.\u00d6.\nResources: N.A.C., D.S.M., I.L.G.N., E.Y., A.K., T.N., R.M.K.F., B.A., K.B.,\nS.A., M.P., G.P., J.A.H., P.R.M., H.IJ., P.M.G., A.A.\u00d6. and S.R.-F. Software:\nN.A.C., J.T. and M.M. Supervision: N.A.C., N.C.A., F.F., N.R., J.F.H., B.A.,\nK.B., C.A.L., N.B., H.IJ. and S.D.P. Validation: N.A.C., P.S.F., N.H., J.T.,\nM.P., N.T., M.M. and M.T.L. Visualization: N.A.C., P.S.F., J.A.H. and L.G.\nWriting\u2014original draft: N.A.C., D.S.M., A.A.\u00d6. and L.G. Writing\u2014review and\nediting: N.A.C., D.S.M., F.M.-R., J.T.L., N.C.A., I.L.G.N., M.L.W., F.F.,\nN.R., A.M., P.S.F., J.F.H., G.K., T.N., N.H., D.Z., B.A., K.B., Y.Y., D.L.E.,\nN.B., G.P., D.M.B.-B., J.A.H., P.R.M., L.G.J.D., H.IJ., N.T., S.D.P., P.M.G.,\nA.A.\u00d6., S.R.-F., P.C.E., L.G., F.S., M.M. and M.T.L.\n\n### Corresponding author\n\nCorrespondence to Nicholas A. Coles.\n\n## Ethics declarations\n\n### Competing interests\n\nThe authors declare no competing interests.\n\n## Peer review\n\n### Peer review information\n\nNature Human Behaviour thanks David Mellor, Rainer Reisenzein, Jared McGinley\nand Quentin Gronau for their contribution to the peer review of this work.\n\n## Supplementary information\n\n### Supplementary Information\n\nSupplementary Figs. 1\u20133, results from pilot studies 1\u20133, and results and\ndiscussion from the main study.\n\n### Reporting Summary\n\n## Source data\n\n### Source Data Fig. 1\n\nData on country-specific sample sizes.\n\n### Source Data Fig. 2\n\nParticipant-level data for the primary analyses.\n\n### Source Data Fig. 3\n\nParticipant-level data for the secondary moderator analyses.\n\n## Rights and permissions\n\nSpringer Nature or its licensor holds exclusive rights to this article under a\npublishing agreement with the author(s) or other rightsholder(s); author self-\narchiving of the accepted manuscript version of this article is solely\ngoverned by the terms of such publishing agreement and applicable law.\n\nReprints and permissions\n\n## About this article\n\n### Cite this article\n\nColes, N.A., March, D.S., Marmolejo-Ramos, F. et al. A multi-lab test of the\nfacial feedback hypothesis by the Many Smiles Collaboration. Nat Hum Behav 6,\n1731\u20131742 (2022). https://doi.org/10.1038/s41562-022-01458-9\n\nDownload citation\n\n  * Received: 21 February 2019\n\n  * Accepted: 07 September 2022\n\n  * Published: 20 October 2022\n\n  * Issue Date: December 2022\n\n  * DOI: https://doi.org/10.1038/s41562-022-01458-9\n\n### Share this article\n\nAnyone you share the following link with will be able to read this content:\n\nSorry, a shareable link is not currently available for this article.\n\nProvided by the Springer Nature SharedIt content-sharing initiative\n\n### Subjects\n\n  * Human behaviour\n  * Psychology\n\n## This article is cited by\n\n  * ### Almost Faces? ;-) Emoticons and Emojis as Cultural Artifacts for Social Cognition Online\n\n    * Marco Viola\n\nTopoi (2024)\n\n  * ### \u2018Big team\u2019 science challenges us to reconsider authorship\n\n    * Nicholas A. Coles\n    * Lisa M. DeBruine\n    * Michael C. Frank\n\nNature Human Behaviour (2023)\n\n  * ### Nature welcomes Registered Reports\n\nNature (2023)\n\n  * ### Facial mimicry is not modulated by dopamine D2/3 and opioid receptor antagonism\n\n    * Sebastian Korb\n    * Alasdair Clarke\n    * Giorgia Silani\n\nPsychopharmacology (2023)\n\n  * ### The replication crisis has led to positive structural, procedural, and community changes\n\n    * Max Korbmacher\n    * Flavio Azevedo\n    * Thomas Evans\n\nCommunications Psychology (2023)\n\nDownload PDF\n\n## Associated content\n\nCollection\n\n### Registered Reports\n\nAdvertisement\n\nNature Human Behaviour (Nat Hum Behav) ISSN 2397-3374 (online)\n\n## nature.com sitemap\n\n### About Nature Portfolio\n\n  * About us\n  * Press releases\n  * Press office\n  * Contact us\n\n### Discover content\n\n  * Journals A-Z\n  * Articles by subject\n  * protocols.io\n  * Nature Index\n\n### Publishing policies\n\n  * Nature portfolio policies\n  * Open access\n\n### Author & Researcher services\n\n  * Reprints & permissions\n  * Research data\n  * Language editing\n  * Scientific editing\n  * Nature Masterclasses\n  * Research Solutions\n\n### Libraries & institutions\n\n  * Librarian service & tools\n  * Librarian portal\n  * Open research\n  * Recommend to library\n\n### Advertising & partnerships\n\n  * Advertising\n  * Partnerships & Services\n  * Media kits\n  * Branded content\n\n### Professional development\n\n  * Nature Careers\n  * Nature Conferences\n\n### Regional websites\n\n  * Nature Africa\n  * Nature China\n  * Nature India\n  * Nature Italy\n  * Nature Japan\n  * Nature Middle East\n\n  * Privacy Policy\n  * Use of cookies\n  * Legal notice\n  * Accessibility statement\n  * Terms & Conditions\n  * Your US state privacy rights\n  * Cancel contracts here\n\n\u00a9 2024 Springer Nature Limited\n\nSign up for the Nature Briefing newsletter \u2014 what matters in science, free to\nyour inbox daily.\n\nGet the most important science stories of the day, free in your inbox. Sign up\nfor Nature Briefing\n\n", "frontpage": false}
