{"aid": "40178512", "title": "Looking for AI Use-Cases", "url": "https://www.ben-evans.com/benedictevans/2024/4/19/looking-for-ai-use-cases", "domain": "ben-evans.com", "votes": 1, "user": "rwmj", "posted_at": "2024-04-27 09:06:27", "comments": 0, "source_title": "Looking for AI use-cases", "source_text": "Looking for AI use-cases \u2014 Benedict Evans\n\nBenedict Evans\n\nBenedict Evans\n\n#\n\nLooking for AI use-cases\n\nWe\u2019ve had ChatGPT for 18 months, but what\u2019s it for? What are the use-cases?\nWhy isn\u2019t it useful for everyone, right now? Do Large Language Models become\nuniversal tools that can do \u2018any\u2019 task, or do we wrap them in single-purpose\napps, and build thousands of new companies around that?\n\nThis image comes from a book by Martin Honeysett called \u2018Microphobia\u2019,\npublished in 1982. It\u2019s full of great jokes and I could have used almost any\nof them, because they\u2019re all making the same point - what are you supposed to\ndo with this thing? I played Saboteur on the ZX Spectrum that my father bought\nthat year, but what else?\n\nA couple of years earlier, Dan Bricklin had found one answer: he saw a\nprofessor making a spreadsheet with chalk, on a blackboard, and realised that\nyou could do this in \u2018software\u2019. So he made VisiCalc, the first successful\ncomputer spreadsheet, and when he showed it to accountants it blew their\nminds: they could do a week\u2019s work in an afternoon. An Apple II to run\nVisiCalc cost at least $12,000* adjusted for inflation, but even so, people\nreached for their cheque-books the moment they saw it: computer spreadsheets\nchanged the world, for accountants.\n\nHowever, if you had showed VisiCalc to a lawyer or a graphic designer, their\nresponse might well have been \u2018that\u2019s amazing, and maybe my book-keeper should\nsee this, but I don\u2019t do that\u2019. Lawyers needed a word processor, and graphic\ndesigners needed (say) Postscript, Pagemaker and Photoshop, and that took\nlonger.\n\nI\u2019ve been thinking about this problem a lot in the last 18 months, as I\u2019ve\nexperimented with ChatGPT, Gemini, Claude and all the other chatbots that have\nsprouted up: \u2018this is amazing, but I don\u2019t have that use-case\u2019.\n\nThe one really big use-case that took off in 2023 was writing code, but I\ndon\u2019t write code. People use it for brainstorming, and making lists and\nsorting ideas, but again, I don\u2019t do that. I don\u2019t have homework anymore. I\nsee people using it to get a generic first draft, and designers making concept\nroughs with MidJourney, but, again, these are not my use-cases. I have not,\nyet, found anything that matches with a use-case that I have. I don\u2019t think\nI\u2019m the only one, either, as is suggested by some of the survey data - a lot\nof people have tried this, especially since you don\u2019t need to spend $12,000 on\na new Apple II, and it\u2019s very cool, but how much do we use it, and what for?\n\nThis wouldn\u2019t matter much (\u2018man says new tech isn\u2019t for him!\u2019), except that\nthat a lot of people in tech look at ChatGPT and LLMs and see a step change in\ngeneralisation, towards something that can be universal. A spreadsheet can\u2019t\ndo word processing or graphic design, and a PC can do all of those but someone\nneeds to write those applications for you first, one use-case at a time. But\nas these models get better and become multi-modal, the really transformative\nthesis is that one model can do \u2018any\u2019 use-case without anyone having to write\nthe software for that task in particular.\n\nSuppose you want to analyse this month\u2019s customer cancellations, or dispute a\nparking ticket, or file your taxes - you can ask an LLM, and it will work out\nwhat data you need, find the right websites, ask you the right questions,\nparse a photo of your mortgage statement, fill in the forms and give you the\nanswers. We could move orders of magnitude more manual tasks into software,\nbecause you don\u2019t need to write software to do each of those tasks one at a\ntime. This, I think, is why Bill Gates said that this is the biggest thing\nsince the GUI. That\u2019s a lot more than a writing assistant.\n\nIt seems to me, though, that there are two kinds of problem with this thesis.\n\nThe narrow problem, and perhaps the \u2018weak\u2019 problem, is that these models\naren\u2019t quite good enough, yet. They will get stuck, quite a lot, in the\nscenarios I suggested above. Meanwhile, these are probabilistic rather than\ndeterministic systems, so they\u2019re much better for some kinds of task than\nothers. They\u2019re now very good at making things that look right, and for some\nuse-cases this is what you want, but for others, \u2018looks right\u2019 is different to\n\u2018right\u2019. Error rates and \u2018hallucinations\u2019 are improving all the time, and\nbecoming more manageable, but we don\u2019t know where this will go - this is one\nof the big scientific arguments around generative AI (and indeed AGI). And\nwhatever you think these models will be in a couple of years, there\u2019s a lot\nthat isn\u2019t there today. These screenshots are a nice example of a use-case\nthat I do have, that should work, and doesn\u2019t - yet.\n\nView fullsize\n\nView fullsize\n\nView fullsize\n\nThe deeper problem, I think, is that no matter how good the tech is, you have\nto think of the use-case. You have to see it. You have to notice something you\nspend a lot of time doing and realise that it could be automated with a tool\nlike this.\n\nSome of this is about imagination, and familiarity. It reminds me a little of\nthe early days of Google, when we were so used to hand-crafting our solutions\nto problems that it took time to realise that you could \u2018just Google that\u2019.\nIndeed, there were even books on how to use Google, just as today there are\nlong essays and videos on how to learn \u2018prompt engineering.\u2019 It took time to\nrealise that you could turn this into a general, open-ended search problem,\nand just type roughly what you want instead of constructing complex logical\nboolean queries on vertical databases. This is also, perhaps, matching a\nclassic pattern for the adoption of new technology: you start by making it fit\nthe things you already do, where it\u2019s easy and obvious to see that this is a\nuse-case, if you have one, and then later, over time, you change the way you\nwork to fit the new tool.\n\nHowever, the other part of this pattern is that it\u2019s not the user\u2019s job to\nwork out how a new tool is useful. Dan Bricklin, and in principle all\nsoftware, had three steps: he had to realise that you could put a spreadsheet\ninto software, then he had to design and code it (and get that right), and\nthen he had to go out and tell accountants why this was great.\n\nIn that case he had perfect product-market fit almost immediately and the\nproduct sold itself, but this is very rare. The concept of product-market fit\nis that normally you have to iterate your idea of the product and your idea of\nthe use-case and customer towards each other - and then you need sales. The\ngreat recurring fallacy in productivity software startups is that you can sell\nbottom-up without a sales force, because the users will see it and want it.\nThe reality, with a tiny number of exceptions, has always been that only a\nvery small percentage of your target users are interested and ready to explore\na new tool, and for the rest, you will need to sell to them.\n\nHence, one hypothesis today might be that generative AI could remove or\nminimise Dan Bricklin\u2019s work actually to build the product, but you still need\nto realise that you could do this, make something tangible that expresses\nthat, and then go out and tell people. People know they\u2019re doing taxes, but\nmost of the things we automate are things we don\u2019t really see or realise we\u2019re\ndoing as a separate, discrete task that could be automated until someone\npoints them out and tries to sell us software.\n\nMeanwhile, spreadsheets were both a use-case for a PC and a general-purpose\nsubstrate in their own right, just as email or SQL might be, and yet all of\nthose have been unbundled. The typical big company today uses hundreds of\ndifferent SaaS apps, all them, so to speak, unbundling something out of Excel,\nOracle or Outlook. All of them, at their core, are an idea for a problem and\nan idea for a workflow to solve that problem, that is easier to grasp and\ndeploy than saying \u2018you could do that in Excel!\u2019 Rather, you instantiate the\nproblem and the solution in software - \u2018wrap it\u2019, indeed - and sell that to a\nCIO. You sell them a problem. And meanwhile, you probably don\u2019t want to give\nChatGPT to Dwight or Big Keith from The Office and tell them to use it for\ninvoicing, anymore than you tell them to use Excel instead of SAP.\n\nHence, the cognitive dissonance of generative AI is that OpenAI or Anthropic\nsay that we are very close to general-purpose autonomous agents that could\nhandle many different complex multi-stage tasks, while at the same time\nthere\u2019s a \u2018Cambrian Explosion\u2019 of startups using OpenAI or Anthropic APIs to\nbuild single-purpose dedicated apps that aim at one problem and wrap it in\nhand-built UI, tooling and enterprise sales, much as a previous generation did\nwith SQL. Back in 1982, my father had one (1) electric drill, but since then\ntool companies have turned that into a whole constellation of battery-powered\nelectric hole-makers. One upon a time every startup had SQL inside, but that\nwasn\u2019t the product, and now every startup will have LLMs inside.\n\nI often compared the last wave of machine learning to automated interns. You\nwant to listen to every call coming into the call centre and recognise which\ncustomers sound angry or suspicious: doing that didn\u2019t need an expert, just a\nhuman (or indeed maybe even a dog), and now you could automate that entire\nclass of problem. Spotting those problems and building that software takes\ntime: machine learning\u2019s breakthrough was over a decade ago now, and yet we\nare still inventing new use-cases for it - people are still creating companies\nbased on realising that X or Y is a problem, realising that it can be turned\ninto pattern recognition, and then going out and selling that problem.\n\nYou could propose the current wave of generative AI as giving us another set\nof interns, that can make things as well as recognise them, and, again, we\nneed to work out what. Meanwhile, the AGI argument comes down to whether this\ncould be far, far more than interns, and if we had that, then it wouldn\u2019t be a\ntool anymore.\n\nBut even if I had an actual human intern, it might be quite hard for them to\nsolve the \u2018one-shot\u2019 request in my screenshots above. You\u2019d have to know that\nI\u2019m asking for a time-series dataset, with probably one number per year but\nperhaps one per decade, of people as employees by occupation (not, say, people\nemployed by elevator operators), on a national and not state basis, and then\nyou\u2019d go to the US Census website and discover that it does collect this kind\nof thing, but on several different layers of detail, at different intervals,\nwith different definitions, and it changes the definitions every few decades,\nand stopped collecting \u2018elevator operators\u2019 at some point (so it\u2019s not in the\ncurrent data at all, only the past data), and meanwhile the website has dozens\nand dozens of different data tools and sources, and it could be an entire\nprofession just to know how to find anything.\n\nAt that point, I\u2019d wander back to the intern\u2019s desk and tell them that they\nshould try FRED, and if that doesn\u2019t have it then it would be quicker to type\nthe data in, one year at a time, from scans of the old Statistical Abstracts,\nand that they\u2019re actually easier to search using the copies in Google Books,\nthat are scanned from random university libraries.\n\nThis is a nice illustration of the old joke that a programmer will spend a\nweek automating a task that would take a day to do by hand. It\u2019s also a great\nautomation chart and I spent ages typing all of this in by hand, so I\u2019m using\nit.\n\nHow much embodied knowledge is that? Can you get there with a better model? A\nmulti-modal agent? Multi-agent collaboration? Or, is it better to capture all\nof that embodied knowledge with a GUI, in a dedicated app or service of some\nkind, where the choices and options are pre-defined by someone who understands\ndata retrieval or taxes or parking ticket disputes? A GUI tells the users what\nthey can do, but it also tells the computer everything we already know about\nthe problem, and with a general-purpose, open-ended prompt, the user has to\nthink of all of that themselves, every single time, or hope it\u2019s already in\nthe training data. So, can the GUI itself be generative? Or do we need another\nwhole generation of Dan Bricklins to see the problem, and then turn it into\napps, thousands of them, one at a time, each of them with some LLM somewhere\nunder the hood?\n\nOn this basis, we would still have an orders of magnitude change in how much\ncan be automated, and how many use-cases can be found for LLMs, but they still\nneed to be found and built one by one. The change would be that these new use-\ncases would be things that are still automated one-at-a-time, but that could\nnot have been automated before, or that would have needed far more software\n(and capital) to automate. That would make LLMs the new SQL, not the new\nHAL9000.\n\n* Visicalc needed an Apple II with 32k of RAM, and including a floppy disk drive, printer and monitor, Apple\u2019s list price in 1979 was $2,875 (plus sales tax), which is around $12,000 in 2024 dollars.\n\nArtificial Intelligence, ProductivityBenedict Evans19 April 2024\n\n## Subscribe\n\nWhat mattered in tech this week?\n\nOnce a week, I send an email newsletter to over 150,000 people - what happened\nin tech that actually mattered, and what it means. I pick out the changes and\nideas you don\u2019t want to miss in all the noise, and give them context and\nanalysis.\n\nSubscribe\n\n\u00a9 Benedict Evans\n\nHours\n\nNewsletter\n\n2024\n\nWhat mattered in tech this week?\n\nOnce a week, I send a newsletter to 175,000 people - what happened in tech\nthat actually mattered, and what it means. I pick out the changes and ideas\nyou don\u2019t want to miss in all the noise, and give them context and analysis.\n\nSUBSCRIBE\n\n\u00a9 BENEDICT EVANS\n\nThis site uses cookies to function, and for anonymous analytics. You can read\nthe privacy policy here.\n\n", "frontpage": false}
