{"aid": "40140924", "title": "WebLlama: Building agents that can browse the web by following instructions", "url": "https://github.com/McGill-NLP/webllama", "domain": "github.com/mcgill-nlp", "votes": 1, "user": "xhlulu", "posted_at": "2024-04-24 05:28:39", "comments": 0, "source_title": "GitHub - McGill-NLP/webllama: Llama-3 agents that can browse the web by following instructions and talking to you", "source_text": "GitHub - McGill-NLP/webllama: Llama-3 agents that can browse the web by\nfollowing instructions and talking to you\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nMcGill-NLP / webllama Public\n\n  * Notifications\n  * Fork 11\n  * Star 313\n\nLlama-3 agents that can browse the web by following instructions and talking\nto you\n\nwebllama.github.io\n\n### License\n\nMIT license\n\n313 stars 11 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# McGill-NLP/webllama\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n1 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nxhlucaFix duplicate entry in config.yaml for training llamaApr 23, 202485dbf54\n\u00b7 Apr 23, 2024Apr 23, 2024\n\n## History\n\n7 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| Add files for pypi release (#1)| Apr 20, 2024  \n  \n### app\n\n|\n\n### app\n\n| Initial development (#2)| Apr 22, 2024  \n  \n### assets\n\n|\n\n### assets\n\n| Initial development (#2)| Apr 22, 2024  \n  \n### modeling\n\n|\n\n### modeling\n\n| Fix duplicate entry in config.yaml for training llama| Apr 23, 2024  \n  \n### webllama\n\n|\n\n### webllama\n\n| Add files for pypi release (#1)| Apr 20, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Ignore all of results| Apr 23, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Initial commit| Apr 19, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| Update README.md| Apr 22, 2024  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| Initial development (#2)| Apr 22, 2024  \n  \n### setup.py\n\n|\n\n### setup.py\n\n| Add files for pypi release (#1)| Apr 20, 2024  \n  \n## Repository files navigation\n\n# \ud83d\udda5\ufe0f WebLlama\ud83e\udd99\n\nBuilding agents that can browse the web by following instructions and talking\nto you\n\n\ud83d\udcbb GitHub| \ud83c\udfe0 Homepage| \ud83e\udd17 Llama-3-8B-Web  \n---|---|---  \n  \nImportant\n\nWe are thrilled to release Llama-3-8B-Web, the most capable agent built with \ud83e\udd99\nLlama 3 and finetuned for web navigation with dialogue. You can download the\nagent from the \ud83e\udd17 Huggingface Model Hub.\n\nWebLlama helps you build powerful agents, powered by Meta Llama 3, for\nbrowsing the web on your behalf| Our first model, Llama-3-8B-Web, surpasses\nGPT-4V (*zero-shot) by 18% on WebLINX  \n---|---  \n  \n## About the project\n\nWebLlama| The goal of our project is to build effective human-centric agents\nfor browsing the web. We don't want to replace users, but equip them with\npowerful assistants.  \n---|---  \nModeling| We are build on top of cutting edge libraries for training Llama\nagents on web navigation tasks. We will provide training scripts, optimized\nconfigs, and instructions for training cutting-edge Llamas.  \nEvaluation| Benchmarks for testing Llama models on real-world web browsing.\nThis include human-centric browsing through dialogue (WebLINX), and we will\nsoon add more benchmarks for automatic web navigation (e.g. Mind2Web).  \nData| Our first model is finetuned on over 24K instances of web interactions,\nincluding click, textinput, submit, and dialogue acts. We want to continuously\ncurate, compile and release datasets for training better agents.  \nDeployment| We want to make it easy to integrate Llama models with existing\ndeployment platforms, including Playwright, Selenium, and BrowserGym. We are\ncurrently focusing on making this a reality.  \n  \n## Modeling\n\nNote\n\nThe model is available on the \ud83e\udd17 Hugging Face Model Hub as McGill-\nNLP/Llama-3-8B-Web. The training and evaluation data is available on\nHuggingface Hub as McGill-NLP/WebLINX.\n\nOur first agent is a finetuned Meta-Llama-3-8B-Instruct model, which was\nrecently released by Meta GenAI team. We have finetuned this model on the\nWebLINX dataset, which contains over 100K instances of web navigation and\ndialogue, each collected and verified by expert annotators. We use a 24K\ncurated subset for training the data.\n\nIt surpasses GPT-4V (zero-shot *) by over 18% on the WebLINX benchmark,\nachieving an overall score of 28.8% on the out-of-domain test splits (compared\nto 10.5% for GPT-4V). It chooses more useful links (34.1% vs 18.9% seg-F1),\nclicks on more relevant elements (27.1% vs 13.6% IoU) and formulates more\naligned responses (37.5% vs 3.1% chr-F1).\n\nIt's extremely straightforward to use the model via Huggingface's\ntransformers, datasets and hub libraries:\n\n    \n    \n    from datasets import load_dataset from huggingface_hub import snapshot_download from transformers import pipeline # We use validation data, but you can use your own data here valid = load_dataset(\"McGill-NLP/WebLINX\", split=\"validation\") snapshot_download(\"McGill-NLP/WebLINX\", \"dataset\", allow_patterns=\"templates/*\") template = open('templates/llama.txt').read() # Run the agent on a single state (text representation) and get the action state = template.format(**valid[0]) agent = pipeline(\"McGill-NLP/Llama-3-8b-Web\") out = agent(state, return_full_text=False)[0] print(\"Action:\", out['generated_text']) # Here, you can use the predictions on platforms like playwright or browsergym action = process_pred(out['generated_text']) # implement based on your platform env.step(action) # execute the action in your environment\n\n## Evaluation\n\nWe believe short demo videos showing how well an agent performs is NOT enough\nto judge an agent. Simply put, we do not know if we have a good agent if we do\nnot have good benchmarks. We need to systematically evaluate agents on wide\nrange of tasks, spanning from simple instruction-following web navigation to\ncomplex dialogue-guided browsing.\n\nThis is why we chose WebLINX as our first benchmark. In addition to the\ntraining split, the benchmark has 4 real-world splits, with the goal of\ntesting multiple dimensions of generalization: new websites, new domains,\nunseen geographic locations, and scenarios where the user cannot see the\nscreen and relies on dialogue. It also covers 150 websites, including booking,\nshopping, writing, knowledge lookup, and even complex tasks like manipulating\nspreadsheets. Evaluating on this benchmark is very straightforward:\n\n    \n    \n    cd modeling/ # After installing dependencies, downloading the dataset, and training/evaluating your model, you can evaluate: python -m weblinx.eval # automatically find all `results.jsonl` and generate an `aggregated_results.json` file # Visualize your results with our app: cd .. streamlit run app/Results.py\n\n> \ud83d\udc77\u2640\ufe0f Next steps We are planning to evaluate our models on more benchmarks,\n> including Mind2Web, a benchmark for automatic web navigation. We believe\n> that a good agent should be able to navigate the web both through dialogue\n> and autonomously, and potentially attain even broader ranges of capabilities\n> useful for real-world web browsing.\n\n## Data\n\nAlthough the 24K training examples from WebLINX provide a good starting point\nfor training a capable agent, we believe that more data is needed to train\nagents that can generalize to a wide range of web navigation tasks. Although\nit has been trained and evaluated on 150 websites, there are millions of\nwebsites that has never been seen by the model, with new ones being created\nevery day.\n\nThis motivates us to continuously curate, compile and release datasets for\ntraining better agents. As an immediate next step, we will be incorporating\nMind2Web's training data into the equation, which also covers over 100\nwebsites.\n\n## Deployment\n\nWe are working hard to make it easy for you to deploy Llama web agents to the\nweb. We want to integrate WebLlama with existing deployment platforms,\nincluding Microsoft's Playwright, ServiceNow Research's BrowserGym, and other\npartners.\n\n## Code\n\nThe code for finetuning the model and evaluating it on the WebLINX benchmark\nis available now. You can find the detailed instructions in modeling.\n\n> \ud83d\udc77\u2640\ufe0f Next steps We are actively working on new data, evaluation, and\n> deployment integrations at the moment, so stay tuned!\n\n## Citation\n\nIf you use WebLlama in your research, please cite the following paper (upon\nwhich the data, training and evaluation are originally based on):\n\n    \n    \n    @misc{l\u00f92024weblinx, title={WebLINX: Real-World Website Navigation with Multi-Turn Dialogue}, author={Xing Han L\u00f9 and Zden\u011bk Kasner and Siva Reddy}, year={2024}, eprint={2402.05930}, archivePrefix={arXiv}, primaryClass={cs.CL} }\n\n## License\n\nThe code in this repository is licensed under the MIT license, unless\notherwise specified in the header of the file. Other materials (models, data,\nimages) have their own licenses, which are specified in the original pages.\n\n## FAQ\n\n### How can I contribute to the project?\n\nWe are actively looking for collaborators to help us build the best Llama-3\nweb agents! To get started, open an issue about what you would like to\ncontribute, and once it has been discussed, you can submit a pull request. We\nwill also soon be announcing a Discord channel for the project, where you can\nask questions and discuss with other contributors.\n\n## About\n\nLlama-3 agents that can browse the web by following instructions and talking\nto you\n\nwebllama.github.io\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\nActivity\n\nCustom properties\n\n### Stars\n\n313 stars\n\n### Watchers\n\n7 watching\n\n### Forks\n\n11 forks\n\nReport repository\n\n## Releases 1\n\n0.0.1pre1 Latest\n\nApr 20, 2024\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * Python 100.0%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
