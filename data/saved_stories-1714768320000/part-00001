{"aid": "40245769", "title": "A Minimal Model for Biological Evolution and Other Adaptive Processes", "url": "https://writings.stephenwolfram.com/2024/05/why-does-biological-evolution-work-a-minimal-model-for-biological-evolution-and-other-adaptive-processes/", "domain": "stephenwolfram.com", "votes": 2, "user": "simonpure", "posted_at": "2024-05-03 09:29:58", "comments": 0, "source_title": "Why Does Biological Evolution Work? A Minimal Model for Biological Evolution and Other Adaptive Processes", "source_text": "Why Does Biological Evolution Work? A Minimal Model for Biological Evolution\nand Other Adaptive Processes\u2014Stephen Wolfram Writings\n\n# Stephen Wolfram\n\nWritings\n\nRecent |\n\n  * Artificial Intelligence\n  * Big Picture\n  * Companies & Business\n  * Computational Science\n  * Computational Thinking\n  * Data Science\n  * Education\n  * Future Perspectives\n  * Historical Perspectives\n  * Language & Communication\n  * Life & Times\n  * Life Science\n  * Mathematica\n  * Mathematics\n  * New Kind of Science\n  * New Technology\n  * Personal Analytics\n  * Philosophy\n  * Physics\n  * Ruliology\n  * Software Design\n  * Wolfram|Alpha\n  * Wolfram Language\n  * Other\n\n|\n\nContents\n\n  * Top\n  * The Model\n  * The Multiway Graph of All Possible Mutation Histories\n  * The Fitness Landscape\n  * The Whole Space: Exhaustive Search vs. Adaptive Evolution\n  * The Issue of Undecidability\n  * Computation Theoretic Perspectives and Busy Beavers\n  * Probabilistic Approximations?\n  * Other Adaptive Evolution Strategies\n  * An Aside: Sexual Reproduction\n  * An Even More Minimal Model\n  * What Can Adaptive Evolution Achieve?\n  * What It Means for What\u2019s Going On in Biology\n  * Correspondence with Biological Phenomena\n  * Historical Notes\n  * Personal Notes\n  * Thanks\n\nWhy Does Biological Evolution Work? A Minimal Model for Biological Evolution\nand Other Adaptive Processes\n\n# Why Does Biological Evolution Work? A Minimal Model for Biological Evolution\nand Other Adaptive Processes\n\nMay 2, 2024\n\n## The Model\n\nWhy does biological evolution work? And, for that matter, why does machine\nlearning work? Both are examples of adaptive processes that surprise us with\nwhat they manage to achieve. So what\u2019s the essence of what\u2019s going on? I\u2019m\ngoing to concentrate here on biological evolution, though much of what I\u2019ll\ndiscuss is also relevant to machine learning\u2014but I\u2019ll plan to explore that in\nmore detail elsewhere.\n\nOK, so what is an appropriate minimal model for biology? My core idea here is\nto think of biological organisms as computational systems that develop by\nfollowing simple underlying rules. These underlying rules in effect correspond\nto the genotype of the organism; the result of running them is in effect its\nphenotype. Cellular automata provide a convenient example of this kind of\nsetup. Here\u2019s an example involving cells with 3 possible colors; the rules are\nshown on the left, and the behavior they generate is shown on the right:\n\nWe\u2019re starting from a single ( ) cell, and we see that from this \u201cseed\u201d a\nstructure is grown\u2014which in this case dies out after 51 steps. And in a sense\nit\u2019s already remarkable that we can generate a structure that neither goes on\nforever nor dies out quickly\u2014but instead manages to live (in this case) for\nexactly 51 steps.\n\nBut let\u2019s say we start from the trivial rule that makes any pattern die out\nimmediately. Can we end up \u201cadaptively evolving\u201d to the rule above? Imagine\nmaking a sequence of randomly chosen \u201cpoint mutations\u201d\u2014each changing just one\noutcome in the rule, as in:\n\nThen suppose that at each step\u2014in a minimal analog of natural selection\u2014we\n\u201caccept\u201d any mutation that makes the lifetime longer (though not infinite), or\nat least the same as before, and we reject any mutation that makes the\nlifetime shorter, or infinite. It turns out that with this procedure we can\nindeed \u201cadaptively evolve\u201d to the rule above (where here we\u2019re showing only\n\u201cwaypoints\u201d of progressively greater lifetime):\n\nDifferent sequences of random mutations give different sequences of rules. But\nthe remarkable fact is that in almost all cases it\u2019s possible to \u201cmake\nprogress\u201d\u2014and routinely reach rules that give long-lived patterns (here with\nlifetimes 107, 162 and 723) with elaborate morphological structure:\n\nIs it \u201cobvious\u201d that our simple process of adaptive evolution will be able to\nsuccessfully \u201cwrangle\u201d things to achieve this? No. But the fact that it can\nseems to be at the heart of why biological evolution manages to work.\n\nLooking at the sequences of pictures above we see that there are often in\neffect \u201cdifferent mechanisms\u201d for producing long lifetimes that emerge in\ndifferent sequences of rules. Typically we first see the mechanism in simple\nform, then as the adaptive process continues, the mechanism gets progressively\nmore developed, elaborated and built on\\\\[LongDash]not unlike what we often\nappear to see in the fossil record of biological evolution.\n\nBut let\u2019s drill down and look in a little more detail at what\u2019s happening in\nthe simple model we\u2019re using. In the 3-color nearest-neighbor (k = 3, r = 1)\ncellular automata we\u2019re considering, there are 26 (= 3^3 \u2013 1) relevant cases\nin the rule (there\u2019d be 27 if we didn\u2019t insist that ). \u201cPoint mutations\u201d\naffect a single case, changing it to one of two (= 3 \u2013 1) possible alternative\noutcomes\u2014so that there are altogether 52 (= 26 \u00d7 2) possible distinct \u201cpoint\nmutations\u201d that can be made to a given rule.\n\nFor example, starting from the rule\n\nthe results of possible single point mutations are:\n\nAnd even with such point mutations there\u2019s usually considerable diversity in\nthe behavior they generate:\n\nIn quite a few cases the pattern generated is exactly the same as the one for\nthe original rule. In other cases it dies out more quickly\u2014or it doesn\u2019t die\nout at all (either becoming periodic, or growing forever). And in this\nparticular example, in just one case it achieves \u201chigher fitness\u201d, surviving\nlonger.\n\nIf we make a sequence of random mutations, many will produce shorter-lived or\ninfinite lifetime (\u201ctumor\u201d) patterns, and these we\u2019ll reject (or, in\nbiological terms, we can imagine they\u2019re \u201cselected out\u201d):\n\nBut still there can be many \u201cneutral mutations\u201d that don\u2019t change the final\npattern (or at least give a pattern of the same length). And at first we might\nthink that these don\u2019t achieve anything. But actually they\u2019re critical in\nallowing single point mutations to build up to larger mutations that can\neventually give longer-lived patterns:\n\nTracing our whole adaptive evolution process above, the total number of point\nmutations involved in getting from one (increasingly long-lived) \u201cfitness\nwaypoint\u201d to another is:\n\nHere are the underlying rules associated with these fitness waypoints (where\nthe numbers count \u201ccumulative\u201d mutations, ignoring ones that go \u201cback and\nforth\u201d)\n\nwhere we\u2019re indicating here the number of actual \u201caccepted mutations\u201d between\nthese \u201cwaypoint rules\u201d.\n\nOne way to get a sense of what\u2019s going on is to take the whole sequence of\n(\u201caccepted\u201d) rules in the adaptive evolution process, and plot them in a\ndimension-reduced rendering of the (27-dimensional) rule space:\n\nThere are periods where there\u2019s a lot of \u201cwandering around\u201d going, with many\nmutations needed to \u201cmake progress\u201d. And there are other periods when things\ngo much faster, and fewer mutations are needed.\n\nAs another way to see what\u2019s going on, we can plot the maximum lifetime\nachieved so far against the total number of mutation steps made:\n\nWe see plateaus (including an extremely long one) in which \u201cno progress\u201d is\nmade, punctuated by sometimes-quite-large, sudden changes, often brought on by\njust a single mutation.\n\nIf we include \u201crejected mutations\u201d we see that there\u2019s a lot of activity going\non even in the plateaus; it just doesn\u2019t manage to make progress (one can\nthink of each red dot that lies below a plateau as being like a mutation\u2014or an\norganism\u2014that \u201cdoesn\u2019t make it\u201d, and is selected out):\n\nIt\u2019s worth noting that there can be multiple different (\u201cphenotype\u201d) patterns\nthat occur across a plateau. Here\u2019s what one sees in the particular example\nwe\u2019re considering:\n\nBut even between these \u201cphenotypically different\u201d cases, there can be many\n\u201cgenotypically different\u201d rules. And in a sense this isn\u2019t surprising, because\nusually only parts of the underlying rule are \u201ccoding\u201d; other parts are\n\u201cnoncoding\u201d, in the sense that they\u2019re not sampled during the generation of\nthe pattern from that rule.\n\nAnd for example this highlights for each \u201cfitness waypoint rule\u201d which cells\nmake use of a \u201cfresh\u201d case in the rule that hasn\u2019t so far been sampled during\nthe generation of the pattern:\n\nAnd we see that even in the last rule shown here, only 18 of the 26 relevant\ncases in the rule are actually ever sampled during the generation of the\npattern (from the particular, single-red-cell initial condition used). So this\nmeans that 8 cases in the rule are \u201cundetermined\u201d from the phenotype, implying\nthat there are 3^8 = 6561 possible genotypes (i.e. rules) that will give the\nsame result.\n\nSo far we\u2019ve mostly been talking about one particular random sequence of\nmutations. But what happens if we look at many possible such sequences? Here\u2019s\nhow the longest lifetime (or, in effect, \u201cfitness\u201d) increases for 100\ndifferent sequences of random mutations:\n\nAnd what\u2019s perhaps most notable here is that it seems as if these adaptive\nprocesses indeed don\u2019t \u201cget stuck\u201d. It may take a while (with the result that\nthere are long plateaus) but these pictures suggest that eventually \u201cadaptive\nevolution will find a way\u201d, and one will get to rules that show longer\nlifetimes\u2014as the progressive development of the distribution of lifetimes\nreflects:\n\n## The Multiway Graph of All Possible Mutation Histories\n\nIn what we\u2019ve done so far we\u2019ve always been discussing particular paths of\nadaptive evolution, determined by particular sequences of random mutations.\nBut a powerful way to get a more global view of the process of adaptive\nevolution is to look\u2014in the spirit of our Physics Project, the ruliad,\netc.\u2014not just at individual paths of adaptive evolution, but instead at the\nmultiway graph of all possible paths. (And in making a correspondence with\nbiology, multiway graphs give us a way to talk about adaptive evolution not\njust of individual sequences of organisms, but also populations.)\n\nTo start our discussion, let\u2019s consider not the 3-color cellular automata of\nthe previous section, but instead (nearest-neighbor) 2-color cellular\nautomata\u2014for which there are just 128 possible relevant rules. How are these\nrules related by point mutations? We can construct a graph of every possible\nway that one rule from this set can be transformed to another by a single\npoint mutation:\n\nIf we imagine 5-bit rather than 7-bit rules, there are only 16 relevant ones,\nand we can readily see that the graph of possible mutations has the form of a\nBoolean hypercube:\n\nLet\u2019s say we start from the \u201cnull rule\u201d . Then we enumerate the rules obtained\nby a single point mutation (and therefore directly connected to the null rule\nin the graph above)\u2014then we see what behavior they produce, say from the\ninitial condition ......:\n\nSome of these rules we can view as \u201cmaking progress\u201d, in the sense that they\nyield patterns with longer lifetimes (not impressively longer, just 2 rather\nthan 1). But other rules \u201cmake no progress\u201d or generate patterns that \u201clive\nforever\u201d. Keeping only mutations that don\u2019t lead to shorter or infinite\nlifetimes, we can construct a multiway graph that shows all possible mutation\npaths:\n\nAlthough this is a very small graph (with just 15 rules appearing), we can\nalready see hints of some important phenomena. There are \u201cfitness-neutral\u201d\nmutations that can \u201cgo both ways\u201d. But there are also plenty of mutations that\nonly \u201cgo one way\u201d\u2014because the other way they would decrease fitness. And a\nnotable feature of the graph is that once one\u2019s \u201ccommitted\u201d to a particular\npart of the graph, one often can\u2019t reach a different one\u2014suggesting an analogy\nto the existence of distinct branches in the tree of life.\n\nMoving beyond 2-color, nearest-neighbor (k = 2, r = 1) cellular automata, we\ncan consider k = 2, r = ones. A typical such cellular automaton is:\n\nFor k = 2, r = 1 there were a total of 128 (= 2^2^3 \u2013 1) relevant rules. For k\n= 2, r = , there are a total of 32,768 (= 2^2^4 \u2013 1). Starting with the null\nrule, and again using initial condition ......, here are a few specific\nexamples of adaptive evolution paths for such cellular automata:\n\nAnd here is the beginning of the multiway graph for k = 2, r = rules\u2014showing\nrules reached by up to two mutations starting from the null rule:\n\nThis graph contains many examples of \u201cfitness-neutral sets\u201d\u2014rules that have\nthe same fitness and that can be transformed into each other by mutations. A\nfew examples of such fitness-neutral sets:\n\nIn the first case here, the \u201cmorphology of the phenotypic patterns\u201d is the\nsame for all \u201cgenotypic rules\u201d in the fitness-neutral set. But in the other\ncases there are multiple morphologies within a single fitness-neutral set.\n\nIf we included all individual rules we\u2019d get a complete k = 2, r = multiway\ngraph with a total of 1884 nodes. But if we just include one representative\nfrom every fitness-neutral set, we get a more manageable multiway graph, with\na total of 86 nodes:\n\nKeeping only one representative from pairs of patterns that are related by\nleft-right symmetry, we get a still-simpler graph, now with a total of 49\nnodes:\n\nThere\u2019s quite a lot of structure in this graph, with both divergence and\nconvergence of possible paths. But overall, there\u2019s a certain sense that\ndifferent sections of the graph separate into distinct branches in which\nadaptive evolution in effect \u201cpursues different ideas\u201d about to how increase\nfitness (i.e. lifetime of patterns).\n\nWe can think of fitness-neutral sets as representing a certain kind of\nequivalence class of rules. There\u2019s quite a range of possible structures to\nthese sets\u2014from ones with a single element to ones with many elements but few\ndistinct morphologies, to ones with different morphologies for every element:\n\nWhat about larger spaces of rules? For k = 2, r = 2 there are altogether about\n2 billion (2^2^5 \u2013 1) relevant rules. But if we choose to look only at left-\nright symmetric ones, this number is reduced to 524,288 (= 2^19). Here are\nsome examples of sequences of rules produced by adaptive evolution in this\ncase, starting from the null rule, and allowing only mutations that preserve\nsymmetry (and now using a single black cell as the initial condition):\n\nOnce again we can identify fitness-neutral sets\u2014though this time, in the vast\nmajority of cases, the patterns generated by all members of a given set are\nthe same:\n\nReducing out fitness-neutral sets, we can then compute the complete\n(transitively reduced) multiway graph for symmetric k = 2, r = 2 rules\n(containing a total of 60 nodes):\n\nBy reducing out fitness-neutral sets, we\u2019re creating a multiway graph in which\nevery edge represents a mutation that \u201cmakes progress\u201d in increasing fitness.\nBut actual paths of adaptive evolution based on random sequences of mutations\ncan do any amount of \u201crattling around\u201d within fitness-neutral sets\u2014not to\nmention \u201ctrying\u201d mutations that decrease fitness\u2014before reaching mutations\nthat \u201cmake progress\u201d. So this means that even though the reduced multiway\ngraph we\u2019ve drawn suggests that the maximum number of steps (i.e. mutations)\nneeded to adaptively evolve from the null rule to any other is 9, it can\nactually take any number of steps because of the \u201crattling around\u201d within\nfitness-neutral sets.\n\nHere\u2019s an example of a sequence of accepted mutations in a particular adaptive\nevolution process\u2014with the mutations that \u201cmake progress\u201d highlighted, and\nnumbers indicating rejected mutations:\n\nWe can see \u201crattling around\u201d in a fitness-neutral set, with a cycle of\nmorphologies being generated. But while this represents one way to reach the\nfinal pattern, there are also plenty of others, potentially involving many\nfewer mutations. And indeed one can determine from the multiway graph that an\nabsolutely shortest path is:\n\nThis involves the sequence of rules:\n\nWe\u2019re starting from the null rule, and at each step making a single point\nmutation (though because of symmetry two bits can sometimes be changed). The\nfirst few mutations don\u2019t end up changing the \u201cphenotypic behavior\u201d. But after\na while, enough mutations (here 6) have built up that we get morphologically\ndifferent behavior. And after just 3 more mutations, we end up with our final\npattern.\n\nOur original random sequence of mutations gets to the same result, but in a\nmuch more tortuous way, doing a total of 169 mutations which often cancel each\nother out:\n\nIn drawing a multiway graph, we\u2019re defining what evolutionary paths are\npossible. But what about probabilities? If we assume that every point mutation\nis equally likely, we can in effect \u201canalyze the flow\u201d in the multiway graph,\nand determine the ultimate probability that each rule will be reached:\n\n## The Fitness Landscape\n\nMultiway graphs give a very global view of adaptive evolution. But in\nunderstanding the process of adaptive evolution, it\u2019s also often useful to\nthink somewhat more locally. We can imagine that all the possible rules are\nlaid out in a certain space, and that adaptive evolution is trying to find\nappropriate paths in this space. Potentially we can suppose that there\u2019s a\n\u201cfitness landscape\u201d defined in the space, and that adaptive evolution is\ntrying to follow a path that progressively ascends to higher peaks of fitness.\n\nLet\u2019s consider again the very first example we gave above\u2014of adaptive\nevolution in the space of 3-color cellular automata. At each step in this\nadaptive evolution, there are 52 possible point mutations that can be made to\nthe rule. And one can think of each of these mutations as corresponding to\nmaking an \u201celementary move\u201d in a different direction in the (26-dimensional)\nspace of rules.\n\nHere\u2019s a visual representation of what\u2019s going on, based on the particular\npath of adaptive evolution from our very first example above:\n\nWhat we\u2019re showing here is in effect the sequence of \u201cdecisions\u201d that are\nbeing made to get us from one \u201cfitness waypoint\u201d to another. Different\npossible mutations are represented by different radial directions, with the\nlength of each line being proportional to the fitness achieved by doing that\nmutation. At each step the gray disk represents the previous fitness. And what\nwe see is that many possible mutations lead to lower fitness outcomes, shown\n\u201cwithin the disk\u201d. But there are at least some mutations that have higher\nfitness, and \u201cescape the disk\u201d.\n\nIn the multiway graph, we\u2019d trace every mutation that leads to higher fitness.\nBut for a particular path of adaptive evolution as we\u2019ve discussed it so far,\nwe imagine we always just pick at random one mutation from this set\u2014as\nindicated here by a red line. (Later we\u2019ll discuss different strategies.)\n\nOur radial icons can be thought of as giving a representation of the \u201clocal\nderivative\u201d at each point in the space of rules, with longer lines\ncorresponding to directions with larger slopes \u201cup the fitness landscape\u201d.\n\nBut what happens if we want to \u201cknit together\u201d these local derivatives to form\na picture of the whole space? Needless to say, it\u2019s complicated. And as a\nfirst example, consider k = 2, r = 1 cellular automaton rules.\n\nThere are a total of 128 relevant such rules, that (as we discussed above) can\nbe thought of as connected by point mutations to form on a 7-dimensional\nBoolean hypercube. As also discussed above, of all 128 relevant rules, only 15\nappear in adaptive evolution processes (the others are in effect never\nselected because they represent lower fitness). But now we can ask where these\nrules lie on the whole hypercube:\n\nEach node here represents a rule, with the size of the highlighted nodes\nindicating their corresponding fitness (computed from lifetime with initial\ncondition ......). The node shown in green corresponds to the null rule.\n\nRendering this in 3D, with fitness shown as height, we get what we can\nconsider a \u201cfitness landscape\u201d:\n\nAnd now we can think of our adaptive evolution as proceeding along paths that\nnever go to nodes with lower height on this landscape.\n\nWe get a more filled-in \u201cfitness landscape\u201d when we look at k = 2, r = rules\n(here with initial condition ......):\n\nAdaptive evolution must trace out a \u201cnever-go-down\u201d path on this landscape:\n\nAlong this path, we can make \u201cderivative\u201d pictures like the ones above to\nrepresent \u201clocal topography\u201d around each point\u2014indicating which of the\npossible upwards-on-the-landscape directions is taken:\n\nThe rule space over which our \u201cfitness landscape\u201d is defined is ultimately\ndiscrete and effectively very high-dimensional (15-dimensional for k = 2, r =\nrules)\u2014and it\u2019s quite challenging to produce an interpretable visualization of\nit in 3D. We\u2019d like it if we could lay out our rendering of the rule space so\nthat rules which differ just by one mutation are a fixed (\u201celementary\u201d) 2D\ndistance apart. In general this won\u2019t be possible, but we\u2019re trying to at\nleast approximate this by finding a good layout for the underlying \u201cmutation\ngraph\u201d.\n\nUsing this layout we can in principle make a \u201cfitness landscape surface\u201d by\ninterpolating between discrete points. It\u2019s not clear how meaningful this is,\nbut it\u2019s perhaps useful in engaging our spatial intuition:\n\nWe can try machine learning and dimension reduction, operating on the set of\n\u201crule vectors\u201d (i.e. outcome lists) that won\u2019t be rejected in our adaptive\nevolution process\u2014and the results are perhaps slightly better:\n\nBy the way, if we use this dimension reduction for rule space, here\u2019s how the\nbehavior of rules lays out:\n\nAnd here, for comparison, is a feature space plot based on the visual\nappearance of these patterns:\n\n## The Whole Space: Exhaustive Search vs. Adaptive Evolution\n\nIn adaptive evolution, we start, say, from the null rule and then make random\nmutations to try to reach rules with progressively larger fitness. But what\nabout just exhaustively searching the complete space of possible rules? The\nnumber of rules rapidly becomes unmanageably big\u2014but some cases are definitely\naccessible:\n\nFor example, there are just 524,288 symmetric k = 2, r = 2 rules\u2014of which\n77,624 generate phenotypic patterns with finite lifetimes. Ultimately, though,\nthere are just 77 distinct patterns that appear, with varying multiplicity\n(which at least in this case is always associated with \u201cunused bits\u201d in the\nrule):\n\nHow do these exhaustive results compare with what\u2019s generated in the multiway\ngraph of adaptive evolutions? They\u2019re almost the same, but for the addition of\nthe two cases\n\nwhich are generated by rules of the form (where the gray entries don\u2019t\nmatter):\n\nWhy don\u2019t such rules ever appear in our adaptive evolution? The reason is that\nthere isn\u2019t a chain of point mutations starting from the null rule that can\nreach these rules without going through rules that would be rejected by our\nadaptive evolution process. If we draw a multiway graph that includes every\npossible \u201cacceptable\u201d rule, then we\u2019ll see a separate part in the graph, with\nits own root, that contains rules that can\u2019t be reached by our adaptive\nevolution from the null rule:\n\nSo now if we look at all (symmetric k = 2, r = 2) rules, here\u2019s the\ndistribution of lifetimes we get:\n\n<\n\nThe maximum, as seen above, is 65. The overall distribution roughly follows a\npower law, with an exponent around \u20133:\n\nAs we saw above, not all rules make use of all their bits (i.e. outcomes) in\ngenerating phenotypic patterns. But what we see is that the larger the\nlifetime achieved, the more bits tend to be needed:\n\nAnd in a sense this isn\u2019t surprising: as we\u2019ll discuss later, we can expect to\nneed \u201cmore bits in the program\u201d to specify more elaborate behavior\u2014or, in\nparticular, behavior that embodies a larger number for lifetime.\n\nSo what about general k = 2, r = 2 rules? There are 2^31 \u2245 2 billion of these.\nIf we exhaustively search through them, we find about 75 million that have\nfinite lifetimes. The distribution of these lifetimes is:\n\nAgain it\u2019s roughly a power law, but with exponent around \u20133.5:\n\nHere are the actual 100 patterns produced that have the longest lifetimes (in\nall asymmetric cases there are also rules giving left-right flipped patterns):\n\nIt\u2019s interesting to see here a variety of \u201cqualitatively different ideas\u201d\nbeing used by different rules. Some (like the one with lifetime 151) we might\nsomehow imagine could have been constructed specifically \u201cfor the purpose\u201d of\nhaving their particular, long lifetime. But others (like the one with lifetime\n308) somehow seem more \u201ccoincidental\u201d\u2014behaving in an apparently random way,\nand then just \u201chappening to die out\u201d after a certain number of steps.\n\nSince we found these rules by exhaustive search, we know they\u2019re the only\npossible ones with such long lifetimes (at least with k = 2, r = 2). So then\nwe can infer that the ornate structures we see are in some sense necessary to\nachieve the objective of, say, having a finite lifetime of more than 100\nsteps. So that means that if we go through a process of adaptive evolution and\nachieve a lifetime above 100 steps, we see a complex pattern of behavior not\nbecause of \u201ccomplicated choices in our process of adaptive evolution\u201d, but\nrather because to achieve such a lifetime one has no choice but to use such a\ncomplex pattern. Or, in other words, the complexity we see is a reflection of\n\u201ccomputational necessity\u201d, not historical accidents of adaptive evolution.\n\nNote also that (as we\u2019ll discuss in more detail below) there are certain\nbehaviors we can get, and others that we cannot. So, for example, there is a\nrule that gives lifetime 308, but none that gives lifetime 300. (Though, yes,\nif we used more complicated initial conditions or a more complicated family of\nrules we could find such a rule.)\n\nMuch as we saw in the symmetric k = 2, r = 2 case above, almost any long\nlifetimes require using all the available bits in the rule:\n\n<\n\nBut, needless to say, there\u2019s an exception\u2014a pair of rules with lifetime 84\nwhere the outcome for the case doesn\u2019t matter:\n\nBut, OK, so can these long-lifetime rules be reached by single-mutation\nadaptive evolution from the null rule? Rather than trying to construct the\nwhole multiway graph for the general k = 2, r = 2 case starting from the null\nrule, we can instead construct what\u2019s in effect an inverse multiway graph in\nwhich we start from a given rule, then successively make all single point\nmutations that reach rules with progressively shorter lifetimes:\n\nAnd what we see is that at least in this case such a procedure never reaches\nthe null rule. The \u201cfurthest\u201d it gets is to lifetime-2 rules, and among these\nrules the closest to the null rule are:\n\nBut it turns out that there\u2019s no way to reach these 2-bit rules by a single\npoint mutation from any of the 26 1-bit rules that aren\u2019t rejected by our\nadaptive evolution process. And in fact this isn\u2019t just an issue for this\nparticular long-lifetime rule: it turns out that it\u2019s something quite general\namong k = 2 rules. Constructing the \u201cforward\u201d multiway graph starting from the\nnull rule, we find we can only ever reach lifetime-1 rules.\n\nUltimately this is a particular feature of rules with just 2 colors\u2014it\u2019s\nspecific to starting with something like the null rule that has lifetime 1\u2014but\nit\u2019s an illustration of the fact that there can even be large swaths of rule\nspace that can\u2019t be reached by adaptive evolution with single point mutations.\n\nWhat about symmetric k = 2, r = 2 rules? Well, to maintain symmetry we have to\ndeal with mutations that change not just one but two bits. And the result of\nthis is that (except in the cases we discovered above) the inverse multiway\nsystem starting from long-lifetime rules always successfully reaches the null\nrule:\n\nThere\u2019s something else to notice here, however. Looking at this graph, we see\nthat there\u2019s a way to get with just one 2-bit mutation from a lifetime-1 to a\nlifetime-65 rule:\n\nWe didn\u2019t see this in our multiway graph above because we had applied\ntransitive reduction to it. But if we don\u2019t do that, we find that there are a\nfew large lifetime jumps\u2014visible on this plot of possible lifetimes before and\nafter a single point mutation:\n\nGoing beyond k = 2, r = 2 rules, we can consider symmetric k = 3, r = 1 rules,\nof which there are 3^17, or about 129 million. The distribution of lifetimes\nin this case is\n\nwhich again roughly fits a power law, again with exponent around \u20133.5:\n\nBut now the maximum lifetime found is not just 308, but 2194:\n\nOne again, there are some different \u201cideas\u201d on display, with a few curious\nexamples of convergence\u2014such as the rules we see with lifetimes 989 and 990\n(as well as 1068 and 1069) which give essentially the same patterns after just\nexchanging colors, and one step of \u201cprefatory\u201d behavior.\n\nWhat about general k = 3, r = 1 rules? There are too many to easily search\nexhaustively. But directed random sampling reveals plenty of long-lifetime\nexamples, such as:\n\nAnd now the tail of very long lifetimes extends further, for example with:\n\nIt\u2019s a little easier to see what the lifetime-10863 rule does if one\nvisualizes it in sections (and changes colors to get more contrast):\n\nSampling 100 steps out every 2000 (as well as at the very end), we see\nelaborate alternation between periodic and seemingly random behavior\u2014but none\nof it gives any clue of the remarkable fact that after 10863 steps the whole\npattern will die out:\n\n## The Issue of Undecidability\n\nAs our example criterion for the \u201cfitness\u201d of cellular automaton rules, we\u2019ve\nused the lifetimes of the patterns they generate\u2014always assuming that if the\npatterns don\u2019t terminate at all they should be considered to have fitness\nzero.\n\nBut how can we tell if a pattern is going to terminate? In the previous\nsection, for example, we saw patterns that live a very long time\u2014but do\neventually terminate.\n\nHere are some examples of the first 100 steps of patterns generated by a few k\n= 3, r = 1 symmetric rules:\n\nWhat will happen with these patterns? We know from what we see here that none\nof them have lifetimes less than 100 steps. But what would allow us to say\nmore? In a few cases we can see that the patterns are periodic, or have\nobvious repeating structures, which means they\u2019ll never terminate. But in the\nother cases there\u2019s no obvious way to predict what will happen. Explicitly\nrunning the rules for another 100 steps we discover some more outcomes:\n\nGoing to 500 steps there are some surprises. Rule (a) becomes periodic after\n388 steps; rules (o) and (v) terminate after 265 and 377 steps, respectively:\n\nBut is there a way to systematically say what will happen with all the\nremaining rules \u201cin the end\u201d? The answer is that in general there is not; it\u2019s\nsomething that must be considered undecidable by any finite computation.\n\nGiven how comparatively simple the cellular automaton rules we\u2019re considering\nare, we might have assumed that with all our sophisticated mathematical and\ncomputational methods we\u2019d always be able to \u201cjump ahead of them\u201d\u2014and figure\nout their outcome without the computational effort of explicitly running each\nstep.\n\nBut the Principle of Computational Equivalence suggests that pretty much\nwhenever the behavior of these rules isn\u2019t obviously simple, it will in effect\nbe of equal computational sophistication to any other system, and in\nparticular to any methods that we might use to predict it. And the result is\nthe phenomenon of computational irreducibility that implies that in many\nsystems\u2014presumably including most of the cellular automata here\u2014there isn\u2019t\nany way to figure out their outcome much more efficiently than by explicitly\ntracing each of their steps. So this means that to know what will happen \u201cin\nthe end\u201d\u2014after an infinite number of steps\u2014might take an unlimited amount of\ncomputational effort. Or, in other words, it must be considered effectively\nundecidable by any finite computation.\n\nAs a practical matter we might look at the observed distribution of lifetimes\nfor a particular type of cellular automaton, and become pretty confident that\nthere won\u2019t be longer finite lifetimes for that type of cellular automaton.\nBut for the k = 3, r = 1 rules from the previous section, we might have been\nfairly confident that a few thousand steps was the longest lifetime that would\never occur\u2014until we discovered the 10,863-step example.\n\nSo let\u2019s say we run a particular rule for 10,000 steps and it hasn\u2019t died out.\nHow can we tell if it never will? Well, we have to construct a proof of some\nkind. And that\u2019s easy to do if we can see that the pattern becomes, say,\ncompletely periodic. But in general, computational irreducibility implies we\nwon\u2019t be able to do it. Might there, though, still be special cases where we\ncan? In effect, those would have to correspond to \u201cpockets of computational\nreducibility\u201d where we manage to find a compressed description of the cellular\nautomaton behavior.\n\nThere are cases like this where there isn\u2019t strict periodicity, but where in\nthe end there\u2019s basically repetitive behavior (here with period 480):\n\nAnd there are cases of nested behavior, which is never periodic, but is\nnevertheless simple enough to be predictable:\n\nBut there are always surprises. Like this example\u2014which eventually resolves to\nhave period 6, but only after 7129 steps:\n\nSo what does all this mean for our adaptive evolution process? It implies that\nin principle we could miss a very long finite lifetime for a particular rule,\nassuming it to be infinite. In a biological analogy we might have a genome\nthat seems to lead to unbounded perhaps-tumor-like growth\u2014but where actually\nthe growth in the end \u201cunexpectedly\u201d stops.\n\n## Computation Theoretic Perspectives and Busy Beavers\n\nWhat we\u2019re asking about the dying out of patterns in cellular automata is\ndirectly analogous to the classic halting problem for Turing machines, or the\ntermination problem for term rewriting, Post tag systems, etc. And in looking\nfor cellular automata that have the longest-lived patterns, we\u2019re studying a\ncellular automaton analog of the so-called busy beaver problem for Turing\nmachines.\n\nWe can summarize the results we\u2019ve found so far (all for single-cell initial\nconditions):\n\nThe profiles (i.e. widths of nonzero cells) for the patterns generated by\nthese rules are\n\nand the \u201cintegrals\u201d of these curves are what give the \u201careas\u201d in the table\nabove.\n\nFor the reasons described in the previous section, we can only be certain that\nwe\u2019ve found lower bounds on the actual maximum lifetime\u2014though except in the\nlast few cases listed it seems very likely that we do in fact have the maximum\nlifetime.\n\nIt\u2019s somewhat sobering, though, to compare with known results for maximum\n(\u201cbusy beaver\u201d) lifetimes for Turing machines (where now s is the number of\nTuring machine states, the Turing machines are started from blank tapes, and\nthey are taken to \u201chalt\u201d when they reach a particular halt state):\n\nSufficiently small Turing machines can have only modest lifetimes. But even\nslightly bigger Turing machines can have vastly larger lifetimes. And in fact\nit\u2019s a consequence of the undecidability of the halting problem for Turing\nmachines that the maximum lifetime grows with the size of the Turing machine\nfaster than any computable function (i.e. any function that can be computed in\nfinite time by a Turing machine, or whose value can be proved by a finite\nproof in a finite axiom system).\n\nBut, OK, the maximum lifetime increases with the \u201csize of the rule\u201d used in a\nTuring machine, or a cellular automaton. But what defines the \u201csize of a\nrule\u201d? Presumably it should be roughly the number of independent bits needed\nto specify the rule (which we can also think of as an approximate measure of\nits \u201cinformation content\u201d)\u2014or something like log_2 of the number of possible\nrules of its type.\n\nAt the outset, we might imagine that all 2^32 k = 2, r = 2 rules would need 32\nbits to specify them. But as we discussed above, in some cases some of the\nbits in the rule don\u2019t matter when it comes to determining the patterns they\nproduce. And what we see is that the more bits that matter (and so have to be\nspecified), the longer the lifetimes that are possible:\n\nSo far we\u2019ve only been discussing cellular automata with single-cell initial\nconditions. But if we use more complicated initial conditions what we\u2019re\neffectively doing is adding more information content into the system\u2014with the\nresult that maximum lifetimes can potentially get larger. And as an example,\nhere are possible lifetimes for k = 2, r = rules with a sequence of possible\ninitial conditions:\n\n## Probabilistic Approximations?\n\nCellular automata are at their core deterministic systems: given a particular\ncellular automaton rule and a particular initial condition, every aspect of\nthe behavior that is generated is completely determined. But is there any way\nthat we can approximate this behavior by some probabilistic model? Or might we\nat least usefully be able to use such a model if we look at the aggregate\nproperties of large numbers of different rules?\n\nOne hint along these lines comes from the power-law distributions we found\nabove for the frequencies of different possible lifetimes for cellular\nautomata of given types. And we might wonder whether such distributions\u2014and\nperhaps even their exponents\u2014could be found from some probabilistic model.\n\nOne possible approach is to approximate a cellular automaton by a\nprobabilistic process\u2014say one in which a cell becomes black with probability p\nif it or either of its neighbors were black on the step before. Here are some\nexamples of what can happen with this (\u201cdirected percolation\u201d) setup:\n\nThe behavior varies greatly with p; for small p everything dies out, while for\nlarge p it fills in:\n\nAnd indeed the final density\u2014starting from random initial conditions\u2014has a\nsharp (phase) transition at around p = 0.54 as one varies p:\n\nIf instead one starts from a single initial black cell one sees a slightly\ndifferent transition:\n\nOne can also plot the probabilities for different \u201csurvival times\u201d or\n\u201clifetimes\u201d for the pattern:\n\nAnd right around the transition the distribution of lifetimes follows a power\nlaw\u2014that\u2019s roughly \u03c4^\u20131 (which happens to be what one gets from a mean field\ntheory estimate).\n\nSo how does this relate to cellular automata? Let\u2019s say we have a k = 2 rule,\nand we suppose that the colors of cells can be approximated as somehow random.\nThen we might suppose that the patterns we get could be like in our\nprobabilistic model. And a potential source for the value of p to use would be\nthe fraction of cases in the rule that give a black cell as output.\n\nPlotting the lifetimes for k = 2, r = 2 rules against these fractions, we see\nthat the longest lifetimes do occur when a little under half the outcomes are\nblack (though notice this is also where the binomial distribution implies the\nlargest number of rules are concentrated):\n\nIf we don\u2019t try thinking about the details of cellular automaton evolution,\nbut instead just consider the boundaries of finite-lifetime patterns we\ngenerate, we can imagine approximating these (say for symmetric rules) just by\nrandom walks\u2014that when they collide correspond to the pattern dying out:\n\nThe standard theory of random walks then tells us that the probability to\nsurvive \u03c4 steps is proportional to \u03c4^\u20133/2 for large \u03c4\u2014a power law, though not\nimmediately the same one as we\u2019ve observed for our cellular automaton\nlifetimes.\n\n## Other Adaptive Evolution Strategies\n\nIn what we\u2019ve done so far, we\u2019ve always taken each step of our process of\nadaptive evolution to pick an outcome of equal or greater fitness. But what if\nwe adopt a \u201cmore impatient\u201d procedure in which at each step we insist on an\noutcome that has strictly greater fitness?\n\nFor k = 2 it\u2019s simply not possible with this procedure (at least with a null\ninitial condition) to \u201cescape\u201d the null rule; everything that can be reached\nwith 1 mutation still has lifetime 1. With k = 3 it\u2019s possible to go one step,\nbut only one, as captured by this multiway graph:\n\nBut we\u2019re assuming here that we have to reach greater fitness with just one\nmutation. What if we allow two mutations at a time? Well, then we can \u201cmake\nprogress\u201d. And here\u2019s the multiway graph in this case for symmetric k = 2, r =\n2 rules:\n\nWe don\u2019t reach as many phenotypic patterns as by using single mutations and\nallowing \u201cfitness-neutral moves\u201d, but where we do get, we get much quicker,\nwithout any \u201cback and forth\u201d in fitness-neutral spaces.\n\nIf we allow up to 3 mutations, we get still further:\n\nAnd indeed we seem to get a pretty good representative sampling of \u201cwhat\u2019s out\nthere\u201d in this rule space, even though we reach only 37 rules, compared to the\n77,624 (albeit with many duplicated phenotypic patterns) from our standard\napproach allowing neutral moves.\n\nFor k = 3, r = 1 symmetric rules single mutations can get 2 steps:\n\nBut now if we allow up to 2 mutations, we can go much further\u2014and the fact\nthat we now don\u2019t have to deal with neutral moves means we can explicitly\nconstruct at least the first few steps of the multiway graph in this case:\n\nWe can go further if at each step we just pick a random higher-fitness rule\nreached with two or fewer mutations:\n\nThe adaptive evolution histories we just showed can be generated in effect by\nrandomly trying a series of possibilities at each step, then picking the first\none that shows increased fitness. Another approach is to use what amounts to\n\u201clocal exhaustive search\u201d: at each step, look at results from all possible\nmutations, and pick one that gives the largest fitness. At least in smaller\nrule spaces, it\u2019s common that there will be several results with the same\nfitness, and as an example we\u2019ll just pick among these at random:\n\nOne might think that this approach would in effect always be an optimization\nof the adaptive evolution process. But in practice its systematic character\ncan end up making it get stuck, in some sense repeatedly \u201ctrying to do the\nsame thing\u201d even if it \u201cisn\u2019t working\u201d.\n\nSomething of an opposite approach involves loosening our criteria for which\npaths can be chosen\u2014and for example allowing paths that temporarily reduce\nfitness, say by one step of lifetime:\n\nIn effect here we\u2019re allowing less-than-maximally-fit organisms to survive.\nAnd we can represent the overall structure of what\u2019s happening by a multiway\ngraph\u2014which now includes \u201cbacktracking\u201d to lower fitnesses:\n\nBut although the details are different, in the end it doesn\u2019t seem as if\nallowing this kind of backtracking has any dramatic effect. Somehow the basic\nphenomena around the process of adaptive evolution are strong enough that most\nof the details of how the adaptive evolution is done don\u2019t ultimately matter\nmuch.\n\n## An Aside: Sexual Reproduction\n\nIn everything we\u2019ve done so far, we\u2019ve been making mutations only to\nindividual rules. But there\u2019s another mechanism that exists in many biological\norganisms: sexual reproduction, in which in effect a pair of rules (i.e.\ngenomes) get mixed to produce a new rule. As a simple model of the crossover\nthat typically happens with actual genomes, we can take two rules, and splice\ntogether the beginning of one with the end of the other:\n\nIn general there will be many ways to combine pairs of rules like this. In a\ndirect analogy to our Physics Project, we can represent such \u201crecombinations\u201d\nas \u201cevents\u201d that take two rules and produce one:\n\nThe analog of our multiway graph for all possible paths of adaptive evolution\nby mutations is now what we call in our Physics Project a token-event graph:\n\nIn dealing just with mutations we were able to take a single rule and\nprogressively modify it. Now we always have to work with a \u201cpopulation\u201d of\nrules, combining them two at a time to generate new rules. We can represent\nconceivable combinations among one set of rules as follows:\n\nThere are at this point many different choices we could make about how to set\nup our model. The particular approach we\u2019ll use selects just n of the = n (n \u2013\n1)/2 possible combinations:\n\nThen for each of these selected combinations we attempt a crossover, keeping\nthose \u201cchildren\u201d (drawn here between their parents) that are not rejected as a\nresult of having lower fitness:\n\nFinally, to \u201cmaintain our gene pool\u201d, we carry forward parents selected at\nrandom, so that we still end up with n rules. (And, yes, even though we\u2019ve\nattempted to make this whole procedure as a clean as possible, it\u2019s still a\nmess\u2014which seems to be inevitable, and which has, as we\u2019ll discuss below,\nbedeviled computational studies of evolution in the past.)\n\nOK, so what happens when we apply this procedure, say to k = 3, r = 1 rules?\nWe\u2019ll pick 4 rules at random as our initial population (and, yes, two happen\nto produce the same pattern):\n\nThen in a sequence of steps we\u2019ll successively pick various combinations:\n\nAnd here are the distinct \u201cphenotype patterns\u201d produced in this process (note\nthat even though there can be multiple copies of the same phenotype pattern,\nthe underlying genotype rules are always distinct):\n\nAs a final form of summarization we can just plot the successive fitnesses of\nthe patterns we generate (with the size of each dot reflecting the number of\ntimes a particular fitness occurs):\n\nIn this case we reach a steady state after 9 steps. The larger the population\nthe longer the adaptive evolution will typically keep going. Here are a couple\nof examples with population 10, showing all the patterns obtained:\n\nShowing in each case only the longest-lifetime rule found so far we get:\n\nThe results aren\u2019t obviously different from what we were finding with mutation\nalone\u2014even though now we\u2019ve got a much more complicated model, with a whole\npopulation of rules rather than a single rule. (One obvious difference,\nthough, is that here we can end up with overall cycles of populations of\nrules, whereas in the pure-mutation case that can only happen among fitness-\nneutral rules.)\n\nHere are some additional examples\u2014now obtained after 500 steps with population\n25\n\nand with population 50:\n\nAnd so far as one can tell, even here there are no substantial differences\nfrom what we saw with mutation. Certainly there detailed features introduced\nby sexual reproduction and crossover, but for our purposes in understanding\nthe big picture of what\u2019s happening in adaptive evolution it seems sufficient\nto do as we have done so far, and consider only mutation.\n\n## An Even More Minimal Model\n\nBy investigating adaptive evolution in cellular automata we\u2019re already making\ndramatic simplifications relative, say, to actual biology. But in the effort\nto understand the essence of phenomena we see, it\u2019s helpful to go even\nfurther\u2014and instead of thinking about computational rules and their behavior,\njust think about vertices on a \u201cmutation graph\u201d, each assigned a certain\nfitness.\n\nAs an example, we can set up a 2D grid, assigning each point a certain random\nfitness:\n\nAnd then, starting from a minimum-fitness point, we can follow the same kind\nof adaptive evolution procedure as above, at each step going to a neighboring\npoint with an equal or greater fitness:\n\nTypically we don\u2019t manage to go far before we get stuck, though with the\nuniform distribution of fitness values used here, we still usually end on a\nfairly large fitness value.\n\nWe can summarize the possible paths we can take by the multiway graph:\n\nIn our cellular automaton rule space\u2014and, for that matter, in\nbiology\u2014neighboring points don\u2019t just have independent random fitnesses;\ninstead, the fitnesses are determined by a definite computational procedure.\nSo as a simple approximation, we can just take the fitness of each point to be\na particular function of its graph coordinates. If the function forms\nsomething like a \u201cuniform hill\u201d, then the adaptive evolution procedure will\njust climb it:\n\nBut as soon as the function has \u201csystematic bumpiness\u201d there\u2019s a tremendous\ntendency to quickly get stuck:\n\nAnd if there\u2019s some \u201cunexpected spot of high fitness\u201d adaptive evolution\ntypically won\u2019t find it (and it certainly won\u2019t if it\u2019s surrounded by a lower-\nfitness \u201cmoat\u201d):\n\nSo what happens if we increase the dimensionality of the \u201cmutation space\u201d in\nwhich we\u2019re operating? Basically it becomes easier to find a path that\nincreases fitness:\n\nAnd we can see this, for example, if we look at Boolean hypercubes in\nincreasing numbers of dimensions:\n\nBut ultimately this relies on the fact that in the neighborhood reachable by\nmutations from a given point, there\u2019ll be a \u201csufficiently random\u201d collection\nof fitness values that it\u2019ll (likely) be possible to find a \u201cdirection\u201d that\u2019s\n\u201cgoing up\u201d in fitness. Yet this alone won\u2019t in general be enough, because we\nalso need it to be the case that there\u2019s enough regularity in the fitness\nlandscape that we can systematically navigate it to find its maximum\u2014and that\nthe maximum is not somehow \u201cunexpected and isolated\u201d.\n\n## What Can Adaptive Evolution Achieve?\n\nWe\u2019ve seen that adaptive evolution can be surprisingly successful at finding\ncellular automata that produce patterns with long but finite lifetimes. But\nwhat about other types of \u201ctraits\u201d? What can (and cannot) adaptive evolution\nultimately manage to do?\n\nFor example, what if we\u2019re trying to find cellular automata whose patterns\ndon\u2019t just live \u201cas long as possible\u201d but instead die after a specific number\nof steps? It\u2019s clear that within any finite set of rules (say with particular\nk and r) there\u2019ll only be a limited collection of possible lifetimes. For\nsymmetric k = 2, r = 2 rules, for example, the possible lifetimes are:\n\nBut as soon as we\u2019re dealing even with k = 3, r = 1 symmetric rules it\u2019s\nalready in principle possible to get every lifetime up to 100. But what about\nadaptive evolution? How well does it do at reaching rules with all those\nlifetimes? Let\u2019s say we do single point mutation as before, but now we\n\u201caccept\u201d a mutation if it leads not specifically to a larger finite lifetime,\nbut to a lifetime that is closer in absolute magnitude to some desired\nlifetime. (Strictly, and importantly, in both cases we also allow \u201cfitness-\nneutral\u201d mutations that leave the lifetime the same.)\n\nHere are examples of what happens if we try to adaptively evolve to get\nlifetime exactly 50 in k = 3, r = 1 rules:\n\nIt gets close\u2014and sometimes it overshoots\u2014but, at least in these particular\nexamples, it never quite makes it. Here\u2019s what we see if we look at the\nlifetimes achieved with 100 different random sequences of mutations:\n\nBasically they mostly get stuck at lifetimes close to 50, but not exactly 50.\nIt\u2019s not that k = 3, r = 1 rules can\u2019t yield lifetime 50; exhaustive search\nshows that even many symmetric such rules can:\n\nIt\u2019s just that our adaptive evolution process usually gets stuck before it\nreaches rules like these. Even though there\u2019s usually enough \u201croom to\nmaneuver\u201d in k = 3, r = 1 rule space to get to generally longer lifetimes,\nthere\u2019s not enough to specifically get to lifetime 50.\n\nBut what about k = 4, r = 1 rule space? There are now not 10^12 but about\n10^38 possible rules. And in this rule space it becomes quite routine to be\nable to reach lifetime 50 through adaptive evolution:\n\nIt can sometimes take a while, but most of the time in this rule space it\u2019s\npossible to get exactly to lifetime 50:\n\nWhat happens with other \u201clifetime goals\u201d? Even symmetric k = 3, r = 1 rules\ncan achieve many lifetime values:\n\nIndeed, the first \u201cmissing\u201d values are 129, 132, 139, etc. And, for example,\nmany multiples of 50 can be achieved:\n\nBut it becomes increasingly difficult for adaptive evolution to reach these\nspecific goals. Increasing the size of the rule space always seems to help; so\nfor example with k = 4, r = 1, if one\u2019s aiming for lifetime 100, the actual\ndistribution of lifetimes reached is:\n\nIn general the distribution gets broader as the lifetime sought gets larger:\n\nWe saw above that across the whole space of, say, k = 4, r = 1 rules, the\nfrequency of progressively larger lifetimes falls roughly according to a power\nlaw. So this means that the fractional region in rule space that achieves a\ngiven lifetime gets progressively smaller\u2014with the result that typically the\npaths followed by adaptive evolution are progressively more likely to get\nstuck before they reach it.\n\nOK, so what about other kinds of objectives? Say ones more related to the\nmorphologies of patterns? As a simple example, let\u2019s consider the objective of\nmaximizing the \u201cwidths\u201d of finite-lifetime patterns. We can try to achieve\nthis by adaptive evolution in which we reject any mutations that lead to\ndecreased width (where \u201cwidth\u201d is defined as the maximum horizontal extent of\nthe pattern). And once again this process manages to \u201cdiscover\u201d all sorts of\n\u201cmechanisms\u201d for achieving larger widths (here each pattern is labeled by its\nheight\u2014i.e. lifetime\u2014and width):\n\nThere are certain structural constraints here. For example, the width can\u2019t be\ntoo large relative to the height\u2014because if it\u2019s too large, patterns tend to\ngrow forever.\n\nBut what if we specifically try to select for maximal \u201cpattern aspect ratio\u201d\n(i.e. ratio of width to height)? In essentially every case so far, adaptive\nevolution has in effect \u201cinvented many different mechanisms\u201d to achieve\nwhatever objective we\u2019ve defined. But here it turns out we essentially see\n\u201cthe same idea\u201d being used over and over again\u2014presumably because this is the\nonly way to achieve our objective given the overall structure of how the\nunderlying rules we\u2019re using work:\n\nWhat if we ask something more specific? Like, say, that the aspect ratio be as\nclose to 3 as possible. Much of the time the \u201csolution\u201d that adaptive\nevolution finds is the correct if trivial:\n\nBut sometimes it finds another solution\u2014and often a surprisingly elaborate and\ncomplicated one:\n\nHow about if our goal is an aspect ratio of \u03c0 \u2248 3.14? It turns out adaptive\nevolution can still do rather well here even just with the symmetric k = 3, r\n= 1 rules that we\u2019re using:\n\nWe can also ask about properties of the \u201cinside\u201d of the pattern. For example,\nwe can ask to maximize the lengths of uniform runs of nonwhite cells in the\ncenter column of the pattern. And, once again, adaptive evolution can\nsuccessfully lead us to rules (like these random examples) where this is\nlarge:\n\nWe can go on and get still more detailed, say asking about runs of particular\nlengths, or the presence or number of particular subpatterns. And\neventually\u2014just like when we asked for too long a lifetime\u2014we\u2019ll find that the\ncases we\u2019re looking for are \u201ctoo sparse\u201d, and adaptive evolution won\u2019t be able\nto find them, even if exhaustive search could still identify at least a few\nexamples.\n\nBut just what kinds of objectives (or fitness functions) can be handled how\nwell by adaptive evolution, operating for example on the \u201craw material\u201d of\ncellular automata? It\u2019s an important question\u2014an analog of which is also\ncentral to the investigation of machine learning. But as of now we don\u2019t\nreally have the tools to address it. It\u2019s somehow reminiscent of asking what\nkinds of functions can be approximated how well by different methods or basis\nfunctions. But it\u2019s more complicated. Solving it, though, would tell us a lot\nabout the \u201creach\u201d of adaptive evolution processes, not only for biology but\nalso for machine learning.\n\n## What It Means for What\u2019s Going On in Biology\n\nHow do biological organisms manage to be the way they are, with all their\ncomplex and seemingly clever solutions to such wide range of challenges? Is it\njust natural selection that does it, or is there in effect more going on? And\nif \u201cnatural selection does it\u201d, how does it actually manage it?\n\nFrom the point of view of traditional engineering what we see in biology is\noften very surprising, and much more complex and \u201cclever\u201d than we\u2019d imagine\never being able to create ourselves. But is the secret of biology in a sense\njust natural selection? Well, actually, there\u2019s often an analog of natural\nselection going on even in engineering, as different designs get tried and\nonly some get selected. But at least in traditional engineering a key feature\nis that one always tries to come up with designs where one can foresee their\nconsequences.\n\nBut biology is different. Mutations to genomes just happen, without any notion\nthat their consequences can be foreseen. But still one might assume that\u2014when\nguided by natural selection\u2014the results wouldn\u2019t be too different to what we\u2019d\nget in traditional engineering.\n\nBut there\u2019s a crucial piece of intuition missing here. And it has to do with\nhow randomly chosen programs behave. We might have assumed (based on our\ntypical experience with programs we explicit construct for particular\npurposes) that at least a simple random program wouldn\u2019t ever do anything\nterribly interesting or complicated.\n\nBut the surprising discovery I made in the early 1980s is that this isn\u2019t\ntrue. And instead, it\u2019s a ubiquitous phenomenon that in the computational\nuniverse of possible programs, one can get immense complexity even from very\nsimple programs. So this means that as mutation operates on a genome, it\u2019s\nessentially inevitable that it\u2019ll end up sampling programs that show highly\ncomplex behavior. At the outset, one might have imagined that such complexity\ncould only be achieved by careful design and would inevitably be at best rare.\nBut the surprising fact is that\u2014because of how things fundamentally work in\nthe computational universe\u2014it\u2019s instead easy to get.\n\nBut what does complexity have to do with creating \u201csuccessful organisms\u201d? To\ncreate a \u201csuccessful organism\u201d that can prosper in a particular environment\nthere fundamentally has to be some way to get to a genome that will \u201csolve the\nnecessary problems\u201d. And this is where natural selection comes in. But the\nfact that it can work is something that\u2019s not at all obvious.\n\nThere are really two issues. The first is whether a program (i.e. genome) even\nexists that will \u201csolve the necessary problems\u201d. And the second is whether\nsuch a program can be found by a \u201cthread\u201d of adaptive evolution that goes only\nthrough intermediate states that \u201cfit enough\u201d to survive. As it turns out,\nboth these issues are related to the same fundamental features of\ncomputation\u2014which are also responsible for the ubiquitous appearance of\ncomplexity.\n\nGiven some underlying framework\u2014like cellular automata, or like the basic\napparatus of life\u2014is there some rule that can be implemented in that framework\nthat will achieve some particular (computational) objective? The Principle of\nComputational Equivalence says that generically the answer will be yes. In\neffect, given almost any \u201cunderlying hardware\u201d, it\u2019ll ultimately possible to\ncome up with \u201csoftware\u201d (i.e. a rule) that achieves almost any (\u201cphysically\npossible\u201d) given objective\u2014like growing an organism of at least some kind that\ncan survive in a particular environment. But how can we actually find a rule\nthat achieves this?\n\nIn principle we could do exhaustive search. But that will be exponentially\ndifficult\u2014and in all but toy cases will be utterly infeasible in practice. So\nwhat about adaptive evolution? Well, that\u2019s the big question. And what we\u2019ve\nseen here is that\u2014rather surprisingly\u2014simple mutation and selection (i.e. the\nmechanisms of natural selection) very often provide a dramatic shortcut for\nfinding rules that do what we want.\n\nSo why is this? In effect, adaptive evolution is finding a path through rule\nspace that gets to where we want to go. But the surprising part is that it\u2019s\nmanaging to do this one step at a time. It\u2019s just trying random variations\n(i.e. mutations) and as soon as it finds one that\u2019s not a \u201cstep down in\nfitness\u201d, it\u2019ll \u201ctake it\u201d, and keep going. At the outset it\u2019s certainly not\nobvious that this will work. In particular, it could be that at some point\nthere just won\u2019t be any \u201cway forward\u201d. All \u201cdirections\u201d will lead only to\nlower fitness, and in effect the adaptive evolution will get stuck.\n\nBut the key observation from the experiments in our simple model here is that\nthis typically doesn\u2019t happen. And there seem to be basically two things going\non. The first is that rule space is in effect very high-dimensional. So that\nmeans there are \u201cmany directions to choose from\u201d in trying to find one that\nwill allow one to \u201ctake a step forward\u201d. But on its own this isn\u2019t enough.\nBecause there could be correlations between these directions that would mean\nthat if one\u2019s blocked in one direction one would inevitably be blocked in all\nothers.\n\nSo why doesn\u2019t this happen? Well, it seems to be the result of the fundamental\ncomputational phenomenon of computational irreducibility. A traditional view\nbased on experience with mathematical science had been that if one knew the\nunderlying rule for a system then this would immediately let one predict what\nthe system would do. But what became clear from my explorations in the 1980s\nand 1990s is that in the computational universe this generically isn\u2019t true.\nAnd instead, that the only way one can systematically find out what most\ncomputational systems will do is explicitly to run their rules, step by step,\ndoing in effect the same irreducible amount of computational work that they\ndo.\n\nSo if one\u2019s just presented with behavior from the system one won\u2019t be in a\nposition to \u201cdecode it\u201d and \u201csee its simple origins\u201d. Unless one\u2019s capable of\ndoing as much computational work as the system itself, one will just have to\nconsider what it\u2019s doing as (more or less) \u201crandom\u201d. And indeed this seems to\nbe at the root of many important phenomena, such as the Second Law of\nthermodynamics. And I also suspect it\u2019s at the root of the effectiveness of\nadaptive evolution, notably in biology.\n\nBecause what computational irreducibility implies is that around every point\nin rule space there\u2019ll be a certain \u201ceffective randomness\u201d to fitnesses one\nsees. And if there are many dimensions to rule space that means it\u2019s\noverwhelmingly likely that there\u2019ll be \u201cpaths to success\u201d in some directions\nfrom that point.\n\nBut will the adaptive evolution find them? We\u2019ve assumed that there are a\nseries of mutations to the rule, all happening \u201cat random\u201d. And the point is\nthat if there are n elements in the rule, then after some fraction of n\nmutations we should find our \u201csuccess direction\u201d. (If we were doing exhaustive\nsearch, we\u2019d instead have to try about k^n possible rules.)\n\nAt the outset it might seem conceivable that the sequence of mutations could\nsomehow \u201ccleverly probe\u201d the structure of rule space, \u201cknowing\u201d what\ndirections would or would not be successful. But the whole point is that going\nfrom a rule (i.e. genotype) to its behavior (i.e. phenotype) is generically a\ncomputationally irreducible process. So assuming that mutations are generated\nin a computationally bounded way it\u2019s inevitable that they can\u2019t \u201cbreak\ncomputational irreducibility\u201d and so will \u201cexperience\u201d the fitness landscape\nin rule space as \u201ceffectively random\u201d.\n\nOK, but what about \u201cachieving the characteristics an organism needs\u201d? What\nseems to be critical is that these characteristics are in a sense\ncomputationally simple. We want an organism to live long enough, or be tall\nenough, or whatever. It\u2019s not that we need the organism to perform some\nspecific computationally irreducible task. Yes, there are all sorts of\ncomputationally irreducible processes happening in the actual development and\nbehavior of an organism. But as far as biological evolution is concerned all\nthat matters is ultimately some computationally simple measure of fitness.\nIt\u2019s as if biological evolution is\u2014in the sense of my recent observer theory\u2014a\ncomputationally bounded observer of underlying computationally irreducible\nprocesses.\n\nAnd to the observer what emerges is the \u201csimple law\u201d of biological evolution,\nand the idea that, yes, it is possible just by natural selection to\nsuccessfully generate all sorts of characteristics.\n\nThere are all sorts of consequences of this for thinking about biology. For\nexample, in thinking about where complexity in biology \u201ccomes from\u201d. Is it\n\u201cgenerated by natural selection\u201d, perhaps reflecting the complicated sequence\nof historical accidents embodied in the particular collection of mutations\nthat occurred? Or is it from somewhere else?\n\nIn the picture we\u2019ve developed here it\u2019s basically from somewhere else\u2014because\nit\u2019s essentially a reflection of computational irreducibility. Having said\nthat, we should remember that the very possibility of being able to have\norganisms with such a wide range of different forms and functions is a\nconsequence of the universal computational character of their underlying\nsetup, which in turn is closely tied to computational irreducibility.\n\nAnd it\u2019s in effect because natural selection is so coarse in its operation\nthat it does not somehow avoid the ubiquitous computational irreducibility\nthat exists in rule space, with the result that when we \u201clook inside\u201d\nbiological systems we tend to see computational irreducibility and the\ncomplexity associated with it.\n\nSomething that we\u2019ve seen over and over again here is that, yes, adaptive\nevolution manages to \u201csolve a problem\u201d. But its solution looks very complex to\nus. There might be some \u201csimple engineering solution\u201d\u2014involving, say, a very\nregular pattern of behavior. But that\u2019s not what adaptive evolution finds;\ninstead it finds something that to us is typically very surprising\u2014very often\nan \u201cunexpectedly clever\u201d solution in which lots of pieces fit together just\nright, in a way that our usual \u201cunderstand-what\u2019s-going-on\u201d engineering\npractices would never let us invent.\n\nWe might not have expected anything like this to emerge from the simple\nprocess of adaptive evolution. But\u2014as the models we\u2019ve studied here\nhighlight\u2014it seems to be an inevitable formal consequence of core features of\ncomputational systems. And as soon as we recognize that biological systems can\nbe viewed as computational, then it also becomes something inevitable for\nthem\u2014and something we can view as in a sense formally derivable for them.\n\nAt the outset we might not have been able to say \u201cwhat matters\u201d in the\nemergence of complexity in biology. But from the models we\u2019ve studied, and the\narguments we\u2019ve made, we seem to have quite firmly established that it\u2019s a\nfundamentally computational phenomenon, that relies only on certain general\ncomputational features of biological systems, and doesn\u2019t depend on their\nparticular detailed components and structure.\n\nBut in the end, how \u201cgeneric\u201d is the complexity that comes out of adaptive\nevolution? In other words, if we were to pick programs, say completely at\nrandom, how different would the complexity they produce be from the complexity\nwe see in programs that have been adaptively evolved \u201cfor a purpose\u201d? The\nanswer isn\u2019t clear\u2014though to know it would provide important foundational\ninput for theoretical biology.\n\nOne has the general impression that computational irreducibility is a strong\nenough phenomenon that it\u2019s the \u201cdominant force\u201d that determines behavior and\nproduces complexity. But there\u2019s still usually something a bit different about\nthe patterns we see from rules we\u2019ve found by adaptive evolution, compared to\nrules we pick at random. Often there seems to be a certain additional level of\n\u201capparent mechanism\u201d. The details still look complicated and in some ways\nquite random, but there seems to be a kind of \u201coverall orchestration\u201d to\nwhat\u2019s going on.\n\nAnd whenever we can identify such regularities it\u2019s a sign of some kind of\ncomputational reducibility. There\u2019s still plenty of computational\nirreducibility at work. But \u201chigh fitness\u201d rules that we find through adaptive\nevolution typically seem to exhibit traces of their specialness\u2014that manifests\nin at least a certain amount of computational reducibility.\n\nWhenever we manage to come up with a \u201cnarrative explanation\u201d or a \u201cnatural\nlaw\u201d for something, it\u2019s a sign that we\u2019re found a pocket of computational\nreducibility. If we say that a cellular automaton manages to live long because\nit generates certain robust geometric patterns\u2014or, for that matter, that an\norganism lives long because it proofreads its DNA\u2014we\u2019re giving a narrative\nthat\u2019s based on computational reducibility.\n\nAnd indeed whenever we can successfully identify a \u201cmechanism\u201d in our cellular\nautomaton behavior, we\u2019re in effect seeing computational reducibility. But\nwhat can we say about the aggregate of a whole collection of mechanisms?\n\nIn a different context I\u2019ve discussed the concept of a \u201cmechanoidal phase\u201d,\ndistinguished, say, from solid and liquids, by the presence of a \u201cbulk\norchestration\u201d of underlying components. It\u2019s something closely related to\nclass 4 behavior. And it\u2019s interesting to note that if we look, for example,\nat the rules we found from adaptive evolution at the end of the previous\nsection, their evolution from random initial conditions mostly shows\ncharacteristic class 4 behavior:\n\nIn other words, adaptive evolution is potentially bringing us to\n\u201ccharacteristically special\u201d places in rule space\u2014perhaps suggesting that\nthere\u2019s something \u201ccharacteristically special\u201d about the kind of structures\nthat are produced in biological systems. And if we could find a way to make\ngeneral statements about that \u201ccharacteristic specialness\u201d it would\npotentially lead to us to a framework for constructing a new broad formal\ntheory in biology.\n\n## Correspondence with Biological Phenomena\n\nThe models we\u2019ve studied here are extremely simple in their basic\nconstruction. And at some level it\u2019s remarkable that\u2014without for example\nincluding any biophysics or biochemistry\u2014they can get anywhere at all in\ncapturing features of biological systems and biological evolution.\n\nIn a sense this is ultimately a reflection of the fundamentally computational\ncharacter of biology\u2014and the generality of computational phenomena. But it\u2019s\nvery striking that even the patterns of cellular automaton behavior we see\nlook very \u201clifelike and organic\u201d.\n\nIn actual biology even the shortest genomes are vastly longer than the tiny\ncellular automaton rules we\u2019ve considered. But even by the time we\u2019re looking\nat the length-27 \u201cgenomic sequences\u201d in k = 3, r = 1 cellular automata, there\nare already 3 trillion possible sequences, which seems to be enough to see\nmany core \u201ccombinatorially driven\u201d biology-like phenomena.\n\nThe running of a cellular automaton rule might also at first seem far away\nfrom the actual processes that create biological organisms\u2014involving as they\ndo things like the construction of proteins and the formation of elaborate\nfunctional and spatial structures. But there are more analogies than one might\nat first imagine. For example, it\u2019s common for only particular cases in the\ncellular automaton rule to be used in a given region of the pattern that\u2019s\nformed, much as particular genes are typically turned on in different tissues\nin biological organisms.\n\nAnd, for example, the \u201cgeometrical restriction\u201d to a simple 1D array of\n\u201ccells\u201d doesn\u2019t seem to matter much as soon as there\u2019s sophisticated\ncomputation going on; we still get lots of structures that are actually\nsurprisingly reminiscent of typical patterns of biological growth.\n\nOne of the defining features of biological organisms is their capability for\nself-reproduction. And indeed if it wasn\u2019t for this kind of \u201ccopying\u201d there\nwouldn\u2019t be anything like adaptive evolution to discuss. Our models don\u2019t\nattempt to derive self-reproduction; they just introduce it as something built\ninto the models.\n\nAnd although we\u2019ve considered several variants, we\u2019re basically also just\nbuilding into our models the idea of mutations. And what we find is that it\nseems as if single point mutations made one at a time are enough to capture\nbasic features of adaptive evolution.\n\nWe\u2019ve also primarily considered what amounts to a single lineage\u2014in which\nthere\u2019s just a single rule (or genome) at a given step. We do mutations, and\nwe mostly \u201cimplement natural selection\u201d just by keeping only rules that lead\nto patterns whose fitness is no less than what we had before.\n\nIf we had a whole population of rules it probably wouldn\u2019t be so significant,\nbut in the simple setup we\u2019re using, it turns out to be important that we\ndon\u2019t reject \u201cfitness-neutral mutations\u201d. And indeed we\u2019ve seen many examples\nwhere the system wanders around fitness-neutral regions of rule space before\nfinally \u201cdiscovering\u201d some \u201cinnovation\u201d that allows it to increase fitness.\nThe way our models are set up, that \u201cwandering\u201d always involves changes in the\n\u201cgenotype\u201d\u2014but usually at most minor changes in the phenotype. So it\u2019s very\ntypical to see long periods of \u201capparent equilibrium\u201d in which the phenotype\nchanges rather little, followed by a \u201cjump\u201d to a new fitness level and a\nrather different phenotype.\n\nAnd this observation seems quite aligned with the phenomenon of \u201cpunctuated\nequilibrium\u201d often reported in the fossil record of actual biological\nevolution.\n\nAnother key feature of biological organisms and biological evolution is the\nformation of distinct species, as well as distinct phyla, etc. And indeed we\nubiquitously see something that seems to be directly analogous in our multiway\ngraphs of all possible paths of adaptive evolution. Typically we see distinct\nbranches forming, based on what seem like \u201cdifferent mechanisms\u201d for achieving\nfitness.\n\nNo doubt in actual biology there are all sorts of detailed phenomena related\nto reproductive or spatial isolation. But in our models the core phenomenon\nthat seems to lead to the analog of \u201cbranching in the tree of life\u201d is the\nexistence of \u201cdistinctly different computational mechanisms\u201d in different\nparts of rule space. It\u2019s worth noting that at least with our finite rule\nspaces, branches can die out, with no \u201csuccessor species\u201d appearing the\nmultiway graph.\n\nAnd indeed looking at the actual patterns produced by rules in different parts\nof the multiway graph it\u2019s easy to imagine morphologically based taxonomic\nclassifications\u2014that would be somewhat, though not perfectly, aligned with the\nphylogenetic tree defined by actual rule mutations. (At a morphological level\nwe quite often see some level of \u201cconvergent evolution\u201d in our multiway\ngraphs; in small examples we sometimes also see actual \u201cgenomic\nconvergence\u201d\u2014which will typically be astronomically rare in actual biological\nsystems.)\n\nOne of the remarkable features of our models is that they allow quite global\ninvestigation of the \u201coverall history\u201d of adaptive evolution. In many of the\nsimple cases we\u2019ve discussed, the rule space we\u2019re using is small enough that\nin a comparatively modest number of mutation steps we get to the \u201chighest\nfitness we can reach\u201d. But (as the examples we saw in Turing machines suggest)\nexpanding the size of the rules we\u2019re using even just a little can be expected\nto be sufficient to allow us to get astronomically further.\n\nAnd the further we go, the more \u201cmechanisms\u201d will be \u201cinvented\u201d. It\u2019s an\ninevitable feature of systems that involve computational irreducibility that\nthere are new and unpredictable things that will go on showing up\nforever\u2014along with new pockets of computational reducibility. So even after a\nfew billion years\u2014and the trillion generations and 10^40 or so organisms that\nhave ever lived\u2014there\u2019s still infinitely further for biological evolution to\ngo, and more and more branches to be initiated in the tree of life, involving\nmore and more \u201cnew mechanisms\u201d.\n\nI suppose one might imagine that at some point biological organisms would\nreach a \u201cmaximum fitness\u201d, and go no further. But even in our simple model\nwith fitness measured in terms of pattern lifetime, there\u2019ll be no upper limit\non fitness; given any particular lifetime, it\u2019s a feature of the fundamental\ntheory of computation that there\u2019ll always be a program that will yield a\nlarger lifetime. Still, one might think, at some point enough is enough: the\ngiraffe\u2019s neck is long enough, etc. But if nothing else, competition between\norganisms will always drive things forward: yes, a particular lineage of\norganisms achieved a certain fitness, but then another lineage can come along\nand get to that fitness too, forcing the first lineage to go even further so\nas to not lose out.\n\nOf course, in our simple model we\u2019re not explicitly accounting for\ninteractions with other organisms\u2014or for detailed properties of the\nenvironment, as well as countless other effects. And no doubt there are many\nbiological phenomena that depend on these effects. But the key point here is\nthat even without explicitly accounting for any of these effects, our simple\nmodel still seems to capture many core features of biological evolution.\nBiological evolution\u2014and, indeed, adaptive evolution in general\u2014is, it seems,\nfundamentally a computational phenomenon that robustly emerges quite\nindependent of the details of systems.\n\nIn the past few years our Physics Project has given strong evidence that the\nfoundations of physics are fundamentally computational\u2014with the core laws of\nphysics arising as inevitable consequences of the way observers like us\n\u201cparse\u201d the ruliad of all possible computational processes. And what we\u2019ve\nseen here now suggests that there\u2019s a remarkable commonality between the\nfoundations of physics and biology. Both are anchored in computational\nirreducibility. And both sample slices of computational reducibility. Physics\nbecause that\u2019s what observers like us do to get descriptions of the world that\nfit in our finite minds. Biology because that\u2019s what biological evolution does\nin order to achieve the \u201ccoarse objectives\u201d set by natural selection.\n\nThe intuition of physics tends to be that there are ultimately simple models\nfor things, whereas in biology there\u2019s a certain sense that everything is\nalways almost infinitely complicated, with a new effect to consider at every\nturn. But presumably that\u2019s in large part because what we study in biology\ntends to quickly come face to face with computational irreducibility\u2014whereas\nin physics we\u2019ve been able to find things to study that avoid this. But now\nthe commonality in foundations between physics and biology suggests that there\nshould also be in biology the kind of structure we have in physics\u2014complete\nwith general laws that allow us to make useful, broad statements. And perhaps\nthe simple model I\u2019ve presented here can help lead us there\u2014and in the end\nhelp build up a new paradigm for thinking about biology in a fundamentally\ntheoretical way.\n\n## Historical Notes\n\nThere\u2019s a long\u2014if circuitous\u2014history to the things I\u2019m discussing here. Basic\nnotions of heredity\u2014particularly for humans\u2014were already widely recognized in\nantiquity. Plant breeding was practiced from the earliest days of agriculture,\nbut it wasn\u2019t until the late 1700s that any kind of systematic selective\nbreeding of animals began to become commonplace. Then in 1859 Charles Darwin\ndescribed the idea of \u201cnatural selection\u201d whereby competition of organisms in\ntheir natural environment could act like artificial selection, and, he\nposited, would over long periods lead to the development of new species. He\nended his Origin of Species with the claim that:\n\n> ... from the war of nature ... the production of the higher animals,\n> directly follows. ... and whilst this planet has gone cycling on according\n> to the fixed law of gravity, from so simple a beginning endless forms most\n> beautiful and most wonderful have been, and are being, evolved.\n\nWhat he appears to have thought is that there would somehow follow from\nnatural selection a general law\u2014like the law of gravity\u2014that would lead to the\nevolution of progressively more complex organisms, culminating in the \u201chigher\nanimals\u201d. But absent the kind of model I\u2019m discussing here, nothing in the\nlater development of traditional evolutionary theory really successfully\nsupported this\u2014or was able to give much analysis of it.\n\nRight around the same time as Darwin\u2019s Origin of Species, Gregor Mendel began\nto identify simple probabilistic laws of inheritance\u2014and when his work was\nrediscovered at the beginning of the 1900s it was used to develop mathematical\nmodels of the frequencies of genetic traits in populations of organisms, with\nkey contributions to what became the field of population genetics being made\nin the 1920s and 1930s by J. B. S. Haldane, R. A. Fisher and Sewall Wright,\nwho came up with the concept of a \u201cfitness landscape\u201d.\n\nOn a quite separate track there had been efforts ever since antiquity to\nclassify and understand the growth and form of biological organisms, sometimes\nby analogy to physical or mathematical ideas\u2014and by the 1930s it seemed fairly\nclear that chemical messengers were somehow involved in the control of growth\nprocesses. But the mathematical methods used for example in population\ngenetics basically only handled discrete traits (or simple numerical ones\naccessible to biometry), and didn\u2019t really have anything to say about\nsomething like the development of complexity in the forms of biological\norganisms.\n\nThe 1940s saw the introduction of what amounted to electrical-engineering-\ninspired approaches to biology, often under the banner of cybernetics.\nIdealized neural networks were introduced by Warren McCulloch and Walter Pitts\nin 1943, and soon the idea emerged (notably in the work of Donald Hebb in\n1949) that learning in such systems could occur through a kind of adaptive\nevolution process. And by the time practical electronic computing began to\nemerge in the 1950s there was widespread belief that ideas from\nbiology\u2014including evolution\u2014would be a useful as an inspiration for what could\nbe done. Often what would now just be described as adaptive algorithms were\ncouched in biological evolution terms. And when iterative methods were used\nfor optimization (say in industrial production or engineering design) they\nwere sometimes presented as being grounded in biological evolution.\n\nMeanwhile, by the 1960s, there began to be what amounted to Monte Carlo\nsimulations of population-genetics-style evolutionary processes. A\nparticularly elaborate example was work by Nils Barricelli on what he called\n\u201cnumeric evolution\u201d in which a fairly complicated numerical-cellular-\nautomaton-like \u201ccompetition between organisms\u201d program with \u201crandomness\u201d\ninjected from details of data layout in computer memory showed what he claimed\nto be biological-evolution-like phenomena (such as symbiosis and parasitism).\n\nIn a different direction there was an attempt\u2014notably by John von Neumann\u2014to\n\u201cmathematicize the foundations of biology\u201d leading by the late 1950s to what\nwe\u2019d now call 2D cellular automata \u201cengineered\u201d in complicated ways to show\nphenomena like self-reproduction. The followup to this was mostly early-\ntheoretical-computer-science work, with no particular connection to biology,\nand no serious mention of adaptive evolution. When the Game of Life was\nintroduced in 1970 it was widely noted as \u201cdoing lifelike things\u201d, but\nessentially no scientific work was done in this direction. By the 1970s,\nthough, L-systems and fractals had introduced the idea of recursive tree-like\nor nested structures that could be generated by simple algorithms and rendered\nby computer graphics\u2014and seemed to give forms close to some seen in biology.\nMy own work on 1D cellular automata (starting in 1981) focused on systematic\nscientific investigation of simple programs and what they do\u2014with the\nsurprising conclusion that even very simple programs can produce highly\ncomplex behavior. But while I saw this as informing the generation of\ncomplexity in things like the growth of biological organisms, I didn\u2019t at the\ntime (as I\u2019ll describe below) end up seriously exploring any adaptive\nevolution angles.\n\nStill another thread of development concerned applying biological-like\nevolution not just to parameters but to operations in programs. And for\nexample in 1958 Richard Friedberg at IBM tried making random changes to\ninstructions in machine-code programs, but didn\u2019t manage to get this to do\nmuch. (Twenty years later, superoptimizers in practical compilers did begin to\nsuccessfully use such techniques.) Then in the 1960s, John Holland (who had at\nfirst studied learning in neural nets, and was then influenced by Arthur Burks\nwho had worked on cellular automata with von Neumann) suggested representing\nwhat amounted to programs by simple strings of symbols that could readily be\nmodified like genomic sequences. The typical idea was to interpret the symbols\nas computational operations\u2014and to assign a \u201cfitness\u201d based on the outcome of\nthose operations. A \u201cgenetic algorithm\u201d could then be set up by having a\npopulation of strings that was adaptively evolved. Through the 1970s and 1980s\noccasional practical successes were reported with this approach, particularly\nin optimization and data classification\u2014with much being made of the importance\nof sexual-reproduction-inspired crossover operations.\n\nBy the beginning of the 1980s the idea had also emerged of adaptively\nmodifying the structure of mathematical expressions\u2014and of symbolic\nexpressions representing programs. There were notable applications in computer\ngraphics (e.g. by Karl Sims) as well as to things like the 1984 Core War\n\u201cgame\u201d involving competition between programs in a virtual machine. In the\n1990s John Koza was instrumental in developing the idea of \u201cgenetic\nprogramming\u201d, notably as a way to \u201cautomatically create inventions\u201d, for\nexample in areas like circuit and antenna design. And indeed to this day\nscattered applications of these methods continue to pop up, particularly in\ngeometrical and mechanical design.\n\nFrom the very beginning there\u2019d been controversy around Darwin\u2019s ideas about\nevolution. First, there was the issue of conflict with religious accounts of\ncreation. But there were also\u2014often vigorous\u2014disagreements within the\nscientific community about the interpretation of the fossil record and about\nhow large-scale evolution was really supposed to operate. A notable\nissue\u2014still very active in the 1980s\u2014was the relationship between the \u201cfreedom\nof evolution\u201d and the constraints imposed by the actual dynamics of growth in\norganisms (and interactions between organisms). And despite much insistence\nthat the only reasonable \u201cscientific\u201d (as opposed to religious) point of view\nwas that \u201cnatural selection is all there is\u201d, there were nagging mysteries\nthat suggested there must be other forces at work.\n\nBuilding on the possibilities of computer experimentation (as well as things\nlike my work on cellular automata) there emerged in the mid-1980s,\nparticularly through the efforts of Chris Langton, a focus on investigating\ncomputational models of \u201cartificial life\u201d. This resulted in all sorts of\nsimulations of ecosystems, etc. that did produce a variety of evolution-\nrelated phenomena known from field biology\u2014but typically the models were far\ntoo complex in their structure for it to be possible to extract fundamental\nconclusions from them. Still, there continued to be specific, simpler\nexperiments. For example, in 1986, for his book The Blind Watchmaker, Richard\nDawkins made pictures of what he called \u201cbiomorphs\u201d, produced by adaptively\nadjusting parameters for a simple tree-growth algorithm based on the overall\nshapes generated.\n\nIn the 1980s, stimulated by my work, there were various isolated studies of\n\u201crule evolution\u201d in cellular automata (as well as art and museum exhibits\nbased on this), and in the 1990s there was more systematic work\u2014notably by Jim\nCrutchfield and Melanie Mitchell\u2014on using genetic algorithms to try to evolve\ncellular automaton rules to solve tasks like density classification. (Around\nthis time \u201cevolutionary computation\u201d also began to emerge as a general term\ncovering genetic algorithms and other usually-biology-inspired adaptive\ncomputational methods.)\n\nMeanwhile, accelerating in the 1990s, there was great progress in\nunderstanding actual molecular mechanisms in biology, and in figuring out how\ngenetic and developmental processes work. But even as huge amounts of data\naccumulated, enthusiasm for large-scale \u201ctheories of biology\u201d (that might for\nexample address the production of complexity in biological evolution) seemed\nto wane. (The discipline of systems biology attempted to develop specific,\nusually mathematical, models for biological systems\u2014but there never emerged\nmuch in the way of overarching theoretical principles, except perhaps,\nsomewhat specifically, in areas like immunology and neuroscience.)\n\nOne significant exception in terms of fundamental theory was Greg Chaitin\u2019s\nconcept from around 2010 of \u201cmetabiology\u201d: an effort (see below) to use ideas\nfrom the theory of computation to understand very general features of the\nevolution of programs and relate them to biological evolution.\n\nStarting in the 1950s another strand of development (sometimes viewed as a\npractical branch of artificial intelligence) involved the idea of \u201cmachine\nlearning\u201d. Genetic algorithms were one of half a dozen common approaches.\nAnother was based on artificial neural nets. For decades machine learning\nlanguished as a somewhat esoteric field, dominated by engineering solutions\nthat would occasionally deliver specific application results. But then in 2011\nthere was unexpectedly dramatic success in using neural nets for image\nidentification, followed in subsequent years by successes in other areas, and\nculminating in 2022 with the arrival of large language models and ChatGPT.\n\nWhat hadn\u2019t been anticipated was that the behavior of neural nets can change a\nlot if they\u2019re given sufficiently huge amounts of training. But there isn\u2019t\nany good understanding of just why this is so, and just how successful neural\nnets can be at what kinds of tasks. Ever since the 1940s it has been\nrecognized that there are relations between biological evolution and learning\nin neural nets. And having now seen the impressive things neural nets can do,\nit seems worthwhile to look again at what happens in biological evolution\u2014and\nto try to understand why it works, not least as a prelude to understanding\nmore about neural nets and machine learning.\n\n## Personal Notes\n\nIt\u2019s strange to say, but most of what I\u2019ve done here I should really have done\nforty years ago. And I almost did. Except that I didn\u2019t try quite the right\nexperiments. And I didn\u2019t have the intuition to think that it was worth trying\nmore.\n\nForty years later, I have new intuition, particularly informed by experience\nwith modern machine learning. But even now, what made possible what I\u2019ve done\nhere was a chance experiment done for a somewhat different purpose.\n\nBack in 1981 I had become very interested in the question of how complexity\narises in the natural world, and I was trying to come up with models that\nmight capture this. Meanwhile, I had just finished Version 1.0 of SMP, the\nforerunner to Mathematica and the Wolfram Language\u2014and I was wondering how one\nmight generalize its pattern-matching paradigm to \u201cgeneral AI\u201d.\n\nAs it happened, right around that time, neural nets gained some (temporary)\npopularity. And seeing them as potentially relevant to both my topics I\nstarted simulating them and trying to see what kind of general theory I could\ndevelop about them. But I found them frustrating to work with. There seemed to\nbe too many parameters and details to get any clear conclusions. And, at a\npractical level, I couldn\u2019t get them to do anything particularly useful.\n\nI decided that for my science question I needed to come up with something much\nsimpler. And as a kind of minimal merger of spin systems and neural nets I\nended up inventing cellular automata (only later did I discover that versions\nof them had been invented several times before).\n\nAs soon as I started doing experiments on them, I discovered that cellular\nautomata were a window into an amazing new scientific world\u2014that I have\ncontinued to explore in one way or another ever since. My key methodology, at\nleast at first, was just to enumerate the simplest possible cellular automaton\nrules, and see what they did. The diversity\u2014and complexity\u2014of their behavior\nwas remarkable. But the simplicity of the rules meant that the details of\n\u201csuccessive rules\u201d were usually fairly different\u2014and while there were common\nthemes in their overall behavior, there didn\u2019t seem to be any particular\nstructure to \u201crule space\u201d. (Occasionally, though, particularly in finding\nexamples for exposition, I would look at slightly more complicated and\n\u201cmulticolored\u201d rules, and I certainly anecdotally noticed that rules with\nnearby rule numbers often had definite similarities in their behavior.)\n\nIt so happened that around the time I started publishing about cellular\nautomata in 1983 there was a fair amount of ambient interest in theoretical\nbiology. And (perhaps in part because of the \u201ccellular\u201d in \u201ccellular\nautomata\u201d) I was often invited to theoretical biology conferences. People\nwould sometimes ask about adaptation in cellular automata, and I would usually\njust emphasize what individual cellular automata could do, without any\nadaptation, and what significance it might have for the development of\norganisms.\n\nBut in 1985 I was going to a conference (at Los Alamos) on \u201cEvolution, Games\nand Learning\u201d and I decided I should take a look at the relation of these\ntopics to cellular automata. But, too quickly, I segued away from\ninvestigating adaptation to trying to see what kind of pattern matching and\nother operations cellular automata might be able to be explicitly set up to\ndo:\n\nMany aspects of this paper still seem quite modern (and in fact should\nprobably be investigated more now!). But\u2014even though I absolutely had the\ntools to do it\u2014I simply failed at that time to explore what I\u2019ve now explored\nhere.\n\nBack in 1984 Problem 7 in my \u201cTwenty Problems in the Theory of Cellular\nAutomata\u201d was \u201cHow is different behavior distributed in the space of cellular\nautomaton rules?\u201d And over the years I\u2019d occasionally think about \u201ccellular\nautomaton rule space\u201d, wondering, for example, what kind of geometry it might\nhave, particularly in the continuum limit of infinitely large rules.\n\nBy the latter half of the 1980s \u201ctheoretical biology\u201d conferences had segued\nto \u201cartificial life\u201d ones. And when I went to such conferences I was often\nfrustrated. People would show me simulations that seemed to have far too many\nparameters to ever be able to conclude much. People would also often claim\nthat natural selection was a \u201cvery simple theory\u201d, but as soon as it was\n\u201cimplemented\u201d there\u2019d be all kinds of issues\u2014and choices to be made\u2014about\npopulation sizes, fitness cutoffs, interactions between organisms, and so on.\nAnd the end result was usually a descent into some kind of very specific\nsimulation without obvious robust implications.\n\n(In the mid-1980s I put a fair amount of effort into developing both the\ncontent and the organization of a new direction in science that I called\n\u201ccomplex systems research\u201d. My emphasis was on systems\u2014like cellular\nautomata\u2014that had definite simple rules but highly complex behavior.\nGradually, though, \u201ccomplexity\u201d started to be a popular general buzzword,\nand\u2014I suspect partly to distinguish themselves from my efforts\u2014some people\nstarted emphasizing that they weren\u2019t just studying complex systems, they were\nstudying complex adaptive systems. But all too often this seemed mostly to\nprovide an excuse to dilute the clarity of what could be studied\u2014and I was\nsufficiently put off that I paid very little attention.)\n\nBy the mid-1990s, I was in the middle of writing A New Kind of Science, and I\nwanted to use biology as an example application of my methodology and\ndiscoveries in the computational universe. In a section entitled \u201cFundamental\nIssues in Biology\u201d I argued (as I have here) that computational irreducibility\nis a fundamentally stronger force than natural selection, and that when we see\ncomplexity in biology it\u2019s most likely of \u201ccomputational origin\u201d rather than\nbeing \u201csculpted\u201d by natural selection. And as part of that discussion, I\nincluded a picture of the \u201coften-somewhat-gradual changes\u201d in behavior that\none sees with successive 1-bit changes in a k = 3, r = 1 cellular automaton\nrule (yes, the book was not in color):\n\nThis wasn\u2019t done adaptively; it was basically just looking along a \u201crandom\nstraight line\u201d in rule space. And indeed both here and in most of the book, I\nwas concerned with what systems like cellular automata \u201cnaturally do\u201d, not\nwhat they can be constructed (or adaptively evolved) to do. I did give\n\u201cconstructions\u201d of how cellular automata can perform particular computational\ntasks (like generating primes), and, somewhat obscurely, in a section on\n\u201cIntelligence in the Universe\u201d I explored finding k = 3, r = 1 rules that can\nsuccessfully \u201cdouble their input\u201d (my reason for discussing these rules was to\nhighlight the difficulty of saying whether one of these cellular automata was\n\u201cconstructed for a purpose\u201d or was just \u201cdoing what it does\u201d):\n\nMany years went by. There\u2019d be an occasional project at our Summer School\nabout rule space, and occasionally about adaptation. I maintained an interest\nin foundational questions in biology, gradually collecting information and\nsometimes giving talks about the subject. Meanwhile\u2014though I didn\u2019t\nparticularly internalize the connection then\u2014by the mid-2010s, through our\npractical work on it in the Wolfram Language, I\u2019d gotten quite up to speed\nwith modern machine learning. Around the same time I also heard from my friend\nGreg Chaitin about his efforts (as he put it) to \u201cprove Darwin\u201d using the kind\nof computational ideas he\u2019d applied in thinking about the foundations of\nmathematics.\n\nThen in 2020 came our Physics Project, with its whole formalism around things\nlike multiway graphs. It didn\u2019t take long to realize that, yes, what I was\ncalling \u201cmulticomputation\u201d wasn\u2019t just relevant for fundamental physics; it\nwas something quite general that could be applied in many areas, which by 2021\nI was trying to catalog:\n\nI did some thinking about each of these. The one I tackled most seriously\nfirst was metamathematics, about which I finished a book in 2022. Late that\nyear I was finishing a (50-year-in-gestation) project\u2014informed by our Physics\nProject\u2014on understanding the Second Law of thermodynamics, and as part of this\nI made what I thought was some progress on thinking about the fundamental\ncharacter of biological systems (though not their adaptive evolution).\n\nAnd then ChatGPT arrived. And in addition to being involved with it\ntechnologically, I started to think about the science of it, and particularly\nabout how it could work. Part of it seemed to have to do with unrecognized\nregularities in human language, but part of it was a reflection of the\nemerging \u201cmeta discovery\u201d that somehow if you \u201cbashed\u201d a machine learning\nsystem hard enough, it seemed like it could manage to learn almost anything.\n\nBut why did this work? At first I thought it must just be an \u201cobvious\u201d\nconsequence of high dimensionality. But I soon realized there was more to it.\nAnd as part of trying to understand the boundaries of what\u2019s possible I ended\nup a couple of months ago writing a piece exploring \u201cCan AI Solve Science?\u201d:\n\nI talked about different potential objectives for science (making predictions,\ngenerating narrative explanations, etc.) And deep inside the piece I had a\nsection entitled \u201cExploring Spaces of Systems\u201d in which I talked about science\nproblems of the form \u201cCan one find a system that does X?\u201d\u2014and asked whether\nsystems like neural nets could somehow let one \u201cjump ahead\u201d in what would\notherwise be huge exhaustive searches. As a sideshow to this I thought it\nmight be interesting to compare with what a non-neural-net adaptive evolution\nprocess could do.\n\nRemembering Greg Chaitin\u2019s ideas about connecting the halting problem to\nbiological evolution I wondered if perhaps one could just adaptively evolve\ncellular automaton rules to find ones that generated a pattern with a\nparticular finite lifetime. I imagined it as a classic machine learning\nproblem, with a \u201closs function\u201d one needed to minimize.\n\nAnd so it was that just after 1 am on February 22 I wrote three lines of\nWolfram Language code\u2014and tried the experiment:\n\nAnd it worked! I managed to find cellular automaton rules that would generate\npatterns living exactly 50 steps:\n\nIn retrospect, I was slightly lucky. First, that this ended up being such a\nsimple experiment to try (at least in the Wolfram Language) that I did it even\nthough I didn\u2019t really expect it to work. And second, that for my very first\nexperiment I picked parameters that happened to immediately work (k = 4,\nlifetime 50, etc.).\n\nBut, yes, I could in principle have done the same experiment 40 years ago,\nthough without the Wolfram Language it wouldn\u2019t have been so easy. Still, the\ncomputers I had back then were powerful enough that I could in principle have\ngenerated the same results then as now. But without my modern experience of\nmachine learning I don\u2019t think I would have tried\u2014and I would certainly have\ngiven up too easily. And, yes, it\u2019s a little humbling to realize that I\u2019ve\ngone so many years assuming adaptive evolution was out of the reach of simple,\nclean experiments. But it\u2019s satisfying now to be able to check off another\nmystery I\u2019ve long wondered about. And to think that much more about the\nfoundations of biology\u2014and machine learning\u2014might finally be within reach.\n\n## Thanks\n\nThanks to Brad Klee, Nik Murzin and Richard Assar for their help.\n\nThe specific results and ideas I\u2019ve presented here are mostly very recent, but\nthey build on background conversations I\u2019ve had\u2014some recently, some more than\n40 years ago\u2014with many people, including: Sydney Brenner, Greg Chaitin,\nRichard Dawkins, David Goldberg, Nigel Goldenfeld, Jack Good, Jonathan Gorard,\nStephen J. Gould, Hyman Hartman, John Holland, Christian Jacob, Stuart\nKauffman, Mark Kotanchek, John Koza, Chris Langton, Katja Della Libera,\nAristid Lindenmayer, Pattie Maes, Bill Mydlowec, John Novembre, Pedro De\nOliveira, George Oster, Norman Packard, Alan Perelson, Thomas Ray, Philip\nRosedale, Robert Rosen, Terry Sejnowski, Brian Silverman, Karl Sims, John\nMaynard Smith, Catherine Wolfram, Christopher Wolfram and Elizabeth Wolfram.\n\nPosted in: Uncategorized\n\nRecent Writings\n\nWhen Exactly Will the Eclipse Happen? A Multimillennium Tale of Computation\n\nMarch 29, 2024\n\nComputing the Eclipse: Astronomy in the Wolfram Language\n\nMarch 29, 2024\n\nCan AI Solve Science?\n\nMarch 5, 2024\n\nThe Story Continues: Announcing Version 14 of Wolfram Language and Mathematica\n\nJanuary 9, 2024\n\nObserver Theory\n\nDecember 11, 2023\n\nAll by date\n\nPopular Categories\n\n  * Artificial Intelligence\n  * Big Picture\n  * Companies & Business\n  * Computational Science\n  * Computational Thinking\n  * Data Science\n  * Education\n  * Future Perspectives\n  * Historical Perspectives\n  * Language & Communication\n  * Life & Times\n  * Life Science\n  * Mathematica\n  * Mathematics\n  * New Kind of Science\n  * New Technology\n  * Personal Analytics\n  * Philosophy\n  * Physics\n  * Ruliology\n  * Software Design\n  * Wolfram|Alpha\n  * Wolfram Language\n  * Other\n\nWritings by Year\n\n  * 2024\n  * 2023\n  * 2022\n  * 2021\n  * 2020\n  * 2019\n  * 2018\n  * 2017\n  * 2016\n  * 2015\n  * 2014\n  * 2013\n  * 2012\n  * 2011\n  * 2010\n  * 2009\n  * 2008\n  * 2007\n  * 2006\n  * 2004\n  * 2003\n  * All\n\n\u00a9 Stephen Wolfram, LLC | Open content: (code: ) | Terms | RSS\n\n", "frontpage": false}
