{"aid": "40222965", "title": "Computer Vision, ML, and AI in the Study of Fine Art \u2013 Communications of the ACM", "url": "https://cacm.acm.org/research/computer-vision-ml-and-ai-in-the-study-of-fine-art/", "domain": "acm.org", "votes": 1, "user": "rbanffy", "posted_at": "2024-05-01 13:33:00", "comments": 0, "source_title": "Computer Vision, ML, and AI in the Study of Fine Art \u2013 Communications of the ACM", "source_text": "Computer Vision, ML, and AI in the Study of Fine Art \u2013 Communications of the\nACM\n\n## This website uses cookies\n\nWe use cookies to personalise content and ads, to provide social media\nfeatures and to analyse our traffic. We also share information about your use\nof our site with our social media, advertising and analytics partners who may\ncombine it with other information that you\u2019ve provided to them or that they\u2019ve\ncollected from your use of their services.\n\nDeny Allow all Show details\n\nOK\n\nDeny Allow selection Allow all\n\nShow details\n\nCookie declaration [#IABV2SETTINGS#] About\n\nNecessary (19) Preferences (6) Statistics (11) Marketing (26) Unclassified (0)\n\nNecessary cookies help make a website usable by enabling basic functions like\npage navigation and access to secure areas of the website. The website cannot\nfunction properly without these cookies.\n\nName| Provider| Purpose| Expiry| Type  \n---|---|---|---|---  \n__cf_bm [x3]| ACM Vimeo| This cookie is used to distinguish between humans and\nbots. This is beneficial for the website, in order to make valid reports on\nthe use of their website.| 1 day| HTTP  \nobject(#-#-##:#:#.#)| api.kaltura.nordu.net| Holds the users timezone.|\nPersistent| HTML  \nCookieConsent| Cookiebot| Stores the user's cookie consent state for the\ncurrent domain| 1 year| HTTP  \nwpEmojiSettingsSupports| ACM| This cookie is part of a bundle of cookies which\nserve the purpose of content delivery and presentation. The cookies keep the\ncorrect state of font, blog/picture sliders, color themes and other website\nsettings.| Session| HTML  \nmopDeploy| Mopinion| This is the mechanism by which CACM collects feedback\nfrom website users.| Session| HTML  \n__jid| c.disquscdn.com| Used to add comments to the website and remember the\nuser's Disqus login credentials across websites that use said service.|\nSession| HTTP  \ndisqusauth| c.disquscdn.com| Registers whether the user is logged in. This\nallows the website owner to make parts of the website inaccessible, based on\nthe user's log-in status.| Session| HTTP  \n_cfuvid [x2]| ACM Vimeo| This cookie is a part of the services provided by\nCloudflare - Including load-balancing, deliverance of website content and\nserving DNS connection for website operators.| Session| HTTP  \nhex (32)| CERN| Used to manage server calls to the website's backend systems.|\nSession| HTTP  \n1.gif| Cookiebot| Used to count the number of sessions to the website,\nnecessary for optimizing CMP product delivery.| Session| Pixel  \nbcookie| LinkedIn| Used in order to detect spam and improve the website's\nsecurity.| 1 year| HTTP  \nJSESSIONID [x3]| New Relic LinkedIn Lynda.com| Preserves users states across\npage requests.| Session| HTTP  \nt.gif| WordPress.com| Ensures that product pictures are presented correctly on\nwebsite.| Session| Pixel  \nbscookie| LinkedIn| This cookie is used to identify the visitor through an\napplication. This allows the visitor to login to a website through their\nLinkedIn application for example.| 1 year| HTTP  \n  \nPreference cookies enable a website to remember information that changes the\nway the website behaves or looks, like your preferred language or the region\nthat you are in.\n\nName| Provider| Purpose| Expiry| Type  \n---|---|---|---|---  \naet-dismiss| c.disquscdn.com| Necessary for the functionality of the website's\ncomment-system.| Persistent| HTML  \ndrafts.queue| c.disquscdn.com| Necessary for the functionality of the\nwebsite's comment-system.| Persistent| HTML  \nsubmitted_posts_cache| c.disquscdn.com| Necessary for the functionality of the\nwebsite's comment-system.| Persistent| HTML  \nlang [x2]| LinkedIn Lynda.com| Necessary for maintaining language-settings\nacross subpages on the website.| Session| HTTP  \nlidc| LinkedIn| Registers which server-cluster is serving the visitor. This is\nused in context with load balancing, in order to optimize user experience.| 1\nday| HTTP  \n  \nStatistic cookies help website owners to understand how visitors interact with\nwebsites by collecting and reporting information anonymously.\n\nName| Provider| Purpose| Expiry| Type  \n---|---|---|---|---  \n_hjSession_#| Hotjar| Collects statistics on the visitor's visits to the\nwebsite, such as the number of visits, average time spent on the website and\nwhat pages have been read.| 1 day| HTTP  \n_hjSessionUser_#| Hotjar| Collects statistics on the visitor's visits to the\nwebsite, such as the number of visits, average time spent on the website and\nwhat pages have been read.| 1 year| HTTP  \n_hjTLDTest| Hotjar| Registers statistical data on users' behaviour on the\nwebsite. Used for internal analytics by the website operator.| Session| HTTP  \natuserid| mybbc-analytics.files.bbci.co.uk| Registers statistical data on\nusers' behaviour on the website. Used for internal analytics by the website\noperator.| 13 months| HTTP  \nINVENIOSESSION| CERN| Supports playback tracking for videos embedded from\nCERN.| Session| HTTP  \nINVENIOSESSIONstub| CERN| Supports playback tracking for videos embedded from\nCERN.| Session| HTTP  \njwplayer.captionLabel| CERN| Supports playback tracking for videos embedded\nfrom CERN.| Session| HTTP  \ndisqus_unique| c.disquscdn.com| Collects statistics related to the user's\nvisits to the website, such as number of visits, average time spent on the\nwebsite and loaded pages.| Session| HTTP  \ng.gif| WordPress.com| Registers statistical data on users' behaviour on the\nwebsite. Used for internal analytics by the website operator.| Session| Pixel  \nvuid| Vimeo| Collects data on the user's visits to the website, such as which\npages have been read.| 2 years| HTTP  \ntd| Google| Registers statistical data on users' behaviour on the website.\nUsed for internal analytics by the website operator.| Session| Pixel  \n  \nMarketing cookies are used to track visitors across websites. The intention is\nto display ads that are relevant and engaging for the individual user and\nthereby more valuable for publishers and third party advertisers.\n\nName| Provider| Purpose| Expiry| Type  \n---|---|---|---|---  \n__Host-GAPS| Google| Collects data on the user's visits to the website, such\nas the number of visits, average time spent on the website and what pages have\nbeen loaded with the purpose of generating reports for optimising the website\ncontent.| 2 years| HTTP  \noptin| acm.nui.media| Supports display advertising from CACM's ad partner| 1\nday| HTTP  \n_ga| Google| Used to send data to Google Analytics about the visitor's device\nand behavior. Tracks the visitor across devices and marketing channels.| 2\nyears| HTTP  \n_ga_#| Google| Used to send data to Google Analytics about the visitor's\ndevice and behavior. Tracks the visitor across devices and marketing\nchannels.| 2 years| HTTP  \nbadges-message| c.disquscdn.com| Collects data on the visitor\u2019s use of the\ncomment system on the website, and what blogs/articles the visitor has read.\nThis can be used for marketing purposes.| Persistent| HTML  \nNID| Google| Registers a unique ID that identifies a returning user's device.\nThe ID is used for targeted ads.| 6 months| HTTP  \ncsi| Google| Collects data on visitors' preferences and behaviour on the\nwebsite - This information is used make content and advertisement more\nrelevant to the specific visitor.| Session| Pixel  \n#-#| YouTube| Pending| Session| HTML  \niU5q-!O9@$| YouTube| Registers a unique ID to keep statistics of what videos\nfrom YouTube the user has seen.| Session| HTML  \nLAST_RESULT_ENTRY_KEY| YouTube| Used to track user\u2019s interaction with embedded\ncontent.| Session| HTTP  \nLogsDatabaseV2:V#||LogsRequestsStore| YouTube| Pending| Persistent| IDB  \nremote_sid| YouTube| Necessary for the implementation and functionality of\nYouTube video-content on the website.| Session| HTTP  \nServiceWorkerLogsDatabase#SWHealthLog| YouTube| Necessary for the\nimplementation and functionality of YouTube video-content on the website.|\nPersistent| IDB  \nTESTCOOKIESENABLED| YouTube| Used to track user\u2019s interaction with embedded\ncontent.| 1 day| HTTP  \nVISITOR_INFO1_LIVE| YouTube| Tries to estimate the users' bandwidth on pages\nwith integrated YouTube videos.| 180 days| HTTP  \nVISITOR_PRIVACY_METADATA| YouTube| Stores the user's cookie consent state for\nthe current domain| 180 days| HTTP  \nYSC| YouTube| Registers a unique ID to keep statistics of what videos from\nYouTube the user has seen.| Session| HTTP  \nytidb::LAST_RESULT_ENTRY_KEY| YouTube| Used to track user\u2019s interaction with\nembedded content.| Persistent| HTML  \nYtIdbMeta#databases| YouTube| Used to track user\u2019s interaction with embedded\ncontent.| Persistent| IDB  \nyt-remote-cast-available| YouTube| Stores the user's video player preferences\nusing embedded YouTube video| Session| HTML  \nyt-remote-cast-installed| YouTube| Stores the user's video player preferences\nusing embedded YouTube video| Session| HTML  \nyt-remote-connected-devices| YouTube| Stores the user's video player\npreferences using embedded YouTube video| Persistent| HTML  \nyt-remote-device-id| YouTube| Stores the user's video player preferences using\nembedded YouTube video| Persistent| HTML  \nyt-remote-fast-check-period| YouTube| Stores the user's video player\npreferences using embedded YouTube video| Session| HTML  \nyt-remote-session-app| YouTube| Stores the user's video player preferences\nusing embedded YouTube video| Session| HTML  \nyt-remote-session-name| YouTube| Stores the user's video player preferences\nusing embedded YouTube video| Session| HTML  \n  \nUnclassified cookies are cookies that we are in the process of classifying,\ntogether with the providers of individual cookies.\n\nWe do not use cookies of this type.  \n---  \n  \n[#IABV2_LABEL_PURPOSES#] [#IABV2_LABEL_FEATURES#] [#IABV2_LABEL_PARTNERS#]\n\n[#IABV2_BODY_PURPOSES#]\n\n[#IABV2_BODY_FEATURES#]\n\n[#IABV2_BODY_PARTNERS#]\n\nCookies are small text files that can be used by websites to make a user's\nexperience more efficient.\n\nThe law states that we can store cookies on your device if they are strictly\nnecessary for the operation of this site. For all other types of cookies we\nneed your permission.\n\nThis site uses different types of cookies. Some cookies are placed by third\nparty services that appear on our pages.\n\nYou can at any time change or withdraw your consent from the Cookie\nDeclaration on our website.\n\nLearn more about who we are, how you can contact us and how we process\npersonal data in our Privacy Policy.\n\nPlease state your consent ID and date when you contact us regarding your\nconsent.\n\nCookie declaration last updated on 4/26/24 by Cookiebot\n\nSkip to content\n\nSearch Sign In\n\nJoin ACM\n\nResearch and Advances\n\nArtificial Intelligence and Machine Learning\n\n# Computer Vision, ML, and AI in the Study of Fine Art\n\nOngoing research in the analysis of art is building upon the vast store of\nalgorithms and knowledge from mainstream computer vision, deep learning, and\nartificial intelligence.\n\nBy David G. Stork\n\nPosted Apr 30 2024\n\n  * Share\n\n    * Twitter\n    * Reddit\n    * Hacker News\n  * Download PDF\n  * Print\n  * Join the Discussion\n  * View in the ACM Digital Library\n\n     * Computer Vision in the Study of Fine-Art Paintings and Drawings\n     * Computer-based Tools for Image Analysis of Art\n     * Computer Methods in Resolving Debates in Art Analysis\n     * Problems in Art Analysis that Resist Techniques from Mainstream AI Research\n     * Conclusions, Opportunities, and Future Directions\n     * Acknowledgments\n     * References\n\nIn the past decade, computer vision (CV), machine learning (ML), and\nartificial intelligence (AI) have been applied to problems in the history and\ninterpretation of fine-art paintings and drawings. Such automated methods\nprovide new tools for connoisseurs and art scholars and have resolved art-\nhistorical debates that proved resistant to traditional art-historical\nmethods. Nevertheless, immense challenges and opportunities remain for the\napplication of AI in the study of art, specifically on problems that are\ninadequately addressed by mainstream AI research. For this reason, art\nanalysis serves as a grand challenge to image-based AI.\n\n## Key Insights\n\n  * Fine-art images are some of the most sophisticated, complex and valuable images ever created.\n\n  * Such images present entire classes of problems not well addressed by mainstream AI research.\n\n  * Fine-art paintings and drawings thus serve as a grand challenge to AI.\n\n  * The computational tools, used with deep understanding of the relevant art-historical context, empower art scholars to answer outstanding questions, pose new classes of questions, and develop richer interpretive strategies.\n\n## Computer Vision in the Study of Fine-Art Paintings and Drawings\n\nAdvances in imaging technology and especially CV and AI have, for decades,\nbenefited nearly every scientific and engineering discipline, including\nmedicine, geology, biology, chemistry, and psychology. Consider that works of\nart bear the most memorable and important images ever created by humans, and\nmany works themselves are exceedingly valuable\u2014not just financially but\nculturally. It is natural, then, that computer methods, properly guided by\nscholars\u2019 knowledge of history and context, should be of service in the\nhumanistic studies of art as well. In fact, in the past few years, rigorous\nautomated image analysis has assisted some art historians, critics, and\nconnoisseurs in their scholarly studies of fine-art paintings and drawings.\n\nSuch rigorous computer image analysis of fine art is rather different from\ntraditional \u201cdigital humanities,\u201d which has generally concentrated on digital\nmethods of capture and display but where the fundamental analyses and\ninterpretations are still performed by human scholars and connoisseurs.^38 As\nwe shall see, however, artworks pose several profound problems that require\nsophisticated methods beyond those in traditional digital humanities. These\nrepresent a grand challenge to AI, well beyond what is generally addressed in\nresearch in digital humanities programs and even mainstream artificial\nintelligence.\n\nThis article explores three manifestations of research into computer image-\nbased analysis of fine art. First, the article offers an example of how\ncomputer image analysis can help art scholars by expanding traditional non-\nautomatic approaches. Then, we refer to some debates and issues in art\nscholarship that have been aided significantly\u2014and in some cases solved\u2014thanks\nin large part to computer methods. The article then turns to broad problems in\nimage-based intelligence that arise in art analysis that are inadequately\naddressed by mainstream AI research and hence present great opportunities for\nresearch. The article concludes with thoughts about future directions.\n\n## Computer-based Tools for Image Analysis of Art\n\nComputer image analysis has automated several tasks traditionally performed by\nconnoisseurs and art historians, such as the analysis of composition in\nlandscapes,^22 of brushstrokes and other marks,^23 of canvas weave,^24\nlighting,^21 and general properties of style.^9 Such tools do not replace the\nconnoisseur but instead empower art scholars and extend the analyses they can\nperform, including at scales impractical for efforts solely \u201cby eye.\u201d These\ndigital tools, when used with an awareness of the art historical context, can\nprovide rigor and consistency to analyses and enable the analyses of large-\nscale trends.\n\nConsider just one example, the analysis of pose in portraiture\u2014a formal\nproperty that artists set for numerous compositional and expressive ends.^39\nArt scholars have traditionally used rather subjective, informal, and coarse\ndescriptions of portrait poses\u2014such as frontal, profile, or three-quarters\nview\u2014which they determine entirely by eye. Such traditional methods scale\npoorly and preclude detailed analyses of thousands of portraits, as might\nreveal trends in portraiture over centuries or even over a single prolific\nportraitist\u2019s career.\n\nComputer image analysis offers a powerful tool for portrait pose analysis.\nFigure 1 shows how a pose can be described by three rotation angles as well as\na \u201cproduction model\u201d of the projection of a generic head onto the artist\u2019s\npicture plane. Two deep neural network (DNN) methods\u2014Perspective-n-point^17\nand Fine-grained Structured Aggregation network (FSA-net)^40\u2014can estimate\nthese pose angles automatically based on the locations of extracted visual\nkeypoints, such as the corners of the eyes, mouth, tip of the nose, and so on.\nThese algorithms prove remarkably robust to variations in artistic style.\n\nFigure 1. (L) The head orientation of a subject\u2019s pose can be described by\nrotation angles about three perpendicular axes\u2014yaw, roll, and pitch. (R) We\nmodel the portrait as a projection of the subject\u2019s head onto the picture\nplane of the artwork. The pose angles are computed by a deep neural network\nfrom the geometric configuration of extracted visual keypoints in the artwork.\nEven highly expressive and non-realistic portraits can be analyzed in this\nway, as we shall see in Figure 3.\n\nSuch automated tools permit the rapid and accurate analysis of large corpora\nof portraits. Figure 2 shows computed distributions of the absolute value of\nthe roll angle of 11,000 portraits from a half millennium of Western canon and\nJapanese art, here grouped by art movement. Yaw, tilt, and measures such as\nthe location of the head within the frame of the artwork can be similarly\nestimated, all within four minutes on a desktop computer.^4\n\nFigure 2. Box-whisker plots of the computed absolute value of roll angle in\n11,000 portraits, grouped by art movement. Notice especially the large\ndifference between the means and variances for Japanese Ukiyo-e and so-called\nNa\u00efve or Primitivist portraits, as illustrated in Figure 3.\n\nThere is rich information to be interpreted in this, and related plots, but\nconsider just the differences between Japanese Ukiyo-e (\u201cFloating world\u201d) art\nand so-called Na\u00efve or Primitivist art. The box-whisker plots in Figure 2\nconfirm that Ukiyo-e portraits often exhibit large rotation angles associated\nwith the mie poses of kabuki actors in dramatic moments in plays, or of\ngeishas in seductive poses. By contrast, in Na\u00efve or Primitivist portraits,\nposes are rather \u201csimple,\u201d favoring direct forward gaze. Such pronounced\ndifferences are evident in the representative works in Figure 3.\n\nFigure 3. (L) Portraits from the Japanese Ukiyo-e period, which often depict\nactors in dramatic mie poses in key moments of kabuki plays or geishas in\nfluid or occasionally erotic poses. (R) By contrast, portrait heads in so-\ncalled \u201cNa\u00efve\u201d or \u201cPrimitive\u201d paintings of the Western canon are nearly always\nfrontal and vertical. Such information, and much more, is summarized in box-\nwhisker plots, such as in Figure 2. Image credits (left, clockwise from top\nleft): Toyohara Kunichika, The Actor Ichikawa Sadanji I as Akiyama Kii No\nKami, (1894), Art Institute of Chicago (CCo); Hashiguchi Goyou, Woman Combing\nHer Hair, Detail, (1920), Walters Art Museum (CCo); Utagawa Toyokuni III,\nMitate Sanko No Uchi, (1858), Walters Art Museum, (CCo); Masatsuya, Otani\nOniji III as Ono Sadakuro, Art Institute of Chicago (CCo); (right, clockwise\nfrom top left): Pablo Picasso, Les Demoiselles D\u2019Avignon, (1907), Museum of\nModern Art {{PD-U.S.}}; Henri Rosseau, Myself\u2013Portrait-Landscape, (1890),\nNational Gallery, Prague {{PD-U.S.}}; Amedeo Modigliani, Young Woman, (1918),\nNational Museum, Oslo, Norway {{PD-U.S.}}; Henri Matisse, The Italian Woman,\n(1916), The Solomon R. Guggenheim Museum {{PD-U.S.}}.\n\nArtists often take characteristic bodily stances in the studio when executing\nself-portraits. For instance, a right-handed artist will place the easel to\nthe right of the plane mirror so as to better reach it with the dominant hand,\nand the artist\u2019s head is often rotated somewhat toward the canvas. The head of\na left-handed artist will be rotated in the opposite direction. The\ndistribution of (signed) yaw angles will differ between right- and left-handed\nself-portraitists; indeed, such differences are evident in the computational\ndata. That is, the computational results reveal which artists were likely\nleft-handed.^4\n\nThe automated pose-estimation algorithms extend previous work, providing a\nfoundation for a range of future studies in art analysis.^18 For instance, one\ncan incorporate face-based gender recognition as a pre-processing step to\nexplore gender-specific trends in poses.^25 Likewise, with possible style-\nbased tailoring of face-recognition algorithms, one might explore trends in\nnon-Western art, particularly Asian art, such as portraits from the Song\nDynasty^41 or from the Renaissance.^13\n\nDeep neural networks for art analysis. Deep networks developed for natural\nphotographs have been modified through their architectures and transfer\ntraining to perform well on segmentation of art images throughout a wealth of\nstyles and media\u2014a task vastly more difficult than in natural images.^14 Deep\nnetworks trained with large corpora of art images and contributed textual\nsummaries of human responses can accurately predict human emotional responses\nto novel artworks.^1 Deep networks have been applied to the extremely\nchallenging and important task of art authentication.^8^,^28 Most of these\nmethods address just image information and thus have not been accepted by the\nart community because authentication also rests on studies of materials\n(pigment, canvas, and so on), provenance (documentary record of ownership and\ndisplay), iconography, and more. As such, there are deep challenges to AI for\nincorporating such diverse forms of information for authentication, which will\nbe discussed again later in this article.\n\n## Computer Methods in Resolving Debates in Art Analysis\n\nRigorous computer image analysis has not merely served as a tool easing\ntraditional interpretive tasks but has also resolved art historical debates\nfor which methods from traditional art scholarship proved incomplete or\ninadequate. In 2000, the celebrated British and American artist David Hockney,\nlater aided by thin-film physicist Charles Falco, claimed to have \u201cproven\u201d\nthat some artists as early as 1420 secretly used optical devices during the\nexecution of some of their works, and more broadly that the use of optics led\nto an enhanced realism or \u201coptical look\u201d of the \u201cars nova\u201d or new art of that\ntime.^15^,^16\n\n> Rigorous computer image analysis has not merely served as a tool easing\n> traditional interpretive tasks but has also resolved art historical debates.\n\nPart of the evidence they adduced rested on Hockney\u2019s claim that the complex\nchandelier in Jan van Eyck\u2019s Arnolfini portrait was \u201cin perfect perspective,\u201d\nwhich (Hockney claimed) implied van Eyck used optics to draw it. Sophisticated\nhomographic analysis of the image of the chandelier, based on an ACM\nDissertation Award-winning thesis,^6 showed that in fact the chandelier\ndeviated significantly from \u201cperfect perspective,\u201d thereby rebutting the\noptical proposal, at least for that painting.^5^,^6^,^29\n\nHockney also adduced Georges de la Tour\u2019s Christ in the Carpenter\u2019s Shop as\nevidence that this artist used optical projections. In brief, his claim rests\non his reading of the work that the light source was \u201coutside the [frame of\nthe] picture.\u201d Application of sophisticated and rigorous occluding-contour\nalgorithms and maximum-likelihood estimation of the location of the source of\nillumination based on five classes of image information showed definitively\nthat Hockney\u2019s claim was false and that instead the source of the illumination\nwas at the depicted candle. Such rigorous methods thus refuted Hockney\u2019s\nargument.^36\n\nHockney and Falco claimed their most definitive evidence for Lorenzo Lotto\u2019s\nputative use of optics arose in Husband and Wife, where they claimed geometric\nand other \u201canomalies\u201d in the depicted carpet \u201cproved\u201d that Lotto used a small,\nconcave mirror to project an image during the execution of this work.^16\nRigorous analysis using computer ray-tracing software showed instead that the\nproposed setup simply could not work as claimed. Moreover, when the required\ncorrections to their setup were made, the computer ray-tracing evidence\ncontradicted the optical claim.^27\n\nBroadly speaking, computer image analysis supported and confirmed the\nunanimous independent scholarly rejection of Hockney\u2019s theory.^35 Indeed,\npartially in response to the rigorous computer-assisted analyses, Hockney\nhimself has retreated from his projection claim. Similarly, engineer and self-\ndescribed non-artist Tim Jenison argued that Johannes Vermeer secretly used a\ncatadioptric telescope during the creation of his sublime interior genre\npaintings,^20 but computer-enhanced analyses (and facts of historical and\nmaterial culture) refuted Jenison\u2019s claim.^31^,^32^,^37\n\n## Problems in Art Analysis that Resist Techniques from Mainstream AI Research\n\nMost traditional AI algorithms have been developed for analyzing natural\nphotographs, videos, and specialized images such as medical x-radiographs.\nThese images have properties that, at base, derive from the laws governing the\nnatural world, be they everyday physics of objects and light, medical or\nremote images governed by electromagnetic radiation, and so on. Art images\ndiffer in numerous ways from those just listed and present several deep\nchallenges that are inadequately addressed by current mainstream research,\nincluding the following:\n\nStyle. There is no unanimous agreement concerning the definition of style in\nfine-art paintings. Nevertheless, style certainly refers to formal properties\nof color, composition, marks, brush strokes, and so on considered as distinct\nfrom the nominal subject matter. Portraits, to take just one genre, can be\nrendered in styles that are highly realistic, expressive, or abstract, in\nunnatural colors executed in a wide variety of marks and brush strokes and\ninnumerable personal styles. The variety of styles found in paintings is\nvastly greater than that found in the natural photographs that have commanded\nthe attention of the AI community.\n\nStyle presents several challenges to computer analysis, for instance the\nrecognition of style and identifying an artist (\u201cauthor\u201d) by the style of a\nwork: image segmentation, object recognition, and scene analysis. Works such\nas shown in Figure 4 present great challenges in these regards\u2014challenges to\nhuman viewers and algorithms alike.\n\nFigure 4. Willem de Kooning\u2019s Woman I (1950\u201352), Museum of Modern Art,\nillustrates Abstract Expressionism\u2019s emphasis on bold visible brush strokes,\nunnatural colors, and distortion of form, and more. Such a work presents deep\nchallenges in visual analysis to both human viewers and algorithms alike.\n\nSmall data sets. As mentioned earlier in this article, an important recent\ndevelopment in image analysis is the use of DNNs trained with hundreds of\nmillions or more natural photographs. Such approaches have provided human-\nlevel or superhuman-level performance on several image-analysis tasks.\nUnfortunately, such systems generally perform quite poorly on stylized\npaintings and drawings, for instance the work in Figure 4.\n\nThe rather obvious approach would be to train deep networks with large corpora\nof representative art images. Alas, this approach generally cannot be followed\ndirectly because there simply are not enough representative art images. After\nall, the Spanish master Pablo Picasso\u2014one of the most prolific artists of all\ntime\u2014leaves us merely 13,500 paintings. Johannes Vermeer leaves us just 33,\neach considered a distinctive masterpiece, such as shown in Figure 5.\n\nFigure 5. Johannes Vermeer\u2019s A Glass of Wine (1658\u201360); (Photo \u00a9 Jos\u00e9 Luiz\nBernardes Ribeiro /CC-BY: 4.0), Gem\u00e4ldegalerie, Berlin. Vermeer leaves us\nroughly 33 paintings\u2014far too few to train deep networks to recognize the\nmaster\u2019s works reliably.\n\nOne way to overcome the relative paucity of art images is to transfer-train a\nDNN, that is, present art images as additional training patterns to a network\npreviously trained with a very large number of photographs. This approach has\nproven of only modest value on problems such as image segmentation and is\nunlikely to provide significant benefit on more challenging problems, such as\nscene analysis. An alternate approach has shown success for the problem of\nimage segmentation in artworks. We used deep networks to map artistic style\nonto photographs to thereby produce a large corpus of images of modern\nsubjects rendered in artistic styles of artists. Training with this large\ncorpus of \u201csurrogate artworks\u201d yields highly accurate performance on tasks\nsuch as segmentation.^14 Nevertheless, much research remains to be done.\n\nImaginary objects. Non-realist artists frequently depict imaginary objects or\ncreatures, such as angels, dragons, and so on. Artists from the Dada Movement\nof the early 20^th century, such as Salvador Dal\u00ed, Marcel Duchamp, Man Ray,\nand Ren\u00e9 Magritte, frequently altered the properties of objects for surprise.\nThe fact that these objects are unusual or even unique is often central to the\nartist\u2019s expressive goals, of course. The fact that such objects are rare or\nunique presents a great challenge to AI systems for recognizing such objects\nand interpreting their associated artworks. These objects do not appear in\nlarge corpora of photographs typically used for training networks for image\nanalysis. Perhaps one approach would be to develop modular deep networks that\ncan flexibly decompose an image passage into components and styles that are\nrarely found in images.\n\nNonphysical conventions. Because artists are not constrained to slavishly\ndepict the physical world, they can employ nonphysical conventions in service\nof their artistic goals. Thus, they can depict figures floating into the\nheavens, bulls that swim, infants that glow, and so on, as exemplified in\nFigure 6. The computational problem here is to recognize the non-physical\nconvention given that training sets of natural photographs do not depict\nscenes in such conventions.\n\nFigure 6. Michelangelo\u2019s The Last Judgement from the Cistine Chapel (1512),\nThe Vatican {{PD-U.S.}}.\n\nThe development of a work, as revealed by its multiple layers. Many works of\nart, in particular Old Master easel paintings, were developed through\nunderdrawings, revisions, and so on. These hidden layers are revealed through\nX-ray, infrared, and other imaging methods. Art scholars seek to understand an\nartist\u2019s praxis and artistic intent by studying the changes in composition and\nother formal properties. For example, Figure 7 shows an X-ray and the visible\nimage in the central passage in Rembrandt\u2019s The Night Watch. Careful\nexamination reveals numerous differences\u2014large and small\u2014between these two\nversions, and these are studied closely by art scholars crafting\ninterpretations.\n\nFigure 7. Rembrandt\u2019s The Night Watch (1642), detail, Rijksmuseum. (Left)\nX-ray showing underdrawings and pentimenti, the earliest stages of the\ncomposition. (Right) The final painting in visible light. {{PD-U.S.}}\n\nThe computational task is to detect, represent, analyze, and ultimately\ninterpret such changes, which have no counterpart in the vast number of\nnatural photographs that dominate traditional AI research.\n\nAbstraction. Abstraction is an extremely important genre of art, spanning a\ngreat variety of forms and styles (See Figure 8), and one for which natural\nphotographs have little or no relevance. The challenges to AI research include\nrecognizing artists (\u201cauthors\u201d) by their abstract works,^19^,^30 tracing the\ndevelopment of abstract styles throughout an artist\u2019s career (and thus helping\nto establish the execution date of works), and related problems.\n\nFigure 8. Morris Louis\u2019 Dalet Kaf (1959), Modern Art Museum of Fort Worth, TX.\nThis work from the Washington Color School was executed by pouring layers and\nlayers of dilute paint onto the canvas draped over supports so that the paint\nwould flow and stain the canvas.\n\nRecovering lost works. A great deal of fine art, including some of the most\nimportant and influential artworks ever created, has been lost to war, fire,\nflood, iconoclasm, theft, and other reasons.^3 For example, Diego Vel\u00e1zquez\u2019s\nLas Meninas is often considered one of the most important paintings of the\nWestern canon; it barely escaped a fire in the Alcazar Palace in 1743. Alas,\nthis artist\u2019s Expulsion of the Moriscos, which in his day was even more highly\npraised than Las Meninas, was completely burned in that same fire. Recovering\nthe image of such a work would be of immense value to art history and to our\ncultural heritage more generally. It would provide deeper insight into\nVel\u00e1zquez and his oeuvre, the cultural environment of the Spanish Golden Age,\nprovide insights into artists who were influenced by the lost work, and much\nmore.^7\n\nFigure 9. Proof-of-concept computational reconstruction of Diego Vel\u00e1zquez\u2019s\n(lost) The Expulsion of the Moriscos (1627).\n\nComputational methods based on DNNs have shown promise in recovering\nproperties or portions of lost artwork, and thus show such as the colors in\npaintings by the Austrian artist Gustav Klimt,^26 and of ghost paintings^2 and\nmissing passages of Rembrandt\u2019s The Night Watch.^10 Computational\nreconstruction of a full image of a lost artwork would require a sophisticated\nintegration of information in diverse forms: preparatory sketches and other\nworks by the artist, copies by other artists, textual descriptions of the\nwork, knowledge of the author\u2019s working methods and media (available pigments\nand drawing tools), the likely date of execution, and more, as shown in the\nproof-of-concept computational reconstruction in Figure 9.^11\n\nSemantics. Much of human communications is indirect or non-explicit, and so\nonly relatively narrow forms of intelligence can be captured in datasets of\nreal images, for instance. While one of the core purposes of artwork was for\nthe artist to convey a complex and indirect meaning, verbose descriptions for\nwhich accompany virtually every masterpiece.\n\nAs a result, perhaps the deepest and most challenging class of problems posed\nby art that is not adequately addressed by current traditional AI research\nconcerns semantics, that is, deriving coherent \u201cmeanings\u201d associated with\nworks.\n\nMainstream AI approaches to semantic image analysis seek to form text\nsummaries, such as captions, of a photographic image. The semantic problems\narising in art are rather different. Here the goal is to infer the artist\u2019s\nmeaning or intention, for example what message, moral, story, or abstract idea\nthe artist seeks to convey. Consider, for instance, Ren\u00e9 Magritte\u2019s celebrated\nThe Treachery of Images in Figure 10. Mainstream semantic analysis would\nrecognize the pipe, and the text, and presumably detect the contradiction, but\nnot infer why the artist created this work and how this relates to the fact\nthat this is a painting of a pipe, a painting of text, and much more.\nPreliminary results using deep networks extract components of meaning in\nreligious art.^34\n\nFigure 10. Ren\u00e9 Magritte\u2019s The Treachery of Images (1928), \u00a9 Ren\u00e9 Magritte\nFair Use, Los Angeles County Museum of Art (LACMA). The many readings and\ninterpretations of this Surrealist work include a recognition of the\ncontradiction between what is being depicted and what is stated through text,\nthe fact that \u201cthis\u201d could refer to the image or to the artwork or to the\nsentence itself, and much more.\n\n## Conclusions, Opportunities, and Future Directions\n\nFine art paintings and drawings represent some of the most carefully\nconstructed, memorable, complex, and important images of any form, and they\npresent deep challenges to computer vision and artificial intelligence that in\nmany cases are not addressed by mainstream research focused on natural\nphotographs, medical and remote sensed images, and others.\n\nOngoing research in the analysis of art is building upon the vast store of\nalgorithms and knowledge from mainstream computer vision, deep learning, and\nartificial intelligence. Continued progress demands an integration of\nhumanists\u2019 knowledge of art historical facts and contexts as well as on\ncomputer scientists\u2019 knowledge of algorithms, and creativity in tailoring them\nto problems in art. Such a research program promises to empower humanist\nscholars and shed light upon some of the most sophisticated and fascinating\naspects of intelligence\u2014human and machine.^12^,^33\n\n## Acknowledgments\n\nThe author wrote much of this article while an External Reader at the Library\nat the Getty Research Institute, Los Angeles and as a Leonardo@Djerassi Fellow\nin Residency at the Djerassi Foundation, Woodside, CA, and would like to thank\nthese institutions for their support.\n\n## References\n\n    * 1\\. Achlioptas, P. et al. ArtEmis. Guibas. ArtEmis: Affective language for visual art. In Proceedings of the Conf. on Computer Vision and Pattern Recognition, (2021), 11569\u201311579.\n\n    * 2\\. Bourached, A., Cann, G.H., Griffiths, R., and Stork, D.G. Recovery of underdrawings and ghost-paintings via style transfer by deep convolutional neural networks: A digital tool for art scholars. In Computer Vision and Analysis of Art. D.G. Stork and K. Heumiller (eds.). IS&T, (2021).\n\n    * 3\\. Charney, N. The Museum of Lost Art. Phaidon Press, New York, NY (2018).\n\n    * 4\\. Chou, J.-P. and Stork, D.G. Computational tracking of head pose through 500 years of fine-art portraiture. In Computer Vision and Analysis of Art. Electronic Imaging. D.G. Stork and K. Heumiller (eds.), (2023).\n\n    * 5\\. Criminisi, A. Machine vision: The answer to the optical debate? In Proceedings of the Optical Society of American Annual Meeting. Rochester, NY (2004).\n\n    * 6\\. Criminisi, A. and Stork, D.G. Did the great masters use optical projections while painting? Perspective comparisons of paintings and photographs of Renaissance chandeliers. In Proceedings of the 17th Intern. Conf. on Pattern Recognition IV. J. Kittler, M. Petrou, and M.S. Nixon (eds.), 2004, 645\u2013648.\n\n    * 7\\. Demetriou, M.L., Hardeberg, J.Y., and Adelmann, G. Computer-aided reclamation of lost art. In Proceedings of the European Conf. on Computer Vision 7583. Springer, (2012), 551\u2013560.\n\n    * 8\\. Elgammal, A., Kang, Y., and Leeuv, M.D. Picasso, Matisse, or a fake? Automated analysis of drawings at the stroke level for attribution and authentication. In Proceedings of the 32nd AAAI Conf. on Artificial Intelligence, (2018), 42\u201350.\n\n    * 9\\. Elgammal, A. et al. The shape of art history in the eyes of the machine. In Proceedings of the AAAI Conf. on Artificial Intelligence, (2018), 2183\u20132191.\n\n    * 10\\. Erdmann, R. Rembrandt\u2019s The Night Watch painting restored by AI. BBC , (2021); www.bbc.com/news/technology-57588270.\n\n    * 11\\. Eriksson, J., Bourached, A., Cann, G., and Stork, D.G. Recovering lost artworks by deep neural networks: Motivations, methodology, and proof-of-concept simulations. In Computer Vision and Analysis of Art. D.G. Stork and K. Heumiller (eds.). IS&T (2023).\n\n    * 12\\. Foka, A. Computer vision applications for art history: Reflections and paradigms for future research. In Proceedings of EVA, (2021), 73\u201380.\n\n    * 13\\. Gupta, A., Mithun, N., Rudolph, C., and Roy-Chowdhury, A.K. Deep learning based identity verification in Renaissance portraits. In Proceedings of the IEEE Intern. Conf. on Multimedia and Expo, (2018), 1\u20136.\n\n    * 14\\. Heitzinger, T. and Stork, D.G. Improving semantic segmentation of fine art images using photographs rendered in a style learned from artworks. Computer Vision and Analysis of Art. D.G. Stork and K. Heumiller (eds.). IS&T, (2022).\n\n    * 15\\. Hockney, D. Secret Knowledge: Rediscovering the Lost Techniques of the Old Masters. Viking Studio, New York, NY (2001).\n\n    * 16\\. Hockney, D. and Falco, C.M. Optical insights into Renaissance art. Optics and Photonics News 11, 7 (2000), 52\u201359.\n\n    * 17\\. Hu, Y., Fua, P., Wang, W., and Salzmann, M. Single-stage 6D object pose estimation. In Proceedings of the Conf. on Computer Vision and Pattern Recognition, (2020), 2930\u20132939.\n\n    * 18\\. Huber, M. et al. Verification of sitter identity across historical portrait paintings by confidence-aware face recognition. In Proceedings of the 26th Intern. Conf. on Pattern Recognition, (2022), 938\u2013944.\n\n    * 19\\. Irfan, M. and Stork, D.G. Multiple visual features for the computer authentication of Jackson Pollock\u2019s drip paintings: Beyond box-counting and fractals. In Electronic Imaging: Image Processing: Machine Vision Applications II, 7251 , K. S. Niel and D. Fofi (eds.), (2009).\n\n    * 20\\. Jenison, T. Tim\u2019s Vermeer: A film by Penn and Teller. Sony Pictures Classic and High Delft Pictures LLC, (2013).\n\n    * 21\\. Johnson, M.K., Stork, D.G., Biswas, S., and Furuichi, Y. Inferring illumination direction estimated from disparate sources in paintings: An investigation into Jan Vermeer\u2019s Girl with a pearl earring. In Computer Vision and Analysis of Art 6810. D.G.Stork and J.Coddington (eds.), (2008).\n\n    * 22\\. Lee, B. et al. Dissecting landscape art history with information theory. In Proceedings of the National Academy of Science 117, 43 (2020), 26580\u201326590.\n\n    * 23\\. Li, J., Yao, L., Hendriks, E., and Wang, J.Z. Rhythmic brushstrokes distinguish van Gogh from his contemporaries: Findings via automated brushstroke extraction. In Proceedings of IEEE Transactions on Pattern Analysis and Machine Intelligence 34, 6 (2012), 1159\u20131176.\n\n    * 24\\. Liedtke, W., Johnson, Jr., C.R., and Johnson, D.H. Canvas matches in Vermeer: A case study in the computer analysis of fabric supports. Metropolitan Museum J. 47, 1 (2012), 101\u2013108.\n\n    * 25\\. Ng, C., Tay, Y., and Goi, B. A review of facial gender recognition. In Proceedings of IEEE Transactions on Pattern Analysis and Applications 18, (2015), 739\u2013755.\n\n    * 26\\. Rein, S. How machine learning revived long lost masterpieces by Klimt. Google Arts and Culture, (2021); https://bit.ly/49OTuU5\n\n    * 27\\. Robinson, M.D. and Stork, D.G. Aberration analysis of the putative projector for Lorenzo Lotto\u2019s Husband and wife: Image analysis through computer ray-tracing. Computer Vision and Analysis of Art 6810. D.G. Stork and J. Coddington (eds.), (2008).\n\n    * 28\\. Sander, M.E., Tom, T.S., and Sylvestre, M. Unveiling the secrets of paintings: Deep neural networks trained on high-resolution multispectral images for accurate attribution and authentication. In Proceedings of the 16th Intern. Conf. on Quality Control by Artificial Vision 12749, (2023), 312\u2013318.\n\n    * 29\\. Stork, D.G. Optics and realism in Renaissance art. Scientific American 291, 6 (2004), 76\u201384.\n\n    * 30\\. Stork, D.G. Learning-based authentication of Jackson Pollock\u2019s drip paintings. SPIE Newsroom (May 27, 2009).\n\n    * 31\\. Stork, D.G. Tim\u2019s Vermeer, reconsidered. Optics and Photonics News 32, 3 (March 2021), 38\u201345.\n\n    * 32\\. Stork, D.G. Did Vermeer use a telescope while painting? Analyzing Tim\u2019s Vermeer IFAR J. 21, 1\u20132 (2022), 43\u201350.\n\n    * 33\\. Stork, D.G. Pixels & Paintings: Foundations of Computer-Assisted Connoisseurship. Wiley, Hoboken, NJ, (2023).\n\n    * 34\\. Stork, D.G., Bourached, A., Cann, G.H., and Griffiths, R. Computational identification of significant figures in paintings through symbols and attributes. In Computer Vision and Analysis of Art. D.G. Stork and K. Heumiller (eds.). IS&T, (2021).\n\n    * 35\\. Stork, D.G. et al. Did early Renaissance painters trace optically projected images? The conclusion of independent scientists, art historians and artists. In Digital Imaging for Cultural Heritage Preservation, CRC Press, (2011), 379\u2013407.\n\n    * 36\\. Stork, D.G. and Johnson, M.K. Estimating the location of illuminants in realist master paintings: Computer image analysis addresses a debate in art history of the Baroque. In Proceedings of the 18th Intern. Conf. on Pattern Recognition I , IEEE Press, (2006), 255\u2013258.\n\n    * 37\\. Stork, D.G., Tyler, C.W., and Schechner, S.J. Did Tim paint a Vermeer? J. of Imaging Science and Technology 64, 6 (2020).\n\n    * 38\\. Defining Digital Humanities: A Reader. M. Terras, J. Nyhan, and E. Vanhoutte (eds.). Routledge Press, (2013).\n\n    * 39\\. Portraiture: Facing the Subject. J. Woodward (Ed.), Manchester University Press, (1997).\n\n    * 40\\. Yang, T.-Y., Chen, Y.-T., Lin, Y.-Y., and Chuang, Y.-Y. FSA-net: Learning fine-grained structure aggregation for head pose estimation from a single image. In Proceedings of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (2019), 1087\u20131096.\n\n    * 41\\. Zhong, G. A computer vision-aided analysis of facial similarities in Song dynasty imperial portraits. In Proceedings of Computer Vision and Analysis of Art IS&T . D.G. Stork and K. Heumiller (eds.), (2023).\n\nDavid G. Stork is adjunct professor of Symbolic Systems and Material Science\nand Engineering, and visiting lecturer in Electrical Engineering and\nComputational Mathematical Engineering at Stanford University. He is widely\nconsidered a pioneer in the application of computer methods to problems in the\nhistory and interpretation of art, material discussed in his book Pixels &\nPaintings: Foundations of Computer-assisted Connoisseurship (Wiley, 2024).\n\n  * Share\n\n    * Twitter\n    * Reddit\n    * Hacker News\n  * Download PDF\n  * Print\n  * Join the Discussion\n\nSubmit an Article to CACM\n\nCACM welcomes unsolicited submissions on topics of relevance and value to the\ncomputing community.\n\nYou Just Read\n\n#### Computer Vision, ML, and AI in the Study of Fine Art\n\nView in the ACM Digital Library\n\n\u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to\nACM.\n\n### DOI\n\n10.1145/3633454\n\n### Related Reading\n\n  * Practice\n\nTo PiM or Not to PiM\n\nArchitecture and Hardware\n\n  * Research and Advances\n\nDemocratizing Domain-Specific Computing\n\nArchitecture and Hardware\n\nAdvertisement\n\nAdvertisement\n\n### Join the Discussion (0)\n\n#### Become a Member or Sign In to Post a Comment\n\nSign In Sign Up\n\n### The Latest from CACM\n\nExplore More\n\nBLOG@CACM May 1 2024\n\nHiPEAC\u2019s Vision for the Future\n\nTullio Vardanega and Marc Duranton\n\nComputing Profession\n\nBLOG@CACM Apr 29 2024\n\nA Brief History of Embodied Artificial Intelligence, and Its Future Outlook\n\nShaoshan Liu and Shuang Wu\n\nArchitecture and Hardware\n\nBLOG@CACM Apr 26 2024\n\nOptimizing Energy Efficiency in Datacenters with Advanced Cooling Technologies\n\nAlex Williams\n\nArchitecture and Hardware\n\n### Shape the Future of Computing\n\nACM encourages its members to take a direct hand in shaping the future of the\nassociation. There are more ways than ever to get involved.\n\nGet Involved\n\n### Communications of the ACM (CACM) is now a fully Open Access publication.\n\nBy opening CACM to the world, we hope to increase engagement among the broader\ncomputer science community and encourage non-members to discover the rich\nresources ACM has to offer.\n\nLearn More\n\nTopics\n\n  * Architecture and Hardware\n  * Artificial Intelligence and Machine Learning\n  * Computer History\n  * Computing Applications\n  * Computing Profession\n  * Data and Information\n  * Education\n  * HCI\n  * Philosophy of Computing\n  * Security and Privacy\n  * Society\n  * Software Engineering and Programming Languages\n  * Systems and Networking\n  * Theory\n\nMagazine\n\n  * Latest Issue\n  * Magazine Archive\n  * Editorial Staff and Board\n  * Submit an Article\n  * Alerts & Feeds\n  * Author Guidelines\n\nCommunications of the ACM\n\n  * About Us\n  * Frequently Asked Questions\n  * Contact Us\n  * For Advertisers\n  * Join ACM\n\n\u00a9 2024 Communications of the ACM. All Rights Reserved.\n\n  * Cookie Notice\n  * Privacy Policy\n\n", "frontpage": false}
