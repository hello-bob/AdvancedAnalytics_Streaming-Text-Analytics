{"aid": "40291408", "title": "Python Scraper Based on AI", "url": "https://github.com/VinciGit00/Scrapegraph-ai", "domain": "github.com/vincigit00", "votes": 1, "user": "adif_sgaid", "posted_at": "2024-05-07 21:00:19", "comments": 0, "source_title": "GitHub - VinciGit00/Scrapegraph-ai: Python scraper based on AI", "source_text": "GitHub - VinciGit00/Scrapegraph-ai: Python scraper based on AI\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nVinciGit00 / Scrapegraph-ai Public\n\n  * Notifications\n  * Fork 186\n  * Star 2.4k\n\nPython scraper based on AI\n\nscrapegraph-doc.onrender.com/\n\n### License\n\nMIT license\n\n2.4k stars 186 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# VinciGit00/Scrapegraph-ai\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n6 Branches\n\n42 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nVinciGit00Merge pull request #167 from KPCOFGS/mainMay 7, 20249a873ca \u00b7 May 7,\n2024May 7, 2024\n\n## History\n\n630 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| ci: remove pull request trigger and fix plugin release train| Apr 26, 2024  \n  \n### docs\n\n|\n\n### docs\n\n| Update installation.rst| May 4, 2024  \n  \n### examples\n\n|\n\n### examples\n\n| Resolve merge conflicts| May 4, 2024  \n  \n### manual deployment\n\n|\n\n### manual deployment\n\n| add new version| Apr 27, 2024  \n  \n### scrapegraphai\n\n|\n\n### scrapegraphai\n\n| removed unused node| May 5, 2024  \n  \n### tests\n\n|\n\n### tests\n\n| Merge branch 'pre/beta' into main| May 2, 2024  \n  \n### .gitattributes\n\n|\n\n### .gitattributes\n\n| Initial commit| Jan 27, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| add csv scraper| May 1, 2024  \n  \n### .releaserc.yml\n\n|\n\n### .releaserc.yml\n\n| ci: add ci workflow to manage lib release with semantic-release| Apr 25,\n2024  \n  \n### CHANGELOG.md\n\n|\n\n### CHANGELOG.md\n\n| ci(release): 0.9.0 [skip ci]| May 4, 2024  \n  \n### CODE_OF_CONDUCT.md\n\n|\n\n### CODE_OF_CONDUCT.md\n\n| Create CODE_OF_CONDUCT.md| Feb 5, 2024  \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n| fix: examples and graphs| May 2, 2024  \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n| Create Dockerfile| Apr 10, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| add new node| Feb 17, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| Update README.md| May 7, 2024  \n  \n### SECURITY.md\n\n|\n\n### SECURITY.md\n\n| changed documentation + fixed a typo for the path| Feb 7, 2024  \n  \n### citation.cff\n\n|\n\n### citation.cff\n\n| add quotation file| Mar 4, 2024  \n  \n### docker-compose.yml\n\n|\n\n### docker-compose.yml\n\n| docker compose working ollama implementation| Apr 7, 2024  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| ci(release): 0.9.0 [skip ci]| May 4, 2024  \n  \n### readthedocs.yml\n\n|\n\n### readthedocs.yml\n\n| changed the read the docs command| Feb 15, 2024  \n  \n### requirements-dev.txt\n\n|\n\n### requirements-dev.txt\n\n| add: poetry.toml for actions| Feb 17, 2024  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| build(deps): bump tqdm from 4.66.1 to 4.66.3| May 4, 2024  \n  \n## Repository files navigation\n\n# \ud83d\udd77\ufe0f ScrapeGraphAI: You Only Scrape Once\n\nScrapeGraphAI is a web scraping python library that uses LLM and direct graph\nlogic to create scraping pipelines for websites, documents and XML files. Just\nsay which information you want to extract and the library will do it for you!\n\n## \ud83d\ude80 Quick install\n\nThe reference page for Scrapegraph-ai is available on the official page of\npypy: pypi.\n\n    \n    \n    pip install scrapegraphai\n\nyou will also need to install Playwright for javascript-based scraping:\n\n    \n    \n    playwright install\n\nNote: it is recommended to install the library in a virtual environment to\navoid conflicts with other libraries \ud83d\udc31\n\n## \ud83d\udd0d Demo\n\nOfficial streamlit demo:\n\nTry it directly on the web using Google Colab:\n\nFollow the procedure on the following link to setup your OpenAI API key: link.\n\n## \ud83d\udcd6 Documentation\n\nThe documentation for ScrapeGraphAI can be found here.\n\nCheck out also the docusaurus documentation.\n\n## \ud83d\udcbb Usage\n\nYou can use the SmartScraper class to extract information from a website using\na prompt.\n\nThe SmartScraper class is a direct graph implementation that uses the most\ncommon nodes present in a web scraping pipeline. For more information, please\nsee the documentation.\n\n### Case 1: Extracting information using Ollama\n\nRemember to download the model on Ollama separately!\n\n    \n    \n    from scrapegraphai.graphs import SmartScraperGraph graph_config = { \"llm\": { \"model\": \"ollama/mistral\", \"temperature\": 0, \"format\": \"json\", # Ollama needs the format to be specified explicitly \"base_url\": \"http://localhost:11434\", # set Ollama URL }, \"embeddings\": { \"model\": \"ollama/nomic-embed-text\", \"base_url\": \"http://localhost:11434\", # set Ollama URL } } smart_scraper_graph = SmartScraperGraph( prompt=\"List me all the articles\", # also accepts a string with the already downloaded HTML code source=\"https://perinim.github.io/projects\", config=graph_config ) result = smart_scraper_graph.run() print(result)\n\n### Case 2: Extracting information using Docker\n\nNote: before using the local model remember to create the docker container!\n\n    \n    \n    docker-compose up -d docker exec -it ollama ollama pull stablelm-zephyr\n\nYou can use which models available on Ollama or your own model instead of\nstablelm-zephyr\n\n    \n    \n    from scrapegraphai.graphs import SmartScraperGraph graph_config = { \"llm\": { \"model\": \"ollama/mistral\", \"temperature\": 0, \"format\": \"json\", # Ollama needs the format to be specified explicitly # \"model_tokens\": 2000, # set context length arbitrarily }, } smart_scraper_graph = SmartScraperGraph( prompt=\"List me all the articles\", # also accepts a string with the already downloaded HTML code source=\"https://perinim.github.io/projects\", config=graph_config ) result = smart_scraper_graph.run() print(result)\n\n### Case 3: Extracting information using Openai model\n\n    \n    \n    from scrapegraphai.graphs import SmartScraperGraph OPENAI_API_KEY = \"YOUR_API_KEY\" graph_config = { \"llm\": { \"api_key\": OPENAI_API_KEY, \"model\": \"gpt-3.5-turbo\", }, } smart_scraper_graph = SmartScraperGraph( prompt=\"List me all the articles\", # also accepts a string with the already downloaded HTML code source=\"https://perinim.github.io/projects\", config=graph_config ) result = smart_scraper_graph.run() print(result)\n\n### Case 4: Extracting information using Groq\n\n    \n    \n    from scrapegraphai.graphs import SmartScraperGraph from scrapegraphai.utils import prettify_exec_info groq_key = os.getenv(\"GROQ_APIKEY\") graph_config = { \"llm\": { \"model\": \"groq/gemma-7b-it\", \"api_key\": groq_key, \"temperature\": 0 }, \"embeddings\": { \"model\": \"ollama/nomic-embed-text\", \"temperature\": 0, \"base_url\": \"http://localhost:11434\", }, \"headless\": False } smart_scraper_graph = SmartScraperGraph( prompt=\"List me all the projects with their description and the author.\", source=\"https://perinim.github.io/projects\", config=graph_config ) result = smart_scraper_graph.run() print(result)\n\n### Case 5: Extracting information using Azure\n\n    \n    \n    from langchain_openai import AzureChatOpenAI from langchain_openai import AzureOpenAIEmbeddings lm_model_instance = AzureChatOpenAI( openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"], azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] ) embedder_model_instance = AzureOpenAIEmbeddings( azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\"], openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"], ) graph_config = { \"llm\": {\"model_instance\": llm_model_instance}, \"embeddings\": {\"model_instance\": embedder_model_instance} } smart_scraper_graph = SmartScraperGraph( prompt=\"\"\"List me all the events, with the following fields: company_name, event_name, event_start_date, event_start_time, event_end_date, event_end_time, location, event_mode, event_category, third_party_redirect, no_of_days, time_in_hours, hosted_or_attending, refreshments_type, registration_available, registration_link\"\"\", source=\"https://www.hmhco.com/event\", config=graph_config )\n\n### Case 6: Extracting information using Gemini\n\n    \n    \n    from scrapegraphai.graphs import SmartScraperGraph GOOGLE_APIKEY = \"YOUR_API_KEY\" # Define the configuration for the graph graph_config = { \"llm\": { \"api_key\": GOOGLE_APIKEY, \"model\": \"gemini-pro\", }, } # Create the SmartScraperGraph instance smart_scraper_graph = SmartScraperGraph( prompt=\"List me all the articles\", source=\"https://perinim.github.io/projects\", config=graph_config ) result = smart_scraper_graph.run() print(result)\n\nThe output for all 3 the cases will be a dictionary with the extracted\ninformation, for example:\n\n    \n    \n    { 'titles': [ 'Rotary Pendulum RL' ], 'descriptions': [ 'Open Source project aimed at controlling a real life rotary pendulum using RL algorithms' ] }\n\n## \ud83e\udd1d Contributing\n\nFeel free to contribute and join our Discord server to discuss with us\nimprovements and give us suggestions!\n\nPlease see the contributing guidelines.\n\n## \ud83d\udcc8 Roadmap\n\nCheck out the project roadmap here! \ud83d\ude80\n\nWanna visualize the roadmap in a more interactive way? Check out the markmap\nvisualization by copy pasting the markdown content in the editor!\n\n## \u2764\ufe0f Contributors\n\n## \ud83c\udf93 Citations\n\nIf you have used our library for research purposes please quote us with the\nfollowing reference:\n\n    \n    \n    @misc{scrapegraph-ai, author = {Marco Perini, Lorenzo Padoan, Marco Vinciguerra}, title = {Scrapegraph-ai}, year = {2024}, url = {https://github.com/VinciGit00/Scrapegraph-ai}, note = {A Python library for scraping leveraging large language models} }\n\n## Authors\n\nContact Info  \n---  \nMarco Vinciguerra  \nMarco Perini  \nLorenzo Padoan  \n  \n## \ud83d\udcdc License\n\nScrapeGraphAI is licensed under the MIT License. See the LICENSE file for more\ninformation.\n\n## Acknowledgements\n\n  * We would like to thank all the contributors to the project and the open-source community for their support.\n  * ScrapeGraphAI is meant to be used for data exploration and research purposes only. We are not responsible for any misuse of the library.\n\n## About\n\nPython scraper based on AI\n\nscrapegraph-doc.onrender.com/\n\n### Topics\n\nmachine-learning scraping sc automated-scraper scraping-python gpt-3 gpt-4 llm\nscrapingweb llama3\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\n### Code of conduct\n\nCode of conduct\n\n### Security policy\n\nSecurity policy\n\n### Citation\n\nActivity\n\n### Stars\n\n2.4k stars\n\n### Watchers\n\n19 watching\n\n### Forks\n\n186 forks\n\nReport repository\n\n## Releases 41\n\nv0.9.0 Latest\n\nMay 4, 2024\n\n\\+ 40 releases\n\n## Sponsor this project\n\n  * https://www.paypal.me/MarcoVinciguerra00\n\n## Packages 0\n\nNo packages published\n\n## Contributors 20\n\n\\+ 6 contributors\n\n## Languages\n\n  * Python 98.8%\n  * Shell 1.1%\n  * Dockerfile 0.1%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
