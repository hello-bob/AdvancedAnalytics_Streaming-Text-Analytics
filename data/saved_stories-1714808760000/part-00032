{"aid": "40253684", "title": "Smart AI voice assistant and internet knowledge", "url": "https://serpapi.com/blog/build-a-smart-ai-voice-assistant-connect-to-the-internet/", "domain": "serpapi.com", "votes": 1, "user": "tuktuktuk", "posted_at": "2024-05-04 00:08:41", "comments": 0, "source_title": "Build a smart AI voice assistant (connect to the Internet)", "source_text": "Build a smart AI voice assistant (connect to the Internet)\n\nopenai\n\n# Build a smart AI voice assistant (connect to the Internet)\n\nLet's learn how to build a smart AI assistant using OpenAI API assistant and\nfunction calling so we can expand its knowledge with real-time data.\n\n#### Hilman Ramadhan\n\nMay 3, 2024 \u2022 6 min read\n\nTABLE OF CONTENTS\n\n  1. Expand the AI knowledge\n  2. How to connect the assistant to the internet\n  3. Step by Step\n\n    1. Create a new assistant\n    2. Add functions calling as tools\n    3. Clone the base code from the introduction tutorial\n    4. Install and use SerpApi\n  4. Let's try!\n  5. Things we can improve\n\nLet's learn how to build a smart AI voice assistant! Previously, we built a\nsimple AI voice assistant using the OpenAI API. Feel free to follow the\ntutorial here.\n\nBuild an AI Voice assistant like Siri (use OpenAI AI Assistant)\n\nLearn how to build an AI Voice assistant like Siri, Alexa, etc. We will use\nOpenAI assistant as the main brain for the assistant.\n\nSerpApiHilman Ramadhan\n\nThis time, we want to eliminate the knowledge limitation of the OpenAI model\n(which is cut off in a certain year) by adding the ability to Google for an\nanswer. If we can Google the answer, we can get real-time data!\n\nHere is the video demo of what we're going to build:\n\n## Expand the AI knowledge\n\n\"LLMs can reason about wide-ranging topics, but their knowledge is limited to\nthe public data up to a specific point in time that they were trained on. If\nyou want to build AI applications that can reason about private data or data\nintroduced after a model\u2019s cutoff date, you need to augment the knowledge of\nthe model with the specific information it needs. The process of bringing the\nappropriate information and inserting it into the model prompt is known as\nRetrieval Augmented Generation (RAG).\" - What is RAG - LangChain.\n\nWe're going to see a simple implementation of RAG using OpenAI.\n\nBuild a smart AI voice assistant (connect to the Internet) illustration.\n\n## How to connect the assistant to the internet\n\nOpenAI has a separate API called function calling , which enables the AI\nassistant to call external APIs. Luckily, SerpApi offers an API to access\nGoogle Search results. So, we'll call the SerpApi Google Search API via\nfunction calling inside our app whenever the assistant needs real-time data.\n\n> Using function calling, the assistant is smart enough to decide when to call\n> and when not to call for an external API.\n\nHere is how our app is structured:\n\nVoice input with real-time data app structure.\n\nReference: - Connect OpenAI with external APIs using Function calling. -\nGoogle Search API by SerpApi.\n\nSerpApi provides answer_box in the response, which we can utilize to get\nanswers to common questions like: - What's the weather in {location} - Stock\nprice information for {company name} - Step by step on doing something, for\nexample how to clean up disk c - etc.\n\nGoogle's answer box and the response from SerpApi.\n\n## Step by Step\n\nLet's look at the step-by-step process of building a smart AI voice assistant\nusing OpenAI. Don't worry, the final source code for this blog post is\navailable on GitHub:\n\nGitHub - hilmanski/simple-ai-voice-assistant-openai-with-internet-demo\n\nContribute to hilmanski/simple-ai-voice-assistant-openai-with-internet-demo\ndevelopment by creating an account on GitHub.\n\nGitHubhilmanski\n\nI won't cover all the codes line by line. Instead, I'll highlight the\nimportant parts.\n\n### Create a new assistant\n\nJust like before, we need to create a new assistant. We can do it\nprogrammatically or via GUI. I prefer the latter. Make sure you have an OpenAI\naccount. You can create the assistant from the platform page.\n\nHere is the instruction I gave:\n\n> You're a general AI assistant that can help with anything. You're a voice\n> assistant, so don't speak too much, make it clear and concise. When needed,\n> you can access the internet through an external functions that available to\n> you. The external function is access to Google, you can get a direct answer\n> or knowledge graph from your Google search. Only use the external API when\n> needed.\n\nI choose the gpt-4-model-preview . Make sure to choose a model that supports\nmultiple function callings.\n\n### Add functions calling as tools\n\nLet's add a function schema during the assistant creation. This is like\npreparing the AI to call a described function whenever necessary. We'll\ndeclare the actual function (external API) in the code.\n\n> Feel free to add as many functions as you need.\n\nAdd functions to OpenAI assistant API.\n\nHere is the function that I added to the OpenAI GUI platform:\n\n    \n    \n    { \"name\": \"getSearchResult\", \"description\": \"return search results from a given keyword\", \"parameters\": { \"type\": \"object\", \"properties\": { \"query\": { \"type\": \"string\", \"description\": \"The search query\" } }, \"required\": [ \"query\" ] } }\n\n### Clone the base code from the introduction tutorial\n\nWe've covered the basic functionality in the first part of this serie. Feel\nfree to take a look. Here is what we did: - Use Web Speech API for the voice\ninput. - Add Assistant API for the logic. - Use Web Speech API for the voice\noutput. - Prepare a simple interface for the demo.\n\nThe source code from the first tutorial is available on GitHub.\n\n### Install and use SerpApi\n\nMake sure to register at serpapi.com. You'll get a free API key. Add this API\nkey to the .env file called SERPAPI_KEY.\n\nLet's add SerpApi package to this repo\n\n    \n    \n    npm install serpapi --save\n\nAdd SerpApi code in the index.js file\n\n    \n    \n    const OpenAI = require('openai'); const { OPENAI_API_KEY, ASSISTANT_ID, SERPAPI_KEY } = process.env; // add serpapi key const { getJson } = require(\"serpapi\"); // main SerpAPi function ... // SerpApi function async function getSearchResult(query) { console.log('------- CALLING AN EXTERNAL API ----------') const json = await getJson({ engine: \"google\", api_key: SERPAPI_KEY, q: query, location: \"Austin, Texas\", }); // I only return the answer_box. Feel free to adjust based on the response you'll need. return json['answer_box'] ; }\n\nUpdate checkingStatus method to support function calling\n\n    \n    \n    async function checkingStatus(res, threadId, runId) { const runObject = await openai.beta.threads.runs.retrieve( threadId, runId ); const status = runObject.status; console.log('> Current status: ' + status); if(status == 'completed') { clearInterval(pollingInterval); const messagesList = await openai.beta.threads.messages.list(threadId); const lastMessage = messagesList.body.data[0].content[0].text.value res.json({ message: lastMessage }); } else if(status == 'queued' || status == 'in_progress') { console.log('Still in progress or queued ... ') await new Promise(r => setTimeout(r, 2000)); // wait 2 seconds checkingStatus(res, threadId, runId) } else if(status === 'requires_action') { if(runObject.required_action.type === 'submit_tool_outputs') { console.log('submit tool outputs ... ') const tool_calls = await runObject.required_action.submit_tool_outputs.tool_calls // We can call for a function simultaneously, by adding them in one array let toolOutputs = [] for(const toolCall of tool_calls) { const parsedArgs = JSON.parse(toolCall.function.arguments); const apiResponse = await getSearchResult(parsedArgs.query) console.log('Query for 3rd API: ' + parsedArgs.query) toolOutputs.push({ tool_call_id: toolCall.id, output: JSON.stringify(apiResponse) }) } openai.beta.threads.runs.submitToolOutputs( threadId, runId, { tool_outputs: toolOutputs } ) await new Promise(r => setTimeout(r, 2000)); // wait 2 seconds checkingStatus(res, threadId, runId) } } }\n\nUpdate message endpoint to call the runStatus method:\n\n    \n    \n    app.post('/message', async (req, res) => { const { message, threadId } = req.body; addMessage(threadId, message).then(message => { runAssistant(threadId).then(run => { const runId = run.id; checkingStatus(res, threadId, runId); // The polling is now happened inside the checkingStatus method }); }); });\n\n## Let's try!\n\nYou can run the backend code with node index.js and run the frontend part with\na live server like VSCode live extension for example. Feel free to ask\nanything, including general information or something that needs a real-time\ndata resource. I hope you enjoy this post!\n\n## Things we can improve\n\nThere are several things we can improve for this voice assistant.\n\nVoice and listening We use native browser API to listen and speak. Better\nalternatives exist, such as Elevenlabs, AssemblyAI, and more!\n\nMore real-time data Not every question can be answered by the Google Answer\nbox, we can provide more 3rd party APIs as a backup.\n\n## Free Plan \u00b7 100 searches / month\n\nGet started\n\n## Scraping public pages is legal in the US (2024)\n\nDisclaimer: SerpApi, including any of its employees or contractors, does not\nprovide legal advice. The content of this blog post is for informational\npurposes only and should not be considered as legal counsel. For specific\nlegal issues, consult with a qualified attorney. You can legally scrape public\npages in the\n\nPaige Butler Apr 29, 2024 \u2022 12 min read\n\n## Build an AI Voice assistant like Siri (use OpenAI AI Assistant)\n\nLearn how to build an AI Voice assistant like Siri, Alexa, etc. We will use\nOpenAI assistant as the main brain for the assistant.\n\nHilman Ramadhan Apr 25, 2024 \u2022 7 min read\n\n## How to Scrape Yandex Reverse Image Results\n\nYandex Search Engine is the most popular search engine, especially for Russian\ncontent. Similar to Google's Reverse Image Search, Yandex Reverse Image Search\nallows you to search for information, related web pages, and similar images\nfrom your images. You can upload an image directly from your device or\n\nAndy L Apr 25, 2024 \u2022 2 min read\n\n# Documentation\n\n  * Google Search API\n  * Google Maps API\n  * Google Jobs API\n  * Google Shopping API\n  * Google Images API\n  * Google News API\n  * Google Local API\n  * Google Trends API\n  * Google Autocomplete API\n  * Google About This Result\n  * Google Lens API\n  * Google Finance API\n  * Google Related Questions API\n  * Google Scholar API\n  * Google Play Store API\n  * Google Product API\n  * Google Immersive Product API\n  * Google Reverse Image API\n  * Google Events API\n  * Google Local Services API\n  * Google Videos API\n  * Google Health Insurance API\n  * Google Patents API\n  * Google Ads Transparency Center API\n  * Google Flights API\n  * Google Hotels API\n  * Baidu Search API\n  * Bing Search API\n  * DuckDuckGo Search API\n  * Yahoo! Search API\n  * Yandex Search API\n  * Ebay Search API\n  * YouTube Search API\n  * Walmart Search API\n  * The Home Depot Search API\n  * Apple App Store API\n  * Naver Search API\n  * Yelp Search API\n  * Extra APIs\n\n# About\n\n  * Home\n  * Integrations\n  * Features\n  * Pricing\n  * Use cases\n  * Team\n  * Careers\n  * FAQ\n  * Legal\n  * Security\n  * Contact us\n  * Blog\n\n# Contact\n\n  * SerpApi, LLC\n  * 5540 N Lamar Blvd #12\n  * Austin, TX 78751\n  * +1 (512) 666-8245\n  * contact@serpapi.com\n\n# Our Values\n\nWe value full transparency and painful honesty both in our internal and\nexternal communications. We believe a world with complete and open\ntransparency is a better world.\n\nBuilt with love in Austin, TX. \u00a9 2024 SerpApi, LLC.\n\n", "frontpage": false}
