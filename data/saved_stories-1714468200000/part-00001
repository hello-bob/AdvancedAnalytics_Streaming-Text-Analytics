{"aid": "40206843", "title": "How We Tracked Down a Linux Kernel Bug with Fallout", "url": "https://www.datastax.com/blog/how-we-tracked-down-linux-kernel-bug-fallout", "domain": "datastax.com", "votes": 1, "user": "thunderbong", "posted_at": "2024-04-30 03:09:50", "comments": 0, "source_title": "How We Tracked Down a Linux Kernel Bug with Fallout | Datastax", "source_text": "How We Tracked Down a Linux Kernel Bug with Fallout | Datastax\n\n  * Docs\n  * Contact Us\n  * Sign In\n\nLimited time: Get 24/7 Enterprise Support and $2k of Astra credits, for only\n$1k\n\nBack to Technology\n\nTechnology\u2022September 27, 2021\n\n# How We Tracked Down a Linux Kernel Bug with Fallout\n\n###### Matt FlemingPerformance Engineer\n\nBugs come in all shapes and sizes and it\u2019s not always clear at the beginning\nof a debugging session which one you\u2019re currently chasing. Some bugs can be\nfixed up in a matter of minutes while others take weeks to nail down. And the\nreally tricky ones require you to dig through multiple layers of your software\nstack, stressing the limits of your patience.\n\nThis article covers an example of the latter kind of bug. When one of the\ndaily performance tests started timing out after 16 hours, it turned out that\nI had unknowingly stumbled onto an issue in the Linux kernel hrtimer code.\nSince I didn\u2019t know it was a kernel bug when I started looking, I had to\nmethodically dig deeper into the software stack as I homed in on the problem.\n\nFallout is an open-source distributed systems testing service that we use\nheavily at DataStax to run functional and performance tests for Apache\nCassandra, Apache Pulsar, and other projects. Fallout automatically provisions\nand configures distributed systems and clients, runs a variety of workloads\nand benchmarks, and gathers test results for later analysis.\n\nAs you\u2019ll see below, Fallout was instrumental in being able to quickly iterate\nand gather new data to validate and invalidate my guesses about the underlying\nbug.\n\n## The original bug report\n\nAt DataStax we run a variety of nightly functional and performance tests\nagainst Cassandra, and one morning we noticed that one of our write-throughput\nbenchmarks failed to complete after 16 hours. Normally, this test would\ncomplete within four, so something was clearly wrong. Like all good engineers,\nwe checked to see what had changed since the test last passed, and sure enough\nwe found a commit in our git repository that could potentially explain the\nfailure.\n\nSince the most important thing after discovering a test failure is to get the\ntests passing again, we reverted the suspected commit and re-ran the tests.\nThey passed. So with the tests now passing we figured that even if we hadn\u2019t\nanalysed the commit to understand how the test could be failing, we\u2019d at least\nnarrowed down the cause of the issue to a single commit. High-fives were\nexchanged and we all went back to work leaving the author of the reverted\ncommit to understand the root cause of the failure.\n\nOnly the test failed again the next day, even with the reverted commit.\nClearly we\u2019d been too hasty in our diagnosis and hadn\u2019t actually fixed\nanything.\n\nBut this begged the question: if the commit we reverted didn\u2019t originally\ncause the test to fail, why had it suddenly started failing? It dawned on us\nthat we were dealing with an intermittent failure and our task now was to\nfigure out how to reproduce it more reliably.\n\n## Reproducing the failure\n\nIntermittent failures are a pain to debug because they take so much longer to\nanalyze when you can\u2019t trigger the conditions for the bug on every test run.\nSometimes there\u2019s no telling how many runs you\u2019ll need to hit it. Worse, you\nhave to gather much more data to be confident that you\u2019ve actually solved the\nbug once you apply your fix.\n\nAlmost all of the performance tests at DataStax run using Fallout, our\ndistributed systems testing service. Tests are described in a single YAML file\nand Fallout takes care of scheduling tests on available hardware and\ncollecting the results for later analysis. Our team figured out we could\nnormally hit this bug at least once every five runs. We initially looked at\ntrying to increase the reproducibility of this bug but simply couldn\u2019t make\nthe failure happen more regularly. Fortunately, there was one way we could\nreduce the time to trigger it -- by running multiple tests in parallel. Since\nFallout can automatically queue test runs and execute them once hardware\nbecomes available, I fired up five runs of the same test and waited for the\nresults to come in. Instead of having to wait up to 20 hours to see if I had\nhit the bug, I now only needed to wait around four hours. Still not ideal, but\nit meant that I could make progress every day.\n\nBut we were still using the \u201cdoes the test run for longer than four hours\u201d\nsymptom to detect when we\u2019d run into a problem. Finding a less time-consuming\nway to know when we\u2019d triggered the bug required understanding the side\neffects of the bug at the Cassandra level. In other words, we had to know what\nCassandra was doing to cause the test to timeout in the first place.\n\n## The side effects of the bug\n\nCassandra has a number of tools to understand what\u2019s happening internally as\nit serves data to clients. A lot of this is tracked as metrics in monitoring\ntools such as Prometheus or Grafana which integrate with Fallout. Checking\nthose metrics showed that request throughput (requests per second) dropped off\nto near zero whenever we triggered the bug. To understand what was happening\non the server side, I waited for the bug to occur and then took a look at the\noutput of nodetool tpstats.\n\nUsing nodetool tpstats for diagnosing bugs is much easier if you have a mental\nmodel of how requests are handled by Cassandra. Native-Transport-Requests\nthreads are responsible for handling requests from clients and they are run by\nthe SEPWorker mechanism which is the thread pool framework inside of\nCassandra. Cassandra uses a pool of threads and wakes up threads when all the\nrunning threads are busy and there\u2019s still work to be done. When there\u2019s no\nwork to do, threads are put to sleep again until more work comes in.\n\nFrom the output of tpstats I could see that there was plenty of work to do\nbecause the number of pending requests was high but the number of active\nrequests at any one time hovered around two or three. To put this into\nperspective, there were hundreds of requests and around 172 Native-Transport-\nRequests threads on the machine but most of those threads were sleeping\ninstead of handling the incoming requests from clients. Something was\npreventing Cassandra from waking up more Native-Transport-Requests threads.\n\nThe SEPWorker infrastructure has a mechanism for only waking up the minimum\nnumber of threads necessary when work comes in. If the currently running\nthreads finish processing all of their work they enter the SPINNING state\nwhich is part of the internal Cassandra state machine. In this state, threads\nwill check for available work and then sleep for a short period of time if\nthere isn\u2019t any. When they wake up they do one more check for work and if\nthere still isn\u2019t any work they go to sleep until explicitly awakened by\nanother thread. If there is work, then before processing it they check to see\nwhether they took the last work item and wake up another thread to process the\nnext one if there\u2019s still outstanding work.\n\nKnowing all of this and combining that knowledge with the tpstats output I\ndecided to see what all of the Native-Transport-Requests threads were doing by\nlooking at their callstacks with jstack. Most of the threads were sleeping\njust like I expected based on the tpstats output, and a few were busily\nexecuting work. But one had this interesting callstack:\n\n    \n    \n    \"Native-Transport-Requests-2\" #173 daemon prio=5 os_prio=0 cpu=462214.94ms elapsed=19374.32s tid=0x00007efee606eb00 nid=0x385d waiting on condition [0x00007efec18b9000] 4 java.lang.Thread.State: TIMED_WAITING (parking) 5 at jdk.internal.misc.Unsafe.park(java.base@11.0.6/Native Method) 6 at java.util.concurrent.locks.LockSupport.parkNanos(java.base@11.0.6/LockSupport.java:357) 7 at org.apache.cassandra.concurrent.SEPWorker.doWaitSpin(SEPWorker.java:268)\n\nThis showed that Native-Transport-Requests-2 was currently in the SPINNING\nstate and sleeping prior to checking for more work one last time before\nsleeping permanently. The only problem was, no matter how many times I ran\njstack, this thread never exited parkNanos() which meant no other threads\nwould ever be woken up to help process the backlog of work!\n\nThis finally explained why throughput dropped whenever we hit the bug. The\nnext step was understanding how parkNanos() was behaving.\n\n## Understanding the parkNanos() implementation\n\nFirst of all, I wanted to make sure that Cassandra wasn\u2019t somehow passing a\nreally big value to parkNanos() which could make it appear that it was blocked\nindefinitely when in actual fact it was just sleeping for a very long time.\nNow that I had more of an idea what to look for, it was easy to verify the\nvalues passed to parkNanos() by printing a log message every time this code\npath was executed. All of the values looked within the expected range so I\nconcluded that we definitely weren\u2019t calling parkNanos() incorrectly.\n\nNext, I turned my attention to the implementation of parkNanos(). parkNanos()\nuses the timeout feature of pthread\u2019s conditional variables to sleep for a\nspecified time. Internally, pthread uses the kernel to provide the timeout\nfacility, specifically by using the futex() system call. As a quick recap, the\nfutex() (or fast userspace mutex) system call allows application threads to\nsleep, waiting for the value at a memory address to change. The thread is\nwoken up when either the value changes or the timeout expires.\n\nThe parkNanos() call was putting the Native-Transport-Requests thread to sleep\nexpecting the timer to expire within 10 microseconds or so but it was starting\nto look like that never happened. Two questions came to mind: did the thread\nsomehow miss the signal to wake up from the expiring timer or did the timer\nnever actually expire? I couldn\u2019t see anything obviously wrong with the code,\nand I didn\u2019t want to deal with building a custom version of the Java SE\nDevelopment Kit (JDK) to pursue that line further. Instead, I decided to\nswitch gears and write a BPF script to explore the problem from the kernel\nside first\n\n## Tracing kernel timers with BPF\n\nBPF is an in-kernel virtual machine that\u2019s capable of dynamically running\nkernel code injected from userspace. The beauty of BPF is that you can run\nthese scripts without needing to recompile your kernel or even reboot your\nmachine. Among other things, BPF allows you to insert probes or hooks at the\nentry and exit of kernel functions, effectively allowing you to run your own\nkernel code. Tracing through the kernel\u2019s futex code I could see that if I\nhooked my script into the return path of the internal functions, I could\ndisplay the timer details when the thread returned from the futex call. The\nnext trick was getting the stuck thread to return.\n\nSignals are a handy way of interrupting sleeping application threads that are\ninside the kernel and you can often send a SIGSTOP, SIGCONT sequence without\ntriggering any error paths in the kernel or your application. So by sending\nthese two signals I could force the sleeping Native-Transport-Requests thread\nto return from the blocking futex() call, run my BPF script, and print the\ntimer details in my terminal window.\n\nThe main timer detail I was interested in was the expired value which tells\nyou when the timer should have expired and awakened the sleeping thread. If\nthe value was far into the future it seemed likely that the timer had been\nprogrammed incorrectly, but if it was in the past then we\u2019d missed the wakeup\nor it had never been sent. I bundled my BPF script into a bash script that\nalso took care of first sending the SIGSTOP and SIGCONT signals to the Native-\nTransport-Requests thread.\n\n    \n    \n    $ sudo ./futex 14469 Tracing pid 14469... Sending SIGSTOP 55880730777795 expires\n\nThe expires value for high-resolution timers in the kernel is in nanoseconds\nsince boot. Doing a quick bit of math (5880730777795/1000000000 / 60 = 98.012\nor 98 minutes of uptime) I could tell that the expire value looked correct\nbecause it was within the 4 hours that the test usually took. And the real\nissue was that a wakeup had never been sent to the sleeping Native-Transport-\nRequests thread. At this point, I was convinced that our test was hitting a\nkernel bug.\n\n## How are timers implemented in the Linux kernel?\n\nHigh-resolution timers, or hrtimers, is the in-kernel infrastructure\nresponsible for programming the timer hardware in your CPU. At the application\nlevel, hrtimers are programming using system calls such as clock_nanosleep()\nand nanosleep(). Each CPU maintains its own tree of hrtimers grouped by clock\nID (CLOCK_MONOTONIC, CLOCK_REALTIME, etc). Each tree is implemented using a\nred-black tree data structure. Timers are inserted into the red-black tree and\nsorted based on their expiration time. The kernel\u2019s red-black tree\nimplementation also maintains a pointer to the smallest entry in the tree\nwhich enables the kernel to lookup the next expiring timer in O(1).\n\nI modified my BPF script to display the location in the red-black tree for the\nhrtimer our Native-Transport-Requests thread was waiting on and discovered\nthat it never reached the leftmost spot. This explained why the thread was\nnever awakened! This is also a violation of the way that red-black trees are\nsupposed to work: it\u2019s normally expected that the entries in the tree are in\nsorted order, smallest to highest, at all times.\n\n## Tracing the behaviour of the kernel\u2019s red-black trees\n\nTracing the workings of these red-black trees was beyond anything I could\nachieve with a BPF script. I resorted to writing a kernel patch to print a\nwarning message and dump the contents of the hrtimer red-black trees whenever\nthe auxiliary pointer to the leftmost entry no longer pointed to the timer\nthat expired next.\n\n    \n    \n    10: was adding node=00000000649f0970 10: found node in wrong place last=0000000091a72b7e, next=00000000649f0970 (expires 208222423748, 208222332591) 10: last timer=0000000091a72b7e function=hrtimer_wakeup+0x0/0x30, next=00000000649f0970 timer function=hrtick+0x0/0x70 Printing rbtree ========= node=0000000091a72b7e, expires=208222423748, function=hrtimer_wakeup+0x0/0x30 node=00000000649f0970, expires=208222332591, function=hrtick+0x0/0x70 node=00000000063113c0, expires=208225793771, function=tick_sched_timer+0x0/0x80 node=000000003705886f, expires=209277793771, function=watchdog_timer_fn+0x0/0x280 node=00000000e3f371a2, expires=233222750000, function=timerfd_tmrproc+0x0/0x20 node=0000000068442340, expires=265218903415, function=hrtimer_wakeup+0x0/0x30 node=00000000785c2d62, expires=291972750000, function=timerfd_tmrproc+0x0/0x20 node=0000000085e65b06, expires=86608220562558, function=hrtimer_wakeup+0x0/0x30 node=00000000049a0b4d, expires=100000159000051377, function=hrtimer_wakeup+0x0/0x30\n\nBefore I started this part, I wasn\u2019t even sure that Fallout would allow me to\nboot into a custom kernel. Sure enough, it was trivial to do.\n\nAfter rebooting into my custom kernel I saw the warnings triggering\nimmediately on startup so I naturally assumed that something was broken with\nmy patch. But after a closer look I realized that it was possible to trigger\nmy bug within two minutes of booting the VM! I no longer had to wait up to\nfour hours to see if I had reproduced the issue. What was even better was that\nI was able to hit this warning every single time I booted the VM. With the\nreproduction time cut by around 99% I quickly made progress understanding the\nkernel bug that caused the red-black tree to become inconsistent.\n\n## The real bug and the fix\n\nThe kernel bug underlying this whole ordeal was already fixed upstream in\nFebruary this year in Linux 5.12 but not yet pulled into Ubuntu\u2019s kernel. What\nwas happening was that some of the kernel\u2019s scheduler code was modifying the\nexpiration time of a hrtimer it had previously inserted into the red-black\ntree without first removing it from the tree. This violated the red-black tree\nproperty that all entries in the tree need to be sorted by their expiration\ntime and resulted in hrtimers not firing. This meant that threads waiting on\nthose timers were never woken up.\n\nBut why had no one else hit this kernel bug? The reason is because of a\nlittle-known or documented scheduler tunable that we were using. We were using\nthe kernel\u2019s HRTICK feature in order to improve scheduler latency.\nUnfortunately, it\u2019s not widely used and a number of bugs have been fixed over\nthe years. What\u2019s worse is that HRTICK fixes are not being backported to\nstable kernels. So Linux distributions need to take them in an ad-hoc fashion.\nRather than waiting for this to happen or rolling our own kernels, we decided\nto disable the feature altogether to avoid any future multi-week kernel\ndebugging.\n\n## Conclusion\n\nIt\u2019s helpful when debugging these multi-layered issues to have a bag of tools\nand techniques you can use to understand the behavior of your app at various\nlevels of the stack. Even if you don\u2019t know how to instrument the code at a\nparticular point (or don\u2019t want to), remember how I didn\u2019t want to build a\ncustom version of the JDK? You can still infer the location of a bug by using\ntools to understand the behavior above and below a layer. And when you don\u2019t\nknow exactly how a piece of code works, having a mental model or a rough idea\nof what goes on inside can help you to make forward progress by skipping\nlayers that are unlikely to contain the bug.\n\nSecondly, there is no way I could have taken on this problem without a service\nto automatically deploy and provision virtual machines for running the test.\nFallout was the key to unlocking this bug because even though the bug could\nonly be reproduced intermittently, I managed to parallelize the test runs and\nreduce the time to trigger the issue. The whole investigation took several\nweeks, and that\u2019s despite my being able to analyze test results to make a\nlittle bit of progress every day.\n\nIf any of this sounds like the kind of problem you\u2019d enjoy working on, check\nout the open roles on the DataStax careers page. We\u2019re always on the lookout\nfor tenacious developers and software engineers!\n\nFollow the DataStax Tech Blog for more developer stories. Check out our\nYouTube channel for tutorials and here for DataStax Developers on Twitter for\nthe latest news about our developer community.\n\n*Originally published in Medium.\n\n##### Share\n\n##### Share\n\nJUMP TO SECTION\n\n## The original bug report\n\n## Reproducing the failure\n\n## The side effects of the bug\n\n## Understanding the parkNanos() implementation\n\n## Tracing kernel timers with BPF\n\n## How are timers implemented in the Linux kernel?\n\n## Tracing the behaviour of the kernel\u2019s red-black trees\n\n## The real bug and the fix\n\n## Conclusion\n\n## More Technology\n\nView All\n\nTechnology \u2022 April 25, 2024\n\n###### How to Build a Crystal Image Search App with Vector Search\n\nTechnology \u2022 April 18, 2024\n\n###### Knowledge Graphs for RAG without a GraphDB\n\nTechnology \u2022 April 17, 2024\n\n###### How Winweb Built its AI Assistant with DataStax Astra DB and LangChain\n\nTechnology \u2022 April 16, 2024\n\n###### Vercel + Astra DB: Get Data into Your GenAI Apps Fast\n\n#### One-stop Data API for Production GenAI\n\nAstra DB gives JavaScript developers a complete data API and out-of-the-box\nintegrations that make it easier to build production RAG apps with high\nrelevancy and low latency.\n\nLearn More\n\nGet Started for Free\n\nAlso of Interest\n\n  * Supported platforms :: DataStax Docs\n  * Nodes appear unresponsive due to a Linux...\n  * OOM Killer\n\nCompany\n\nResources\n\nCloud Partners\n\nDataStax, is a registered trademark of DataStax, Inc.. Apache, Apache\nCassandra, Cassandra, Apache Pulsar, and Pulsar are either registered\ntrademarks or trademarks of the Apache Software Foundation.\n\n###### United States\n\n## Privacy Preference Center\n\n### Your Privacy\n\n### Your Privacy\n\nWhen you visit any website, it may store or retrieve information on your\nbrowser, mostly in the form of cookies. This information might be about you,\nyour preferences or your device and is mostly used to make the site work as\nyou expect it to. The information does not usually directly identify you, but\nit can give you a more personalized web experience. Because we respect your\nright to privacy, you can choose not to allow some types of cookies. Click on\nthe different category headings to find out more and change our default\nsettings. However, blocking some types of cookies may impact your experience\nof the site and the services we are able to offer. More information\n\n  * ### Targeting Cookies\n\n### Targeting Cookies\n\nThese cookies may be set through our site by our advertising partners. They\nmay be used by those companies to build a profile of your interests and show\nyou relevant adverts on other sites. They do not store directly personal\ninformation, but are based on uniquely identifying your browser and internet\ndevice. If you do not allow these cookies, you will experience less targeted\nadvertising.\n\n  * ### Performance Cookies\n\n### Performance Cookies\n\nThese cookies allow us to count visits and traffic sources so we can measure\nand improve the performance of our site. They help us to know which pages are\nthe most and least popular and see how visitors move around the site. All\ninformation these cookies collect is aggregated and therefore anonymous. If\nyou do not allow these cookies we will not know when you have visited our\nsite, and will not be able to monitor its performance.\n\n  * ### Functional Cookies\n\n### Functional Cookies\n\nThese cookies enable the website to provide enhanced functionality and\npersonalisation. They may be set by us or by third party providers whose\nservices we have added to our pages. If you do not allow these cookies then\nsome or all of these services may not function properly.\n\n  * ### Strictly Necessary Cookies\n\n### Strictly Necessary Cookies\n\nAlways Active\n\nThese cookies are necessary for the website to function and cannot be switched\noff in our systems. They are usually only set in response to actions made by\nyou which amount to a request for services, such as setting your privacy\npreferences, logging in or filling in forms. You can set your browser to block\nor alert you about these cookies, but some parts of the site will not then\nwork. These cookies do not store any personally identifiable information.\n\nConsent Leg.Interest\n\nSelect All\n\n  * ### 33Across\n\n#### 33Across\n\n    * Name\n\ncookie name\n\nDataStax uses its own and third party cookies to provide you the best possible\nexperience, to support our marketing campaigns, and to advertise to you on our\nwebsites and on others. Some cookies may continue to collect information after\nyou have left our websites. To learn more about cookies and how to adjust\ncookie settings please find our privacy policy located in the footer.\n\n", "frontpage": false}
