{"aid": "40163651", "title": "AI music isn't going away. Here are 4 big questions about what's next", "url": "https://text.npr.org/1246928162", "domain": "npr.org", "votes": 1, "user": "rntn", "posted_at": "2024-04-25 22:06:13", "comments": 0, "source_title": "AI music isn't going away. Here are 4 big questions about what's next", "source_text": "AI music isn't going away. Here are 4 big questions about what's next\n\nText-Only Version Go To Full Site\n\nNPR > Music Features\n\n# AI music isn't going away. Here are 4 big questions about what's next\n\nBy Jewly Hight\n\nThursday, April 25, 2024 \u2022 5:00 AM EDT\n\nThe radio version of this story originally ran on All Things Considered on\nApril 8, 2024.\n\nFor as long as people have been making money from music, there have been\ndisagreements to hash out \u2014 over who gets to claim credit for what, where\nmusic can be used and shared, how revenue should be split and, occasionally,\nwhat ownership even means. Each time the industry settles on a set of rules to\naccount for those ambiguities, nothing disrupts the status quo all over again\nquite like new advancements in technology. When radio signals sprang up around\nthe nation, competitors proliferated just across the border. When hip-hop's\nearly architects created an entirely new sonic culture, their building blocks\nwere samples of older music, sourced without permission. When peer-to-peer\nfile-sharing ran rampant through college dorm rooms, it united an internet-\nconnected youth audience even as its legality remained an open question. \"This\nindustry always seems to be the canary in the coal mine,\" observed Mitch\nGlazier, the head of the Recording Industry Association of America, in an\ninterview. \"Both in adapting to new technology, but also when it comes to\nabuse and people taking what artists do.\"\n\nIn the music world as in other creative industries, generative AI \u2014 a class of\ndigital tools that can create new content based on what they \"learn\" from\nexisting media \u2014 is the latest tech revolution to rock the boat. Though it's\nresurfacing some familiar issues, plenty about it is genuinely new. People are\nalready using AI models to analyze artists' signature songwriting styles,\nvocal sounds or production aesthetics, and create new work that mirrors their\nold stuff without their say. For performers who assiduously curate their\nonline images and understand branding as the coin of the realm, the threat of\nthese tools proliferating unchecked is something akin to identity theft. And\nfor those anxious that the inherent value of music has already sunk too far in\nthe public eye, it's doubly worrying that the underlying message of AI's\npowers of mimicry is, \"It's pretty easy to do what you do, sound how you\nsound, make what you make,\" as Ezra Klein put it in a recent podcast episode.\nWith no comprehensive system in place to dictate how these tools can and can't\nbe used, the regulatory arm of the music industry is finding itself in an\nextended game of Whac-a-Mole.\n\nRelated Story: Tennessee becomes the first state to protect musicians and\nother artists against AI\n\nLast month, the nation's first law aimed at tamping down abuses of AI in music\nwas added to the books in Tennessee. Announced by Governor Bill Lee in January\nat a historic studio on Nashville's Music Row, the ELVIS Act \u2014 which stands\nfor Ensuring Likeness Voice and Image Security, and nods to an earlier legal\nreckoning with entities other than the Elvis Presley estate slapping the\nKing's name and face on things \u2014 made its way through the Tennessee General\nAssembly with bipartisan support. Along the way, there were speeches from the\nbill's co-sponsors and performers and songwriters who call the state home,\nmany of them representing the country and contemporary Christian music\nindustries, insisting on the importance of protecting artists from their\nvoices being cloned and words being put in their mouths. On a Thursday in\nMarch, Governor Lee signed the measure at a downtown Nashville honky-tonk and\nfist-bumped Luke Bryan, who was among the supportive music celebrities on\nhand.\n\nTo understand the stakes of this issue and the legal tangle that surrounds it,\nNPR Music sought the expertise of a few people who have observed the passage\nof the ELVIS Act, and the evolving discourse around generative AI, from\ndifferent vantage points. They include the RIAA's Glazier, a seasoned advocate\nfor the recording industry; Joseph Fishman, a professor at Vanderbilt Law\nSchool who instructs future attorneys in the nuances of intellectual property\nlaw; Mary Bragg, an independent singer-songwriter and producer with a longtime\nethos of self-sufficiency; and the three knowledgeable founders of ViNIL, a\nNashville-based tech startup directing problem-solving efforts at the\nuncertainty stoked by AI. Drawing on their insights, we've unpacked four\npressing questions about what's happening with music and machine learning.\n\n### 1) What exactly does generative AI do, and how has it intersected with\nmusic so far?\n\nTalk of generative AI can easily slip into dystopian territory, and it's no\nwonder: For more than half a century, we've been watching artificial\nintelligence take over and wipe out any humans standing in its way in sci-fi\nepics like 2001: A Space Odyssey, The Matrix and the Terminator franchise.\n\nThe reality is a little more pedestrian: The machine learning models with us\nnow are taking on tasks that we're accustomed to seeing performed by humans.\nThey aren't actually autonomous, or creative, for that matter. Their\ndevelopers input vast quantities of human-made intellectual and artistic\noutput \u2014 books, articles, photos, graphic designs, musical compositions, audio\nand video recordings \u2014 so that the AI models can taxonomize all of that\nexisting material, then recognize and replicate its patterns.\n\nAI is already being put to use by music-makers in plenty of ways, many of them\ngenerally viewed as benign to neutral. The living Beatles employed it to\nsalvage John Lennon's vocals from a muddy, lo-fi 1970s recording, so that they\ncould add their own parts and complete the song \"Now and Then.\" Nashville\nsinger-songwriter Mary Bragg reported that some of her professional peers\ntreat ChatGPT like a tool for overcoming writer's block. \"Of course, it sort\nof became a larger topic around town,\" she told me, specifying that she hasn't\nyet employed it that way herself.\n\nWhat she does do, though, is let her recording software show her shortcuts to\nevening out audio levels on her song demos. \"You press one single button and\nit listens to the information that you feed it,\" she explained at her home\nstudio in a Nashville suburb, \"and then it thinks for you about what it thinks\nyou should do. Oftentimes it's a pretty darn good suggestion. It doesn't mean\nyou should always take that suggestion, but it's a starting point.\" Those\ndemos are meant for pitching her songs, not for public consumption, and Bragg\nmade clear that she still enlists human mastering engineers to finalize music\nshe's going to release out into the world.\n\nRelated Story: When you realize your favorite new song was written and\nperformed by ... AI\n\nRelated Story: Holly Herndon: How AI can transform your voice\n\nEarly experiments with the musical potential of generative AI were received\nlargely as harmless and fascinating geekery. Take \"Daddy's Car,\" a Beatles-\nesque bop from 2016 whose music (though not its lyrics) was composed by the AI\nprogram Flow Machines. For more variety, try the minute-long, garbled genre\nexercises dubbed \"Jukebox Samples\" that OpenAI churned out four years later.\nThese all felt like facsimiles made from a great distance, absurdly\ngeneralized and subtly distorted surveys of the oeuvres of C\u00e9line Dion, Frank\nSinatra, Ella Fitzgerald or Simon & Garfunkel. In case it wasn't clear whose\nmusic influenced each of those OpenAI tracks, they were titled, for instance,\n\"Country, in the style of Alan Jackson.\" The explicit citing of those artists\nas source material forecast copyright issues soon to come.\n\nThe specter of AI-generated music has grown more ominous, however, as the\nattempts have landed nearer their soundalike targets \u2014 especially when it\ncomes to the mimicry or cloning of famous voices. Deepfake technology got a\nboost in visibility after someone posted audio on YouTube that sounded very\nnearly like Jay-Z \u2014 down to his smooth, imperious flow \u2014 reciting Shakespeare;\nditto when the brooding, petulant banger \"Heart on My Sleeve\" surfaced on\nTikTok, sounding like a collab between Drake and The Weeknd, though it was\nquickly confirmed that neither was involved. Things got real enough that the\nrecord labels behind all three of those stars demanded the stuff be taken\ndown. (In an ironic twist, Drake recently dropped his own AI stunt, harnessing\nthe deepfaked voices of 2Pac and Snoop Dogg for a diss track in his ongoing\nfeud with Kendrick Lamar.)\n\n### 2) Who are the people calling for protections against AI in music, and\nwhat are they worried about?\n\nFrom the outside, it can seem like the debate over AI comes down to choosing\nsides; you're either for or against it. But it's not that simple. Even those\nworking on generative AI are saying that its power will inevitably increase\nexponentially. Simply avoiding it probably isn't an option in a field as\nreliant on technology as music.\n\nThere is, however, a divide between enthusiastic early adopters and those\ninclined to proceed with caution. Grimes, famously a tech nonconformist, went\nall in on permitting fans to use and manipulate her voice in AI-aided music\nand split any profits. Ghostwriter, the anonymous writer-producer behind\n\"Heart on My Sleeve,\" and his manager say they envisioned that deepfake as a\ndemonstration of potential opportunity for music-makers who work behind the\nscenes.\n\nPerhaps among the better indicators of the current ambivalence in the industry\nare the moves made so far by the world's biggest record label, Universal Music\nGroup. Its CEO, Lucian Grainge, optimistically and proactively endorsed the\nMusic AI Incubator, a collaboration with YouTube to explore what music-makers\non its own roster could create with the assistance of machine learning. At the\nsame time, Grainge and Universal have made a strong appeal for regulation.\nThey're not alone in their concern: Joining the cause in various ways are\nrecord labels and publishing companies great and small, individual performers,\nproducers and songwriters operating on every conceivable scale and the trade\norganizations that represent them. Put more simply, it's the people and groups\nwho benefit from protecting the copyrights they hold, and ensuring the\ndistinctness of the voices they're invested in doesn't get diluted. \"I was\nborn with an instrument that I love to use,\" was how Bragg put it to me. \"And\nthen I went and trained. My voice is the thing that makes me special.\"\n\nThe RIAA has played a leading advocacy role thus far, one that the\norganization's chairman and CEO Mitch Glazier told me accelerated when \"Heart\non My Sleeve\" dropped last spring and calls and emails poured in from industry\nexecs, urgently inquiring about legal provisions against deepfakes. \"That's\nwhen we decided that we had to get together with the rest of the industry,\" he\nexplained. The RIAA helped launch a special coalition, the Human Artistry\nCampaign, with partners from across the entertainment industry, and got down\nto lobbying.\n\nGrowing awareness of the fact that many AI models are trained by scraping the\ninternet and ingesting copyrighted works to use as templates for new content\nprompted litigation. A pile of lawsuits were filed against OpenAI by fiction\nand nonfiction authors and media companies, including The New York Times. A\ngroup of visual artists sued companies behind AI image generators. And in the\nmusic realm, three publishing companies, Universal, Concord and ABKO, filed\nagainst Anthropic, the company behind the AI model Claude, last fall for\ncopyright infringement. One widely cited piece of evidence that Claude might\nbe utilizing their catalogs of compositions: When prompted to write a song\n\"about the death of Buddy Holly,\" the AI ripped entire lines from \"American\nPie,\" the folk-rock classic famously inspired by Holly's death and controlled\nby Universal.\n\n\"I think no matter what kind of content you produce, there's a strong belief\nthat you're not allowed to copy it, create an AI model from it, and then\nproduce new output that competes with the original that you trained on,\"\nGlazier says.\n\nThat AI is enabling the cloning of an artist's \u2014 or anyone's \u2014 voice and\nlikeness is a separate issue. It's on this other front that the RIAA and other\nindustry stakeholders are pursuing legislation on state and federal levels.\n\n### 3) Why is AI music so hard to regulate?\n\nWhen Roc Nation demanded the Shakespearean clip of Jay-Z be taken down,\narguing that it \"unlawfully uses an AI to impersonate our client's voice,\" the\nwording of their argument got some attention of its own: That was a novel\napproach to a practice that wasn't already clearly covered under U.S. law. The\nclosest thing to it are the laws around \"publicity rights.\"\n\n\"Every state has some version of it,\" says law professor Joseph Fishman,\nseated behind the desk of his on-campus office at Vanderbilt. \"There are\ndifferences around the margins state to state. But it is basically a way for\nindividuals to control how their identity is used, usually in commercial\ncontexts. So, think: advertisers trying to use your identity, particularly if\nyou're a celebrity, to sell cars or potato chips. If you have not given\nauthorization to a company to plaster your face in an ad saying 'this person\napproves' of whatever the product is, publicity rights give you an ability to\nprevent that from happening.\"\n\nTwo states with a sizable entertainment industry presence, New York and\nCalifornia, added voice protections to their statutes after Bette Midler and\nTom Waits went to court to fight advertising campaigns whose singers were\nmeant to sound like them (both had declined to do the ads themselves). But\nTennessee's ELVIS Act is the first measure in the nation aimed not at\ncommercial or promotional uses, but at protecting performers' voices and\nlikenesses specifically from abuses enabled by AI. Or as Glazier described it,\n\"protecting an artist's soul.\"\n\nTennessee lawmakers didn't have templates in any other states to look to.\n\"Writing legislation is hard,\" Fishman says, \"especially when you don't have\nothers' mistakes to learn from. The goal should be not only to write the\nlanguage in a way that covers all the stuff you want to cover, but also to\nexclude all the stuff that you don't want to cover.\"\n\nWhat's more, new efforts to prevent the exploitation of performers' voices\ncould inadvertently affect more accepted forms of imitation, such as cover\nbands and biopics. As the ELVIS Act made its way through the Tennessee General\nAssembly, the Motion Picture Association raised a concern that its language\nwas too broad. \"What the [MPA] was pointing out, I think absolutely\ncorrectly,\" Fishman says, \"was this would also include any kind of film that\ntries to depict real people in physically accurate ways, where somebody really\ndoes sound like the person they're trying to sound like or really does look\nlike the person they are trying to look like. That seems to be swept under\nthis as well.\"\n\nAnd of course, getting a law on the books in one state, even a state that's\nhome to a major industry hub, isn't a complete solution: The music business\ncrosses state lines and national borders. \"It's very difficult to have a\npatchwork of state laws applicable to a global, borderless system,\" Glazier\nsays. Right now, there's a great amount of interest in getting federal\nlegislation \u2014 like the NO AI FRAUD Act, effectively a nationalized version of\npublicity rights law \u2014 in place.\n\nSome industry innovators also see a need for thinking beyond regulation. \"Even\nwhen laws pass and even when the laws are strong,\" notes Jeremy Brook, an\nentertainment industry attorney who helped launch the startup ViNIL, \"that\ndoesn't mean they're easy to enforce.\"\n\nBrook and his co-founders, computer coder Sada Garba and digital strategist\nCharles Alexander, have set out to offer content creators \u2014 those who use AI\nand those who don't \u2014 as well as companies seeking to license their work, \"a\nlegal way\" to handle their transactions. At South by Southwest last month,\nthey rolled out an interface that allows individuals to license their image or\nvoice to companies, then marks the agreed-upon end product with a trackable\ndigital stamp certifying its legitimacy.\n\n### 4) New technology has upended the music industry before. Can we take any\nlessons from history?\n\nThe music industry has forever found itself in catch-up mode when new\ninnovations disrupt its business models. Both the rise of sampling incubated\nby hip-hop and the illegal downloading spree powered by Napster were met with\nlawsuits, the latter of which accomplished the aim of getting the file-sharing\nplatform shut down. Eventually came specific guidance for how samples should\nbe cleared, agreements with platforms designed to monetize digital music (like\nthe iTunes store and Spotify), and updates to the regulation of payments in\nthe streaming era \u2014 but it all took time and plenty of compromise. After\nhashing all of that out, Glazier says, music executives wanted to ensure \"that\nwe didn't have a repeat of the past.\"\n\nThe tone of the advocacy for restricting AI abuses feels a little more\ncircumspect than the complaints against Napster. For one thing, people in the\nindustry aren't talking like machine learning can, or should, be shut down.\n\"You do want to be able to use generative AI and AI technology for good\npurposes,\" Glazier says. \"You don't want to limit the potential of what this\ntechnology can do for any industry. You want to encourage responsibility.\"\n\nThere's also a need for a nuanced understanding of ownership. Popular music\nhas been the scene for endless cases of cultural theft, from the great\nwhitewashing of rock and roll up to the virtual star FN Meka, a Black-\npresenting \"AI-powered robot rapper\" conceived by white creators, signed by a\nlabel and met with extreme backlash in 2022. Just a few weeks ago, a nearly\nreal-sounding Delta blues track caused its own controversy: A simple prompt\nhad gotten an AI music generator to spit out a song that simulated the grief\nand grit of a Black bluesman in the Jim Crow South. On the heels of \"Heart on\nMy Sleeve,\" the most notorious musical deepfake to date \u2014 which paired the\nvocal likenesses two Black men, Drake and The Weeknd \u2014 it was a reminder that\nthe ethical questions circling the use of AI are many, some of them all too\nfamiliar.\n\nRelated Story: Grimes invites fans to make songs with an AI-generated version\nof her voice\n\nThe online world is a place where music-makers carve out vanishingly small\nprofit margins from the streaming of their own music. As an example of the\nlack of agency many artists at her level feel, Bragg pointed out a\nparticularly vexing kind of streaming fraud that's cropped up recently, in\nwhich scammers reupload another artist's work under new names and titles and\ncollect the royalties for themselves. Other types of fraud have been\nprosecuted or met with crackdowns that, in certain cases, inadvertently\npenalize artists who aren't even aware that their streaming numbers have been\nartificially inflated by bots. Just as it's hard to imagine musicians pulling\ntheir music from streaming platforms in order to protect it from these\nschemes, the immediate options can feel few and bleak for artists newly\nentered in a surreal competition with themselves, through software that can\nclone their sounds and styles without permission. All of this is playing out\nin a reality without precedent. \"There is a problem that has never existed in\nthe world before,\" says ViNIL's Brook, \"which is that we can no longer be sure\nthat the face we're seeing and the voice we're hearing is actually authorized\nby the person it belongs to.\"\n\nFor Bragg, the most startling use of AI she's witnessed wasn't about stealing\nsomeone's voice, but giving it back. A friend sent her the audio of a speech\non climate change that scientist Bill Weihl was preparing to deliver at a\nconference. Weihl had lost the ability to speak due to ALS \u2014 and yet, he was\nable to address an audience sounding like his old self with the aid of\nElevenLabs, one of many companies testing AI as a means of helping people with\nsimilar disabilities communicate. Weihl and a collaborator fed three hours of\nold recordings of him into the AI model, then refined the clone by choosing\nwhat inflections and phrasing sounded just right.\n\n\"When I heard that speech, I was both inspired and also pretty freaked out,\"\nBragg recalled. \"That's, like, my biggest fear in life, either losing my\nhearing or losing the ability to sing.\"\n\nThat is, in a nutshell, the profoundly destabilizing experience of\nencountering machine learning's rapidly expanding potential, its promise of\noptions the music business \u2014 and the rest of the world \u2014 have never had. It's\nthere to do things we can't or don't want to have to do for ourselves. The\neffects could be empowering, catastrophic or, more likely, both. And\nattempting to ignore the presence of generative AI won't insulate us from its\npowers. More than ever before, those who make, market and engage with music\nwill need to continuously and conscientiously adapt.\n\n\u00a9 NPR\n\n", "frontpage": false}
