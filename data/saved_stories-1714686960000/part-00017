{"aid": "40237573", "title": "Nvidia's ChatRTX receives update \u2013 better photo search, AI speech recognition", "url": "https://www.tomshardware.com/tech-industry/artificial-intelligence/nvidias-chatrtx-receives-major-update-better-photo-search-ai-speech-recognition-and-more-llm-options", "domain": "tomshardware.com", "votes": 2, "user": "DeathArrow", "posted_at": "2024-05-02 15:47:27", "comments": 0, "source_title": "Nvidia's ChatRTX chatbot receives major update \u2014 better photo search, AI speech recognition, and more LLM options", "source_text": "Nvidia's ChatRTX chatbot receives major update \u2014 better photo search, AI speech recognition, and more LLM options | Tom's Hardware\n\nSkip to main content\n\nWhen you purchase through links on our site, we may earn an affiliate\ncommission. Here\u2019s how it works.\n\n# Nvidia's ChatRTX chatbot receives major update \u2014 better photo search, AI\nspeech recognition, and more LLM options\n\nNews\n\nBy Dallin Grimm\n\npublished yesterday\n\nRTX ON also means powerful local AI.\n\n(Image credit: Nvidia)\n\nNvidia's ChatRTX app has released its anticipated version 0.3 update today on\nNvidia's website. The update to the ChatGPT-like app opens up a host of new\nfeatures first teased at Nvidia's GTC conference in March, including photo\nsearch capabilities, AI-powered speech recognition, and compatibility with\neven more LLMs.\n\nChatRTX represents another Nvidia foremost tech demonstration of the power of\nAI when fueled by consumer RTX graphics cards. The ChatRTX program offers a\nChatGPT-adjacent experience locally installed on your computer, with the\nability to leverage your data into AI use cases without the risk of having\nthat data stolen for training purposes or more nefarious uses. An example of\nthe program in practice can be seen in this example of an enthusiast putting\nan RTX card into a NAS to use ChatRTX's data synthesis abilities on their data\nnetwork-wide.\n\nWe were able to download the new version before its official release and check\nout some of the new features. ChatRTX has expanded its stable of supported\nLLMs (language learning models; i.e. GPT-4) to include new options like Gemma,\nthe latest LLM from Google, and ChatGLM3-6B, a new open-source option. The\nability to choose your own LLM is invaluable, as different LLMs may perform\nthe same tasks entirely differently.\n\nChatRTX's photo searching and interaction tools have also seen a massive\nupgrade, with tech borrowed from OpenAI's CLIP tool allowing the program to\nsearch images without the extensive complex metadata labeling previously\nrequired by the app. Finally, ChatRTX users can now speak with their data,\nwith added support for Whisper, an AI-powered speech recognition system that\nenables ChatRTX to understand verbal speech.\n\nThe tech demo leverages the power of Nvidia's tensor cores and the TensorRT\nlibrary, so it requires an RTX GPU \u2014 and for the time being, it doesn't\nsupport the first generation RTX 20-series either. So if you're looking to run\nthe app yourself, you'll need an Nvidia RTX 30- or 40-series GPU with at least\n8GB of VRAM \u2014 and likewise, any of the professional Ampere or Ada GPUs will\nalso do the trick.\n\nThe program is likely to continue to grow in functionality before an eventual\n1.0 release, including the expected return of its YouTube link scrubbing\ncapabilities that were removed recently, shortly after the emergency 0.2.x\nupdates to patch a security vulnerability.\n\n## Stay on the Cutting Edge\n\nJoin the experts who read Tom's Hardware for the inside track on enthusiast PC\ntech news \u2014 and have for over 25 years. We'll send breaking news and in-depth\nreviews of CPUs, GPUs, AI, maker hardware and more straight to your inbox.\n\nBy submitting your information you agree to the Terms & Conditions and Privacy\nPolicy and are aged 16 or over.\n\nDallin Grimm\n\nFreelance News Writer\n\nMore about artificial intelligence\n\nNvidia H100 GPU black market prices drop in China \u2014 banned by US sanctions but\nstill available\n\nIntel expects paltry $500 million in Gaudi 3 AI sales for the rest of the year\n\u2014 Nvidia to rake in $40 billion for data center AI this year\n\nLatest\n\nRyzen 7 8700F hits Amazon for $299.99 \u2014 pricier than the better-performing\n7700X\n\nSee more latest \u25ba\n\n3 Comments Comment from the forums\n\n  * Chargino\n\nWhy is Windoze 11 required?\n\nReply\n\n  * hotaru251\n\n> Chargino said:\n>\n> Why is Windoze 11 required?\n\nlikely because win10 has 1 yr from oct before losing support so companies will\nfocus only on supported version.\n\nReply\n\n  * JarredWaltonGPU\n\n> hotaru251 said:\n>\n> likely because win10 has 1 yr from oct before losing support so companies\n> will focus only on supported version.\n\nOfficially, Nvidia may say Windows 11 is required, but I tried an earlier\nrelease on Windows 10 and it was fine. I know sometimes Nvidia lists\nrequirements that match what it has tested, and very likely it isn't doing\nmuch in the way of Windows 10 testing these days \u2014 for the reasons you point\nout.\n\nReply\n\n##### Most Popular\n\nTSMC details 12.8 Tbps on-package optical communications \u2014 an efficient\nsilicon photonics interconnect for AI\n\nThe race to 2nm process technology heats up \u2014 Samsung will discuss its next-\ngen 2nm node in June\n\nIntel continues search for source of Core i9 chip crashes \u2014 issues statement\nabout recommended BIOS settings to board partners\n\nTeen breaks six Tetris world records \u2014 wins cash prize as first to score over\n10 million points\n\nSummerCart64 open source N64 flash cart revealed \u2014 turns a regular console\ninto a Nintendo 64DD\n\nIntel expects paltry $500 million in Gaudi 3 AI sales for the rest of the year\n\u2014 Nvidia to rake in $40 billion for data center AI this year\n\nXFX unveils Radeon RX 7900 XTX Phoenix Nirvana graphics card with phase-change\nthermal pad\n\nEnthusiast mods a 512GB QLC SSD into a 120GB SLC SSD \u2014 endurance and\nperformance benefits charted\n\nAlibaba's Yitian 710 is the fastest Arm-based CPU for cloud servers, study\nclaims\n\nNASA demonstrates space network speeds of up to 267 Mbps \u2014 Deep Space Optical\nCommunications stretch beyond 140 million miles\n\nChinese vendor appears to be selling Arrow Lake-S engineering samples for $14\n\nTom's Hardware is part of Future US Inc, an international media group and\nleading digital publisher. Visit our corporate site.\n\n\u00a9 Future US, Inc. Full 7th Floor, 130 West 42nd Street, New York, NY 10036.\n\n", "frontpage": false}
