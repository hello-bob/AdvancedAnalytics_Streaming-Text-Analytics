{"aid": "40157628", "title": "Lace: A Probabilistic Machine Learning Tool for Scientific Discovery", "url": "https://www.lace.dev/#lace-a-probabilistic-machine-learning-tool-for-scientific-discovery", "domain": "lace.dev", "votes": 2, "user": "spewil", "posted_at": "2024-04-25 13:54:49", "comments": 0, "source_title": "Introduction - Lace Documentation", "source_text": "Introduction - Lace Documentation\n\n# Lace Documentation\n\n### Lace: A Probabilistic Machine Learning tool for Scientific Discovery\n\nDocumentation: User guide | Rust API | Python API |\n\nInstallation: Rust | Python | CLI\n\nContents: Problem | QUICK START | License\n\nLace is a probabilistic cross-categorization engine written in rust with an\noptional interface to python. Unlike traditional machine learning methods,\nwhich learn some function mapping inputs to outputs, Lace learns a joint\nprobability distribution over your dataset, which enables users to...\n\n  * predict or compute likelihoods of any number of features conditioned on any number of other features\n  * identify, quantify, and attribute uncertainty from variance in the data, epistemic uncertainty in the model, and missing features\n  * determine which variables are predictive of which others\n  * determine which records/rows are similar to which others on the whole or given a specific context\n  * simulate and manipulate synthetic data\n  * work natively with missing data and make inferences about missingness (missing not-at-random)\n  * work with continuous and categorical data natively, without transformation\n  * identify anomalies, errors, and inconsistencies within the data\n  * edit, backfill, and append data without retraining\n\nand more, all in one place, without any explicit model building.\n\n    \n    \n    import pandas as pd import lace # Create an engine from a dataframe df = pd.read_csv(\"animals.csv\", index_col=0) engine = lace.Engine.from_df(df) # Fit a model to the dataframe over 5000 steps of the fitting procedure engine.update(5000) # Show the statistical structure of the data -- which features are likely # dependent (predictive) on each other engine.clustermap(\"depprob\", zmin=0, zmax=1)\n\n## The Problem\n\nThe goal of lace is to fill some of the massive chasm between standard machine\nlearning (ML) methods like deep learning and random forests, and statistical\nmethods like probabilistic programming languages. We wanted to develop a\nmachine that allows users to experience the joy of discovery, and indeed\noptimizes for it.\n\n### Short version\n\nStandard, optimization-based ML methods don't help you learn about your data.\nProbabilistic programming tools assume you already have learned a lot about\nyour data. Neither approach is optimized for what we think is the most\nimportant part of data science: the science part: asking and answering\nquestions.\n\n### Long version\n\nStandard ML methods are easy to use. You can throw data into a random forest\nand start predicting with little thought. These methods attempt to learn a\nfunction f(x) -> y that maps inputs x, to outputs y. This ease-of-use comes at\na cost. Generally f(x) does not reflect the reality of the process that\ngenerated your data, but was instead chosen by whoever developed the approach\nto be sufficiently expressive to better achieve the optimization goal. This\nrenders most standard ML completely uninterpretable and unable to yield\nsensible uncertainty estimate.\n\nOn the other extreme you have probabilistic tools like probabilistic\nprogramming languages (PPLs). A user specifies a model to a PPL in terms of a\nhierarchy of probability distributions with parameters \u03b8. The PPL then uses a\nprocedure (normally Markov Chain Monte Carlo) to learn about the posterior\ndistribution of the parameters given the data p(\u03b8|x). PPLs are all about\ninterpretability and uncertainty quantification, but they place a number of\npretty steep requirements on the user. PPL users must specify the model\nthemselves from scratch, meaning they must know (or at least guess) the model.\nPPL users must also know how to specify such a model in a way that is\ncompatible with the underlying inference procedure.\n\n### Example use cases\n\n  * Combine data sources and understand how they interact. For example, we may wish to predict cognitive decline from demographics, survey or task performance, EKG data, and other clinical data. Combined, this data would typically be very sparse (most patients will not have all fields filled in), and it is difficult to know how to explicitly model the interaction of these data layers. In Lace, we would just concatenate the layers and run them through.\n  * Understanding the amount and causes of uncertainty over time. For example, a farmer may wish to understand the likelihood of achieving a specific yield over the growing season. As the season progresses, new weather data can be added to the prediction in the form of conditions. Uncertainty can be visualized as variance in the prediction, disagreement between posterior samples, or multi-modality in the predictive distribution (see this blog post for more information on uncertainty)\n  * Data quality control. Use surprisal to find anomalous data in the table and use -logp to identify anomalies before they enter the table. Because Lace creates a model of the data, we can also contrive methods to find data that are inconsistent with that model, which we have used to good effect in error finding.\n\n### Who should not use Lace\n\nThere are a number of use cases for which Lace is not suited\n\n  * Non-tabular data such as images and text\n  * Highly optimizing specific predictions\n\n    * Lace would rather over-generalize than over fit.\n\n## Quick start\n\n### Installation\n\nLace requires rust.\n\nTo install the CLI:\n\n    \n    \n    $ cargo install --locked lace-cli\n\nTo install pylace\n\n    \n    \n    $ pip install pylace\n\n### Examples\n\nLace comes with two pre-fit example data sets: Satellites and Animals.\n\n    \n    \n    >>> from lace.examples import Satellites >>> engine = Satellites() # Predict the class of orbit given the satellite has a 75-minute # orbital period and that it has a missing value of geosynchronous # orbit longitude, and return epistemic uncertainty via Jensen- # Shannon divergence. >>> engine.predict( ... 'Class_of_Orbit', ... given={ ... 'Period_minutes': 75.0, ... 'longitude_radians_of_geo': None, ... }, ... ) ('LEO', 0.023981898950561048) # Find the top 10 most surprising (anomalous) orbital periods in # the table >>> engine.surprisal('Period_minutes') \\ ... .sort('surprisal', reverse=True) \\ ... .head(10) shape: (10, 3) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 index \u2506 Period_minutes \u2506 surprisal \u2502 \u2502 --- \u2506 --- \u2506 --- \u2502 \u2502 str \u2506 f64 \u2506 f64 \u2502 \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561 \u2502 Wind (International Solar-Terres... \u2506 19700.45 \u2506 11.019368 \u2502 \u2502 Integral (INTErnational Gamma-Ra... \u2506 4032.86 \u2506 9.556746 \u2502 \u2502 Chandra X-Ray Observatory (CXO) \u2506 3808.92 \u2506 9.477986 \u2502 \u2502 Tango (part of Cluster quartet, ... \u2506 3442.0 \u2506 9.346999 \u2502 \u2502 ... \u2506 ... \u2506 ... \u2502 \u2502 Salsa (part of Cluster quartet, ... \u2506 3418.2 \u2506 9.338377 \u2502 \u2502 XMM Newton (High Throughput X-ra... \u2506 2872.15 \u2506 9.13493 \u2502 \u2502 Geotail (Geomagnetic Tail Labora... \u2506 2474.83 \u2506 8.981458 \u2502 \u2502 Interstellar Boundary EXplorer (... \u2506 0.22 \u2506 8.884579 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nAnd similarly in rust:\n\n    \n    \n    use lace::prelude::*; use lace::examples::Example; fn main() { // In rust, you can create an Engine or and Oracle. The Oracle is an // immutable version of an Engine; it has the same inference functions as // the Engine, but you cannot train or edit data. let mut engine = Example::Satellites.engine().unwrap(); // Predict the class of orbit given the satellite has a 75-minute // orbital period and that it has a missing value of geosynchronous // orbit longitude, and return epistemic uncertainty via Jensen- // Shannon divergence. engine.predict( \"Class_of_Orbit\", &Given::Conditions(vec![ (\"Period_minutes\", Datum:Continuous(75.0)), (\"Longitude_of_radians_geo\", Datum::Missing), ]), Some(PredictUncertaintyType::JsDivergence), None, ) }\n\n### Fitting a model\n\nTo fit a model to your own data you can use the CLI\n\n    \n    \n    $ lace run --csv my-data.csv -n 1000 my-data.lace\n\n...or initialize an engine from a file or dataframe.\n\n    \n    \n    >>> import pandas as pd # Lace supports polars as well >>> from lace import Engine >>> engine = Engine.from_df(pd.read_csv(\"my-data.csv\", index_col=0)) >>> engine.update(1_000) >>> engine.save(\"my-data.lace\")\n\nYou can monitor the progress of the training using diagnostic plots\n\n    \n    \n    >>> from lace.plot import diagnostics >>> diagnostics(engine)\n\n## License\n\nLace is licensed under the Business Source License v1.1, which restricts\ncommercial use. See LICENSE for full details.\n\nIf you would like a license for use in commercial please contact\nlace@redpoll.ai\n\n## Academic use\n\nLace is free for academic use. Please cite lace according the the CITATION.cff\nmetadata.\n\n", "frontpage": false}
