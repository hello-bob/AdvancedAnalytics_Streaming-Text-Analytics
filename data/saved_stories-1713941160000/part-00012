{"aid": "40138526", "title": "Capturing a Billion Emo(j)I-Ons", "url": "https://highscalability.com/capturing-a-billion-emo-j-i-ons/", "domain": "highscalability.com", "votes": 1, "user": "thrusong", "posted_at": "2024-04-23 23:21:06", "comments": 0, "source_title": "Capturing A Billion Emo(j)i-ons", "source_text": "Capturing A Billion Emo(j)i-ons\n\nHigh Scalability\n\nSign in Subscribe\n\n# Capturing A Billion Emo(j)i-ons\n\n#### HS Editor\n\nMar 26, 2024 \u2014 5 min read\n\n> This blog post was written by Dedeepya Bonthu. This is a repost from her\n> Medium article, approved by the author.\n\nIn stadiums, sports fans love to express themselves by cheering for their\nfavorite teams, holding up placards and team logos. Emoji\u2019s allow fans at home\nto rapidly express themselves, and when millions of fans do it simultaneously,\nthat\u2019s a technical problem that we solved!\n\nAt Hotstar, we strive to build features that make the viewing experience more\nengaging to users with an interactive Social Feed. We discussed the \u201cHotstar\nSports Bar\u201d from a design and product point of view. Here we talk about how we\nbuilt this feature from a technical perspective.\n\nSocial Feed GIF\n\nEmojis show the real-time changes in the opinions of the audience. When Dhoni\nbats, people want a boundary shot on every ball but when he is keeping, people\nwant to see the wickets fall. Collecting these user-generated signals in real-\ntime, condensing these opinions to an emoji swarm that shows the mood of the\naudience and displaying the changing moods in real-time is challenging when\nyou plan to receive billions of such emoji submissions during a tournament.\n\nFor a while, we used a third-party service to power this feature. However, we\ncould not achieve the performance and stability we hoped for, while also not\nbeing a cost-effective. The time had come to bring this core service, in-\nhouse.\n\nIn this article, we\u2019ll discuss the architecture of Emojis, key design\nprinciples involved in building it, the impact created and how it paved the\nway for building other features like Voting.\n\n## High-Level Design\n\nArchitecture Diagram\n\n### Key Design Principles\n\n### Scalability\n\nThe system should be horizontally scalable to be able to support the\nincreasing traffic. We achieved horizontal scalability with the help of load\nbalancers and configured auto-scaling to scale the resources up or down.\n\n### Decomposition\n\nThe system needs to be decomposed into smaller components each being able to\ncarry out the assigned task independent of each other. This also provides us\nwith the ability to scale each component as needed.\n\n### Asynchronous\n\nAsynchronous processing enables execution without blocking resources and thus\nsupports higher concurrency. We will talk more about this later.\n\n## Implementation\n\n### How are client requests handled?\n\nClients send user\u2019s submitted emojis via HTTP API. To prevent hogging the\nclient connection, heavy processing on the API needs to be done offline. We\nneed to write the data somewhere so processing applications can consume it.\nMessage Queue is a commonly used mechanism for asynchronous communication\nbetween applications.\n\nThere are a lot of message queues available out there. A comparison of some of\nthe available Message Queues is reviewed in this blog. For Emojis, we needed a\ntechnology that offered high throughput, availability, low latency and\nsupports consumer groups. Kafka seemed like the best option but managing Kafka\non our own takes significant effort. Thankfully, Hotstar has an amazing data\nplatform called Knol built on top of Kafka which is flexible for all our use\ncases.\n\n## How do we write messages to the queue?\n\nSynchronous: Wait for the acknowledgment that the message is written before\nsending a success response to clients. In case of a failure, we could have\nretries configured at both server and client. If your data is transactional or\ncannot suffer any loss, this approach is preferable.\n\nAsynchronous: Write the message to a local buffer and respond with success to\nclients. Messages from the buffer could be written asynchronously to the\nqueue. The downside is that if not handled properly, this could result in data\nloss.\n\nFor Emojis, we need very low latency and data loss in rare scenarios is not a\nbig concern (although we haven\u2019t seen any so far). So we chose the\nAsynchronous approach.\n\nGolang has great support for concurrency. It ships with an implementation\ncalled Goroutines. Goroutines are lightweight threads that can execute\nfunctions asynchronously. We just need to say go do_something(). We use\nGoroutines and Channels in Golang to write messages to Kafka. Messages to be\nproduced are written to a Channel. A Producer runs in the background as a\nGoroutine and flushes the data periodically to Kafka. Using client libraries\nlike Confluent or Sarama, we can provide the flush configuration to achieve\noptimal performance. We configured our flush interval to 500ms and maximum\nmessages sent to Kafka broker in a single request to 20000.\n\n## How does the processing happen?\n\nGoal: Consume a stream of data from Kafka and compute aggregates of the data\nover an interval. Time interval should be small enough to provide a real-time\nexperience to users.\n\nAfter considering different streaming frameworks like Flink, Spark, Storm,\nKafka Streams we decided to go with Spark. Spark has support for micro\nbatching and aggregations which are essential for our use case and better\ncommunity support compared to competitors like Flink. Check out this blogfor\nmore details about different streaming frameworks.\n\nWe wrote a Spark streaming job that computes aggregates over a batch of 2\nseconds and writes computed data to another Kafka queue.\n\n## What about data delivery?\n\nWe use PubSub as our delivery mechanism. PubSub is a real-time messaging\ninfrastructure built at Hotstar to deliver messages to users in our Social\nFeed. You can dig deeper into the journey of PubSub in this article.\n\nWe wrote a simple Kafka consumer in Python. Consumption rate depends on the\nbatch duration configured in the Spark job. Let\u2019s say that it\u2019s set to 1\nsecond, this consumer would receive a message per second. We perform\nnormalization over the data and send top (relatively more popular) emojis to\nPubSub. Clients receive messages from PubSub and show Emojis animation to\nusers.\n\n## Impact\n\nEmojis are a huge hit at Hotstar. We received around 5 Billion Emojis from\n55.83 Million users during the ICC Cricket World Cup 2019. This system has\ncaptured more than 6.5 Billion Emojis to date. Here\u2019s what we achieved from\nbuilding this in-house.\n\n## Voting and more\n\nIf we think about it, Emojis and Voting have a common problem statement\n\n> Process quantifiable user responses in near real-time\n\nSo we extended this system to build the Voting feature. Hotstar is currently\nthe sole voting platform for a few big Indian reality shows like Dance Plusand\nBigg Boss (Telugu, Tamil, Malayalam). This infrastructure equipped to power\nEmojis and Voting for Hotstar, can now also power Polls and Trivia contests\nout of the box.\n\n> We have received around 3 Billion votes to date!\n\nCollection of Emojis on Social Feed\n\nNext time you visit our Social Feed, tap away on these.\n\nWant to work with us? Check out https://tech.hotstar.com/ for some exciting\nopportunities.\n\n## Read more\n\n### Brief History of Scaling Uber\n\nThis blog post was written by Josh Clemm, Senior Director of Engineering at\nUber Eats. This is a repost from his LinkedIn article, approved by the author.\nOn a cold evening in Paris in 2008, Travis Kalanick and Garrett Camp couldn't\nget a cab. That's when\n\nBy HS Editor Mar 14, 2024\n\n### Behind AWS S3\u2019s Massive Scale\n\nThis is a guest article by Stanislav Kozlovski, an Apache Kafka Committer. If\nyou would like to connect with Stanislav, you can do so on Twitter and\nLinkedIn. AWS S3 is a service every engineer is familiar with. It\u2019s the\nservice that popularized the notion of cold-storage to the\n\nBy HS Editor Mar 6, 2024\n\n### The Swedbank Outage shows that Change Controls don't work\n\nThis week I\u2019ve been reading through the recent judgment from the Swedish FSA\non the Swedbank outage. If you\u2019re unfamiliar with this story, Swedbank had a\nmajor outage in April 2022 that was caused by an unapproved change to their IT\nsystems. It temporarily left nearly a million\n\nBy Bruce Johnston Aug 16, 2023\n\n### Lessons Learned Running Presto at Meta Scale\n\nPresto is a free, open source SQL query engine. We\u2019ve been using it at Meta\nfor the past ten years, and learned a lot while doing so. Running anything at\nscale - tools, processes, services - takes problem solving to overcome\nunexpected challenges. Here are four things we learned\n\nBy Philip Bell Jul 16, 2023\n\nHigh Scalability\n\nPowered by Ghost\n\n## High Scalability\n\nBuilding bigger, faster, more reliable websites.\n\n", "frontpage": false}
