{"aid": "40215128", "title": "MIT 6.S191 Introduction to Deep Learning (2024 Edition)", "url": "http://introtodeeplearning.com/", "domain": "introtodeeplearning.com", "votes": 2, "user": "mdp2021", "posted_at": "2024-04-30 19:22:41", "comments": 0, "source_title": "MIT Deep Learning 6.S191", "source_text": "MIT Deep Learning 6.S191\n\nBack to Top\n\n# MIT 6.S191\n\n# Introduction to Deep Learning\n\n##### MIT's introductory program on deep learning methods with applications in\ncomputer vision, and more!\n\n## Description\n\n##### An efficient and high-intensity bootcamp designed to teach you the\nfundamentals of deep learning as quickly as possible!\n\nMIT's introductory program on deep learning methods with applications to\nnatural language processing, computer vision, biology, and more! Students will\ngain foundational knowledge of deep learning algorithms, practical experience\nin building neural networks, and understanding of cutting-edge topics\nincluding large language models and generative AI. Program concludes with a\nproject proposal competition with feedback from staff and panel of industry\nsponsors. Prerequisites assume calculus (i.e. taking derivatives) and linear\nalgebra (i.e. matrix multiplication), we'll try to explain everything else\nalong the way! Experience in Python is helpful but not necessary. Listeners\nare welcome!\n\n## Time and Location\n\n##### Mon Apr 29 - Mon Jun 24, 2024 Every Monday at 10am ET Every week!\n\nThe 2024 in-person edition has completed and was held in MIT Room 32-123. The\nonline edition of the course is live on Monday at 10am ET, every week!\n\nSubscribe here to be notified when a new lecture is released!\n\n## Schedule\n\n#### New 2024 lectures, slides, and labs! Taught in-person at MIT \u2014 open-\nsourced to the world.\n\n##### Intro to Deep Learning\n\n###### Lecture 1\n\nApr. 29, 2024\n\n[Slides] [Video]\n\n##### Deep Sequence Modeling\n\n###### Lecture 2\n\nMay 6, 2024\n\n[Slides] [Video] coming soon!\n\n##### Intro to TensorFlow; Music Generation\n\n###### Software Lab 1\n\n[Code] coming soon!\n\n##### Deep Computer Vision\n\n###### Lecture 3\n\nMay 13, 2024\n\n[Slides] [Video] coming soon!\n\n##### Deep Generative Modeling\n\n###### Lecture 4\n\nMay 20, 2024\n\n[Slides] [Video] coming soon!\n\n##### Facial Detection Systems\n\n###### Software Lab 2\n\n[Code] coming soon!\n\n##### Deep Reinforcement Learning\n\n###### Lecture 5\n\nMay 27, 2024\n\n[Slides] [Video] coming soon!\n\n##### New Frontiers\n\n###### Lecture 6\n\nJune 3, 2024\n\n[Slides] [Video] coming soon!\n\n##### Large Language Models\n\n###### Software Lab 3\n\n[Code] coming soon!\n\n##### Generative AI for Media\n\n###### Lecture 7\n\nJune 10, 2024\n\n[Slides] [Video] coming soon!\n\n##### Stories from Models in the Wild\n\n###### Lecture 8\n\nJune 17, 2024\n\n[Slides] [Video] coming soon!\n\n##### Final Project\n\n###### Work on final projects\n\n##### Final Project\n\n###### Work on final projects\n\nJune 24, 2024\n\n##### Project Presentations\n\n###### Pitch your ideas!\n\nJune 24, 2024\n\n##### Awards Ceremony\n\n###### Final awards and celebration!\n\n## Frequently Asked Questions\n\n##### For any other questions please reach out to the staff at\nintrotodeeplearning-staff@mit.edu.\n\n##### Are listeners allowed to attend?\n\nAll listeners are welcome to attend!\n\n##### What is the grading policy?\n\nIn 2024, 6.S191 will be offered as a for-credit 6-unit MIT course and graded\nP/D/F based on completion of project proposal assignment.\n\n##### How can I register?\n\nRegistration opens on Dec 1 at 9am. If you are a current MIT student please\nregister here after registration opens. You can specify if you want to take\nthe course for credit or as a listener there.\n\nIn addition, everyone interested in taking the course (MIT or not; and in-\nperson or not), should also register on the internal registration to receive\nupdates.\n\nAfter the MIT program, the content will be open-sourced to the world. Again,\nplease sign up for the internal registration to receive updates when this\noccurs.\n\n##### What pre-requisites are required?\n\nWe are expecting very elementary knowledge of linear algebra and calculus. How\nto multiply matrices, take derivatives and apply the chain rule. Familiarity\nin Python is a big plus as well. The program will be beginner friendly since\nwe have many registered students from outside of computer science.\n\n##### Is there a mailing list I can join?\n\nIf you would like to receive related updates and lecture materials please\nsubscribe to our YouTube channel and sign up for our mailing list.\n\n##### Are the materials open-source?\n\nAll materials are open-sourced to the world for free and are copyrighted under\nthe MIT license. If you are an instructor and would like to use any materials\nfrom this program (slides, labs, code), you must add the following reference\nto each slide:\n\n> \u00a9 Alexander Amini and Ava Amini MIT Introduction to Deep Learning\n> IntroToDeepLearning.com\n\n##### How do I reference these materials?\n\nAll materials are copyrighted and licensed under the MIT license. If you are\nan instructor and would like to use any materials from this program (slides,\nlabs, code), you must add the following reference to each slide:\n\n> \u00a9 Alexander Amini and Ava Amini MIT 6.S191: Introduction to Deep Learning\n> IntroToDeepLearning.com\n\n##### How can I help teach this class?\n\nIf you are an MIT student, postdoc, faculty, or affiliate and would like to\nbecome involved with this program please email introtodeeplearning-\nstaff@mit.edu. We are always accepting new applications to join the program\nstaff.\n\n##### How can I become a sponsor?\n\nThis class would not be possible without our amazing sponsors and has been\nsponsored by Google, IBM, NVIDIA, Microsoft, Amazon, LambdaLabs, Tencent AI,\nErnst and Young, and Onepanel. If you are interested in becoming involved in\nthis program as a sponsor please contact us at introtodeeplearning-\nstaff@mit.edu.\n\n##### Where are the websites from past editions?\n\nTo view archived versions of this website from past years please click here\nfor 2023, 2022, 2021, 2020, 2019, 2018, and 2017.\n\n## Team\n\nAlexander Amini\n\nLead Instructor Organizer\n\nAva Amini\n\nLead Instructor Organizer\n\nSadhana Lolla\n\nInstructor Lead TA\n\n### TAs and Staff\n\nJohn Werner\n\nCommunity & Strategy\n\nEva Xie\n\nTeaching Assistant\n\nShorna Alam\n\nTeaching Assistant\n\nAnirudh Valiveru\n\nTeaching Assistant\n\nDivya Nori\n\nTeaching Assistant\n\nAlex Lavaee\n\nTeaching Assistant\n\nShreya Ravikumar\n\nTeaching Assistant\n\nFranklin Wang\n\nTeaching Assistant\n\nJohn Werner\n\nCommunity & Strategy\n\nEva Xie\n\nTeaching Assistant\n\nShorna Alam\n\nTeaching Assistant\n\nAnirudh Valiveru\n\nTeaching Assistant\n\n##### We are always accepting new applications to join the program staff. If\nyou are interested in becoming a Teaching Assistant (TA), please contact\nintrotodeeplearning-staff@mit.edu\n\n## Sponsors\n\n##### This program and delivery would not be possible without our amazing\nsponsors! If you are interested in becoming involved in this program as a\nsponsor please contact us at introtodeeplearning-staff@mit.edu\n\n#### About!\n\n6.S191 teaches the foundations of deep learning at MIT!\n\n#### Lectures and Labs\n\nWe open-source all materials. Checkout the lecture schedule for details!\n\n#### Social Media\n\nCopyright \u00a9 MIT 6.S191. banner image\n\n\u00d7\n\n#### Methods for Audio, Image, and Video Generation\n\n##### Douglas Eck, Senior Research Director, Google DeepMind\n\n###### Talk Abstract\n\nThis talk will provide a broad overview of Google DeepMind's research in\naudio, image, 3D and video generation. We will focus on autoregressive\napproaches and diffusion-based approaches. I will try to also provide a\nhistorical lens on attempts to use ML to genereate media, going back to early\nwork using RNNs and LSTM in the late 1990s and early 2000s. Given the breadth,\nwe won't have time to dive into many of the mathematical details of these\nmethods.\n\n###### Speaker Bio\n\nDoug is leading Google DeepMind\u2019s research efforts in Generative Media,\nincluding image, video, 3D, music and audio generation. He also leads a\nbroader group active in areas including including Fundamental Learning\nAlgorithms, Natural Language Processing, Multimodal Learning, Reinforcement\nLearning, Computer Vision and Generative Models. His own research lies at the\nintersection of machine learning and human-computer interaction (HCI). Doug\ncreated Magenta, an ongoing research project exploring the role of AI in art\nand music creation. He is also an advocate for PAIR, a multidisciplinary team\nthat explores the human side of AI through fundamental research, building\ntools, creating design frameworks, and working with diverse communities. In\nthe past, Doug worked on music perception, aspects of music performance,\nmachine learning for large audio datasets and music recommendation. He\ncompleted his PhD in Computer Science and Cognitive Science at Indiana\nUniversity in 2000 and went on to a postdoctoral fellowship with Juergen\nSchmidhuber at IDSIA in Lugano Switzerland. Before joining Google in 2010,\nDoug was faculty in Computer Science in the University of Montreal machine\nlearning group (now the MILA machine learning lab) where he became Associate\nProfessor. For more information see http://g.co/research/douglaseck.\n\n\u00d7\n\n#### Endless Experimentation: Stories from Models in the Wild\n\n##### Nikolas Laskaris, VP, Comet ML\n\n##### Douglas Blank, Head of Research, Comet ML\n\n###### Talk Abstract\n\nWhile ML model development is a challenging process, the management of these\nmodels becomes even more complex once they're in production. Shifting data\ndistributions, upstream pipeline failures, segmentation challenges, model\nhallucination and much more can create thorny feedback loops between\ndevelopment and production. In this talk, Niko will: (1) examine naive ML\nworkflows that don\u2019t take the development-production feedback loop into\naccount and explore why they break down; (2) share industry case studies where\nteams have applied these principles to their production ML systems; (3)\nshowcase generalizable system design principles that help manage these\nfeedback loops more effectively.\n\n###### Speaker Bio\n\nNiko Laskaris is a researcher and entrepreneur. Previously, Niko worked as a\nresearch scientist at Yale University, studying climate change and complex\nsystems. He also founded and built an educational consulting company based in\nVermont, Long Trail Prep. Niko holds a bachelor\u2019s degree from Yale University\nin Connecticut.\n\nDouglas Blank is the Head of Research at Comet ML, where he works with many\nteams, including Engineering, Customer Success, and Product Design. Prior to\nComet, Douglas completed his PhD in Computer Science and Cognitive Science\nfrom Indiana University, Bloomington. His thesis explored the training of\nneural networks to make analogies. He taught courses in Robotics, Cognitive\nScience, and Computer Science at Bryn Mawr College, where he created a\nresearch agenda called \"Developmental Robotics,\" focusing on using Deep\nLearning as the foundation for a mentally developing robot.\n\n", "frontpage": false}
