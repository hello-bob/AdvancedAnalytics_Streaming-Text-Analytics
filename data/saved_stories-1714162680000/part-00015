{"aid": "40169716", "title": "TorchGeo: Datasets and pre-trained models for geospatial data", "url": "https://github.com/microsoft/torchgeo", "domain": "github.com/microsoft", "votes": 1, "user": "zerojames", "posted_at": "2024-04-26 14:14:39", "comments": 0, "source_title": "GitHub - microsoft/torchgeo: TorchGeo: datasets, samplers, transforms, and pre-trained models for geospatial data", "source_text": "GitHub - microsoft/torchgeo: TorchGeo: datasets, samplers, transforms, and\npre-trained models for geospatial data\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nmicrosoft / torchgeo Public\n\n  * Notifications\n  * Fork 286\n  * Star 2.2k\n\nTorchGeo: datasets, samplers, transforms, and pre-trained models for\ngeospatial data\n\nwww.osgeo.org/projects/torchgeo/\n\n### License\n\nMIT license\n\n2.2k stars 286 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# microsoft/torchgeo\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n14 Branches\n\n11 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\ndependabot[bot]Bump codecov/codecov-action from 3.1.6 to 4.3.0 (#2030)Apr 26,\n20249fdbb09 \u00b7 Apr 26, 2024Apr 26, 2024\n\n## History\n\n1,904 Commits  \n  \n### .devcontainer\n\n|\n\n### .devcontainer\n\n| Use ruff (#1994)| Apr 15, 2024  \n  \n### .github\n\n|\n\n### .github\n\n| Bump codecov/codecov-action from 3.1.6 to 4.3.0 (#2030)| Apr 26, 2024  \n  \n### docs\n\n|\n\n### docs\n\n| Add South Africa Crop Type DataModule (#1970)| Apr 25, 2024  \n  \n### experiments\n\n|\n\n### experiments\n\n| Experiments: SSL4EO-L is no longer a WIP (#2026)| Apr 26, 2024  \n  \n### images\n\n|\n\n### images\n\n| Better README (#626)| Jun 30, 2022  \n  \n### logo\n\n|\n\n### logo\n\n| Add favicon to ReadTheDocs| Sep 8, 2021  \n  \n### requirements\n\n|\n\n### requirements\n\n| Bump ruff from 0.4.1 to 0.4.2 in /requirements (#2027)| Apr 25, 2024  \n  \n### tests\n\n|\n\n### tests\n\n| Add South Africa Crop Type DataModule (#1970)| Apr 25, 2024  \n  \n### torchgeo\n\n|\n\n### torchgeo\n\n| Add South Africa Crop Type DataModule (#1970)| Apr 25, 2024  \n  \n### .codecov.yml\n\n|\n\n### .codecov.yml\n\n| Remove Codecov annotations from PRs| Sep 19, 2021  \n  \n### .gitattributes\n\n|\n\n### .gitattributes\n\n| gitattributes: allow diff of test data (#470)| Mar 19, 2022  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Fix reprojection issues (#1344)| May 19, 2023  \n  \n### .pre-commit-config.yaml\n\n|\n\n### .pre-commit-config.yaml\n\n| Bump torchvision from 0.17.2 to 0.18.0 in /requirements (#2023)| Apr 25,\n2024  \n  \n### .readthedocs.yaml\n\n|\n\n### .readthedocs.yaml\n\n| RtD: use latest Ubuntu (#1954)| Mar 27, 2024  \n  \n### CITATION.cff\n\n|\n\n### CITATION.cff\n\n| Fix CITATION.cff format (#1633)| Oct 8, 2023  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| LICENSE: Remove indentation (#1955)| Mar 20, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| README: add Hugging Face badge (#1957)| Mar 27, 2024  \n  \n### hubconf.py\n\n|\n\n### hubconf.py\n\n| Add Multi-Weight Support API (#917)| Jan 22, 2023  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| Use ruff (#1994)| Apr 15, 2024  \n  \n## Repository files navigation\n\nTorchGeo is a PyTorch domain library, similar to torchvision, providing\ndatasets, samplers, transforms, and pre-trained models specific to geospatial\ndata.\n\nThe goal of this library is to make it simple:\n\n  1. for machine learning experts to work with geospatial data, and\n  2. for remote sensing experts to explore machine learning solutions.\n\nCommunity:\n\nPackaging:\n\nTesting:\n\n## Installation\n\nThe recommended way to install TorchGeo is with pip:\n\n    \n    \n    $ pip install torchgeo\n\nFor conda and spack installation instructions, see the documentation.\n\n## Documentation\n\nYou can find the documentation for TorchGeo on ReadTheDocs. This includes API\ndocumentation, contributing instructions, and several tutorials. For more\ndetails, check out our paper, podcast episode, tutorial, and blog post.\n\n## Example Usage\n\nThe following sections give basic examples of what you can do with TorchGeo.\n\nFirst we'll import various classes and functions used in the following\nsections:\n\n    \n    \n    from lightning.pytorch import Trainer from torch.utils.data import DataLoader from torchgeo.datamodules import InriaAerialImageLabelingDataModule from torchgeo.datasets import CDL, Landsat7, Landsat8, VHR10, stack_samples from torchgeo.samplers import RandomGeoSampler from torchgeo.trainers import SemanticSegmentationTask\n\n### Geospatial datasets and samplers\n\nMany remote sensing applications involve working with geospatial\ndatasets\u2014datasets with geographic metadata. These datasets can be challenging\nto work with due to the sheer variety of data. Geospatial imagery is often\nmultispectral with a different number of spectral bands and spatial resolution\nfor every satellite. In addition, each file may be in a different coordinate\nreference system (CRS), requiring the data to be reprojected into a matching\nCRS.\n\nIn this example, we show how easy it is to work with geospatial data and to\nsample small image patches from a combination of Landsat and Cropland Data\nLayer (CDL) data using TorchGeo. First, we assume that the user has Landsat 7\nand 8 imagery downloaded. Since Landsat 8 has more spectral bands than Landsat\n7, we'll only use the bands that both satellites have in common. We'll create\na single dataset including all images from both Landsat 7 and 8 data by taking\nthe union between these two datasets.\n\n    \n    \n    landsat7 = Landsat7(root=\"...\", bands=[\"B1\", ..., \"B7\"]) landsat8 = Landsat8(root=\"...\", bands=[\"B2\", ..., \"B8\"]) landsat = landsat7 | landsat8\n\nNext, we take the intersection between this dataset and the CDL dataset. We\nwant to take the intersection instead of the union to ensure that we only\nsample from regions that have both Landsat and CDL data. Note that we can\nautomatically download and checksum CDL data. Also note that each of these\ndatasets may contain files in different coordinate reference systems (CRS) or\nresolutions, but TorchGeo automatically ensures that a matching CRS and\nresolution is used.\n\n    \n    \n    cdl = CDL(root=\"...\", download=True, checksum=True) dataset = landsat & cdl\n\nThis dataset can now be used with a PyTorch data loader. Unlike benchmark\ndatasets, geospatial datasets often include very large images. For example,\nthe CDL dataset consists of a single image covering the entire continental\nUnited States. In order to sample from these datasets using geospatial\ncoordinates, TorchGeo defines a number of samplers. In this example, we'll use\na random sampler that returns 256 x 256 pixel images and 10,000 samples per\nepoch. We also use a custom collation function to combine each sample\ndictionary into a mini-batch of samples.\n\n    \n    \n    sampler = RandomGeoSampler(dataset, size=256, length=10000) dataloader = DataLoader(dataset, batch_size=128, sampler=sampler, collate_fn=stack_samples)\n\nThis data loader can now be used in your normal training/evaluation pipeline.\n\n    \n    \n    for batch in dataloader: image = batch[\"image\"] mask = batch[\"mask\"] # train a model, or make predictions using a pre-trained model\n\nMany applications involve intelligently composing datasets based on geospatial\nmetadata like this. For example, users may want to:\n\n  * Combine datasets for multiple image sources and treat them as equivalent (e.g., Landsat 7 and 8)\n  * Combine datasets for disparate geospatial locations (e.g., Chesapeake NY and PA)\n\nThese combinations require that all queries are present in at least one\ndataset, and can be created using a UnionDataset. Similarly, users may want\nto:\n\n  * Combine image and target labels and sample from both simultaneously (e.g., Landsat and CDL)\n  * Combine datasets for multiple image sources for multimodal learning or data fusion (e.g., Landsat and Sentinel)\n\nThese combinations require that all queries are present in both datasets, and\ncan be created using an IntersectionDataset. TorchGeo automatically composes\nthese datasets for you when you use the intersection (&) and union (|)\noperators.\n\n### Benchmark datasets\n\nTorchGeo includes a number of benchmark datasets\u2014datasets that include both\ninput images and target labels. This includes datasets for tasks like image\nclassification, regression, semantic segmentation, object detection, instance\nsegmentation, change detection, and more.\n\nIf you've used torchvision before, these datasets should seem very familiar.\nIn this example, we'll create a dataset for the Northwestern Polytechnical\nUniversity (NWPU) very-high-resolution ten-class (VHR-10) geospatial object\ndetection dataset. This dataset can be automatically downloaded, checksummed,\nand extracted, just like with torchvision.\n\n    \n    \n    from torch.utils.data import DataLoader from torchgeo.datamodules.utils import collate_fn_detection from torchgeo.datasets import VHR10 # Initialize the dataset dataset = VHR10(root=\"...\", download=True, checksum=True) # Initialize the dataloader with the custom collate function dataloader = DataLoader( dataset, batch_size=128, shuffle=True, num_workers=4, collate_fn=collate_fn_detection, ) # Training loop for batch in dataloader: images = batch[\"image\"] # list of images boxes = batch[\"boxes\"] # list of boxes labels = batch[\"labels\"] # list of labels masks = batch[\"masks\"] # list of masks # train a model, or make predictions using a pre-trained model\n\nAll TorchGeo datasets are compatible with PyTorch data loaders, making them\neasy to integrate into existing training workflows. The only difference\nbetween a benchmark dataset in TorchGeo and a similar dataset in torchvision\nis that each dataset returns a dictionary with keys for each PyTorch Tensor.\n\n### Pre-trained Weights\n\nPre-trained weights have proven to be tremendously beneficial for transfer\nlearning tasks in computer vision. Practitioners usually utilize models pre-\ntrained on the ImageNet dataset, containing RGB images. However, remote\nsensing data often goes beyond RGB with additional multispectral channels that\ncan vary across sensors. TorchGeo is the first library to support models pre-\ntrained on different multispectral sensors, and adopts torchvision's multi-\nweight API. A summary of currently available weights can be seen in the docs.\nTo create a timm Resnet-18 model with weights that have been pretrained on\nSentinel-2 imagery, you can do the following:\n\n    \n    \n    import timm from torchgeo.models import ResNet18_Weights weights = ResNet18_Weights.SENTINEL2_ALL_MOCO model = timm.create_model(\"resnet18\", in_chans=weights.meta[\"in_chans\"], num_classes=10) model.load_state_dict(weights.get_state_dict(progress=True), strict=False)\n\nThese weights can also directly be used in TorchGeo Lightning modules that are\nshown in the following section via the weights argument. For a notebook\nexample, see this tutorial.\n\n### Reproducibility with Lightning\n\nIn order to facilitate direct comparisons between results published in the\nliterature and further reduce the boilerplate code needed to run experiments\nwith datasets in TorchGeo, we have created Lightning datamodules with well-\ndefined train-val-test splits and trainers for various tasks like\nclassification, regression, and semantic segmentation. These datamodules show\nhow to incorporate augmentations from the kornia library, include\npreprocessing transforms (with pre-calculated channel statistics), and let\nusers easily experiment with hyperparameters related to the data itself (as\nopposed to the modeling process). Training a semantic segmentation model on\nthe Inria Aerial Image Labeling dataset is as easy as a few imports and four\nlines of code.\n\n    \n    \n    datamodule = InriaAerialImageLabelingDataModule(root=\"...\", batch_size=64, num_workers=6) task = SemanticSegmentationTask( model=\"unet\", backbone=\"resnet50\", weights=True, in_channels=3, num_classes=2, loss=\"ce\", ignore_index=None, lr=0.1, patience=6, ) trainer = Trainer(default_root_dir=\"...\") trainer.fit(model=task, datamodule=datamodule)\n\nTorchGeo also supports command-line interface training using LightningCLI. It\ncan be invoked in two ways:\n\n    \n    \n    # If torchgeo has been installed torchgeo # If torchgeo has been installed, or if it has been cloned to the current directory python3 -m torchgeo\n\nIt supports command-line configuration or YAML/JSON config files. Valid\noptions can be found from the help messages:\n\n    \n    \n    # See valid stages torchgeo --help # See valid trainer options torchgeo fit --help # See valid model options torchgeo fit --model.help ClassificationTask # See valid data options torchgeo fit --data.help EuroSAT100DataModule\n\nUsing the following config file:\n\n    \n    \n    trainer: max_epochs: 20 model: class_path: ClassificationTask init_args: model: \"resnet18\" in_channels: 13 num_classes: 10 data: class_path: EuroSAT100DataModule init_args: batch_size: 8 dict_kwargs: download: true\n\nwe can see the script in action:\n\n    \n    \n    # Train and validate a model torchgeo fit --config config.yaml # Validate-only torchgeo validate --config config.yaml # Calculate and report test accuracy torchgeo test --config config.yaml --trainer.ckpt_path=...\n\nIt can also be imported and used in a Python script if you need to extend it\nto add new features:\n\n    \n    \n    from torchgeo.main import main main([\"fit\", \"--config\", \"config.yaml\"])\n\nSee the Lightning documentation for more details.\n\n## Citation\n\nIf you use this software in your work, please cite our paper:\n\n    \n    \n    @inproceedings{Stewart_TorchGeo_Deep_Learning_2022, address = {Seattle, Washington}, author = {Stewart, Adam J. and Robinson, Caleb and Corley, Isaac A. and Ortiz, Anthony and Lavista Ferres, Juan M. and Banerjee, Arindam}, booktitle = {Proceedings of the 30th International Conference on Advances in Geographic Information Systems}, doi = {10.1145/3557915.3560953}, month = nov, pages = {1--12}, publisher = {Association for Computing Machinery}, series = {SIGSPATIAL '22}, title = {{TorchGeo}: Deep Learning With Geospatial Data}, url = {https://dl.acm.org/doi/10.1145/3557915.3560953}, year = {2022} }\n\n## Contributing\n\nThis project welcomes contributions and suggestions. If you would like to\nsubmit a pull request, see our Contribution Guide for more information.\n\nThis project has adopted the Microsoft Open Source Code of Conduct. For more\ninformation see the Code of Conduct FAQ or contact opencode@microsoft.com with\nany additional questions or comments.\n\n## About\n\nTorchGeo: datasets, samplers, transforms, and pre-trained models for\ngeospatial data\n\nwww.osgeo.org/projects/torchgeo/\n\n### Topics\n\ncomputer-vision deep-learning geospatial models pytorch remote-sensing\nsatellite-imagery datasets earth-observation transforms torchvision\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\n### Code of conduct\n\nCode of conduct\n\n### Security policy\n\nSecurity policy\n\n### Citation\n\nActivity\n\nCustom properties\n\n### Stars\n\n2.2k stars\n\n### Watchers\n\n45 watching\n\n### Forks\n\n286 forks\n\nReport repository\n\n## Releases 11\n\nv0.5.2 Latest\n\nMar 3, 2024\n\n\\+ 10 releases\n\n## Contributors 68\n\n\\+ 54 contributors\n\n## Languages\n\n  * Python 99.2%\n  * Shell 0.8%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
