{"aid": "40188756", "title": "The hardest program I've ever written", "url": "https://journal.stuffwithstuff.com/2015/09/08/the-hardest-program-ive-ever-written/", "domain": "stuffwithstuff.com", "votes": 1, "user": "andsoitis", "posted_at": "2024-04-28 14:17:10", "comments": 0, "source_title": "The Hardest Program I\u2019ve Ever Written", "source_text": "The Hardest Program I\u2019ve Ever Written \u2013 journal.stuffwithstuff.com\n\n# The Hardest Program I\u2019ve Ever Written\n\n\u21a9 \u21aa\n\n#### September 08, 2015 code dart\n\nThe hardest program I\u2019ve ever written, once you strip out the whitespace, is\n3,835 lines long. That handful of code took me almost a year to write.\nGranted, that doesn\u2019t take into account the code that didn\u2019t make it. The\ncommit history shows that I deleted 20,704 lines of code over that time. Every\nsurviving line has about three fallen comrades.\n\nIf it took that much thrashing to get it right, you\u2019d expect it to do\nsomething pretty deep right? Maybe a low-level hardware interface or some\nwicked graphics demo with tons of math and pumping early-90s-style techno? A\nlikely-to-turn-evil machine learning AI Skynet thing?\n\nNope. It reads in a string and writes out a string. The only difference\nbetween the input and output strings is that it modifies some of the\nwhitespace characters. I\u2019m talking, of course, about an automated code\nformatter.\n\n## Introducing dartfmt\n\nI work on the Dart programming language. Part of my job is helping make Dart\ncode more readable, idiomatic, and consistent, which is why I ended up writing\nour style guide. That was a good first step, but any style guide written in\nEnglish is either so brief that it\u2019s ambiguous, or so long that no one reads\nit.\n\nGo\u2019s gofmt tool showed a better solution: automatically format everything.\nCode is easier to read and contribute to because it\u2019s already in the style\nyou\u2019re used to. Even if the output of the formatter isn\u2019t great, it ends those\ninterminable soul-crushing arguments on code reviews about formatting.\n\nOf course, I still have to sell users on running the formatter in the first\nplace. For that, having great output really does matter. Also, I\u2019m pretty\npicky with the formatting in my own code, and I didn\u2019t want to tell users to\nuse a tool that I didn\u2019t use myself.\n\nGetting that kind of quality means applying pretty sophisticated formatting\nrules. That in turn makes performance difficult. I knew balancing quality and\nspeed would be hard, but I didn\u2019t realize just how deep the rabbit hole went.\n\nI have finally emerged back into the sun, and I\u2019m pleased with what I brought\nback. I like the output, and the performance is solid. On my laptop, it can\nblow through over two million lines of code in about 45 seconds, using a\nsingle core.\n\n## Why is formatting hard?\n\nAt this point, you\u2019re probably thinking, \u201cWait. What\u2019s so hard about\nformatting?\u201d After you\u2019ve parsed, can\u2019t you just walk the AST and pretty-print\nit with some whitespace?\n\nIf every statement fit within the column limit of the page, yup. It\u2019s a piece\nof cake. (I think that\u2019s what gofmt does.) But our formatter also keeps your\ncode within the line length limit. That means adding line breaks (or \u201csplits\u201d\nas the formatter calls them), and determining the best place to add those is\nfamously hard.\n\nCheck out this guy:\n\n    \n    \n    experimental = document.querySelectorAll('link').any((link) => link.attributes['rel'] == 'import' && link.attributes['href'] == POLYMER_EXPERIMENTAL_HTML);\n\nThere are thirteen places where a line break is possible here according to our\nstyle rules. That\u2019s 8,192 different combinations if we brute force them all 1.\nThe search space we have to cover is exponentially large, and even ranking\ndifferent solutions is a subtle problem. Is it better to split before the\n.any()? Why or why not?\n\nWhat is up with the skulls?\n\nI had two goals with this article: to explain how dartfmt works, and to show a\nrealistic picture of how a real programmer solves a difficult problem with all\nof the messiness that entails. Alas, the first is more than long enough to try\nyour patience, so I shunted all of the dead ends and failed attempts to\nfootnotes. Click the skulls to laugh at my misfortune.\n\nIn Dart, we made things harder on ourselves. We have anonymous functions, lots\nof higher-order functions, and\u2014until we added async and await\u2014used futures for\nconcurrency. That means lots of callbacks and lots of long method chains. Some\nDart users really dig a functional style and appear to be playing a game where\nwhoever writes the most code with the fewest semicolons wins.\n\nHere\u2019s real code from an amateur player:\n\n    \n    \n    _bindAssignablePropsOn.forEach((String eventName) => node .addEventListener(eventName, (_) => zone.run( () => bindAssignableProps.forEach( (propAndExp) => propAndExp[1].assign( scope.context, jsNode[propAndExp[0]])))));\n\nYeah, that\u2019s four nested functions. 1,048,576 ways to split that one. Here\u2019s\none of the best that I\u2019ve found. This is what a pro player brings to the game:\n\n    \n    \n    return doughnutFryer .start() .then((_) => _frostingGlazer.start()) .then((_) => Future.wait([ _conveyorBelts.start(), sprinkleSprinkler.start(), sauceDripper.start() ])) .catchError(cannotGetConveyorBeltRunning) .then((_) => tellEveryoneDonutsAreJustAboutDone()) .then((_) => Future.wait([ croissantFactory.start(), _giantBakingOvens.start(), butterbutterer.start() ]) .catchError(_handleBakingFailures) .timeout(scriptLoadingTimeout, onTimeout: _handleBakingFailures) .catchError(cannotGetConveyorBeltRunning)) .catchError(cannotGetConveyorBeltRunning) .then((_) { _logger.info(\"Let's eat!\"); });\n\n(The funny names are because this was sanitized from internal code.) That\u2019s a\nsingle statement, all 565 characters of it. There are about 549 billion ways\nwe could line break it.\n\nUltimately, this is what the formatter does. It applies some fairly\nsophisticated ranking rules to find the best set of line breaks from an\nexponential solution space. Note that \u201cbest\u201d is a property of the entire\nstatement being formatted. A line break changes the indentation of the\nremainder of the statement, which in turn affects which other line breaks are\nneeded. Sorry, Knuth. No dynamic programming this time 2.\n\nI think the formatter does a good job, but how it does it is a mystery to\nusers. People get spooked when robots surprise them, so I thought I would\ntrace the inner workings of its metal mind. And maybe try to justify to myself\nwhy it took me a year to write a program whose behavior in many ways is\nindistinguishable from cat.\n\n## How the formatter sees your code\n\nAs you\u2019d expect from a program that works on source code, the formatter is\nstructured much like a compiler. It has a front end that parses your code and\nconverts that to an intermediate representation 3. It does some optimization\nand clean up on that 4, and then the IR goes to a back end 5 that produces the\nfinal output. The main objects here are chunks, rules, and spans.\n\n### Chunks\n\nA chunk is an atomic unit of formatting. It\u2019s a contiguous region of\ncharacters that we know will not contain any line breaks. Given this code:\n\n    \n    \n    format /* comment */ this;\n\nWe break it into these chunks: format, /* comment */, and this;.\n\nChunks are similar to a token in a conventional compiler, but they tend to be,\nwell, chunkier. Often, the text for several tokens ends up in the same chunk,\nlike this and ; here. If a line break can never occur between two tokens, they\nend up in the same chunk 6.\n\nChunks are mostly linear. For example, given an expression like:\n\n    \n    \n    some(nested, function(ca + ll))\n\nWe chunk it to the flat list: some( nested, function( ca + ll)).\n\nWe could treat an entire source file like a single flat sequence of chunks,\nbut it would take forever and a day to line break the whole thing 7. With\nthings like long chains of asynchronous code, a single \u201cstatement\u201d may be\nhundreds of lines of code containing several nested functions or collections\nthat each contain their own piles of code.\n\nWe can\u2019t treat those nested functions or collection literals entirely\nindependently because the surrounding expression affects how they are\nindented. That in turn affects how long their lines are. Indent a function\nbody two more spaces and now its statements have two fewer spaces before they\nhit the end of the line.\n\nInstead, we treat nested block bodies as a separate little list of chunks to\nbe formatted mostly on their own but subordinate to where they appear. The\nchunk that begins one of these literals, like the { preceding a function or\nmap, contains a list of child block chunks for the contained block. In other\nwords, chunks do form a tree, but one that only reflects block nesting, not\nexpressions.\n\nThe end of a chunk marks the point where a split may occur in the final\noutput, and the chunk has some data describing it 8. It keeps track of whether\na blank line should be added between the chunks (like between two class\ndefinitions), how much the next line should be indented, and the expression\nnesting depth at that point in the code.\n\nThe most important bit of data about the split is the rule that controls it 9.\n\n### Rules\n\nEach potential split in the program is owned by a rule. A single rule may own\nthe splits of several chunks. For example, a series of binary operators of the\nsame kind like a + b + c + d uses a single rule for the splits after each +\noperator.\n\nA rule controls which of its splits break and which don\u2019t. It determines this\nbased on the state that the rule is in, which it calls its value. You can\nthink of a rule like a dial and the value is what you\u2019ve turned it to. Given a\nvalue, the rule will tell you which of its chunks get split.\n\nThe simplest rule is a hard split rule. It says that its chunk always splits,\nso it only has one value: 0. This is useful for things like line comments\nwhere you always need to split after it, even in the middle of an expression\n10.\n\nThen there is a simple split rule. It allows two values: 0 means none of its\nchunks split and 1 means they all do. Since most splits are independent of the\nothers, this gets used for most of the splits in the program.\n\nBeyond that, there are a handful of special-case rules. These are used in\nplaces where we want to more precisely control the configuration of a set of\nsplits. For example, the positional argument list in a function list is\ncontrolled by a single rule. A function call like:\n\n    \n    \n    function(first, second, third)\n\nWill have splits after function(, first,, second,, and third). They are all\nowned by a single rule that only allows the following configurations:\n\n    \n    \n    // 0: Don't split at all. function(first, second, third) // 1: Split before the first. function( first, second, third) // 2: Split only before the last argument. function(first, second, third) // 3: Split only before the middle argument. function(first, second, third) // 4: Split before all of them. function( first, second, third)\n\nHaving a single rule for this instead of individual rules for each argument\nlets us prohibit undesired outputs like:\n\n    \n    \n    function( first, second, third)\n\n### Constraints\n\nGrouping a range of splits under a single rule helps us prevent split\nconfigurations we want to avoid like the previous example, but it\u2019s not\nenough. There are more complex constraints we want to enforce like: \u201cif a\nsplit occurs inside a list element, the list should split too\u201d. That avoids\noutput like this:\n\n    \n    \n    [first, second + third, fourth]\n\nHere, the list and the + expression have their own rules, but those rules need\nto interact. If the + takes value 1, the list rule needs to as well. To\nsupport this, rules can constrain each other. Any rule can limit the values\nanother rule is allowed to take based on its own value. Typically, constraints\nare used to make a subexpression rule force the surrounding rules to split\nwhen the subexpression splits 11.\n\nFinally, each rule has a cost. This is a numeric penalty that applies when any\nof that rule\u2019s chunks are split. This helps us determine which sets of splits\nare better or worse than others 12. Rule costs are only part of how overall\nfitness is calculated. Most of the cost calculation comes from spans.\n\n### Spans\n\nA span marks a series of contiguous chunks that we want to avoid splitting. I\npicture it like a rubber band stretching around them. If a split happens in\nany of those chunks, the span is broken. When that happens, the solution is\npenalized based on the cost of the span.\n\nSpans can nest arbitrarily deeply. In an expression like:\n\n    \n    \n    function(first(a, b), second(c, d))\n\nThere will be spans around a, b and c, d to try to keep those argument lists\nfrom splitting, but also another span around first(a, b), second(c, d) to keep\nthe outer argument list from splitting:\n\nIf a split occurs between a, and b, the a, b span splits, but so does the\nfirst(a, b), second(c, d) one. However, if a split occurs after first(a, b),\nthen the a, b span is still fine. In this way, spans teach the formatter to\nprefer splitting at a higher level of nesting when possible since it breaks\nfewer nested spans.\n\n## Parsing source to chunks\n\nConverting your raw source code to this representation is fairly\nstraightforward. The formatter uses the wonderful analyzer package to parse\nyour code to an AST. This gives us a tree structure that represents every\nsingle byte of your program. Unlike many ASTs, it even includes comments.\n\nOnce we have that, the formatter does a top-down traversal of the tree. As it\nwalks, it writes out chunks, rules, and spans for the various grammar\nproductions. This is where the formatting \u201cstyle\u201d is determined.\n\nThere\u2019s no rocket science here, but there are a lot of hairy corner cases.\nComments can appear in weird places. We have to handle weird things like:\n\n    \n    \n    function(argument, // comment argument)\n\nHere, we normally would have a split after the first argument owned by an\nargument list rule. But the line comment adheres to the , and has a hard split\nafter it, so we need to make sure the argument list rule handles that.\n\nWhitespace is only implicitly tracked by the AST so we have to reconstitute it\nin the few places where your original whitespace affects the output. Having a\ndetailed test suite really helps here.\n\nOnce we\u2019ve visited the entire tree, the AST has been converted to a tree of\nchunks and a bunch of spans wrapped around pieces of it.\n\n## Formatting chunks\n\nWe\u2019ve got ourselves a big tree of chunks owned by a slew of rules. Earlier, I\nsaid rule values are like knobs. Now we get to dial those knobs in. Doing this\nna\u00efvely is infeasible. Even a small source file contains hundreds of\nindividual rules and the set of possible solutions is exponential in the\nnumber of rules.\n\nThe first thing we do is divide the chunk list into regions we know can\u2019t\ninterfere with each other. These are roughly \u201clines\u201d of code. So with:\n\n    \n    \n    first(line); second(line);\n\nWe know that how we split the first statement has no effect on the second one.\nSo we run through the list of chunks and break them into shorter lists\nwhenever we hit a hard split that isn\u2019t nested inside an expression.\n\nEach of these shorter chunk lists is fed to the line splitter. Its job is to\npick the best set of values for all the rules used by the chunks in the line.\nIn most cases, this is trivial: if the whole line fits on the page, every rule\ngets set to zero\u2014no splits\u2014and we\u2019re done.\n\nWhen a line doesn\u2019t fit, the splitter has to figure out which combination of\nrule values produces the best result. That is:\n\n  1. The one with the fewest characters that go over the column limit.\n\n  2. The one with the lowest cost, based on which rules and spans were split.\n\nCalculating the cost for a set of rule values is pretty easy, but there are\nstill way too many permutations to brute force it. If we can\u2019t brute force it,\nhow do we do it?\n\n## How line splitting works\n\nSince I dropped out of college, my knowledge of algorithms was fairly, um,\nrudimentary. So before I interviewed at Google, I spent two days in a hotel\nroom cramming as many of them\u2014mostly graph traversal\u2014in my head as I could. At\nthe time, I thought graphs would never come up in the interviews...\n\nThen I had multiple interview questions that reduced down to doing the right\nkind of traversal over a graph. At the time, I thought this stuff would never\nbe relevant to my actual job...\n\nThen I spent the past few years at Google discovering that damn near every\nprogram I have to write can be reduced down to some kind of graph search. I\nwrote a package manager where dependencies are a transitive closure and\nversion constraint solving is graph based. My hobby roguelike uses graphs for\npathfinding. Graphs out the wazoo. I can do BFS in my sleep now.\n\nNaturally, after several other failed approaches, I found that line splitting\ncan be handled like a graph search problem 13. Each node in the graph\nrepresents a solution\u2014a set of values for each rule. Solutions can be partial:\nsome rules may be left with their values unbound.\n\nFrom a given partial solution (including the initial \u201cno rules bound\u201d one),\nthere are edges to new partial solutions. Each edges binds one additional rule\nto a value. By starting from an empty solution and walking this graph, we\neventually reach complete solutions where all of the rules have been bound to\nvalues.\n\nGraph search is great if you know where your destination is and you\u2019re trying\nto find the best path. But we don\u2019t actually know that. We don\u2019t know what the\nbest complete solution is. (If we did, we\u2019ve be done already!)\n\nGiven this, no textbook graph search algorithm is sufficient. We need to apply\nsome domain knowledge\u2014we need to take advantage of rules and conditions\nimplicit in the specific problem we\u2019re solving.\n\nAfter a dozen dead ends, I found three (sort of four) that are enough to get\nit finding the right solution quickly:\n\n### Bailing early\n\nWe are trying to minimize two soft constraints at the same time:\n\n  1. We want to minimize the number of characters that overflow the line length limit. We can\u2019t make this a hard constraint that there is no overflow because it\u2019s possible for a long identifier or string literal to overflow in every solution. In that case, we still need to find the result that\u2019s closest to fitting.\n\n  2. We want to find the lowest cost\u2014the fewest split rules and broken spans.\n\nThe first constraint dominates the second\u2014we prefer a solution with any cost\nif it fits one more character in. In practice, there is almost always a\nsolution that does fit, so it usually comes down to picking the lowest cost\nsolution 14.\n\nWe don\u2019t know a priori what the cost of the winning solution will be, but we\ndo know one useful piece of information: forcing a rule to split always\nincreases the cost.\n\nIf we treat any unbound rule as being implicitly unsplit 15, that means the\nstarting solution with every rule unbound always has the lowest cost (zero).\nWe can then explore outward from there in order of increasing cost by adding\none rule at a time.\n\nThis is a basic best-first search. We keep a running queue of all of the\npartial solutions we\u2019ve haven\u2019t explored yet, sorted from lowest cost to\nhighest. Each iteration, we pop a solution off.\n\nIf the solution completely fits in the page width, then we know we\u2019ve won the\noverflow constraint. Since we\u2019re exploring in order of increasing cost, we\nalso know it\u2019s the lowest cost. So, ta-da!, we found the winner and can stop\nexploring. Otherwise, if the current best solution has any unbound rules, we\nenqueue new solutions, each of which binds one of those to a value.\n\nWe basically explore the entire solution space in order of increasing cost. As\nsoon as we find a solution that fits in the page, we stop.\n\n### Avoiding dead ends\n\nThe above sounds pretty promising, but it turns out that there can be an\nimperial ton of \u201clow-cost but overflowing\u201d solutions. When you\u2019re trying to\nformat a really long line, there are plenty of ways it can not fit, and this\nalgorithm will try basically all of them. After all, they\u2019re low cost since\nthey don\u2019t have many splits.\n\nWe need to avoid wasting time tweaking rules that aren\u2019t part of the problem.\nFor example, say we\u2019re looking at a partial solution like this:\n\n    \n    \n    // Blog-friendly 40-char line limit: | function( firstCall(a, b, c, d, e, f, g, h), secondCall(\"very long argument string here\"));\n\nThere are a bunch of ways we can split the arguments to firstCall(), but we\ndon\u2019t need to. Its line already fits. The only line we need to worry about is\nthe secondCall() one.\n\nSo, when we are expanding a partial solution, we only bind rules that have\nchunks on overflowing lines. If all of a rule\u2019s chunks are on lines that\nalready fit, we don\u2019t mess with it. In fact, we don\u2019t even worry about rules\non any overflowing line but the first. Since tweaking the first line will\naffect the others, there\u2019s no reason to worry about them yet 16.\n\nThis dramatically cuts down \u201cbranchiness\u201d of the graph. Even though a partial\nsolution may have dozens of unbound rules, usually only a couple are on long\nlines and only those get explored.\n\n### Pruning redundant branches\n\nThis gets us pretty far, but the splitter can still go off the deep end in\nsome cases. The problem is that within large statements, you still run into\ncases where how you format part of the statement is mostly independent of\nlater parts.\n\nTake something like:\n\n    \n    \n    // Blog-friendly 40-char line limit: | new Compiler( assertions: options.has('checked-mode'), annotations: options.has('annotations'), primitives: options.has('primitives'), minify: options.has('minify'), preserve: options.has('preserve'), liveAnalysis: check(options.has('live'), options.has('analysis')), multi: options.has('multi'), sourceMap: options.has('source-map'));\n\nEach of those named arguments can be split in a few different ways. And, since\nthose are less nested\u2014which means fewer split spans\u2014than that nasty\nliveAnalysis: line, it will try every combination of all of them before it\nfinally gets down to the business of splitting that check() call.\n\nThe best way to split the liveAnalysis: line is the best way to split it\nregardless of how we split assertions: or annotations:. In other words, there\nare big branches of the solution space that initially differ in irrelevant\nways, but eventually reconvene to roughly the same solution. We traverse every\nsingle one of them.\n\nWhat we need is a way to prune entire branches of the solution space. Given\ntwo partial solutions A and B, if we could say not just \u201cA is better than B\u201d\nbut \u201cevery solution we can get to from A will be better than every solution we\ncan get to from B\u201d then we can discard B and the entire branch of solutions\nstemming from it.\n\nIt took some work, but I finally figured out that you can do this in many\ncases. Given two partial solutions, if one has a lower cost than the other\nand:\n\n  * They have the same set of unbound rules (but their bound rules have different values, obviously).\n\n  * None of their bound rules are on the same line as an unbound rule.\n\n  * None of their bound rules place constraints on an unbound rule.\n\nThen the solution with a lower cost will always lead to solutions that also\nhave lower costs. Its entire branch wins. We can discard the other solution\nand everything that it leads to. Once I got this working, the formatter could\nline split damn near anything in record time 17.\n\n### An escape hatch\n\nAlas, that \u201cdamn near\u201d is significant. There are still a few cases where the\nformatter takes a long time. I\u2019ve only ever seen this on machine generated\ncode. Stuff like:\n\n    \n    \n    class ResolutionCopier { @override bool visitClassDeclaration(ClassDeclaration node) { ClassDeclaration toNode = this._toNode as ClassDeclaration; return javaBooleanAnd( javaBooleanAnd( javaBooleanAnd( javaBooleanAnd(javaBooleanAnd(javaBooleanAnd( javaBooleanAnd(javaBooleanAnd( javaBooleanAnd(javaBooleanAnd(javaBooleanAnd( _isEqualNodes(node.documentationComment, toNode.documentationComment), _isEqualNodeLists( node.metadata, toNode.metadata)), _isEqualTokens(node.abstractKeyword, toNode.abstractKeyword)), _isEqualTokens( node.classKeyword, toNode.classKeyword)), _isEqualNodes( node.name, toNode.name)), _isEqualNodes( node.typeParameters, toNode.typeParameters)), _isEqualNodes( node.extendsClause, toNode.extendsClause)), _isEqualNodes( node.withClause, toNode.withClause)), _isEqualNodes( node.implementsClause, toNode.implementsClause)), _isEqualTokens(node.leftBracket, toNode.leftBracket)), _isEqualNodeLists( node.members, toNode.members)), _isEqualTokens( node.rightBracket, toNode.rightBracket)); } }\n\nYeah, welcome to my waking nightmare. Unsurprisingly, code like this bogs down\nthe formatter. I want dartfmt to be usable in things like presubmit scripts\nwhere it will have a ton of weird code thrown at it and it must complete in a\nreliable amount of time.\n\nSo there is one final escape hatch. If the line splitter tries, like, 5,000\nsolutions and still hasn\u2019t found a winner yet, it just picks the best it found\nso far and bails.\n\nIn practice, I only see it hit this case on generated code. Thank God.\n\n## Finally, output\n\nOnce the line splitter has picked values for all of the rules, the rest is\neasy. The formatter walks the tree of chunks, printing their text. When a rule\nforces a chunk to split, it outputs a newline (or two), updates the\nindentation appropriately and keeps trucking.\n\nThe end result is a string of (I hope!) beautifully formatted Dart code. So\nmuch work just to add or remove a few spaces!\n\n### Footnotes\n\n1 Yes, I really did brute force all of the combinations at first. It let me\nfocus on getting the output correct before I worried about performance. Speed\nwas fine for most statements. The other few wouldn\u2019t finish until after the\nheat death of the universe.\n\n2 For most of the time, the formatter did use dynamic programming and\nmemoization. I felt like a wizard when I first figured out how to do it. It\nworked fairly well, but was a nightmare to debug.\n\nIt was highly recursive, and ensuring that the keys to the memoization table\nwere precise enough to not cause bugs but not so precise that the cache\nlookups always fail was a very delicate balancing act. Over time, the amount\nof data needed to uniquely identify the state of a subproblem grew, including\nthings like the entire expression nesting stack at a point in the line, and\nthe memoization table performed worse and worse.\n\n3 The IR evolved constantly. Spans and rules were later additions. Even the\nway chunks tracked indentation changed frequently. Indentation used to be\nstored in levels, where each level was two spaces. Then directly in spaces.\nExpression nesting went through a number of representations.\n\nIn all of this, the IR\u2019s job is to balance being easy for the front-end to\nproduce while being efficient for the back end to consume. The back end really\ndrives this. The IR is structured to be the right data structure for the\nalgorithm the back end wants to use.\n\n4 Comments were the one of the biggest challenges. The formatter initially\nassumed there would be no newlines in some places. Who would expect a newline,\nsay, between the keywords in abstract class? Alas, there\u2019s nothing preventing\na user from doing:\n\n    \n    \n    abstract // Oh, crap. A line comment. class Foo {}\n\nSo I had to do a ton of work to make it resilient in the face of comments and\nnewlines appearing in all sorts of weird places. There\u2019s no single clean\nsolution for this, just lots of edge cases and special handling.\n\n5 The back end is where all of the performance challenges come from, and it\nwent through two almost complete rewrites before it ended up where it is\ntoday.\n\n6 I started from a simpler formatter written by a teammate that treated text,\nwhitespace, and splits all as separate chunks. I unified those so that each\nchunk included non-whitespace text, line split information, and whitespace\ninformation if it didn\u2019t split. That simplified a lot.\n\n7 When I added support for better indentation of nested functions, I broke the\ncode that handled dividing the source code into separate line-splittable\nregions. For a while, a single top-level statement would be split as a single\nunit, even if it contained nested functions with hundreds of lines of code. It\nwas... not fast.\n\n8 Ideally, the split information in a chunk would describe the split before\nthe chunk\u2019s text. This would avoid the pointless split information on the last\nchunk, and also solve annoying special-case handling of the indentation before\nthe very first chunk.\n\nI\u2019ve tried to correct this mistake a number of times, but it causes a near-\ninfinite number of off-by-one bugs and I just haven\u2019t had the time to push it\nall the way through and fix everything.\n\n9 Rules are a relatively recent addition. Originally each chunk\u2019s split was\nhandled independently. You could specify some relations between them like \u201cif\nthis chunk splits then this other one has to as well\u201d, but you could not\nexpress things like \u201conly one of these three chunks may split\u201d\n\nEventually, I realized the latter is what I really needed to get argument\nlists formatting well, so I conceived of rules as a separate concept and\nrewrote the front and line splitter to work using those.\n\n10 At first, I thought hard splits weren\u2019t needed. Any place a mandatory\nnewline appears (like between two statements) is a place where you could just\nbreak the list of chunks in two and line split each half independently. From\nthe line splitter\u2019s perspective, there would be no hard splits.\n\nWhich would work... except for line comments:\n\n    \n    \n    some(expression, // with a line comment rightInTheMiddleOfIt);\n\nThis has to be split as a single unit to get the expression nesting and\nindentation correct, but it also contains a mandatory newline after the line\ncomment.\n\n11 There used to be a separate class for a \u201cmultisplit\u201d to directly handle\nforcing outer expressions to split when inner ones did. Once rules came along,\nthey also needed to express constraints between them, and eventually those\nconstraints were expressive enough to be able to handle the multisplit\nbehavior directly and multisplits were removed.\n\n12 I spent a lot of time tuning costs for different grammar productions to\ncontrol how tightly bound different expressions were. The goal was to allow\nsplits at the places where the reader thought code was \u201cloosest\u201d, so stuff\nlike higher precedence expressions would have higher costs.\n\nTuning these costs was a nightmare. It was like a hanging mobile where\ntweaking one cost would unbalance all of the others. On more than one\noccasion, I found myself considering making them floating point instead of\nintegers, a sure sign of madness.\n\nIt turns out spans are what you really want in order to express looseness.\nNested infix operators then fall out naturally because you have more spans\naround the deeper nested operands. The parse tree gives it to you for free.\n\nThese days, almost every chunk and span has a cost of 1, and it\u2019s the quantity\nof nested spans and contained chunks that determine where it splits.\n\n13 I had known that clang-format worked this way for a long time, but I could\nnever wrap my head around how to apply it to dartfmt\u2019s richer chunk/rule/span\nsystem.\n\nI took a lot of walks along the bike trail next to work trying to think\nthrough a way to get graph search working when the two numbers being optimized\n(overflow characters and cost) are in direct opposition, and we don\u2019t even\nknow what the goal state looks like. It took a long time before it clicked.\nEven then, it didn\u2019t work at all until I figured out the right heuristics to\nuse to optimize it.\n\n14 For a long time, overflow and cost were treated as a single fitness\nfunction. Every overflow character just added a very high value to the cost to\nmake the splitter strongly want to avoid them.\n\nSplitting overflow out as a separate metric turned out to be key to getting\nthe graph search to work because it let us order the solutions by cost\nindependently of overflow characters.\n\n15 I went back and forth on how an unbound rule should implicitly behave.\nTreating it as implicitly split gives you solutions with fewer overflow\ncharacters sooner. Treating it as unsplit gives you lower costs.\n\n16 Oh, God. I tried a million different ways to reduce the branchiness before\nI hit on only looking at rules in the first long line. I\u2019m still amazed that\nit works.\n\nI could also talk about how controlling branchiness lets us avoid reaching the\nsame state from multiple different paths. After all, it\u2019s a graph, but\neverything I\u2019ve described talks about it like it\u2019s a tree. By carefully\ncontrolling how we extend partial solutions, we ensure we only take a single\npath to any given complete solution.\n\nBefore I got that working, I had to keep a \u201cvisited\u201d set to make sure we\ndidn\u2019t explore the same regions twice, but just maintaining that set was a big\nperformance sink.\n\n17 Discarding overlapping branches is the last macro-optimization I did and\nits behavior is very subtle. Correctly detecting when two partial solutions\noverlap took a lot of iteration. Every time I thought I had it, one random\nweird test would fail where it accidentally collapsed two branches that would\neventually diverge.\n\nThat bullet list was paid for in blood, sweat, and tears. I honestly don\u2019t\nthink I could have figured them out at all until late in the project when I\nhad a comprehensive test suite.\n\n", "frontpage": false}
