{"aid": "40222634", "title": "The future of our fight against biometric mass surveillance", "url": "https://edri.org/our-work/the-future-of-our-fight-against-biometric-mass-surveillance/", "domain": "edri.org", "votes": 2, "user": "skilled", "posted_at": "2024-05-01 13:07:57", "comments": 0, "source_title": "The future of our fight against biometric mass surveillance - European Digital Rights (EDRi)", "source_text": "The future of our fight against biometric mass surveillance - European Digital\nRights (EDRi)\n\nSkip to content\n\n  * Search the site\n  * Donate\n\n## Search\n\nHow would you best describe that thing you're looking for?\n\n  * About us\n\n    * Who we are\n    * Our Team\n    * Our Network\n    * Board\n    * Victories\n    * Funding\n    * Annual reports\n  * What we do\n\n    * Our work\n    * Advocating for better policy\n    * Decolonising digital rights\n    * Media relations\n    * Publications\n    * The future is now\n  * Take action\n\n    * Donate to EDRi\n    * EDRi visions for digital futures\n    * Stay up to date via the EDRi-gram\n    * Get involved in our campaigns\n    * Attend an event\n    * Work with us\n\n# The future of our fight against biometric mass surveillance\n\nThe final AI Act is disappointingly full of holes when it comes to bans on\ndifferent forms of biometric mass surveillance (BMS). Despite this, there are\nsome silver linings in the form of opportunities to oppose BMS in public\nspaces and to push for better protection of people\u2019s sensitive biometric data.\n\nBy EDRi \u00b7 May 1, 2024\n\nThroughout spring 2024, European Union (EU) lawmakers have been taking the\nfinal procedural steps to pass a largely disappointing new law, the EU\nArtificial Intelligence (AI) Act.\n\nThis law is expected to come into force in the summer, with one of the most\nhotly-contested parts of the law \u2013 the bans on unacceptably harmful uses of AI\n\u2013 slated to apply from the end of 2024 (six months and 20 days after the legal\ntext is officially published).\n\nThe first draft of this Act, in 2021, proposed to ban some forms of public\nfacial recognition, showing that lawmakers were already listening to the\ndemands of our Reclaim Your Face campaign. Since then, the AI Act has\ncontinued to be a focus point for our fight to stop people being treated as\nwalking barcodes in public spaces.\n\nBut after a gruelling three-year process, AI Act negotiations are coming to an\nunderwhelming end, with numerous missed opportunities to protect people\u2019s\nrights and freedoms or to uphold civic space.\n\nOne of the biggest problems we see is that the bans on different forms of\nbiometric mass surveillance, or BMS, are full of holes. BMS is the term we\u2019ve\nused as an umbrella for different methods of using people\u2019s biometric data to\nsurveil them in an untargeted or arbitrarily-targeted way \u2013 which have no\nplace in a democratic society.\n\nAt the same time, all is not lost. As we get into the nitty-gritty of the\nfinal text, and reflect on the years of hard work, we mourn the existence of\nthe dark clouds \u2013 and we celebrate the silver linings and the opportunities\nthey create to better protect people\u2019s sensitive biometric data.\n\n### Legitimising biometric mass surveillance\n\nWhilst the AI Act is supposed to ban a lot of unacceptable biometric\npractices, we\u2019ve argued since the beginning that it could instead become a\nblueprint for how to conduct BMS.\n\nAs we predicted, the final Act takes a potentially dystopian step towards\nlegalising live public facial recognition \u2013 which so far has never been\nexplicitly allowed in any EU country. The same goes for pseudo-scientific AI\n\u2018mind-reading\u2019 systems, which the AI Act shockingly allows states to use in\npolicing and border contexts. Using machines to categorise people\u2019s gender and\nother sensitive characteristics, based on how they look, is also allowed in\nseveral contexts.\n\nWe have long argued that these practices can never be compatible with our\nfundamental rights to dignity, privacy, data protection, free expression and\nnon-discrimination. By allowing them in a range of contexts, the AI Act\nlegitimises these horrifying practices.\n\n### Reasons for hope\n\nYet whilst the law falls far short of the full ban on biometric mass\nsurveillance in public spaces that we called for, it nevertheless offers\nseveral points to continue our fight in the future. To give one example, we\nhave the powerful opportunity to capitalise on the wide political will in\nsupport of our ongoing work against BMS to make sure that the AI Act\u2019s\nloopholes don\u2019t make it into national laws in EU member states.\n\nOur upcoming \u2018Legal and practical guide to fighting BMS after the AI Act\u2019 is\ntherefore intended to inform and equip those who are reflecting and re-\nfuelling for the next stage in the fight against BMS. You can already find\npart one of the guide here.\n\nThis guide will lay out where we can use the AI Act\u2019s opportunities to fight\nfor better protections for our rights to exist free from BMS in public spaces.\nThis includes charting out more than 10 specific advocacy opportunities\nincluding formal and informal spaces to influence, and highlighting the parts\nof the legal text that create space for our advocacy efforts.\n\n### A precedent for banning dangerous AI\n\nWe also remind ourselves that whilst the biometrics bans have been dangerously\nwatered down, the Act nevertheless accepts that we must ban AI systems that\nare not compatible with a democratic society. This idea has been a vital\nconcept for those of us working to protect human rights in the age of AI, and\nwe faced a lot of opposition on this point from industry and conservative\nlawmakers.\n\nThis legal and normative acceptance of the need for AI bans has the potential\nto set an important global precedent for putting the rights and freedoms of\npeople and communities ahead of the private interests of the lucrative\nsecurity and surveillance tech industry. The industry wants all technologies\nand practices to be on the table \u2013 but the AI Act shows that this is not the\nEU\u2019s way.\n\n## Ella Jakubowska\n\n### Head of Policy\n\nTwitter: @ellajakubowska1 Mastodon: @ella@eupolicy.social\n\n## Defending your rights online\n\nEuropean Digital Rights (EDRi) is an association of civil and human rights\norganisations from across Europe. We defend your rights and freedoms in the\ndigital environment.\n\n## Quick links\n\n  * Contact us\n  * About us\n  * Complaints Mechanism\n  * Media relations\n\n## Take action\n\n  * Together, we can build a people-centered, democratic society!\n  * Stay up to date via the EDRi-gram\n  * Attend an event\n\n## Follow us\n\n  * Twitter\n\n  * Mastodon\n\n  * Facebook\n\n  * LinkedIn\n\n  * YouTube\n\n  * Privacy policy\n\nContents of this website are shared under CC-BY 4.0 license (unless stated\notherwise). This means you are free to share and adapt them, as long as you\nremember to give us the appropriate credit.\n\nWebsite by Reason Digital\n\n", "frontpage": false}
