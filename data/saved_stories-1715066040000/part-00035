{"aid": "40280071", "title": "MIT Programming Languages Review 2024", "url": "https://plr.csail.mit.edu/", "domain": "csail.mit.edu", "votes": 1, "user": "matt_d", "posted_at": "2024-05-06 22:07:55", "comments": 0, "source_title": "MIT PL Review 2024", "source_text": "MIT PL Review 2024 | This is the website for the MIT PL Review 2024. We will be hosting the PL Review on May 4th, both in-person and virtually.\n\n# MIT PL Review 2024\n\nThis is the website for the MIT PL Review 2024. We will be hosting the PL\nReview on May 4th, both in-person and virtually.\n\n  * View On GitHub\n\n  * GitHub Profile\n\n# MIT Programming Languages Review\n\nThe mission of the MIT PL Review is to highlight recent developments that we\nbelieve have significant potential to shape the future direction of PL\nresearch and/or industry practice. We aim to select papers that may\nsubstantially transform the PL community and beyond, with a focus on emerging\ntrends rather than established lines of research. We favor papers whose\ncontributions are broadly accessible (and likely to be appreciated) across the\nPL community, but we do not limit the papers to those published at PL venues.\nOur selection process is not meant to provide an objective evaluation of works\nbut rather to highlight and celebrate works that resonated with our committee\nmembers.\n\nThank you for coming! We look forward to seeing you next year!\n\nRecordings of the presentations and faculty panel are now available here!\n\nYou can see last year\u2019s program here.\n\n# Schedule\n\nTime| Event  \n---|---  \n9:00-10:00| Breakfast  \n10:00-10:30| Prompting Is Programming: A Query Language for Large Language\nModels  \n10:30-11:00| Bit-Stealing Made Legal  \n11:00-11:30| Efficient Bottom-Up Synthesis for Programs with Local Variables  \n11:30-12:30| Lunch  \n12:30-1:00| Guided Equality Saturation  \n1:00-1:30| Algebraic Effects Meet Hoare Logic in Cubical Agda  \n1:30-2:00| An Extensible User Interface for Lean 4  \n2:00-2:30| Coffee Break  \n2:30-3:00| Register Tiling for Unstructured Sparsity in Neural Network\nInference  \n3:00-3:30| Better Together: Unifying Datalog and Equality Saturation  \n3:30-4:00| Instruction Scheduling for the GPU on the GPU  \n4:00-5:00| PL Faculty Panel  \n  \n# Selected Papers^*\n\n^*To avoid conflicts of interest, no MIT affiliated papers were considered.\n\n## Better Together: Unifying Datalog and Equality Saturation\n\n### Authors: Yihong Zhang, Yisu Remy Wang, Oliver Flatt, David Cao, Philip\nZucker, Eli Rosenthal, Zachary Tatlock, Max Willsey\n\n### Presentation available\n\nWe present egglog, a fixpoint reasoning system that unifies Datalog and\nequality saturation (EqSat). Like Datalog, it supports efficient incremental\nexecution, cooperating analyses, and lattice-based reasoning. Like EqSat, it\nsupports term rewriting, efficient congruence closure, and extraction of\noptimized terms. We identify two recent applications\u2013a unification-based\npointer analysis in Datalog and an EqSat-based floating-point term\nrewriter\u2013that have been hampered by features missing from Datalog but found in\nEqSat or vice-versa. We evaluate egglog by reimplementing those projects in\negglog. The resulting systems in egglog are faster, simpler, and fix bugs\nfound in the original systems.\n\nNotes from the program committee:\n\n> By unifying datalog and eqsat, this work neatly combines two long standing\n> lines of work in PL: datalog based analysis and eqSat based analysis. We\n> think that in doing so this work will become a major point of exchange\n> between these two communities in addition to non-trivially improving the\n> existing PL applications of egraphs.\n\nRead the paper here\n\n## Prompting Is Programming: A Query Language for Large Language Models\n\n### Authors: Luca Beurer-Kellner, Marc Fischer, Martin Vechev\n\n### Presentation available\n\nLarge language models have demonstrated outstanding performance on a wide\nrange of tasks such as question answering and code generation. On a high\nlevel, given an input, a language model can be used to automatically complete\nthe sequence in a statistically-likely way. Based on this, users prompt these\nmodels with language instructions or examples, to implement a variety of\ndownstream tasks. Advanced prompting methods can even imply interaction\nbetween the language model, a user, and external tools such as calculators.\nHowever, to obtain state-of-the-art performance or adapt language models for\nspecific tasks, complex task- and model-specific programs have to be\nimplemented, which may still require ad-hoc interaction. Based on this, we\npresent the novel idea of Language Model Programming (LMP). LMP generalizes\nlanguage model prompting from pure text prompts to an intuitive combination of\ntext prompting and scripting. Additionally, LMP allows constraints to be\nspecified over the language model output. This enables easy adaption to many\ntasks while abstracting language model internals and providing high-level\nsemantics. To enable LMP, we implement LMQL (short for Language Model Query\nLanguage), which leverages the constraints and control flow from an LMP prompt\nto generate an efficient inference procedure that minimizes the number of\nexpensive calls to the underlying language model. We show that LMQL can\ncapture a wide range of state-of-the-art prompting methods in an intuitive\nway, especially facilitating interactive flows that are challenging to\nimplement with existing high-level APIs. Our evaluation shows that we retain\nor increase the accuracy on several downstream tasks, while also significantly\nreducing the required amount of computation or cost in the case of pay-to-use\nAPIs (26-85% cost savings).\n\nNotes from the program committee:\n\n> The probabilistic nature of large language models makes them unreliable for\n> many tasks, hindering the realization of their full potential. Constrained\n> generation is a promising avenue to improve their reliability, and this work\n> is the first to both systematize constrained generation for large language\n> models and put forth a programming model that facilitates it. Taken to its\n> limit, this work enables confident integration of LLMs into software\n> systems.\n\nRead the paper here\n\n## Instruction Scheduling for the GPU on the GPU\n\n### Authors: Ghassan Shobaki, P\u0131nar Muyan-\u00d6z\u00e7elik, Josh Hutton, Bruce Linck,\nVladislav Malyshenko, Austin Kerbow, Ronaldo Ramirez-Ortega, Vahl Scott Gordon\n\n### Presentation available\n\nIn this paper, we show how to use the GPU to parallelize a precise instruction\nscheduling algorithm that is based on Ant Colony Optimization (ACO). ACO is a\nnature-inspired intelligent-search technique that has been used to compute\nprecise solutions to NP-hard problems in operations research (OR). Such\nintelligent-search techniques were not used in the past to solve NP-hard\ncompiler optimization problems, because they require substantially more\ncomputation than the heuristic techniques used in production compilers. In\nthis work, we show that parallelizing such a compute-intensive technique on\nthe GPU makes using it in compilation reasonably practical. The register-\npressure-aware instruction scheduling problem addressed in this work is a\nmulti-objective optimization problem that is significantly more complex than\nthe problems that were previously solved using parallel ACO on the GPU. We\ndescribe a number of techniques that we have developed to efficiently\nparallelize an ACO algorithm for solving this multi-objective optimization\nproblem on the GPU. The target processor is also a GPU. Our experimental\nevaluation shows that parallel ACO-based scheduling on the GPU runs up to 27\ntimes faster than sequential ACO-based scheduling on the CPU, and this leads\nto reducing the total compile time of the rocPRIM benchmarks by 21%. ACO-based\nscheduling improves the execution-speed of the compiled benchmarks by up to\n74% relative to AMD\u2019s production scheduler. To the best of our knowledge, our\nwork is the first successful attempt to parallelize a compiler optimization\nalgorithm on the GPU.\n\nNotes from the program committee:\n\n> This work introduces a technique for parallelizing a precise instruction\n> scheduling algorithm on the GPU based in intelligent-search techniques. We\n> believe that going forward, works that make compute-intensive compiler\n> techniques feasible like this, will be developed and continue to\n> meaningfully expand the menu of compiler optimization techniques used and\n> available.\n\nRead the paper here\n\n## Guided Equality Saturation\n\n### Authors: Thomas Koehler, Andr\u00e9s Goens, Siddharth Bhat, Tobias Grosser,\nPhil Trinder, Michel Steuwer\n\n### Presentation available\n\nRewriting is a principled term transformation technique with uses across\ntheorem proving and compilation. In theorem proving, each rewrite is a proof\nstep; in compilation, rewrites optimize a program term. While developing\nrewrite sequences manually is possible, this process does not scale to larger\nrewrite sequences. Automated rewriting techniques, like greedy simplification\nor equality saturation, work well without requiring human input. Yet, they do\nnot scale to large search spaces, limiting the complexity of tasks where\nautomated rewriting is effective, and meaning that just a small increase in\nterm size or rewrite length may result in failure. This paper proposes a semi-\nautomatic rewriting technique as a means to scale rewriting by allowing human\ninsight at key decision points. Specifically, we propose guided equality\nsaturation that embraces human guidance when fully automated equality\nsaturation does not scale. The rewriting is split into two simpler automatic\nequality saturation steps: from the original term to a human-provided\nintermediate guide, and from the guide to the target. Complex rewriting tasks\nmay require multiple guides, resulting in a sequence of equality saturation\nsteps. A guide can be a complete term, or a sketch containing undefined\nelements that are instantiated by the equality saturation search. Such\nsketches may be far more concise than complete terms. We demonstrate the\ngenerality and effectiveness of guided equality saturation using two case\nstudies. First, we integrate guided equality saturation in the Lean 4 proof\nassistant. Proofs are written in the style of textbook proof sketches, as a\nseries of calculations omitting details and skipping steps. These proofs\nconclude in less than a second instead of minutes when compared to unguided\nequality saturation, and can find complex proofs that previously had to be\ndone manually. Second, in the compiler of the Rise array language, where\nunguided equality saturation fails to perform optimizations within an hour and\nusing 60 GB of memory, guided equality saturation performs the same\noptimizations with at most 3 guides, within seconds using less than 1 GB\nmemory.\n\nNotes from the program committee:\n\n> This paper introduces guided equality saturation, a semi-automatic rewriting\n> technique that enables equality saturation to scale by allowing human\n> insight to guide the process at key points. The authors demonstrate its\n> effectiveness through case studies in theorem proving and program\n> optimization, presenting a promising direction for future research that\n> combines human intuition with the power of automation.\n\nRead the paper here\n\n## An Extensible User Interface for Lean 4\n\n### Authors: Wojciech Nawrocki, Edward W. Ayers, Gabriel Ebner\n\n### Presentation available\n\nContemporary proof assistants rely on complex automation and process libraries\nwith millions of lines of code. At these scales, understanding the emergent\ninteractions between components can be a serious challenge. One way of\nmanaging complexity, long established in informal practice, is through varying\nexternal representations. For instance, algebraic notation facilitates term-\nbased reasoning whereas geometric diagrams invoke spatial intuition. Objects\nviewed one way become much simpler than when viewed differently. In contrast,\nmodern general-purpose ITP systems usually only support limited, textual\nrepresentations. Treating this as a problem of human-computer interaction, we\naim to demonstrate that presentations - UI elements that store references to\nthe objects they are displaying - are a fruitful way of thinking about ITP\ninterface design. They allow us to make headway on two fronts - introspection\nof prover internals and support for diagrammatic reasoning. To this end we\nhave built an extensible user interface for the Lean 4 prover with an\nassociated ProofWidgets 4 library of presentation-based UI components. We\ndemonstrate the system with several examples including type information\npopups, structured traces, contextual suggestions, a display for algebraic\nreasoning, and visualizations of red-black trees. Our interface is already\npart of the core Lean distribution.\n\nNotes from the program committee:\n\n> This paper illustrates an important design space in the development of\n> interactive theorem provers: interactive visual components. Especially as\n> mathematicians begin formalizing more of their work, frameworks that allow\n> users to percieve, interact with, and express their proofs visually may\n> become a critical feature in improving the ITP experience to or beyond the\n> level of paper proofs.\n\nRead the paper here\n\n## Register Tiling for Unstructured Sparsity in Neural Network Inference\n\n### Authors: Lucas Wilkinson, Kazem Cheshmi, Maryam Mehri Dehnavi\n\n### Presentation available\n\nUnstructured sparse neural networks are an important class of machine learning\n(ML) models, as they compact model size and reduce floating point operations.\nThe execution time of these models is frequently dominated by the sparse\nmatrix multiplication (SpMM) kernel, C=A\u00d7 B, where A is a sparse matrix, and B\nand C are dense matrices. The unstructured sparsity pattern of matrices in\npruned machine learning models along with their sparsity ratio has rendered\nuseless the large class of libraries and systems that optimize sparse matrix\nmultiplications. Reusing registers is particularly difficult because accesses\nto memory locations should be known statically. This paper proposes Sparse\nRegister Tiling, a new technique composed of an unroll-and-sparse-jam\ntransformation followed by data compression that is specifically tailored to\nsparsity patterns in ML matrices. Unroll-and-sparse-jam uses sparsity\ninformation to jam the code while improving register reuse. Sparse register\ntiling is evaluated across 2396 weight matrices from transformer and\nconvolutional models with a sparsity range of 60-95% and provides an average\nspeedup of 1.72\u00d7 and 2.65\u00d7 over MKL SpMM and dense matrix multiplication,\nrespectively, on a multicore CPU processor. It also provides an end-to-end\nspeedup of 2.12\u00d7 for MobileNetV1 with 70% sparsity on an ARM processor\ncommonly used in edge devices.\n\nNotes from the program committee:\n\n> This paper presents an innovative technique designed to improve hardware\n> utilization for sparse programs. The authors illustrate how this method\n> boosts performance by creating specialized code that maximizes register\n> reuse, customized to fit the sparsity pattern. Looking ahead, we believe\n> this approach holds broad applicability beyond SpMM on CPU, potentially\n> accelerating various sparse applications in the future.\n\nRead the paper here\n\n## Bit-Stealing Made Legal\n\n### Authors: Tha\u00efs Baudon, Gabriel Radanne, Laure Gonnord\n\n### Presentation available\n\nInitially present only in functional languages such as OCaml and Haskell,\nAlgebraic Data Types (ADTs) have now become pervasive in mainstream languages,\nproviding nice data abstractions and an elegant way to express functions\nthrough pattern matching. Unfortunately, ADTs remain seldom used in low-level\nprogramming. One reason is that their increased convenience comes at the cost\nof abstracting away the exact memory layout of values. Even Rust, which tries\nto optimize data layout, severely limits control over memory representation.\nIn this article, we present a new approach to specify the data layout of rich\ndata types based on a dual view: a source type, providing a high-level\ndescription available in the rest of the code, along with a memory type,\nproviding full control over the memory layout. This dual view allows for\nbetter reasoning about memory layout, both for correctness, with dedicated\nvalidity criteria linking the two views, and for optimizations that manipulate\nthe memory view. We then provide algorithms to compile constructors and\ndestructors, including pattern matching, to their low-level memory\nrepresentation. We prove our compilation algorithms correct, implement them in\na tool called ribbit that compiles to LLVM IR, and show some early\nexperimental results.\n\nNotes from the program committee:\n\n> This work introduces a type system and a principled, compilation technique\n> for expressing storage format choices and optimizations for algebraic\n> datatypes in a high-level language. This not only improves efficiency of the\n> compiled functional programs, but also provides a degree of control and\n> expressivity that is often only found and implemented ad-hoc in low-level,\n> systems-oriented language. We believe this work and any future works like it\n> are invaluable in expanding capabilities of functional programming by\n> improving the performance capabilities and expressivity.\n\nRead the paper here\n\n## Algebraic Effects Meet Hoare Logic in Cubical Agda\n\n### Authors: Donnacha Ois\u00edn Kidney, Zhixuan Yang, Nicolas Wu\n\n### Presentation available\n\nThis paper presents a novel formalisation of algebraic effects with equations\nin Cubical Agda. Unlike previous work in the literature that employed setoids\nto deal with equations, the library presented here uses quotient types to\nfaithfully encode the type of terms quotiented by laws. Apart from tools for\nequational reasoning, the library also provides an effect-generic Hoare logic\nfor algebraic effects, which enables reasoning about effectful programs in\nterms of their pre- and post- conditions. A particularly novel aspect is that\nequational reasoning and Hoare-style reasoning are related by an elimination\nprinciple of Hoare logic.\n\nNotes from the program committee:\n\n> This work proves a correspondence between two major approaches to handling\n> effects. It does so in a generic way by operating on a theory of algebraic\n> effects, formalized as syntax quotiented by equations. We believe that this\n> work opens up opportunities to combine lessons, techniques, and advantages\n> from both styles of semantics.\n\nRead the paper here\n\n## Efficient Bottom-Up Synthesis for Programs with Local Variables\n\n### Authors: Xiang Li, Xiangyu Zhou, Rui Dong, Yihong Zhang, Xinyu Wang\n\n### Presentation available\n\nWe propose a new synthesis algorithm that can efficiently search programs with\nlocal variables (e.g., those introduced by lambdas). Prior bottom-up synthesis\nalgorithms are not able to evaluate programs with free local variables, and\ntherefore cannot effectively reduce the search space of such programs (e.g.,\nusing standard observational equivalence reduction techniques), making\nsynthesis slow. Our algorithm can reduce the space of programs with local\nvariables. The key idea, dubbed lifted interpretation, is to lift up the\nprogram interpretation process, from evaluating one program at a time to\nsimultaneously evaluating all programs from a grammar. Lifted interpretation\nprovides a mechanism to systematically enumerate all binding contexts for\nlocal variables, thereby enabling us to evaluate and reduce the space of\nprograms with local variables. Our ideas are instantiated in the domain of web\nautomation. The resulting tool, Arborist, can automate a significantly broader\nrange of challenging tasks more efficiently than state-of-the-art techniques\nincluding WebRobot and Helena.\n\nNotes from the program committee:\n\n> This work introduces a technique for synthesizing terms with local\n> variables, such as lambdas and loops, in a bottom-up fashion based on finite\n> tree automata by generalizing the program synthesis concept of observational\n> equivalence. We believe that this work will greatly expand the domain of\n> language features that bottom-up synthesis can support.\n\nRead the paper here\n\n# PL Review Program Committee\n\n  * Amanda Liu (Conference Chair)\n  * Dustin Jamner (Program Chair)\n  * Jaeyeon Won\n  * Jesse Michel\n  * Logan Weber (AV Chair)\n  * Maddy Bowers\n  * Teodoro Collin\n  * William Brandon\n  * Yuka Ikarashi\n\nHosted on GitHub Pages using the Dinky theme\n\n", "frontpage": false}
