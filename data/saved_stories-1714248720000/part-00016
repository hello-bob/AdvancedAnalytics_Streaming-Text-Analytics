{"aid": "40179877", "title": "I Witnessed the Future of AI, and It's a Broken Toy", "url": "https://www.theatlantic.com/technology/archive/2024/04/rabbit-r1-impressions/678226/", "domain": "theatlantic.com", "votes": 1, "user": "fortran77", "posted_at": "2024-04-27 13:40:46", "comments": 0, "source_title": "I Witnessed the Future of AI, and It\u2019s a Broken Toy", "source_text": "I Witnessed the Future of AI, and It\u2019s a Broken Toy - The Atlantic\n\n## More From Artificial Intelligence\n\n## More From Artificial Intelligence\n\nExplore This Series\n\n  * ### I Witnessed the Future of AI, and It\u2019s a Broken Toy\n\nCaroline Mimbs Nyce\n\n  * ### Would Limitlessness Make Us Better Writers?\n\nRachel Khong\n\n  * ### It\u2019s the End of the Web as We Know It\n\nJudith DonathBruce Schneier\n\n  * ### The AI Revolution Is Crushing Thousands of Languages\n\nMatteo Wong\n\nTechnology\n\n# I Witnessed the Future of AI, and It\u2019s a Broken Toy\n\nThe Rabbit R1 is a device defined by empty promises.\n\nBy Caroline Mimbs Nyce\n\nIllustration by The Atlantic. Sources: Rabbit; Getty.\n\nApril 27, 2024, 6 AM ET\n\nThis story was supposed to have a different beginning. You were supposed to\nhear about how, earlier this week, I attended a splashy launch party for a new\nAI gadget\u2014the Rabbit R1\u2014in New York City, and then, standing on a windy curb\noutside the venue, pressed a button on the device to summon an Uber home.\nInstead, after maybe an hour of getting it set up and fidgeting with it, the\nconnection failed.\n\nThe R1 is a bright-orange chunk of a device, with a camera, a mic, and a small\nscreen. Press and hold its single button, ask it a question or give it a\ncommand using your voice, and the cute bouncing rabbit on screen will perk up\nits ears, then talk back to you. It\u2019s theoretically like communicating with\nChatGPT through a walkie-talkie. You could ask it to identify a given flower\nthrough its camera or play a song based on half-remembered lyrics; you could\nask it for an Uber, but it might get hung up on the last step and leave you\nstranded in Queens.\n\nWhen I finally got back to my hotel room, I turned on the R1\u2019s camera and held\nup a cold slice of pizza. \u201cWhat am I looking at?\u201d I asked. \u201cYou are looking at\na slice of pizza,\u201d the voice told me. (Correct!) \u201cIt looks appetizing and\nfreshly baked.\u201d (Well, no.) I decided to try something else. \u201cWhat are top 10\n...\u201d I stumbled, letting go of the button. I tried again: \u201cWhat are the top 10\nbest use cases for AI for a normal person?\u201d The device, perhaps confused by\nour previous interaction, started listing out pizza toppings beginning with\nthe No. 2. \u201c2. Sausage. 3. Mushrooms. 4. Extra Cheese.\u201d\n\nUntil now, consumer AI has largely been defined by software: chatbots such as\nChatGPT or the iPhone\u2019s souped-up autocorrect. Now we are experiencing a\nthingification: Companies are launching and manufacturing actual bits of metal\nand plastic that are entirely dedicated to AI features. These devices are\ndistinguished from previous AI gadgets, such as the Amazon Echo, in that they\nincorporate the more advanced generative-AI technology that has recently been\nin vogue, allowing users more natural interactions. There are pins and\npendants and a whole new round of smart glasses.\n\nRead: Alexa, should we trust you?\n\nYet for all its promise, this new era is not going very well. Take Humane, a\nRabbit competitor that launched a wearable \u201cAI Pin\u201d earlier this month. That\ndevice has been positioned as a smartphone replacement, with a price to match:\nIt costs $699 and requires a $24 monthly subscription fee. Reviewers\nbrutalized the pin, saying it is slow, overheats, and struggles to answer\nbasic queries. \u201cI\u2019m hard-pressed to name a single thing it\u2019s genuinely good\nat,\u201d The Verge wrote.\n\nBy comparison, the R1 is satisfyingly small in its ambition and (relatively)\naffordable in its price ($199, no subscription). The device itself is fun and\nretro-chic: Jesse Lyu, Rabbit\u2019s founder and CEO, reportedly bought every\nmember of his team a Tamagotchi for inspiration. And, in fairness, the R1 does\nsome interesting things. Onstage, Lyu showed how the device can interpret a\nhandwritten table and convert it into a working digital spreadsheet. It\nmanaged to speak a summary of a handwritten page when I asked, though only\nwith about 65 percent accuracy. I was able to use the gadget to order an acai\nbowl on DoorDash, although it couldn\u2019t handle any customizations. (I wanted\npeanut butter.) And I never got Uber to work. (Though at one point, the device\ntold me the request had failed when it in fact hadn\u2019t, leaving me on the hook\nfor a $9 ride I didn\u2019t even take.)\n\nOne of the big selling points of the R1 is that it supposedly runs something\ncalled a large action model, or LAM\u2014a spin on the phrase large language model,\nwhich is the technology powering recent chatbots. Whereas ChatGPT can answer\nquestions and draft you a mediocre essay, the R1 can, in theory, complete\nactions that you might take on different apps (Venmo-ing your friend $20, for\nexample). Rabbit has said the device will be able to learn any app, if you\nteach it. Lyu compared the technology to a Tesla: When on autopilot, a Tesla\ncar can in theory recognize a stop sign not because engineers tell it how a\nstop sign looks but because it has been trained on countless hours of footage\nto recognize the sign\u2019s physical attributes. Likewise, R1 will be able to\naccomplish tasks on your phone without having to be taught each app.\n\nThe problem is, none of this is actually real. At least not yet. As with so\nmany AI products, the R1 is fueled more by hype than by a persuasive use case.\n(So many of its functions could, after all, be done on a smartphone.) Back in\nFebruary, Lyu said the Rabbit was training its model on 800 apps. This week,\nit launched with the ability to use just four: Spotify, DoorDash, Uber, and\nMidjourney (a popular AI art generator). The company says LAM is in \u201cvery\nearly stages.\u201d\n\nRead: Phones will never be fun again\n\nOnstage before an audience of reporters and Rabbit fanboys on Tuesday night,\nLyu seemed nervous at times, at one point encouraging people to laugh in order\nto ease his nerves. Prior to the event, a user had posted on GitHub accusing\nRabbit of misrepresenting its technology. \u201cFor those with a technical\nbackground, it\u2019s painfully clear that there\u2019s no artificial intelligence or\nlarge action model in sight,\u201d the anonymous post, which has since been\ndeleted, read. On X, Lyu characterized the post as \u201call false claims.\u201d Lyu\npromised to fix any bugs that might crop up in R1 devices. Before demoing\nDoorDash onstage, he admitted that the feature doesn\u2019t yet work as fast as\nthey\u2019d like it to: \u201cBut I want to show you, and I want to be frank with you\nguys.\u201d\n\nYet Lyu also breathlessly announced a number of new initiatives, including a\nhigh-concept system that would allow people to someday merge the physical and\nthe digital, so people could point at various smart items in their home and\ncontrol them through Rabbit\u2019s AI. (Never mind that the R1 has launched without\nmany of its promised features.) Toward the end of the presentation, the words\nBe Humble appeared on the giant screen behind him. \u201cWe are a really, really\nhumble team,\u201d Lyu told the crowd. Those words were still displayed when, a few\nmoments later, the curtains on either side of the stage dramatically dropped\nto reveal conveyor belts loaded with boxes of R1s. Music started blasting, and\npeople started lining up to snatch theirs.\n\nThe R1 is a reminder of the disconnect, for better and for worse, between a\nSilicon Valley culture that often prioritizes speed over quality and high\nconsumer expectations about the products they use. And to be fair,\nexpectations are high at least in part because of the extraordinary products\nthat have emerged from that same competitive and iterative culture over the\nyears.\n\nAs the party wound down, news of the first bug arrived: There was no way to\nchange the time zone on the devices, many of which were programmed by default\nto the West Coast. Turns out the future is stuck three hours behind.\n\nCaroline Mimbs Nyce is a staff writer at The Atlantic.\n\n", "frontpage": false}
