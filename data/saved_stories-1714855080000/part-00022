{"aid": "40257506", "title": "Synthesizing Martian Speech", "url": "https://dukope.itch.io/mars-after-midnight/devlog/653705/synthesizing-martian-speech", "domain": "dukope.itch.io", "votes": 1, "user": "philips", "posted_at": "2024-05-04 13:27:58", "comments": 0, "source_title": "Synthesizing Martian Speech - Mars After Midnight by dukope", "source_text": "Synthesizing Martian Speech - Mars After Midnight by dukope\n\n  * View all by dukopedukope\n  * Follow dukopeFollowFollowing dukopeFollowing\n  * Add To CollectionCollection\n  * Devlog\n\n# Mars After Midnight\n\n# Synthesizing Martian Speech\n\nMars After Midnight \u00bb Devlog\n\nLike54\n\n113 days ago by dukope (@dukope)\n\nShare this post:\n\nShare on TwitterShare on Facebook\n\nOver the course of this project, I've made three separate attempts to generate\nsynthesized speech for the martians.\n\n## Classic Speech Synthesis\n\nBefore there were neural networks and machine learnings to do all our computer\ntalking, speech was generally synthesized by modeling the vocal cords and\nresonant cavities of the mouth. There's decades of research into this and\nprobably the most well-known classic example is SAM the Software Automatic\nMouth from the early 80's.\n\nEven though I love the way SAM sounds, and just look at him, it wasn't quite\nwhat I had in mind for the martians in this game. Something less familiar\nwould be nice for a start. Also, speech synths in this form are finely honed\nmasterpieces of software design and who's got time for that.\n\n# First Attempt: Amateur Hour\n\nSo let's tumble down a rabbit hole and roll our own speech synth system. Start\nby blasting some vowels into a microphone.\n\nBeautiful. Now as a first stab at manipulating these sounds into something\nmore interesting, try crossfading between them to get an AHYEEYAH sound.\n\nWhoops it doesn't work. Here's what it should sound like.\n\nThe human voice doesn't crossfade. Vowels are blended by adjusting the jaw,\nlips, tongue, etc. That sounds hard to simulate, surely there's a shortcut.\n\nMaybe the problem is that we're working with raw samples in the time domain.\nLet's switch to the frequency domain and try interpolating there. We want this\nto work on portable hardware so first break the audio clips down to a limited\nset of important frequencies.\n\nWaveform, spectrum, and detected peaks for 'AH' clip\n\nSame thing for the 'EE' clip\n\nI put together some numpy/scipy python code to do this part. The result is a\nset of frequencies and amplitudes that can be used to reconstruct the sound\nwith sine waves. Baby's first MP3. Maybe there's something interesting we can\ndo once everything is driven by sine waves instead of individual samples.\n\nOriginal 'AH' recording (top) and sinewave-reconstructed version (bottom)\n\nSame thing for the 'EE' clip\n\nThe result:\n\nSounds basically right, if a little muffled. I can hear the martians already.\nNow try blending between the reconstructed clips by interpolating the sine\nfrequencies. This should hopefully be an improvement on crossfading the\nsamples. Waveform (top) & spectrogram (bottom):\n\nNope! That makes a good siren but it doesn't sound like a voice. The peak\nfrequencies can be pretty far apart for each vowel and there's a \"whipping\"\neffect when interpolating between them. I suspect the spectrum is just too\nsparse and it would need a lot more sine waves to avoid sounding artificial.\nThis rabbit hole sucks. With basically no DSP or speech theory experience this\nwas a lost cause and after a fair bit of flailing I put the whole thing down\nand moved on to other non-speech stuff.\n\n# Second Attempt: Audio Clips\n\nAlmost a year later, I came back to the speech synthesis task. Having\nforgotten most of the first try my plan this time was to go even simpler. Why\nsynthesize anything at all? Just string together a bunch of audio clips and\ncall it a day.\n\nI recorded myself making some vocalizations, mixed up their speed, and played\nthem back. There should be no surprise at how this sounds.\n\nOk. Adding alien-sounding clicks and pops is trivial. With the right source\nclips and offline processing, throw in a simple runtime vocoder, I could\nprobably get some decent results.\n\nWell, maybe. I didn't give it much chance. This technique just wasn't grabbing\nme. One for being too simple and two for having so few limitations. There are\ninfinite ways to prepare and process audio clips for sequential playback. I\nneed constraints, the more the better.\n\nStrike two. I put it away again for another year.\n\n# Third Attempt: Surrender\n\nThis was finally the point for a more solid think about what I really wanted\nfrom the speech synthesizer. No more experimenting with carefree wonder. What\nshould the martians sound like?\n\nIt came down to three things:\n\n  1. Be voice-like.\n  2. Be easy to control/vary.\n  3. Be funny.\n\nIf, like me, you've ever crossed paths with The Talking Moose on a classic Mac\nthen you know all three requirements are handily met by a traditional speech\nsynthesizer. The Moose is based on MacinTalk which as far as I can tell is\nimplemented similarly to SAM.\n\nThe Talking Moose. All we ever wanted from computer speech.\n\nI trashed all my previous code and researched the details of how these synths\nactually work. The seminal model here is the Klatt speech synthesizer. Dennis\nKlatt worked out a system of cascading and parallel filters applied to the\nfundamental waveform + noise, and all the complicated articulations necessary\nto sound like human voice. Back in 1980.\n\nThe best way I found to see all this in action is through Christian\nd'Heureuse's KlattSyn and the epseak-ng github repo.\n\nBrief summary. The human vocal system has cavities that amplify & resonate the\nvocal cords' vibrations at certain frequency bands. These bands are called\nformants and they change based on the shape of the mouth, tongue, lips,\npalette, etc. Each vowel sound has a different set of formants.\n\nFormants are different from the peaks I was detecting in my first try in that\nthey're independent of the fundamental pitch of the voice, and they have a\nbandwidth. To get the formant frequencies and bandwidths I ditched my custom\npython code and switched to using Praat, which is laser focused on this exact\ntask.\n\nPraat-detected formants in 'AH' clip\n\nNote that these are not marking sharp spikes as much as broad hilltops in the\nspectrum. It's somewhat surprising (to me) that these vowel formant\nfrequencies don't vary much from person to person. From Synthesizing static\nvowels and dynamic sounds:\n\nMeasured formants for random male subject, closely matching my voice\n\nWith this formant model, I wrote C code for synthesizing vowels using a\nsawtooth wave passed through a series of resonating filters. I'm familiar with\nusing these kinds of filters in hardware and DAW synths. What do they look\nlike in actual code? Basically just a weighted sum of the current sample and\nprevious outputs. The weights are calculated from your desired filter\nfrequency, resonance, and bandwidth. MusicDSP.org was a great resource when\nworking on this.\n\nAfter days of stumbling and tweaking, the ungarnished result sounds fairly\nstandard.\n\nPretty much exacly like SAM and glad for it. Nothing like a desperate third\nattempt to slide the goalposts right up. The AH-EE-AH blend that didn't work\nbefore sounds fine now when interpolating filter frequencies:\n\nThe next step was to integrate a noise source to synthesize the 't', 'ch',\n's', 'k', and other non-voiced sounds. Unlike with the vowels, these use a\nseparate parallel filter bank. I made some good progress here before realizing\nthat (A) this part is much trickier since it requires careful modulation to\nsound right and (B) the end result would be better sounding human speech,\nwhich I wasn't really after.\n\nSo I stopped there and decided make the vowels slightly more interesting, with\nenough variability to match the wide gamut of procedurally-generated faces.\n\n# Vowel Synth Features\n\nThe final vowel synth has parameters for overall speed, input waveform,\nfundamental pitch (including sub-oscillator, vibrato, and randomized LFO), and\nformant frequencies. A set of these parameters defines the basic sound of a\nvoice.\n\nVowel synth block diagram\n\nAlong with the A, E, I, O, and U vowel formant sets, I also added M and R\nsupport. The Klatt model has special handling for these nasally sounds that\nintegrates with the normal vowels' resonators.\n\nOne trick I found to get slightly less muffled output was to fix the two\nhighest-frequency formants at 4kHz and 6kHz. This is essentially a HF boost\nand adds a noticeable crispness when running at the synth's relatively low\n11kHz samplerate.\n\nTo get usable formant data, I process audio clips of me saying the vowels with\nPraat, then pass that to a python script that cleans up the results and writes\nthem out as C struct data.\n\nFor controlling the synth, I designed a simple command string format:\n\n\"m~ee_e/i+uu|u<<+a--u\"\n\nEach aeioumr character activates a formant set and the rest are inline commands for modulation. ~ & _ enable or disable vibrato, / & | denote pauses, + & \\- add pitch changes in semitones. There's a default vowel token duration which can be sped up or slowed down with > & <. Pitch and speed commands can be stacked to go higher or lower.\n\n\"a+aa+aa+++~aaaa\"\n\nWhen processing a command string, the synth first breaks it into words at / &\n|, then sets up envelopes to blend between pitches, volumes, speeds, and\nformants.\n\nA few more examples of \"m~ee_e/i+uu|u<<+a--u\" with randomized voice\nproperties:\n\nAn interesting discovery is that creating intelligible words is still possible\nwith this limited vowel-only synth. Quick starts and stops are almost enough\nfor faking a few consonants. The brain fills in the rest I guess.\n\n\"om-i/i~uaa\" (Konnichiwa)\n\n\"ao~o/+aa-r/<++i-u-u\" (How are you?)\n\n\"++<ai/-emm|++<o/-ei\" (I am okay)\n\n# Fixing Floats\n\nEven in its simplified vowel-only form, the synth still has a fair bit of\ncomplex C code. I wrote everything initially using floating point math, as a\nsane person would. Unfortunately the performance requirements to run at 11kHz\nwere too much for the hardware, mostly because of the floats. Once it was\nworking okay I refactored the inner loops to use fixed point math.\n\nTesting on the arm64 Playdate hardware I found that int64 arithmetic is the\nfastest, then int32, then float. To keep the memory cache unstressed I settled\non int32 with S.15.16 fixed point format. Ideally, you'd want more bits after\nthe decimal when dealing with mostly -1.0 -> 1.0 audio samples. In this case\nthe range needed to also cover several multiples of the sample rate so with a\nunified format I couldn't slide the decimal point very far left.\n\nRewriting the floating point math to fixed point was mostly straightforward,\nwith special care to not overflow the resonators. A pure engineering task like\nthis is a nice break sometimes.\n\nSpeaking of performance, one might ask how SAM and MacinTalk could run\nperfectly fine on 40-year-old computers. Based on Tyomitch's reverse\nengineering it seems that, besides lots of clever optimisations, they summed\npre-baked formant waveforms instead of running the math-heavy filter code.\nSounds a bit like my first attempt up there.\n\n# Flapping Lips\n\nOnce I was happy with the audio output the next step was to hook it into the\ngame's visuals. Knowing I'd want the martians to eventually talk, I've been\ndrawing three frames of animation for each mouth since the beginning:\n\n  1. Lips closed\n  2. Open \"Ah\" sound\n  3. Open \"Oh\" sound\n\nYou'd want more frames if you had the resources to draw them. I'm settling for\nthe bare minimum here to save some work.\n\nA few mouths and their speech animation frames\n\nWhen generating a martian face, the mouth frames are tucked away in the image\natlas and can be swapped in at runtime.\n\nMartian image atlas with mouth frames in the bottom left there\n\nIn-game, the vowel synth keeps track of which formant sets are used in a word,\nand the game logic can query which one is currently playing. The full voiced\nlist of aeioumr is reduced down to aom for the mouth frame selection. Add a\nlittle shake and bob's your uncle.\n\n# Time Sink\n\nI spent too long working on all of this, really. Anyone paying for 'talking\nmartians' would have a few questions. Luckily, it's just me using up my own\nenergy here, and spending ages learning about things is 90% of why I make\ngames.\n\nSTILL, wouldn't it be nice if the speech synth could be used for more than a\nfew martian dialog bleeps and bloops. Can I take this minor side feature and\nexpand it into something more important, papering over the embarassingly long\ndev time to make it all look intentional?\n\nWell it's hard to turn a vowel-only speech synth into a core feature in an\nalready-weird game like this but that'll hardly stop me from trying. And hey I\ngot an idea while implementing the speech bubble animations.\n\n# Speech Bubbling\n\nIn-game speech bubble\n\nThis was my plan for the talking martians. They'd blurt out some hilarious-\nsounding unintelligible speech and a helpful dialog bubble would show a single\nglyph translation.\n\nHow is a single glyph enough? I don't know, I hadn't figured that part out. It\nshould be possible to reduce the conversation surface enough to use emotes or\nother solitary symbols. I just know that I didn't want to put straight text\ntranslations in the bubble and adding some ridiculous restriction here might\nbe fruitful.\n\nThe taste of the fruit is debatable but what I've ended up doing is adding a\nwhole other system to the game called the BLAB-O-DEX.\n\n# The BLAB-O-DEX\n\nA handy guide\n\nWhen martians say something translatable, their dialog bubble shows only a\nreference number.\n\nSpeech bubble showing BLAB-O-DEX reference number\n\nThis number is an index into the BLAB-O-DEX, accessable from the Playdate's\nin-game system menu. Players can refer to the translations here after they've\nheard the phrase at least once. Unheard entries are present in the list as a\nblank dash.\n\nOminous\n\nThe thought is that players will hear some of these phrases enough times to\nrecognize either the speech itself or the reference number.\n\nTreating dialog as a trackable collectible like this has the potential to\nsolve several design problems I've been facing. For one, how to make the\nbackground street scene more engaging.\n\nLittle conversation going on back there\n\nI have a few reservations about the BLAB-O-DEX at the moment so we'll see how\nit actually plays out. The speech synth is fine though for sure.\n\n### Mars After Midnight\n\nOn Mars, after midnight, at the off-colony community support center. For\nPlaydate.\n\nAdd Game To Collection\n\nStatus| In development  \n---|---  \nAuthor| dukope  \n  \n### More posts\n\n  * Face Generator Updates\n\nMay 19, 2023\n\n  * Sound Design\n\nApr 04, 2023\n\n  * Gameplay Loop\n\nMar 03, 2023\n\n  * Photoshop Exporting & Scenegraphing\n\nNov 10, 2022\n\n  * Typography\n\nOct 18, 2022\n\n  * Working in One Bit\n\nAug 21, 2021\n\n  * Making Martian Faces\n\nJun 18, 2021\n\n  * Mars After Midnight\n\nJun 08, 2021\n\nSee all posts\n\n## Comments\n\nLog in with itch.io to leave a comment.\n\norangedrink65 days ago(+3)\n\ncongrats on the release date trailer!\n\n(in case anyone missed it 13:24)\n\nReply\n\nlittle curry bread82 days ago\n\nvery cool, love to see some C code. #c-langgang\n\nReply\n\nwhiskas_fanatic83 days ago (1 edit)\n\nThanks for these updates, can't wait for final game! I just wanted to add\nanother vote for the idea to use Galactic Alphabet for speech bubbles. It\nwould look more.. dunno, appropriate I guess, because the numbers are looking\nmore like placeholder. And blab-o-dex where you decipher those symbols will\nlook more organic in this world, IMO.\n\nReply\n\nDarkSeed107 days ago(+3)\n\nWhen Lukas does something, it's always interesting, original and amazing.\nCan't wait! :)\n\nReply\n\nSpelpojken111 days ago\n\nSoooo cool\n\nReply\n\nAndy D111 days ago\n\nI love these peeks behind the curtain. And I'm also grateful that you're (I\nhope!) not setting the price of this game based on the millions of hours\nyou've spent making it. :)\n\nReply\n\nWally Hackenslacker112 days ago(+3)\n\nThis series has been the most fascinating dev diary of all time, imho! I\nreally want to get a Playdate just for this one game!\n\nReply\n\nCitrus Architect112 days ago(+1)\n\nThis was a really fascinating read, thank you for detailing your process! I am\na sound designer by trade - I edit voices every single day but I don't know\nwhere I would even start when it comes to the synthesizing the human voice.\nI'm no programmer but I think you ultimately ended up in a really cool spot.\nIt's amazing how much range you get even without consonants. Well done!\n\nReply\n\ndogmatagram112 days ago(+2)\n\nThis was an excellent and fascinating read!\n\nI love how you outlined your naive approaches to speech synthesis and\nwhere/why they didn't work.\n\nReply\n\nyeuk0112 days ago(+1)\n\nI think I love you. Many many thanks for sharing this. I always struggled with\nsound implementation and this adds so interesting conclusions! I admire your\nhanger for new knowledge and, in fact, yours helped mine here.\n\nKeep rocking, all I wish for now is having MAM in my Playdate.\n\nReply\n\nSanta Ragione112 days ago(+2)\n\nI'm honestly speechless (ha!) thank you for sharing the process.\n\nReply\n\nStephanRewind113 days ago(+6)\n\nJust when I thought the whole concept couldn\u2019t become any cooler, in a vintage\n8-bit kind of way, now the martians babble like adorable Speak and Spells . So\nappropriate. You\u2019re killing me.\n\nReply\n\nMrInconsistent113 days ago(+2)\n\nDo you reckon replacing the numbers with wacky martian symbols might be cool?\nI like the idea of translating things, but seeing martians talk saying things\nlike \"2!\" \"3.\" \"1\" is a bit weird, if not funny in its own way\n\nReply\n\ndukope113 days ago(+3)\n\nI tried this first, but found it really hard to recognize/remember [random-\nglyph] as \"hello\". Better if it's readable, even if unrelated, to make looking\nit up in the blab-o-dex easier. I may add a letter to separate conversations,\nso \"H2\" instead of \"31\". Still figuring it out.\n\nReply\n\ntheeie113 days ago (3 edits)\n\nYou could do a bit of both and make a glyph numbering system.\n\nSomething like the Mayan numeral system, but a Marsian numeral system.\n\nReply\n\nDimitriBarronmore112 days ago(+2)\n\nI'd consider trying it with short nonsense phrases written in the Standard\nGalactic Alphabet, of Keen and Minecraft fame. It was designed as a genuine\nfont with the intention of players being able to legitimately read it, so it\nmight work better, and it's already got a storied history of being used on\nmars.\n\nReply\n\nneilka107 days ago (1 edit)\n\nYou may have played it already but Chants of Sennaar is a (very good) recent\ngame that tackled the same kinds of problems\n\nReply\n\ncliff24113 days ago(+1)\n\nGreat job!\n\nReply\n\nNew Beings113 days ago(+4)\n\nThis is an amazing write up! \ud83d\udc96\n\nI actually made a game inspired by some of your stuff that is about\ntranslating alien speech audio. I actually thought this game might be about\nthat when you first posted it! It'd be really wild to do something like that\nmore proceedurally.\n\nReply\n\ndukope113 days ago(+2)\n\nThanks! Just played FCD, love it <3\n\nReply\n\nNew Beings113 days ago\n\nYooooooo, thanks!\n\nReply\n\nRibbon \ud83c\udf80113 days ago(+1)\n\nSo cool!! \ud83d\udc7d\ud83d\udcac\n\nReply\n\nitch.io\u00b7View all by dukope\u00b7Report\n\nMars After Midnight \u203a Blog\n\n", "frontpage": false}
