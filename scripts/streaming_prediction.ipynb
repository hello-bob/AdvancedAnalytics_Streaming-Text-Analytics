{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7040a554-46dc-4f62-a882-5da3226fa098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca444d20-156a-4644-a14d-407ca1c5ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change file path\n",
    "os.chdir(\"/Users/hydraze/Library/CloudStorage/GoogleDrive-tohziyu2@gmail.com/My Drive/Studies/KU Leuven/Courses/Classes/Y1S2/Advanced Analytics in Business/Project/3/AdvancedAnalytics_Streaming-Text-Analytics\")\n",
    "file_path = \"/Users/hydraze/Library/CloudStorage/GoogleDrive-tohziyu2@gmail.com/My Drive/Studies/KU Leuven/Courses/Classes/Y1S2/Advanced Analytics in Business/Project/3/AdvancedAnalytics_Streaming-Text-Analytics/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5049263-efcf-4648-8051-2e06ab101330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hydraze/Library/CloudStorage/GoogleDrive-tohziyu2@gmail.com/My Drive/Studies/KU Leuven/Courses/Classes/Y1S2/Advanced Analytics in Business/Project/3/AdvancedAnalytics_Streaming-Text-Analytics/models/lrm_model.model'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path+\"models/lrm_model.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2beb48c6-4b18-41b1-b764-ca31cfec88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "lrModel = LogisticRegressionModel.load(file_path+\"models/lrm_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "febe474c-5e7c-4aae-9d5e-391a2f441e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy predict function that returns a random probability. Normally you'd use your loaded globals()['my_model'] here\n",
    "def predict(df):\n",
    "    return random.random()\n",
    "\n",
    "predict_udf = udf(predict, StringType())\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    df.show()\n",
    "    \n",
    "    # And then predict using the loaded model (uncomment below):\n",
    "    df_result = lrModel.transform(df)\n",
    "    df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd1dec46-1893-4cc8-bdc5-3f3c4ea36b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/streaming/context.py:72: FutureWarning: DStream is deprecated as of Spark 3.4.0. Migrate to Structured Streaming.\n",
      "  warnings.warn(\n",
      "24/05/08 18:54:18 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:18 WARN BlockManager: Block input-0-1715187258200 replicated to only 0 peer(s) instead of 1 peers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2024-05-08 18:54:20 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/08 18:54:21 ERROR JobScheduler: Error running job streaming job 1715187260000 ms.0\n",
      "org.apache.spark.SparkException: An exception was raised by Python:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/streaming/util.py\", line 71, in call\n",
      "    r = self.func(t, *rdds)\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/4h/j84nnmnn0nj01mk0ndxyk7n40000gn/T/ipykernel_38474/3994392985.py\", line 18, in process\n",
      "    df_result = lrModel.transform(df)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/ml/base.py\", line 262, in transform\n",
      "    return self._transform(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/ml/wrapper.py\", line 398, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sparkSession)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\", line 185, in deco\n",
      "    raise converted from None\n",
      "pyspark.errors.exceptions.captured.IllegalArgumentException: final_feature_vector does not exist. Available: aid, comments, domain, frontpage, posted_at, source_text, source_title, title, url, user, votes\n",
      "\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hydraze/anaconda3/envs/aa24/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/var/folders/4h/j84nnmnn0nj01mk0ndxyk7n40000gn/T/ipykernel_38474/1411170812.py\", line 18, in run\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/streaming/context.py\", line 239, in awaitTermination\n",
      "    self._jssc.awaitTermination()\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\", line 179, in deco\n",
      "    return f(*a, **kw)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py\", line 326, in get_return_value\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o100.awaitTermination.\n",
      ": org.apache.spark.SparkException: An exception was raised by Python:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/streaming/util.py\", line 71, in call\n",
      "    r = self.func(t, *rdds)\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/4h/j84nnmnn0nj01mk0ndxyk7n40000gn/T/ipykernel_38474/3994392985.py\", line 18, in process\n",
      "    df_result = lrModel.transform(df)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/ml/base.py\", line 262, in transform\n",
      "    return self._transform(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/ml/wrapper.py\", line 398, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sparkSession)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\", line 185, in deco\n",
      "    raise converted from None\n",
      "pyspark.errors.exceptions.captured.IllegalArgumentException: final_feature_vector does not exist. Available: aid, comments, domain, frontpage, posted_at, source_text, source_title, title, url, user, votes\n",
      "\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+--------+-----+\n",
      "|     aid|comments|      domain|frontpage|          posted_at|         source_text|        source_title|               title|                 url|    user|votes|\n",
      "+--------+--------+------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+--------+-----+\n",
      "|40294481|       0|theverge.com|     true|2024-05-08 05:01:21|More Tesla employ...|More Tesla employ...|More Tesla employ...|https://www.theve...|robblack|    5|\n",
      "+--------+--------+------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/08 18:54:21 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:21 WARN BlockManager: Block input-0-1715187261200 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:54:22 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:22 WARN BlockManager: Block input-0-1715187262200 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:54:25 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:25 WARN BlockManager: Block input-0-1715187265200 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:54:27 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:27 WARN BlockManager: Block input-0-1715187267200 replicated to only 0 peer(s) instead of 1 peers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2024-05-08 18:54:30 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/08 18:54:30 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:30 WARN BlockManager: Block input-0-1715187270200 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:54:30 ERROR JobScheduler: Error running job streaming job 1715187270000 ms.0\n",
      "org.apache.spark.SparkException: An exception was raised by Python:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/streaming/util.py\", line 71, in call\n",
      "    r = self.func(t, *rdds)\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/4h/j84nnmnn0nj01mk0ndxyk7n40000gn/T/ipykernel_38474/3994392985.py\", line 18, in process\n",
      "    df_result = lrModel.transform(df)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/ml/base.py\", line 262, in transform\n",
      "    return self._transform(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/ml/wrapper.py\", line 398, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sparkSession)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\", line 185, in deco\n",
      "    raise converted from None\n",
      "pyspark.errors.exceptions.captured.IllegalArgumentException: final_feature_vector does not exist. Available: aid, comments, domain, frontpage, posted_at, source_text, source_title, title, url, user, votes\n",
      "\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+\n",
      "|     aid|comments|         domain|frontpage|          posted_at|         source_text|        source_title|               title|                 url|       user|votes|\n",
      "+--------+--------+---------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+\n",
      "|40294485|       0|telegraph.co.uk|    false|2024-05-08 05:02:00|AstraZeneca admit...|AstraZeneca admit...|AstraZeneca admit...|https://www.teleg...|    amarant|    2|\n",
      "|40294501|       0|       shom.dev|     true|2024-05-08 05:04:49|Enshittification ...|Enshittification ...|Enshittification ...|https://shom.dev/...|dargscisyhp|    5|\n",
      "|40294502|       0|   eduquila.org|    false|2024-05-08 05:04:51|                \\n\\n|                NULL|Show HN: I Build ...|https://www.eduqu...|    elotify|    1|\n",
      "|40294534|       0|    youtube.com|    false|2024-05-08 05:09:23|Charlie Munger's ...|Charlie Munger's ...|Becky Quick reads...|https://www.youtu...|  nipponese|    1|\n",
      "+--------+--------+---------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/08 18:54:33 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:33 WARN BlockManager: Block input-0-1715187273400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:54:38 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:38 WARN BlockManager: Block input-0-1715187278400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:54:39 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:39 WARN BlockManager: Block input-0-1715187279400 replicated to only 0 peer(s) instead of 1 peers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2024-05-08 18:54:40 =========\n",
      "+--------+--------+-------------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+\n",
      "|     aid|comments|             domain|frontpage|          posted_at|         source_text|        source_title|               title|                 url|       user|votes|\n",
      "+--------+--------+-------------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+\n",
      "|40294535|       0|        youtube.com|    false|2024-05-08 05:09:28|Dead trout in flo...|Dead trout in flo...|  Dead Trout [video]|https://www.youtu...|my12parsecs|    1|\n",
      "|40294546|       0|       theverge.com|    false|2024-05-08 05:11:30|Microsoft shuts d...|Microsoft shuts d...|Microsoft shuts d...|https://www.theve...|      pjmlp|    2|\n",
      "|40294554|       0|            npr.org|    false|2024-05-08 05:12:52|Why sperm whale c...|What are sperm wh...|Why sperm whale c...|https://www.npr.o...|   rrauenza|    2|\n",
      "|40294555|       4|fouronnes.github.io|     true|2024-05-08 05:12:58|                NULL|                NULL|     The C++ Iceberg|https://fouronnes...|thunderbong|   17|\n",
      "+--------+--------+-------------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/08 18:54:40 ERROR JobScheduler: Error running job streaming job 1715187280000 ms.0\n",
      "org.apache.spark.SparkException: An exception was raised by Python:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/streaming/util.py\", line 71, in call\n",
      "    r = self.func(t, *rdds)\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/4h/j84nnmnn0nj01mk0ndxyk7n40000gn/T/ipykernel_38474/3994392985.py\", line 18, in process\n",
      "    df_result = lrModel.transform(df)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/ml/base.py\", line 262, in transform\n",
      "    return self._transform(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/ml/wrapper.py\", line 398, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sparkSession)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\", line 185, in deco\n",
      "    raise converted from None\n",
      "pyspark.errors.exceptions.captured.IllegalArgumentException: final_feature_vector does not exist. Available: aid, comments, domain, frontpage, posted_at, source_text, source_title, title, url, user, votes\n",
      "\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/05/08 18:54:44 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:44 WARN BlockManager: Block input-0-1715187284400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:54:48 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:48 WARN BlockManager: Block input-0-1715187288400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:54:49 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:49 WARN BlockManager: Block input-0-1715187289400 replicated to only 0 peer(s) instead of 1 peers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2024-05-08 18:54:50 =========\n",
      "+--------+--------+--------------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------+-----+\n",
      "|     aid|comments|              domain|frontpage|          posted_at|         source_text|        source_title|               title|                 url|         user|votes|\n",
      "+--------+--------+--------------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------+-----+\n",
      "|40294588|       0|nationalcrimeagen...|    false|2024-05-08 05:17:24|LockBit leader un...|LockBit leader un...|LockBit Leader Un...|https://nationalc...|       doener|    2|\n",
      "|40294630|       2|forbes.com/sites/...|     true|2024-05-08 05:25:04|U.S. Labor Board ...|U.S. Labor Board ...|U.S. Rules Apple ...|https://www.forbe...|iancmceachern|   36|\n",
      "|40294637|       0|twitter.com/omarn...|    false|2024-05-08 05:27:16|X\\n\\nDonâ€™t miss w...|                   X|The AI Research A...|https://twitter.c...|         ofou|    1|\n",
      "+--------+--------+--------------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/08 18:54:50 ERROR JobScheduler: Error running job streaming job 1715187290000 ms.0\n",
      "org.apache.spark.SparkException: An exception was raised by Python:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/streaming/util.py\", line 71, in call\n",
      "    r = self.func(t, *rdds)\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/4h/j84nnmnn0nj01mk0ndxyk7n40000gn/T/ipykernel_38474/3994392985.py\", line 18, in process\n",
      "    df_result = lrModel.transform(df)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/ml/base.py\", line 262, in transform\n",
      "    return self._transform(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/ml/wrapper.py\", line 398, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sparkSession)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\", line 185, in deco\n",
      "    raise converted from None\n",
      "pyspark.errors.exceptions.captured.IllegalArgumentException: final_feature_vector does not exist. Available: aid, comments, domain, frontpage, posted_at, source_text, source_title, title, url, user, votes\n",
      "\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/05/08 18:54:50 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:50 WARN BlockManager: Block input-0-1715187290400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:54:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:54 WARN BlockManager: Block input-0-1715187294400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:54:55 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:55 WARN BlockManager: Block input-0-1715187295400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:54:57 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:54:57 WARN BlockManager: Block input-0-1715187297400 replicated to only 0 peer(s) instead of 1 peers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2024-05-08 18:55:00 =========\n",
      "+--------+--------+------------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+----------+-----+\n",
      "|     aid|comments|            domain|frontpage|          posted_at|         source_text|        source_title|               title|                 url|      user|votes|\n",
      "+--------+--------+------------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+----------+-----+\n",
      "|40294640|       0| indiadispatch.com|    false|2024-05-08 05:27:27|Venture firms dou...|Venture firms dou...|Venture Firms Dou...|https://indiadisp...|  jmsflknr|    1|\n",
      "|40294650|       0|         arxiv.org|     true|2024-05-08 05:28:43|[2405.04517] xLST...|xLSTM: Extended L...|XLSTM: Extended L...|https://arxiv.org...|mauricesvp|   26|\n",
      "|40294660|       0|aestuans.github.io|     true|2024-05-08 05:30:03|blob\\n\\ncode\\n\\nF...|                blob|Show HN: A simple...|https://aestuans....|  aestuans|    4|\n",
      "|40294711|       0|      benexdict.io|    false|2024-05-08 05:39:21|mission - by bene...|             mission|             Mission|https://benexdict...|  exolymph|    1|\n",
      "+--------+--------+------------------+---------+-------------------+--------------------+--------------------+--------------------+--------------------+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/08 18:55:00 ERROR JobScheduler: Error running job streaming job 1715187300000 ms.0\n",
      "org.apache.spark.SparkException: An exception was raised by Python:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/streaming/util.py\", line 71, in call\n",
      "    r = self.func(t, *rdds)\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/4h/j84nnmnn0nj01mk0ndxyk7n40000gn/T/ipykernel_38474/3994392985.py\", line 18, in process\n",
      "    df_result = lrModel.transform(df)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/ml/base.py\", line 262, in transform\n",
      "    return self._transform(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/ml/wrapper.py\", line 398, in _transform\n",
      "    return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sparkSession)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/hydraze/Downloads/spark/spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\", line 185, in deco\n",
      "    raise converted from None\n",
      "pyspark.errors.exceptions.captured.IllegalArgumentException: final_feature_vector does not exist. Available: aid, comments, domain, frontpage, posted_at, source_text, source_title, title, url, user, votes\n",
      "\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)\n",
      "\tat org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\n",
      "\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/05/08 18:55:00 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:55:00 WARN BlockManager: Block input-0-1715187300400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:55:03 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "24/05/08 18:55:03 WARN BlockManager: Block input-0-1715187303400 replicated to only 0 peer(s) instead of 1 peers\n",
      "24/05/08 18:55:06 ERROR ReceiverTracker: Receiver has been stopped. Try to restart it.\n",
      "org.apache.spark.SparkException: Job 5 cancelled as part of cancellation of all jobs\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:2731)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$doCancelAllJobs$2(DAGScheduler.scala:1114)\n",
      "\tat scala.runtime.java8.JFunction1$mcVI$sp.apply(JFunction1$mcVI$sp.java:23)\n",
      "\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:1113)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3022)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "24/05/08 18:55:06 ERROR Inbox: Ignoring error\n",
      "java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\n",
      "This stopped SparkContext was created at:\n",
      "\n",
      "org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "py4j.Gateway.invoke(Gateway.java:238)\n",
      "py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "The currently active SparkContext was created at:\n",
      "\n",
      "org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "py4j.Gateway.invoke(Gateway.java:238)\n",
      "py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "java.base/java.lang.Thread.run(Thread.java:829)\n",
      "         \n",
      "\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:122)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$makeRDD$2(SparkContext.scala:1039)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.SparkContext.withScope(SparkContext.scala:924)\n",
      "\tat org.apache.spark.SparkContext.makeRDD(SparkContext.scala:1038)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint.org$apache$spark$streaming$scheduler$ReceiverTracker$ReceiverTrackerEndpoint$$startReceiver(ReceiverTracker.scala:609)\n",
      "\tat org.apache.spark.streaming.scheduler.ReceiverTracker$ReceiverTrackerEndpoint$$anonfun$receive$1.applyOrElse(ReceiverTracker.scala:496)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "ssc = StreamingContext(sc, 10)\n",
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.foreachRDD(process)\n",
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a836d1-5f25-4600-8e61-1c262573868f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
