{"aid": "40216353", "title": "Why are video players on the web so big?", "url": "https://www.mux.com/blog/what-is-a-video-playback-engine", "domain": "mux.com", "votes": 3, "user": "mmcclure", "posted_at": "2024-04-30 21:07:13", "comments": 0, "source_title": "Why does my video player embed load so much JavaScript? | Mux", "source_text": "Why does my video player embed load so much JavaScript? | Mux\n\nSkip to content\n\nMux Logo\n\nBack to Blog Home\n\nSign upSign up\n\nGet a demoGet a demoLog inLog in\n\nPublished on April 15, 2024 (15 days ago)\n\n# Why are video players so big? A trip down the rabbit hole of video playback\nengines\n\nBy Christian and Darius \u2022 17 min read \u2022 Video education\n\nThere\u2019s a rite of passage you might\u2019ve gone on if you\u2019re a web developer. You\nembed your first YouTube video and all of a sudden... wham! 3MB of JavaScript\nload. And it\u2019s not just YouTube; Mux Player is pretty big, too.\n\nWe have ways of dealing with this. Most boil down to showing a facade while\nyou lazy-load your player. But we\u2019re not here to talk about lazy-loading. (We\nalready did that here and here!) We\u2019re here to talk about why video players\nare so big.\n\nAfter all, lazy-loading isn\u2019t the best user experience. And if you don\u2019t lazy-\nload, these big JavaScript packages might negatively impact your web vitals or\nvideo QoE metrics like startup time... or both. What do you get in exchange\nfor that bundle size? And can anything be done to make it smaller?\n\nThis rabbit hole goes deep. You\u2019ll learn more about video playback engines\nthan you might expect. But before we get there, let\u2019s start simple. Let\u2019s ask,\nwhat is a video player, anyway?\n\n## What is a video player?\n\nA video player is... well... it\u2019s a thing in your browser or app that plays\nvideos. But we can break it down more than that.\n\nIt\u2019s helpful to think of video players as two things. The face and the brain.\nHow it looks, and how it works. What the user clicks, and how those clicks\nshow video. The chrome and the playback engine.^1\n\nLet\u2019s start by talking about chrome. No, not that Chrome. In the context of a\nvideo player, chrome is the user interface elements and controls surrounding\nthe video. Play/pause buttons, the timeline scrubber, volume, full-screen,\nsubtitles, video quality, playback speed, and so on. Not only does chrome have\nto look good, but it has to remain accessible and respond to a wide variety of\npossible changes to the video. This is one reason video players are big. (By\nthe way: we at Mux work on the Media Chrome project to try and make building\nthis kind of chrome easier for you. Check it out!)\n\nAs you can see in the Bundlephobia diagram below, Media Chrome takes up about\na quarter of Mux Player. Another quarter is glue code and analytics.\nMeanwhile, more than half of the bundle is taken up by our playback engine of\nchoice, hls.js. Therefore, to answer the question of why video players are so\nbig, the playback engine seems like the most important thing to check out. So\nlet\u2019s spend some more time talking about playback engines: what do they do...\nand why are they so big?\n\n## What does a video playback engine do?\n\nBrowsers have built-in support for a few different video formats, like MP4 and\nWebM... but this only takes you so far. What if that MP4 is too big for a\nmobile connection or too small for a 4K TV? What if you want to send a media\ncontainer or codec that the browser doesn\u2019t support? What if you want to\nencrypt your media or protect your content with DRM? And how does the server\ncommunicate these video complexities to the client, anyway? You probably know\nwhere this is going: beyond the most basic video use case, you\u2019re going to\nneed a playback engine.\n\nA video playback engine is, in short, the part of a video player that\u2019s\nresponsible for handling these problems (and so much more!) and playing the\nresulting video.\n\nLet\u2019s dig into these problems a bit more so we can appreciate the hard work\nthat playback engines are doing for us. Maybe that will help us understand an\nengine\u2019s size. Starting with this diagram of hls.js \u2013 an open source, feature-\nrich, extremely popular playback engine (that, as mentioned, we happily use in\nMux Player). What do some of these modules do? Looks like some of them line up\nwith our problems up above...\n\nWe\u2019ll be using the hls.js as our example playback engine. However, we don\u2019t\nmean to pick on hls.js here; dashjs, shaka-player, @videojs/http-streaming and\neven commercial playback engines like @theoplayer/basic-hls-dash all tackle\nsimilar problems and grow to similar sizes\n\n### Working with HLS - playlists, fragments, etc.\n\nFirst things first: what is the \u201cHLS\u201d of \u201chls.js\u201d and how does it solve our\nproblems? That\u2019s a bigger question than we\u2019re prepared to answer here. Long\nstory short, HLS is a protocol that lets media servers and clients talk about\nmedia in a more complex way. Rather than just saying \u201chey, here\u2019s an MP4\u201d, we\ncan break media down into multiple segments and add all sorts of additional\ninformation about those segments. (We\u2019ll get more specific in upcoming\nsections.)\n\nhls.js needs a bunch of code to \u201cspeak\u201d the HLS protocol: it fetches, parses,\nand models HLS playlists, and understands what to do with that information in\norder to get a video playing in the browser.\n\n### Adaptive bitrate streaming engine - buffering, switching, fetching logic\n\nOne of the biggest reasons that standards like HLS exist is adaptive bitrate\nstreaming, or \u201cABR\u201d. ABR is a technique that solves our biggest problem: how\ndo we provide different versions of our video that work in different\nsituations?\n\nABR involves converting a video down into various resolutions and bitrates.\nThose various versions are called renditions. Those renditions are broken down\nand provided to the player in segments. Here\u2019s the trick: when things are\ngood, the player can grab a few high-quality segments. Then, when things\nchange (like, your train goes into a tunnel or something) the player can\nswitch to lower-quality segments mid-stream. Neat!\n\nTo do this, hls.js needs to consider things like network conditions, dropped\nframes, and player size in order to select the best rendition. It then fetches\nand buffers segments for that rendition, and manages filling and purging media\nSouceBuffers. Along the way, hls.js is working hard to make decisions about\nhow lazily or eagerly to do this all.\n\n### Media containers and codecs - decoding, transmuxing, and managing content\n\nAt the end of the day, hls.js\u2019s job is to get media segments and provide them\nto the browser via the Media Source API. However, just downloading and\nproviding the right segments isn\u2019t enough. HLS has a few extra jobs while\ndecoding and transmuxing those segments. To name just two:\n\n  1. Web browsers natively support only a handful of media formats. For example, many HLS streams use MPEG-TS segments, instead of the more-commonly-supported MP4 standard (or, if we\u2019re being technical, ISO-BMFF).\n  2. hls.js may also be extracting additional media-relevant information contained within a media container (e.g. ID3, IMSC/TTML, CEA-608 text track information).\n\nAnd speaking of text tracks...\n\n### Subtitles\n\nOut of the box, the browser does support subtitles with the <track> element.\nWith HLS, though, you unlock all sorts of capabilities. Provide the user with\ndozens of subtitle tracks without having to download them all at once.\nDescribe details about the subtitles through metadata, like if they\u2019re closed\ncaptions. Handle types other than VTT. Show subtitles, but only when there\u2019s\ndialogue not in your user\u2019s native tongue. Line up subtitles with timestamps\ndifferent from those in your video (which is especially relevant when it comes\nto clipping). All of these tasks? HLS and hls.js have got it. Oh and by the\nway, it\u2019s not just subtitles. hls.js has got your back if you have multiple\naudio tracks, too.\n\n### DRM & encrypted media\n\nListen. You could interface with the browser\u2019s EME API yourself to handle\nencrypted and DRM content yourself, but wouldn\u2019t you rather have hls.js do it\nfor you? HLS and hls.js provide all sorts of tools for dealing with such\ncontent, whether using \"Clear Key\" decryption keys or some DRM system.\n\nOf course, to manage this, HLS now needs to extract relevant information from\nthe HLS playlists or media containers, load keys at the right time, and\naccount for integration with different DRM servers and standards using the EME\nAPI.\n\n### But wait, there's more\n\nI think you get it. hls.js has a lot of jobs.\n\nBut let\u2019s pause for a moment and underline what an amazing Swiss Army knife\nhls.js really is. We\u2019ll start by naming a few modules that we missed up above:\n\n  1. Content Steering (See, e.g. this WWDC presentation by Zheng Naiwei)\n  2. CMCD/CMSD (See, e.g. this Demuxed presentation by Will Law)\n  3. Multi-track audio (See, e.g. this Mux guide by Phil Cluff)\n  4. Peripheral HLS info/tags (e.g. #EXT-X-DATERANGE, variable substitution)\n  5. Error handling/modeling\n  6. Generic core playback engine functionality (e.g. events, logging, types, task loops, fetch/XHR)\n  7. Other bits and bobs, including various categories of defensive code (e.g. \"gap-controller\")\n\nAnd that \u201cdefensive code\u201d deserves more of an explanation because it\u2019s a key\ncomponent of this Swiss Army knife philosophy. Every module has its jobs, but\nhls.js takes care that the module is ready for almost every situation.\n\nLet\u2019s take, for example, the media containers and codecs module: While\nperforming its regular duties, the module also makes sure that even the most\nunusual media makes it to playback without a hitch. What kind of unusual\nmedia? For one, hls.js can adjust timelines between audio and video for out-\nof-sync segments. For another, it will account for different durations when\ntransitioning between discontinuities.\n\nSo, in many ways, \u201cSwiss Army knife\u201d is the wrong analogy here. A Swiss Army\nknife \u2013 with its stubby little tools \u2013 is a jack of all trades, master of\nnone. Somehow, though, hls.js has managed to be competent at all.\n\n## We need to talk about playback engine architecture\n\nYou probably feel like you have the answer to this blog post\u2019s titular\nquestion: \u201cWhy are video players so big? Because they have a lot of great\nfeatures.\u201d And yeah, that\u2019s true, but stick with us for one last section,\nbecause the answer is actually a bit bigger and more interesting than that.\nThere\u2019s one last size-aggravating factor that needs talking about: features\nthat span across the playback engine.\n\nUp above, we named a bunch of \u201cbuckets\u201d of video playback engine\nfunctionality. There are some features, however, that don\u2019t fit neatly into a\nbucket. These features have a particular impact on size. Consider the\nfollowing example:\n\nhls.js supports both on-demand and live streaming. Some of the on-demand/live\ncode lives in the \u201cworking with HLS\u201d module, some of it in the \u201cABR\u201d module,\nsome in the \u201cDecoding\u201d module, and some elsewhere. It\u2019s diffused throughout\nthe codebase. On top of that, everywhere this code appears, it appears\nsupporting both on-demand and live, since the two actually share many\nsimilarities in implementation. These two pieces of functionality are coupled.\n\n(You can see these diffused and coupled code all over. With DVR use-cases,\nwith low-latency vs. standard live streams, with discontinuities, with HTTP\nrange request support, with encrypted media/DRM key rotation... You get the\npoint.)\n\n### But why is diffused and coupled code a problem for playback engine size?\n\nGreat question, thanks for asking. Let\u2019s say you don\u2019t need a jack of all\ntrades. Let\u2019s say you\u2019re a dedicated media and entertainment company that has\ntight control over its streaming media use case and knows the exact handful of\nfeatures it needs. (If you\u2019re reading this, I\u2019m guessing you\u2019re probably\nnot... but you\u2019re also probably curious, so let\u2019s keep going!) Because of this\ndiffused and coupled architecture, it becomes difficult to drop features.\nDon\u2019t want live streaming? Too bad; it\u2019s hard to remove because it\u2019s so spread\nout and shares so much code with on-demand.\n\nDiffused and coupled code is why, at least in part, the official light version\nof hls.js only removes alternate audio, subtitles, CMCD, EME (DRM), and\nvariable substitution support. Sure it shrinks the package by over 25%, but\nthat package still likely includes things you don\u2019t need. Mind you, you could\ngo through the effort of forking hls.js and configuring your own build... but\neven then, you\u2019re still limited to dropping the same handful of features.\n\nYou can get a sense of this diffusion and coupling by looking at the\ndependency relationships in hls.js\u2019s source code. Here\u2019s a visual generated by\nmadge. This graph shows the complex dependencies that make subsetting\ndifficult.\n\n### If that\u2019s a problem, why does Mux use hls.js?\n\nDespite its bundle size and its subsetting limitations, we at Mux (as well as\nseveral other major players out there) still use hls.js. Clearly we consider\nthe trade-off worth it. And maybe it\u2019s worth it for you, too.\n\nHere's how we thought about it. First, why did we pick hls.js in particular?\nHopefully, for obvious reasons, closed-source/commercial playback engines were\nnon-starters. That left a very short free-and-open-source list. Since Mux\nVideo only supports HLS, not MPEG-DASH, that list became even shorter. We\nexplored cutting off unneeded bits of Shaka Player and VHS, but in the end,\nhls.js was a very clear (and good!) choice for us.\n\nBut if we could build our own chrome with Media Chrome, why didn\u2019t we just\nbuild our own playback engine? Co-author of this piece Christian Pillsbury has\nspent years doing significant work on several playback engines. He would be\nthe first to tell you about the time and effort DIY would take, even for the\nsubset of HLS features Mux Video supports (including low-latency and multi-\ntrack audio). Even if we just DIY'd for some cases and used hls.js for others,\nwe would still run into a deeper issue: hls.js is battle-tested and our DIY\nsolution wouldn\u2019t be. A DIY solution would be more work and more risk.\n\nLike the media and entertainment companies we mentioned above (and unlike, we\nimagine, many of our readers), we do have control over our streaming media\npipeline. And even for us, it makes sense \u2013 at least for now \u2013 to take\nadvantage of the incredible work that has been done on hls.js.\n\nWe hope to help continue that work and improve hls.js, too. Discussions and\ninitial steps are already underway among the maintainers of hls.js \u2013 including\nourselves \u2013 to make targeted, slimmed down usage of hls.js easier. This can be\nyou as well! If you want to help improve hls.js, please file specific issues\nand contribute to the project.\n\n## So where does that leave us?\n\nVideo playback engines are big. But don\u2019t be mad at the playback engines or\ntheir authors for that.\n\nIn hls.js's 9+ years of life, contributors have changed 83,263 lines of code.\n38,065 of those changes \u2013 more than 45% \u2013 were contributed by Rob Walch alone.\nYou reach more than 86% if you include top contributors Tom Jenkinson, John\nBartos, Guillaume du Pontavice aka \u201cmangui\u201d, Jamie Stackhouse, and of course\nStephan Hesse.^2 Although these folks may receive some support from their\ncompanies, this herculean effort is often done alongside a \u201creal job\u201d. And\nthen, like the vast majority of long-lived, complex projects, tech debt\naccrues. Expedient fixes, improvements, and feature additions are often fit\ninto pre-existing implementations out of necessity and time scarcity. Complete\nre-architectures are rare, if not impossible.\n\nAnd despite this, look at what they\u2019ve built! hls.js and its video playback\nengine peers are engineering marvels: Swiss Army knives that support so many\nfeatures and edge cases. Developers shouldn\u2019t have to know the ins and outs of\nhow streaming media works, how their media servers or OVPs work, or what\nstreaming media features they rely on. Are you sometimes playing low latency\nlive streams and other times using on-demand? No problem. Does some of your\ncontent have in-mux CEA-708 closed caption data carried in transport stream\nmedia containers, and some use WebVTT subtitle media playlists? You\u2019re good.\nDoes your OVP occasionally produce small gaps between your media segments,\nmade more complex because you also rely on segment discontinuities to stitch\ntogether your brand\u2019s splash video segments before the primary content, where\nall of that content is also DRM-protected with Widevine, FairPlay, and\nPlayReady for cross-browser and cross-platform compatibility? Don\u2019t worry\nabout... ok, this case may have some rough edges still, but playback engines\nlike hls.js will still try really hard to handle most of the complexity.\n\nThe great thing about a Swiss Army knife is that it can do a whole bunch of\ndifferent things. Things you didn\u2019t even know you\u2019d be doing. For the vast\nmajority of cases, it will Just WorkTM.\n\nStill, one problem with a Swiss Army knife is that sometimes you just need a\npair of tweezers, and now you\u2019re getting hassled by the TSA and might miss\nyour flight. In other words, playback engines often pull in more than you need\nfor a given use case, and the result is large JavaScript packages that can\naffect your user experience. Like Joe Armstrong said in Coders At Work: \"You\nwanted a banana but what you got was a gorilla holding the banana and the\nentire jungle\".\n\nThere are companies out there \u2013 like a few of those media and entertainment\ncompanies streaming TV on the internet \u2013 who did traipse through the TSA\njungle and find their banana-tweezers. They do have smaller playback engines.\nBut they also have the engineering resources to build it and to control their\nstreaming media use case. For everyone else, that trade-off might not be worth\nit. For everyone else, there are superpowered Swiss Army knife video playback\nengines like hls.js.\n\n  1. Depending on who you ask, this is either a little oversimplified or way oversimplified. Some people might call what\u2019s going on under the hood the \u201cvideo player\u201d and what the website is shipping with \u201cthe application layer\u201d. Others will mention that stopping at the playback engine is silly, and that you have to go deeper, to OS-level tools like AVFoundation, and to the device drivers and hardware-level encoders and decoders down below. For now, though, let\u2019s just talk about chrome and playback engines. As a developer, that\u2019s probably what\u2019s in the package you\u2019re adding to your website or app.\u21a9\n  2. If you want to check our work: `git ls-files | while read f; do git blame -w -M -C -C --line-porcelain \"$f\" | grep -I '^author '; done | sort -f | uniq -ic | sort -n`\u21a9\n\n## Written By\n\n### Christian Pillsbury \u2013 Staff Software Engineer & Tech Lead\n\nStarted working on OTT streaming media & players over a decade ago for a bunch\nof folks back in the Adobe Flash/RTMP days as a consultant at Digital\nPrimates. When I\u2019m not working on video players, I\u2019m spending my time doing\ndeep dives in philosophy, stomping around the Chicago arts scene, and watching\nTV on the internet with my cat Grits.\n\n### Darius Cepulis \u2013 Senior Community Engineer\n\nPretends he knows more about coffee than he does. Happier when he's outside.\nThinks the web is pretty neat.\n\n## Leave your wallet where it is\n\nNo credit card required to get started.\n\nSign upSign up\n\n## Read more like this\n\nPublished on July 1, 2020 \u2022 By Scott Kidder\n\n### Why You Should Use a CDN for Video\n\nPublished on October 10, 2022 \u2022 By Christian Pillsbury\n\n### Gone in a Flash: a brief history of HTTP Adaptive Streaming\n\nPublished on July 29, 2020 \u2022 By Matthew Szatmary\n\n### Your browser and my browser see different colors\n\n### Check out our newsletter\n\nA monthly-ish digest of all the best new blog posts and features\n\nMux Logo\n\n## United States\n\n50 Beale Street, Floor 9 San Francisco, CA, 94105 510-402-2257\n\n## United Kingdom\n\n34-37 Liverpool Street London, EC2M 7PP\n\nContact usMux on TwitterMux on LinkedInMux on GitHub\n\n## Platform\n\n### Mux Video\n\nOverviewFeaturesOn-DemandLiveInteractiveEncodingPricing\n\n### Mux Data\n\nOverviewMonitoringPricing\n\n### Mux Player\n\nOverview\n\nBeta features\n\n## Docs and Tools\n\nMux Video docsMux Data docsMux Player docsAPI referenceWebhook referenceOpen\nsource software\n\n### Integrations\n\nNodeRubyPHPPythonElixirGoSvelteKitNext.jsRemix.jsGenerative AI\n\n## Company\n\nTeamJobsBlogCustomersResourcesPartnersSupportDownload Press Kit\n\n## More Video\n\nVideo glossaryLearn about videoSign up for our newsletterDemuxedHowVideo.Works\n\n\u00a9 Mux, Inc. 2024\n\nTerms of serviceSecurityPrivacy policySitemap\n\nStatus:Loading....\n\n", "frontpage": false}
