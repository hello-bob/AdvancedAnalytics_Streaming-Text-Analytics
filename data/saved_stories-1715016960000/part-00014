{"aid": "40273065", "title": "AI IQ scores (mostly) confirmed, using new offline IQ test", "url": "https://www.maximumtruth.org/p/ai-iq-scores-mostly-confirmed-using", "domain": "maximumtruth.org", "votes": 2, "user": "ironyman", "posted_at": "2024-05-06 10:31:41", "comments": 0, "source_title": "AI IQ scores (mostly) confirmed, using new offline IQ test", "source_text": "AI IQ scores (mostly) confirmed, using new offline IQ test\n\n# Maximum Truth\n\nShare this post\n\n#### AI IQ scores (mostly) confirmed, using new offline IQ test\n\nwww.maximumtruth.org\n\n#### Discover more from Maximum Truth\n\nJoin me on a data-driven search for the truth!\n\nOver 4,000 subscribers\n\nContinue reading\n\nSign in\n\n# AI IQ scores (mostly) confirmed, using new offline IQ test\n\n### Major AIs suffer 8% loss on novel questions; all AIs have 20% loss\n\nMaxim Lott\n\nMay 06, 2024\n\n5\n\nShare this post\n\n#### AI IQ scores (mostly) confirmed, using new offline IQ test\n\nwww.maximumtruth.org\n\n2\n\nShare\n\nHow smart are AIs? Knowing that can help us answer questions like \u201cwill AIs\ntake our jobs?\u201d and \u201cwill AIs kill us all soon?\u201d\n\nAIs seem smart partly because they have lots of knowledge. They\u2019re trained on\nfar more information than any human has seen. But their intelligence \u2014 their\nability to use logic and reason to analyze questions \u2014 often reveals basic\nerrors.\n\nIn my last deep dive, I gave a verbalized matrix-style IQ test to AIs, and\nfound the following:\n\nThe results seem plausible to me. Interacting with AI chatbots feels like\ndealing with someone who\u2019s not that bright, but who knows how to write, and\nhas access to an Encyclopedia of Everything.\n\nHowever, several smart people raised a plausible concern: perhaps the IQ\nquestions and answers (which came from Mensa Norway\u2019s online quiz) were\nalready in the AI training data. AI reporter Timothy B Lee wrote:\n\nAnother commenter wrote:\n\nThe concern makes sense. AI companies have sucked in massive sections of the\nweb for AI training. A recent Verge headline notes, \u201cOpenAI transcribed over a\nmillion hours of YouTube videos to train GPT-4.\u201d That\u2019s particularly relevant,\nbecause YouTube does contain videos with the test answers and reasoning. That\nsaid, there are approximately 156 million hours of YouTube videos, so ChatGPT\nhas logged less than 1% of all YouTube content.\n\nIn order for humans to get a fully valid IQ test result, they need to have not\npracticed or thought in detail about IQ questions. Did the AI do that? Did it\n\u201ccheat\u201d?\n\n##\n\nDid the AIs \u201ccheat\u201d by using IQ questions in their databases? Preliminary\nevidence\n\nSome patterns suggest that AIs do not memorize the answers.\n\nThat\u2019s because AIs are much more likely to get easy questions right, compared\nto hard ones.\n\nThe below graph shows the results of two test administrations for the smartest\nAI. The tall bars mean it got the question right both times it was asked, the\nshort bars mean it got it right just once (and no bar means it got the\nquestion wrong both times):\n\nThat pattern doesn\u2019t look like the answers of someone with an answer key.\nInstead, it suggests that the AI was working through the problems using\npattern matching skills, in the same way a human might.\n\nThe reasoning that AIs provide as they solve their questions also backs that\nup. In some cases, the AI takes upon itself to draw the IQ problem in question\nit was read:\n\nDrawing out the problem is something that no online answer key would suggest;\nhumans can see the questions, and have no need to re-draw them.\n\nDespite the above, it remains possible that AIs do have the IQ questions Q&As\nin their database, but just use them imperfectly.\n\nAdditionally, even if the AIs don\u2019t \u201ccheat\u201d yet by having the questions in\ntheir database \u2014 in the future, they certainly might, as they are trained on\nlarger and larger datasets.\n\nSo it would be really nice to have an offline test which will always be able\nto answer the question of whether AIs are passing IQ tests due to\nintelligence, or due to having the answers in their database.\n\n##\n\nCreating a new offline-only test to run on AIs\n\nJurij, a Mensa member and commenter here who creates IQ questions as a hobby,\noffered to create new IQ test questions. I took him up on that.\n\nJurij created 16 questions from scratch, which were quite different in\nappearance from the Mensa Norway ones, while still testing the same kind of\nabstract pattern logic. Here is an example of one of his easier questions\n(which is not part of the AI test; I can\u2019t publish those online, or it would\ninvalidate future tests with it):\n\nOnce I had Jurij\u2019s questions and answers together, I still needed to \u201cnorm\u201d\nthem \u2014 in other words, to figure out how hard the new questions were compared\nto the Mensa Norway questions that I previously gave AIs.\n\nTo do that, I paired the 16 new questions with all the even-numbered questions\nfrom Mensa Norway\u2019s online IQ test, and I then asked blog readers to take the\nquiz.\n\n59 readers took it (thank you very much! I hope it wasn\u2019t too painful.)\n\n35 of the responses were usable, meaning the test-taker got to the end, and\nhadn\u2019t seen the Mensa Norway questions before. Out of those, here\u2019s how the\nscores broke down \u2014 quite a wide range:\n\nThe average score was 103, and the median was 95\n\nThat breakdown is based just on the 17 Mensa Norway questions that respondents\nanswered.\n\nI suspect the scores are too low. However, the formula I used is faithful to\nthe Mensa Norway scoring \u2014 I sanity-checked it by manually entering in 16\ncorrect answer into their test, which gives you a score of 95. My test used\nhalf of their questions, and also gives you, for example, 95 for 8 answers\ncorrect.\n\nSo I suspect that their test isn\u2019t perfectly calibrated, and 100 actually\nrepresents a somewhat above-average person.\n\nThat will require more research to nail down (specifically, a survey of the\ngeneral population.)\n\nBut in the meantime, it\u2019s not particularly relevant for determining whether\nthe AIs \u201ccheat\u201d \u2014 the important thing is that this is fundamentally the same\nscoring formulas1 by which AIs were graded in the last analysis.\n\nThe quiz is now offline, and precautions were taken to prevent the new\nquestions from being exposed to the public internet while they were briefly\nonline for blog readers to take.2\n\nSo, how do the new questions compare to the old ones in difficulty?\n\n##\n\nMethods: \u201cNormalizing\u201d the new test questions\n\nThe purpose of my survey was to determine the difficulty of the new, offline-\nonly questions, compared to the Mensa Norway questions.\n\nThe survey results revealed that two questions were ill-formed (fewer people\ngot them right than one would expect by chance, and also, the top-scorers were\nalso not better at them.) Those two questions were dropped.\n\nAnother question turned out to have two correct answers; that question was\nkept, and either correct answer was given credit.\n\nThat left 14 new questions, which had good predictive power of people\u2019s Mensa\nNorway scores.\n\nOut of the 14 new questions, respondents averaged 8.94 correct. Out of the 17\nNorway Mensa questions, they averaged 9.2 correct.\n\nSince there were fewer new questions, that means each one was slightly easier;\nsurvey takers got 63.8% of new questions right, compared to 54.1% of Norway\nMensa questions.\n\nSince each new question was slightly easier, after adjusting for randomness\nand the size of the tests, the scoring formula counts each correct answer as\nworth 88% of a Mensa Norway answer. Formulas are detailed in footnote 1.\n\nThis method ensures that the average IQ of each set of questions is the same\n(both are 103.) But each individual has a different score using the new\nquestions, and the distribution is slightly different:\n\nAverage is 103; median is now also 103. Note: in the previous chart, all but\none of the\u201c80s\u201d was 89, and that\u2019s why this chart may appear to have a higher\nmean. But it is the same.\n\nAbility at answering the new IQ questions, and the Mensa Norway ones,\ncorrelates with R^2 at .45. That means that differences in IQ estimates based\non Norway Mensa predict close to half of the differences in the IQ estimates\nbased on the new questions:\n\nIf the dots were in a straight line, like the blue dotted one, then how a\nrespondent did on the old questions would perfectly match how they did on the\nnew ones\n\nThat\u2019s far from a perfect correlation, but I think it\u2019s enough to get some\nsense of how the AIs are at an offline-only IQ test.\n\nNow that we\u2019ve figured out how hard the new questions are compared to the old\nones, and the relevant formulas, we can go on to scoring the AIs based on the\nnew test.\n\n##\n\nResult: Top AIs did 8% worse with novel questions\n\nHere are the new results, alongside the old ones:\n\nNote that AIs actually get the new questions right slightly more often than\nthe old ones. But that\u2019s because they\u2019re easier, as determined by giving the\nquestions to humans. The IQs have been adjusted based on that.\n\nLooking at the top 5 AIs that I had previously scored (Claude-3, ChatGPT-4,\nBing Copilot, Gemini, and Gemini Advanced), they had a loss of 3 IQ points.\nThose AIs would have averaged 6.6 correct answers, if they\u2019d be equally good\nat the different questions; instead, they got 6.1 correct answers. That\u2019s an\n8% reduction in performance.\n\nNote that we\u2019re talking about 3 fewer IQ points, on a test that has been\nnormed to how humans did on the two kinds of questions. In other words, the\ntests have already been set to have the same average score when humans take\nthem \u2014 but the AIs do not get quite as high of a score on the novel, offline\nquestions.\n\n##\n\nResult: AIs overall did 20% worse with novel questions\n\nThe AIs overall averaged about 6 fewer IQ points using the new test which has\nnever been online.\n\nThe 6 IQ-point difference translates to roughly 1 fewer question correct out\nof the 14 asked. The average AI would\u2019ve gotten 5 questions right, instead of\n4, if it had done as well as it does on the Mensa Norway questions. So that\u2019s\na 20% loss in performance.\n\nThis suggests that there might have been a bit of \u201ccheating\u201d in terms of the\nAIs using IQ questions that were online to craft their answers.\n\nBut it doesn\u2019t necessarily show \u201ccheating.\u201d Here are other possibilities:\n\n\u2014 It could be random chance (though that seems unlikely; every single except\nChatGPT-4 did worse on the new test.)\n\n\u2014 It\u2019s possible that my translations were inadvertently be worse, or harder,\nthis time.\n\n\u2014 It\u2019s possible that the questions themselves are harder for AIs. In\nparticular, the new questions involve more unique shapes, and have more\nextraneous detail, than do the Norway Mensa questions. For example, the order\nof shapes is sometimes random, and the shapes are often things like a\n\u201cstylized Z\u201d rather than just a triangle. These extraneous details are likely\nto be more easily overlooked by humans using \u201ccommon sense\u201d, but when I do the\nverbal translations, I have to describe this extraneous detail to the AIs, and\nit has to realize that the real pattern lies elsewhere. IF it were the case\nthat AIs really are just as good at novel offline-only questions, I suspect\nthis would explain it.\n\n##\n\nMeta\u2019s Llama-3 is a new AI, and an outlier\n\nFor some reason, Meta\u2019s Llama-3 (which did not exist when I did my previous\nanalysis) does decently on Norway Mensa questions, but is no better than\nrandom at the novel, offline questions. That\u2019s surprising, and suggests that\nperhaps Llama-3 has the questions in its training data more than any other\nmajor AI.\n\n##\n\nIt makes sense that AIs saw relatively little dropoff in performance\n\nTimothy B Lee of Understanding AI, in his comment quoted above, cited a study\nthat found that AIs solved 50-80% fewer math problems when given novel\nquestions that don\u2019t exist online.\n\nI found nothing like that kind of dropoff with IQ questions. I think that\nmakes sense, because it\u2019s very rare for people to study for IQ tests. The\nanswers were not that easy for me to find online (though I eventually found\nthem in a YouTube video.) In contrast, math problems have been a core part of\nthe educational system forever, and they live just about everywhere on the\ninternet.\n\nShare\n\n##\n\nConclusion: AI IQs are fairly robust, especially among top AIs\n\nOverall, the ranking of AIs based on the new questions is pretty similar to\nthe ranking based on the Mensa Norway questions. Here it is again:\n\nUsing the new questions, I also still find a massive performance difference\nbetween the \u201cChatGPT-3.5\u201d generation AIs, and the \u201cChatGPT-4\u201d generation AIs.\n\nThis suggests that the test is picking up something real. After doing this\nanalysis, I\u2019m still just as excited to use this method once the \u201cChatGPT-5\u201ds\nstart rolling out. I think that\u2019ll give us some sense of whether AIs actually\nthreaten jobs on a mass scale soon, and also whether it\u2019s scaling in a way\nthat\u2019s on track to become omnipotent \u2014 or not.\n\nThe reason it\u2019s an interesting test is because it differentiates AI knowledge\nfrom AI intelligence, in a way that other tests like GMATS and SATs don\u2019t.\n\nI\u2019m now working on adding this novel AI IQ test (and the old one, too) to\nTrackingAI.org, where both tests will run weekly, providing an IQ range for\neach AI.\n\nWeekly runs will both help with any problems caused by small sample sizes, and\nalso detect trends over time!\n\nPlease consider supporting more research!\n\nThis blog is still small \u2014 we\u2019re nearing 5,000 subscribers. Please consider\nsharing this post to spread the word!\n\nShare\n\n1\n\nFormula for Full Norway Mensa:\n\n63.5 + 3 * (correct answers - 5.833) [5.833 is the number of questions one\nwould get by chance.]\n\nFormula for Mensa Norway short version (even-numbered questions only):\n\n1) Take # of correct answers on 17 even-numbered questions\n\n2) Subtract (17/6), for the number of questions one would get by chance.\n\n3) Multiply by (35/17), to account for the fact that we don\u2019t have the full\nquestion set.\n\n4) Call that resulting number \u201cadjusted correct answers\u201d, then do: 63.5 +\nadjusted correct answers * 3\n\nIn full, this can expressed as: 63.5 + 3 * ((correct answers -\n(17/6))*(35/17))\n\nFormula for Offline Answers:\n\n1) Take # of correct answers on the 14 valid questions (so, not including 9\nand 11.)\n\n2) Subtract 3 (aka (1/5)*13 + (2/5)), for the number of questions one would\nget by chance. Note: 2/5 is because one question has two valid answers. The\n\u201c/5\u201d as opposed to \u201c/6\u201d is because the offline test questions have 5 possible\nanswers, not 6.\n\n3) Multiply by (35/14), to account for the fact that we don\u2019t have the full\nquestion set.\n\n4) Multiply by 0.8823, to account for the fact that the new questions were\nslightly easier than than the Norway Mensa ones.\n\n5) Call that resulting number \u201cadjusted correct answers\u201d, then do: 63.5 +\nadjusted correct answers * 3\n\nIn full, this can expressed as: 63.5 + 3 * 0.8823 * ((correct answers -\n3)*(35/14))\n\n2\n\nThe Mensa Norway questions were in black, and the \u201coffline\u201d ones were in\ncolor. Also, here are the precautions taken to ensure the test stayed offline:\nWhile the quiz was take-able, the images were hosted on a server of mine with\na \u201cnorobots.txt\u201d file to deter scraping, and the site was never located by a\nsearch engine. The images were on it for only a few days, before being\ndeleted, along with the quiz.\n\nSide note: there was an error in the formula for the scores shown to the 35\npeople who took the test, which caused, for example, one person to be shown a\nscore of 168 after taking the test. It should have be in the 140s. Aside from\nthat, scores shown to takers were generally accurate within 10 points. The\ncorrectly-calculated score breakdown is in the bar chart in this post, and was\nexclusively used in this analysis.\n\n### Subscribe to Maximum Truth\n\nBy Maxim Lott \u00b7 Launched 3 years ago\n\nJoin me on a data-driven search for the truth!\n\n5 Likes\n\n\u00b7\n\n3 Restacks\n\n5\n\nShare this post\n\n#### AI IQ scores (mostly) confirmed, using new offline IQ test\n\nwww.maximumtruth.org\n\n2\n\nShare\n\n2 Comments\n\nJ.K. LundRisk & Progress1 hr agoMaxim, great work. Where do you see this\nheading in the near future? Are we going to have AIs that exceed human\nintelligence in the coming five years?Expand full commentLikeReplyShare  \n---  \n  \nFrancis TurnerL'Ombre de l'Olivier5 hrs ago\u00b7edited 5 hrs agoYou make me\ncurious to see the offline questions. Though I understand the problem I wonder\nif there might be a way to cut out scrapers without impacting humans. I have\nsome ideas based on fronting the questions with a service like cloudflare\nwhich allows you to redirect based on the requester's source (and indeed to\nmake the bot click on the \"I'm not a robot\" box, which it ought to fail at).\nThis would let humans see your test questions and exclude the various web\ncrawlers including the AI ones.It should be possible to test this by putting\nsome other information behind a test block and see if that information shows\nup in AI programs or indeed in google/bing etc.Expand full\ncommentLikeReplyShare  \n---  \n  \nDEEP DIVE: Covid Myths\n\nHow the medical establishment AND skeptics failed\n\nDec 3, 2021 \u2022\n\nMaxim Lott\n\n35\n\nShare this post\n\n#### DEEP DIVE: Covid Myths\n\nwww.maximumtruth.org\n\n125\n\nDEEP DIVE: The Covid \"Fudge Factor\"\n\nA map of Covid data corruption -- and the Covid approach that worked!\n\nAug 30, 2022 \u2022\n\nMaxim Lott\n\n94\n\nShare this post\n\n#### DEEP DIVE: The Covid \"Fudge Factor\"\n\nwww.maximumtruth.org\n\n103\n\nAIs ranked by IQ; AI passes 100 IQ for first time, with release of Claude-3\n\nWhen AIs are given \"special accommodations\" in an IQ test, as if they were\nblind people, their scores improve\n\nMar 5 \u2022\n\nMaxim Lott\n\n35\n\nShare this post\n\n#### AIs ranked by IQ; AI passes 100 IQ for first time, with release of\nClaude-3\n\nwww.maximumtruth.org\n\n38\n\nReady for more?\n\n\u00a9 2024 Maxim Lott\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}
