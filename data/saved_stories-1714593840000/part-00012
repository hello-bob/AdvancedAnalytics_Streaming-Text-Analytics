{"aid": "40221154", "title": "LLMs Can't Do Probability", "url": "https://brainsteam.co.uk/2024/05/01/llms-cant-do-probability/", "domain": "brainsteam.co.uk", "votes": 8, "user": "DrRavenstein", "posted_at": "2024-05-01 09:29:32", "comments": 0, "source_title": "LLMs Can't Do Probability - Brainsteam", "source_text": "LLMs Can't Do Probability - Brainsteam\n\nLLMs Can't Do Probability - Brainsteam\n\nSkip to content\n\n# Brainsteam\n\n## LLMs Can\u2019t Do Probability\n\n1 May 2024\n\n/\n\nUncategorised\n\n/\n\njamesravey\n\nI\u2019ve seen a couple of recent posts where the writer mentioned asking LLMs to\ndo something with a certain probability or a certain percentage of the time.\nThere is a particular example that stuck in my mind which I\u2019ve since lost the\nlink to (If you\u2019re the author, please get in touch so I can link through to\nyou):\n\nThe gist is that the author built a Custom GPT with educational course\nmaterial and then put in the prompt that their bot should lie about 20% of the\ntime. They then asked the students to chat to the bot and try to pick out the\nlies. I think this is a really interesting, lateral thinking use case since\nthe kids are probably going to use ChatGPT anyway.\n\nThe thing that bothered me is that transformer-based LLMs don\u2019t know how to\ninterpret requests for certain probabilities of outcomes. We already know that\nChatGPT reflects human bias when generating random numbers. But, I decided to\nput it to the test with making random choices.\n\n## Testing Probability in LLMS\n\nI prompted the models with the following:\n\n> You are a weighted random choice generator. About 80% of the time please say\n> \u2018left\u2019 and about 20% of the time say \u2018right\u2019. Simply reply with left or\n> right. Do not say anything else\n\nAnd I ran this 1000 times through some different models. Random chance is\nrandom (profound huh?) so we\u2019re always going to get some deviation from\nperfect odds but we\u2019re hoping for roughly 800 \u2018lefts\u2019 and 200 \u2018rights\u2019 \u2013\nsomething in that ballpark.\n\nHere are the results:\n\nModel| Lefts| Rights  \n---|---|---  \nGPT-4-Turbo| 999| 1  \nGPT-3-Turbo| 975| 25  \nLllama-3-8B| 1000| 0  \nPhi-3-3.8B| 1000| 0  \n  \nAs you can see, LLMs seem to struggle with probability expressed in the system\nprompt. It almost always answers left even though we asked it to only do so\n80% of the time. I didn\u2019t want to burn lots of $$$ asking GPT-3.5 (which did\nbest in the first round) to reply with single word choices to silly questions\nbut I tried a couple of other combinations of words to see how it affects\nthings. This time I only ran each 100 times.\n\nChoice (Always 80% / 20%)| Result  \n---|---  \nCoffee / Tea| 87/13  \nDog / Cat| 69/31  \nElon Musk/Mark Zuckerberg| 88/12  \nRandom choices from GPT-3.5-turbo\n\nSo what\u2019s going on here? Well, the models have their own internal weighting to\ndo with words and phrases that is based on the training data that was used to\nprepare them. These weights are likely to be influencing how much attention\nthe model pays to your request.\n\nSo what can we do if we want to simulate some sort of probabilistic outcome?\nWell we could use a Python script to randomly decide whether or not to send\none of two prompts:\n\nPlain text\n\nCopy to clipboard\n\nOpen code in new window\n\nEnlighterJS 3 Syntax Highlighter\n\nimport random\n\nfrom langchain_openai import ChatOpenAI\n\nfrom langchain_core.messages import HumanMessage, SystemMessage\n\nchoices = (['prompt1'] * 80) + (['prompt2'] * 20)\n\n# we should now have a list of 100 possible values - 80 are prompt1, 20 are\nprompt2\n\nassert len(choices) == 100\n\n# randomly pick from choices - we should have the odds we want now\n\nchat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n\nif random.choice(choices) == 'prompt1':\n\nr = chat.invoke(input=[SystemMessage(content=\"Always say left and nothing\nelse.\")])\n\nelse:\n\nr = chat.invoke(input=[SystemMessage(content=\"Always say right and nothing\nelse.\")])\n\nimport random from langchain_openai import ChatOpenAI from\nlangchain_core.messages import HumanMessage, SystemMessage choices =\n(['prompt1'] * 80) + (['prompt2'] * 20) # we should now have a list of 100\npossible values - 80 are prompt1, 20 are prompt2 assert len(choices) == 100 #\nrandomly pick from choices - we should have the odds we want now chat =\nChatOpenAI(model=\"gpt-3.5-turbo\") if random.choice(choices) == 'prompt1': r =\nchat.invoke(input=[SystemMessage(content=\"Always say left and nothing\nelse.\")]) else: r = chat.invoke(input=[SystemMessage(content=\"Always say right\nand nothing else.\")])\n\n    \n    \n    import random from langchain_openai import ChatOpenAI from langchain_core.messages import HumanMessage, SystemMessage choices = (['prompt1'] * 80) + (['prompt2'] * 20) # we should now have a list of 100 possible values - 80 are prompt1, 20 are prompt2 assert len(choices) == 100 # randomly pick from choices - we should have the odds we want now chat = ChatOpenAI(model=\"gpt-3.5-turbo\") if random.choice(choices) == 'prompt1': r = chat.invoke(input=[SystemMessage(content=\"Always say left and nothing else.\")]) else: r = chat.invoke(input=[SystemMessage(content=\"Always say right and nothing else.\")])\n\n## Conclusion\n\nHow does this help non-technical people who want to do these sorts of use\ncases or build Custom GPTs that reply with certain responses? Well it kind of\ndoesn\u2019t. I guess a technical-enough user could build a CustomGPT that uses\nfunction calling to decide how it should answer a question for a \u201cspot the\nmisinformation\u201d pop quiz type use case.\n\nHowever, my broad advice here is that you should be very wary of asking LLMs\nto behave with a certain likelihood unless you\u2019re able to control that\nlikelihood externally (via a script).\n\nWhat could I have done better here? I could have tried a few more different\nwords, different distributions (instead of 80/20) and maybe some keywords like\n\u201csometimes\u201d or \u201coccasionally\u201d.\n\nPrevious: Can Phi3 and Llama3 Do Biology?\n\n### Leave a Reply Cancel reply\n\n## Categories\n\n  * AI and Machine Learning\n  * Data Science\n  * Engineering Leadership\n  * Personal\n  * Philosophy and Thinking\n  * Software Development\n  * Tools for Thought\n  * Uncategorised\n\n## Quick Links\n\n  * About Me\n  * Digital Garden\n\njamesravey\n\n@jamesravey@brainsteam.co.uk\n\nCopyright \u00a9 James Ravenscroft 2023. All Rights Reserved.\n\nNotifications\n\n", "frontpage": true}
