{"aid": "40245852", "title": "How the CSI (Container Storage Interface) Works", "url": "https://sklar.rocks/how-container-storage-interface-works/", "domain": "sklar.rocks", "votes": 1, "user": "noctarius", "posted_at": "2024-05-03 09:48:39", "comments": 0, "source_title": "How the CSI (Container Storage Interface) Works", "source_text": "How the CSI (Container Storage Interface) Works\n\nsklar.rocks\n\n# How the CSI (Container Storage Interface) Works\n\n2024-01-12\n\n:: tags: #kubernetes\n\nIf you work with persistent storage in Kubernetes, maybe you've seen articles\nabout how to migrate from in-tree to CSI volumes, but aren't sure what all the\nfuss is about? Or perhaps you're trying to debug a stuck VolumeAttachment that\nwon't unmount from a node, holding up your important StatefulSet rollout? A\nclear understanding of what the Container Storage Interface (or CSI for short)\nis and how it works will give you confidence when dealing with persistent data\nin Kubernetes, allowing you to answer these questions and more!\n\nThe Container Storage Interface is an API specification that enables\ndevelopers to build custom drivers which handle the provisioning, attaching,\nand mounting of volumes in containerized workloads. As long as a driver\ncorrectly implements the CSI API spec, it can be used in any supported\nContainer Orchestration system, like Kubernetes. This decouples persistent\nstorage development efforts from core cluster management tooling, allowing for\nthe rapid development and iteration of storage drivers across the cloud native\necosystem.\n\nIn Kubernetes, the CSI has replaced legacy in-tree volumes with a more\nflexible means of managing storage mediums. Previously, in order to take\nadvantage of new storage types, one would have had to upgrade an entire\ncluster's Kubernetes version to access new PersistentVolume API fields for a\nnew storage type. But now, with the plethora of independent CSI drivers\navailable, you can add any type of underlying storage to your cluster\ninstantly, as long as there's a driver for it.\n\nBut what if existing drivers don't provide the features that you require and\nyou want to build a new custom driver? Maybe you're concerned about the\nramifications of migrating from in-tree to CSI volumes? Or, you simply want to\nlearn more about how persistent storage works in Kubernetes? Well, you're in\nthe right place! This article will describe what the CSI is and detail how\nit's implemented in Kubernetes.\n\n## It's APIs All the Way Down\n\nLike many things in the Kubernetes ecosystem, the Container Storage Interface\nis actually just an API specification. In the container-storage-interface/spec\nGitHub repo, you can find this spec in 2 different versions:\n\n  1. A protobuf file that defines the API schema in gRPC terms\n  2. A markdown file that describes the overall system architecture and goes into detail about each API call\n\nWhat I'm going to discuss in this section is an abridged version of that\nmarkdown file, while borrowing some nice ASCII diagrams from the repo itself!\n\n### Architecture\n\nA CSI Driver has 2 components, a Node Plugin and a Controller Plugin. The\nController Plugin is responsible for high-level volume management; creating,\ndeleting, attaching, detatching, snapshotting, and restoring physical (or\nvirtualized) volumes. If you're using a driver built for a cloud provider,\nlike EBS on AWS, the driver's Controller Plugin communicates with AWS HTTPS\nAPIs to perform these operations. For other storage types like NFS, EXSI, ZFS,\nand more, the driver sends these requests to the underlying storage's API\nendpoint, in whatever format that API accepts.\n\nOn the other hand, the Node Plugin is responsible for mounting and\nprovisioning a volume once it's been attached to a node. These low-level\noperations usually require privileged access, so the Node Plugin is installed\non every node in your cluster's data plane, wherever a volume could be\nmounted.\n\nThe Node Plugin is also responsible for reporting metrics like disk usage back\nto the Container Orchestration system (referred to as the \"CO\" in the spec).\nAs you might have guessed already, I'll be using Kubernetes as the CO in this\npost! But what makes the spec so powerful is that it can be used by any\ncontainer orchestration system, like Nomad for example, as long as it abides\nby the contract set by the API guidelines.\n\nThe specification doc provides a few possible deployment patterns, so let's\nstart with the most common one.\n\n    \n    \n    CO \"Master\" Host +-------------------------------------------+ | | | +------------+ +------------+ | | | CO | gRPC | Controller | | | | +-----------> Plugin | | | +------------+ +------------+ | | | +-------------------------------------------+ CO \"Node\" Host(s) +-------------------------------------------+ | | | +------------+ +------------+ | | | CO | gRPC | Node | | | | +-----------> Plugin | | | +------------+ +------------+ | | | +-------------------------------------------+ Figure 1: The Plugin runs on all nodes in the cluster: a centralized Controller Plugin is available on the CO master host and the Node Plugin is available on all of the CO Nodes.\n\nSince the Controller Plugin is concerned with higher-level volume operations,\nit does not need to run on a host in your cluster's data plane. For example,\nin AWS, the Controller makes AWS API calls like ec2:CreateVolume,\nec2:AttachVolume, or ec2:CreateSnapshot to manage EBS volumes. These functions\ncan be run anywhere, as long as the caller is authenticated with AWS. All the\nCO needs is to be able to send messages to the plugin over gRPC. So in this\narchitecture, the Controller Plugin is running on a \"master\" host in the\ncluster's control plane.\n\nOn the other hand, the Node Plugin must be running on a host in the cluster's\ndata plane. Once the Controller Plugin has done its job by attaching a volume\nto a node for a workload to use, the Node Plugin (running on that node) will\ntake over by mounting the volume to a well-known path and optionally\nformatting it. At this point, the CO is free to use that path as a volume\nmount when creating a new containerized process; so all data on that mount\nwill be stored on the underlying volume that was attached by the Controller\nPlugin. It's important to note that the Container Orchestrator, not the\nController Plugin, is responsible for letting the Node Plugin know that it\nshould perform the mount.\n\n### Volume Lifecycle\n\nThe spec provides a flowchart of basic volume operations, also in the form of\na cool ASCII diagram:\n\n    \n    \n    CreateVolume +------------+ DeleteVolume +------------->| CREATED +--------------+ | +---+----^---+ | | Controller | | Controller v +++ Publish | | Unpublish +++ |X| Volume | | Volume | | +-+ +---v----+---+ +-+ | NODE_READY | +---+----^---+ Node | | Node Publish | | Unpublish Volume | | Volume +---v----+---+ | PUBLISHED | +------------+ Figure 5: The lifecycle of a dynamically provisioned volume, from creation to destruction.\n\nMounting a volume is a synchronous process: each step requires the previous\none to have run successfully. For example, if a volume does not exist, how\ncould we possibly attach it to a node?\n\nWhen publishing (mounting) a volume for use by a workload, the Node Plugin\nfirst requires that the Controller Plugin has successfully published a volume\nat a directory that it can access. In practice, this usually means that the\nController Plugin has created the volume and attached it to a node. Now that\nthe volume is attached, it's time for the Node Plugin to do its job. At this\npoint, the Node Plugin can access the volume at its device path to create a\nfilesystem and mount it to a directory. Once it's mounted, the volume is\nconsidered to be published and it is ready for a containerized process to use.\nThis ends the CSI mounting workflow.\n\nContinuing the AWS example, when the Controller Plugin publishes a volume, it\ncalls ec2:CreateVolume followed by ec2:AttachVolume. These two API calls\nallocate the underlying storage by creating an EBS volume and attaching it to\na particular instance. Once the volume is attached to the EC2 instance, the\nNode Plugin is free to format it and create a mount point on its host's\nfilesystem.\n\nHere is an annotated version of the above volume lifecycle diagram, this time\nwith the AWS calls included in the flow chart.\n\n    \n    \n    CreateVolume +------------+ DeleteVolume +------------->| CREATED +--------------+ | +---+----^---+ | | Controller | | Controller v +++ Publish | | Unpublish +++ |X| Volume | | Volume | | +-+ | | +-+ | | <ec2:CreateVolume> | | <ec2:DeleteVolume> | | <ec2:AttachVolume> | | <ec2:DetachVolume> | | +---v----+---+ | NODE_READY | +---+----^---+ Node | | Node Publish | | Unpublish Volume | | Volume +---v----+---+ | PUBLISHED | +------------+\n\nIf a Controller wants to delete a volume, it must first wait for the Node\nPlugin to safely unmount the volume to preserve data and system integrity.\nOtherwise, if a volume is forcibly detatched from a node before unmounting it,\nwe could experience bad things like data corruption. Once the volume is safely\nunpublished (unmounted) by the Node Plugin, the Controller Plugin would then\ncall ec2:DetachVolume to detatch it from the node and finally ec2:DeleteVolume\nto delete it, assuming that the you don't want to reuse the volume elsewhere.\n\nWhat makes the CSI so powerful is that it does not prescribe how to publish a\nvolume. As long as your driver correctly implements the required API methods\ndefined in the CSI spec, it will be compatible with the CSI and by extension,\nbe usable in COs like Kubernetes and Nomad.\n\n## Running CSI Drivers in Kubernetes\n\nWhat I haven't entirely make clear yet is why the Controller and Node Plugins\nare plugins themselves! How does the Container Orchestrator call them, and\nwhere do they plug into?\n\nWell, the answer depends on which Container Orchestrator you are using. Since\nI'm most familiar with Kubernetes, I'll be using it to demonstrate how a CSI\ndriver interacts with a CO.\n\n### Deployment Model\n\nSince the Node Plugin, responsible for low-level volume operations, must be\nrunning on every node in your data plane, it is typically installed using a\nDaemonSet. If you have heterogeneous nodes and only want to deploy the plugin\nto a subset of them, you can use node selectors, affinities, or anti-\naffinities to control which nodes receive a Node Plugin Pod. Since the Node\nPlugin requires root access to modify host volumes and mounts, these Pods will\nbe running in privileged mode. In this mode, the Node Plugin can escape its\ncontainer's security context to access the underlying node's filesystem when\nperforming mounting and provisioning operations. Without these elevated\npermissions, the Node Plugin could only operate inside of its own\ncontainerized namespace without the system-level access that it requires to\nprovision volumes on the node.\n\nThe Controller Plugin is usually run in a Deployment because it deals with\nhigher-level primitives like volumes and snapshots, which don't require\nfilesystem access to every single node in the cluster. Again, lets think about\nthe AWS example I used earlier. If the Controller Plugin is just making AWS\nAPI calls to manage volumes and snapshots, why would it need access to a\nnode's root filesystem? Most Controller Plugins are stateless and highly-\navailable, both of which lend themselves to the Deployment model. The\nController also does not need to be run in a privileged context.\n\n### Event-Driven Sidecar Pattern\n\nNow that we know how CSI plugins are deployed in a typical cluster, it's time\nto focus on how Kubernetes calls each plugin to perform CSI-related\noperations. A series of sidecar containers, that are registered with the\nKubernetes API server to react to different events across the cluster, are\ndeployed alongside each Controller and Node Plugin. In a way, this is similar\nto the typical Kubernetes controller pattern, where controllers react to\nchanges in cluster state and attempt to reconcile the current cluster state\nwith the desired one.\n\nThere are currently 6 different sidecars that work alongside each CSI driver\nto perform specific volume-related operations. Each sidecar registers itself\nwith the Kubernetes API server and watches for changes in a specific resource\ntype. Once the sidecar has detected a change that it must act upon, it calls\nthe relevant plugin with one or more API calls from the CSI specification to\nperform the desired operations.\n\n#### Controller Plugin Sidecars\n\nHere is a table of the sidecars that run alongside a Controller Plugin:\n\nSidecar Name| K8s Resources Watched| CSI API Endpoints Called  \n---|---|---  \nexternal-provisioner| PersistentVolumeClaim| CreateVolume,DeleteVolume  \nexternal-attacher| VolumeAttachment| Controller(Un)PublishVolume  \nexternal-snapshotter| VolumeSnapshot(Content)| CreateSnapshot,DeleteSnapshot  \nexternal-resizer| PersistentVolumeClaim| ControllerExpandVolume  \n  \nHow do these sidecars work together? Let's use an example of a StatefulSet to\ndemonstrate. In this example, we're dynamically provisioning our\nPersistentVolumes (PVs) instead of mapping PersistentVolumeClaims (PVCs) to\nexisting PVs. We start at the creation of a new StatefulSet with a\nVolumeClaimTemplate.\n\n    \n    \n    --- apiVersion: apps/v1 kind: StatefulSet spec: volumeClaimTemplates: - metadata: name: www spec: accessModes: [ \"ReadWriteOnce\" ] storageClassName: \"my-storage-class\" resources: requests: storage: 1Gi\n\nCreating this StatefulSet will trigger the creation of a new PVC based on the\nabove template. Once the PVC has been created, the Kubernetes API will notify\nthe external-provisioner sidecar that this new resource was created. The\nexternal-provisioner will then send a CreateVolume message to its neighbor\nController Plugin over gRPC. From here, the CSI driver's Controller Plugin\ntakes over by processing the incoming gRPC message and will create a new\nvolume based on its custom logic. In the AWS EBS driver, this would be an\nec2:CreateVolume call.\n\nAt this point, the control flow moves to the built-in PersistentVolume\ncontroller, which will create a matching PV and bind it to the PVC. This\nallows the StatefulSet's underlying Pod to be scheduled and assigned to a\nNode.\n\nHere, the external-attacher sidecar takes over. It will be notified of the new\nPV and call the Controller Plugin's ControllerPublishVolume endpoint, mounting\nthe volume to the StatefulSet's assigned node. This would be the equivalent to\nec2:AttachVolume in AWS.\n\nAt this point, we have an EBS volume that is mounted to an EC2 instance, all\nbased on the creation of a StatefulSet, PersistentVolumeClaim, and the work of\nthe AWS EBS CSI Controller Plugin.\n\n#### Node Plugin Sidecars\n\nThere is only one unique sidecar that is deployed alongside the Node Plugin;\nthe node-driver-registrar. This sidecar, running as part of a DaemonSet,\nregisters the Node Plugin with a Node's kubelet. During the registration\nprocess, the Node Plugin will inform the kubelet that it is able to mount\nvolumes using the CSI driver that it is part of. The kubelet itself will then\nwait until a Pod is scheduled to its corresponding Node, at which point it is\nthen responsible for making the relevant CSI calls (PublishVolume) to the Node\nPlugin over gRPC.\n\n#### Common Sidecars\n\nThere is also a livenessprobe sidecar that runs in both the Container and Node\nPlugin Pods that monitors the health of the CSI driver and reports back to the\nKubernetes Liveness Probe mechanism.\n\n### Communication Over Sockets\n\nHow do these sidecars communicate with the Controller and Node Plugins? Over\ngRPC through a shared socket! So each sidecar and plugin contains a volume\nmount pointing to a single unix socket.\n\nThis diagram highlights the pluggable nature of CSI Drivers. To replace one\ndriver with another, all you have to do is simply swap the CSI Driver\ncontainer with another and ensure that it's listening to the unix socket that\nthe sidecars are sending gRPC messages to. Becase all drivers advertise their\nown different capabilities and communicate over the shared CSI API contract,\nit's literally a plug-and-play solution.\n\n## Conclusion\n\nIn this article, I only covered the high-level concepts of the Container\nStorage Interface spec and implementation in Kubernetes. While hopefully it\nhas provided a clearer understanding of what happens once you install a CSI\ndriver, writing one requires significant low-level knowledge of both your\nnodes' operating system(s) and the underlying storage mechanism that your\ndriver is implementing. Luckily, CSI drivers exist for a variety of cloud\nproviders and distributed storage solutions, so it's likely that you can find\na CSI driver that already fulfills your requirements. But it always helps to\nknow what's happening under the hood in case your particular driver is\nmisbehaving.\n\nIf this article interests you and you want to learn more about the topic,\nplease let me know! I'm always happy to answer questions about CSI Drivers,\nKubernetes Operators, and a myriad of other DevOps-related topics.\n\nOlder posts\n\n\u2190 What Are Kubernetes Operators? (Operators 101: Part 1) An Introduction to\nCustom Resource Definitions and Custom Resources (Operators 101: Part 2) \u2192\n\n\u00a9 2024 Steven Sklar :: Theme: Terminimal by pawroman\n\n", "frontpage": false}
