{"aid": "40069975", "title": "Postgres vs. Pinecone: For vector search, easy isn't so easy", "url": "https://www.pinecone.io/blog/pinecone-vs-pgvector/", "domain": "pinecone.io", "votes": 2, "user": "gk1", "posted_at": "2024-04-17 20:56:24", "comments": 0, "source_title": "Pinecone vs. Postgres pgvector: For vector search, easy isn\u2019t so easy | Pinecone", "source_text": "Pinecone vs. Postgres pgvector: For vector search, easy isn\u2019t so easy | Pinecone\n\nOpens in a new window Opens an external website Opens an external website in a\nnew window\n\nThis website utilizes technologies such as cookies to enable essential site\nfunctionality, as well as for analytics, personalization, and targeted\nadvertising purposes. You may change your settings at any time or accept the\ndefault settings. You may close this banner to continue with only essential\ncookies. Cookie Policy\n\nAnnouncementNew serverless free plan with 3x capacityLearn more\n\nBlog\n\n# Pinecone vs. Postgres pgvector: For vector search, easy isn\u2019t so easy\n\nApr 17, 2024 - in Engineering\n\nDave Rigby\n\nStaff Software Engineer\n\nJanum Shah\n\nSoftware Engineer\n\nRam Sriharsha\n\nCTO\n\nOver the past several months, people have come to Pinecone after trying and\nfailing with pgvector and other bolt-on vector databases. One common line of\nthought is: I already have Postgres to store stuff, so why not use it for\nvector search too? This line of thought seems reasonable at first, but there\nare much better approaches than this if you want to build a successful Gen AI\napplication.\n\nWhen we investigated why people choose pgvector initially and then switched to\nPinecone, one thing that struck us was how little experimentation went into\nselecting a database. Instead of evaluating quality first, then simplicity and\nease, many users do the opposite. They start using pgvector and other bolt-on\nsolutions out of convenience. But they soon run into complexities and need\nhelp to achieve high-quality searches. Thus, they reach out to Pinecone, as\nthe importance of prioritizing quality first, then simplicity becomes evident.\nThey realize that their database needs to provide high search quality to be\nuseful for their Gen AI applications. If they\u2019re tweaking their databases,\nthen that is valuable time they are not spending on building and optimizing\ntheir products. And that is detrimental, especially in a fast-moving space\nlike GenAI.\n\nWhen it comes to vector search, easy is far from simple: vector databases are\nfundamentally different from traditional databases and document stores, and\nthinking of vectors as just another type in a Postgres database will not\nresult in a performant solution. Such an attempt defeats the purpose of\nchoosing Postgres in the first place. You will introduce significant\ncomplexity even for small and medium workloads for a perceived ease.\n\nConsider one example customer: Notion uses Pinecone to power Notion AI,\nthrough which their users continuously create, update, search, and delete\nvectors in Pinecone. Their users\u2019 usage patterns are highly variable: Some\nusers update their content frequently, others infrequently; some query often,\nand others only periodically. It is difficult to tune and tweak knobs on\npgvector even for predictable, uniform workloads... doing so for highly\nvariable usage patterns across many tenants is nearly impossible.\n\nMoreover, not only does Notion have these strict requirements and large,\nhighly variable workloads, but they also can\u2019t waste time and effort tuning\nand tweaking knobs, changing resources, and hand-holding their vector\ndatabase. It would be an expensive operational burden and unrealistic for\nthem.\n\n## AI applications require a purpose-built vector database\n\nPostgres is a capable solution for many storage use cases and powers many\nservices and products. But, it is often not the right choice for vector\nsearch. In this article, we will examine the architecture of SQL databases\nlike Postgres, how they have bolted-on vector search on top of their core\narchitecture, and why it adds significant operational overheads even for small\nto medium workloads. We will contrast it with how Pinecone makes it easy to\nscale vector search by providing low-cost ramp-up, an intuitive UX, and high-\nquality results with zero hand-holding. Pinecone is purpose-built for powerful\nvector search, which means that it scales with your workloads seamlessly for a\nfraction of the cost of other bolt-on solutions, which is why customers like\nNotion choose Pinecone.\n\n## PostgreSQL and pgvector: A Brief Overview\n\nPostgreSQL is a mature and feature-rich Open-Source SQL database, in wide use.\nIt has a powerful extensions API which allows additional functionality to be\nadded to it. One such extension is pgvector, which introduces a new data type\nand module (vector) and allows users to query this data type, and build vector\nindexes.\n\nThe vector indexes themselves are one of two types:\n\n  * HNSW, based on the popular graph index. We\u2019ve written about HNSW before, check it out here.\n  * IVF-Flat, which is a clustering based index. While IVF-Flat is available in Postgres, it is not useful for many applications as it cannot handle data drift. Every time your data changes, you will either need to fully rebuild this clustering index (an expensive operation), or live with degraded search quality due to the index partitions being stale. We will demonstrate this in our benchmarks, and for this reason we will only discuss the HNSW index in this blog post. That said, the broader conclusions will still hold as to why we think pgvector fundamentally cannot handle vector search well even for small to moderate workloads.\n\nDuring writes (to either type of index), pgvector maintains a working set of\nthe index in memory. The working set memory is controlled by the parameter:\nmaintenance_work_mem\n\n## Experimenting with pgvector\n\nWe went through a series of various experiments on pgvector to see how the\narchitectural limitations of Postgres have a practical impact on vector\nworkloads. Below, we will go through our findings from a series of experiments\non Postgres, using the following four datasets (available via Pinecone Public\nDatasets):\n\n  * mnist: 60k record dataset consisting of images of handwritten digits.\n  * nq-768-tasb: 2.6M record dataset of natural language questions.\n  * yfcc: 10M record dataset taken from Yahoo-Flicker Creative Commons image set embedded with CLIP (as used by big-ANN)\n  * cohere: 10M record dataset of en-wikipedia embedded using Cohere-768\n\n### Index Building\n\nLet\u2019s start with the first thing one must do for a vector search workload:\nbuild an index. Using the Cohere-768 dataset (10 million 768-dimensional\nvectors), we provisioned a 64 GB RAM VM (more than the total index size), and\nthen, with various subsets of vector counts, we measure the amount of RAM\nactually used when building the HNSW index:\n\nWe see that the amount of RAM needed to build an index scales as the dataset\ndoes. For Cohere-768, we consistently need RAM proportional to the dataset\nsize, specifically 1.2x of the entire dataset to build the index.\n\nWe only found this relationship after over-provisioning the RAM needed for\nthis dataset, which we also knew the exact size of. What happens if you don\u2019t\nknow the exact size of the workload beforehand, as with most production\nworkloads? And even if you do, what happens if you don\u2019t want to massively\noverprovision the amount of RAM you need for pgvector?\n\nFor this modest dataset (28.6GiB) the required amount of RAM (35 GiB) is\nreadily available on typical instances, but for a dataset 2x, 4x or 10x\nlarger, provisioning such instances becomes very costly. Compare this to\nPinecone Serverless, where the resources needed to build the index are not the\nuser\u2019s concern \u2014 you pay only for the writes to upsert the data and the total\nspace used.\n\nNote that pgvector can page out to disk if RAM is exceeded, which suggests we\ndon\u2019t necessarily have to scale our machines\u2019 RAM as dataset size increases.\nHowever, in practical terms, the impact on index build time is significant.\nHere we re-run the same experiment as above, but with Postgres running on a\nsmaller machine, with the amount of memory available for index build\n(maintenance_work_mem) set to 16GB. We measure the time taken to index the\ndifferent dataset sizes:\n\nWhen the HNSW index can fit entirely in RAM (<16GB) we see reasonably constant\nindex build throughput around 10 MiB/s, however once the index exceeds RAM the\nbuild throughput drops precipitously \u2014 over 10x slower. This is because the\nHNSW graph has exceeded the working memory, and needs to spill to disk to\ncontinue to build the index. As such it\u2019s not feasible to rely on Postgres\u2019s\nability to page from disk during index builds and maintain quick build times.\n\nSimilar behavior is seen when incrementally updating an existing index. As\nlong as the graph can fit into memory, updates are relatively fast as they\ndon\u2019t require waiting for disk. But, if the index starts exceeding the working\nset memory, then parts of the index need to be read back from disk before they\nare modified, and update rate drops by an order of magnitude.\n\nThe consequence of this is often an unexpected performance drop when the\ndataset grows past this critical point. That is, you could build an\napplication with pgvector and achieve your target query latency, then\ngradually add more data, and when the index no longer fits in RAM and query\nlatency suddenly increases by 10x. Postgres + pgvector does not seem so simple\nanymore: now you need to start resizing your resources, and in some cases even\nsharding your database, since you might not have enough RAM to allocate to\nhold the entire dataset.\n\nPinecone avoids these problems. With a Serverless index you can simply keep on\nadding more and more data and query latency stays fast; there\u2019s no index RAM\nsizing to worry about.\n\n### Index size estimation\n\nWe explored the memory needed for different sized samples of the same dataset\n(Cohere-768) above, but what about different datasets? Given the importance of\nensuring the index fits in RAM, how does one accurately predict how much RAM\nwill be required to build the index for a given workload?\n\nHere we measure the index RAM / dataset ratio to build an index for 4\ndifferent datasets \u2014 mnist, nq-768-tasb, yfcc and cohere \u2014 how much actual RAM\nis needed to represent the index compared to the input dataset size:\n\nThe \u201cexpansion factor\u201d \u2014 the ratio of the index RAM to the original dataset \u2014\nvaries significantly across the different datasets. The largest expansion is\nfor mnist and yfcc; where the index is over 5x larger than the raw data.\n\nThis is counterintuitive: there is no simple way to figure out how to size the\nindex\u2019s working set memory, and the consequences of getting this wrong are\nsignificant.\n\nWe are just talking about small datasets here. In comparison, Pinecone\nroutinely handles billion scale datasets without customers even having to\nthink about them.\n\nThis presents another sizing dimension when using pgvector: you cannot easily\npredict the size of the vector index (and hence the amount of RAM to be\nprovisioned) without analyzing the dataset itself.\n\nPinecone serverless avoids this concern; you can upload and query datasets of\nany size, without having to think about node sizes or counts. You\u2019re just\ncharged based on the amount of data stored.\n\n### HNSW and Metadata filtering\n\nWe also explored an experiment with another common use case in vector\ndatabases: metadata filtering.\n\nMetadata filtering is a powerful technique to improve the relevance of vector\nsearch by specifying additional predicates to match the queried vectors\nagainst. In this experiment, we again use the yfcc-10mm dataset, which\nconsists of images which have been embedded with the CLIP model; along with a\n\u201cbag\u201d of tags extracted from the description, camera model, year of capture\nand country. A search is performed specifying an image embedding, plus one or\ntwo tags to constrain the search space. Our objective is to achieve high\nquality recall (\u2265 80%) with latency suitable for a real-time application \u2014\n200ms or lower, which is realistic for many production applications.\n\nAfter loading yfcc-10mm, we started trying to submit some queries. At a basic\nlevel, PostgreSQL + pgvector supports metadata filtering as a simple WHERE\nclause added to the SELECT statement. However, this is only post-filtering,\nmeaning the results are filtered after the search occurs. For all practical\npurposes, this is unusable, since there\u2019s no guarantee about the number of\nresults that are returned. For example, if we just examine the 3rd query from\nthe queries set, zero results are returned instead of the desired 10:\n\n    \n    \n    SELECT id, embedding FROM yfcc_10m WHERE metadata @> '{\"tags\": [\"108757\"]}' ORDER BY embedding <-> '[...]' LIMIT 10; ... (0 rows)\n\nIf we use EXPLAIN ANALYZE against the query, we can see how the query planner\nhas constructed the query to help us understand the behavior we are seeing:\n\n    \n    \n    EXPLAIN ANALYZE SELECT id, embedding FROM yfcc_10m WHERE metadata @> '{\"tags\": [\"108757\"]}' ORDER BY embedding <-> '[...]' LIMIT 10; Limit (cost=64.84..3298.63 rows=10 width=791) (actual time=1.111..1.111 rows=0 loops=1) -> Index Scan using yfcc_10m_embedding_idx on yfcc_10m (cost=64.84..32337942.84 rows=100000 width=791) (actual time=1.110..1.110 rows=0 loops=1) Order By: (embedding <-> '[...]'::vector) Filter: ((metadata -> 'tags'::text) @> '\"108757\"'::jsonb) Rows Removed by Filter: 41 Planning Time: 0.075 ms Execution Time: 1.130 ms\n\nReading from bottom to top, we see Postgres first performs an Index Scan using\nthe HNSW index (yfcc_10m_embedding_idx), then filters by the specified\npredicate; however, that discards all rows as none matched.\n\nIncreasing the candidates search count (hnsw.ef_search) from the default (40)\nto the maximum value (1000) manages to increase the number of found records\nfrom 0 to 1, but 9 of the requested 10 are still not returned.\n\nThis is a known issue with pgvector \u2014 see pgvector issue #263 and issue #259.\nThe crux of these issues is that pgvector\u2019s HNSW implementation does not have\nsupport for metadata filtering as part of the index itself. While one can\nbuild partitioned HNSW indexes, this isn\u2019t practical when the cardinality of\nthe predicate being used is high. In the case of yfcc-10mm, there are over\n200,000 possible tags, so we would need to build and maintain 200,000 indexes\nif partitioning was utilized!\n\nWhat we want is pre-filtering, meaning the corpus is filtered first and then\nthe search occurs, returning the top_k nearest neighbors that match the\nfilter. This is the only way to guarantee that we actually get top_k results\nevery time.\n\nPostgres offers another solution for this problem. For this kind of highly\nselective query, there is another index type provided: Generalized Inverted\nIndex (GIN). This index type can be used to index semi-structured data like\nthe sets of tags we have here, allowing Postgres to efficiently identify\nmatching documents first (i.e. pre-filtering), and then calculating vector\ndistances of the (hopefully small) remaining candidates.\n\nSo, we create a GIN index on the metadata field via:\n\n    \n    \n    postgres=# CREATE INDEX ON yfcc_10M USING gin (metadata);\n\nThe addition of the GIN index does improve results for some queries - the\nabove query now uses the metadata index first; then performs an exhaustive kNN\nsearch on the matching rows. This results in recall increasing from 0% of\n100%, with a query latency of 3.3ms; still well within our 200ms requirement:\n\n    \n    \n    EXPLAIN ANALYZE SELECT id, embedding FROM yfcc_10m WHERE metadata @> '{\"tags\": [\"108757\"]}' ORDER BY embedding <-> '[...]' LIMIT 10; Limit (cost=3718.63..3718.66 rows=10 width=791) (actual time=3.232..3.235 rows=10 loops=1) -> Sort (cost=3718.63..3720.95 rows=929 width=791) (actual time=3.231..3.232 rows=10 loops=1) Sort Key: ((embedding <-> '[...]'::vector)) Sort Method: top-N heapsort Memory: 42kB -> Bitmap Heap Scan on yfcc_10m (cost=43.44..3698.56 rows=929 width=791) (actual time=2.892..3.187 rows=148 loops=1) Recheck Cond: (metadata @> '{\"tags\": [\"108757\"]}'::jsonb) Heap Blocks: exact=138 -> Bitmap Index Scan on yfcc_10m_metadata_idx (cost=0.00..43.20 rows=929 width=0) (actual time=2.868..2.868 rows=148 loops=1) Index Cond: (metadata @> '{\"tags\": [\"108757\"]}'::jsonb) Planning Time: 0.172 ms Execution Time: 3.258 ms (11 rows)\n\nWe see here that the pre-filtering via the metadata index (Bitmap Index Scan)\nidentified the 148 rows which matched the predicate in 3.187ms, calculating\nthe distance to those small number of vectors and sorting the top 10 is fast,\ntaking 0.05ms.\n\nHowever, this isn\u2019t the case for all queries. For example another query, while\nappearing similar, only results in a recall of 50% because the GIN metadata\nindex was not consulted and only the HNSW index was used:\n\n    \n    \n    SELECT id, embedding FROM yfcc_10M WHERE metadata @> '{\"tags\": [\"1225\"]}' ORDER BY embedding <-> '[135.0, 82.0, 151.0, ..., 126.0]' LIMIT 10; ... (5 rows)\n    \n    \n    EXPLAIN ANALYZE SELECT id, embedding FROM yfcc_10M WHERE metadata @> '{\"tags\": [\"1225\"]}' ORDER BY embedding <-> '[...]' LIMIT 10; QUERY PLAN Limit (cost=64.84..3508.90 rows=10 width=791) (actual time=14.743..15.452 rows=5 loops=1) -> Index Scan using yfcc_10m_embedding_idx on yfcc_10m (cost=64.84..32312927.39 rows=93822 width=791) (actual time=14.742..15.449 rows=5 loops=1) Order By: (embedding <-> '[...]'::vector) Filter: (metadata @> '{\"tags\": [\"1225\"]}'::jsonb) Rows Removed by Filter: 1044 Planning Time: 0.174 ms Execution Time: 15.474 ms (7 rows)\n\nIn another instance, the query planner didn\u2019t use the HNSW index at all,\nresulting in a very slow (3.8s) query due to it performing a full table scan\n(\u201cParallel Seq Scan\u201d):\n\n    \n    \n    EXPLAIN ANALYZE SELECT id, embedding FROM yfcc_10M WHERE metadata @> '{\"tags\": [\"3432\"]}' AND metadata @> '{\"tags\": [\"3075\"]}' ORDER BY embedding <-> '[...]' LIMIT 10; QUERY PLAN Limit (cost=1352639.11..1352639.12 rows=1 width=791) (actual time=3786.265..3792.470 rows=10 loops=1) -> Sort (cost=1352639.11..1352639.12 rows=1 width=791) (actual time=3730.084..3736.288 rows=10 loops=1) Sort Key: ((embedding <-> '[...]'::vector)) Sort Method: top-N heapsort Memory: 43kB -> Gather (cost=1000.00..1352639.10 rows=1 width=791) (actual time=4.756..3734.891 rows=2259 loops=1) Workers Planned: 2 Workers Launched: 2 -> Parallel Seq Scan on yfcc_10m (cost=0.00..1351639.00 rows=1 width=791) (actual time=113.590..3711.979 rows=753 loops=3) Filter: ((metadata @> '{\"tags\": [\"3432\"]}'::jsonb) AND (metadata @> '{\"tags\": [\"3075\"]}'::jsonb)) Rows Removed by Filter: 3332580 Planning Time: 0.250 ms Execution Time: 3792.897 ms (16 rows) Time: 3793.678 ms (00:03.794)\n\nIt\u2019s not clear why the query planner decides to use or not use a particular\nindex, and the choice can vary across what appear to be similar queries. In\nshort: Getting consistent, high quality results with low latency can require\nextensive tuning of the database and its indexes. And even then, it might not\nbe possible. With Pinecone, you can expect high quality results with a small\nfraction of the latency without any tuning.\n\nOur initial objective was 200ms latency and at least 80% p95 recall. Note that\npgvector cannot achieve this object for even half of the queries (p50), let\nalone the vast majority of queries (p95):\n\nIn comparison, Pinecone Serverless achieves this target with zero tuning at\nboth p50 and p95, out of the box. For any non-trivial workload that requires\nfiltering, it\u2019s impractical to rely on Postgres, regardless of the tuning and\nsetup.\n\n### IVF-Flat and data drift\n\nWe mentioned earlier that pgvector offers another type of index: IVF-Flat.\nThis is appealing because the memory requirements are often much lower than\nHNSW, sometimes as low as 1/10th. However, because of its architecture, IVF-\nFlat doesn\u2019t handle \u201cdrift\u201d well. That is, changes or updates after the index\nis initially built will become problematic for IVF-Flat indexes.\n\nConsider two basic workloads:\n\n  1. All data from a dataset is populated, then the vector index is built. This is what we\u2019ll refer to as the Baseline workload.\n  2. Only a portion of the dataset is inserted. For experimentation purposes, this portion is strictly only the set of vectors which never appear in the ground truth top-k of the queries dataset (that is, recall would just be 0). After inserting this portion, we build the index. Then, we load the remaining portion of the dataset, hoping to improve recall. This is a Drift workload.\n\nFor each workload, we built the IVF-Flat index with the recommended\nconfiguration (lists = rows / 1000 for up to 1M rows and sqrt(rows) for over\n1M rows). Query parameter (ivfflat.probes) is set to the largest value which\nresults in p95 query latency under 100ms. We then measured the recall of the\nbaseline workload vs the drift workload):\n\nWe can see that across the datasets, pgvector\u2019s recall drops when the dataset\nhas drifted since the initial IVF-Flat partitions were created. In a practical\nsense, this means that, unless you have the exact data you want to upload, and\nyou never update that data, IVF-Flat indexes will not be able to support your\napplication. In fact, even if you do have all the data and never update it,\nyour recall will still not be as high in Postgres as in Pinecone:\n\nFor Pinecone Serverless, we get high recall to begin with, and even after\ndrift, we maintain that high recall. It\u2019s not realistic to expect that\ncustomers have static data, which is why we built Pinecone to support these\nuse cases.\n\n### Cost\n\nWe\u2019ve looked at various metrics relating to quality, since the goal of this\npost was the focus on experience and the architectural limitations of using\nPostgres, as well as how we built Pinecone to mitigate these headaches and\nsolve the bottlenecks. At the same time, though, we also want to offer an\naffordable solution with pay-as-you-go pricing that scales for customers as\nthey grow. So: what are the basic cost comparisons of these various workloads?\nHere we model the cost per month to perform a given workload pattern on each\ndataset:\n\n  * Upsert the entire dataset\n  * Perform, on average, 10 queries per minute\n  * Modify 10% of the dataset every month\n\nFor Pinecone, the cost is estimated using the Pinecone's cost estimator, for\npgvector it is the monthly cost of the EC2 instance needed to run the workload\nat <100ms p95 query latency, plus the EBS cost.\n\nCosts will vary for different workloads, but here we see that Pinecone\nServerless is cheaper for the four tested datasets - even including the one-\noff initial upsert cost \u2014 by a factor of 1.1x\u20132.2x. If we only consider the\nongoing monthly cost then the cost difference is even more significant:\nbetween 1.5x and 2.9x lower. These are, in fact, relatively small workloads\nfor the scale that Pinecone can handle.\n\nThis doesn\u2019t even include the cost of maintaining the Postgres database, high\navailability and other aspects of managed databases that dramatically reduce\nthe overhead of maintaining and operating these databases \u2014 all of which is\nprovided out of the box by Pinecone.\n\nWe understand that all workloads look different \u2013 so we\u2019d encourage you to\ntest out Pinecone for yourself.\n\nShare via:\n\n#### Further Reading\n\nFree plan gets 3x more capacity with serverless upgrade\n\nIntroducing the Pinecone Partner Program: Integrate and Grow with Pinecone\n\nSixfold's Transformation of Insurance Underwriting with Pinecone\n\nDave Rigby\n\nStaff Software Engineer\n\nJanum Shah\n\nSoftware Engineer\n\nRam Sriharsha\n\nCTO\n\n  * AI applications require a purpose-built vector database\n  * PostgreSQL and pgvector: A Brief Overview\n  * Experimenting with pgvector\n\nShare via:\n\n## What will you build?\n\nUpgrade your search or chatbots applications with just a few lines of code.\n\nSign up for freeContact Sales\n\nProduct\n\nOverviewDocumentationIntegrationsTrust and SecurityWhat is a Vector Database?\n\nSolutions\n\nCustomersRAGSemantic SearchMulti-Modal SearchCandidate\nGenerationClassification\n\nResources\n\nLearning CenterCommunityPinecone BlogSupport CenterSystem Status\n\nCompany\n\nAboutPartnersCareersNewsroomContact\n\nLegal\n\nTermsPrivacyCookiesCookie Preferences\n\n\u00a9 Pinecone Systems, Inc. | San Francisco, CA\n\nPinecone is a registered trademark of Pinecone Systems, Inc.\n\n", "frontpage": false}
