{"aid": "40199118", "title": "Tiered storage won't fix Kafka", "url": "https://www.warpstream.com/blog/tiered-storage-wont-fix-kafka", "domain": "warpstream.com", "votes": 39, "user": "itunpredictable", "posted_at": "2024-04-29 14:54:38", "comments": 10, "source_title": "Tiered Storage Won\u2019t Fix Kafka", "source_text": "Tiered Storage Won\u2019t Fix Kafka - WarpStream - Stream More, Manage Less\n\nBook a DemoConsoleGet started\n\nEngineering\n\n# Tiered Storage Won\u2019t Fix Kafka\n\nApr 28, 2024\n\nRichie\n\nLink copied!\n\nReturn To Blog\n\nCloud Disks are (Really!) Expensive\n\n## Tiered Storage Seems Like a Good Idea\n\nTiered storage is a hot topic in the world of data streaming systems, and for\ngood reason. Cloud disks are (really) expensive, object storage is cheap, and\nin most cases, live consumers are just reading the most recently written data.\nPaying for expensive cloud disks to store historical data isn\u2019t cost-\neffective, so historical data should be moved (tiered) to object storage. On\npaper, it makes all the sense in the world.\n\nBut first, what exactly does tiered storage mean in the context of a streaming\nsystem? The basic idea is to only persist recent data to disk, and\nasynchronously move historical data to object storage where it can rest\ncheaply.\n\nTiered storage in action.\n\nThis optimization is particularly useful in scenarios where the primary\nscaling dimension for Kafka is storage, for example when you need long topic\nretention. In those scenarios, tiered storage can (sometimes dramatically)\nreduce the number of required EBS volumes, which will (sometimes dramatically)\nreduce your costs.\n\nIn theory, tiered storage should also ease operational burden by reducing the\namount of data stored on each broker\u2019s local disk, which (among other\nbenefits) should make scaling the cluster in and out faster. Some particularly\nenthusiastic users are even optimistic that taken to its logical conclusion,\ntiered storage could turn Kafka into a modern data lake.\n\nThe excitement around the addition of tiered storage in Apache Kafka is\npalpable, most likely because there has been very little innovation in the\nKafka space for the last few years, but users are still frustrated with the\nstatus quo in terms of cost, complexity, and operational burden. Could tiered\nstorage be the silver bullet that everyone\u2019s been waiting for?\n\nUnfortunately, the answer seems to be no. I have talked to hundreds of Kafka\n(and other streaming systems) users in the last year, many at the largest and\nmost advanced engineering organizations in the world, and I have yet to find a\nsingle happy and satisfied tiered storage user.\n\nWhat I did find was many people who evaluated it, realized it wouldn\u2019t reduce\ntheir costs very much, and moved on. I also found some people who tried to\nadopt it, ran into a number of operational issues and friction points, and\ndecided it wasn\u2019t worth it. I even found a few people who managed to get into\nproduction with it, but they had a lot of extra gray hairs to show for it, and\nalmost all of them were underwhelmed with the end result.\n\nI realize that everything I'm saying runs contrary to popular sentiment in the\nindustry, so let me explain how I got here.\n\n## The Tarpit\n\nTiered storage can reduce costs for some workloads, but it ends up doing so in\na way that is penny wise and pound foolish. Specifically, the main issue with\ntiered storage is that it doesn\u2019t address the two primary problems that people\nactually have with Kafka today:\n\n  1. Complexity and Operational Burden\n  2. Costs (specifically, inter-zone networking fees)\n\nIn fact I\u2019ll argue that it doesn\u2019t just not solve these problems, it actually\nmakes them worse.\n\n## Increased Complexity and Operational Burden\n\nThe first problem with tiered storage is that instead of making Kafka simpler\nand easier to deal with, it actually makes it more difficult and more\ncomplicated. Retrofitting an existing system like Apache Kafka to account for\nthe fact that some portion of the data is stored in a completely different\nstorage medium, with completely different cost and performance\ncharacteristics, is incredibly complex. The end result is a finicky and\nbrittle system with a never-ending series of limitations, sharp edges, and\ngotchas.\n\nFor example, reasoning about performance becomes incredibly difficult.\nConsider a Kafka consumer that wants to read a topic from the beginning. In\nnormal circumstances, fetching a batch of records from Kafka should only take\ntens or hundreds of milliseconds. But with tiered storage enabled, it can take\ntens of seconds or even minutes to read the first batch of records.\n\nThe reason for this is that many tiered storage solutions don\u2019t support\nreading data incrementally from the object store. Instead, these\nimplementations require that entire log segments are downloaded from the\nremote object store before any reads can be served. This is problematic\nbecause log segments can be hundreds of MiBs or even gigabytes in size. While\nthese large segments are being downloaded, the consumer is completely blocked\nand unable to make any progress.\n\nSome tiered storage implementations support incremental reads via a chunking\nmechanism, but the log segment chunks still have to be downloaded and cached\non disk after they\u2019re paged in from the object store. Writing the downloaded\nchunks to disk competes with the live workload for the limited amount of IOPS\n(and disk space) available on the Kafka brokers. This means that a single\nconsumer, replaying a tiny amount of historical data, can easily disrupt all\nof the live consumers serving production traffic. This also means that while\ntiered storage does reduce the disk size on the brokers, there are limits to\nhow small these disks can get. We need to leave enough headroom for both the\nlive and historical workload.\n\nFurther compounding the issue, a cloud disk\u2019s available IOPS is often linked\nto the amount of provisioned storage. But the whole point of tiered storage is\nto reduce the amount of disk storage that has to be provisioned in the first\nplace!\n\nIssues like this can be worked around with very careful capacity planning,\nbenchmarking, and configuration tuning, but it is painful. Furthermore, the\nissues that I have described so far tend to lie dormant at first, and then\nrear their head at the worst possible time: when something has gone wrong and\nhistorical data needs to be replayed without sacrificing the reliability of\nthe live workload.\n\nNeeding to read historical data doesn\u2019t just happen in emergencies either. In\nthe last few months, I\u2019ve run into three different organizations who are\ntrying to migrate away from a tiered storage data streaming system, and they\ndescribe being unable to migrate to a new solution because they can\u2019t read\ntheir data out of tiered storage without disrupting live traffic.\n\nFinally, and perhaps worst of all, the extra complexity introduced by tiered\nstorage is additive. In addition to all of the operational problems you\u2019re\nsuffering from currently:\n\n  * Partition rebalancing\n  * Finicky consensus mechanisms\n  * Performance problems\n  * Inelasticity\n  * Hotspots\n  * Broker imbalances\n  * etc\n\nTiered storage adds a whole new set of additional failure modes and\noperational tasks, and eliminates none of the existing ones.\n\n## No Reduction in inter-zone Networking\n\nOperations aside, tiered storage also promises to reduce the overall total\ncost of Kafka. Unfortunately, it usually doesn\u2019t live up to this promise\neither, and the reason might surprise you: cloud networking fees.\n\nIf you thought cloud disks were expensive, cloud networking will really make\nyour eyes water. Inter-zone networking fees are the silent killer of data\nstreaming workloads. To put this into concrete terms, every GiB of data that\nis written through an Apache Kafka cluster running in a standard HA three\navailability zone setup costs 5.3 cents per GiB. By comparison, storing a GiB\nof data in S3 for a month only costs 2 cents.\n\nData path for a standard HA Kafka cluster running in three availabiltiy zones.\n\nSo how does tiered storage help reduce inter-zone networking costs?\nUnfortunately, it doesn\u2019t. At all. To ensure high availability and durability,\nall data that you write to a cluster with tiered storage enabled still has to\nbe replicated to three disks in three different availability zones before\nbeing acknowledged and considered durable. Tiering does not happen until\nlater. That\u2019s a big problem because inter-zone networking is often responsible\nfor 80%+ of a streaming workload's total cost.\n\nThis means that no matter how small the brokers\u2019 local disks are, or how\nquickly the tiered storage implementation copies data to object storage,\nstreaming systems that leverage a tiered storage architecture will usually\ncost almost exactly as much as a traditional Kafka cluster for any workload\nthat is not storage-bound, even if they only store data on local disks for one\nminute.\n\n## It doesn\u2019t enable new use cases\n\nOkay fine. So maybe tiered storage doesn\u2019t save you as much money as you\nhoped, and hey the performance is unpredictable, but you can provision EBS\nvolumes with dedicated IOPS, do some very careful gamedays, and test that\neverything will work as you expect. It\u2019s a little bit more complex to deal\nwith, but the benefits are well worth it right? After all, tiered storage\nisn\u2019t just about reducing costs, it\u2019s also about all the new stuff that tiered\nstorage enables you to do.\n\nFor example, since all of the data is stored in object storage, in theory, you\ncould also just run batch jobs/queries against that data directly, bypassing\nthe brokers entirely. Voila, your data stream is now a data lake.\n\nThat would indeed be useful if it was possible, but in practice, it\u2019s not. The\ndata in the object store is being actively \u201cmanaged\u201d by the brokers\n(compacted, retention enforced, etc) and so querying the data files directly\nwould result in anomalies: missing and duplicate records, specifically due to\nlack of snapshot isolation. And unless you figure out how to provide a single\npane of glass between broker disks and object storage, you will only be able\nto query data that is outside of the hot set, which means that you can only\nquery stale data.\n\nYou can still query all of the data using the Kafka APIs, but in practice,\nyou\u2019ll be bottlenecked by the maximum throughput of however many brokers\nhappen to be hosting the topic-partitions that you want to query. For example,\nif you only want to query a subset of the topics, and those topics are only\nhosted on a subset of your brokers, you may only be able to use a tiny\nfraction of your cluster\u2019s total capacity to run the query even though your\nother brokers are all sitting idle.\n\nIn theory, when you need to scale your read capacity, you could temporarily\nmark some of the brokers as \u201cread replicas\u201d for specific topic-partitions such\nthat they have all the metadata for the data tiered to object storage and can\nserve reads, but don\u2019t participate in any leader elections, and you\u2019d just\nneed to make sure they don\u2019t also replicate the data that hasn\u2019t been tiered\nyet to not waste too much disk space, and... well this is all starting to\nsound like an awful amount of work.\n\n## Tiered Storage in Disguise\n\nI\u2019m not the only person in the streaming space that is disappointed with the\nfalse promises of tiered storage. Many users and experts in the industry are\nbeginning to recognize that tiered storage isn\u2019t the silver bullet they\nexpected it to be. As a result, many systems and vendors are taking the path\nof less resistance: rebranding.\n\nLook out for the following phrases:\n\n  1. \u201cCloud First Storage\u201d (tiered storage)\n  2. \u201cMostly Stateless\u201d (tiered storage)\n  3. \u201cUse disks as a cache in front of object storage\u201d (tiered storage)\n\nThese terms are all just the same old tiered storage in disguise. I\u2019ve written\nabout this before, but it bears repeating: It\u2019s much easier for existing\nplayers to make incremental changes, and then repackage and rebrand their\nexisting products than it is for them to do the right thing for their users:\nrebuild from scratch for the cloud.\n\n## Zero Disks Would be Better\n\nHopefully, by now you\u2019re convinced that while tiered storage does have some\nbenefits, namely reducing storage costs for some workloads, it\u2019s not the\nradical improvement that you were promised, and while it may reduce costs, it\ncertainly won\u2019t simplify operations or make your life any easier. Quite the\nopposite actually, it will make your Kafka workloads more unpredictable and\nmore difficult to manage.\n\nI\u2019ll conclude with this. Tiered storage is all about using fewer disks. But if\nyou could rebuild streaming from the ground up for the cloud, you could\nachieve something a lot better than fewer disks \u2013 zero disks. The difference\nbetween some disks and zero disks is night and day. Zero disks, with\neverything running directly through object storage with no intermediary disks,\nwould be better. Much better. But more on that in a future blog post.\n\n#### Table of Contents\n\nTiered Storage Seems Like a Good Idea\n\nThe Tarpit\n\nIncreased Complexity and Operational Burden\n\nNo Reduction in inter-zone Networking\n\nIt doesn\u2019t enable new use cases\n\nTiered Storage in Disguise\n\nZero Disks Would be Better\n\nTalk to an expert\n\n## Subscribe\n\nSubscribe\n\n## Subscribe\n\nRSS Feed\n\nWarpStream is a Kafka compatible data streaming platform built directly on top\nof object storage: no inter-AZ bandwidth costs, no disks to manage, and\ninfinitely scalable, all within your VPC.\n\nThank you! You've been added to our mailing list.\n\nOops! Something went wrong while submitting the form.\n\nJoin our mailing list to stay up to date!\n\nSubscribe\n\n## Subscribe\n\nPricingCompanyDocumentationBlogContact Us\n\nSlack\n\nDiscord\n\nX (Twitter)\n\nLinkedIn\n\n\u00a9 2024 WarpStream. All rights reserved.\n\nApache, Apache Kafka, Kafka, and associated open source project names are\ntrademarks of the Apache Software Foundation.\n\nPrivacy PolicySLATerms of ServiceTrust Center\n\nTiered Storage Won\u2019t Fix Kafka\n\nReal-Time Website Security Monitoring wi...\n\nFancy Stream Processing Made (even more)...\n\nThe Original Sin of Cloud Infrastructure\n\nDeterministic Simulation Testing for Our...\n\nPublic Benchmarks and TCO Analysis\n\nKafka as a KV Store: deduplicating milli...\n\nAnatomy of a serverless usage based bill...\n\nMiddleware saves 85% by replacing Apache...\n\nS3 Express is All You Need\n\nUnlocking Idempotency with Retroactive T...\n\nMinimizing S3 API Costs with Distributed...\n\nWarpStream + Materialize: Simpler Stream...\n\nHacking the Kafka PRoTocOL\n\nKafka is dead, long live Kafka\n\n", "frontpage": true}
