{"aid": "40131330", "title": "Nhost Auth, from Node.js to Go", "url": "https://nhost.io/blog/auth-to-go", "domain": "nhost.io", "votes": 3, "user": "nunopato", "posted_at": "2024-04-23 12:45:12", "comments": 0, "source_title": "Auth Service to Go | Nhost", "source_text": "Auth Service to Go | Nhost\n\nNhost AI Week \ud83e\udde0 Dec 18-22!\n\nStar us on GitHub\n\nSign inSign up\n\nBack to Blog\n\nProduct \u00b7 Auth|23 April 2024\n\nProduct | Auth\n\n# Auth Service to Go\n\n23 April 2024\n\nPosted by\n\nDavid Barroso\n\nCTO\n\nThis is one of those posts about how we migrated X from Y language to Z and\nall the improvements and amazing things we saw along the way. If you are\ntriggered by this kind of post or you are a fan of Y (or some other language\nentirely) and are equally triggered, apologies in advance ;)\n\n# What?\n\nSo let's get started with what we did exactly. In the last couple of months we\nstarted migrating our Auth service from Node.js to Go. In order to be able to\nmigrate this bit by bit we followed the strangler fig pattern (more on this\nlater) and at the time of writing this document we have migrated most of the\nfunctionality already. Enough to see the benefits and start writing yet-\nanother-I-migrated-from-x-to-y-post.\n\n# Why, Oh Why?\n\nSeveral reasons, which can be summarized as:\n\n  1. Performance - We are seeing lots of performance improvements which will improve end user's experience and improve scalabiity while requiring fewer resources. More on this later.\n  2. Reliability - Using a compiled language should bring major reliability improvements compared to an interpreted language like JavaScript.\n  3. Decoupling from Hasura - With the rewrite we decided to decouple the Auth service from Hasura, this means the Auth service will interface directly with postgres. This shouldn't have any major impact on developers, on the contrary, it will allow users to finally be able to configure whether to use camel case or snake case.\n\nOther less technical/more subjective reasons why we decided to migrate to Go\nare:\n\n  1. Very low entry barrier. Go is a very easy to learn programming language.\n  2. In our personal opinion, it has the perfect balance between programming speed, ease of development and performance.\n  3. For the aforementioned reasons, finding good backend engineers that can write Go effectively is easy.\n\n## Why not Rust?\n\nI knew someone was going to ask. See previous paragraph :)\n\n# The strangler what?\n\nNow that all the excuses are out of the way, let's start with the fun details.\nAccording to the wikipedia:\n\n> In programming, the strangler fig pattern or strangler pattern is an\n> architectural pattern that involves wrapping old code [...] One use of this\n> pattern is during software rewrites. Code can be divided into many small\n> sections, wrapped with the strangler fig pattern, then that section of old\n> code can be swapped out with new code before moving on to the next section.\n> This is less risky and more incremental than swapping out the entire piece\n> of software.\n\nLet's see what this actually means. In PR #464 we added to the Auth service a\nGo process that simply proxied all requests. When a request would come in, it\nwould forward the request to the Node.js process, nothing else:\n\nGo process proxying requests towards Node.js process\n\nIn the picture above a request to the endpoint /signup comes in, it is\nreceived by the Go process and forwarded to the Node.js one. The Go process\ndoesn't really do anything with it.\n\nNow that we have the Go process in place we can start migrating and serving\nendpoints one by one. For instance, after implementing the /signup endpoint in\nthe Go process we can start serving it directly without any involvement from\nthe Node.js process:\n\nGo process serving requests\n\nAt the same time, endpoints not yet migrated will still be forwarded to the\nNode.js process. For instance, a request to /signin would still be proxied to\nthe Node.js process:\n\nGo process proxying requests towards Node.js process\n\n# Performance Improvements\n\nLet's start with the elephant in the room; \"wouldn't adding a second process\nactually demand more resources?\". Yes, but:\n\n  * The Go process takes ~4MB of RAM only, while the Node.js takes ~93MB so this is just a fraction of the total\n  * The Go process only takes a few milliCPUs to proxy the request\n  * As we will see below the net impact is almost negligible and even decreases memory consumption.\n\nIn order to perform the benchmarks we have set the following scenario:\n\n  * We are using a Pro project without dedicated compute. This means half a core for each service (shared).\n  * The project has been deployed in eu-central-1 and the tests are being executed from Stockholm, resulting in ~25ms of latency.\n  * For each test we are going to use a different number of workers. Workers are processes that can trigger requests so if you have 100 workers that means that 100 concurrent requests will be made.\n  * We will test Auth v0.26.0 (Node.js) against Auth v0.29.1 (Go)\n\nWithout further ado, let's see the raw results:\n\nNode.js (10)| Node,js (100)| Node,js (200)| Go (10)| Go (100)| Go (200)| Go\n(800)  \n---|---|---|---|---|---|---  \nrequests completed| 557| 1582| 1522| 580| 5312| 8943| 23934  \navg| 86.31ms| 2s 690ms| 6s 510ms| 38.04ms| 35ms| 38ms| 181.4ms  \nmin| 45ms| 53ms| 47ms| 27.02ms| 26ms| 26ms| 25.74ms  \nmax| 487ms| 12s 100ms| 35s 32ms| 175.95ms| 251ms| 268ms| 553.93ms  \np90| 148.33ms| 5s 500ms| 13s 880ms| 44.41ms| 45ms| 52ms| 324.89ms  \np95| 256.85ms| 6s 800ms| 16s 490ms| 48.04ms| 54ms| 71ms| 356.94ms  \npeak memory| 141| 141| 144| 97| 97| 97| 110  \n  \nThere is a lot to unpack here, let's start by looking at the data for 10\nworkers. As you can see both processes completed almost the same number of\nrequests in 60s, however, latency metrics are vastly better on the Go case.\nWhile the P95 (the latency most of your end users will experience) was ~250ms,\nin the Go case the latency was merely 48ms.\n\nIf we start looking at 100 and 200 workers we can see the Node.js version\nstarts showing big bottlenecks, more interestingly you can see that with 200\nworkers the bottlenecks got so bad that it processed fewer requests in total\nthat with 100 workers. On the other hand, with 100 and 200 workers the Go\nprocess handled 5312 and 8943 requests respectively. More importantly, the P90\nand P95 latency metrics barely got a hit. To see what would happen we decided\nto test the Go process with 800 workers. Here we can see we managed to process\nalmost 24000 requests in 60s and, while the P90 and P95 metrics go a hit, they\nare still within reasonable numbers given the load.\n\nIf we look at the memory usage we can also see that the Go process has better\nmetrics than the Node.js one despite the fact that, due to the strangler\npattern, the Go process actually includes the Node.js one in order to process\nthe endpoint not migrated yet. If you consider that the Node.js process is\ntaking 93MB when in standby, this means the Go process managed to process\n24000 requests in 60s while consuming only 17MB of RAM.\n\n# Here Be Dragons\n\nThe migration should be transparent for users. The API and the SDK remains the\nsame so what worked before should work now, and we are quite confident in our\ntests coverage. However, let's not forget this is a rewrite of a service with\nlots of features, so some edge cases not covered by the tests may suffer\nregressions. We ask you patience, if something arises we promise to tackle it\nas soon as possible. We promise it will be worth in the end.\n\n# Conclusion\n\nWhile we expect a few minor bumps along the road we think migrating the Auth\nservice from Node.js to go will bring clear benefits to everybody. We expect\nto see much better scale and latency metrics while decreasing resources\nneeded.\n\nShare this post\n\n### Features\n\n  * Database\n  * GraphQL\n  * Auth\n  * Storage\n  * Functions\n\n### Product\n\n  * Pricing\n  * Blog\n\n### Company\n\n  * About\n  * Customers\n\n### Resources\n\n  * Docs\n  * Status\n  * Legal\n\n", "frontpage": false}
