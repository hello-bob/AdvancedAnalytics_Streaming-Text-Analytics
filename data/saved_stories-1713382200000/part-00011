{"aid": "40063795", "title": "Quantum mechanics is the OS for Physics", "url": "https://www.scottaaronson.com/democritus/lec9.html", "domain": "scottaaronson.com", "votes": 11, "user": "cl3misch", "posted_at": "2024-04-17 12:38:40", "comments": 2, "source_title": "PHYS771 Lecture 9: Quantum", "source_text": "PHYS771 Lecture 9: Quantum\n\nPHYS771 Lecture 9: Quantum\n\nScott Aaronson\n\nThere are two ways to teach quantum mechanics. The first way -- which for most\nphysicists today is still the only way -- follows the historical order in\nwhich the ideas were discovered. So, you start with classical mechanics and\nelectrodynamics, solving lots of grueling differential equations at every\nstep. Then you learn about the \"blackbody paradox\" and various strange\nexperimental results, and the great crisis these things posed for physics.\nNext you learn a complicated patchwork of ideas that physicists invented\nbetween 1900 and 1926 to try to make the crisis go away. Then, if you're\nlucky, after years of study you finally get around to the central conceptual\npoint: that nature is described not by probabilities (which are always\nnonnegative), but by numbers called amplitudes that can be positive, negative,\nor even complex.\n\nToday, in the quantum information age, the fact that all the physicists had to\nlearn quantum this way seems increasingly humorous. For example, I've had\nexperts in quantum field theory -- people who've spent years calculating path\nintegrals of mind-boggling complexity -- ask me to explain the Bell inequality\nto them. That's like Andrew Wiles asking me to explain the Pythagorean\nTheorem.\n\nAs a direct result of this \"QWERTY\" approach to explaining quantum mechanics -\nwhich you can see reflected in almost every popular book and article, down to\nthe present -- the subject acquired an undeserved reputation for being hard.\nEducated people memorized the slogans -- \"light is both a wave and a\nparticle,\" \"the cat is neither dead nor alive until you look,\" \"you can ask\nabout the position or the momentum, but not both,\" \"one particle instantly\nlearns the spin of the other through spooky action-at-a-distance,\" etc. -- and\nalso learned that they shouldn't even try to understand such things without\nyears of painstaking work.\n\nThe second way to teach quantum mechanics leaves a blow-by-blow account of its\ndiscovery to the historians, and instead starts directly from the conceptual\ncore -- namely, a certain generalization of probability theory to allow minus\nsigns. Once you know what the theory is actually about, you can then sprinkle\nin physics to taste, and calculate the spectrum of whatever atom you want.\nThis second approach is the one I'll be following here.\n\nSo, what is quantum mechanics? Even though it was discovered by physicists,\nit's not a physical theory in the same sense as electromagnetism or general\nrelativity. In the usual \"hierarchy of sciences\" -- with biology at the top,\nthen chemistry, then physics, then math -- quantum mechanics sits at a level\nbetween math and physics that I don't know a good name for. Basically, quantum\nmechanics is the operating system that other physical theories run on as\napplication software (with the exception of general relativity, which hasn't\nyet been successfully ported to this particular OS). There's even a word for\ntaking a physical theory and porting it to this OS: \"to quantize.\"\n\nBut if quantum mechanics isn't physics in the usual sense -- if it's not about\nmatter, or energy, or waves, or particles -- then what is it about? From my\nperspective, it's about information and probabilities and observables, and how\nthey relate to each other.\n\nRay Laflamme: That's very much a computer-science point of view.\n\nScott: Yes, it is.\n\nMy contention in this lecture is the following: Quantum mechanics is what you\nwould inevitably come up with if you started from probability theory, and then\nsaid, let's try to generalize it so that the numbers we used to call\n\"probabilities\" can be negative numbers. As such, the theory could have been\ninvented by mathematicians in the 19^th century without any input from\nexperiment. It wasn't, but it could have been.\n\nRay Laflamme: And yet, with all the structures mathematicians studied, none of\nthem came up with quantum mechanics until experiment forced it on them...\n\nScott: Yes -- and to me, that's a perfect illustration of why experiments are\nrelevant in the first place! More often than not, the only reason we need\nexperiments is that we're not smart enough. After the experiment has been\ndone, if we've learned anything worth knowing at all, then hopefully we've\nlearned why the experiment wasn't necessary to begin with -- why it wouldn't\nhave made sense for the world to be any other way. But we're too dumb to\nfigure it out ourselves!\n\nTwo other perfect examples of \"obvious-in-retrospect\" theories are evolution\nand special relativity. Admittedly, I don't know if the ancient Greeks,\nsitting around in their togas, could have figured out that these theories were\ntrue. But certainly -- certainly! -- they could've figured out that they were\npossibly true: that they're powerful principles that would've at least been on\nGod's whiteboard when She was brainstorming the world.\n\nIn this lecture, I'm going to try to convince you -- without any recourse to\nexperiment -- that quantum mechanics would also have been on God's whiteboard.\nI'm going to show you why, if you want a universe with certain very generic\nproperties, you seem forced to one of three choices: (1) determinism, (2)\nclassical probabilities, or (3) quantum mechanics. Even if the \"mystery\" of\nquantum mechanics can never be banished entirely, you might be surprised by\njust how far people could've gotten without leaving their armchairs! That they\ndidn't get far until atomic spectra and so on forced the theory down their\nthroats is one of the strongest arguments I know for experiments being\nnecessary.\n\nA Less Than 0% Chance\n\nAlright, so what would it mean to have \"probability theory\" with negative\nnumbers? Well, there's a reason you never hear the weather forecaster talk\nabout a -20% chance of rain tomorrow -- it really does make as little sense as\nit sounds. But I'd like you to set any qualms aside, and just think abstractly\nabout an event with N possible outcomes. We can express the probabilities of\nthose events by a vector of N real numbers:\n\n(p_1,....,p_N),\n\nMathematically, what can we say about this vector? Well, the probabilities had\nbetter be nonnegative, and they'd better sum to 1. We can express the latter\nfact by saying that the 1-norm of the probability vector has to be 1. (The\n1-norm just means the sum of the absolute values of the entries.)\n\nBut the 1-norm is not the only norm in the world -- it's not the only way we\nknow to define the \"size\" of a vector. There are other ways, and one of the\nrecurring favorites since the days of Pythagoras has been the 2-norm or\nEuclidean norm. Formally, the Euclidean norm means the square root of the sum\nof the squares of the entries. Informally, it means you're late for class, so\ninstead of going this way and then that way, you cut across the grass.\n\nNow, what happens if you try to come up with a theory that's like probability\ntheory, but based on the 2-norm instead of the 1-norm? I'm going to try to\nconvince you that quantum mechanics is what inevitably results.\n\nLet's consider a single bit. In probability theory, we can describe a bit as\nhaving a probability p of being 0, and a probability 1-p of being 1. But if we\nswitch from the 1-norm to the 2-norm, now we no longer want two numbers that\nsum to 1, we want two numbers whose squares sum to 1. (I'm assuming we're\nstill talking about real numbers.) In other words, we now want a vector (\u03b1,\u03b2)\nwhere \u03b1^2 + \u03b2^2 = 1. Of course, the set of all such vectors forms a circle:\n\nThe theory we're inventing will somehow have to connect to observation. So,\nsuppose we have a bit that's described by this vector (\u03b1,\u03b2). Then we'll need\nto specify what happens if we look at the bit. Well, since it is a bit, we\nshould see either 0 or 1! Furthermore, the probability of seeing 0 and the\nprobability of seeing 1 had better add up to 1. Now, starting from the vector\n(\u03b1,\u03b2), how can we get two numbers that add up to 1? Simple: we can let \u03b1^2 be\nthe probability of a 0 outcome, and let \u03b2^2 be the probability of a 1 outcome.\n\nBut in that case, why not forget about \u03b1 and \u03b2, and just describe the bit\ndirectly in terms of probabilities? Ahhhhh. The difference comes in how the\nvector changes when we apply an operation to it. In probability theory, if we\nhave a bit that's represented by the vector (p,1-p), then we can represent any\noperation on the bit by a stochastic matrix: that is, a matrix of nonnegative\nreal numbers where every column adds up to 1. So for example, the \"bit flip\"\noperation -- which changes the probability of a 1 outcome from p to 1-p -- can\nbe represented as follows:\n\nIndeed, it turns out that a stochastic matrix is the most general sort of\nmatrix that always maps a probability vector to another probability vector.\n\nExercise 1 for the Non-Lazy Reader: Prove this.\n\nBut now that we've switched from the 1-norm to the 2-norm, we have to ask:\nwhat's the most general sort of matrix that always maps a unit vector in the\n2-norm to another unit vector in the 2-norm?\n\nWell, we call such a matrix a unitary matrix -- indeed, that's one way to\ndefine what a unitary matrix is! (Oh, all right. As long as we're only talking\nabout real numbers, it's called an orthogonal matrix. But same difference.)\nAnother way to define a unitary matrix, again in the case of real numbers, is\nas a matrix whose inverse equals its transpose.\n\nExercise 2 for the Non-Lazy Reader: Prove that these two definitions are\nequivalent.\n\nGus Gutoski: So far you've given no motivation for why you've set the sum of\nthe squares equal to 1, rather than the sum of the cubes or the sum of the\nfourth powers...\n\nScott: I'm gettin' to it -- don't you worry about that!\n\nThis \"2-norm bit\" that we've defined has a name, which as you know is qubit.\nPhysicists like to represent qubits using what they call \"Dirac ket notation,\"\nin which the vector (\u03b1,\u03b2) becomes . Here \u03b1 is the amplitude of outcome |0\u3009,\nand \u03b2 is the amplitude of outcome |1\u3009.\n\nThis notation usually drives computer scientists up a wall when they first see\nit -- especially because of the asymmetric brackets! But if you stick with it,\nyou see that it's really not so bad. As an example, instead of writing out a\nvector like (0,0,3/5,0,0,0,4/5,0,0), you can simply write , omitting all of\nthe 0 entries.\n\nSo given a qubit, we can transform it by applying any 2-by-2 unitary matrix --\nand that leads already to the famous effect of quantum interference. For\nexample, consider the unitary matrix\n\nwhich takes a vector in the plane and rotates it by 45 degrees\ncounterclockwise. Now consider the state |0\u3009. If we apply U once to this\nstate, we'll get -- it's like taking a coin and flipping it. But then, if we\napply the same operation U a second time, we'll get |1\u3009:\n\nSo in other words, applying a \"randomizing\" operation to a \"random\" state\nproduces a deterministic outcome! Intuitively, even though there are two\n\"paths\" that lead to the outcome |0\u3009, one of those paths has positive\namplitude and the other has negative amplitude. As a result, the two paths\ninterfere destructively and cancel each other out. By contrast, the two paths\nleading to the outcome |1\u3009 both have positive amplitude, and therefore\ninterfere constructively.\n\nThe reason you never see this sort of interference in the classical world is\nthat probabilities can't be negative. So, cancellation between positive and\nnegative amplitudes can be seen as the source of all \"quantum weirdness\" --\nthe one thing that makes quantum mechanics different from classical\nprobability theory. How I wish someone had told me that when I first heard the\nword \"quantum\"!\n\nMixed States\n\nOnce we have these quantum states, one thing we can always do is to take\nclassical probability theory and \"layer it on top.\" In other words, we can\nalways ask, what if we don't know which quantum state we have? For example,\nwhat if we have a 1/2 probability of and a 1/2 probability of ? This gives us\nwhat's called a mixed state, which is the most general kind of state in\nquantum mechanics.\n\nMathematically, we represent a mixed state by an object called a density\nmatrix. Here's how it works: say you have this vector of N amplitudes,\n(\u03b1_1,...,\u03b1_N). Then you compute the outer product of the vector with itself --\nthat is, an N-by-N matrix whose (i,j) entry is \u03b1_i\u03b1_j (again in the case of\nreal numbers). Then, if you have a probability distribution over several such\nvectors, you just take a linear combination of the resulting matrices. So for\nexample, if you have probability p of some vector and probability 1-p of a\ndifferent vector, then it's p times the one matrix plus 1-p times the other.\n\nThe density matrix encodes all the information that could ever be obtained\nfrom some probability distribution over quantum states, by first applying a\nunitary operation and then measuring.\n\nExercise 3 for the Non-Lazy Reader: Prove this.\n\nThis implies that if two distributions give rise to the same density matrix,\nthen those distributions are empirically indistinguishable, or in other words\nare the same mixed state. As an example, let's say you have the state with 1/2\nprobability, and with 1/2 probability. Then the density matrix that describes\nyour knowledge is\n\nIt follows, then, that no measurement you can ever perform will distinguish\nthis mixture from a 1/2 probability of |0\u3009 and a 1/2 probability of |1\u3009.\n\nThe Squaring Rule\n\nNow let's talk about the question Gus raised, which is, why do we square the\namplitudes instead of cubing them or raising them to the fourth power or\nwhatever?\n\nDevin Smith: Because it gives you the right answer?\n\nScott: Yeah, you do want an answer that agrees with experiment. So let me put\nthe question differently: why did God choose to do it that way and not some\nother way?\n\nRay Laflamme: Well, given that the numbers can be negative, squaring them just\nseems like the simplest thing to do!\n\nScott: Why not just take the absolute value?\n\nAlright, I can give you a couple of arguments for why God decided to square\nthe amplitudes.\n\nThe first argument is a famous result called Gleason's Theorem from the\n1950's. Gleason's Theorem lets us assume part of quantum mechanics and then\nget out the rest of it! More concretely, suppose we have some procedure that\ntakes as input a unit vector of real numbers, and that spits out the\nprobability of an event. Formally, we have a function f that maps a unit\nvector to the unit interval [0,1]. And let's suppose N=3 -- the theorem\nactually works in any number of dimensions three or greater (but\ninterestingly, not in two dimensions). Then the key requirement we impose is\nthat, whenever three vectors v_1,v_2,v_3 are all orthogonal to each other,\n\nf(v_1) + f(v_2) + f(v_3) = 1.\n\nIntuitively, if these three vectors represent \"orthogonal ways\" of measuring a\nquantum state, then they should correspond to mutually-exclusive events.\nCrucially, we don't need any assumption other than that -- no continuity, no\ndifferentiability, no nuthin'.\n\nSo, that's the setup. The amazing conclusion of the theorem is that, for any\nsuch f, there exists a mixed state such that f arises by measuring that state\naccording to the standard measurement rule of quantum mechanics. I won't be\nable prove this theorem here, since it's pretty hard. But it's one way that\nyou can \"derive\" the squaring rule without exactly having to put it in at the\noutset.\n\nExercise 4 for the Non-Lazy Reader: Why does Gleason's Theorem not work in two\ndimensions?\n\nIf you like, I can give you a much more elementary argument. This is something\nI put it in one of my papers, though I'm sure many others knew it before.\n\nLet's say we want to invent a theory that's not based on the 1-norm like\nclassical probability theory, or on the 2-norm like quantum mechanics, but\ninstead on the p-norm for some . Call (v_1,...,v_N) a unit vector in the\np-norm if\n\n|v_1|^p+...+|v_N|^p = 1.\n\nThen we'll need some \"nice\" set of linear transformations that map any unit\nvector in the p-norm to another unit vector in the p-norm.\n\nIt's clear that for any p we choose, there will be some linear transformations\nthat preserve the p-norm. Which ones? Well, we can permute the basis elements,\nshuffle them around. That'll preserve the p-norm. And we can stick in minus\nsigns if we want. That'll preserve the p-norm too. But here's the little\nobservation I made: if there are any linear transformations other than these\ntrivial ones that preserve the p-norm, then either p=1 or p=2. If p=1 we get\nclassical probability theory, while if p=2 we get quantum mechanics.\n\nRay Laflamme: So if you don't want something boring...\n\nScott: Exactly! Then you have to set p=1 or p=2.\n\nExercise 5 for the Non-Lazy Reader: Prove my little observation.\n\nAlright, to get you started, let me give some intuition about why my\nobservation might be true. Let's assume, for simplicity, that everything is\nreal and that p is a positive even integer (though the observation also works\nwith complex numbers and with any real p\u22650). Then for a linear transformation\nA=(a_ij) to preserve the p-norm means that\n\nwhenever\n\nNow we can ask: how many constraints are imposed on the matrix A by the\nrequirement that this be true for every v_1,...,v_N? If we work it out, in the\ncase p=2 we'll find that there are constraints. But since we're trying to pick\nan N-by-N matrix, that still leaves us N(N-1)/2 degrees of freedom to play\nwith.\n\nOn the other hand, if (say) p=4, then the number of constraints grows like ,\nwhich is greater than N^2 (the number of variables in the matrix). That\nsuggests that it will be hard to find a nontrivial linear transformation that\npreserves 4-norm. Of course it doesn't prove that no such transformation\nexists -- that's left as a puzzle for you.\n\nIncidentally, this isn't the only case where we find that the 1-norm and\n2-norm are \"more special\" than other p-norms. So for example, have you ever\nseen the following equation?\n\nx^n + y^n = z^n\n\nThere's a cute little fact -- unfortunately I won't have time to prove it in\nclass -- that the above equation has nontrivial integer solutions when n=1 or\nn=2, but not for any larger integers n. Clearly, then, if we use the 1-norm\nand the 2-norm more than other vector norms, it's not some arbitrary whim --\nthese really are God's favorite norms! (And we didn't even need an experiment\nto tell us that.)\n\nReal vs. Complex Numbers\n\nEven after we've decided to base our theory on the 2-norm, we still have at\nleast two choices: we could let our amplitudes be real numbers, or we could\nlet them be complex numbers. We know the solution God chose: amplitudes in\nquantum mechanics are complex numbers. This means that you can't just square\nan amplitude to get a probability; first you have to take the absolute value,\nand then you square that. In other words, if the amplitude for some\nmeasurement outcome is \u03b1 = \u03b2 + \u03b3i, where \u03b2 and \u03b3 are real, then the\nprobability of seeing the outcome is |\u03b1|^2 = \u03b2^2 + \u03b3^2.\n\nWhy did God go with the complex numbers and not the real numbers?\n\nYears ago, at Berkeley, I was hanging out with some math grad students -- I\nfell in with the wrong crowd -- and I asked them that exact question. The\nmathematicians just snickered. \"Give us a break -- the complex numbers are\nalgebraically closed!\" To them it wasn't a mystery at all.\n\nBut to me it is sort of strange. I mean, complex numbers were seen for\ncenturies as fictitious entities that human beings made up, in order that\nevery quadratic equation should have a root. (That's why we talk about their\n\"imaginary\" parts.) So why should Nature, at its most fundamental level, run\non something that we invented for our convenience?\n\nAnswer: Well, if you want every unitary operation to have a square root, then\nyou have to go to the complex numbers...\n\nScott: Dammit, you're getting ahead of me!\n\nAlright, yeah: suppose we require that, for every linear transformation U that\nwe can apply to a state, there must be another transformation V such that V^2\n= U. This is basically a continuity assumption: we're saying that, if it makes\nsense to apply an operation for one second, then it ought to make sense to\napply that same operation for only half a second.\n\nCan we get that with only real amplitudes? Well, consider the following linear\ntransformation:\n\nThis transformation is just a mirror reversal of the plane. That is, it takes\na two-dimensional Flatland creature and flips it over like a pancake, sending\nits heart to the other side of its two-dimensional body. But how do you apply\nhalf of a mirror reversal without leaving the plane? You can't! If you want to\nflip a pancake by a continuous motion, then you need to go into ... dum dum\ndum ... THE THIRD DIMENSION.\n\nMore generally, if you want to flip over an N-dimensional object by a\ncontinuous motion, then you need to go into the (N+1)^st dimension.\n\nExercise 6 for the Non-Lazy: Prove that any norm-preserving linear\ntransformation in N dimensions can be implemented by a continuous motion in\nN+1 dimensions.\n\nBut what if you want every linear transformation to have a square root in the\nsame number of dimensions? Well, in that case, you have to allow complex\nnumbers. So that's one reason God might have made the choice She did.\n\nAlright, I can give you two other reasons why amplitudes should be complex\nnumbers.\n\nThe first comes from asking, how many independent real parameters are there in\nan N-dimensional mixed state? As it turns out, the answer is exactly N^2 --\nprovided we assume, for convenience, that the state doesn't have to be\nnormalized (i.e., that the probabilities can add up to less than 1). Why?\nWell, an N-dimensional mixed state is represented mathematically by a N-by-N\nHermitian matrix with positive eigenvalues. Since we're not normalizing, we've\ngot N independent real numbers along the main diagonal. Below the main\ndiagonal, we've got N(N-1)/2 independent complex numbers, which means N(N-1)\nreal numbers. Since the matrix is Hermitian, the complex numbers below the\nmain diagonal determine the ones above the main diagonal. So the total number\nof independent real parameters is N + N(N-1) = N^2.\n\nNow we bring in an aspect of quantum mechanics that I didn't mention before.\nIf we know the states of two quantum systems individually, then how do we\nwrite their combined state? Well, we just form what's called the tensor\nproduct. So for example, the tensor product of two qubits, \u03b1|0\u3009+\u03b2|1\u3009 and\n\u03b3|0\u3009+\u03b4|1\u3009, is given by\n\nAgain one can ask: did God have to use the tensor product? Could She have\nchosen some other way of combining quantum states into bigger ones? Well,\nmaybe someone else can say something useful about this question -- I have\ntrouble even wrapping my head around it! For me, saying we take the tensor\nproduct is almost what we mean when we say we're putting together two systems\nthat exist independently of each other.\n\nAs you all know, there are two-qubit states that can't be written as the\ntensor product of one-qubit states. The most famous of these is the EPR\n(Einstein-Podolsky-Rosen) pair:\n\nGiven a mixed state \u03c1 on two subsystems A and B, if \u03c1 can be written as a\nprobability distribution over tensor product states , then we say \u03c1 is\nseparable. Otherwise we say \u03c1 is entangled.\n\nNow let's come back to the question of how many real parameters are needed to\ndescribe a mixed state. Suppose we have a (possibly-entangled) composite\nsystem AB. Then intuitively, it seems like the number of parameters needed to\ndescribe AB -- which I'll call d_AB -- should equal the product of the number\nof parameters needed to describe A and the number of parameters needed to\ndescribe B:\n\nd_AB = d_A d_B.\n\nIf amplitudes are complex numbers, then happily this is true! Letting N_A and\nN_B be the number of dimensions of A and B respectively, we have\n\nd_AB = (N_A N_B)^2 = N_A^2 N_B^2 = d_A d_B.\n\nBut what if the amplitudes are real numbers? In that case, in an N-by-N\ndensity matrix, we'd only have N(N+1)/2 independent real parameters. And it's\nnot the case that if N = N_A N_B then\n\nQuestion: Can this same argument be used to rule out quaternions?\n\nScott: Excellent question. Yes! With real numbers the left-hand side is too\nbig, whereas with quaternions it's too small. Only with complex numbers is it\njuuuuust right!\n\nThere's actually another phenomenon with the same \"Goldilocks\" flavor, which\nwas observed by Bill Wootters -- and this leads to my third reason why\namplitudes should be complex numbers. Let's say we choose a quantum state\n\nuniformly at random (if you're a mathematician, under the Haar measure). And\nthen we measure it, obtaining outcome |i\u3009 with probability |\u03b1_i|^2. The\nquestion is, will the resulting probability vector also be distributed\nuniformly at random in the probability simplex? It turns out that if the\namplitudes are complex numbers, then the answer is yes. But if the amplitudes\nare real numbers or quaternions, then the answer is no! (I used to think this\nfact was just a curiosity, but now I'm actually using it in a paper I'm\nworking on...)\n\nLinearity\n\nWe've talked about why the amplitudes should be complex numbers, and why the\nrule for converting amplitudes to probabilities should be a squaring rule. But\nall this time, the elephant of linearity has been sitting there undisturbed.\nWhy would God have decided, in the first place, that quantum states should\nevolve to other quantum states by means of linear transformations?\n\nAnswer: Because if the transformations weren't linear, you could crunch\nvectors to be bigger or smaller...\n\nScott: Close! Steven Weinberg and others proposed nonlinear variants of\nquantum mechanics in which the state vectors do stay the same size. The\ntrouble with these variants is that they'd let you take far-apart vectors and\nsquash them together, or take extremely close vectors and pry them apart!\nIndeed, that's essentially what it means for such theories to be nonlinear. So\nour configuration space no longer has this intuitive meaning of measuring the\ndistinguishability of vectors. Two states that are exponentially close might\nin fact be perfectly distinguishable. And indeed, in 1998 Abrams and Lloyd\nused exactly this observation to show that, if quantum mechanics were\nnonlinear, then one could build a computer to solve NP-complete problems in\npolynomial time.\n\nQuestion: What's the problem with that?\n\nScott: What's the problem with being able to solve NP-complete problems in\npolynomial time? Oy, if by the end of this class you still don't think that's\na problem, I will have failed you... [laughter]\n\nSeriously, of course we don't know whether NP-complete problems are\nefficiently solvable in the physical world. But in a survey I wrote a couple\nyears ago, I explained why the ability to solve NP-complete problems would\ngive us \"godlike\" powers -- arguably, even more so than the ability to\ntransmit superluminal signals or reverse the Second Law of Thermodynamics. The\nbasic point is that, when we talk about NP-complete problems, we're not just\ntalking about scheduling airline flights (or for that matter, breaking the RSA\ncryptosystem). We're talking about automating insight: proving the Riemann\nHypothesis, modeling the stock market, seeing whatever patterns or chains of\nlogical deduction are there in the world to be seen.\n\nSo, suppose I maintain the working hypothesis that NP-complete problems are\nnot efficiently solvable by physical means, and that if a theory suggests\notherwise, more likely than not that indicates a problem with the theory. Then\nthere are only two possibilities: either I'm right, or else I'm a god! And\neither one sounds pretty good to me...\n\nExercise 7 for the Non-Lazy Reader: Prove that if quantum mechanics were\nnonlinear, then not only could you solve NP-complete problems in polynomial\ntime, you could also use EPR pairs to transmit information faster than the\nspeed of light.\n\nQuestion: But if I were crafting a universe in my garage, I could choose to\nmake the speed of light equal to infinity.\n\nScott: Yeah, you've touched on another one of my favorite questions: why\nshould the speed of light be finite? Well, one reason I'd like it to be finite\nis that, if aliens from the Andromeda galaxy are going to hurt me, then I at\nleast want them to have to come here first!\n\nFurther Reading\n\nSee this paper by Lucien Hardy for a \"derivation\" of quantum mechanics that's\nclosely related to the arguments I gave, but much, much more serious and\ncareful. Also see pretty much anything Chris Fuchs has written (and especially\nthis paper by Caves, Fuchs, and Schack, which discusses why amplitudes should\nbe complex numbers rather than reals or quaternions).\n\n[Discussion of this lecture on blog]\n\n[\u2190 Previous lecture | Next lecture \u2192]\n\n[Return to PHYS771 home page]\n\n", "frontpage": true}
