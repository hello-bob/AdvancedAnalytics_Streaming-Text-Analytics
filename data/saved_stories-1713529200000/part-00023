{"aid": "40083913", "title": "A policy proposal on our approach to deepfake tools and responsible AI", "url": "https://github.blog/2024-04-18-a-policy-proposal-on-our-approach-to-deepfake-tools-and-responsible-ai/", "domain": "github.blog", "votes": 4, "user": "Tiberium", "posted_at": "2024-04-19 06:18:19", "comments": 5, "source_title": "A policy proposal on our approach to deepfake tools and responsible AI", "source_text": "A policy proposal on our approach to deepfake tools and responsible AI - The\nGitHub Blog\n\nSkip to content\n\n  * Policy\n\n# A policy proposal on our approach to deepfake tools and responsible AI\n\nWe\u2019re asking for feedback on a proposed Acceptable Use Policy update to\naddress the use of synthetic and manipulated media tools for non-consensual\nintimate imagery and disinformation while protecting valuable research.\n\nAuthor\n\nJesse Geraci\n\nApril 18, 2024\n\nWe are proposing an addition to our Acceptable Use Policies on Misinformation\nand Disinformation to address the development of synthetic and manipulated\nmedia tools for the creation of non-consensual intimate imagery (NCII) and\ndisinformation. We have opened a pull request for public comment on the\nproposed change, which reads as follows:\n\n> Synthetic and Manipulated Media Tools GitHub does not allow any projects\n> that are designed for, encourage, promote, support, or suggest in any way\n> the use of synthetic or manipulated media for the creation of non-consensual\n> intimate imagery or any content that would constitute misinformation or\n> disinformation under this policy.\n\n## Why are we proposing this change?\n\nArtificial intelligence (AI) has rapidly progressed beyond the realm of\nscience fiction. One of its most impressive capabilities is the ability to\ngenerate realistic looking images, audio, and video, which has substantial\nbenefits for creativity and innovation, but also introduces new vectors of\nabuse. As we move into a significant year for global elections, we have\nobserved rising concern for the use of AI-generated disinformation such as\ndeepfake videos, images, and robocalls. Additionally, several high-profile\ncases of the use of deepfake technology to generate NCII have prompted a wave\nof state and federal legislative proposals. As a code collaboration platform\nthat could be used to share the tools to make synthetic or manipulated media,\nwe must take responsible measures to address these harms while protecting\nvaluable research.\n\nAt GitHub, we have always adapted our policies to reflect new technologies and\ntheir impacts. This proposed change addresses concerns about the use of\ntechnology to create deepfakes for election disinformation, harassment, and\nother deceptive misuses, while enabling legitimate uses of this technology.\n\n## How are we thinking about this?\n\nOur mission is to accelerate human progress through developer collaboration.\nOne way we further that goal is by making a vast amount of source code\navailable to the public. The more source code available, the more the world\ncan learn from it, secure it, and build off it. So, whenever we make changes\nto our Acceptable Use Policies, we think hard about how our policies will\naffect the public availability of code on our platform.\n\nThere is always some educational value to sharing code, and removing code from\nthe public removes important information that can be used to address critical\nchallenges, understand key concepts, and enable important innovation. For\nexample, security researchers gain enormous value from examining the source\ncode that generates exploits, which allows them to develop tools that can\ndetect malware and create counter measures for it, but such software also has\nthe potential to be abused. We publicly addressed these questions a few years\nago when we updated our policies on malware, where we disallow actively\nharmful projects but allow dual-use content that is shared for the purpose of\nsecurity research. We want to take a similar approach here.\n\nGitHub is a home for all developers. If you are developing synthetic and\nmanipulated media tools that contribute to the world\u2019s knowledge, we want that\nresearch and creative energy here in this community. It is important for this\nresearch to happen in the open where others can learn from it. At the same\ntime, we cannot tolerate tools on our platform designed to create harmful non-\nconsensual intimate imagery or whose purpose is to develop synthetic media\nintended to misinform and spread disinformation. Through enforcing this\npolicy, we will differentiate between harmful misuse and legitimate dual or\ngeneral use and consider proportionate responses to possible abuse.\n\n## Next steps\n\nYou can review our proposed Acceptable Use Policy addition in the site-policy\nrepository, where we continually develop and make updates to our policies\ncollaboratively with the community. We invite all stakeholders to comment for\nthe 30-day period from now until May 20, and look forward to learning from and\nengaging with the broader community on these important topics.\n\nTags:\n\n  * acceptable use,\n  * AI,\n  * GitHub Policy,\n  * responsible AI\n\n## We do newsletters, too\n\nGet tips, technical guides, and best practices right in your inbox.\n\nSubscribe\n\n## Table of Contents\n\n  * Why are we proposing this change?\n  * How are we thinking about this?\n  * Next steps\n\n## More on AI\n\n### Found means fixed: Introducing code scanning autofix, powered by GitHub\nCopilot and CodeQL\n\nNow in public beta for GitHub Advanced Security customers, code scanning\nautofix helps developers remediate more than two-thirds of supported alerts\nwith little or no editing.\n\nPierre Tempel & Eric Tooley\n\n### Customizing and fine-tuning LLMs: What you need to know\n\nLearn how your organization can customize its LLM-based solution through\nretrieval augmented generation and fine-tuning.\n\nNicole Choi\n\n### How AI code generation works\n\nExplore the capabilities and benefits of AI code generation, and how it can\nimprove the developer experience for your enterprise.\n\nJeimy Ruiz\n\n## Related posts\n\nPolicy\n\n## Helping policymakers weigh the benefits of open source AI\n\nGitHub enables developer collaboration on innovative software projects, and\nwe\u2019re committed to ensuring policymakers understand developer needs when\ncrafting AI regulation.\n\nPeter Cihon\n\nPolicy\n\n## Explore the seasons of software development with four full years of data\n\nDiscover the latest trends and insights on public software development\nactivity on GitHub with the release of Q4 2023 data for the Innovation Graph.\n\nKevin Xu\n\nPolicy\n\n## Exploring an increase in circumvention claims in our transparency data\n\nOur full year of 2023 transparency reporting data is now available and we\u2019re\ntaking a deep dive into how a form change caused an abrupt increase in\ncircumvention claims.\n\nKevin Xu\n\n## Explore more from GitHub\n\n### Policy\n\nShaping laws, regulations, norms, and standard practices.\n\nLearn more\n\n### The ReadME Project\n\nStories and voices from the developer community.\n\nLearn more\n\n### GitHub Copilot\n\nDon't fly solo. Try 30 days for free.\n\nLearn more\n\n### Work at GitHub!\n\nCheck out our current job openings.\n\nLearn more\n\n## Subscribe to our newsletter\n\nCode with confidence. Discover tips, technical guides, and best practices in\nour biweekly newsletter just for devs.\n\n## Product\n\n  * Features\n  * Security\n  * Enterprise\n  * Customer Stories\n  * Pricing\n  * Resources\n\n## Platform\n\n  * Developer API\n  * Partners\n  * Atom\n  * Electron\n  * GitHub Desktop\n\n## Support\n\n  * Docs\n  * Community Forum\n  * Training\n  * Status\n  * Contact\n\n## Company\n\n  * About\n  * Blog\n  * Careers\n  * Press\n  * Shop\n\n  * GitHub on X\n  * GitHub on Facebook\n  * GitHub on YouTube\n  * GitHub on Twitch\n  * GitHub on TikTok\n  * GitHub on LinkedIn\n  * GitHub\u2019s organization on GitHub\n\n  * \u00a9 2024 GitHub, Inc.\n  * Terms\n  * Privacy\n\nWe use optional cookies to improve your experience on our websites and to\ndisplay personalized advertising based on your online activity. If you reject\noptional cookies, only cookies necessary to provide you the services listed\nabove will be used. You may change your selection on which cookies to accept\nby clicking \"Manage Cookies\" at the bottom of the page to change your\nselection. This selection is maintained for 180 days. Please review your\nselections regularly.\n\nHow to manage cookie preferences | Privacy Statement | Third-Party Cookies.\n\n", "frontpage": false}
