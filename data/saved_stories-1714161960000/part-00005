{"aid": "40167456", "title": "How to Build a Social Media Sentiment Analysis Pipeline", "url": "https://kwatch.io/how-to-build-a-social-media-sentiment-analysis-pipeline", "domain": "kwatch.io", "votes": 1, "user": "arthurdelerue", "posted_at": "2024-04-26 09:44:26", "comments": 0, "source_title": "How To Build A Social Media Sentiment Analysis Pipeline", "source_text": "How To Build A Social Media Sentiment Analysis Pipeline\n\n  * Features\n  * Pricing\n\nKWatch.io\n\n  * Features\n  * Pricing\n\nDashboard\n\n# How To Build A Social Media Sentiment Analysis Pipeline\n\n## April 25, 2024\n\nSentiment analysis on social media can be very useful to monitor your brand,\nyour competitors, or any other topic of interest. In this article we show you\nhow to build a system that listens to social media like Reddit, Hacker News,\nLinkedin, Twitter, etc., and automatically perform sentiment analysis on the\ncontent thanks to generative AI.\n\n## Combining Social Listening With Sentiment Analysis For Brand Sentiment\nAnalysis\n\nSocial listening is the act of paying attention to and interpreting\nconversations around a any sort of topics on social media platforms, review\nsites, and other online channels.\n\nSentiment analysis, on the other hand, is the process of identifying and\ncategorizing opinions expressed in a piece of text as positive, negative, or\nneutral. It involves using natural language processing, text analysis, and\ncomputational linguistics to systematically identify, extract, quantify, and\nstudy affective states and subjective information.\n\nWhen you combine social listening and sentiment analysis, you can track and\nanalyze the sentiment expressed in conversations related to your brand or your\ncompetitors. This is also known as \"brand sentiment analysis\". Brand sentiment\nanalysis allows you to automatically understand how consumers feel about your\nbrand or your competitors, identify areas for improvement, jump into the right\nconversation on social media to engage with potential customers, and make\ndata-driven decisions to enhance your brand's reputation and customer loyalty.\n\n## Building a Social Listening Platform\n\nCreating a social listening platform requires that you plug into a social\nmedia platform and retrieve every new posts and comments that contain the\nkeywords you want to monitor.\n\nThis is more easily achieved if the platform you are planning to monitor\nexposes an API. For example, Reddit exposes an API that you can easily\nconsume. Here is a simple cURL request that retrieves the last 100 Reddit\nposts:\n\n    \n    \n    curl https://www.reddit.com/r/all/new/.json?limit=100\n\nAnd here is a typical response returned by their API:\n\n    \n    \n    { \"kind\": \"Listing\", \"data\": { \"after\": \"t3_1asad4n\", \"dist\": 100, \"modhash\": \"ne8fi0fr55b56b8a75f8075df95fa2f03951cb5812b0f9660d\", \"geo_filter\": \"\", \"children\": [ { \"kind\": \"t3\", \"data\": { \"approved_at_utc\": null, \"subreddit\": \"GunAccessoriesForSale\", \"selftext\": \"Morning gents. I\\u2019m looking to snag up your forgotten factory yellow spring for the 509T. I need to source one for a buddy who lost his and I cannot find any available anywhere! \\n\\nIf one of you have the yellow spring laying around, looking to pay $50 shipped\\u2026 \\n\\nTo my 509t owners, it\\u2019s the \\u201clight\\u201d spring that comes in a plastic bag in the carrying case. \\n\\nThanks in advance \", \"author_fullname\": \"t2_2ezh71n6\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"[WTB] 509T yellow spring\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/GunAccessoriesForSale\", [...] \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": \"dark\", \"permalink\": \"/r/GunAccessoriesForSale/comments/1asadbj/wtb_509t_yellow_spring/\", \"parent_whitelist_status\": null, \"stickied\": false, \"url\": \"https://www.reddit.com/r/GunAccessoriesForSale/comments/1asadbj/wtb_509t_yellow_spring/\", \"subreddit_subscribers\": 182613, \"created_utc\": 1708094934.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false } }, [...] ] } }\n\nWe made a dedicated tutorial showing how to monitor Reddit with a simple Go\nprogram. Read more here about how to monitor Reddit with Go.\n\nEach social media platform has its own subtleties that we can't cover in this\narticle unfortunately. In order to easily monitor social media platforms (like\nReddit, Linkedin, X (Twitter), Hacker News, and more), you might want to\nsubscribe to a dedicated social listening platform like our KWatch.io service.\nTry KWatch.io for free here.\n\nAdd Keywords in Your KWatch.io Dashboard\n\nSome of the main challenges, when performing social media listening, are the\nhigh volume of data that you have to handle, the fact that you can be blocked\nby the social media platform if you make too many requests, and the fact that\nyou have to be smart about the way you handle the data.\n\nIn the next section, we will explain how to integrate the collected data into\nyour system.\n\n## Integrating Social Media Data Into Your System\n\nOnce you have collected the data from social media platforms, you need to\nstore it in a database or a data warehouse. This will allow you to analyze the\ndata, perform sentiment analysis, and generate insights.\n\nThere are several ways to store social media data (which is basically pure\ntext data), depending on your requirements and the volume of data you are\ndealing with. Some common options include:\n\n  * \u2022 Using a relational database like MySQL or PostgreSQL\n  * \u2022 Using a NoSQL database like MongoDB or Cassandra\n  * \u2022 Using a data warehouse like Amazon Redshift or Google BigQuery\n\nIf you have subscribed to a social listening platform, you should check if\nthey offer a way to transfer the data into your system.\n\nWebhooks, often referred to as 'web callbacks' or 'HTTP push API,' serve as a\nmeans for applications to share real-time data with other applications. This\nis achieved by generating HTTP POST requests when specific events transpire,\nthus delivering information to other applications promptly.\n\nFor example on our platform, KWatch.io, you should go to the \"notifications\"\nsection and set a webhook URL pointing to your system.\n\nAPI Webhook on KWatch.io\n\nHere is what the KWatch.io webhook looks like (it is a JSON payload):\n\n    \n    \n    { \"platform\": \"reddit\", \"query\": \"Keywords: vllm\", \"datetime\": \"19 Jan 24 05:52 UTC\", \"link\": \"https://www.reddit.com/r/LocalLLaMA/comments/19934kd/sglang_new/kijvtk5/\", \"content\": \"sglang runtime has a different architecture on the higher-level part with vllm.\", }\n\nIf you're new to this, you can effortlessly receive these webhooks in Python\nusing FastAPI.\n\nInstall FastAPI with the Uvicorn server:\n\n    \n    \n    pip install fastapi uvicorn\n\nNow create a new Python file and paste the following code (you might need to\nadapt this script):\n\n    \n    \n    # Import necessary modules from fastapi import FastAPI from pydantic import BaseModel # Initialize your FastAPI app app = FastAPI() # Update the Pydantic model to properly type-check and validate the incoming data class WebhookData(BaseModel): platform: str query: str datetime: str link: str content: str # Define an endpoint to receive webhook data @app.post(\"/kwatch-webhooks\") async def receive_webhook(webhook_data: WebhookData): # Process the incoming data # For demonstration, we're just printing it print(\"Received webhook data:\", webhook_data.dict()) # Return a response return {\"message\": \"Webhook data received successfully\"} if __name__ == \"__main__\": # Run the server with Uvicorn import uvicorn uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n\nSave the file and run the server with the following command:\n\n    \n    \n    uvicorn webhook_server:app \u2014 reload \u2014 host 0.0.0.0 \u2014 port 8000\n\nYour server is now running and ready to receive webhooks from KWatch.io.\n\n## Performing Sentiment Analysis on The Data With Generative AI Models Like\nGPT-4 or LLaMA 3\n\nOnce you have collected and stored the social media data, you can perform\nsentiment analysis on it.\n\nToday the most accurate way to perform sentiment analysis on a piece of text\nabout a specific keyword is by using generative AI models like GPT-4, LLaMA 3,\nChatDolphin, etc. These LLMs are not necessarily fast and can be costly at\nscale, but they guarantee state of the art results. If you need to analyze\nvery high volumes of keywords, you might want to lower the costs by using\nsmaller models, or fine-tune your own model.\n\nYou could deploy your own AI model, or plug into an AI API like OpenAI or NLP\nCloud. In this article we will plug into the NLP Cloud AI API.\n\n{%tr You can register on NLP Cloud and retrieve your API key here.\n\nYour request does not have to be too complex. For example here is a comment on\nReddit, about OpenAI:\n\nA Comment on Reddit About OpenAI\n\nLet's use the ChatDolphin model on NLP Cloud in order to analyze the sentiment\nabout OpenAI in this Reddit comment. First, install the NLP Cloud Python\nclient:\n\n    \n    \n    pip install nlpcloud\n\nNow you can analyze the sentiment of the Reddit comment with the following\nPython code:\n\n    \n    \n    import nlpcloud brand = \"OpenAI\" reddit_comment = \"Wasn't it the same with all OpenAI products? Amazing and groundbreaking at first, soon ruined by excessive censorship and outpaced by the competitors\" client = nlpcloud.Client(\"chatdolphin\", \"your api token\", gpu=True) print(client.generation(f\"What is the sentiment about {brand} in the following comment? Positive, negative, or neutral? Answer with 1 word only.\\n\\n{reddit_comment}\"))\n\nThe response will be:\n\n    \n    \n    Negative\n\nNow let's wrap up and write the final code that listens to the API webhook and\nperforms sentiment analysis on the data:\n\n    \n    \n    from fastapi import FastAPI from pydantic import BaseModel import nlpcloud client = nlpcloud.Client(\"dolphin\", \"your api token\", gpu=True) app = FastAPI() class WebhookData(BaseModel): platform: str query: str datetime: str link: str content: str @app.post(\"/kwatch-webhooks\") async def receive_webhook(webhook_data: WebhookData): brand = \"OpenAI\" print(client.generation(f\"\"\"What is the sentiment about {brand} in the following comment? Positive, negative, or neutral? Answer with 1 word only.\\n\\n {webhook_data.content}\"\"\")) return {\"message\": \"Webhook data received successfully\"} if __name__ == \"__main__\": import uvicorn uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n\n## Conclusion\n\nAs you can see it's possible to automate sentiment analysis on social media\ndata with the help of modern generative AI models and efficient social\nlistening tools. This approach can be applied in various social media\nmonitoring scenarios. Here are some ideas:\n\n  * \u2022 Tracking your brand's reputation\n  * \u2022 Tracking a competitor's reputation\n  * \u2022 Keeping an eye on sentiment surrounding a stock option\n  * \u2022 Monitoring sentiment related to a specific technological trend, such as AI or crypto\n  * \u2022 ...\n\nProductionizing such a program can be challenging though. First because social\nmedia are not so easy to monitor, but also because generative AI models can be\ncostly to use on large volumes of data.\n\nIf you do not want to build and maintain such a system by yourself, we\nrecommend that you use our KWatch.io platform instead, as we automatically\nmonitor social media and perform sentiment analysis on the detected posts and\ncomments: register on KWatch.io here.\n\nArthur CTO at KWatch.io\n\nCopyright \u00a9 2024 - All right reserved by KWatch.io\n\n", "frontpage": false}
