{"aid": "40184372", "title": "Show HN: Data Bonsai: a Python package to clean your data with LLMs", "url": "https://github.com/databonsai/databonsai", "domain": "github.com/databonsai", "votes": 3, "user": "alvin_r_h", "posted_at": "2024-04-27 22:59:03", "comments": 0, "source_title": "GitHub - databonsai/databonsai: clean & curate your data with LLMs.", "source_text": "GitHub - databonsai/databonsai: clean & curate your data with LLMs.\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\ndatabonsai / databonsai Public\n\n  * Notifications\n  * Fork 3\n  * Star 27\n\nclean & curate your data with LLMs.\n\n### License\n\nMIT license\n\n27 stars 3 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# databonsai/databonsai\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nalvin-rreadme editsApr 27, 2024a8949e4 \u00b7 Apr 27, 2024Apr 27, 2024\n\n## History\n\n40 Commits  \n  \n### databonsai\n\n|\n\n### databonsai\n\n| bug fixes, prompt enhancements. Simplified LLM provider logic by remo...|\nApr 27, 2024  \n  \n### docs\n\n|\n\n### docs\n\n| bug fixes, prompt enhancements. Simplified LLM provider logic by remo...|\nApr 27, 2024  \n  \n### tests\n\n|\n\n### tests\n\n| added few shot examples, updated readme and test| Apr 17, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| added few shot examples, updated readme and test| Apr 17, 2024  \n  \n### .readthedocs.yaml\n\n|\n\n### .readthedocs.yaml\n\n| readthedocs edit| Apr 9, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| initial commit| Apr 7, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| readme edits| Apr 27, 2024  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| bug fixes, prompt enhancements. Simplified LLM provider logic by remo...|\nApr 27, 2024  \n  \n### setup.py\n\n|\n\n### setup.py\n\n| bug fixes, prompt enhancements. Simplified LLM provider logic by remo...|\nApr 27, 2024  \n  \n## Repository files navigation\n\n# databonsai\n\n## Clean & curate your data with LLMs\n\ndatabonsai is a Python library that uses LLMs to perform data cleaning tasks.\n\n## Features\n\n  * Suite of tools for data processing using LLMs including categorization, transformation, and extraction\n  * Validation of LLM outputs\n  * Batch processing for token savings\n  * Retry logic with exponential backoff for handling rate limits and transient errors\n\n## Installation\n\n    \n    \n    pip install databonsai\n\nStore your API keys on an .env file in the root of your project, or specify it\nas an argument when initializing the provider.\n\n    \n    \n    OPENAI_API_KEY=xxx # if you use OpenAiProvider ANTHROPIC_API_KEY=xxx # If you use AnthropicProvider\n\n## Quickstart\n\n### Categorization\n\nSetup the LLM provider and categories (as a dictionary.\n\n    \n    \n    from databonsai.categorize import MultiCategorizer, BaseCategorizer from databonsai.llm_providers import OpenAIProvider, AnthropicProvider provider = OpenAIProvider() # Or AnthropicProvider(). Highly recommend using Haiku, which is the default AnthropicProvider() model, as it is cheap and effective for these tasks categories = { \"Weather\": \"Insights and remarks about weather conditions.\", \"Sports\": \"Observations and comments on sports events.\", \"Politics\": \"Political events related to governments, nations, or geopolitical issues.\", \"Celebrities\": \"Celebrity sightings and gossip\", \"Others\": \"Comments do not fit into any of the above categories\", \"Anomaly\": \"Data that does not look like comments or natural language\", } few_shot_examples = [ {\"example\": \"Big stormy skies over city\", \"response\": \"Weather\"}, {\"example\": \"The team won the championship\", \"response\": \"Sports\"}, {\"example\": \"I saw a famous rapper at the mall\", \"response\": \"Celebrities\"}, ]\n\nCategorize your data:\n\n    \n    \n    categorizer = BaseCategorizer( categories=categories, llm_provider=provider, examples = few_shot_examples, #strict = False # Default true, set to False to allow for categories not in the provided dict ) category = categorizer.categorize(\"It's been raining outside all day\") print(category)\n\nOutput:\n\n    \n    \n    Weather\n\nUse categorize_batch to categorize a batch. This saves tokens as it only sends\nthe schema and few shot examples once! (Works best for better models. Ideally,\nuse at least 3 few shot examples.)\n\n    \n    \n    categories = categorizer.categorize_batch([ \"Massive Blizzard Hits the Northeast, Thousands Without Power\", \"Local High School Basketball Team Wins State Championship After Dramatic Final\", \"Celebrated Actor Launches New Environmental Awareness Campaign\", ]) print(categories)\n\nOutput:\n\n    \n    \n    ['Weather', 'Sports', 'Celebrities']\n\n### AutoBatch for Larger datasets\n\nIf you have a pandas dataframe or list, use apply_to_column_autobatch\n\n  * Batching data for LLM api calls saves tokens by not sending the prompt for every row. However, too large a batch size / complex tasks can lead to errors. Naturally, the better the LLM model, the larger the batch size you can use.\n\n  * This batching is handled adaptively (i.e., it will increase the batch size if the response is valid and reduce it if it's not, with a decay factor)\n\nOther features:\n\n  * Progress bar\n  * Returns the last successful index so you can resume from there, in case it exceeds max_retries\n  * Modifies your output list in place, so you don't lose any progress\n\nRetry Logic:\n\n  * LLM providers have retry logic built in for API related errors. This can be configured in the provider.\n  * The retry logic in the apply_to_column_autobatch is for handling invalid responses (e.g. unexpected category, different number of outputs, etc.)\n\n    \n    \n    from databonsai.utils import apply_to_column_batch, apply_to_column, apply_to_column_autobatch import pandas as pd headlines = [ \"Massive Blizzard Hits the Northeast, Thousands Without Power\", \"Local High School Basketball Team Wins State Championship After Dramatic Final\", \"Celebrated Actor Launches New Environmental Awareness Campaign\", \"President Announces Comprehensive Plan to Combat Cybersecurity Threats\", \"Tech Giant Unveils Revolutionary Quantum Computer\", \"Tropical Storm Alina Strengthens to Hurricane as It Approaches the Coast\", \"Olympic Gold Medalist Announces Retirement, Plans Coaching Career\", \"Film Industry Legends Team Up for Blockbuster Biopic\", \"Government Proposes Sweeping Reforms in Public Health Sector\", \"Startup Develops App That Predicts Traffic Patterns Using AI\", ] df = pd.DataFrame(headlines, columns=[\"Headline\"]) df[\"Category\"] = None # Initialize it if it doesn't exist, as we modify it in place success_idx = apply_to_column_autobatch( df[\"Headline\"], df[\"Category\"], categorizer.categorize_batch, batch_size=3, start_idx=0)\n\nThere are many more options available for autobatch, such as setting a\nmax_retries, decay factor, and more. Check Utils for more details\n\nIf it fails midway (even after exponential backoff), you can resume from the\nlast successful index + 1.\n\n    \n    \n    success_idx = apply_to_column_autobatch( df[\"Headline\"], df[\"Category\"], categorizer.categorize_batch, batch_size=10, start_idx=success_idx+1)\n\nThis also works for regular python lists.\n\nNote that the better the LLM model, the greater the batch_size you can use\n(depending on the length of your inputs). If you're getting errors, reduce the\nbatch_size, or use a better LLM model.\n\nTo use it with batching, but with a fixed batch size:\n\n    \n    \n    success_idx = apply_to_column_batch( df[\"Headline\"], df[\"Category\"], categorizer.categorize_batch, batch_size=3, start_idx=0)\n\nTo use it without batching:\n\n    \n    \n    success_idx = apply_to_column( df[\"Headline\"], df[\"Category\"], categorizer.categorize)\n\n### View System Prompt\n\n    \n    \n    print(categorizer.system_message) print(categorizer.system_message_batch)\n\n### View token usage\n\nToken usage is recorded for OpenAI and Anthropic. Use these to estimate your\ncosts!\n\n    \n    \n    print(provder.input_tokens) print(provder.output_tokens)\n\n## Docs\n\n### Tools (Check out the docs for usage examples and details)\n\n  * BaseCategorizer - categorize data into a category\n  * MultiCategorizer - categorize data into multiple categories\n  * BaseTransformer - transform data with a prompt\n  * ExtractTransformer - Extract data into a structured format based on a schema\n  * .. more coming soon!\n\n### LLM Providers\n\n  * OpenAIProvider - OpenAI\n  * AnthropicProvider - Anthropic\n  * OllamaProvider - Ollama\n  * .. more coming soon!\n\n### Examples\n\n  * Examples (TBD)\n\n### Acknowledgements\n\nBonsai icon from icons8 https://icons8.com/icon/74uBtdDr5yFq/bonsai\n\n## About\n\nclean & curate your data with LLMs.\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\nActivity\n\nCustom properties\n\n### Stars\n\n27 stars\n\n### Watchers\n\n1 watching\n\n### Forks\n\n3 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * Python 88.7%\n  * Jupyter Notebook 11.3%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": true}
