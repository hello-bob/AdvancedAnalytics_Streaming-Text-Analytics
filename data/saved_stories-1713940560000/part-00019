{"aid": "40136329", "title": "I asked 100 devs why they aren't shipping faster. Here's what I learned", "url": "https://greptile.com/blog/100-devs", "domain": "greptile.com", "votes": 7, "user": "rbanffy", "posted_at": "2024-04-23 19:43:24", "comments": 2, "source_title": "I asked 100 devs why they aren\u2019t shipping faster. Here\u2019s what I learned - Greptile", "source_text": "I asked 100 devs why they aren\u2019t shipping faster. Here\u2019s what I learned -\nGreptile\n\n# I asked 100 devs why they aren\u2019t shipping faster. Here\u2019s what I learned\n\nDaksh Gupta\n\nFeb 19, 2024\n\nI\u2019ve been very interested in the topic of development velocity for a long\ntime. It\u2019s something we spend a lot of time thinking about at Onboard AI, both\nfor our internal operations as well as for the thousands of developers that\nuse Onboard to ship code faster.\n\nIn my conversations with engineering leaders, there is near unanimous\nagreement that development speed should be a top 3 priority for CTOs,\nalongside quality and compliance. CTOs, however, have -\n\n  * a wide variety of ways to measure dev speed\n\n  * very little consensus on what actually slows devs down.\n\nNaturally #2 varies based on company size, culture, as well as the nature of\nthe product and composition of the team. Is it a team of young, high-energy\nbut low experience developers? Relatively flat hierarchy? Are the teams\nsiloed?\n\nI figured it would be interesting to examine this topic at the grassroots, or\nindividual contributor, level. So I found 100 software engineers from these\ncompanies \u2192\n\n  * Meta\n\n  * Pinterest\n\n  * Amazon\n\n  * Paradigm\n\n  * Heroku\n\n  * Zeta\n\n  * C3\n\n  * Roblox\n\n  * Humane\n\n  * Stripe\n\n  * Granular\n\n  * Palantir\n\n  * Segment\n\n  * eBay\n\n  * Splunk\n\n  * DraftKings\n\n  * Arista Networks\n\n  * Zillow\n\n  * Workday\n\n  * Cisco\n\n  * Stripe\n\n  * Convoy\n\n  * CrowdStrike\n\n  * SpaceX\n\n  * Google\n\n...and I asked them exactly one question.\n\nWhat\u2019s stopping you from shipping faster?\n\nI was surprised by two things:\n\n  1. Almost no-one had to think about it. People shot back with an immediate answer, as though I had just asked about a pain that was always on their mind, but never surfaced by another person.\n\n  2. There were a surprisingly high number of people for whom the reason had to do with build, compile, and deployment times. Devs really hate waiting for things.\n\nThe answers were diverse but I have done my best to broadly divide them into\ncategories and subcategories.\n\n## Codebase\n\n### Dependency bugs\n\nSoftware is a delicate of house cards with open source libraries all the way\ndown. In a lot of software, the source code comprises mostly of dependencies,\nand very often your most frustrating bug is no even your fault.\n\nJack, ex-Microsoft and ex-Bridgewater lists his #1 barrier to shipping faster\n-\n\n>Hitting random mysterious bugs with libraries that require reading tons of\nold stack overflow links and Github issues\n\n### Complicated codebase\n\nThis one is closest to my heart. In the last decade as dev speed has evolved\ninto a necessary competitive advantage, nearly every software team suffers\nfrom code sprawl. The logic is sound:\n\n  * \u2192 Growing startup\n\n  * \u2192 must ship faster\n\n  * \u2192 no time to write docs\n\n  * \u2192 early engineers churn as company grows\n\n  * \u2192 new engineers need to navigate the mess.\n\nMaria, who is an SDE at Amazon says this about her team\u2019s codebase:\n\n>There is so much undocumented in our service, including poor records of new\nfeatures, nonexistent or outdated info on our dependencies, or even essential\nthings like best practices for testing, a lot of time is wasted in syncs\ntrying to find the right information\n\nInterestingly, this problem only gets worse with time -\n\n>Nobody has time to update the documentation, which creates a vicious cycle\nwhere more features are shipped, causing the docs to be more outdated and\nuseless, meaning no one updates or uses them, and so on. A lot of our docs\nhaven\u2019t been updated in years\n\n>Microservices architectures bring the additional challenge of being difficult\nto understand on a systems level.\n\nJennifer, senior engineer at Palantir describes her struggles with navigating\nmicroservices architectures:\n\n>...ramping up on how all the different microservices interacted with each\nother for a project that touched many pieces at once was always a challenge.\n\nOf course, this problem extends to enormous monoliths too. Here\u2019s what Pranav,\na senior engineer at Stripe had to say about that:\n\n>We had Ruby code in the millions of lines. We had a service called livegrep\nthat would let us search the entire codebase very quickly but it was still\nhard to find things sometimes and other times, you found way too many matches\n(for eg, if you were search for a typed structure to see how folks have used\nit)\n\nOften at larger companies, the problem is understanding systems, rather than\nmodules. This especially harder when the stack is fragmented. Here\u2019s Dharma, a\nsenior engineer at Meta, on why this matters:\n\n>I have to touch cross-language repos. One part of the code will be in PHP,\nand another in Python or C++, and switching between each and seeing how they\ninteract makes it harder to finish the features.\n\nNiam, an engineer at Google, had this to say about how editing codebases and\nnot code is the hard part -\n\n>I would say deeply understanding the different components that make up a\nsystem.\n\nLike since the codebase is so big and you have to design a feature\nimplementation, you have to make sure that you understand very well how your\nfeature fits within the whole picture along with finding code pointers to the\nindividual subsystems you need to make changes to for it to work*\n\n## Process\n\n### QA Loops\n\nQA processes represent the tradeoff between quality and velocity. Developers\nwill often accuse QA of being to \u201cnitty\u201d and adding useless repetition to the\ndev cycle.\n\nTaylor, who has worked at a series of high-growth startups and now runs one,\ndescribed the QA process like this:\n\n>Me creating a test spec for QA. QA finding problems (because QA will always\nfind problems) >Getting list of problems 2 days later >Fixing merge conflicts\nbecause more code has shipped since I last pushed. Plus context switching\n>Back to QA*\n\nIn the amount of time it takes QA to review code, underlying context might\nchange, making the change more involved.\n\n### Waiting for spec\n\nAs teams grow, the number of stakeholders involved in any decision grow\nsuperlinearly. Invariably this introduces additional steps, redraws, and\namendments to the spec before engineers can begin execution.\n\nBrianna, an ex-Convoy engineer had only this to say when asked why she wasn\u2019t\nshipping faster -\n\n>just awaiting spec approval\n\n### Awaiting stakeholder approval\n\nRaj had this to say about Amazon\u2019s tedious stakeholder involvement, which he\nfelt was overreaching to the effect of detriment.\n\n> At Amazon? Meetings, approval, talking to 10 different stakeholders because\n> changing the color of a button affects 15 micro services\n\nThere is certainly stakeholder creep and that can significantly slow down\ndevelopment. Classic too many cooks. Here\u2019s Josh, ex-Meta senior software\nengineer -\n\n> Under standing product requirements took forever > Too much process for sign\n> off and too many reviewers.\n\n### Writing tests\n\nDevs complains around tests could basically be divided into not enough tests,\nand bad tests.\n\nNot enough tests - not having E2E testing means every new task needs to\ninclude writing a lot of new ad-hoc tests, no matter how small the task.\n\nHere\u2019s what Grant, SWE at a fintech unicorn had to say about that -\n\n> ...the biggest thing was we didn\u2019t have good tests or good types, so I had\n> to do a lot of work to do e2e testing of stuff whenever I wanted to ship\n> stuff\n\nBad tests - clog up the CI/CD pipeline and add unnecessary time to the deploy\nprocess. Here\u2019s Sadir, a senior engineer at Splunk, on what slows him down.\n\n> My reason would be running pipelines take lots of time and to ensure proper\n> code coverage with test cases sometimes we require these pipelines taking\n> their due time, which in turn slows us down\n\n## Tooling\n\n### Deployment/build speed\n\nThis one was quite surprising for me because I did not realize how many people\nsuffered from this. I have a whole theory around the toxicity of idle time -\ntime that is not a break but not productive either. Waiting for deployments is\nexactly that.\n\nDeploy times can often be into hours. Here\u2019s what Aryan, a developer at Arista\nNetworks had to say about what slows him down:\n\n> So for me at work it takes like 3-4 hours for a full build to complete that\n> I can run all the tests for a PR on, and those test can take anywhere from\n> 1d to 3d to get done, even with a lot of optimization So even a small\n> change, like modifying a filename can get tedious\n\nRaymond, senior engineer at Stripe, had this to say:\n\n> CI/CD pipelines being slow\n\n## People\n\n### Awaiting PR Review\n\nMost modern software companies have some version of a code review process\nwhere peers or sometimes senior engineers review code before it is merged.\nOften, engineers view this as a secondary responsibility (the primary one\nbeing writing new code). Naturally, this means code spends a disproportionate\namount of time in review.\n\nRoman, a former senior product engineer at Stripe, had this to say about PR\nreviews:\n\n> The entire PR flow i\u2019d say, even when it goes well then you wait till\n> someone approves the PR to continue\n\nAt some companies, the problem is at the other end of the spectrum -\noverreaching PR reviews eating time.\n\n> I think the number one reason I\u2019m unable to ship faster at my job is the\n> tedious code review process. Other engineers scrutinize and meticulously\n> review code, pointing out the tiniest flaws, making it harder to ship\n> sometimes.\n\n> It seems like other engineers do it just for the sake of it. Another reason\n> I can\u2019t ship code faster sometimes is because I\u2019m asking for approval from\n> senior engineers. I work on a product team, and so, every change I make is\n> very crucial and can be catastrophic, which leads to the senior engineers\n> (L6 folks) scrutinizing code at times.\n\nThis was a recurring theme, and there were come patterns:\n\n  * Most an engineers agreed that time spent awaiting PR review + time doing revisions is a necessary evil.\n\n  * Most also agree that nit-picky PR reviews are often a result of:\n\n    * Personal vendettas/prejudice/patronization.\n\n    * Developers having too much free time.\n\n    * Misaligned incentives (just because thoroughly reviewing code is good doesn\u2019t mean every nit should be picked)\n\n  * The general sense I got from engineers about the PR process does lead me to recommend to engineering leaders that they audit their teams\u2019 PR practices. There might be lost time there that is easily recoverable.\n\n### Scope creep\n\nJosh, a former engineer at C3.ai answered with brevity when asked what slowed\nhim down -\n\nPM-induced scope creep.\n\n> The human tendency to stuff last-minute items into the crevices of their\n> luggage minutes before leaving for the airport manifests itself at software\n> companies as scope creep. Slowly and surely, it pushed back your release-\n> date, with every incremental addition feeling like an insignificant task,\n> but in aggregate adding significantly molasses to a team\u2019s velocity.\n\n### Unclear requirements\n\nUnclear requirements slowing developers down is unsurprising. Based on my\nconversations, this was broadly because of three reasons:\n\n  1. Productivity closely varies with conviction. Lack of clarity on goals and success state definitions = low conviction = low motivation = low productivity.\n\n  2. You can run faster when the ground underneath you feels firm.\n\n  3. Developers don\u2019t trust management when management lacks clarity on what should be built. More so when developers don\u2019t feel that they have influence over what should be built.\n\nJustine, an ex-Meta software engineer said this about unclear requirements in\nher org.\n\n> Understanding product requirements took forever > Too much process for sign\n> off and too many reviewers. > Bad management.\n\n### Excessive meetings\n\nThis is unsurprisingly a major concern for developers. A common framework to\nthink about this is the \u201cmaker\u201d schedule and the \u201cmanager\u201d schedule. Managers\ncan scatter meetings through their day since their tasks can be done in pieces\nin the time between meetings. Making is deep work - it requires vast swaths of\nuninterrupted creative time.\n\nThe problem usually takes some form of managers managing maker time,\ninadvertently imposing the manager schedule on makers.\n\nMaria, an SDE at Amazon, cites excessive meetings as a #1 time sink.\n\n> ...lot of time is wasted in syncs trying to find the right information.\n\n## Motivation\n\nDiane, a former engineer at Meta, had this to say about the #1 reason that\nslowed her down:\n\n>honest answer is i was on ads >and that\u2019s a very old / complicated / large\nstack (edited) >and i didn\u2019t understand it >my friends on younger teams seemed\nhappier, i was miserable\n\nThis one should not be surprising. Great engineers are usually vert smart\npeople, so they want to work on things that are interesting and inspiring.\nSome projects are generally more interesting others, and those tend to move\nfaster.\n\nAnother aspect of this the lack of reward for marginally more effort. Rohan,\nan Amazon SDE, had this to say:\n\nAlso motivation. I didn\u2019t care to grind because I was on track for a promotion\nthe same rate anyway so what\u2019s the point of putting in more than a few hours\nif I\u2019m beyond expectations anyway\n\nAt large companies, individual impact is nearly impossible to measure. This\nmeans two things:\n\n  1. It\u2019s easy to get away with coasting. (Rest and vest).\n\n  2. It\u2019s hard to get recognized and rewarded for going above and beyond.\n\nThe result? Many people coast, far fewer blow past expectations.\n\n## Conclusion\n\nIt is generally accepted that development speed is a business-critical\nadvantage. Great companies live and die by how fast they ship. From the\npatterns I gathered, larger companies generally tend to be at a disadvantage\nwhen it comes to shipping fast. Sometimes for good reason, sometimes not.\n\nThey are intrinsically more risk-averse because there are serious costs to\nmissteps. This manifests itself as extensive PR reviews, QA, planning etc.\nThey are more likely to have excessive meetings and push makers to run on\nmanager schedule.\n\nThis is perhaps the circle of life - it is the added agility of an early-stage\nstartup that allows them to upset slow incumbents. If they succeed, they\nthemselves become slow-moving incumbents, waiting to be upset by their upstart\nsuccessor.\n\nNow, some graphs.\n\n## Why aren\u2019t you shipping faster (visualized)?\n\nI had to use some discretion to assign each message a category, and below is\nmy best attempt. Complicated codebase awaiting stakeholder approval were the\nbiggest deterrents to dev speed. That said, there is a significant long-tail\nof reasons. Turns out, developers have a lot to complain about.\n\nNearly a third of respondents alluded to a company or team-specific qualm, so\nI decided to omit those in interest of keeping this generally useful. (e.g.\nWorkday engineers feel slowed down by their proprietary programing language.\nFascinating, but not relevant to nearly any other company).\n\nTo make this more readable, I made a more concise chart that combines these\ninto 7 overarching categories, leaving some of the long-tail reasons out.\n\n  * Process\n\n  * People\n\n  * Codebase\n\n  * DevOps/tooling\n\n  * Motivation\n\n  * Debugging\n\n  * Docs\n\nPeople and process are usually related, and those two combined account for\nnearly half of all respondents.\n\nDisclaimer: names of survey participants have been changed to protect their\nprivacy.\n\n", "frontpage": true}
