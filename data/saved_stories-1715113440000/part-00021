{"aid": "40284633", "title": "TechScape: How cheap, outsourced labour in Africa is shaping AI English", "url": "https://www.theguardian.com/technology/2024/apr/16/techscape-ai-gadgest-humane-ai-pin-chatgpt", "domain": "theguardian.com", "votes": 1, "user": "bookofjoe", "posted_at": "2024-05-07 12:24:01", "comments": 0, "source_title": "TechScape: How cheap, outsourced labour in Africa is shaping AI English", "source_text": "TechScape: How cheap, outsourced labour in Africa is shaping AI English | Technology | The Guardian\n\nSkip to main contentSkip to navigation\n\nSkip to navigation\n\nPrint subscriptions\n\nSign in\n\nSearch jobs\n\nSearch\n\n  * Europe edition\n\n  * UK edition\n\n  * US edition\n\n  * Australia edition\n\n  * International edition\n\nThe Guardian - Back to homeThe Guardian\n\n  * World\n  * Europe\n  * US\n  * Americas\n  * Asia\n  * Australia\n  * Middle East\n  * Africa\n  * Inequality\n  * Global development\n\nThe text AI assistants spit out is ineffably generated ... ChatGPT.\nPhotograph: Kirill Kudryavtsev/AFP/Getty Images\n\nThe text AI assistants spit out is ineffably generated ... ChatGPT.\nPhotograph: Kirill Kudryavtsev/AFP/Getty Images\n\nTechScape newsletterTechnology\n\n# TechScape: How cheap, outsourced labour in Africa is shaping AI English\n\nWorkers in Africa have been exploited first by being paid a pittance to help\nmake chatbots, then by having their own words become AI-ese. Plus, new AI\ngadgets are coming for your smartphones\n\nDon\u2019t get TechScape delivered to your inbox? Sign up for the full article here\n\nAlex Hern\n\nShare\n\nWe\u2019re witnessing the birth of AI-ese, and it\u2019s not what anyone could have\nguessed. Let\u2019s delve deeper.\n\nIf you\u2019ve spent enough time using AI assistants, you\u2019ll have noticed a certain\nquality to the responses generated. Without a concerted effort to break the\nsystems out of their default register, the text they spit out is, while\ngrammatically and semantically sound, ineffably generated.\n\nSome of the tells are obvious. The fawning obsequiousness of a wild language\nmodel hammered into line through reinforcement learning with human feedback\nmarks chatbots out. Which is the right outcome: eagerness to please and\ngeneral optimism are good traits to have in anyone (or anything) working as an\nassistant.\n\nSimilarly, the domains where the systems fear to tread mark them out. If you\never wonder whether you\u2019re speaking with a robot or a human, try asking them\nto graphically describe a sex scene featuring Mickey Mouse and Barack Obama,\nand watch as the various safety features kick in.\n\nOther tells are less noticeable in isolation. Sometimes, the system is too\ngood for its own good: A tendency to offer both sides of an argument in a\nsingle response, an aversion to single-sentence replies, even the generally\nflawless spelling and grammar are all what we\u2019ll shortly come to think of as\n\u201crobotic writing\u201d.\n\nAnd sometimes, the tells are idiosyncratic. In late March, AI influencer\nJeremy Nguyen, at the Swinburne University of Technology in Melbourne,\nhighlighted one: ChatGPT\u2019s tendency to use the word \u201cdelve\u201d in responses. No\nindividual use of the word can be definitive proof of AI involvement, but at\nscale it\u2019s a different story. When half a percent of all articles on research\nsite PubMed contain the word \u201cdelve\u201d \u2013 10 to 100 times more than did a few\nyears ago \u2013 it\u2019s hard to conclude anything other than an awful lot of medical\nresearchers using the technology to, at best, augment their writing.\n\nA search by Dr Jeremy Nguyen suggests that a portion of articles on PubMed may\nhave been partly written by ChatGPT. Photograph: Jeremy Nguyen/X\n\nAccording to another dataset, \u201cdelve\u201d isn\u2019t even the most idiosyncratic word\nin ChatGPT\u2019s dictionary. \u201cExplore\u201d, \u201ctapestry\u201d, \u201ctestament\u201d and \u201cleverage\u201d all\nappear far more frequently in the system\u2019s output than they do in the internet\nat large.\n\nIt\u2019s easy to throw our hands up and say that such are the mysteries of the AI\nblack box. But the overuse of \u201cdelve\u201d isn\u2019t a random roll of the dice.\nInstead, it appears to be a very real artefact of the way ChatGPT was built.\n\nA brief explanation of how things work: GPT-4 is a large language model. It is\na truly mammoth work of statistics, taking a dataset that seems to close to\n\u201cevery piece of written English on the internet\u201d and using it to create a\ngigantic glob of data that spits out the next word in a sentence.\n\nBut an LLM is raw. It is tricky to wrangle into a useful form, hard to prevent\ngoing off the rails and requires genuine skill to use well. Turning it into a\nchatbot requires an extra step, the aforementioned reinforcement learning with\nhuman feedback: RLHF.\n\nAn army of human testers are given access to the raw LLM, and instructed to\nput it through its paces: asking questions, giving instructions and providing\nfeedback. Sometimes, that feedback is as simple as a thumbs up or thumbs down,\nbut sometimes it\u2019s more advanced, even amounting to writing a model response\nfor the next step of training to learn from.\n\nThe sum total of all the feedback is a drop in the ocean compared to the\nscraped text used to train the LLM. But it\u2019s expensive. Hundreds of thousands\nof hours of work goes into providing enough feedback to turn an LLM into a\nuseful chatbot, and that means the large AI companies outsource the work to\nparts of the global south, where anglophonic knowledge workers are cheap to\nhire. From last year:\n\n> The images pop up in Mophat Okinyi\u2019s mind when he\u2019s alone, or when he\u2019s\n> about to sleep. Okinyi, a former content moderator for OpenAI\u2019s ChatGPT in\n> Nairobi, Kenya, is one of four people in that role who have filed a petition\n> to the Kenyan government calling for an investigation into what they\n> describe as exploitative conditions for contractors reviewing the content\n> that powers artificial intelligence programs.\n\nI said \u201cdelve\u201d was overused by ChatGPT compared to the internet at large. But\nthere\u2019s one part of the internet where \u201cdelve\u201d is a much more common word: the\nAfrican web. In Nigeria, \u201cdelve\u201d is much more frequently used in business\nEnglish than it is in England or the US. So the workers training their systems\nprovided examples of input and output that used the same language, eventually\nending up with an AI system that writes slightly like an African.\n\nAnd that\u2019s the final indignity. If AI-ese sounds like African English, then\nAfrican English sounds like AI-ese. Calling people a \u201cbot\u201d is already a\nschoolyard insult (ask your kids; it\u2019s a Fortnite thing); how much worse will\nit get when a significant chunk of humanity sounds like the AI systems they\nwere paid to train?\n\nskip past newsletter promotion\n\nSign up to TechScape\n\nFree weekly newsletter\n\nAlex Hern's weekly dive in to how technology is shaping our lives\n\nPrivacy Notice: Newsletters may contain info about charities, online ads, and\ncontent funded by outside parties. For more information see our Privacy\nPolicy. We use Google reCaptcha to protect our website and the Google Privacy\nPolicy and Terms of Service apply.\n\nafter newsletter promotion\n\n## AI hardware is here\n\nRabbit Inc\u2019s R1, an \u2018intuitive companion device\u2019.\n\nThe world of atoms moves more slowly than the world of bits. The November 2022\nlaunch of ChatGPT led to a flurry of activity. But where digital competitors\nlaunched in a matter of weeks, we\u2019re only now starting to see the physical\nramifications of the AI revolution.\n\nOn Monday, AI-search-engine-for-your-mind startup Limitless revealed its first\nphysical product, a $99 pendant that you wear on your shirt to record, well,\neverything. From the Verge:\n\n> The $99 device is meant to be with you all the time ... and uses beam-\n> forming tech to more clearly record the person speaking to you and not the\n> rest of the coffee shop or auditorium. Limitless can do a lot to help you\n> keep track of conversations. What was that new app someone mentioned in the\n> board meeting? What restaurant did Shannon say we should go to next time?\n> Where did I leave off with Jake when we met two weeks ago? In theory,\n> Limitless can get that data and use AI models to get it back to you any time\n> you ask.\n\nIt\u2019s a genuinely exciting space to cover because no one actually knows what AI\nhardware should be. Limitless has one answer; Rabbit has a very different one,\nwith its R1:\n\n> R1 is built as an intuitive companion device that saves users time. While\n> phones have evolved into all-encompassing personal entertainment devices in\n> recent years, r1 is positioned as a standalone hardware portal to cut\n> through distractions and help users handle their everyday digital tasks\n> smarter, more efficiently, and more delightfully.\n\nLooking like a small, square smartphone, the R1 is a push-button partner to an\nAI agent which, the company says, can be trained to carry out tasks on your\nbehalf. The physical object, designed by renowned consultancy Teenage\nEngineering, looks delectable, but the whole thing rides on whether the AI\nagent at its heart can actually be trusted. At its best, it could bring\npowerful AI assistants into our daily lives; at its worst, it would just make\nyou nostalgic for Siri.\n\nAnd the worst is not impossible. Humane is the first major company to get AI\nhardware to market, with its AI Pin \u2013 and it\u2019s not gone well. From the Verge\u2019s\nreview:\n\n> As the overall state of AI improves, the AI Pin will probably get better,\n> and I\u2019m bullish on AI\u2019s long-term ability to do a lot of fiddly things on\n> our behalf. But there are too many basic things it can\u2019t do, too many things\n> it doesn\u2019t do well enough, and too many things it does well but only\n> sometimes that I\u2019m hard-pressed to name a single thing it\u2019s genuinely good\n> at. None of this \u2013 not the hardware, not the software, not even GPT-4 \u2013 is\n> ready yet.\n\nThe AI pin isn\u2019t going to be the last piece of AI hardware we see, then. But\nit might be Humane\u2019s last.\n\nIf you want to read the complete version of the newsletter please subscribe to\nreceive TechScape in your inbox every Tuesday.\n\nExplore more on these topics\n\n  * Technology\n  * TechScape newsletter\n  * ChatGPT\n  * Gadgets\n  * Artificial intelligence (AI)\n  * Language\n  * Nigeria\n  * Africa\n  * newsletters\n\nShare\n\nReuse this content\n\n## Most viewed\n\n## Most viewed\n\n  * World\n  * Europe\n  * US\n  * Americas\n  * Asia\n  * Australia\n  * Middle East\n  * Africa\n  * Inequality\n  * Global development\n\n  * News\n  * Opinion\n  * Sport\n  * Culture\n  * Lifestyle\n\nOriginal reporting and incisive analysis, direct from the Guardian every\nmorning\n\nSign up for our email\n\n  * Help\n  * Complaints & corrections\n  * SecureDrop\n  * Work for us\n  * Privacy policy\n  * Cookie policy\n  * Terms & conditions\n  * Contact us\n\n  * All topics\n  * All writers\n  * Digital newspaper archive\n  * Facebook\n  * YouTube\n  * Instagram\n  * LinkedIn\n  * Twitter\n  * Newsletters\n\n  * Advertise with us\n  * Search UK jobs\n\nBack to top\n\n\u00a9 2024 Guardian News & Media Limited or its affiliated companies. All rights\nreserved. (dcr)\n\n", "frontpage": false}
