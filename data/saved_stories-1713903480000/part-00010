{"aid": "40131955", "title": "Compute Visual Similarity of Top-Level Domains (2014)", "url": "https://hissa.nist.gov/~black/GTLD/", "domain": "nist.gov", "votes": 1, "user": "rdpintqogeogsaa", "posted_at": "2024-04-23 13:50:56", "comments": 0, "source_title": "Compute Visual Similarity of Top-Level Domains", "source_text": "Compute Visual Similarity of Top-Level Domains\n\n## Special Project\n\n# Compute Visual Similarity of Top-Level Domains\n\nCompute the visual similarity between a possible new Generic Top-Level Domain\n(TLD) and other proposed TLDs, current TLDs, and reserved words.\n\nThis web site describes experimental software developed at the National\nInstitute of Standards and Technology (NIST). No algorithms, code, or\ndescriptions in whole or in part are recommended, used, or endorsed by the\nInternet Corporation for Assigned Names and Numbers (ICANN) or any other\nentity.\n\n## Compare Against All\n\nCompare a string to other proposed TLDs, current TLDs, including country\ncodes, and reserved words.\n\nProposed Top-Level Domain:\n\nNote: All characters other than 0-9, a-z, A-Z, and hyphen (-) are removed.\n\n## Compare Two Strings\n\nCompare two strings to each other.\n\nString 1: String 2:\n\nNote: All characters other than 0-9, a-z, A-Z, and hyphen (-) are removed.\n\n### Background\n\nComputers connect the Internet with numbers, IP addresses. However, people use\nstrings ending in short segments like .edu, .uk, .tv, and .com, called Top-\nLevel Domains (TLDs) to navigate the World Wide Web. Ensuring the ongoing\nsecurity and stability of the Domain Name System is one activity of the\nInternet Corporation for Assigned Names and Numbers (ICANN). With the growth\nof the Web, there is a possibility of a lot of new TLDs. As one method to\nimplement the recommendation that, \"Strings must not be confusingly similar to\nan existing top-level domain ...\", this web page invokes an algorithm\ndeveloped at NIST \"to provide an open, objective, and predictable mechanism\nfor assessing the degree of visual confusion\" between proposed or existing\nTLDs.\n\nThe algorithm takes into account varying degrees of similarity between some 60\npairs, like 0 and O (zero and oh), 1 and l (one and L), Z and 2, h and n, rn\n(R and N) and m, and w and vv (v v). Even insertions or deletions may cause\nconfusion, for example .aaaah and .aaaaah look very much alike. The task is\nall the more challenging because domain names are not case sensitive.\n\nDoes such confusion happen in real life? Here's a piece of text from my\nscreen.\n\nI actually read the second line as \"w a m s\", not \"w a r n s\", even though\n\"wams\" is not a word!\n\nNote that the algorithm is not meant to consider phonetic similarity. For\nexample, \"fish\", \"phish\", and \"fiche\" sound alike, but are visually distinct\nand unlikely to be confused.\n\n### Web Interface\n\nThe first form has the algorithm compare a string against proposed generic\nTLDs, existing TLDs, including country codes, and reserved words. It reports\nexact matches, near matches, and best matches if there are no near matches.\n\nThe second form uses the algorithm to compare two strings against each other.\n\nOnly alphabetic characters (a-z and A-Z), numerals (0-9), and hyphens (-) are\nallowed in strings. See RFC 1035 2.3.1.\n\n### The Code and The Algorithm\n\nThe score is an enhanced Levenshtein distance that is adjusted for length and\nnormalized. Other possibilities for distance measures are Jaro-Winkler,\nDamerau-Levenshtein, cosine distance, and many others.\n\nThe code is written in Python. The interface to the algorithm itself is a\nsingle function, howConfusableAre(). It takes two parameters: the two strings\nto be compared.\n\nHowConfusableAre() calls levenshtein() to compute a form of edit difference,\nthen normalizes the score and accounts for string lengths.\n\nLevenshtein() takes two strings. It is an enhanced Levenshtein distance\nalgorithm that accounts for substituting two characters by one (or vice\nversa), inserting an additional repeated character, and transposition, as well\nas the usual insertion, deletion, and substitution. The result is roughly the\nnumber of visual differences between the strings. I say \"roughly\" because\nsubstituting O (upper case letter \"o\") for 0 (zero) is a much smaller\ndifference than substituting, say, w for t. Levenshtein() calls two routines\nto find similarity, and hence cost, for substituting or transposing characters\nor \"digraph\" (character pairs): characterSimilarity() and digraphSimilarity().\n\nBoth characterSimilarity() and digraphSimilarity() take two strings (single\ncharacters in the case of characterSimilarity()). Both work much the same way:\nlook up the passed strings in a table. If they are in the table, return the\nvalue in the table. If not, use the default: 0 means completely different and\n1 means identical.\n\nThe code, data, and automatic test material are in the file\nvisualSimilarity.tar, which is a tar file.\n\n### Cautions\n\nThe algorithm, consisting of the distance measure, the scoring formula, and\nthe character similarities are mostly just my estimations. Several people have\nlooked at resulting scores. I adjusted the formula and a few weights to\ncorrespond with feedback. Still the algorithm has not been systematically or\nindependently validated.\n\nWeb page Created Tue Feb 5 16:49:10 2008 by Paul E. Black\n(paul.black@nist.gov) Updated Mon Jun 9 13:47:03 2014 by Paul Black\n(paul.black@nist.gov)\n\nContact: webmaster@nist.gov PRIVACY/SECURITY ISSUES FOIA \u2022 Disclaimer \u2022\nUSA.gov| Information Technology Laboratory Software and Systems Division NIST\nis an agency of the U.S. Commerce Department  \n---|---\n\n", "frontpage": false}
