{"aid": "40198120", "title": "Designing Usefully Unintelligent AI Summaries", "url": "https://multi.app/blog/designing-usefully-unintelligent-ai-summaries", "domain": "multi.app", "votes": 1, "user": "embirico", "posted_at": "2024-04-29 13:32:13", "comments": 0, "source_title": "Multi Blog \u2013 Designing Usefully Unintelligent AI Summaries", "source_text": "Multi Blog \u2013 Designing Usefully Unintelligent AI Summaries\n\nChatbots are being added to every software product in the cloud and under the\nsun. But while they're mostly cool, they're not consistently useful.\n\nA cool exploration of adding an AI bot to chat in Multi, which we thankfully\ndid not ship\n\nMany AI features fail because they require too much \"intelligence\" from both\nLLMs and users. And it's not because the models \"aren't quite good enough.\"\nChatbots are not the future. Instead LLM features require careful UX design\nfor a specific use case.\n\nLast week, we shipped our first LLM-based features: Summaries and Shared\nContent References. Unlike other approaches we\u2019ve seen, we deliver our\nsummaries in a real-time multiplayer text editor, and iterated to surprisingly\nsimple underlying prompts. In this post, we\u2019ll explore some of the principles\nthat led to those decisions.\n\n# Our use case: Video calls for getting work done together\n\nAt Multi, we're building video calls to help software teams get work done\ntogether. So far, we\u2019ve been focused on features for multiplayer collaboration\nduring sessions. A modern take on Screenhero.\n\nNow we're starting to use LLMs to help with follow ups, sharing context with\nteammates, and keeping a team\u2019s knowledge fresh. For any productivity nerds,\nthat\u2019s connecting \"sync & async.\"\n\n# Challenges building for software teams\n\nThere\u2019s a growing plethora of summarizers and recorders for sales, support and\ngeneral use cases, but they miss the mark for software teams.\n\nConversations about building together bring a few additional challenges:\n\n  * Discussion centers around designs, code, or docs. Imagine pairing without seeing the screenshare! The transcript is woefully insufficient.\n\n  * Any knowledge that does lie in the transcript is highly specific in both terms and phrasing. LLMs are unlikely to retain that nuance.\n\n  * Conversations are collaborative, which means that participants need shared outputs, and shared affordances to generate them.\n\n# Principles\n\nOur goal is for AI features in Multi to feel like they're provided by a\nproactive AI assistant that coinhabits your workspace and leans on shared\ncontext.\n\nHere are the principles we came to:\n\n  1. Lean on the facts\n\n  2. Make the AI feel like a teammate\n\n  3. No prompts. Instead, provide useful actions in context\n\n# 1\\. Lean on the facts\n\n## LLM summaries are imprecise but can serve as skimmable pointers to factual\ncontent\n\nLLMs aren\u2019t suited to writing at the specificity needed to communicate\ndecisions, rationales, or plans. One classic mistake is missed or confused\nnegations. For example \u201cAlice,\u201d a user in our early access, sent us this\nsummary point we'd generated:\n\n\u00b7 Alice is merging extraction work to avoid blocking production deployment.\n\nShe then told us:\n\n\"I wasn\u2019t merging anything to avoid blocking a deployment. I was merging stuff\nand it needs to be tested out before we can deploy to production. So it was\ninversed.\"\n\nAlthough GPT4 got the nuance of the plan wrong here, it did capture a few\nrelevant themes: \u201cAlice,\u201d \u201cextraction work\u201d, and \u201cblocking production\ndeployment.\u201d This generalizes to something useful: LLMs are good at\ntransforming transcripts into skimmable snippets that capture the gist of a\nconversation.\n\n## Skimmable summaries; factual details\n\nFor the details that LLMs are not suited for, we can rely instead on the\nactual artifacts that were discussed. We can link to those, include\nscreenshots, or find the right moment in the recording. This pairing of\nskimmable summaries with factual details brings us to a content taxonomy,\nwhich is in effect a roadmap for us.\n\nTo intuit this, imagine catching up on Slack. Can you see yourself skimming\nsomething in the left column, and occasionally wanting to learn more?\nConversely, how often will you read a transcript or watch a recording without\nsome skimmable context first?\n\n## The notepad\n\nLets see these elements in Multi. As of our March 7th changelog, here\u2019s what a\nnotepad looks like after a session:\n\nWe think the above is still light on facts, and plan to fix that. Here\u2019s an\nexploration of how we might add citations that reference the transcript and\nrecording:\n\n# 2\\. Make the AI feel like a teammate\n\n## High fidelity AI outputs require high fidelity human inputs\n\nWattenberger writes about the \u201cspectrum of how much human input is required\nfor a task\":\n\n  * \"When a task requires mostly human input, the human is in control.\"\n\n  * \"But once we offload the majority of the work to a machine, the human is no longer in control.\u201d\n\nMulti is a team communication tool. How can we elegantly provide control of AI\nacross multi-step workflows like taking notes then sharing them, or tracking\naction items then filing tickets?\n\nDavis Treybig mentions Debuild as a good example of \u201cvalidation affordances\u201d:\n\nDebuild \"asks you to validate the use cases it thinks you need, and you can\nedit/modify those use cases before moving forward.\"\n\nThis works well for a single focused workflow, but each custom flow we add\ndistracts from the ongoing discussion and makes the app more complex. Build\none for each possible workflow during or after a conversation, and we quickly\nend up an overwhelming app.\n\n## The AI is just a teammate taking notes with you\n\nCan we feed AI into familiar multiplayer affordances, instead of creating a\nnew system? Luckily, we\u2019ve spent a year designing simple but powerful\nprimitives for multiplayer collaboration in Multi.\n\nWe realized that if we build the AI to interact with us like a teammate, it\nbecomes immediately obvious to understand all of the below, in real time:\n\n  * What it\u2019s doing, including intermediate steps\n\n  * How to add, edit, and remove intermediate and final AI outputs\n\n  * When teammates are interacting with it\n\nThat\u2019s why Multi\u2019s AI primarily delivers output in the same realtime\nmultiplayer notepad that users can take notes in. Here are some of the options\nwe explored to get to that:\n\nUltimately, we decided that the closer AI notes felt to teammate notes, the\nmore natural it would feel to correct it\u2014to work with it.\n\n## Example workflow: Tracking action items and filing to Linear\n\nWe want a system where:\n\n  * The user, AI, or other teammates can add action items.\n\n  * All action items are editable by any the user or other teammates.\n\n  * All action items, whether or not they've been edited, can become draft Linear issues with one click.\n\nBy making action items blocks in a multiplayer text editor, that have a\n\"Create Issue\" button, this all just works!\n\n# 3\\. No prompts. Instead, provide useful actions in context\n\n## Just do the basic thing, automatically\n\nThe first AI feature we shipped to early access was open-ended prompting. It\nwas my (terrible) idea. After some inspiring conversations with power users\nwho imagined all sorts of use cases, I was excited to see what they\u2019d come up\nwith.\n\nAnd... nobody used it. Few tried prompting, and even fewer tried again. The\nproblems were clear: We were making users guess what capabilities our AI had,\ndecide how and when to use them, and also how to prompt for good results.\n\nWe quickly pivoted and shipped the obvious thing: AI summaries, triggered\nautomatically after a session, with a prompt we\u2019d refined to be useful most of\nthe time.\n\n## The confidence spectrum\n\nAutomatically triggering the AI is great when we\u2019re be confident it\u2019ll be\nuseful. But what happens when we\u2019re less sure? Depending on our level of\nconfidence, here are some UX patterns that we use or plan to use. In each\ncase, we take as much context as possible from the interface so that the user\ndoesn\u2019t have to prompt.\n\n### Expand on a topic\n\nWe can automatically trigger short, skimmable summaries after calls because\nwe\u2019re confident they\u2019ll be useful. However, what if someone wants more detail,\nor they want it during the call? Since we can\u2019t reliably predict the timing or\ncontent, we can give the user explicit affordances to tell us.\n\n### File an issue\n\nSimilarly, it\u2019s useful to quickly file an issue with detailed content, but for\nmost teams,relatively few action items should become issues.\n\n### Transcript-based copilot\n\nGitHub copilot works well in part because it seamlessly takes context from the\nworkspace, and has a lightweight UX for triaging and incorporating\nsuggestions. What if you had a copilot while taking notes, that predicted\nbased on what\u2019s been said?\n\n## So, are open-ended inputs ever the right solution?\n\nAs long as you aren\u2019t relying on them, we think open-ended inputs are worth\nincorporating as another means of interaction for power users.\n\nFor example, the above button to expand on a line is great while editing, but\nit\u2019s not discoverable otherwise. What would a permanent affordance to write a\ndetailed summary or answer look like?\n\n### Open ended summaries, with suggestions\n\nWe brought back our failed experiment of open ended prompts, but with two key\nfixes that have increased usage to healthy levels:\n\n  * First, this prompt is shown below the skimmable summary. That creates a clear workflow of reading the concise summary, and using the prompt to learn more.\n\n  * Second, we added suggestions for topics. This pattern creates buttons for those topics, avoids being annoying when we\u2019re wrong, and most importantly helps teach users how they can use the feature in context.\n\n## Deliver outputs in context. No, really in context\n\nIt seems intuitively right for users and AI come together to write notes in a\nnotepad, but is that really the right place for final delivery? In most cases,\nno. Users want these notes in Slack, Notion, Linear, etc.\n\nSo naturally, we\u2019re exploring how Multi can push notes into existing tools.\nMost of our reasonable explorations look like the \u201cCreate Linear Issue from\nAction Item\u201d flow above: Some action you can take from the notepad.\n\nThe problem is, these might be automations, but they feel like extra work. You\nshouldn\u2019t have to migrate design crit feedback into Figma\u2014it should just be\nthere when you revisit the designs. Hence what might be the most provocative\nidea here...\n\n### AI that responds to OS context\n\nAre you getting minor heartburn thinking about how and when this will activate\nwithout being annoying? So are we. Please send help.\n\n# Conclusion\n\nWe\u2019re just getting started with AI interfaces for calls and desktop OSes. I\u2019d\nlove hear your thoughts on these applied principles, and if you made it here\nI'd love to read whatever else you\u2019re finding interesting. Please find me at\n@embirico on X/Twitter or LinkedIn, or email me at alexander@.\n\nIf Multi seems like it could be useful for you, we have a generous free tier\nthat temporarily includes a preview of the above AI features. I\u2019d love for you\nto check it out!\n\nSubscribe to Remotion email updates\n\nDesign\n\nAlexander Embiricos\n\nMar 15, 2024\n\n\u00b7\n\n# Designing Usefully Unintelligent AI Summaries\n\n\u00a9 Multi Software Co. 2024\n\nDownload\n\nContact\n\nPrivacy\n\nSecurity\n\nTerms\n\nBlog\n\n", "frontpage": false}
