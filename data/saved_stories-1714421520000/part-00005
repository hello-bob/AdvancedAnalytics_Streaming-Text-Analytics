{"aid": "40197851", "title": "Show HN: An API for detecting NSFW images", "url": "https://github.com/steelcityamir/safe-content-ai", "domain": "github.com/steelcityamir", "votes": 1, "user": "codebyamir", "posted_at": "2024-04-29 13:08:18", "comments": 0, "source_title": "GitHub - steelcityamir/safe-content-ai: A fast accurate API for detecting NSFW images.", "source_text": "GitHub - steelcityamir/safe-content-ai: A fast accurate API for detecting NSFW\nimages.\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nsteelcityamir / safe-content-ai Public\n\n  * Notifications\n  * Fork 0\n  * Star 2\n\nA fast accurate API for detecting NSFW images.\n\nsafecontentai.com\n\n### License\n\nMIT license\n\n2 stars 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# steelcityamir/safe-content-ai\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n2 Branches\n\n1 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nsteelcityamirUpdate README.mdApr 24, 202475b9cae \u00b7 Apr 24, 2024Apr 24, 2024\n\n## History\n\n48 Commits  \n  \n### .github/workflows\n\n|\n\n### .github/workflows\n\n| Update ci.yml| Apr 22, 2024  \n  \n### .coveragerc\n\n|\n\n### .coveragerc\n\n| Update .coveragerc| Apr 22, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Initial commit| Apr 22, 2024  \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n| Update Dockerfile| Apr 22, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Initial commit| Apr 22, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| Update README.md| Apr 24, 2024  \n  \n### SECURITY.md\n\n|\n\n### SECURITY.md\n\n| Create SECURITY.md| Apr 22, 2024  \n  \n### main.py\n\n|\n\n### main.py\n\n| Removed /api prefix| Apr 23, 2024  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| Initial commit| Apr 22, 2024  \n  \n### sunflower.jpg\n\n|\n\n### sunflower.jpg\n\n| Updates| Apr 22, 2024  \n  \n### test-requirements.txt\n\n|\n\n### test-requirements.txt\n\n| Updates| Apr 22, 2024  \n  \n### test_main.py\n\n|\n\n### test_main.py\n\n| Removed /api prefix| Apr 23, 2024  \n  \n## Repository files navigation\n\n# Safe Content AI\n\nA fast accurate API for detecting NSFW images. Ideal for content moderation on\ndigital platforms.\n\nThis project uses Python, FastAPI framework, Transformers library, and\nTensorFlow.\n\nTensorFlow will automatically detect and use the GPU if the underlying\nhardware supports it.\n\n## \u2b50 Features\n\n  * Uses the Falconsai/nsfw-image-detection AI model\n  * Caches results based on SHA-256 hash of image data\n\n## \ud83d\udc33 Quick Start using Docker\n\n    \n    \n    docker run -p 8000:8000 steelcityamir/safe-content-ai:latest\n\nTest using curl\n\n    \n    \n    curl -X POST \"http://127.0.0.1:8000/v1/detect\" \\ -H \"Content-Type: multipart/form-data\" \\ -F \"file=@/path/to/your/image.jpeg\"\n\n## Getting Started\n\n### Prerequisites\n\nEnsure you have Python 3.7+ installed on your system.\n\n### Installation\n\nClone the repository to your local machine:\n\n    \n    \n    git clone https://github.com/steelcityamir/safe-content-ai.git\n\nNavigate to the cloned directory:\n\n    \n    \n    cd safe-content-ai\n\nCreate a virtual environment\n\n    \n    \n    python -m venv venv source venv/bin/activate\n\nInstall the required libraries using pip:\n\n    \n    \n    pip install -r requirements.txt\n\n### Running the API\n\nStart the API server from your command line:\n\n    \n    \n    uvicorn main:app --reload\n\nThe API server runs on port 8000.\n\n## API usage\n\n### POST /v1/detect\n\nThis endpoint allows users to upload an image file, which is then processed to\ndetermine if the content is NSFW (Not Safe For Work). The response includes\nwhether the image is considered NSFW and the confidence level of the\nprediction.\n\n#### Request\n\n  * URL: /v1/detect\n  * Method: POST\n  * Content-Type: multipart/form-data\n  * Body:\n\n    * file (required): The image file to be classified.\n\n#### Response\n\n  * Content-Type: application/json\n  * Body:\n    \n        { \"file_name\": \"string\", \"is_nsfw\": \"boolean\", \"confidence_percentage\": \"number\" }\n\n#### Curl\n\n    \n    \n    curl -X POST \"http://127.0.0.1:8000/v1/detect\" \\ -H \"Content-Type: multipart/form-data\" \\ -F \"file=@/path/to/your/image.jpeg\"\n\n## \ud83d\udcc4 License\n\nThis project is licensed under the MIT License - see the LICENSE file for\ndetails.\n\n## Support\n\nFor support, please open an issue in the GitHub issue tracker for this\nproject.\n\n## About\n\nA fast accurate API for detecting NSFW images.\n\nsafecontentai.com\n\n### Topics\n\npython api open-source machine-learning ai tensorflow image-processing image-\nclassification content-moderation nsfw-detection\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\n### Security policy\n\nSecurity policy\n\nActivity\n\n### Stars\n\n2 stars\n\n### Watchers\n\n2 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Releases 1\n\n1.0.0 Latest\n\nApr 23, 2024\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * Python 87.4%\n  * Dockerfile 12.6%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
