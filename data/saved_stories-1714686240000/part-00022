{"aid": "40235832", "title": "The life and time of an Abstract Syntax Tree", "url": "https://blog.trailofbits.com/2024/05/02/the-life-and-times-of-an-abstract-syntax-tree/", "domain": "trailofbits.com", "votes": 1, "user": "frabert", "posted_at": "2024-05-02 13:13:23", "comments": 0, "source_title": "The life and times of an Abstract Syntax Tree", "source_text": "The life and times of an Abstract Syntax Tree | Trail of Bits Blog\n\n# Trail of Bits Blog\n\n# The life and times of an Abstract Syntax Tree\n\n  * Post\n  * May 2, 2024\n  * Leave a comment\n\nBy Francesco Bertolaccini\n\nYou\u2019ve reached computer programming nirvana. Your journey has led you down\nmany paths, including believing that God wrote the universe in LISP, but now\nthe truth is clear in your mind: every problem can be solved by writing one\nmore compiler.\n\nIt\u2019s true. Even our soon-to-be artificially intelligent overlords are nothing\nbut compilers, just as the legends foretold. That smart contract you\u2019ve been\nwriting for your revolutionary DeFi platform? It\u2019s going through a compiler at\nsome point.\n\nNow that we\u2019ve established that every program should contain at least one\ncompiler if it doesn\u2019t already, let\u2019s talk about how one should go about\nwriting one. As it turns out, this is a pretty vast topic, and it\u2019s unlikely\nI\u2019d be able to fit a thorough disquisition on the subject in the margin of\nthis blog post. Instead, I\u2019m going to concentrate on the topic of Abstract\nSyntax Trees (ASTs).\n\nIn the past, I\u2019ve worked on a decompiler that turns LLVM bitcode into Clang\nASTs, and that has made me into someone with opinions about them. These are\nopinions on the things they don\u2019t teach you in school, like: what should the\nAPI for an AST look like? And how should it be laid out in memory? When\ndesigning a component from scratch, we must consider those aspects that go\nbeyond its mere functionality\u2014I guess you could call these aspects\n\u201cpragmatics.\u201d Let\u2019s go over a few of them so that if you ever find yourself\nworking with ASTs in the future, you may skip the more head-scratching bits\nand go straight to solving more cogent problems!\n\n### What are ASTs?\n\nOn their own, ASTs are not a very interesting part of a compiler. They are\nmostly there to translate the dreadful stream of characters we receive as\ninput into a more palatable format for further compiler shenanigans. Yet the\nway ASTs are designed can make a difference when working on a compiler. Let\u2019s\ninvestigate how.\n\n### Managing the unmanageable\n\nIf you\u2019re working in a managed language like C# or Java, one with a garbage\ncollector and a very OOP type system, your AST nodes are most likely going to\nlook something like this:\n\n    \n    \n    class Expr {} class IntConstant : Expr { int value; } class BinExpr : Expr { public Expr lhs; public Expr rhs; }\n\nThis is fine\u2014it serves the purpose well, and the model is clear: since all of\nthe memory is managed by the runtime, ownership of the nodes is not really\nthat important. At the end of the day, those nodes are not going anywhere\nuntil everyone is done with them and the GC determines that they are no longer\nreachable.\n\n(As an aside, I\u2019ll be making these kinds of examples throughout the post; they\nare not meant to be compilable, only to provide the general idea of what I\u2019m\ntalking about.)\n\nI typically don\u2019t use C# or Java when working on compilers, though. I\u2019m a C++\ntroglodyte, meaning I like keeping my footguns cocked and loaded at all times:\nsince there is no garbage collector around to clean up after the mess I leave\nbehind, I need to think deeply about who owns each and every one of those\nnodes.\n\nLet\u2019s try and mimic what was happening in the managed case.\n\n### The naive approach\n\n    \n    \n    struct Expr { virtual ~Expr(); }; struct IntConstant : Expr { int value; }; struct BinExpr : Expr { std::shared_ptr lhs; std::shared_ptr rhs; };\n\nShared pointers in C++ use reference counting (which one could argue is a form\nof automatic garbage collection), which means that the end result is similar\nto what we had in Java and C#: each node is guaranteed to stay valid at least\nuntil the last object holding a reference to it is alive.\n\nThat at least in the previous sentence is key: if this was an Abstract Syntax\nGraph instead of an Abstract Syntax Tree, we\u2019d quickly find ourselves in a\nsituation where nodes would get stuck in a limbo of life detached from\nmaterial reality, a series of nodes pointing at each other in a circle,\nforever waiting for someone else to die before they can finally find their\neternal rest as well.\n\nAgain, this is a purely academic possibility since a tree is by definition\nacyclic, but it\u2019s still something to keep in mind.\n\nI don\u2019t know Rust that well, but it is my understanding that a layout roughly\nequivalent to the one above would be written like this:\n\n    \n    \n    enum Expr { IntConstant(i32), BinExpr(Arc<Expr>, Arc<Expr>) }\n\nWhen using this representation, your compiler will typically hold a reference\nto a root node that causes the whole pyramid of nodes to keep standing. Once\nthat reference is gone, the rest of the nodes follow suit.\n\nUnfortunately, each pointer introduces additional computation and memory\nconsumption due to its usage of an atomic reference counter. Technically, one\ncould avoid the \u201catomic\u201d part in the Rust example by using Rc instead of Arc,\nbut there\u2019s no equivalent of that in C++ and my example would not work as\nwell. In my experience, it\u2019s quite easy to do away with the ceremony of making\neach node hold a reference count altogether, and instead decide on a more\ndisciplined approach to ownership.\n\n### The \u201creverse pyramid\u201d approach\n\n    \n    \n    struct Expr { virtual ~Expr(); }; struct IntConstant : Expr { int value; }; struct BinExpr : Expr { std::unique_ptr lhs; std::unique_ptr rhs; };\n\nUsing unique pointers frees us from the responsibility of keeping track of\nwhen to free memory without adding the overhead of reference counting. While\nit\u2019s not possible for multiple nodes to have an owning reference to the same\nnode, it\u2019s still possible to express cyclic data structures by dereferencing\nthe unique pointer and storing a reference instead. This is (very) roughly\nequivalent to using std::weak_ptr with shared pointers.\n\nJust like in the naive approach, destroying the root node of the AST will\ncause all of the other nodes to be destroyed with it. The difference is that\nin this case we are guaranteed that this will happen, because every child node\nis owned by their parent and no other owning reference is possible.\n\nI believe this representation is roughly equivalent to this Rust snippet:\n\n    \n    \n    enum Expr { IntConstant(i32), BinExpr(Box<Expr>, Box<Expr>) }\n\n#### Excursus: improving the API\n\nWe are getting pretty close to what I\u2019d call the ideal representation, but one\nthing I like to do is to make my data structures as immutable as possible.\n\nBinExpr would probably look like this if I were to implement it in an actual\ncodebase:\n\n    \n    \n    class BinExpr : Expr { std::unique_ptr lhs, rhs; public: BinExpr(std::unique_ptr lhs, std::unique_ptr rhs) : lhs(std::move(lhs)) , rhs(std::move(rhs)) {} const Expr& get_lhs() const { return *lhs; } const Expr& get_rhs() const { return *rhs; } };\n\nThis to me signals a few things:\n\n  * Nodes are immutable.\n  * Nodes can\u2019t be null.\n  * Nodes can\u2019t be moved; their owner is fixed.\n\n### Removing the safeguards\n\nThe next step is to see how we can improve things by removing some of the\nsafeguards that we\u2019ve used so far, without completely shooting ourselves in\nthe foot. I will not provide snippets on how to implement these approaches in\nRust because last time I asked how to do that in my company\u2019s Slack channel,\nthe responses I received were something like \u201cdon\u2019t\u201d and \u201cwhy would you do\nthat?\u201d and \u201csomeone please call security.\u201d It should not have been a surprise,\nas an AST is basically a linked list with extra steps, and Rust hates linked\nlists.\n\nUp until now, the general idea has been that nodes own other nodes. This makes\nit quite easy to handle the AST safely because the nodes are self-contained.\n\nWhat if we decided to transfer the ownership of the nodes to some other\nentity? It is, after all, quite reasonable to have some sort of ASTContext\nobject we can assume to handle the lifetime of our nodes, similar to what\nhappens in Clang.\n\nLet\u2019s start by changing the appearance of our Expr nodes:\n\n    \n    \n    struct BinExpr : Expr { const Expr& lhs; const Expr& rhs; };\n\nNow we create a storage for all of our nodes:\n\n    \n    \n    vector<unique_ptr> node_storage; auto &lhs = node_storage.emplace_back(make_unique(...)); auto &rhs = node_storage.emplace_back(make_unique(...)); auto &binexp = node_storage.emplace_back(make_unique(*lhs, *rhs));\n\nNice! node_storage is now the owner of all the nodes, and we can iterate over\nthem without having to do a tree visit. In fact, go watch this talk about the\ndesign of the Carbon compiler, about 37 minutes in: if you keep your pattern\nof creating nodes predictable, you end up with a storage container that\u2019s\nalready sorted in, e.g., post-visit order!\n\n### Variants on a theme\n\nLet\u2019s now borrow a trick from Rust\u2019s book: the Expr class I\u2019ve been using up\nuntil this point is an old-school case of polymorphism via inheritance. While\nI do believe inheritance has its place and in many cases should be the\npreferred solution, I do think that ASTs are one of the places where\ndiscriminated unions are the way to go.\n\nRust calls discriminated unions enum, whereas C++17 calls them std::variant.\nWhile the substance is the same, the ergonomics are not: Rust has first class\nsupport for them in its syntax, whereas C++ makes its users do template\nmetaprogramming tricks in order to use them, even though they do not\nnecessarily realize it.\n\nThe one feature I\u2019m most interested in for going with variant instead of\ninheritance is that it turns our AST objects into \u201cvalue types,\u201d allowing us\nto store Expr objects directly instead of having to go through an indirection\nvia a reference or pointer. This will be important in a moment.\n\nThe other feature that this model unlocks is that we get the Visitor pattern\nimplemented for free, and we can figure out exactly what kind of node a\ncertain value is holding without having to invent our own dynamic type casting\nsystem. Looking at you, LLVM. And Clang. And MLIR.\n\n### Going off the rails\n\nLet\u2019s take a look back at an example I made earlier:\n\n    \n    \n    vector<unique_ptr> node_storage; auto &lhs = node_storage.emplace_back(make_unique(...)); auto &rhs = node_storage.emplace_back(make_unique(...)); auto &binexp = node_storage.emplace_back(make_unique(*lhs, *rhs));\n\nThere\u2019s one thing that bothers me about this: double indirection, and\nnoncontiguous memory allocation. Think of what the memory layout for this\nstorage mechanism looks like: the vector will have a contiguous chunk of\nmemory allocated for storing pointers to all of the nodes, then each pointer\nwill have an associated chunk of memory the size of a node which, as mentioned\nearlier, varies for each kind of node.\n\nWhat this means is that our nodes, even if allocated sequentially, have the\npotential to end up scattered all over the place. They say early optimization\nis the root of all evil, but for the sake of exhausting all of the tricks I\nhave up my sleeve, I\u2019ll go ahead and show a way to avoid this.\n\nLet\u2019s start by doing what I said I\u2019d do earlier, and use variant for our\nnodes:\n\n    \n    \n    struct IntConstant; struct BinExpr; using Expr = std::variant<IntConstant, BinExpr>; struct IntConstant { int value; }; struct BinExpr { Expr &lhs; Expr &rhs; };\n\nNow that each and every node has the same size, we can finally store them\ncontiguously in memory:\n\n    \n    \n    std::vector node_storage; node_storage.reserve(max_num_nodes); auto &lhs = node_storage.emplace_back(IntConstant{3}); auto &rhs = node_storage.emplace_back(IntConstant{4}); auto &binexp = node_storage.emplace_back(BinExpr{lhs, rhs});\n\nYou see that node_storage.reserve call? That\u2019s not an optimization\u2014that is an\nabsolutely load-bearing part of this mechanism.\n\nI want to make it absolutely clear that what\u2019s happening here is the kind of\nthing C++ gets hate for. This is a proverbial gun that, should you choose to\nuse it, will be strapped at your hip pointed at your foot, fully loaded and\nready to blow your leg off if at any point you forget it\u2019s there.\n\nThe reason we\u2019re using reserve in this case is that we want to make sure that\nall of the memory we will potentially use for storing our nodes is allocated\nahead of time, so that when we use emplace_back to place a node inside of it,\nwe are guaranteed that that chunk of memory will not get reallocated and\nchange address. (If that were to happen, any of our nodes that contain\nreferences to other nodes would end up pointing to garbage, and demons would\nstart flying out of your nose.)\n\nUsing vector and reserve is of course not the only way to do this: using an\nstd::array is also valid if the maximum number of nodes you are going to use\nis known at compile time.\n\nAh yes, max_num_nodes. How do you compute what that is going to be? There\u2019s no\nsingle good answer to this question, but you can find decent heuristics for\nit. For example, let\u2019s say you are parsing C: the smallest statement I can\nthink of would probably look something like a;, or even more extremely, just\na. We can deduce that, if we want to be extremely safe, we could allocate\nstorage for a number of nodes equal to the amount of characters in the source\ncode we\u2019re parsing. Considering that most programs will not be anywhere close\nto this level of pathological behavior, it\u2019s reasonable to expect that most of\nthat memory will be wasted. Unfortunately, we can\u2019t easily reclaim that wasted\nmemory with a simple call to shrink_to_fit, as that can cause a reallocation.\n\nThe technique you can use in that case, or in the case where you absolutely\ncannot avoid allocating additional memory, is to actually do a deep clone of\nthe AST, visiting each node and painstakingly creating a new counterpart for\nit in the new container.\n\nOne thing to keep in mind, when storing your AST nodes like this, is that the\nsize of each node will now be equal to the size of the largest representable\nnode. I don\u2019t think that this matters that much, since you should try and keep\nall of your nodes as small as possible anyway, but it\u2019s still worth thinking\nabout.\n\nOf course, it might be the case that you don\u2019t actually need to extract the\nlast drop of performance and memory efficiency out of your AST, and you may be\nwilling to trade some of those in exchange for some ease of use. I can think\nof three ways of achieving this:\n\n  1. Use std::list.\n  2. Use std::deque.\n  3. Use indices instead of raw pointers.\n\nLet\u2019s go through each of these options one at a time.\n\n### Use std::list instead of std::vector\n\nDon\u2019t. \u2018Nuff said.\n\nAlright, fine. I\u2019ll elaborate.\n\nLinked lists were fine in the time when the \u201crandom access\u201d part of RAM was\nnot a lie yet and memory access patterns didn\u2019t matter. Using a linked list\nfor storing your nodes is just undoing all of the effort we\u2019ve gone through to\noptimize our layout.\n\n### Use std::deque instead of std::vector\n\nThis method is already better! Since we\u2019ll mostly just append nodes to the end\nof our node storage container, and since a double-ended queue guarantees that\ndoing so is possible without invalidating the addresses of any existing\ncontents, this looks like a very good compromise.\n\nUnfortunately the memory layout won\u2019t be completely contiguous anymore, but\nyou may not care about that. If you are using Microsoft\u2019s STL, though, you\nhave even bigger issues ahead of you.\n\n### Use indices instead of raw pointers\n\nThe idea is that instead of storing the pointer of a child node, you store the\nindex of that node inside of the vector. This adds a layer of indirection back\ninto the picture, and you now also have to figure out what vector does this\nindex refer to? Do you store a reference to the vector inside each node?\nThat\u2019s a bit of a waste. Do you store it globally? That\u2019s a bit icky, if you\nask me.\n\n### Parting thoughts\n\nI\u2019ve already written a lot and I\u2019ve barely scratched the surface of the kind\nof decisions a designer will have to make when writing a compiler. I\u2019ve talked\nabout how you could store your AST in memory, but I\u2019ve said nothing about what\nyou want to store in your AST.\n\nThe overarching theme in this exhilarating overview is that there\u2019s a lot\nabout compilers that goes beyond parsing, and all of the abstract ideas needed\nto build a compiler need concretizing at some point, and the details on how\nyou go about doing that matter. I also feel obligated to mention two maxims\none should keep in mind when playing this sort of game: premature optimization\nis the root of all evil, and always profile your code\u2014it\u2019s likely that your\ncodebase contains lower-hanging fruit you can pick before deciding to fine-\ntune your AST storage.\n\nIt\u2019s interesting that most of the techniques I\u2019ve shown in this article are\nnot easily accessible with managed languages. Does this mean that all of this\ndoesn\u2019t really matter, or do compilers written in those languages (I\u2019m\nthinking of, e.g., Roslyn) leave performance on the table? If so, what\u2019s the\nsignificance of that performance?\n\nFinally, I wanted this post to start a discussion about the internals of\ncompilers and compiler-like tools: what do these often highly complex pieces\nof software hide beneath their surface? It\u2019s easy to find material about the\ngeneral ideas regarding compilation\u2014tokenization, parsing, register\nallocation\u2014but less so about the clever ideas people come up with when writing\nprograms that need to deal with huge codebases in a fast and memory-efficient\nmanner. If anyone has war stories to share, I want to hear them!\n\n### Share this:\n\n  * Twitter\n  * LinkedIn\n  * Reddit\n  * Telegram\n  * Facebook\n  * Pocket\n  * Email\n  * Print\n\n### Like this:\n\nLike Loading...\n\n### Related\n\nBreaking the Solidity Compiler with a FuzzerJune 5, 2020In \"Blockchain\"\n\nCreating an LLVM Sanitizer from Hopes and DreamsJune 25, 2019In \"Compilers\"\n\nLet\u2019s talk about CFI: Microsoft EditionDecember 27, 2016In \"Compilers\"\n\nBy Trail of Bits\n\nPosted in Compilers, Research Practice\n\n### Leave a ReplyCancel reply\n\n# About Us\n\nSince 2012, Trail of Bits has helped secure some of the world\u2019s most targeted\norganizations and products. We combine high-end security research with a real\nworld attacker mentality to reduce risk and fortify code.\n\nRead more at www.trailofbits.com\n\n# Subscribe via RSS\n\nRSS - Posts\n\n# Recent Posts\n\n  * The life and times of an Abstract Syntax Tree\n  * Curvance: Invariants unleashed\n  * Announcing two new LMS libraries\n  * 5 reasons to strive for better disclosure processes\n  * Introducing Ruzzy, a coverage-guided Ruby fuzzer\n  * Why fuzzing over formal verification?\n  * Streamline your static analysis triage with SARIF Explorer\n  * Read code like a pro with our weAudit VSCode extension\n  * Releasing the Attacknet: A new tool for finding bugs in blockchain nodes using chaos testing\n  * Secure your blockchain project from the start\n  * DARPA awards $1 million to Trail of Bits for AI Cyber Challenge\n  * Out of the kernel, into the tokens\n  * Cryptographic design review of Ockam\n  * Relishing new Fickling features for securing ML systems\n  * How we applied advanced fuzzing techniques to cURL\n\n# Yearly Archive\n\n  * 2023\n  * 2022\n  * 2021\n  * 2020\n  * 2019\n  * 2018\n  * 2017\n  * 2016\n  * 2015\n  * 2014\n  * 2013\n  * 2012\n\n# Categories\n\n  * AIxCC (3)\n  * Apple (13)\n  * Application Security (6)\n  * Attacks (13)\n  * Audits (11)\n  * Authentication (6)\n  * Binary Ninja (14)\n  * Blockchain (66)\n  * C/C++ (1)\n  * Capture the Flag (11)\n  * Careers (2)\n  * CodeQL (6)\n  * Compilers (28)\n  * Conferences (31)\n  * Confidential Computing (1)\n  * Containers (3)\n  * Cryptography (58)\n  * Crytic (4)\n  * Cyber Grand Challenge (8)\n  * DARPA (24)\n  * Design Review (1)\n  * Dynamic Analysis (14)\n  * Ecosystem Security (5)\n  * Education (17)\n  * Empire Hacking (7)\n  * Engineering Practice (16)\n  * Events (8)\n  * Exploits (30)\n  * Fuzzing (41)\n  * Go (7)\n  * Guides (15)\n  * Internship Projects (36)\n  * Invariant Development (1)\n  * iVerify (5)\n  * Kubernetes (3)\n  * Linux (7)\n  * LLVM (1)\n  * Machine Learning (17)\n  * Malware (7)\n  * Manticore (17)\n  * McSema (11)\n  * Memory Safety (1)\n  * Meta (12)\n  * Mitigations (11)\n  * MLIR (2)\n  * Open Source (11)\n  * osquery (23)\n  * Paper Review (11)\n  * People (6)\n  * Podcast (1)\n  * Policy (9)\n  * Press Release (29)\n  * Privacy (9)\n  * Products (8)\n  * Program Analysis (18)\n  * Recruitment (1)\n  * Remote Work (1)\n  * Research Practice (24)\n  * Reversing (16)\n  * Rust (7)\n  * SafeDocs (1)\n  * Semgrep (7)\n  * Sinter (1)\n  * Slither (4)\n  * Sponsorships (12)\n  * Static Analysis (34)\n  * Supply Chain (3)\n  * Symbolic Execution (18)\n  * Testing Handbook (3)\n  * Threshold Signatures (1)\n  * Tool Release (4)\n  * Training (2)\n  * Uncategorized (35)\n  * VAST (2)\n  * Vulnerability Disclosure (19)\n  * Windows (3)\n  * Working at Trail of Bits (2)\n  * Year in Review (6)\n  * Zero Knowledge (11)\n\nMy Tweets\n\n## Discover more from Trail of Bits Blog\n\nSubscribe now to keep reading and get access to the full archive.\n\nContinue reading\n\n%d\n\n", "frontpage": false}
