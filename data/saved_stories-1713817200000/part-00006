{"aid": "40114304", "title": "What we've learned in 3 days of Llama 3", "url": "https://openpipe.ai/blog/what-we-ve-learned-in-3-days-of-llama-3", "domain": "openpipe.ai", "votes": 3, "user": "kcorbitt", "posted_at": "2024-04-22 13:44:50", "comments": 0, "source_title": "What we've learned in 3 days of Llama 3 - OpenPipe", "source_text": "What we've learned in 3 days of Llama 3 - OpenPipe\n\nNews\n\n## What we've learned in 3 days of Llama 3\n\nKyle Corbitt\n\nApr 21, 2024\n\n4 minutes\n\nHey everyone! You\u2019ve probably heard that last Thursday Meta announced Llama 3,\na new open-source LLM. There are 3 variants announced so far: a small 8B\nparameter model, medium 70B parameter model, and very large 405B parameter\nmodel. The 405B model is still in training but weights for both of the smaller\nsizes are available.\n\n### Good, Bad, or Ugly?\n\nThe Good\n\n  * The benchmarks are absolutely insane. The 8B model is almost as strong as Llama 2\u2019s 70B variant and is much stronger than Mistral 7B, which has been the go-to small model for the last year. The Llama 3 70B model compares favorably to Gemini Pro 1.5 and Claude 3 Sonnet.\n\n  * Meta also released preliminary benchmarks for the 405B model, which compare favorably to GPT-4 Turbo. This model has also been confirmed to be multimodal (text+image input), differing from the smaller two which are text-only. Obviously we\u2019ll have to wait and see what the released model looks like but this is really exciting news.\n\n  * In addition to the base models, Meta released instruct variants of both the 8B and 70B models. The instruction tuning was really well done and these are ready for use immediately. The 70B model is capable of all tasks that you\u2019d have used GPT-3.5 for, and many tasks that previously required GPT-4.\n\nThe Bad\n\n  * The released models are capped at an 8K context window, which compares poorly to GPT-4 Turbo (128K), Claude 3 (200K), or even Mistral 7B (32K). That said, there are now good techniques to extend the context window with minimal additional training, so I expect longer-context variants will drop soon.\n\nThe Ugly\n\n  * We\u2019ll probably have to wait a few more months for the largest model to drop, which could end up being the most impactful of the three.\n\n### Serving Llama 3 \ud83c\udf7d\ufe0f\n\nYou have many good options to serve Llama 3 models in production. Its\narchitecture is nearly identical to Llama 2, so many of the Llama 2 inference\nproviders already have Llama 3 support live. I\u2019ve included a few providers\nthat I\u2019ve personally used and have confidence in for production workloads\nbelow. Note that these are the shared tenancy prices; many of these providers\ncan also give you a dedicated deployment paid by the GPU-hour.\n\n### Fine-Tuning Llama 3 \u2702\ud83e\udd99\n\nAt OpenPipe we\u2019ve found that even models in the 7B weight class can often\nrival GPT-4 when fine-tuned on your specific task.\n\nWe released fine-tuning support for Llama 3 8B on launch day (70B coming\nsoon!). We\u2019ll have benchmarks soon, but in initial testing we\u2019ve found that a\nfine-tuned Llama 3 8B performs similarly to fine-tuned Mixtral 8x7B, while\nbeing much cheaper to serve. And, we had previously found that for most tasks\nMixtral is able to outperform GPT-4 when fine-tuned on a high-quality dataset.\n\nThis means that for many tasks, you can now serve a fine-tuned model that\noutperforms GPT-4 for 1/50th the cost. This is of course a huge deal for many\nbusiness models! So (here comes the pitch): if you\u2019d like to try fine-tuning a\nLlama 3 variant on your own prompts and completions feel free to create an\naccount at openpipe.ai \u2014 it only takes a couple minutes to get started!\n\nFine-tune Llama 3 on production data!\n\nREAD MORE\n\n#### Knowledgebase\n\nBlog\n\nDocumentation\n\nSupport\n\n#### Contact\n\nhello@openpipe.ai\n\n@OpenPipeAI\n\nCareers\n\nGet Started\n\n#### About OpenPipe\n\nOpenPipe is the easiest way to train and deploy your own fine-tuned models. It\nonly takes a few minutes to get started and can save you 14x relative to\nOpenAI with higher quality.\n\n2024 OpenPipe inc.\n\nTerms of Service\n\nPrivacy Policy\n\nFulfilment Terms\n\nInformation Security\n\n", "frontpage": false}
