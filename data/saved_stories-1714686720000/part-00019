{"aid": "40237141", "title": "Show HN: Analyzing GPT-4 Tokens with Llama3", "url": "https://koenvangilst.nl/blog/analyzing-gpt-4-tokens", "domain": "koenvangilst.nl", "votes": 1, "user": "vnglst", "posted_at": "2024-05-02 15:05:04", "comments": 0, "source_title": "Analyzing GPT-4 Tokens | Koen van Gilst", "source_text": "Analyzing GPT-4 Tokens | Koen van Gilst\n\n# Analyzing GPT-4 Tokens\n\nKoen van Gilst / May 2, 2024\n\n5 min read \u2022 \u2013\u2013\u2013 views\n\n  * data visualisation\n  * AI\n  * chatgpt\n\nI recently watched a YouTube video by Andrej Karpathy explaining the quirky\nbehavior of LLMs through their tokenizers. He addresses questions such as why\nLLMs struggle with spelling or react unpredictably to specific terms like\nSolidGoldMagikKarp. If you haven't seen this video yet, I highly recommend it.\n\nKarpathy explains that tokens are akin to the atoms of large language models,\nshaping how they perceive and interact with text. This inherent structure not\nonly facilitates but also limits their capabilities. He notes that the tokens\nfor OpenAI models, like GPT-4, are publicly accessible. This caught my\nattention and I decided to examine these tokens using Llama3, a capable and\nfreely available large language model that I could run on my own laptop.\n\n## Method\n\nThe tokens for GPT-4 are accessible through a link found in OpenAI's GitHub\nrepository for the TikToken. These tokens are encoded in Base64, requiring\ndecoding to reveal a list of approximately 100,000 tokens. The initial entries\nmostly consist of single or dual characters. As the list progresses, it begins\nto include full words and fragments of words.\n\n    \n    \n    available mt Bl ... block Input keep Count open [' throw uilder Action things True url Bo\n\nThis list includes fragments that resemble syntax elements or identifiers from\nvarious programming languages. My goal was to categorize all the tokens using\nLlama3 into the following categories:\n\n  * Natural languages\n\n    * English (en)\n    * Spanish (es)\n    * German (de)\n    * etc.\n  * Computer languages\n\n    * Java\n    * C#\n    * Python\n    * etc.\n\n## Prompting\n\nAfter some trial and error, I created the following prompt for Llama3:\n\n> You are a token categorizer. You categorize lists of tokens into types:\n> code, lang, unknown. The types have the following definitions:\n>\n>   * code: tokens that are part of a programming language (such as Python,\n> JavaScript abbreviated as \"js\", C#, etc.)\n>   * lang: tokens that are part of some natural language.\n>   * unknown: are single characters of tokens where the origin cannot be\n> assessed.\n>\n\n>\n> The next categorization is lang. This specifies which language this is part\n> of. The corresponding languages are:\n>\n>   * for type code: \"javascript\", \"c#\", \"python\", \"java\", \"unknown\", etc.\n>   * for type lang: \"en\", \"es\", \"de\", \"nl\", \"unknown\", etc.\n>   * for type unknown: leave this empty.\n>\n\n>\n> Also, add a property called definition to the objects. It should contain a\n> short description of the token. It should not be longer than a few words.\n> The results should be presented in a JSON structure that clearly defines\n> categories for each token. Here\u2019s an example of how to structure this JSON:\n>\n> Input:\n>\n> liability beam NotFound Charles .SequentialGroup \u043e\u043b\u044c\u043a\u043e _person .history\n> TextView __ \u00eds Markt onDataChange photoshop\n>\n> Output:\n    \n    \n    { \"liability\": {\"type\": \"lang\", \"lang\": \"en\", \"definition\": \"Legal responsibility\"}, \"beam\": {\"type\": \"lang\", \"lang\": \"en\", \"definition\": \"Line of light\"}, \"NotFound\": {\"type\": \"code\", \"lang\": \"javascript\", \"definition\": \"Error message\"}, \"Charles\": {\"type\": \"lang\", \"lang\": \"en\", \"definition\": \"Name\"}, \".SequentialGroup\": {\"type\": \"code\", \"lang\": \"java\", \"definition\": \"Linear processing\"}, \"\u043e\u043b\u044c\u043a\u043e\": {\"type\": \"lang\", \"lang\": \"ru\", \"definition\": \"Only\"}, \"_person\": {\"type\": \"code\", \"lang\": \"python\", \"definition\": \"Individual\"}, \".history\": {\"type\": \"code\", \"lang\": \"javascript\", \"definition\": \"Past events\"}, \"TextView\": {\"type\": \"code\", \"lang\": \"java\", \"definition\": \"Text display\"}, \"__\": {\"type\": \"unknown\", \"lang\": \"\", \"definition\": \"\"}, \"\u00eds\": {\"type\": \"unknown\", \"lang\": \"\", \"definition\": \"\"}, \"Markt\": {\"type\": \"lang\", \"lang\": \"de\", \"definition\": \"Market or fair\"}, \"onDataChange\": {\"type\": \"code\", \"lang\": \"unknown\", \"definition\": \"Data update\"}, \"photoshop\": {\"type\": \"lang\", \"lang\": \"en\", \"definition\": \"Image editing software\"} }\n\n> Do a linguistic analysis of each token. Respond only with valid JSON. Do not\n> add backticks.\n\nI stored the JSON result of this prompt in a SQLite database to facilitate\neasier analysis of the different categories. I used a Python script and the\nOllama endpoints for this.\n\n## Results\n\nAfter a few nights of hard work, Llama3 had processed about 97% of the tokens,\nand the results are illuminating.\n\nAs you can see, the majority of GPT-4's tokens are related to coding. The\nunknown category includes single characters or groups of characters that could\nnot be clearly categorized.\n\nFocusing on natural language tokens, a significant majority are identified as\nEnglish words or fragments. Spanish, the second most represented language, has\nonly 1064 tokens.\n\nThe analysis of programming languages shows Java and JavaScript leading.\nHowever, categorizing syntax elements is complex. For example, the token\ngetFullYear is classified under Java but could also belong to JavaScript. So I\nwould not read too much into this chart.\n\n## Conclusions\n\nThe reliability of Llama3's categorization is questionable, not due to its\nlimitations but because of the inherent challenge in accurately categorizing\nsmall word or code fragments. Nevertheless, this analysis provides intriguing\ninsights into the possible biases in GPT-4.\n\nIt is evident that GPT-4 has a stronger focus on English than I anticipated.\nOf course the main language of the internet is English, but I only counted 124\ntokens that could be classified as Dutch words. This could partially explain\nwhy GPT-4 underperforms in my native language\n\nSurprisingly, the tokens are more code-centric than I expected. While I\nassumed a greater emphasis on natural language tokens across various\nlanguages, the data suggests a reliance on code, at least in training the\ntokenizer.\n\nI hope you found this post interesting. This was my first attempt at using a\nlarge language model for a categorization task. The implementation scripts are\nstraightforward, but I had to invest more in error handling and recovery so\nthat the analysis would keep running even when a prompt failed to deliver a\nparsable result.\n\nDiscuss on Twitter \u2022 Edit on GitHub\n\nHomeAboutDashboard\n\nSnippetsQuotesCredits\n\nTwitterGitHubLinkedIn\n\nMastodon\n\nv. 6.0.0 | ad50812\n\n", "frontpage": false}
