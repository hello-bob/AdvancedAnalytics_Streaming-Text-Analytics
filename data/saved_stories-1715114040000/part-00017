{"aid": "40285852", "title": "Local First with GraphQL", "url": "https://www.plain.com/blog/moving-to-local-first-state-management", "domain": "plain.com", "votes": 1, "user": "bruchim", "posted_at": "2024-05-07 14:24:52", "comments": 0, "source_title": "Moving to local-first state management with GraphQL \u00b7 Plain", "source_text": "Moving to local-first state management with GraphQL \u00b7 Plain\n\nDocs\n\nCustomers\n\nPricing\n\nJobs\n\nBlog\n\nChangelog\n\nBack to all posts\n\nEngineering\n\n# Moving to local-first state management with GraphQL\n\nJordan Drake\n\nMar 27, 2024\n\nIn the past year at Plain we've released several major new features including\nSlack, rich-text editing, AI triage, and an entire re-design just to name a\nfew. However, one feature that may have gone unnoticed was a fundamental shift\nin how we do state management on the front-end.\n\nIf you\u2019re not familiar with Plain, I\u2019ll give you a quick background to help\nyou better understand this post.\n\nPlain is a support platform designed for technical product teams. It helps you\nmanage all of your support requests via email, contact forms, and Slack. It's\nthe kind of tool that is open and in-use, all-day, every day. More than\nanything else, what matters in Plain is the workflow - our users expect\neverything to be as fast, reactive, and as keyboard-friendly as their IDE.\nWhen your customers contact you across any channel, they get raised in Plain\nas a thread where you can triage, respond, attach metadata, and so on.\n\nThe front-end application is a React application built on NextJS, we don\u2019t\ncurrently render server-side but that\u2019s a post for another day! We use Redux\nheavily for both UI state and external state. You don\u2019t need to be a React or\nRedux expert to understand this post. If you\u2019re unfamiliar with these\ntechnologies then think of Redux as the model. You dispatch actions to update\nthis model in a controlled manner and React updates the view whenever any\nmodel changes. If you are familiar with useReducer in React, it\u2019s basically\nlike that but more advanced.\n\n## How state management used to work\n\nThe best way to show you how state management used to work is by talking\nthrough an end-to-end example.\n\nThis is the state management code for fetching a single thread in practice:\n\ntypescript\n\n    \n    \n    type State = { threadRequests: { [threadId: string]: { requestStatus: null | 'LOADING' | 'COMPLETED', error?: Error, thread?: Thread } | undefined } } async function fetchThread(threadId) { try { dispatch(actions.fetchThreadRequest(threadId)); // Sets requestStatus to LOADING const data = await request({ query: ThreadDocument, variables: { threadId, }, }); dispatch(actions.fetchThreadSuccess(threadId, data)); // Sets data and requestStatus to COMPLETED } catch (error) { dispatch(actions.fetchThreadError(threadId, error)); // Sets error and requestStatus to COMPLETED } }\n\nThis is how we\u2019d consume it in the front-end:\n\ntypescript\n\n    \n    \n    function ThreadPage(threadId) { const { thread, error, requestStatus } = useSelector(state => state.threadRequests[threadId]); const dispatch = useDispatch(); useEffect(() => { dispatch(fetchThread(threadId)); }, []); if(requestStatus === 'LOADING') { return <p>Loading...</p>; } if(error) { return <p>An error occurred: {error.message}</p>; } return <p>{thread.title}</p>; }\n\nFor requesting and rendering a single entity, that is pretty manageable.\nHowever, things start to get more complicated when you want to start\ndisplaying lists of things on one page.\n\nBelow is an example of what a list of threads looked like in our Redux store:\n\ntypescript\n\n    \n    \n    type State = { threads: Dictionary<string, Thread>; lists: ThreadListMap ; } type ThreadListMap = { [queryId: string]: undefined | { requestStatus: null | 'LOADING' | 'COMPLETED', error?: Error, variables: ThreadQueryVariables; state: 'fresh' | 'stale'; threadIds: string[]; metadata: { pageInfo { endCursor?: string; hasNextPage: boolean; } } } }\n\nLet me break this down a little:\n\n  * First, we have a map of threads by id. This is all threads across all the lists we\u2019ve seen which lets us easily reference a single thread without having to scan through all lists.\n  * A map of queryId to a thread list which includes some information about the request such as the variables used to call it and ultimately the list of threadIds which we\u2019d expand against threads\n\n    * queryId is a deterministic hash from the variables (both filters and page parameters) used to request that list which serves as a cache should something request a list using the same variables. This ensures that if the UI is making different requests for different lists of threads the relevant data and request state is separate.\n    * state is a flag we would set to \u2018stale\u2019 when something has invalidated this particular list then anything consuming a stale list should immediately re-fetch the list. More on this later but this is how we essentially invalidate lists cached in Redux.\n    * pageInfo provides us with the data needed to call the next page of this particular list. This adheres to Relay\u2019s GraphQL cursor-based pagination specification. Getting the next page for this list, would not modify this list but instead be seen as a separate query (with its own queryId)\n\nWhen we made a query for a list of threads, we'd extract and upsert the\nthreads onto the threads map and at the same time create a new list by\nextracting the ids from the threads. This way we have both the ability to show\nthe list but also show individual items without having to re-fetch just one\nthread by itself.\n\nAlthough complicated, this approach largely worked as we're a support\nplatform; you probably don't want pages and pages of open threads - you want\nzero. With this very manual and complicated state structure, we were able to\nbuild out a lot of the early functionality within Plain.\n\nIt was, however, not without its flaws.\n\n## Pain points\n\n### Liveliness\n\nAs a support platform, your users are spending all day in your tool. With this\ncomes the natural expectation that everything is live. It would be a\nfundamental user experience failure if they had to reload the page to check\nfor new threads so updating the application whenever a new thread came in was\nsomething we built in from the very beginning. For this, we use GraphQL\nsubscriptions over websockets.\n\nUnfortunately, when you\u2019re dealing with a bunch of lists this can be very\ntricky. When you receive a subscription event that a thread has updated, you\nneed to know which lists are now out of date. For that you have to scan all\nyour lists and answer the following questions:\n\n  * If this thread is in this list already, is it in the same order?\n  * If this thread is not in this list, should it be added? How does this affect the previous or next page?\n  * If this thread should now be removed from this list, how does this affect the previous or next page?\n\nYou basically end up having to rewrite filtering, sorting, and querying logic\nin the front-end that exactly matches what you have in the SQL in the back-end\njust so you can understand how the lists you have stored in the front-end are\naffected. Getting this wrong means ending up with out-of-date information,\nduplicates, or missing items entirely. You can avoid this by going the nuclear\noption and invalidating all lists but this would have to happen on any change\nincluding something as trivial as applying a label to a single thread and when\nyou\u2019re dealing with a lot of threads with a lot of support agents this can\nhappen several times a minute.\n\n### Developer experience\n\nCoding against these types of lists can be tedious. It wasn\u2019t just the big\nthread list that was paginated and built as a list, it was pretty much every\nentity we had; labels, groups, snippets, users, customers, and more.\n\nFor each of those, they\u2019d all have their own Redux code. 90% of this was the\nsame from entity to entity but each would have their own idiosyncrasies (we\nhold up our hands here, a lot of this could have been avoided) such as when to\nupsert, soft vs hard deletes, and cascading from other entities (e.g. a thread\nhas a reference to a customer).\n\nThen every place they are shown as a list (even something as minor as a\ndropdown) you need to handle loading states, error states, re-fetching stale\nlists, knowing you\u2019re at the end of a page to load more, etc. Almost all\ncomponents that render an entity end up with some sort of asynchronous\nhandling and whilst React, shared components, and other abstractions can help\nhere these are still logical pathways you need to consider, test, and mitigate\nagainst bugs.\n\n### Performance\n\nSince the requests to fetch particular lists and entities are all driven from\nthe component structure, it is hard to do any sort of meaningful pre-loading\nas you need to wait until you encounter that component before making a\nrequest. This can also result in a bit of a N+1 problem where you make one\nrequest to render one component which itself has components in it that trigger\nadditional requests.\n\nSimilarly, when applying filters or sorts you\u2019d be greeted by a loading\nspinner and whilst this would be relatively fast it impacts perceived\nperformance and disincentivizes our users from using all the features of the\napplication.\n\nWhen we got it right, optimistic updates largely helped with perceived\nperformance but in practice what often would happen is that a simple innocuous\nchange (like adding a label to a thread) would invalidate a bunch of unrelated\nrequests and trigger spinner-armageddon making the whole app feel slow.\n\n### UI Limitations\n\nBy only ever having small slices of the full list for a given entity we often\nfound ourselves having a lot of weird UI limitations.\n\nFor example, if we wanted to show a filter that was contextually relevant to\nthe full list but not within the small slice we currently had, we would have\nto build niche back-end APIs to give us metadata on the full list to know what\nto show.\n\nSimilarly, it\u2019s hard to truly show a full overview of the state of your\nsupport queues. One way of providing this was with total counts given to us\nfrom a back-end API which we did but we\u2019d also constantly have to invalidate\nand update these with similar difficulties as mentioned when invalidating\nlists.\n\nMore often than that, you\u2019re constantly running into small spinners in several\nplaces on the page for metadata, counts, relationships (e.g. displaying\nsomething about a customer of a given thread), and so on.\n\n## Options we considered\n\nIf you\u2019re familiar with using GraphQL within React then at this point you\u2019re\nprobably asking why we didn't turn to a popular GraphQL client (such as Apollo\nor Relay) or even a general request client like react-query. These libraries\nwould handle a lot of what we\u2019ve done ourselves in Redux and you\u2019re given an\ninterface like this:\n\ntypescript\n\n    \n    \n    function ThreadPage(threadId) { const { loading, error, data } = useQuery(THREAD_QUERY, { variables: { threadId, } }); if(loading) { return <p>Loading...</p>; } if(error) { return <p>An error occurred: {error.message}</p>; } return <p>{thread.title}</p>; }\n\nThis is something we considered and investigated but these libraries don\u2019t\nsolve the problems with list invalidation out of the box and we\u2019d still have\nto handle asynchronicity everywhere. It would also require a large amount of\nre-architecturing the existing codebase and make enabling optimistic updates\nacross different parts of our graph very challenging.\n\nAnother approach we briefly considered was Replicache which specializes in\nproviding a local-first, persistent, optimistically updating experience. This\nwould have however meant building a new separate API for the front-end vs\nbeing able to share the same API our customers use to integrate with Plain\ntoday. If we were to rebuild Plain today from scratch Replicache would be a\nvery strong candidate for our front-end architecture.\n\n## Our approach today\n\nTo solve our state management issues an attractive solution would have been to\ngo for a local-first approach similar to Linear where the client downloads all\ndata and then all operations happen on the client and are synced back to the\nback-end.\n\nInitially, we dismissed this approach as we didn\u2019t believe you would be able\nto download all support threads and customers, companies, etc. to the browser\nas the data set would be too large. However, as we built Plain we saw that in\nactual fact your dataset does not grow infinitely unlike articles on a news\npage or messages in a chat room. When you are in a support tool you only care\nabout active support requests and this data set, as you work through your\nsupport queue, will trend downwards. This very much put a local-first state\nmanagement on the table.\n\nWe still however had to have a solution for viewing historical data. To\nachieve this we decided to offer a more classic SPA experience where all data\nis fetched on demand and only cached in memory. We felt comfortable with this\ntrade-off as it optimized the experience for the 90% of cases where you are\ntrying to help your customers while also keeping implementation complexity\ndown.\n\nAnother assumption we saw we could make was that user-created entities such as\nusers, snippets, labels, and customer groups would remain at a relatively\nreasonable (< 10000) size. If we ever have a customer with more than 10000\nusers then I think we can afford to rethink this architecture \ud83d\ude09\n\n## Technical breakdown\n\nWe still store all our entities within Redux in a way that is not too\ndissimilar to the threads mapping of our previous approach. The similarity\nenabled us to speed up the transition massively because a consumer that looked\nup an entity by id remained almost exactly the same.\n\nThe major difference is how these entities get into Redux. Before we\u2019d do a\ntypical Redux flow where each request would have a specific set of actions and\nreducer in Redux. Now we automatically parse the response of every request and\nif we find any entity we upsert it into our Redux state. This approach gives\nus a single pipeline of entity data into our application whether it is from a\nmass fetch, a specific fetch of a single entity, an entity updated in the\nresult of a mutation, or even subscriptions.\n\n### Redux\n\ntypescript\n\n    \n    \n    interface EntitiesState { hasData: boolean; isFetching: boolean; isStale: boolean; error: AppError | null; customers: Dictionary<string, CustomerModel>; threads: Dictionary<string, ThreadModel>; labelTypes: Dictionary<string, LabelTypeModel>; customerGroups: Dictionary<string, CustomerGroupModel>; users: Dictionary<string, UserModel>; snippets: Dictionary<string, SnippetModel>; }\n\nThis is what our Redux store for entities looks like today; a single store for\nall entities with actions for inserting generic entities rather than each\nindividual entity having its own store and own actions ( upsertEntity vs\nupsertThread, upsertUser, etc.). Each entity is a map of the entity id to the\nentity model. There\u2019s no request metadata per entity, just a top-level loading\nstate to cover bootstrapping and hard vs soft loading.\n\nWe created a variety of abstractions to select data from this redux store. For\nperformance reasons, we make use of local memoization and memoized selectors\nwhich means that if several parts of the application want the same data we\nwon\u2019t have to perform various filtering and aggregating twice. One such\nabstraction is our useThreads hook:\n\ntypescript\n\n    \n    \n    export function useThreads({ filters, }: { filters?: ThreadFiltersModel; sort?: ThreadSortType } = {}) { const threads = useSelector(threadsSelector); const filteredThreads = useMemo(() => { if (!filters) { return threads; } return sortThreads( filters.sort, threads.filter((t) => threadMatchesFilters(t, filters)) ); }, [ filters, threads]); return { threads: filteredThreads }; }\n\nWe intentionally abstract away from using selectors directly in components to\nsmoothen potential future transitions.\n\n### Parsing a payload\n\nEvery payload whether it is from a query, mutation or subscription is scanned\nfor entities. This is achieved by adding a small amount of code in our request\nwrapper which is connected to our Redux store. The response is then returned\nback to the original caller.\n\nTo parse potential entities, we use Zod to build models. This gives us the\nconfidence that each entity will have the exact same shape and we can\ntransform the data and add additional client-only properties too.\n\ntypescript\n\n    \n    \n    export const ThreadModel = z.object({ __typename: z.literal('Thread'), id: z.string(), externalId: z.string().nullable(), customer: z.object({ id: z.string(), markedAsSpamAt: DateTimeModel.nullish(), customerGroupMemberships: z.object({ edges: z.array( z.object({ node: CustomerGroupMembershipModel, }) ), }), }), status: z.nativeEnum(ThreadStatus), statusDetail: ThreadStatusDetailModel.nullable(), statusChangedAt: DateTimeModel, title: z.string(), description: z.string().nullable(), previewText: z.string().nullable(), priority: z.number(), labels: z.array(LabelModel), supportEmailAddresses: z.array(z.string()), assignedAt: DateTimeModel.nullable(), assignedTo: ThreadAssigneeModel.nullable(), createdAt: DateTimeModel, createdBy: ActorModel, updatedAt: DateTimeModel, updatedBy: ActorModel, });\n\nThere are several major benefits to this approach:\n\n  * We don\u2019t need to write bespoke code for each possible query and request flow. We just need to define a model and potentially some specific behavior for how that entity is stored (e.g. create vs update vs ignore)\n  * Subscriptions can be parsed just like a response payload\n  * Any response that happens to contain a matching entity, even if indirectly, updates that entity in our Redux ensuring we always have the most up-to-date entities without extra code\n\n### Entity idiosyncrasies\n\nNot all entities are created equal; some differences are integral to their\nbehavior, others are simply a result of our understanding of the problem space\nimproving over time and frankly, some are mistakes on our part. Whilst we try\nto handle entities as generically as possible, we need mechanisms to support\nany different behaviors.\n\nEach entity has an \u2018entity manager\u2019 which is responsible for handling all\nthese differences in one place.\n\nFor an example, here\u2019s the thread entity manager:\n\ntypescript\n\n    \n    \n    export const threadEntityManager = createEntityManager({ key: 'threads', model: ThreadModel, typename: 'Thread', storage: { lookupKey: (t) => t.id, filter: (t) => { return [ThreadStatus.Todo, ThreadStatus.Snoozed].includes(t.status); }, }, upserter: upsertFactory('threads'), requiredPermissions: ['thread:read'], fetchAll: fetchAllThreads, });\n\n  * This logic sits outside Redux but is frequently referenced by it so the key matches the same value within our Redux store\n  * Model is the Zod model we use for parsing an entity\n  * The storage filter ensures that we only store entities in our persistence (see below) that are active to avoid our storage growing infinitely with inactive entities\n  * The upserter is a comparator function that takes a new entity and the previous entity of the same id (if it exists). Fortunately, a thread is a relatively simple case as it has an \u2018updatedAt\u2019 field.\n  * Not all users have permission to view every entity within Plain. requiredPermissions ensures that we don\u2019t attempt to fetch entities that the user does not have access to as this request will error. We obviously enforce these on the back-end but this helps reduce the number of requests to our back-end.\n  * fetchAll is a function that loads all active entities into the store for synchronization. In the case of threads, this is our ThreadsQuery with filters for threads that aren\u2019t marked as done. Typically the filters we apply to a fetch are the same as those in the storage filter.\n\n### Persistence\n\nThe trade-off for loading all the data upfront on application bootstrap is\nthat we\u2019ve significantly increased the time the user is behind a global\nloading state. To mitigate this, we introduced persisting the entities you\u2019ve\ndownloaded to your local storage. This means that when you load Plain you\nimmediately see all the previous threads and state while we sync in the\nbackground.\n\nPersisting data locally comes with a few issues. The first problem is that the\nmodel of the entity you\u2019ve stored might have changed and trying to load it\nwould break the application. In order to avoid this we treat locally stored\ndata the same way we would a response payload; by parsing it to ensure it\nmeets the current model. We also store the entities against a key generated by\nhashing the model schema.\n\nAnother issue is that there\u2019s a reasonable chance somebody else has updated an\nentity (e.g. by responding to a thread) whilst you were offline so whenever\nyou go to a thread we re-fetch that thread behind a loading spinner. Later\ndown the line, we plan to invest in full conflict resolution on the API to\nprovide a complete solution across the board for all entities.\n\n### Mutations\n\nThis entity pipeline model solves querying entities but doesn\u2019t provide any\nsolutions for mutations.\n\nPreviously, a mutation would look very similar to a query, you\u2019d have a\nbespoke flow for it with appropriate Redux actions and request states and when\nit was successful you\u2019d update the entity in its mapping and identify what\nlists are now invalid.\n\nThe new approach automatically solves handling the response of a mutation and\nwhilst we could have continued using Redux we no longer wanted to maintain all\nthe boilerplate around managing request state so we opted to use TanStack\nQuery (formally react-query). This handles request states and errors for us\nwithout us needing to write Redux actions and reducers for each one. With the\nhelp of our own abstractions, we end up with an interface that looks like\nthis:\n\ntypescript\n\n    \n    \n    // mutationHook takes a GraphQL mutation created by code-generation, wraps it in our own request utility, handles some generic concerns and passes it to TanStack Query's useMutation hook. export const useAssignThreadMutation = createMutationHook({ mutation: AssignThreadDocument, }); // In a component: const { mutate: assignUserToThread, isLoading, isError } = useAssignThreadMutation();\n\n### Optimistic updates\n\nWhilst not directly part of the entity pipeline, we wouldn\u2019t want to commit to\nan architecture that didn\u2019t allow us to have optimistic updates when\nperforming mutations as this is something that users expect of a modern web\napplication to make it feel fast and performant. To achieve this we added the\nability to provide \u2018patches\u2019 to our entities from the `createMutationHook`\nabstraction:\n\ntypescript\n\n    \n    \n    export const useAssignThreadMutation = createMutationHook({ mutation: AssignThreadDocument, onMutate: (vars, store) => { const userId = vars.input.userId; const user = userByIdSelector(store.state, userId); return store.dispatch( entityActions.entityOptimisticPatch({ type: 'threads', id: vars.input.threadId, patch: (t) => { t.assignedTo = user; t.assignedAt = { __typename: 'DateTime', iso8601: DateTime.now().toUTC().toISO(), }; }, }) ); }, onSuccess: (ctx) => { ctx?.revertOptimisticPatch(); }, onError: (ctx) => { toast.error('Unable to assign thread.'); ctx?.revertOptimisticPatch(); }, });\n\nA patch is a function that takes an entity and performs a mutation on it. When\nanything reads that entity, the patch is applied until the patch is reverted\neither due to a success (in which case the entity has been updated by the\npipeline) or an error. This uses Immer under the hood which itself uses\nmetaprogramming techniques (Proxies) to provide a mutate-able interface in an\nimmutable system\n\nWe opted for patch functions over patch objects because they\u2019re much more\npowerful, more concise and patch objects can unintentionally override each\nother (e.g. adding and removing items to an array).\n\n### Offline handling\n\nBecause we\u2019ve designed the web application to be used all day, a lot of our\nusers tend to close their work laptops with Plain open and rightfully expect\nPlain to continue to work once they open it again the next morning. Since they\ndon\u2019t reload the page they aren\u2019t going to trigger the soft loading\nsynchronization and their browser has almost certainly paused/disconnected\nfrom the subscription websockets events.\n\nSo we need to know when a user has been away from Plain for a reasonable\namount of time to trigger the synchronization and reconnect the subscriptions.\nTo achieve this we layer a few techniques. Firstly, we reference various\nbrowser APIs such as navigator.onLine (connected to a LAN, not necessarily the\ninternet) and document.visibilityState (the browser/tab is active). These\nAPIs\u2019 behavior across different browsers is not consistent nor well documented\nso we only trust their negative states. Ultimately we worked out that the most\nreliable way to know the browser had paused you was to simply have a\nsetInterval running every second. By comparing the machine\u2019s timestamp between\nevery tick we'd definitely know if the javascript thread had been paused by\nthe browser, the code for this is below:\n\ntypescript\n\n    \n    \n    function checkJavascriptPaused(duration, callback) { let last = Date.now(); setInterval(() => { const now = Date.now(); const difference = now - last; last = now; // Add some buffer to avoid false positives if (difference > (duration * 0.2)) { callback(); } }, duration); }\n\n## Downsides\n\nThis new approach isn\u2019t without its negatives or compromises. Many of these\nare things we can iterate and improve upon over time and some are integral to\nthe approach.\n\nA big concern now is browser performance. We\u2019re demanding a lot more from our\nusers's browsers and with lots of complex filtering there\u2019s potential for some\nO(N*M) operations. We have to be careful here because whilst an expensive\nasynchronous operation will result in a user seeing a loading spinner for a\nwhile, an expensive synchronous operation will completely freeze the browser.\nTo avoid this, we use a combination of good algorithm design (e.g. index\ntables) and meta-programming (e.g. memoization). In the future, we could look\nat Web Workers to offload expensive operations away from the main browser\nthread.\n\nSimilarly, we\u2019re also limited by the browser in terms of persistence storage\nsize. If somebody has several thousand active threads on a browser that has a\nlower local storage capacity then local persistence will fail to work. Even if\nit is too large, the application will still work as expected as persistence is\nbuilt as an addition and not in the critical flow however there are definitely\nother paths we can investigate such as using a different browser storage API\nlike IndexedDB and also look into data compression with libraries such as lz-\nstring.\n\nThe other thing to consider is that a lot of this code is built and maintained\nby us. There are some solutions for pre-loading all entities in some GraphQL\nclient libraries but this is not their typical use-case and I think we\u2019d end\nup almost working against the library\u2019s idioms to end up with the results we\nwant. Additionally, the approach we\u2019ve taken isn\u2019t strongly linked to GraphQL.\nWe could easily change to a REST API, an event-driven API, etc. with very\nminimal changes.\n\nThere are also parts of the application that don\u2019t fit this model at all. We\nhave settings pages and authentication flows that exist entirely out of this.\nPreviously the state for these flows was managed in Redux but as part of this\nwork, we\u2019ve managed to move a lot of it to use TanStack Query instead. This is\nok for now but it's certainly not as nice and simple as having a single way to\ndo things across the full app.\n\nThat all being said, I think we\u2019re in a vastly better place and the negatives\nof this approach are not only much less significant than the previous approach\nbut the benefits are massive.\n\n## How\u2019s it going\n\nIt's been a long journey getting here but we feel we've solved a lot of the\nproblems we set out to tackle.\n\nFor subscriptions, the issue here was knowing what lists to invalidate and re-\nfetch when a new update came in. In the new architecture, there\u2019s no concept\nof lists in our Redux, so when we want to display a list of entities we simply\ndo that consumption by applying filters using client-side code. This also has\nthe additional benefit of making applying filters and sorts instantaneous.\n\nThe UI now is also no longer limited by pages nor does it require niche back-\nend APIs for minor features. We\u2019re able to display as many entities on a given\npage as we\u2019d like. In fact, we\u2019ve become a bit of a victim of our own success\nhere and have had to solve new problems such as the performance of rendering\nhundreds of threads all at once. Fortunately, this is a solved problem in\nReact with virtualization libraries like Virtuoso which basically only renders\nitems in view. We can now build complex filters and views purely on the\nclient-side and we can extract metadata from the entire set of active entities\nto provide something as trivial as a count to more interesting features like\nmetrics.\n\nThe developer experience has also massively improved. We no longer need to\nwrite Redux code to handle every single request flow, we don\u2019t have to handle\nasynchronicity and error states everywhere, and we can be confident that if we\nmake a mutation then the entity will be updated through the pipeline without\nhaving to manually update it.\n\nOverall we\u2019re able to deliver new features faster with fewer lines of code\nwhilst providing a higher quality of user experience than ever before. In\nfact, the front-end codebase before we made these architecture changes had\nsignificantly more lines of code than it did afterward. Typically introducing\na new entity or request flow was always something done begrudgingly by\ndevelopers and now such a joy that there\u2019s often competition between us to see\nwho gets to pick it up.\n\nIt also feels really fast.\n\n## Where might we take this next?\n\nWe've overcome the first step in becoming a local-first app but we still have\na long way to go to make this more mature.\n\nFrom optimizing how we synchronize clients to leveraging service workers,\nqueuing mutations when offline, and handling undo's globally... there is a lot\nto be done\n\nIf you are interested in working on problems like this - we're hiring!\n\n### Sign up for Plain\n\nWe're building Plain to be the fastest, most powerful support tool out there.\nWe'd love for you to try what we've built and tell us what you think.\n\nGet started for free\n\n### Join us\n\n...and write the next post. We're looking for product-centric engineers and\ndesigners to help us change every support interaction.\n\nView open roles now\n\nOlder post\n\n#### Interesting reading\n\nDocs\n\nPricing\n\nJobs\n\nBlog\n\nChangelog\n\nPress\n\nStatus\n\n#### Bedtime reading\n\nPrivacy Policy\n\nTerms of Service\n\nWebsite Terms\n\nData Processing Addendum\n\nVulnerability Disclosure Policy\n\n#### Backed by\n\n\u00a9 2024 Not Just Tickets Limited\n\nPlain and the Plain logo are trademarks and tradenames of Not Just Tickets\nLimited and may not be used or reproduced without consent.\n\n", "frontpage": false}
