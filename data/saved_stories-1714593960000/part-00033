{"aid": "40221662", "title": "Octree-GS: Consistent Real-Time Rendering with LOD-Structured 3D Gaussians", "url": "https://city-super.github.io/octree-gs/", "domain": "city-super.github.io", "votes": 1, "user": "jasondavies", "posted_at": "2024-05-01 10:56:14", "comments": 0, "source_title": "Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians", "source_text": "Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D\nGaussians\n\n# Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D\nGaussians\n\nKerui Ren*^1,2, Lihan Jiang*^1,3, Tao Lu^1, Mulin Yu^1, Linning Xu^4, Zhangkai\nNi^2, Bo Dai^1\n\n^1 Shanghai Artificial Intelligence Laboratory, ^2 Tongji University, ^3\nUniversity of Science and Technology of China, ^4 The Chinese University of\nHong Kong\n\nPaper Code\n\nTL;DR: We introduce Octree-GS, featuring an LOD-structured 3D Gaussian\napproach supporting level-of-detail decomposition for scene representation\nthat contributes to the final rendering results.\n\nOur method can guarantee continuous real-time rendering while achieving better\nvisual quality. (The white points represent the distribution of neural\nGaussian to reflect quantity variance)\n\n## Abstract\n\nThe recent 3D Gaussian splatting (3D-GS) has shown remarkable rendering\nfidelity and efficiency compared to NeRF-based neural scene representations.\nWhile demonstrating the potential for real-time rendering, 3D-GS encounters\nrendering bottlenecks in large scenes with complex details due to an excessive\nnumber of Gaussian primitives located within the viewing frustum. This\nlimitation is particularly noticeable in zoom-out views and can lead to\ninconsistent rendering speeds in scenes with varying details. Moreover, it\noften struggles to capture the corresponding level of details at different\nscales with its heuristic density control operation. Inspired by the Level-of-\nDetail (LOD) techniques, we introduce Octree-GS, featuring an LOD-structured\n3D Gaussian approach supporting level-of-detail decomposition for scene\nrepresentation that contributes to the final rendering results. Our model\ndynamically selects the appropriate level from the set of multi-resolution\nanchor points, ensuring consistent rendering performance with adaptive LOD\nadjustments while maintaining high-fidelity rendering results.\n\n## Method Overview\n\nIllustration of our proposed Octree-GS: Starting from a sparse point cloud, we\nconstruct an octree for the bounded 3D space. Each octree level provides a set\nof anchor Gaussians assigned to the corresponding LOD level. Unlike\nconventional 3D-GS methods treating all Gaussians equally, our approach\ninvolves anchor Gaussians with different LODs. During novel view rendering, we\ndetermine the required LOD level l for each occupied anchor voxel within the\noctree from the observation center and invoke all anchor Gaussians up to that\nlevel for final rendering. This process, shown in the middle, results in an\nincreased level of detail by gradually fetching anchors from higher LODs in an\naccumulation manner. Our model is trained with standard image reconstruction\nloss and additional regularization loss following the practice of Scaffold-GS.\n\n## Results\n\nIn real large scenes, Octree-GS can ensure continuous real-time rendering\nwhile maintaining fine rendering details. Compared with current SOTA methods,\nour method has significant advantages when rendering in the high-altitude\nviews.\n\nScaffold-GS\n\nOctree-GS\n\nMip-Splatting\n\nScaffold-GS\n\nOctree-GS\n\nMip-Splatting\n\n### Comparison with SOTA method\n\nCompared to existing baselines, Octree-GS successfully captures very fine\ndetails present in the scene, particularly for objects with thin structures\nsuch as trees, light-bulbs, decorative texts, etc.\n\n### Performance at different resolutions\n\nThanks to our LOD-structured 3D Gaussians design, Octree-GS can adaptively\nhandle the changed footprint size and effectively address the aliasing issues\ninherent to 3D-GS and Scaffold-GS.\n\n### Effectiveness of Progressive Training\n\nVisualization of anchor Gaussians in different LODs (several levels are\nomitted for visual brevity), displaying both anchor points and splatted 2D\nGaussians in each image. Progressive training can guide the coarse-to-fine\nreconstruction process, avoid overlapping between different LOD levels. This\nstrategy can not only reduce the number of rendered neural Gaussians, but\nimprove the rendering accuracy of coarser LOD levels (e.g. LOD0, LOD1).\n\n### Effectiveness of LOD Bias\n\nLOD bias is set as a learnable parameters for each anchor Gaussian as a\nresidual to LOD levels. it effectively supplement the high-frequency regions\nwith more consistent details to be rendered during inference process, such as\nthose sharp edges of an object.\n\n### Visualization at different LODs\n\nA clear division of roles is evident between different levels: LOD 0 captures\nmost rough scene contents, and higher LODs gradually pick up the previously\nmissed high-frequency details. The following is a hierarchical visualization\nof the rendering results on various types of scenes.\n\n  * Bicycle\n  * Counter\n  * Garden\n  * Stump\n  * Room\n  * Truck\n  * DrJohnson\n  * Playroom\n\nLOD0\n\nLOD1\n\nLOD2\n\nLOD3\n\n## Real-Time Interactive Viewer\n\nGaussian Viewers for Octree-GS is available now! We provide pre-built binaries\nof Real-Time Viewer for Windows here and you can test it with examples below.\n\n  * garden in the Mip-NeRF 360 Dataset;\n  * bicycle in the Mip-NeRF 360 Dataset;\n  * counter in the Mip-NeRF 360 Dataset;\n  * drjohnson in the Deep Blending Dataset;\n\nWe thank the authors of Nerfies that kindly open sourced the template of this\nwebsite.\n\n", "frontpage": false}
