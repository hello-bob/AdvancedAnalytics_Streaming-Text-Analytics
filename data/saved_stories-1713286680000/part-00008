{"aid": "40050423", "title": "How to Build an AI Agent Using No-Code Tools", "url": "https://www.techsistence.com/p/how-to-build-an-ai-agent-using-no", "domain": "techsistence.com", "votes": 3, "user": "gregrog", "posted_at": "2024-04-16 10:39:08", "comments": 0, "source_title": "How to Build an AI Agent Using No-Code Tools?", "source_text": "How to Build an AI Agent Using No-Code Tools?\n\nShare this post\n\n#### How to Build an AI Agent Using No-Code Tools?\n\nwww.techsistence.com\n\n#### Discover more from Tech\u2022sistence\n\nSharing insights on technology: deep dives on AI, automation, as well as\nbusiness-oriented content for founders and developers. Lessons learned from\nthe bootstrapping journey in our various ventures.\n\nOver 2,000 subscribers\n\nContinue reading\n\nSign in\n\n# How to Build an AI Agent Using No-Code Tools?\n\n### An agent in make.com that has long-term memory (xata.io & qdrant.tech) and\nuses tools.\n\nAdam Gospodarczyk\n\nApr 11, 2024\n\n6\n\nShare this post\n\n#### How to Build an AI Agent Using No-Code Tools?\n\nwww.techsistence.com\n\n2\n\nShare\n\n> Note: You can download the scenario schema and the prompts included in it at\n> the bottom of this post.\n\nLarge Language Models can be equipped with long-term memory by dynamically\nloading the context of a query, leading us to Retrieval Augmented Generation.\nMeanwhile, their ability to understand and generate content can also be\nutilized with APIs, opening up a new chapter in user interface design.\n\nTherefore, nothing prevents us from combining these two areas and creating a\nsystem known as an \"agent\" capable of performing complex tasks even without\nour involvement.\n\nIt should be noted here that the concept of agents, especially the most\nadvanced ones, is still in the experimental phase. Additionally, we observe a\nvery dynamic development of both commercial and Open Source LLMs and their\nassociated tools. This strongly suggests that at least at the learning stage\nor early stages of implementation, it is worth choosing a path that will allow\nus to iterate our solutions quickly. My choice here is no-code tools, which\nhave many limitations but allow me to move quickly through the concepts.\nLater, I transfer some of them to code, and some remain in the no-code area,\nas this is entirely sufficient.\n\nIn this post, we will focus on creating the foundations of an agent capable of\nautonomously performing various tasks, using both long-term memory, external\ntools, and quite advanced prompt design techniques. Our system will be based\non modules that can connect with each other and which we can develop\nindependently.\n\n##\n\nBroad perspective and main concepts\n\nThe agent should independently lead a conversation, deciding which memories to\nrecall and tools to use.\n\nThe entire logic will be designed as automation scenarios on the make.com\nplatform. The conversation history, memories, and available skills will be\nstored in the xata.io database, and their search will be conducted with the\nhelp of the vector database qdrant.tech.\n\nAs a result, a sample interaction will look as follows:\n\nHere we have:\n\n  * a user's request to play music\n\n  * a moment when the agent considers what to do (reflection)\n\n  * recognition of the user's intent based on the query and agent\u2019s reflection (intent recognition)\n\n  * asking itself about different memory areas and a list of available actions (self query)\n\n  * verifying which memories are needed and which are not (re-rank)\n\n  * describing the actions to be taken and executing them\n\n  * collecting responses from the actions\n\n  * paraphrasing the collected data and generating a response\n\n  * sending the message to the user\n\nThis translates into the following make.com scenario, which we will discuss\nshortly.\n\nLooking at the above scenario, we see here:\n\n  * loading information about the current conversation and available skills (the upper path, which always executes)\n\n  * then we have two OpenAI modules, the first for reflection increasing the likelihood of proper action planning, and the second consists of actually designing the plan and detecting the user's intent\n\n  * and finally, we have three branches: the first for memories, the second for taking action, and the third for generating a response based on the previous two paths. It is worth adding that filters set on individual paths may block their execution (e.g., it may not always be necessary to take action, and the decision about this is made by the LLM)\n\nWe will return to the assistant's logic shortly, but meanwhile, let's look at\nthe database structure.\n\nAs you can see in the diagram, it has three tables:\n\n  * messages: stores a list of messages connected through conversation_uuid, which will be reset every 30 minutes (or at our request)\n\n  * skills: stores a list of skills in the form of a name and description based on which skills are selected, and a prompt and URL based on which a given skill is activated\n\n  * memories: contains information about memories organized according to our described structure (category and subcategory, and tags). Additionally, these memories are indexed in the Qdrant vector database.\n\nGoing deeper into the topic of the database, it looks as follows:\n\n  * Each message sent by the user creates a new entry in the messages table. This entry is updated when AI generates a response.\n\n  * Messages are connected through a unique identifier. Based on this, we can recreate the current conversation (as we know, LLM is stateless, so with each query, we must recreate the entire conversation)\n\n  * Available skills are retrieved as a list (name and description) for classification prompts (we will look at them shortly). Only when they are activated are the other information, such as the prompt and URL, also loaded.\n\n  * The list of memories contains categories and subcategories, allowing the agent to access only selected areas of its memory. Adding (and possibly updating) them is the responsibility of a separate agent skill, which can be activated like any other. We will also look at this below.\n\nIn this way, we have obtained a foundation that addresses all our assumptions\nrelated to conducting a conversation, using memory, and tools. We are\ntherefore ready for implementation.\n\n##\n\nDatabase and Semantic Search\n\nThe brain of the agent consists of the combination of the xata.io database and\nthe qdrant.tech vector database. We already know their structure, but I would\nlike to dwell here a bit longer.\n\nFirst and foremost, the xata.io database serves long-term information storage.\nAccess to it is possible either through a visual interface or through a ready-\nmade API that we can connect to in make.com or application code.\n\nAlthough each message exchanged with the agent will be saved in the messages\ntable, the agent will not have access to content not found in the current\nconversation. This is a deliberate action, thanks to which only the\ninformation we care about will reach long-term memory. All the more so because\nnothing prevents us from switching between conversations and, if necessary,\nreturning to one that took place earlier.\n\nSuch action directly results from my experience and indicates that we will\nwant only the most valuable and well-described information to be in long-term\nmemory. This will facilitate their later recovery, which will positively\naffect the overall operation of the assistant.\n\nTherefore, currently, remembering information can only happen when we\nexplicitly ask for it. However, in slightly more advanced examples of agents,\nwe can include a solution that will independently decide what to remember and\nwhat not to. This time, however, we will omit that.\n\nMoving on, we have a table storing memories. What is interesting about it is\nprimarily that the content of these memories is generated by the LLM, not\nprovided by us. Thanks to this, their structure and the form of recording\nremain quite consistent and are dependent on the prompts responsible for their\norganization.\n\nAutomatic saving of memories is not only associated with their content but\nalso with the way they are described and placed within categories and\nsubcategories. Specifically, we are talking about the following structure:\n\nThe above list is attached to the prompts responsible both for saving memories\nand for searching them. Of course, it can still happen that a memory is saved\nin category X, and during its retrieval, the model indicates category Y.\nHowever, there is a way to reduce the risk of such a problem by conducting two\nparallel searches \u2014 a general one, ignoring categories, and a narrow one,\nconsidering only the specified area. Although we still do not have 100%\ncertainty that the memory will be found, the risk of such a situation is\nappropriately lower.\n\nMoreover, such a structure will only be effective up to a certain point. Too\nmany entries may appear in one category and subcategory, which will complicate\ntheir later retrieval. This will require reorganizing the memory or adding\nadditional filters, such as tags.\n\nRegarding memory, it is also worth paying attention to the \"sources\" column,\nwhich will usually contain links to the original sources. It is also worth\nconsidering including additional metadata that allows for an even more precise\nindication of the source of information (e.g., a book page or article section\nheader).\n\nAnd finally, we have the skills table, which to some extent is quite unusual.\nTypically, in the case of tools, we would rely on using Function Calling. This\nis a mechanism that allows various tools to be passed to the prompt, and the\nmodel will decide how to use them. In my case, I decided to opt-out of this\nfor the so-called \"JSON mode,\" which is simply a situation where the LLM\nreturns a JSON object describing the function arguments.\n\nOther issues related to skills should be understandable at this stage,\nalthough we will return to them. It is worth adding that at this moment, I\nhave manually entered the above skills, and they are responsible for managing\nthe task list in Linear, calculations with the help of Wolfram, and using\nmemory (or simply remembering information).\n\n##\n\nMain Logic \u2014 Stage #1: Conversation\n\nThe first stage of the make.com scenario implementing the assistant's logic\nbegins with a Webhook to which the user's message is sent.\n\nThen a router is activated, and its upper path where:\n\n  * a message from the last 30 minutes is retrieved from the database from the messages table, and from it, the conversation identifier is read. If not found, the identifier is generated, and the conversation starts anew. If, however, it is found, we use it to retrieve all messages from that conversation, the content of which is read into the context\n\n  * skills from the skills table are also loaded\n\n  * and a new message containing only the user's question is created. Its identifier is saved for later so that we can update its content with the assistant's response\n\n  * all this information is collected and saved in variables, which we load in the second branch of the scenario, marked in the screenshot above.\n\nIn this way, we have a complete set of information necessary to take further\nactions.\n\n##\n\nMain Logic \u2014 Stage #2: Reflection, Intent Recognition, and Planning\n\nIn the second stage, all available information, along with the mentioned\nmemory structure, is processed in two ways. The first one consists solely of\nthe agent's internal speech, pondering what to do next to lead an engaging\nconversation.\n\nThe prompt below thus generates only text reminiscent of thoughts focused on\npotential actions to be taken.\n\nThis mechanism significantly increases the agent's effectiveness, as in the\nnext step, it will no longer have time for this, and its attention will be\nfocused solely on generating a plan of action.\n\nThe above prompt thus encourages the model to whisper, allowing it to\ncontemplate behavior in the context of:\n\n  * the current conversation\n\n  * the list of areas of its memories and skills\n\nCombining whispering with techniques from the field of mentalism (including\nthe cognitive and psychological area) results in generating reflections based\nnot only on what has been said but also on what the user might be thinking.\n\nThe next step is to plan actions and recognize the user's intentions. For this\npurpose, we use a prompt whose role is to generate two lists:\n\n  * a list of queries to its own memory, indicating the areas to be searched\n\n  * a list of actions to be taken as part of the response given\n\nThe result of this prompt allows us to start the third stage of generating a\nresponse.\n\n##\n\nMain Logic \u2014 Stage #3: Recalling Memories and Taking Action\n\nThe final stage of preparing the response involves scanning long-term memory\nand gathering all necessary memories, and then taking action (if necessary).\n\nWe know that at the planning stage, the agent generated a list of queries and\nindicated the areas of its memory that we should focus on. So now, we just\nneed to go through them (using the Iterator module) and use their content to\nsearch the long-term memory.\n\nThe search itself is done with the help of qdrant.tech, which requires us to\nconvert individual queries into so-called embeddings describing their meaning.\nIn the search itself, we also include filters, which allow specifying the\nsearched areas of memory.\n\nFinally, we gather all memories and save them in the form of a variable, which\nwe load in the subsequent paths of the scenario.\n\nThe next path therefore retrieves the accumulated memories and all previous\ninformation, and then goes through the list of actions that need to be taken.\nEach action is reloaded from the database and then added to the prompt\ndescribing its operation. This time the prompt is simple, but it may contain\ntwo elaborate descriptions (instructions and a list of memories).\n\nThe result of the above prompt will always be a JSON object, which will be\nused to execute an HTTP request to the address associated with the given\naction.\n\nIn this way, we can go through each of the tasks defined in the second stage\nof the agent's operation, and their result will be collected and passed on to\nthe last stage.\n\n##\n\nMain Logic \u2014 Stage #4: Paraphrasing and Generating Responses\n\nAnd the last step related to generating responses is paraphrasing the\ncollected information in such a way that the result constitutes a continuation\nof the conversation.\n\nIn this case, the conversation history is recorded directly in the system\nmessage, but usually, it would be located on the list of messages exchanged\nbetween the user and the assistant.\n\nThe final result is therefore a regular response, which is returned as a\nresponse to a query directed at the automation scenario webhook and\nadditionally recorded in the database in the messages table.\n\n##\n\nSkills \u2014 Remembering\n\nThe agent's skills in this case always involve directing a query to a specific\naddress and receiving a response. This means that when creating additional\ntools, we are talking about separate modules, whose interface must be\nconsistent, and their implementation may vary.\n\nAn example of one of the tools could be the agent's memory. In this case, it\nonly allows for recording new information, but nothing prevents it from being\nexpanded to include updating, and even deleting.\n\nThe tool presented above accepts data that is to be remembered. However, its\ncontent does not go directly into the database but passes through an\nadditional prompt, whose role is to appropriately describe the new memory.\n\nAs you can see, this is a quite elaborate prompt, whose role is to generate a\nlist of memories based on the information sent by the user. The example\nincluded also clearly emphasizes the possibility of generating more than one\nmemory based on just one message, which promotes proper organization.\n\nThe memory described in this way is saved in the xata.io database, and its\nmain content is converted into an embedding and, along with metadata, goes to\nthe vector database qdrant.tech.\n\nAll data about the saved memories are usually collected and transmitted as\nfeedback, which can be used at the stage of generating the final response of\nthe assistant.\n\nIn exactly the same way, we can create additional tools, whose name,\ndescription, and operating instructions (prompt) are recorded in the database,\nin the skills table.\n\nJust for example, I am adding an example of the \"Wolfram\" tool, which accepts\na list of queries directed to Wolfram Alpha, and then sends their results in\nresponse.\n\nInteresting fact: nothing prevents adding new skills from also being one of\nthe assistant's skills. Then, instead of manually adding them, we could simply\ntell the agent to remember a new skill.\n\n##\n\nConversation\n\nThe main scenario can be connected directly with any HTTP client (e.g.,\nPostman). In my case, however, I will use the Alice application, in which I\ncreate a remote snippet named \"Agent\" and a prompt generating a JSON object\nwith the \"query\" property.\n\nThen, upon execution, the content of my message will be passed by Alice to the\nmake.com scenario.\n\nSo, if I now simply greet Alice, I will not only receive a greeting but\nalso... a question about my fianc\u00e9e and dog!\n\nThis happened because Alice, at the stage of self-reflection, decided that in\norder to continue such a conversation, she would read additional information\nabout me.\n\nShe then asked herself a few questions, which were used to recall the\nappropriate memories.\n\nIn this particular case, no actions were required, so (as you can see above)\nthe actions list is empty. However, just ask for something specific, and the\nAgent will independently decide what needs to be done.\n\nContinuing the conversation, I asked to list my tasks related to the easy_\nproject. Moments later, I received a correct response generated based on the\ninformation read from linear.app.\n\nExactly on the same principle, I could ask to add new tasks or update existing\nones. The game involves connecting with virtually any services, tools, and\ndevices that provide an API.\n\nBefore we go further, I would like to draw attention again to the way the\nindividual steps are implemented. Namely, in this case, the reflection stage\nclearly indicated the need to connect with the task list in the Linear app,\nand to read information about the easy_ project.\n\nIn this way, the agent \"reflected\" again on the actions to be taken, and then\ncorrectly implemented them.\n\n##\n\nWhat's Next?\n\nWe now have at our disposal an interesting automation scheme, very susceptible\nto extensions, both in terms of memory and new skills. Besides, the simple\ninterface (question - answer) allows for easy voice interaction through Siri\nor Shortcuts. Alternatively, we can also use the Siri app or our own\nintegration.\n\nCollecting all this together, we have here:\n\n  * An agent that can respond to our commands and perform even several different tasks within one query\n\n  * An agent that can learn new things, using a separate scenario responsible for managing its memory\n\n  * An agent that can learn new skills, which it can then use with its memory during conversations\n\n  * An agent that can receive commands not only from us but also from various systems. Each command can be individually considered and addressed according to available memory or skills\n\nThus, our agent can either be connected to the interface from which we will be\nusing it ourselves, or to a set of scripts and automations that will send\nvarious information to it. For example:\n\n  * The make.com scenario can monitor messages tagged by us (or by an automatic filter), which can be converted into tasks or organized according to our rules.\n\n  * Periodically triggered automation can send a message to the agent to take care of organizing, for example, our documents.\n\n  * Also, periodically triggered automation can conduct research on a selected topic, using tools such as exa.ai or scrapingbee.com.\n\n  * Other events can also be linked to sending commands to the assistant, e.g., a new task assigned to us, a new issue on GitHub, a new post on our favorite blog, or a video on YouTube. Linking with these events will allow the agent to take actions determined by us, with his long-term memory.\n\nAnd ultimately, the entire foundation of the agent can be appropriately\nexpanded and adapted, both in terms of prompts and the logic itself.\n\nTech\u2022sistence is a reader-supported publication. To receive new posts and\nsupport my work, consider becoming a free or paid subscriber.\n\n  * The main scenario schema can be downloaded here.\n\n  * The schema of an example tool (memory) can be downloaded here.\n\nThat's all! If you have any questions about the discussed agent, I am\navailable in the comments.\n\nHave fun, Adam\n\n6 Likes\n\n\u00b7\n\n2 Restacks\n\n6\n\nShare this post\n\n#### How to Build an AI Agent Using No-Code Tools?\n\nwww.techsistence.com\n\n2\n\nShare\n\n2 Comments\n\nMarek WituszynskiApr 11Liked by Adam GospodarczykAdam, as usual, a ton of\nknowledge here, and I can't wait to test it by myself. I think there might be\na typo in scrapingbee.com (double p), and the second schema attached is a\nPNG.Expand full commentLike (1)ReplyShare  \n---  \n  \n1 reply\n\n1 more comment...\n\nThe rise of Artificial General Intelligence (AGI)\n\nShould we worry about what's to come in AI?\n\nNov 25, 2023 \u2022\n\nGreg Rog\n\n8\n\nShare this post\n\n#### The rise of Artificial General Intelligence (AGI)\n\nwww.techsistence.com\n\n2\n\nMy framework for goals & efficient delivery\n\nWhat keeps you up at night? Staying productive is challenging when we are\nmissing the purpose. But everyone gets a bit lost once in a while. Here's\nmy...\n\nJan 25 \u2022\n\nGreg Rog\n\n4\n\nShare this post\n\n#### My framework for goals & efficient delivery\n\nwww.techsistence.com\n\nYou gained 3 new friends: 2 humans and 1 robot\n\nAnd this is just for a start. You are about to gain new skills, too: ones that\nhelp you save time & accomplish more with technology. Take our word for...\n\nNov 14, 2023 \u2022\n\nGreg Rog\n\n11\n\nShare this post\n\n#### You gained 3 new friends: 2 humans and 1 robot\n\nwww.techsistence.com\n\nReady for more?\n\n\u00a9 2024 Tech\u2022sistence\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}
