{"aid": "40218582", "title": "ExecuTorch Alpha: Taking LLMs and AI to the Edge", "url": "https://pytorch.org/blog/executorch-alpha/", "domain": "pytorch.org", "votes": 1, "user": "brainer", "posted_at": "2024-05-01 01:38:30", "comments": 0, "source_title": "ExecuTorch Alpha: Taking LLMs and AI to the Edge with Our Community and Partners", "source_text": "ExecuTorch Alpha: Taking LLMs and AI to the Edge with Our Community and Partners | PyTorch\n\n  * Get Started\n  * Ecosystem\n\nPyTorch Conference - 2024\n\nSeptember 18-19 in San Francisco\n\nTools\n\nLearn about the tools and frameworks in the PyTorch Ecosystem\n\n  * Edge\n\nAbout PyTorch Edge ExecuTorch\n\n  * Blog\n  * Tutorials\n  * Docs\n\nPyTorch\n\ntorchaudio\n\ntorchtext\n\ntorchvision\n\ntorcharrow\n\nTorchData\n\nTorchRec\n\nTorchServe\n\nPyTorch on XLA Devices\n\n  * Resources\n\nAbout\n\nLearn about PyTorch\u2019s features and capabilities\n\nPyTorch Foundation\n\nLearn more about the PyTorch Foundation.\n\nCommunity\n\nJoin the PyTorch developer community to contribute, learn, and get your\nquestions answered.\n\nCommunity stories\n\nLearn how our community solves real, everyday machine learning problems with\nPyTorch\n\nDeveloper Resources\n\nFind resources and get questions answered\n\nEvents\n\nFind events, webinars, and podcasts\n\nForums\n\nA place to discuss PyTorch code, issues, install, research\n\nModels (Beta)\n\nDiscover, publish, and reuse pre-trained models\n\n  * GitHub\n  * X\n\nApril 30, 2024\n\n# ExecuTorch Alpha: Taking LLMs and AI to the Edge with Our Community and\nPartners\n\nby Team PyTorch\n\nWe are excited to announce the release of ExecuTorch alpha, focused on\ndeploying large language models (LLMs) and large ML models to the edge,\nstabilizing the API surface, and improving our installation processes. It has\nbeen an exciting few months from our 0.1 (preview) release in collaboration\nwith our partners at Arm, Apple, and Qualcomm Technologies, Inc.\n\nIn this post we\u2019ll discuss our full support for Meta\u2019s Llama 2, early support\nfor Meta\u2019s Llama 3, broad model support in ExecuTorch, and highlight the\nimportant work our partners have done to move us forward.\n\n## Large Language Models on Mobile\n\nMobile devices are highly constrained for compute, memory, and power. To bring\nLLMs to these devices, we heavily leverage quantization and other techniques\nto pack these models appropriately.\n\nExecuTorch alpha supports 4-bit post-training quantization using GPTQ. We\u2019ve\nprovided broad device support on CPU by landing dynamic shape support and new\ndtypes in XNNPack. We\u2019ve also made significant improvements in export and\nlowering, reduced memory overhead and improved runtime performance. This\nenables running Llama 2 7B efficiently on iPhone 15 Pro, iPhone 15 Pro Max,\nSamsung Galaxy S22, S23, and S24 phones and other edge devices. Early support\nfor Llama 3 8B is also included. We are always improving the token/sec on\nvarious edge devices and you can visit GitHub for the latest performance\nnumbers.\n\nWe\u2019re working closely with our partners at Apple, Arm, and Qualcomm\nTechnologies to delegate to GPU and NPU for performance through Core ML, MPS,\nTOSA, and Qualcomm AI Stack backends respectively.\n\n## Supported Models\n\nWe remain committed to supporting an ever-expanding list of models with\nExecuTorch. Since preview, we have significantly expanded our tested models\nacross NLP, vision and speech, with full details in our release notes.\nAlthough support for on-device LLMs is early, we anticipate most traditional\nmodels to function seamlessly out of the box, with delegation to XNNPACK, Core\nML, MPS, TOSA, and HTP for performance. If you encounter any problems please\nopen a GitHub issue with us.\n\n## Productivity\n\nDeploying performant models tuned for specific platforms often require deep\nvisualization into the on-device runtime data to determine the right changes\nto make in the original PyTorch model. With ExecuTorch alpha, we provide a\npowerful SDK with observability throughout the process from model authoring to\ndeployment, including delegate and hardware-level information.\n\nThe ExecuTorch SDK was enhanced to include better debugging and profiling\ntools. Because ExecuTorch is built on PyTorch, the debugging capabilities\ninclude the ability to map from operator nodes back to original Python source\ncode for more efficient anomaly resolution and performance tuning for both\ndelegated and non-delegated model instances. You can learn more about the\nExecuTorch SDK here.\n\n## Partnerships\n\nExecuTorch has only been possible because of strong collaborations across Arm,\nApple, and Qualcomm Technologies. The collaboration for the initial launch of\nExecuTorch continues as we support LLMs and large AI models on the edge for\nPyTorch. As we\u2019ve seen with this early work for ExecuTorch alpha, there are\nunique challenges with these larger models and we\u2019re excited to develop in the\nopen.\n\nWe also want to highlight the great partnership with Google on XNNPACK for CPU\nperformance. The teams continue to work together upstreaming our changes and\nacross the TensorFlow and PyTorch teams to make sure we can all support\ngenerative AI models on the edge with SOTA performance.\n\nLastly, our hardware partner MediaTek has been doing work enabling the Llama\ncollection of models with ExecuTorch on their SoCs. We\u2019ll have more to share\nin the future.\n\n## Alpha and Production Usage\n\nWith our alpha release, we have production-tested ExecuTorch. Meta is using\nExecuTorch for hand tracking on Meta Quest 3 and a variety of models on Ray-\nBan Meta Smart Glasses. In addition, we have begun the rollout of ExecuTorch\nwith Instagram and are integrating with other Meta products. We are excited to\nsee how ExecuTorch can be used for other edge experiences.\n\n## Community\n\nWe are excited to see various efforts in the community to adopt or contribute\nto ExecuTorch. For instance, Unity recently shared their work at the Game\nDevelopers Conference (GDC) on leveraging ExecuTorch and Edge IR to run\nPyTorch models with their neural network inference library Sentis. Leveraging\nExecuTorch\u2019s hackability and extensibility, Unity introduced their own custom\nbackend that serializes ExecuTorch\u2019s Edge Dialect IR into Sentis\u2019 native\nserialized format enabling developers to begin using PyTorch models easily in\ntheir games and apps.\n\nWe\u2019ve been building and innovating with ExecuTorch in the open. Our north star\nis to empower the community to deploy any ML model on edge devices painlessly\nand efficiently. Whether you are a hobbyist or this is your day job, we\u2019d love\nfor you to jump in to bring your ML models to the edge. We are looking for\nyour help to:\n\n  1. Use ExecuTorch to run your LLM models locally on various deployment targets and share your feedback\n  2. Expand our supported models, including bug reports\n  3. Expand our quantization schemes\n  4. Help us build out delegates to GPU and NPU\n\nTo all individual contributors and early adopters of ExecuTorch, a big thank\nyou as well. We can\u2019t wait to have more of you join us!\n\n## Docs\n\nAccess comprehensive developer documentation for PyTorch\n\nView Docs\n\n## Tutorials\n\nGet in-depth tutorials for beginners and advanced developers\n\nView Tutorials\n\n## Resources\n\nFind development resources and get your questions answered\n\nView Resources\n\n  * PyTorch\n  * Get Started\n  * Features\n  * Ecosystem\n  * Blog\n  * Contributing\n  * Security\n\n  * Resources\n  * Tutorials\n  * Docs\n  * Discuss\n  * GitHub Issues\n  * Brand Guidelines\n\n  * Stay up to date\n\n  * Facebook\n  * Twitter\n  * YouTube\n  * LinkedIn\n  * Mastodon\n\n  * PyTorch Podcasts\n\n  * Spotify\n  * Apple\n  * Google\n  * Amazon\n\n  * Terms\n  * |\n  * Privacy\n\n\u00a9 Copyright The Linux Foundation. The PyTorch Foundation is a project of The\nLinux Foundation. For web site terms of use, trademark policy and other\npolicies applicable to The PyTorch Foundation please see\nwww.linuxfoundation.org/legal/policies/. The PyTorch Foundation supports the\nPyTorch open source project, which has been established as PyTorch Project a\nSeries of LF Projects, LLC. For policies applicable to the PyTorch Project a\nSeries of LF Projects, LLC, please see www.lfprojects.org/policies/.\n\n  * Get Started\n  * Ecosystem\n    * PyTorch Conference - 2024\n    * Tools\n  * Edge\n    * About PyTorch Edge\n    * ExecuTorch\n  * Blog\n  * Tutorials\n  * Docs\n    * PyTorch\n    * torchaudio\n    * torchtext\n    * torchvision\n    * torcharrow\n    * TorchData\n    * TorchRec\n    * TorchServe\n    * PyTorch on XLA Devices\n  * Resources\n    * About\n    * PyTorch Foundation\n    * Community\n    * Community stories\n    * Developer Resources\n    * Events\n    * Forum\n    * Models (Beta)\n  * GitHub\n\nTo analyze traffic and optimize your experience, we serve cookies on this\nsite. By clicking or navigating, you agree to allow our usage of cookies. As\nthe current maintainers of this site, Facebook\u2019s Cookies Policy applies. Learn\nmore, including about available controls: Cookies Policy.\n\n", "frontpage": false}
