{"aid": "40136979", "title": "Phi-3: Redefining what's possible with SLMs", "url": "https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/", "domain": "microsoft.com", "votes": 12, "user": "mike-the-brain", "posted_at": "2024-04-23 20:38:32", "comments": 0, "source_title": "Introducing Phi-3: Redefining what's possible with SLMs | Microsoft Azure Blog", "source_text": "Introducing Phi-3: Redefining what's possible with SLMs | Microsoft Azure Blog\n\nSkip to main content\n\nAzure\n\nSign in\n\nSubscribe\n\nAI + Machine Learning, Announcements, Azure AI, Azure AI Studio\n\n# Introducing Phi-3: Redefining what\u2019s possible with SLMs\n\nBy Misha Bilenko Corporate Vice President, Microsoft GenAI\n\nIntroducing Phi-3: Redefining what\u2019s possible with SLMs \u2022 4 min read\n\nShare Introducing Phi-3: Redefining what\u2019s possible with SLMs on Facebook\nShare Introducing Phi-3: Redefining what\u2019s possible with SLMs on X Share\nIntroducing Phi-3: Redefining what\u2019s possible with SLMs on LinkedIn\n\nPosted on April 23, 2024 4 min read\n\nShare Introducing Phi-3: Redefining what\u2019s possible with SLMs on Facebook\nShare Introducing Phi-3: Redefining what\u2019s possible with SLMs on X Share\nIntroducing Phi-3: Redefining what\u2019s possible with SLMs on LinkedIn\n\n  * Tag: AI\n  * Tag: Copilot\n  * Tag: Generative AI\n\nWe are excited to introduce Phi-3, a family of open AI models developed by\nMicrosoft. Phi-3 models are the most capable and cost-effective small language\nmodels (SLMs) available, outperforming models of the same size and next size\nup across a variety of language, reasoning, coding, and math benchmarks. This\nrelease expands the selection of high-quality models for customers, offering\nmore practical choices as they compose and build generative AI applications.\n\nStarting today, Phi-3-mini, a 3.8B language model is available on Microsoft\nAzure AI Studio, Hugging Face, and Ollama.\n\n  * Phi-3-mini is available in two context-length variants\u20144K and 128K tokens. It is the first model in its class to support a context window of up to 128K tokens, with little impact on quality.\n  * It is instruction-tuned, meaning that it\u2019s trained to follow different types of instructions reflecting how people normally communicate. This ensures the model is ready to use out-of-the-box.\n  * It is available on Azure AI to take advantage of the deploy-eval-finetune toolchain, and is available on Ollama for developers to run locally on their laptops.\n  * It has been optimized for ONNX Runtime with support for Windows DirectML along with cross-platform support across graphics processing unit (GPU), CPU, and even mobile hardware.\n  * It is also available as an NVIDIA NIM microservice with a standard API interface that can be deployed anywhere. And has been optimized for NVIDIA GPUs.\n\nIn the coming weeks, additional models will be added to Phi-3 family to offer\ncustomers even more flexibility across the quality-cost curve. Phi-3-small\n(7B) and Phi-3-medium (14B) will be available in the Azure AI model catalog\nand other model gardens shortly.\n\nMicrosoft continues to offer the best models across the quality-cost curve and\ntoday\u2019s Phi-3 release expands the selection of models with state-of-the-art\nsmall models.\n\n## Azure AI Studio\n\nPhi-3-mini is now available\n\nExplore the release\n\n## Groundbreaking performance at a small size\n\nPhi-3 models significantly outperform language models of the same and larger\nsizes on key benchmarks (see benchmark numbers below, higher is better).\nPhi-3-mini does better than models twice its size, and Phi-3-small and\nPhi-3-medium outperform much larger models, including GPT-3.5T.\n\nAll reported numbers are produced with the same pipeline to ensure that the\nnumbers are comparable. As a result, these numbers may differ from other\npublished numbers due to slight differences in the evaluation methodology.\nMore details on benchmarks are provided in our technical paper.\n\nNote: Phi-3 models do not perform as well on factual knowledge benchmarks\n(such as TriviaQA) as the smaller model size results in less capacity to\nretain facts.\n\n## Safety-first model design\n\nResponsible ai principles\n\nLearn about our approach arrow_up_right\n\nPhi-3 models were developed in accordance with the Microsoft Responsible AI\nStandard, which is a company-wide set of requirements based on the following\nsix principles: accountability, transparency, fairness, reliability and\nsafety, privacy and security, and inclusiveness. Phi-3 models underwent\nrigorous safety measurement and evaluation, red-teaming, sensitive use review,\nand adherence to security guidance to help ensure that these models are\nresponsibly developed, tested, and deployed in alignment with Microsoft\u2019s\nstandards and best practices.\n\nBuilding on our prior work with Phi models (\u201cTextbooks Are All You Need\u201d),\nPhi-3 models are also trained using high-quality data. They were further\nimproved with extensive safety post-training, including reinforcement learning\nfrom human feedback (RLHF), automated testing and evaluations across dozens of\nharm categories, and manual red-teaming. Our approach to safety training and\nevaluations are detailed in our technical paper, and we outline recommended\nuses and limitations in the model cards. See the model card collection.\n\n## Unlocking new capabilities\n\nMicrosoft\u2019s experience shipping copilots and enabling customers to transform\ntheir businesses with generative AI using Azure AI has highlighted the growing\nneed for different-size models across the quality-cost curve for different\ntasks. Small language models, like Phi-3, are especially great for:\n\n  * Resource constrained environments including on-device and offline inference scenarios.\n  * Latency bound scenarios where fast response times are critical.\n  * Cost constrained use cases, particularly those with simpler tasks.\n\nFor more on small language models, see our Microsoft Source Blog.\n\nThanks to their smaller size, Phi-3 models can be used in compute-limited\ninference environments. Phi-3-mini, in particular, can be used on-device,\nespecially when further optimized with ONNX Runtime for cross-platform\navailability. The smaller size of Phi-3 models also makes fine-tuning or\ncustomization easier and more affordable. In addition, their lower\ncomputational needs make them a lower cost option with much better latency.\nThe longer context window enables taking in and reasoning over large text\ncontent\u2014documents, web pages, code, and more. Phi-3-mini demonstrates strong\nreasoning and logic capabilities, making it a good candidate for analytical\ntasks.\n\nCustomers are already building solutions with Phi-3. One example where Phi-3\nis already demonstrating value is in agriculture, where internet might not be\nreadily accessible. Powerful small models like Phi-3 along with Microsoft\ncopilot templates are available to farmers at the point of need and provide\nthe additional benefit of running at reduced cost, making AI technologies even\nmore accessible.\n\nITC, a leading business conglomerate based in India, is leveraging Phi-3 as\npart of their continued collaboration with Microsoft on the copilot for Krishi\nMitra, a farmer-facing app that reaches over a million farmers.\n\n> \u201cOur goal with the Krishi Mitra copilot is to improve efficiency while\n> maintaining the accuracy of a large language model. We are excited to\n> partner with Microsoft on using fine-tuned versions of Phi-3 to meet both\n> our goals\u2014efficiency and accuracy!\u201d\n>\n> Saif Naik, Head of Technology, ITCMAARS\n\nOriginating in Microsoft Research, Phi models have been broadly used, with\nPhi-2 downloaded over 2 million times. The Phi series of models have achieved\nremarkable performance with strategic data curation and innovative scaling.\nStarting with Phi-1, a model used for Python coding, to Phi-1.5, enhancing\nreasoning and understanding, and then to Phi-2, a 2.7 billion-parameter model\noutperforming those up to 25 times its size in language comprehension.^1 Each\niteration has leveraged high-quality training data and knowledge transfer\ntechniques to challenge conventional scaling laws.\n\n## Get started today\n\nTo experience Phi-3 for yourself, start with playing with the model on Azure\nAI Playground. You can also find the model on the Hugging Chat playground.\nStart building with and customizing Phi-3 for your scenarios using the Azure\nAI Studio. Join us to learn more about Phi-3 during a special live stream of\nthe AI Show.\n\n^1 Microsoft Research Blog, Phi-2: The surprising power of small language\nmodels, December 12, 2023.\n\n  * ## Explore\n\nLet us know what you think of Azure and what you would like to see in the\nfuture.\n\nProvide feedback\n\n  * Build your cloud computing and Azure skills with free courses by Microsoft Learn.\n\nExplore Azure learning\n\n## Related posts\n\n  * AI + Machine Learning, Azure AI, Azure AI Services, Azure AI Studio, Azure OpenAI Service, Best practices\n\n### AI study guide: The no-cost tools from Microsoft to jump start your\ngenerative AI journey chevron_right\n\n  * AI + Machine Learning, Azure AI, Azure VMware Solution, Events, Microsoft Copilot for Azure, Microsoft Defender for Cloud\n\n### Get ready for AI at the Migrate to Innovate digital event chevron_right\n\n  * AI + Machine Learning, Azure AI Speech, Azure AI Studio, Azure OpenAI Service, Azure SQL Database\n\n### What\u2019s new in Azure Data, AI, and Digital Applications: Helping you\nnavigate the fast pace of change chevron_right\n\n  * AI + Machine Learning, Announcements, Azure AI, Azure AI Search\n\n### Announcing updates to Azure AI Search to help organizations build and\nscale generative AI applications chevron_right\n\n## Additional Navigation\n\nGet the Azure mobile app\n\n### Explore Azure\n\n  * What is Azure?\n  * Get started\n  * Global infrastructure\n  * Datacenter regions\n  * Trust your cloud\n  * Customer enablement\n  * Customer stories\n\n### Products and pricing\n\n  * Products\n  * Pricing\n  * Free Azure services\n  * Flexible purchase options\n  * Cloud economics\n  * Optimize your costs\n\n### Solutions and support\n\n  * Solutions\n  * Resources for accelerating growth\n  * Solution architectures\n  * Support\n  * Azure demo and live Q&A\n\n### Partners\n\n  * Azure Marketplace\n  * Find a partner\n  * Join ISV Success\n\n### Resources\n\n  * Training and certifications\n  * Documentation\n  * Blog\n  * Developer resources\n  * Students\n  * Events and webinars\n  * Analyst reports, white papers, and e-books\n  * Videos\n\n### Cloud computing\n\n  * What is cloud computing?\n  * What is cloud migration?\n  * What is a hybrid cloud?\n  * What is AI?\n  * What is IaaS?\n  * What is SaaS?\n  * What is PaaS?\n  * What is DevOps?\n\nYour Privacy Choices\n\n  * Consumer Health Privacy\n  * Diversity and Inclusion\n  * Accessibility\n  * Privacy & Cookies\n  * Data Protection Notice\n  * Trademarks\n  * Terms of use\n  * Privacy Data Management\n  * Contact us\n  * Feedback\n  * Sitemap\n  * \u00a9 Microsoft 2024\n\nNotifications\n\n", "frontpage": true}
