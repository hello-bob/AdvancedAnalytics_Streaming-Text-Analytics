{"aid": "40237586", "title": "Show HN: Local GLaDOS", "url": "https://github.com/dnhkng/GlaDOS", "domain": "github.com/dnhkng", "votes": 4, "user": "dnhkng", "posted_at": "2024-05-02 15:48:23", "comments": 0, "source_title": "GitHub - dnhkng/GlaDOS: Personality Core", "source_text": "GitHub - dnhkng/GlaDOS: Personality Core\n\nSkip to content\n\n## Navigation Menu\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\ndnhkng / GlaDOS Public\n\n  * Notifications\n  * Fork 74\n  * Star 805\n\nPersonality Core\n\n### License\n\nMIT license\n\n805 stars 74 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# dnhkng/GlaDOS\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\ndnhkngUpdate glados.pyMay 2, 20248de67d0 \u00b7 May 2, 2024May 2, 2024\n\n## History\n\n28 Commits  \n  \n### glados\n\n|\n\n### glados\n\n| improved logging| Apr 30, 2024  \n  \n### models\n\n|\n\n### models\n\n| Update glados.onnx.json| Feb 28, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| GLaDOS live| Apr 28, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| New Models| Dec 11, 2023  \n  \n### README.md\n\n|\n\n### README.md\n\n| Merge pull request #12 from eltociear/patch-1| May 2, 2024  \n  \n### demo.ipynb\n\n|\n\n### demo.ipynb\n\n| New Models| Dec 11, 2023  \n  \n### glados.py\n\n|\n\n### glados.py\n\n| Update glados.py| May 2, 2024  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| Fix missing dependencies in requirements.txt| May 1, 2024  \n  \n## Repository files navigation\n\n# GLaDOS Personality Core\n\nThis is a project dedicated to building a real-life version of GLaDOS.\n\nThis is a hardware and software project that will create an aware,\ninteractive, and embodied GLaDOS.\n\nThis will entail:\n\n  * Train GLaDOS voice generator\n  * Generate a prompt that leads to a realistic \"Personality Core\"\n  * Generate a MemGPT medium- and long-term memory for GLaDOS\n  * Give GLaDOS vision via LLaVA\n  * Create 3D-printable parts\n  * Design the animatronics system\n\n## Software Architecture\n\nThe initial goals are to develop a low-latency platform, where GLaDOS can\nrespond to voice interactions within 600ms.\n\nTo do this, the system constantly records data to a circular buffer, waiting\nfor voice to be detected. When it's determined that the voice has stopped\n(including detection of normal pauses), it will be transcribed quickly. This\nis then passed to streaming local Large Language Model, where the streamed\ntext is broken by sentence, and passed to a text-to-speech system. This means\nfurther sentences can be generated while the current is playing, reducing\nlatency substantially.\n\n### Subgoals\n\n  * The other aim of the project is to minimize dependencies, so this can run on constrained hardware. That means no PyTorch or other large packages.\n  * As I want to fully understand the system, I have removed a large amount of redirection: which means extracting and rewriting code. i.e. as GLaDOS only speaks English, I have rewritten the wrapper around espeak and the entire Text-to-Speech subsystem is about 500 LOC and has only 3 dependencies: numpy, onnxruntime, and sounddevice.\n\n## Hardware System\n\nThis will be based on servo- and stepper-motors. 3D printable STL will be\nprovided to create GlaDOS's body, and she will be given a set of animations to\nexpress herself. The vision system will allow her to track and turn toward\npeople and things of interest.\n\n## Installation Instruction\n\nIf you want to install the TTS Engine on your machine, please follow the steps\nbelow. This has only been tested on Linux, but I think it will work on Windows\nwith small tweaks.\n\n  1. Install the espeak synthesizer according to the installation instructions for your operating system.\n\n  2. Install the required Python packages, e.g., by running pip install -r requirements.txt\n\n  3. For the LLM, install Llama.cpp, and compile it for your CPU or GPU. Edit the LLAMA_SERVER_PATH parameter in glados.py to match your installation path.\n\n  4. For voice recognition, install Whisper.cpp, and after compiling, run make libwhisper.so and then move the \"libwhisper.so\" file to the \"glados\" folder or add it to your path. For Windows, check out the discussion in my whisper pull request.\n\n  5. Download the models:\n\n    1. voice recognition model\n    2. Llama-3 8B or\n    3. Llama-3 70B\n\nand put them in the \"models\" directory.\n\n## Testing\n\nYou can test the systems by exploring the 'demo.ipynb'.\n\n## Star History\n\n## About\n\nPersonality Core\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\nActivity\n\n### Stars\n\n805 stars\n\n### Watchers\n\n27 watching\n\n### Forks\n\n74 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Contributors 4\n\n  * dnhkng David\n  * guangyusong\n  * lcdr\n  * eltociear Ikko Eltociear Ashimine\n\n## Languages\n\n  * Python 98.0%\n  * Jupyter Notebook 2.0%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
