{"aid": "40273311", "title": "Where the Wild Things Are: Second Order Risks of AI", "url": "https://www.philvenables.com/post/where-the-wild-things-are-second-order-risks-of-ai", "domain": "philvenables.com", "votes": 1, "user": "donalhunt", "posted_at": "2024-05-06 11:15:05", "comments": 0, "source_title": "Where the Wild Things Are: Second Order Risks of AI", "source_text": "Where the Wild Things Are: Second Order Risks of AI\n\ntop of page\n\n# RISK & CYBERSECURITY\n\n###### Thoughts from the Field\n\nSearch\n\n  * Phil Venables\n  *     * 3 hours ago\n    * 10 min read\n\n# Where the Wild Things Are: Second Order Risks of AI\n\nEvery major technological change is heralded with claims of significant, even\napocalyptic, risks. These almost never turn out to be immediately correct.\nWhat often turns out to be riskier are the 2nd order effects that are a result\nof what is done with the new technology.\n\nNo matter what, we do have to care about AI risks. Many past technological\nwarnings of disaster have been avoided precisely because we did care. But the\nbigger risks come with what comes after what comes next. This is inherently\nunpredictable but it doesn\u2019t mean we can\u2019t try to foresee this or at least\nlook for warning signs. To paraphrase the thesis from Collingridge\u2019s The\nSocial Control of Technology, when a technology is in its infancy and can be\ncontrolled we don\u2019t understand its consequences - and when we do it is so\nwidespread and entrenched that it is difficult to then control.\n\nClearly, this is all worth paying attention to, not so we are overly anxious\nabout AI but so we can manage the risk and reap the massive rewards in safe\nand responsible ways, and be ready to mitigate the inevitably surprising\nsecond order risks in appropriate ways.\n\n##### Lessons from History\n\nHistory has been punctuated with massive technological shifts. In each case,\nat their inception, predictions of disaster were made that did not come about,\nat least in the timeframes or at the scale predicted. Rather, it was the 2nd\norder effects that had the more significant consequences. Let\u2019s look at a few\nillustrative cases focusing on the second order risk consequences. To be\nclear, I\u2019m in no way diminishing the 10, 100, perhaps 1000X benefits that\noutweigh the negatives of each, but for the purpose of this exercise let\u2019s\njust look at those 2nd order risk effects:\n\n  * The Steam Engine. There were immediate warnings of perpetual explosions and deaths from its use in transport. Instead it led to the industrial revolution and all that came from that.\n\n  * The Car. There were significant concerns about the amount of dust created on unpaved roads. Instead it led to wider forms of pollution and the reshaping of cities.\n\n  * Computing and the Internet. Microelectronics, IT and then the Internet were going to take everyone\u2019s jobs. Instead it led us on a long path to incessant cybersecurity issues and a world in which (to quote Dan Geer) \u201cevery sociopath is your next door neighbor\u201d.\n\n  * The Smart Phone. Smart phones, and cell phones before them, were going to give everyone cancer. Instead the smartphone exponentially amplified the nascent social media platforms and birthed the associated challenges with those.\n\n  * Cryptocurrency. It was going to disrupt economies and eliminate fiat currency. Instead it gave us ransomware.\n\nLet\u2019s look at the Internet a bit more. In the early days of the World Wide Web\n(1990\u2019s) it was dismissed by many as a fad. Many businesses were brought on-\nline by IT staff with skunk-works efforts. At the beginning of the Web we\ntalked of the Information Superhighway and the idea of Internet TV (i.e.\nInternet through your TV rather than what actually happened where the Internet\nate the TV). For threats, the big concerns were spam, on-line crime, people\nbeing socially isolated, cyber-bullying, the digital divide, and the\neradication of jobs. Movies around the time (War Games, Terminator and such)\ndepicted various AI-driven apocalyptic scenarios.\n\nThis paranoia was healthy in that it catalyzed significant work to address\nthese risks. In the 1990\u2019s we developed the SSL protocol that led to today\u2019s\nprotocols that encrypt most Internet traffic which led to an explosion of\ne-commerce. We developed effective anti-spam technology. Jobs and\ninfrastructure were created. In some cases infrastructure was over-built\n(remember the dot-com collapse of 2001) but which laid the foundations of what\ncame next.\n\nBut we, inevitably, missed the 2nd order effects. The massive rise in\norganized crime was not exploiting the Internet itself but rather the weak\nidentity models of businesses naively digitizing existing commerce. Hacking by\ncriminals and nation states was exponentially boosted when Microsoft shoved\nTCP/IP into Windows 95, as did other vendors with their products, to have the\neffect that most computer systems that relied on isolation for security were\nnow connected to everything and everyone else. The standardized protocols and\nthe resultant economy of scale created the Internet-of-things and made\noperational technology a reality where not only all IT is connected but all\ninfrastructure is connected to everything else. This in turn has enabled\ncriminals and nations to use billions of insecure devices as \u201cbot\u201d armies to\ndrive denial of service attacks and provide domestic staging posts for nation\nstate cyber-operatives to hide in plain sight from US intelligence agencies\nconstrained to operate internationally.\n\nAmusingly, we were so worried about security getting too good that the US\nGovernment advocated hard to control cryptography with the Clipper chip and\nsimilar schemes without predicting the 2nd order opportunity of spying through\ninsecure end points now on-line because of the unconstrained proliferation of\nconnectivity.\n\nOur inability to clearly see second order effects isn\u2019t just on security, it\npervades all aspects of technology. Technology like SQL which democratized the\nworkforce\u2019s ability to make queries to connect data sources led to just-in-\ntime supply chains. There are more examples at wider scale (sourced from\nBenedict Evan\u2019s annual presentation):\n\nSo, here we are with Generative AI (we had less fears, for some reason, about\nprior generations of AI in the traditional application of machine learning)\nand the same situation is playing out. Everyone is concerned about many risks,\nsome valid and some not so much, and are working to mitigate them. Some risks\nare overblown and may always be so, and some risks are overblown for now but\nmay occur over the coming years or more. However, as with any prior\ntechnological change we need to also look harder for the 2nd order risks. I\ndon\u2019t think we can reliably predict these, by definition, but we can at least\nbe on the lookout for what comes after what comes next.\n\n##### Example Second Order Risks\n\nThe rest of this post is focused on possible second order risks from a digital\n/ information technology perspective. But, you can also contemplate many other\nexamples from biology, chemistry, and all the other sciences.\n\nOne way of framing these types of analyses is to imagine a world where the\npositive is true, and ask \u201cWhat risks are in such a world?\u201d Then imagine a\nworld where the negative is true, and ask, again, \u201cWhat risks are in such a\nworld?\u201d For example, let\u2019s assume generative AI is truly transformative for\nsynthetic biology and pharmaceutical development. An extreme positive outcome\nis that the treatment of disease is transformed, lifespans are extended,\ntreatments are highly customized for each individual. In that world, what\nrisks do we have? It could be societal pressures to fund healthcare during the\ninitial transition period where treatments are expensive, social security\npressures increase due to longer lifespans, diseases that are deadly might not\nbe cured but simply become chronic with more people living but impaired, all\nthe way through to complications of spotting unique side effects from the\nunique treatment of individuals. What steps do we need to take now to be at\nleast directionally ready for that reality? On the negative side, imagine a\nworld of biological terror with unique pathogens being constructed regularly.\nThat world will have closed borders for people and restricted trade, what\nsteps do we need to take to position for that version of reality?\n\n##### 1.Human Misunderstanding Mediated by AI (\u201cDid we really agree to that?\u201d)\n\nImagine a situation where one person or organization is using AI to generate\ncontent or transactions which are then, in an uncoordinated way, being\nconsumed by another person or organization intermediated by their AI. What are\nthe collective consequences of this (especially at scale)? For example, look\nat legal contracts and their intent. Imagine you have a generative AI\nassistant that helps you write legal contracts and that you send it to a\nperson who has an AI assistant that is helping them parse and understand legal\ncontracts that are sent to them.\n\nThere are some questions to ask here:\n\n  * Does A = B? Does the encoding of the intent match the consequent decoding.\n\n  * Does C = A and/or B? Does the actual contract when independently parsed match what A intended and B understood.\n\n  * Will C be the actual contract? Surely yes, and people will sign that assuming they actually read it but probably didn\u2019t.\n\n  * Will C be reviewed and how? In that case how will C be reviewed and checked against A and B.\n\nNow imagine this for RFPs or any other complex document that people hate\nwriting and also equally dislike reading. What will be the evolutionary\npressure on the way C is automatically generated in the face of \u201cadversarial\u201d\ngeneration between A and B? Will it still be English (or other common\nlanguage) or will there be emergent encodings?\n\nLet's do the same for other inter-personal electronic communications, say\ne-mail. We\u2019re going to soon end up in more situations where you will have a\ngenerative AI agent write your communications for you. At the other end, the\nperson you are sending it to will have an agent to summarize (and perhaps even\nreply) to those communications. There will be pressure to write and optimize\nemail to get the right message through the other person\u2019s agent to reach the\nactual person.\n\nAgain, there will be evolutionary pressure which will evolve the nature of\nintermediate communication. Now we have similar questions:\n\n  * Does A = B? Does the sender's wishes match the receiver's synthesis?\n\n  * Does C = A and/or B? Or will the actual content even be understandable?\n\nWe could develop similar situations for how to think about parties to a video\nconference doing independent transcription, language translation and many\nother possibilities. For example, what happens when we all agree to an AI\u2019s\ntranscription of a meeting that most of us didn\u2019t attend and what happens when\nthe transcription or synthesis provided by our virtual attendee (who we sent\nin our place) doesn\u2019t agree with the moderator\u2019s AI\u2019s transcription of events,\nwill we need independent AI validators?\n\n##### 2\\. Complex Agent Interactions (\u201cWhat are all these agents actually\ndoing?\u201d)\n\nIt is inevitable in the medium term that more people and organizations will\nmediate activities through AI agents (or assistants). Our personal AI agents\nwill interact with other people\u2019s and organization\u2019s agents to coordinate\nevents, mediate transactions, book vacations, evaluate and select products to\npurchase, coordinate medical treatments and monitor outcomes, and much much\nmore.\n\nThere might be a small number of dominant personal agents due to network\neffects, but there will still be a range of \u201cmodules\u201d [think apps] that people\nwill buy and plug into their agents for specific tasks. Businesses will\nimplement a plethora of different agents to interact with people and to\nconduct business to business transactions. So, this world will be full of\nagents with different underlying models, trained in different ways, and\nconfigured with different safety or reliability settings.\n\nWe need to work to understand the emergent properties that might occur in such\na world of trillions of independently interacting agents with powerful\nintelligence all primed to achieve competing goals. Evolutionary pressure\nmight cause agents to change in unpredictable ways. Businesses and governments\nneed to be better equipped to monitor system-wide effects.\n\nSome of the second order risks that might come from this could be:\n\n  * Concentration risk / funneling. Optimal paths / services will be discovered quickly leading to overwhelming traffic surges, massive gyrations of supply-chains into and out of certain products or services. Financial flash crashes from conventional algorithms will look tame compared to this world of agents of people and businesses making purchases on our behalf.\n\n  * Manipulation. Competitive and adversarial pressures will seek to manipulate agents to achieve desired outcomes through small adjustments in agent behavior with outsize network effects or by adversarial AI techniques (e.g. model poisoning).\n\n  * Reproduction. Agents will have the ability to reproduce and replicate, and will introduce modifications to themselves under competitive (evolutionary) pressure. The emergent properties from this could be the path to a more distributed form of AGI (think ant colonies vs. ants).\n\n  * Conflict. Indeed, such a diffuse agent based world will make conflict look more like my \u201cant hill\u201d vs. your \u201cant hill\u201d.\n\n  * Race conditions. Inadvertent creation of critical race conditions in sensor driven, interdependent systems.\n\n##### 3\\. Deskilling (\u201cMost of us can\u2019t smelt iron, that might be ok....or\nnot.\u201d)\n\nAs we become ever more dependent on technology driven by the higher\ncapabilities of AI then will we de-skill people (or more correctly, I guess,\npeople will up-skill away from prior skills). Will it be possible to maintain\nthe societal discipline to keep sufficient slack in the system to sustain\nproductivity if people\u2019s AI agents fail or to have people preserve skills\ngiven up to AI. It\u2019s one thing for Navies to retain the capability for manual\nnavigation by sextant, it\u2019s another to make skills back-up pervasive to some\nlevel of societal resilience.\n\n##### 4\\. Everything Has an API (\u201cYou think customer service is bad now.\u201d)\n\nIn a world of person to person, person to business and business to business\nagent interactions, every single thing will have an API (Application\nProgramming Interface, or an Agent Programming Interface). When your agent\nfails to mediate a task across a complex web of businesses agents/APIs and you\ncall one of those businesses they will have little idea of their role in the\ncomplex web of your agent\u2019s goals. Or, more likely, their \u201ccomplaints\u201d API\nwill struggle to deal with your query.\n\n##### 5\\. Augmented Reality (\u201cYou mean manipulated and filtered reality?\u201d)\n\nAre we underestimating the impact that AR will have? Technologies are emerging\nthat are currently in the oddball stage that will become pervasive in the\nmedium term as visual overlays (glasses, visors, contact lenses). Now the\nsecond order impact here is what happens when your personal AI agent(s) are\nmediated through AR. What happens when an AI agent overlays (or filters) out\nthings it thinks you don\u2019t want to see? What are the societal knock-on effects\nof this? What are the criminal and adversarial opportunities here?\n\n##### 6\\. AI Replacement of Humans in Dual Control Situations (\u201cOpen the pod\nbay doors HAL.\u201d)\n\nMany critical controls in society are subject to human dual control /\nseparation of duties. There is insufficient research on the consequences of\nreplacing Human 1 + Human 2 control with AI + Human, Human + AI or AI + AI for\nthese scenarios. Such scenarios from medical checklist conformance, weapons\nrelease, financial transaction approval, flight safety and many more have\nobvious potential risks.\n\n##### How to Start to Look for 2nd Order Effects\n\nIn my experience the best way to even try to get a handle on 2nd order effects\nis to look through several lenses:\n\n  1. What does the technology want? In other words, what are the economics, incentives, and opportunities that will drive the technology.\n\n  2. What do the humans want? In other words, what do people (or businesses) want from it? From connectedness, growth to safety.\n\n  3. What does a world look like if all the positives come about? Then what are the risks in that world?\n\n  4. What does a world look like if all the negatives come about? Then what are the risks in that world?\n\nScenario planning is a useful technique to do this exercise.\n\nBottom line: We should be appropriately cautious about AI but not so that we\nforgo the truly massive upside that the bold but responsible use of this\ntechnology will give us in a range of fields. It\u2019s healthy to have a societal\nlevel debate about AI risks as that is what will drive the mitigation of those\nrisks so we can enjoy the benefits of this remarkable capability. But, in\ndoing this we need to be much more focused on the real risks that come, and\nhave come in prior technological shifts, from the 2nd order effects. Ask, in a\nsociety reshaped by AI, what does that world look like? And, in that world,\nwhat risks will we face that we don\u2019t face today? Then, what do we need to do\nto be prepared to mitigate those effects? If we\u2019re not careful, that will be\nwhere the wild things truly are.\n\n  * Risk\n  * \u2022\n  * Technology\n\n318 views0 comments\n\n## Recent Posts\n\nSee All\n\nSecurity and Ten Laws of Technology\n\nThere are many well known, so called, laws of technology. Moore\u2019s law being\nparticularly emblematic. Let\u2019s look at some of them and see what the security\nimplications have been for each and what might\n\n3,398\n\nDevOps and Security\n\nEach year, DevOps Research and Assessment (DORA) within Google Cloud publishes\nthe excellent State of DevOps report. The 2023 report published in Q4 was as\ngood as ever and in particular documented so\n\n1,900\n\nThe 80 / 20 Principle\n\nEver since I first became familiar with the 80/20 principle, and other\ncircumstances marked by Pareto distributions, I began to see examples of it\neverywhere. Naturally, I\u2019m particularly biased to obs\n\n2,270\n\n###### Subscribe for updates.\n\n\u00a9 2020 Philip Venables.\n\nbottom of page\n\n", "frontpage": false}
