{"aid": "40105465", "title": "Where the Bitter Lesson Ends", "url": "https://geohot.github.io//blog/jekyll/update/2024/03/27/where-the-bitter-lesson-ends.html", "domain": "geohot.github.io", "votes": 1, "user": "oli5679", "posted_at": "2024-04-21 13:05:50", "comments": 0, "source_title": "Where the Bitter Lesson ends", "source_text": "Where the Bitter Lesson ends | the singularity is nearer\n\nthe singularity is nearer\n\n# Where the Bitter Lesson ends\n\nMar 27, 2024\n\n> Humanity only has one engineering project, building better engineers than\n> humans. After that, the thing we built can do the engineering.\n\nClips have been making the rounds on Twitter from my second Lex about the\n\u201cbishop guy\u201d in a chess engine, or a \u201ccone guy\u201d in a self driving car. These\nengineering ideas look ever more ridiculous.\n\nSince the beginning of comma, I wanted to make a machine that could drive cars\nlike a human. Obviously there\u2019s no reference to traffic cones inside human\nDNA, they learn about them from data. So there shouldn\u2019t be any reference to\ntraffic cones in your codebase.\n\nRich Sutton stated this most iconically in 2019.\n\n> One thing that should be learned from the bitter lesson is the great power\n> of general purpose methods, of methods that continue to scale with increased\n> computation even as the available computation becomes very great. The two\n> methods that seem to scale arbitrarily in this way are search and learning.\n\nBut then where does it stop? Why draw the line at DNA? Evolution is clearly a\nsearch and optimization process. Why is hard coding stuff that\u2019s in the human\nDNA okay, why not evolve a driving agent? Why not evolve life?\n\nThe concept of a Seed AI is very captivating. Build a minimum viable self\nimproving AI, and allow it to bootstrap its way to human and beyond. This is\nclearly possible, evolution did it (though with an ungodly amount of compute).\n\nBut remember, our goal is just to build something superhuman, not go beyond.\nUnlike a self driving car, if you were building a train driving agent,\nlearning like a human is probably not the right choice. It\u2019s simple enough to\ncode and test. You should have a train_signal.py\n\nImagine you are tasked with building a radio. Which of these approaches would\nyou take?\n\n  1. Understanding where radios come from and replicating that. Setting up the same initial conditions of radio, an eccentric Italian man born in 1874, an attic in Pontecchio, an estate owned by the man\u2019s father in Bologna to expand to, etc...\n\n  2. Taking apart a radio. Reverse engineering and documenting each piece. Building things that behave like each piece. Testing them in the original radio. Building a clone.\n\nI imagine the second path would be more fruitful and faster. We have a working\nexample, we just need to clone it. A much easier task than creating it from\nscratch.\n\nI say the bitter lesson stops at human DNA. While we have to avoid cargo\nculting, I think that many of the pieces of the human brain are starting to be\nbuildable with today\u2019s technology. The brain isn\u2019t some hyperelegant machine\nthat captures the essence of learning, it\u2019s a bunch of hacks, and hacks that\nwe can replicate.\n\nHaving a cone guy in your self driving car company is still ridiculous,\nbecause the only working implementation of a driving agent doesn\u2019t have a cone\nguy, it learns cones from data. But the only working implementation of\nengineers do have a neocortex, a hippocampus, a basal ganglia, an amygdala,\nand a thalamus.\n\nI would be fine with our human agent software having directories for each one\nof those pieces. Transformers as a neocortex, some way better RAG as a\nhippocampus, actually working TD-learning as a basal ganglia, an amygdala to\nprevent the robot destroying itself, and a thalamus to coordinate the system\nand search.\n\nWe are just trying to build knock-off humans, not solve life. They can do\nthat.\n\n## the singularity is nearer\n\n  * the singularity is nearer\n  * geohot@gmail.com\n\n  * geohot\n  * realgeorgehotz\n\nA home for poorly researched ideas that I find myself repeating a lot anyway\n\n", "frontpage": false}
