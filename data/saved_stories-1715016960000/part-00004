{"aid": "40272973", "title": "Rice's Theorem and Software Failures", "url": "https://blog.relyabilit.ie/rices-theorem-and-software-failures/", "domain": "relyabilit.ie", "votes": 2, "user": "kiyanwang", "posted_at": "2024-05-06 10:10:05", "comments": 0, "source_title": "Rice's Theorem and Software Failures", "source_text": "Rice's Theorem and Software Failures\n\nMenu\n\nArticle incidents\n\n# Rice's Theorem and Software Failures\n\n#### Niall Murphy\n\n10 Apr 2024 \u2022 4 min read\n\nMental Models of Software\n\nMy corner of the industry spends a lot of time worrying about effective ways\nto understand software behaviour, especially in the context of distributed\nsystems. One important sociological disjunction we see when we try to improve\nour understanding is the disjunction between - I put it loosely - management\nand workers (in particular, incident responders) and what they see as the\nunderlying basis for software failure.\n\nAgain, this is approximate, but let me characterise two views of the world.\n\nIn view A, software runs stably unless acted on by an external force, and that\nforce is overwhelmingly human-originated. Therefore, when something goes wrong\nwith the software, it\u2019s overwhelmingly likely to be a human who did something\nwrong. Restoration of service is a task of reverting the human-originated\nchange, and prevention of error is closely tied with preventing humans doing\n\u201cbad things\u201d. (There are many possible critiques of this view; I merely relate\nthe core proposition.)\n\nIn view B, software is capricious and unstable-by-default, the environment is\nconstantly changing, and if there is a failure, it can be the result of the\ncombination of a collection of side-effects from a thousand different actions\nthat are causally very distant from each other. It is therefore not useful to\nsay a human is at fault. (Critiques of this view are also available: for\nexample, the notion that for deterministic software, at some root of some\nchain must be a human action.)\n\nIt is important to say that these views are not pure logical opposites, and\ncould both plausibly be claimed to be wrong, but are distinct models about the\noperation of software that drive a view on how to attribute sources of failure\nin software (and how to prevent same, restore service, etc). They are roughly\nanalogous to Dekker's Old View versus New View on human error.\n\nFor completeness, we would stereotypically say that management holds view A\nand the workers hold view B.\n\nRice\u2019s Theorem\n\nEnter computational theory.\n\nRice\u2019s Theorem is related to the Halting Problem, which we won\u2019t itself\nspecifically discuss here, except to say that it is hugely important and\ngenerally well covered in undergraduate Computer Science.\n\nRice\u2019s Theorem, a generalization of the Halting Problem, states that all non-\ntrivial semantic properties of programs are undecidable.\n\nNon-trivial in this case has a narrow, technical meaning: for something to be\ntrivial (note the logical inversion) it means it is true for all programs or\nfor no programs. Therefore, for something to be non-trivial, it means it is\ntrue for some subset of programs, and not for the complement set.\n\nSemantic means that it is about a program\u2019s meaning or behaviour, rather than\nits syntax. For example, the property halts for all even inputs is a semantic\nproperty, but program text contains\n\nwhile (x != true) { continue; }\n\nis a syntactic property.\n\nUndecidable has a number of definitions available, but for the purposes of\nthis article we would say \u201ccannot be correctly evaluated to be either true or\nfalse by a program\u201d. We note here that undecidability doesn\u2019t mean that the\nproposition is neither true nor false - just that it cannot be established to\nbe so by the operation of some definite algorithm.\n\nThere are an uncountably infinite number of things which are undecidable. Some\nfamous examples amongst mathematicians would be the continuum hypothesis and\nthe axiom of choice. But it turns out that almost everything useful that you\u2019d\nwant to know about software is also undecidable. Wikipedia outlines the\nfollowing propositions (with quoted preamble):\n\n> Given a program P which takes a natural number n and returns a natural\n> number P(n), the following questions are undecidable:\n\n  * Does P terminate on a given n?\n  * Does P terminate on 0?\n  * Does P terminate on all n?\n  * Does P terminate and return 0 on every input?\n  * Does P terminate and return 0 on some input?\n  * Does P terminate and return the same value for all inputs?\n  * Is P equivalent to a given program Q?\n\nRelevance to software failures\n\nIt seems clear that we can extend this fairly naturally to cover the software\nwe work with today, and therefore the relevance to software failures (and\ntherefore incidents) is direct. To wit, we cannot know for sure whether or not\nsoftware is going to be incident-free. It might well be, but we can\u2019t ever\nprove it.\n\n(The analogy I like, though I know of no theoretical basis for it, is that\nsufficiently complex systems appear to behave more like a \u201cgenerative grammar\u201d\nfor incidents, producing novel problems from combinations of situations in the\nabsolutely vast potential state space of software.)\n\nOf course, undecidability results are satisfyingly broad from a rhetorical\npoint of view - they state that literally no program/algorithm can do X - but\nunsatisfyingly shallow from a behavioural description point of view.\n\nYou can\u2019t prove a program halts, sure, but you can make a lot of progress in\nreasoning about program behaviour outside of halting. (Fascinatingly, Rice\u2019s\ntheorem suggests that the real hope here is in syntactical models for this,\nrather than semantic ones.)\n\nRelevance to mental models\n\nBut it\u2019s precisely that combination of broad and shallow which is useful here.\n\nThe argument uses a similar inversion to the Halting problem itself.\n\nLet us suppose that there was a way to prove that a program would work without\nerrors. Then View A of software would be correct, since by definition, you\nhave proved that the software works for some input X, so if a software failure\nresults, it must be for some reason outside of the combination of code plus\ninput, which is (in View A terms) human action resulting in some change such\nthat the previous proof is no longer valid.\n\nBut there isn\u2019t a way to prove a program will work without errors. Therefore\nView A can\u2019t be correct. Whether or not View B is the correct one instead is\nunclear. But if View A can\u2019t be adopted, View B is one potential substitute.\n\nConclusion\n\nWe need to help holders of view A understand that it is not true, and that\ntheir model that the software is inherently stable is incorrect. To the extent\nit\u2019s useful, it is therefore possible, and true, to say to leaders \u201csoftware\ncannot be shown to be stable, and so it\u2019s safer to assume it isn\u2019t\u201d.\n\nShare\n\nTopic incidents models\n\n## Graceful Degradation and SLOs\n\nWhat is graceful degradation? Graceful degradation is the idea that, when\nyou...\n\n09 Apr 2024\n\n#### Topics\n\nsre-identity: 4 models: 4 organizational: 3 SLOs: 3 planning: 2 future: 2\nincidents: 2 gatekeeping: 1 horizontal: 1 is-not: 1 legibility: 1 okrs: 1\nsystems-thinking: 1 google: 1\n\n", "frontpage": false}
