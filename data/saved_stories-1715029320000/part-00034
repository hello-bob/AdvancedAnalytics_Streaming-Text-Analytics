{"aid": "40274690", "title": "On building with AI", "url": "https://www.eraser.io/decision-node/on-building-with-ai", "domain": "eraser.io", "votes": 5, "user": "yoelhacks", "posted_at": "2024-05-06 13:52:28", "comments": 0, "source_title": "On Building with AI - Decision Node", "source_text": "On Building with AI - Decision Node\n\n\ud83c\udf89 Introducing Eraser AI\n\nThe first copilot for technical design\n\nUpvote on ProductHunt\n\nLearn more\n\n  * Use cases\n\n  * Resources\n\n  * About\n\n  * DiagramGPT\n  * Pricing\n\nLog in\n\nTry Eraser\n\nSign in\n\nTry Eraser\n\n  * Use Cases\n\n  * Resources\n\n  * About\n\n  * Pricing\n\n  * Use cases\n\n  * Resources\n\n  * About\n\n  * DiagramGPT\n  * Pricing\n\nLog in\n\nTry Eraser\n\nSign in\n\nTry Eraser\n\n  * Use Cases\n\n  * Resources\n\n  * About\n\n  * Pricing\n\n# DECISION NODE\n\nMay 6, 2024\n\nBack to index\n\nSubscribe\n\nOpen in Eraser\n\nMay 6, 2024\n\n## On Building with AI\n\nYoel Tadmor\n\n,\u1160\n\nHead of Engineering @ Eraser\n\n### Subscribe for Updates\n\nExploring forks in the road of software design with a weekly newsletter.\n\nSuccessfully Subscribed!\n\nOops! Something went wrong while submitting the form.\n\nIntroduction\n\nAI strategy: What to build\n\nHow to ship\n\nHow it works\n\nTL;DR\n\n## Introduction\n\nIn a few short years, AI has taken the world of software by storm. Every new\nmodel features improved intelligence, better performance, and new, seemingly\nmagical, capabilities. For app builders, it has evoked a mix of kid in a candy\nshop giddiness and keeping up with the Joneses anxiety.\n\nAt Eraser, we started our journey with AI a year ago, building DiagramGPT, and\neventually incorporating multiple AI features into our core app. Today, we\u2019ll\nlook at several decisions we made along the way, addressing some in a more\nphilosophical or strategic manner, and some more tactically:\n\n  * How we decided what to build (and, equally, what not to)\n  * The risks of adding AI to existing features and how we chose to mitigate them\n  * How we approach quality\n  * How our AI diagramming and outlining work\n\n### Who we are\n\nTo provide color and context, a brief introduction is needed:\n\nEraser is a docs and diagrams tool for engineering teams. Our conviction: most\nof us want to get better at making decisions collaboratively and documenting\nour work, but don't because:\n\n  * Switching from coding to writing or diagramming feels like going from flow and creativity to anxiously staring at a blank screen on an unfamiliar tool.\n  * Coding provides near-instant feedback, often subject only to compilation time. Writing can require working alone for days with no help or sense of whether we're on the right track.\n  * Even when we do our chores, the final product often isn't something we're as proud of as our \"real work\".\n  * Because we use a mish-mash of tools and only sporadically document things, it's never clear what's where, what's accurate, and what's relevant.\n\nWe've made a lot of progress solving these problems, and in due time, we aim\nto solve them all.\n\n## AI strategy: What to build\n\nTo answer this question, let's start with a simple model of AI features:\n\nOpen in Eraser\n\nFocusing on any of those might allow us to build a uniquely valuable and\nmagical feature:\n\n  * Inputs: using existing form-factors, data, or assets, we can can create inputs that would impossible (or impractical) to wrangle on one's own.\n\n    * Example: A slack-like chat app could allow users to summarize an entire thread or the last week's worth of posts in a particular channel.\n  * Model interaction: using existing data, train or tune a superior model, or leverage expertise and experimentation to engineer optimized prompts.\n\n    * Example: A customer-support chat app can fine tune a model on existing chats\n  * Outputs: taking generally available inputs, we can ask AI to produce outputs that are uniquely valuable within our application.\n\n    * Example: A canvas app can produce interesting visual outputs\n\nIdeally, we would combine all three!\n\nBecause AI models are so powerful, it's easy to feel drawn in many directions.\nAs a small team, we found value in articulating what we didn't want to build\n(for now, at least):\n\n  * Features that would be very impressive when they worked, but would rarely do so.\n  * Features that would overreach and do too much, taking more time and effort to sort through than would otherwise be saved.\n  * Many small features that provided widely available functionality (e.g. \"change tone\", \"turn into bullets\")\n\n### Our choice: AI diagramming\n\nThrough that lens focusing on novel outputs was the clear choice for us. We\nwanted something that would work well out of the box, even for new teams that\nweren't already using Eraser as a system of record. We had already spent a lot\nof time on our diagram-as-code feature, which converts our in-house DSL into\nbeautiful rendered diagrams. Using an AI to generate our DSL checked many\nboxes:\n\n  * Proven value: Diagram-as-code was already one of our most popular and differentiating features. We had conviction that time spent improving the underlying form factor was time well spent, even if the AI feature ended up going nowhere.\n  * GPT friendly: Many a useful diagram can be described in a modest amount of natural language. SQL schemas, code snippets and infrastructure configuration, while arcane to many, are lexical artifacts that GPTs are optimized to understand.\n  * Philosophical alignment: When you're at a whiteboard, one thing you don't have to do is think about how to draw a square. We want Eraser to embody that - to let you focus on the ideas being communicated, and not the mechanics of drawing. Like a well-crafted abstraction, we want to hide the tedious bits while giving you full reign over what's meaningful. It's why we built diagram-as-code. Building AI into that felt like a natural extension.\n  * A touch of magic: Dropping a few sentences or chunks of SQL into a textbox and seeing a beautiful diagram come out still feels wondrous.\n\n## How to ship\n\nOpen in Eraser\n\nOur goal in the first phase was to spend 1-2 days to prove out the AI\ndiagramming use case. We:\n\n  * Used OpenAI's playground\n  * Tried 10-20 examples that were designed to be non-trivial but straight forward\n  * Did minimal prompt engineering\n\nThe results were better than we had even anticipated. Excited to build, we\nfaced down our next decision: to modify our existing feature or build a new\nexperience.\n\nOpen in Eraser\n\nBuilding AI into our existing app had some attractive upside:\n\n  * Immediate benefit: If it worked well, our app users could start running with it on day one.\n  * Head start on in-app iteration: We knew the eventual goal was a single holistic experience. Starting inside of the app might help us iterate towards that.\n  * Single deployment: For a small team, it can be a major distraction trying to build, deploy, and support a truly separate app.\n  * Code sharing: Relatedly, re-packaging and re-using our complex diagram-as-code parsing and rendering pipeline would be a substantial project on its own.\n\nWe also identified several risks:\n\n  * First impressions: Hallucinations, inconsistent quality, or plain old bugs might cast a bad light on diagram-as-code as a whole. The more separation, the easier it is to truly treat as a beta.\n  * Noise and complexity: Building a UI to accommodate both AI and our syntax editor would necessarily require compromising on simplicity. If the AI didn't work well, this would just end up making a good feature worse.\n  * Local maxima: The AI might work just well enough to discourage people from using and learning the syntax editor, even when it would be easier and faster.\n\nUltimately, we chose a middle ground - we built a sidecar experience hosted on\nour website that still leveraged our existing code and CI/CD pipeline:\n\nOpen in Eraser\n\nThis isn't perfect - we pay a price on load times and it isn't ideal for SEO\npurposes. But it let us move really fast (the whole site took only a couple\nweeks to stand up). It also gave us a long time to talk to users and look at\nanalytics to inform our eventual approach to AI diagramming inside of Eraser.\n\n## How it works\n\n### Functional Overview\n\nOur AI flows has three phases and a simple architecture:\n\nOpen in EraserOpen in Eraser\n\nThe process starts with some user input - some combination of text and images.\n\nThe initial analysis has two goals:\n\n  1. Classify the input - this can determine which follow-up prompts to feed to the AI.\n  2. Create a list of assumptions and questions - these can be fed back to the user to seek clarifications.\n\nThe results of this phase, combined with the initial input, are then fed into\nthe generation prompt. The goal of this phase is to generate structured\noutput.\n\nThis output is then processed and fed into the UI for rendering.\n\n### Ensuring Quality\n\nHistorically, building quality software has fundamentally boiled down to two\nthings:\n\n  1. Having a comprehensive understanding of possible inputs and states and how the program should act in each case.\n  2. Implement testing procedures (unit tests, E2E tools, regular manual testing, etc) to ensure the program works to spec and doesn't regress as new features are added.\n\nThis section will focus on #1 (#2 is interesting, and we are watching the\ndevelopment of tools and best practices in that space).\n\nAI-based features are very often built around open-ended user inputs, and\nresults can be unpredictable. There are no finite testing cases you can plan\naround, and even for archetypical examples, it isn't clear what \"right\" or\n\"wrong\" behavior is.\n\nOur approach to quality has been the following, in a somewhat particular\norder:\n\n  * Do what we can on the model prompting side to maximize result quality. This has several aspects:\n\n    1. Increase the likelihood of strong results from meaningful inputs.\n    2. Guide the AI away from producing nonsense results when faced with mediocre inputs.\n    3. Experiment enough to detect bad habits and try to guide the AI away from them.\n  * Guide the user to provide meaningful inputs and allow iteration. This can be done with\n  * Define the various failure modes and provide clear feedback when they are reached.\n  * Allow rollbacks when AI edits existing work.\n\n### Notes on model selection\n\nThe easiest way to improve the quality of output is to use a best-in-class\nmodel (GPT4-turbo, Claude Opus, etc). Thankfully, creating diagrams and\nstarting documents have several facets in common that allow us to use these\nmodels:\n\n  * Low frequency: One or two successful generations per day is sufficient for the feature to have impact.\n  * High value: If the feature works well, it can replace an hour or more of work.\n  * Low latency sensitivity: While faster is always better, a diagram doesn't need to be drawn within a certain time frame to be useful.\n\nConsequently, we can justify using these best in class models. For other\nfeatures, such as as-you-type suggestions, form auto-fills, or smaller edits,\nthat might not be the case.\n\nWith that said, there is an important nuance. Recall that a single diagram\ngeneration might required several passes with the model (as is true of many\ninteresting AI applications). While the primary generation phase absolutely\nbenefits from a more powerful models, some of the analysis can be performed\nreasonably with lower-quality models such as GPT3.5. At a high level, that\nprocess works something like:\n\nOpen in Eraser\n\nThis continues to be an area of experimentation for us, but we've found a few\nuseful heuristics and techniques for working with a weaker model:\n\n  * Fixed-option classification: While errors and hallucinations are still possible, they are far less likely if the output is limited in scope.\n  * Provide opt out: As with people, if simply provided with several options, an AI can feel pressured to pick one. We've found it helps to offer a \"I don't know\" type of option, and explicitly asking it to only pick an option if confidence is very high. This can combine with a general purpose prompt.\n  * User overrides: As with other quality aspects, it can make more sense to use lower-quality models on aspects of the process that the user can override by specifying the result or providing some specific input.\n\nAn interesting note here is that adding an analysis phase can actually end up\nsaving both time and token cost if it is done with a cheaper model if it\nallows you to use a smaller, more focused, prompt.\n\n### Notes on streaming\n\nIn our view, streaming results from the AI helps make them feel more natural -\nlike a colleague rather a black box. It's part of what made ChatGPT so\nsuccessful, and we wanted to incorporate it as much as possible.\n\nBut streaming also comes with its own set of challenges. While models have\ngotten better at returning structured JSON when requested, we've found that\nasking for other formats can be easier than trying handle partial JSON\nresponses.\n\n### The devil is in the details\n\nWhile Eraser's DSL was created to be as simple as possible, we still offer a\nlot of optional or advanced functionality, including:\n\n  * Icons\n  * Colors\n  * Different types of connections\n  * Connection labels\n\nEach of these adds value when done well, but each also requires a certain\namount of space within the prompt. Much of our iteration on the prompt\nengineering side went into experimenting with these details and seeing which\nones the AI could consistently get right.\n\nAt the same time, each detail does come at a cost - the more that goes into a\nprompt, the more likely it is to confuse the AI and miss some of the larger\npicture.\n\n## TL;DR\n\n### Where to start\n\nFirst things first - it's important to have a good framework for prioritizing\nwhich features to work. One downside of AI's multi-modality is that it can do\nso much - but building a good feature requires a lot of focus and attention to\ndetail.\n\n### How to ship\n\nFeeling ambitious? It can be difficult to manage the risk of building a moon-\nshot feature into your primary flow. Consider all options here - we ended up\nbuilding a new landing page for our initial deployment.\n\n### Thinking in conversations\n\nTo build an experience that offers unique value, it's often important to\ncreate specialized prompts and structured inputs. Consider a multi-phase\nprocess that includes initial AI-powered analysis and classification.\n\n### Getting quality results\n\nWe use state-of-the-art models by default, because our approach is to build\nlow-frequency, high-value features. Even so, there's room for faster and\ncheaper models to do some of the up-front analysis. We're still experimenting\nwith approaches here, more to come!\n\nBeyond the model and prompt engineering, crafting a UX that guides users to\nprovide high-quality inputs is essential. We've combined a few techniques\nhere:\n\n  * Examples that show off archetypical use cases\n  * Structured forms\n  * Input length meters\n\n### A bevy of states\n\nWith AI, best-case scenarios feel electric. But thinking through the entire\nspectrum of results - from \"I can't diagram a rhinoceros\" to \"you just asked\nme to generate an essay out of two words\" to \"I'm not sure I understand\" - is\nwhat separates great from so-so.\n\n### Subscribe for Updates\n\nExploring forks in the road of software design with a weekly newsletter.\n\nThank you! Your submission has been received!\n\nOops! Something went wrong while submitting the form.\n\nDocuments & diagrams for engineering teams\n\n\u00a9 2023 Eraser Labs, Inc.\n\nUse Cases\n\nArchitecture DiagramsDesign DocsDocumentationBrainstormingWireframesWhiteboard\nInterview\n\nProducts\n\nEraser AIGithub integrationDiagram-as-codeAPI \u2192FiguresDark mode\n\nResources\n\nEraser ExamplesDecision NodeDiagramGPTIntegrationsDocs \u2192DesignDocs.dev \u2192\n\nAbout\n\nPricingTeamTeamChangelogSlack Community \u2192Careers \u2192Privacy PolicyTerms\n\n\u00a9 2024 Eraser Labs, Inc.\n\n", "frontpage": false}
