{"aid": "40051130", "title": "Show HN: Harnessing LLMs for automated UI testing", "url": "https://github.com/thetaris/testup-ai-driver", "domain": "github.com/thetaris", "votes": 7, "user": "dadim", "posted_at": "2024-04-16 12:31:06", "comments": 0, "source_title": "GitHub - thetaris/testup-ai-driver", "source_text": "GitHub - thetaris/testup-ai-driver\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nthetaris / testup-ai-driver Public\n\n  * Notifications\n  * Fork 0\n  * Star 2\n\n### License\n\nMIT license\n\n2 stars 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# thetaris/testup-ai-driver\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nAmer QarabsaMerged in feat/fine_tune (pull request #11)d0bb565 \u00b7\n\n## History\n\n123 Commits  \n  \n### examples\n\n|\n\n### examples\n\n| introduced CLAUDE  \n  \n### scripts\n\n|\n\n### scripts\n\n| Merge remote-tracking branch 'origin/main' into feat/fine_tune  \n  \n### src\n\n|\n\n### src\n\n| Merge remote-tracking branch 'origin/feat/fine_tune' into feat/fine_tune  \n  \n### tests\n\n|\n\n### tests\n\n| Merge remote-tracking branch 'origin/feat/fine_tune' into feat/fine_tune  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| introduced CLAUDE  \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n| first rest end point with logger  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| added license file  \n  \n### README.md\n\n|\n\n### README.md\n\n| fix conflict  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| introduce fine tuning script  \n  \n## Repository files navigation\n\n# Testup AI driver\n\nThis project introduces an AI-driven tool to automate website testing through\nSelenium. By harnessing the power of natural language instructions and\nSelenium's comprehensive browser automation capabilities, it simplifies\nexecuting complex test scenarios on web applications. From adding products to\nshopping carts and navigating through pages to verifying webpage elements,\nthis tool makes web testing accessible and efficient.\n\nThis tool is brought to you by testup.io, the easist no-code test automation\ntool on the web.\n\n## Features\n\n  * DOM Tree compression To limit the token count sent to the AI model the first step is to reduce the DOM to relevant information.\n  * Automatic ID generation Ids are added to all DOM elements to ensure back and forth communication with the AI model.\n  * Conversation context The model may use repeated requests to inform the AI about the result of its actions to make sure that the entire task can be completed.\n  * Selenium wrapper: The SeleniumAIUtils class wraps the Selenium WebDriver and offers the additional AI functions.\n  * Training data: By running parameter fine tuning against our sample data you can significantly increase the accuracy of the results.\n\n## Usage\n\nSetup the selenium driver as usual then use our wrapper to execute prompts:\n\n    \n    \n    selenium_utils = SeleniumAiUtils() selenium_utils.set_local_driver(driver, url) selenium_utils.execute_prompt(\"put any product in shopping cart\")\n\n# Setup\n\n## Setting up python and selenium\n\n  1. Make sure you have python installed and add the requireds from the requirements.txt file:\n    \n        pip install -r requirements.txt\n\n  2. Make sure you have ChromeDriver installed and added to your system's PATH. Instructions for installing ChromeDriver can be found at ChromeDriver - WebDriver for Chrome.\n\n  3. If you are using an ide you can then add src and examples to your source root paths and add test to your test root path. Alternatively you can set it up in the shell:\n    \n        export PYTHONPATH=$(pwd)/src\n\n## Setting up the OpenAI connection\n\nBefore running the tool, you must set up the following environment variable:\n\n  * OPENAI_API_KEY: Your OpenAI API key for processing natural language commands.\n\nTo limit the amount of traffic to the API you can optionally set the following\nenvironment variables:\n\n  * MAX_REQUESTS: The maximum number of API requests per minute (default is 20).\n  * MAX_TOKENS: The maximum number of tokens (input characters) per minute (default is 160000).\n\nYou may want to consider setting up these variables in your environment or\nthrough a .env file in the project's root directory for security reasons.\n\n# Usage\n\n## Interactive Mode\n\nThis mode allows real-time natural language commands for web application\ninteraction. Users can change URLs, navigate, click, input data, and exit as\nneeded. To start using the tool:\n\n  1. Run the app:\n    \n        python examples/selenium_ai_app.py\n\n## Example Test Script\n\nIf you want to write your own standalone test, please refer to our reference\nfile testup_mywebshop.py, for an automation script example. It illustrates the\nuse of the api using a simple selneium wrapper. It opens a demo web shop, adds\na product to a shopping cart and checks out. Each step is tested with selenium\ncore functions, demonstrating the mix between AI and traditional testing\nmethods.\n\n  1. Open and customize examples/testup_mywebshop.py to fit your test scenario.\n  2. Execute the script:\n    \n        python examples/testup_mywebshop.py\n\nThe script initiates a browser session, performs the defined actions, and\nautomatically closes the browser upon completion or error.\n\nYou may Adapt examples/testup_mywebshop.py or create new scripts using the\nSeleniumUtils class for AI-driven Selenium interactions and the execute_prompt\nmethod for AI-driven navigation and actions.\n\n# Model Fine-Tuning\n\nFine-tuning a model will help ensuring getting more accurate results from the\ngpt model, the process requires training data in a specific format, this\nsection guides you through the process of preparing your training data and\nexecuting the fine-tuning by converting HTML content to Markdown, which is a\npreferred format for text-based machine learning tasks due to its simplicity,\nreadability and reduced size.\n\n## HTML to Markdown Conversion\n\nThe first step of training is to reduce the HTML content from\nscripts/data/input directory. Execute the following command from your\nproject's root directory:\n\n    \n    \n    cd scripts python prepare_training_data.py\n\n## Fine-Tuning Your Model\n\nOnce your data is prepared and converted to Markdown, you can fine-tune your\nmodel using the provided script. Execute the fine-tuning script with the\nfollowing command, which will use the converted Markdown data for training:\n\n    \n    \n    python3 fine_tune.py\n\nThe script will process the training data and initiate the fine-tuning job. It\nwill continue to run until the fine-tuning is complete, at which point it will\ndisplay the new model ID.\n\n## Setting the New Trained Model\n\nAfter the fine-tuning process is finished and you have your new model ID, you\ncan set your environment to use this trained model for future tasks:\n\n    \n    \n    export GPT_MODEL=<new trained model>\n\nReplace <new trained model> with the actual model ID provided after the fine-\ntuning process.\n\n# Contributing\n\nContributions are welcome! Fork the repository, make your changes, and submit\na pull request.\n\n## About\n\nNo description, website, or topics provided.\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\nActivity\n\n### Stars\n\n2 stars\n\n### Watchers\n\n1 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * HTML 96.7%\n  * Python 3.3%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
