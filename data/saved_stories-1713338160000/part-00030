{"aid": "40057257", "title": "GitHub: Neurallambda/automata: synth data for training FSMs/PDAs/Turing Machines", "url": "https://github.com/neurallambda/automata", "domain": "github.com/neurallambda", "votes": 1, "user": "neurallambda", "posted_at": "2024-04-16 21:09:12", "comments": 0, "source_title": "GitHub - neurallambda/automata: generate synthetic data for training finite state machines/pushdown automata/turing machines", "source_text": "GitHub - neurallambda/automata: generate synthetic data for training finite\nstate machines/pushdown automata/turing machines\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nneurallambda / automata Public\n\n  * Notifications\n  * Fork 0\n  * Star 12\n\ngenerate synthetic data for training finite state machines/pushdown\nautomata/turing machines\n\n12 stars 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# neurallambda/automata\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nfreckletonjUpdate README.md7ea216c \u00b7\n\n## History\n\n20 Commits  \n  \n### app\n\n|\n\n### app\n\n| Add FSM and Turing Machine (Queue Automata) (#1)  \n  \n### data\n\n|\n\n### data\n\n| Add FSM and Turing Machine (Queue Automata) (#1)  \n  \n### rules\n\n|\n\n### rules\n\n| Add FSM and Turing Machine (Queue Automata) (#1)  \n  \n### src\n\n|\n\n### src\n\n| Add FSM and Turing Machine (Queue Automata) (#1)  \n  \n### test\n\n|\n\n### test\n\n| move work over from awesome-reasoning  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| add more programs  \n  \n### CHANGELOG.md\n\n|\n\n### CHANGELOG.md\n\n| move work over from awesome-reasoning  \n  \n### README.md\n\n|\n\n### README.md\n\n| Update README.md  \n  \n### haskell.cabal\n\n|\n\n### haskell.cabal\n\n| Add FSM and Turing Machine (Queue Automata) (#1)  \n  \n## Repository files navigation\n\n# Automata\n\nA tool for generating synthetic data that results from grammars writen for\nvarious automata (eg Finite State Machines, Pushdown Automata and Turing\nMachines). Grammars are saved as json, and you can build 1000 valid strings\nthat match this grammar with:\n\n    \n    \n    $ automata -i my_grammar.json -o output.json -n 1000 aXb aaXbb aaaXbbb aaaaXbbbb ...\n\nThis is intended to help train the neurallambda project and confer reasoning\nability to LLMs.\n\n## Layout\n\n    \n    \n    rules/ # example grammars data/ # data generated from those rules app/ # the CLI tool src/ # the supporting library\n\n## PDA example\n\nThere's a grammar that looks like a^nXb^n, which is any string like aaXbb and\naaaaaXbbbbb, where the same number of bs follow the same number of as (and in\nthe middle is X). You cannot write a regex for this (try defining that n), but\nyou can write a pushdown automata that recognizes it. A transition function\ninvolves the following mappings between states (slightly simplified, see\nrules/anbn.json):\n\n    \n    \n    { \"machine\": \"PDA\", \"symbols\": [\"a\", \"b\", \"X\"], \"rules\": [ # input symbol | # current state # resulting state | | # top of stack | # stack operation | | | | | [[\"a\", \"INITIAL\", \"A\"], [\"Q1\", [\"push\", \"A\"]]], [[\"X\", \"Q1\", \"A\"], [\"Q2\", \"nullop\"]], [[\"b\", \"Q2\", \"A\"], [\"Q2\", \"pop\"]], ] }\n\nNotice there are exactly 5 items in each transition rule for a PDA, and they\ncome as 3 on the Left and 2 on the Right. These represent the left and right\nhand side of the relation that defines a PDA. In english, the rules say:\n\n  1. given an input symbol 'a', if I'm in the state Q1, and the top of the stack is \"A\", let's transition by staying in state Q1, and push an \"A\" on the stack.\n\n  2. if the input symbol is 'X', we know we need to transition to 'Q2', which implies we're gonna start looking for 'b's.\n\n  3. each time we see a 'b', pop the stack. This is how we can ensure that the same number of pushes and pops happen, ie, same number of 'b's and 'a's.\n\nAgain, see rules/anbn.json) for the full implementation.\n\n## About the tool\n\nHaskell was chosen because it produces trustworthy code, especially in this\ndepartment of computer languages. When I next face a funky loss while training\nsome NN, I want to minimize the risk that the data was improperly generated.\n\nA simple typeclass is offered to allow the easy (if you speak haskell)\nspecification of new Automata:\n\n    \n    \n    class Machine m a (s :: Type) where data L m a s -- ^ the Left side of a delta function/relation data R m a s -- ^ the Right side of a delta function/relation data S m a s -- ^ the State of the Machine -- | update the state (ex apply stack ops) action :: R m a s -> S m a s -> S m a s -- | build an input (ex add a peek at the top of a stack) mkL :: a -> S m a s -> L m a s\n\nThere are probably infinite things that are Turing Complete formulations of\nTuring Machines, and I hope to represent some in this library:\n\n  * The classic tape model\n  * An FSM with 1 queue\n  * An FSM with 2 stacks\n  * An FSM with multiple queues\n  * An FSM with multiple tapes\n  * Something (i'm not sure what) with addressable memory\n\n## \"I just got here and have no clue what you're doing\"\n\nThat's because I'm bad at explaining things.\n\nI have a project called neurallambda where I hope to build architectures that\naugment traditional architectures with reasoning ability. Checkout the readme\nif you're skeptical, it explains why I don't think the current batch of AI has\nreasoning.\n\nSo for experimenting on these architectures I need data. Current datasets are\nlargely around Natural Language, and probably GPT generated (therefore their\nreasoning is circumspect). It'll be easier to train on super simple perfectly\ntrustworthy datasets, therefore why not generate them ourselves? That's where\nthis lib comes in.\n\n## About\n\ngenerate synthetic data for training finite state machines/pushdown\nautomata/turing machines\n\n### Resources\n\nReadme\n\nActivity\n\nCustom properties\n\n### Stars\n\n12 stars\n\n### Watchers\n\n1 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * Haskell 100.0%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
