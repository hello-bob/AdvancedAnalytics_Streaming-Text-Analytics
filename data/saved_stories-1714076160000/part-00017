{"aid": "40157450", "title": "CMOS plus stochastic nanomagnets enabling heterogeneous computers", "url": "https://www.nature.com/articles/s41467-024-46645-6", "domain": "nature.com", "votes": 3, "user": "taubek", "posted_at": "2024-04-25 13:40:26", "comments": 0, "source_title": "CMOS plus stochastic nanomagnets enabling heterogeneous computers for probabilistic inference and learning", "source_text": "CMOS plus stochastic nanomagnets enabling heterogeneous computers for probabilistic inference and learning | Nature Communications\n\nLoading [MathJax]/jax/output/HTML-CSS/config.js\n\nSkip to main content\n\nThank you for visiting nature.com. You are using a browser version with\nlimited support for CSS. To obtain the best experience, we recommend you use a\nmore up to date browser (or turn off compatibility mode in Internet Explorer).\nIn the meantime, to ensure continued support, we are displaying the site\nwithout styles and JavaScript.\n\nAdvertisement\n\n  * View all journals\n  * Search\n\n## Search\n\nAdvanced search\n\n### Quick links\n\n    * Explore articles by subject\n    * Find a job\n    * Guide to authors\n    * Editorial policies\n\n  * Log in\n\n  * Explore content\n  * About the journal\n  * Publish with us\n\n  * Sign up for alerts\n  * RSS feed\n\nCMOS plus stochastic nanomagnets enabling heterogeneous computers for\nprobabilistic inference and learning\n\nDownload PDF\n\nDownload PDF\n\n  * Article\n  * Open access\n  * Published: 27 March 2024\n\n# CMOS plus stochastic nanomagnets enabling heterogeneous computers for\nprobabilistic inference and learning\n\n  * Nihal Sanjay Singh ORCID: orcid.org/0009-0004-7554-4317^1^ na1,\n  * Keito Kobayashi^1,2,3^ na1,\n  * Qixuan Cao^1^ na1,\n  * Kemal Selcuk^1,\n  * Tianrui Hu^1,\n  * Shaila Niazi^1,\n  * Navid Anjum Aadit ORCID: orcid.org/0000-0001-9933-0728^1,\n  * Shun Kanai ORCID: orcid.org/0000-0003-4689-1374^2,3,4,5,6,7,8,\n  * Hideo Ohno ORCID: orcid.org/0000-0001-9688-8259^2,4,5,9,\n  * Shunsuke Fukami ORCID: orcid.org/0000-0001-5750-2990^2,3,4,5,9,10 &\n  * ...\n  * Kerem Y. Camsari ORCID: orcid.org/0000-0002-6876-8812^1\n\nNature Communications volume 15, Article number: 2685 (2024) Cite this article\n\n  * 2452 Accesses\n\n  * 75 Altmetric\n\n  * Metrics details\n\n## Abstract\n\nExtending Moore\u2019s law by augmenting complementary-metal-oxide semiconductor\n(CMOS) transistors with emerging nanotechnologies (X) has become increasingly\nimportant. One important class of problems involve sampling-based Monte Carlo\nalgorithms used in probabilistic machine learning, optimization, and quantum\nsimulation. Here, we combine stochastic magnetic tunnel junction (sMTJ)-based\nprobabilistic bits (p-bits) with Field Programmable Gate Arrays (FPGA) to\ncreate an energy-efficient CMOS + X (X = sMTJ) prototype. This setup shows how\nasynchronously driven CMOS circuits controlled by sMTJs can perform\nprobabilistic inference and learning by leveraging the algorithmic update-\norder-invariance of Gibbs sampling. We show how the stochasticity of sMTJs can\naugment low-quality random number generators (RNG). Detailed transistor-level\ncomparisons reveal that sMTJ-based p-bits can replace up to 10,000 CMOS\ntransistors while dissipating two orders of magnitude less energy. Integrated\nversions of our approach can advance probabilistic computing involving deep\nBoltzmann machines and other energy-based learning algorithms with extremely\nhigh throughput and energy efficiency.\n\n### Similar content being viewed by others\n\n### An atomic Boltzmann machine capable of self-adaption\n\nArticle 01 February 2021\n\n### Versatile stochastic dot product circuits based on nonvolatile memories\nfor high performance neurocomputing and neurooptimization\n\nArticle Open access 08 November 2019\n\n### Noise-injected analog Ising machines enable ultrafast statistical sampling\nand machine learning\n\nArticle Open access 04 October 2022\n\n## Introduction\n\nWith the slowing down of Moore\u2019s Law^1, there has been a growing interest in\ndomain-specific hardware and architectures to address emerging computational\nchallenges and energy efficiency, particularly borne out of machine learning\nand AI applications. One promising approach is the co-integration of\ntraditional complementary metal-oxide semiconductor (CMOS) technology with\nemerging nanotechnologies (X), resulting in CMOS + X architectures. The\nprimary objective of this approach is to augment existing CMOS technology with\nnovel functionalities, by enabling the development of physics-inspired\nhardware systems that realize energy-efficiency, massive parallelism, and\nasynchronous dynamics, and apply them to a wide range of problems across\nvarious domains.\n\nBeing named one of the top 10 algorithms of the 20th century^2, Monte Carlo\nmethods have been one of the most effective approaches in computing to solve\ncomputationally hard problems in a wide range of applications, from\nprobabilistic machine learning, optimization to quantum simulation.\nProbabilistic computing with p-bits^3 has emerged as a powerful platform for\nexecuting these Monte Carlo algorithms in massively parallel^4,5 and energy-\nefficient architectures. p-bits have been shown to be applicable to a large\ndomain of computational problems, from combinatorial optimization to\nprobabilistic machine learning and quantum simulation^6,7,8.\n\nSeveral p-bit implementations that use the inherent stochasticity in different\nmaterials and devices have been proposed, based on diffusive memristors^9,\nresistive RAM^10, perovskite nickelates^11, ferroelectric transistors^12,\nsingle photon avalanche diodes^13, optical parametric oscillators^14 and\nothers. Among alternatives sMTJs built out of low-barrier nanomagnets have\ndemonstrated significant potential due to their ability to amplify noise,\nconverting millivolts of fluctuations to hundreds of millivolts over resistive\nnetworks^15, unlike alternative approaches with amplifiers^16. Another\nadvantage of sMTJ-based p-bits is the continuous generation of truly random\nbitstreams without the need to be reset in synchronous pulse-based\ndesigns^17,18. The possibility of designing energy-efficient p-bits using low-\nbarrier nanomagnets has stimulated renewed interest in material and device\nresearch with several exciting demonstrations from nanosecond\nfluctuations^19,20,21 to a better theoretical understanding of nanomagnet\nphysics^22,23,24,25 and novel magnetic tunnel junction designs^26,27.\n\nDespite promising progress with hardware prototypes^28,29,30,31,32, large-\nscale probabilistic computing using stochastic nanodevices remains elusive. As\nwe will establish in this paper, designing purely CMOS-based high-performance\nprobabilistic computers suited to sampling and optimization problems is\nprohibitive beyond a certain scale (>1M p-bits) due to the large area and\nenergy costs of pseudorandom number generators. As such, any large-scale\nintegration of probabilistic computing will involve strong integration with\nCMOS technology in the form of CMOS+X architectures. Given the unavoidable\ndevice-to-device variability, the interplay between continuously fluctuating\nstochastic nanodevices (e.g., sMTJs) with deterministic CMOS circuits and the\npossible applications of such hybrid circuits remain unclear.\n\nIn this paper, we first introduce the notion of a heterogeneous CMOS + sMTJ\nsystem where the asynchronous dynamics of sMTJs control digital circuits in a\nstandard CMOS field programmable gate array (FPGA). We view the FPGA as a\n\u201cdrop-in replacement\u201d for eventual integrated circuits where sMTJs could be\nsituated on top of CMOS. Unlike earlier implementations where sMTJs were\nprimarily used to implement neurons and CMOS or analogue components circuits\nfor synapses^28,29, we design hybrid circuits where sMTJ-based p-bits control\na large number of digital circuits residing in the FPGA without dividing the\nsystem into neurons (sMTJ) and synapses (CMOS). We show how the true\nrandomness injected into deterministic CMOS circuits augments low-quality\nrandom number generators based on linear feedback shift registers (LFSR). This\nresult represents an example of how sMTJs could be used to reduce footprint\nand energy consumption in the CMOS underlayer. In this work, we present a\nsmall example of a CMOS + sMTJ system, however, similar systems can be scaled\nup to much bigger densities, leveraging the proven manufacturability of\nmagnetic memory at gigabit densities. Our results will help lay the groundwork\nfor larger implementations in the presence of unavoidable device-to-device\nvariations. We also focus beyond the common use case of combinatorial\noptimization of similar physical computers^33, considering probabilistic\ninference and learning in deep energy-based models.\n\nSpecifically, we use our system to train 3-hidden 1-visible layer deep and\nunrestricted Boltzmann machines that entirely rely on the asynchronous\ndynamics of the stochastic MTJs. Second, we evaluate the quality of randomness\ndirectly at the application level through probabilistic inference and deep\nBoltzmann learning. This approach contrasts with the majority of related work,\nwhich typically conducts statistical tests at the single device level to\nevaluate the quality of randomness^21,34,35,36,37,38 (see Supplementary Notes\nVIII, XI, and XII for more randomness experiments). As an important new\nresult, we find that the quality of randomness matters in machine learning\ntasks as opposed to optimization tasks that have been explored previously.\nFinally, we conduct a comprehensive benchmark using an experimentally\ncalibrated 7-nm CMOS PDK and find that when the quality of randomness is\naccounted for, the sMTJ-based p-bits are about four orders of magnitude\nsmaller in area and they dissipate two orders of magnitude less energy,\ncompared to CMOS p-bits. We envision that large-scale CMOS + X p-computers\n(>>10^5) can be a reality in scaled-up versions of the CMOS + sMTJ type\ncomputers we discuss in this work.\n\n### Constructing the heterogeneous p-computer\n\nFigure 1 shows a broad overview of our sMTJ-FPGA setup along with device and\ncircuit characterization of sMTJ p-bits. Unlike earlier p-bit demonstrations\nwith sMTJs as standalone stochastic binary neurons, in this work, we use sMTJ-\nbased p-bits to generate asynchronous and truly random clock sources to drive\ndigital p-bits in the FPGA (Fig. 1a\u2013c).\n\nFig. 1: Experimental setup for the CMOS + sMTJ probabilistic computer.\n\na Stack structure of the stochastic magnetic tunnel junction (sMTJ). b The\nproposed sMTJ-based p-bit circuit with two branches whose outputs are provided\nto an operational amplifier. R_ave is the average resistance of R_P and R_AP\nof the sMTJ. 5 sMTJ-based p-bits provide tunable, truly random and\nasynchronous clocks to a digital field programmable gate array (FPGA). c\nDigital p-bits in the FPGA use lookup tables (LUT), comparators, synaptic\nweights, and pseudorandom number generators (PRNG). The clocks of the PRNG are\ndriven by the truly random asynchronous outputs coming from the analog p-bits.\nd Pictorial representation of perpendicular sMTJ. e Image of a single p-bit\ncircuit. f Image of the FPGA. The asynchronous clocks are input through the\nperipheral module (PMOD) pins. g Typical output of p-bits #1 to 5 using 5\nsMTJs obtained from the p-bit circuit (see Supplementary Note III), showing\nvariations in fluctuations. h Experimentally measured \u3008V_OUT\u3009 the time average\n(over a period of 3 minutes) of the p-bit circuit output, as a function of DC\ninput voltage V_IN. The yellow squares are experimental data, and the blue\ndashed line is a fit of the form \\\\(\\langle\n{V}_{{{{{{{{\\rm{OUT}}}}}}}}}\\rangle=1/2\\,{V}_{{{{{{{{\\rm{CC}}}}}}}}}^{{\\prime}\n}[\\tanh [\\beta ({V}_{{{{{{{{\\rm{IN}}}}}}}}}-{V}_{0})]+1]\\\\), where V_0 = 1.55\nV, \u03b2 = 3.43 V^\u22121, \\\\({V}_{{{{{{{{\\rm{CC}}}}}}}}}^{{\\prime}\n}=3\\,\\,{{\\mbox{V}}}\\,\\\\) is a reduced voltage from V_CC = 5 V (see\nSupplementary Note IV).\n\nFull size image\n\nThe conductance of the sMTJ depends on the relative angle \u03b8 between the free\nand the fixed layers, \\\\({G}_{{{{{{{{\\rm{MTJ}}}}}}}}}\\propto [1+{P}^{2}\\cos\n(\\theta )]\\\\), where P is the interfacial spin polarization. When the free\nlayer is made out of a low barrier nanomagnet \u03b8 becomes a random variable in\nthe presence of thermal noise, causing conductance fluctuations between the\nparallel (P) and the antiparallel (AP) states (Fig. 1d).\n\nThe five sMTJs used in the experiment are designed with a diameter of 50 nm\nand have a relaxation time of about 1\u201320 ms, with energy barriers of \u224814\u201317\nk_BT, assuming an attempt time of 1 ns^39 (see Supplementary Note II). In\norder to convert these conductance fluctuations into voltages, we design a new\np-bit circuit (Fig. 1b, e). This circuit creates a voltage comparison between\ntwo branches controlled by two transistors, fed to an operational amplifier.\nAs we discuss in Supplementary Note III, the main difference of this circuit\ncompared to the earlier 3 transistor/1MTJ design used in earlier\ndemonstrations^28,29 is in its ability to provide a larger stochastic window\nto tune the p-bit (Fig. 1h) with more variation tolerance (see Supplementary\nNote IV).\n\nFigure 1c, e, f, g show how the asynchronous clocks obtained from p-bits with\n50/50 fluctuations are fed to the FPGA. Inside the FPGA, we design a digital\nprobabilistic computer where a p-bit includes a lookup table (LUT) for the\nhyperbolic tangent function, a pseudorandom number generator (PRNG) and a\ndigital comparator (see Supplementary Note V).\n\nThe crucial link between analog p-bits and the digital FPGA is established\nthrough the clock of the PRNG used in the FPGA, where a multitude of digital\np-bits can be asynchronously driven by analog p-bits. As we discuss in\nSections 3, 4, depending on the quality of the chosen PRNG, the injection of\nadditional entropy through the clocks has a considerable impact on inference\nand learning tasks. The potential for enhancing low-quality PRNGs using\ncompact and scalable nanotechnologies, such as sMTJs, which can be integrated\nas a BEOL (Back-End-Of-Line) process on top of the CMOS logic, holds\nsignificant promise for future CMOS + sMTJ architectures.\n\n## Results\n\n### Probabilistic inference with heterogeneous p-computers\n\nIn the p-bit formulation, we define probabilistic inference as generating\nsamples from a specified distribution which is the Gibbs-Boltzmann\ndistribution for a given network (see Supplementary Note I for details). This\nis a computationally hard problem^40, and is at the heart of many important\napplications involving Bayesian inference^41, training probabilistic models in\nmachine learning^42, statistical physics^43 and many others^44. Due to the\nbroad applicability of probabilistic inference, improving key figures of\nmerit, such as probabilistic flips per second (sampling throughput) and\nenergy-delay product for this task are extremely important.\n\nTo demonstrate this idea, we evaluate probabilistic inference on a\nprobabilistic version of the full adder (FA)^45 as shown in Fig. 2a. The truth\ntable of the FA is given in Fig. 2b. The FA performs 1-bit binary addition and\nit has three inputs (A, B, Carry in = C_in) and two outputs (Sum = S, and\nCarry out = C_out). The probabilistic FA can be described in a 5 p-bit, fully\nconnected network (Fig. 2a). When the network samples from its equilibrium, it\nsamples states corresponding to the truth table, according to the Boltzmann\ndistribution.\n\nFig. 2: Inference on a probabilistic full adder.\n\na Fully-connected full adder network^45, where p-bits are clocked by the\nsMTJs. b Truth table of the full adder where Dec. represents the decimal\nrepresentation of the state of [A B C_in S C_out] from left to right. c\nKullback-Leibler (KL) divergence between the ideal and measured distributions\nvs. the number of sweeps. Results are shown for LFSR-based p-bit (red line),\nsMTJ-clocked LFSR-based p-bit (blue line), and Xoshiro-based p-bit (green\nline). d Histogram for the measured and ideal distributions at the 10^6 sweep.\nThe red, blue, and yellow bars show LFSR, sMTJ-clocked LFSR, and Boltzmann\ndistribution, respectively. The histogram shows all 8 high probability states\ndenoted in (b) and with a clear bias for the LFSR distribution (see\nSupplementary Note VII for full histograms for all PRNGs, including Xoshiro).\n\nFull size image\n\nWe demonstrate probabilistic sampling on the probabilistic FA using the\ndigital p-bits with standalone LFSRs (only using the FPGA), sMTJ-clocked LFSRs\n(using sMTJ-based p-bits and the FPGA), and standalone Xoshiro RNGs (only\nusing the FPGA). Our main goal is to compare the quality of randomness\nobtained by inexpensive but low-quality PRNGs such as LFSRs^46 with sMTJ-\naugmented LFSRs and high-quality but expensive PRNGs such as Xoshiro^47 (see\nSupplementary Note VI).\n\nFigure 2c shows the comparison of these three different solvers where we\nmeasure the Kullback-Leibler (KL) divergence^48 between the cumulative\ndistribution based on the number of sweeps and the ideal Boltzmann\ndistribution of the FA:\n\n$${{{{{{{\\rm{KL}}}}}}}}[{P}_{\\exp }| | {P}_{{{{{{{{\\rm{ideal}}}}}}}}}]=\\mathop{\\sum}\\limits_{x}{P}_{\\exp }(x)\\log \\frac{{P}_{\\exp }(x)}{{P}_{{{{{{{{\\rm{ideal}}}}}}}}}(x)},$$\n\n(1)\n\nwhere \\\\({P}_{\\exp }\\\\) is the probability obtained from the experiment\n(cumulatively measured), and P_ideal is the probability obtained from the\nBoltzmann distribution. For LFSR (red line), the KL divergence saturates when\nthe number of sweeps exceeds N = 10^4, while for sMTJ-clocked LFSR (blue line)\nand Xoshiro (green line), the KL divergence decreases with increasing the\nnumber of sweeps. The persistent bias of the LFSR is also visible in the\npartial histogram of probabilities measured at N = 10^6 sweeps as shown in\nFig. 2d (see Supplementary Note VII for the full histograms). It is important\nto note here, that in our present context where sMTJs are limited to a handful\nof devices, we use sMTJ-based p-bits to drive low-quality LFSRs, observing how\nthey perform similarly to high-quality PRNGs. In integrated implementations,\nhowever, sMTJ-based p-bits can be directly used as p-bits themselves without\nany supporting PRNG (see Supplementary Note XVI for details on projections of\nintegrated implementations).\n\nThe mechanism of how the sMTJ-clocked LFSRs produce random numbers is\ninteresting: even though the next bit in an LFSR is always perfectly\ndetermined, the randomness in the arrival times of clocks from the sMTJs makes\ntheir output unpredictable. Over the course of the full network\u2019s evolution,\neach LFSR produces an unpredictable bitstream, functioning as truly random\nbits.\n\nThe observed bias of the LFSR can be due to several reasons: first, the LFSRs\ngenerally provide low-quality random numbers and do not pass all the tests in\nthe NIST statistical test suite^49 (see Supplementary Note XII). Second, we\ntake whole words of random bits from the LFSR to generate large random\nintegers. This is a known danger when using LFSRs^50,51, which can be\nmitigated by the use of phase shifters that scramble the parallelly obtained\nbits to reduce their correlation^52. However, such measures increase the\ncomplexity of PRNG designs, further limiting the scalable implementation of\ndigital p-computers (see Supplementary Note XI for detailed experimental\nanalysis of LFSR bias).\n\nThe quality of randomness in Monte Carlo sampling is a rich and well-studied\nsubject (see, for example, refs. ^53,54,55). The main point we stress in this\nwork is that even compact and inexpensive simple PRNGs can perform as well as\nsophisticated, high-quality RNGs when augmented by truly random nanodevices\nsuch as sMTJs.\n\n### Boltzmann learning with heterogeneous p-computers\n\nWe now show how to train deep Boltzmann machines (DBM) with our heterogeneous\nCMOS + sMTJ computer. Unlike probabilistic inference, in this setting, the\nweights of the network are unknown, and the purpose of the training process is\nto obtain desired weights for a given truth table, such as the full adder (see\nSupplementary Note IX for an example of arbitrary distribution generation\nusing the same learning algorithm). We consider this demonstration as a proof-\nof-concept for eventual larger-scale implementations (Fig. 3a, b). Similar to\nprobabilistic inference, we compare the performance of three solvers: LFSR-\nbased, Xoshiro-based and sMTJ+LFSR-based RNGs. We choose a 32-node Chimera\nlattice^56 to train a probabilistic full adder with 5 visible nodes and 27\nhidden nodes in a 3-layer DBM (see Fig. 3b top panel). Note that this deep\nnetwork is significantly harder to train than training fully visible networks\nwhose data correlations are known a priori^29, necessitating positive and\nnegative phase computations (see Supplementary Note VII and Algorithm 1 for\ndetails on the learning algorithm and implementation).\n\nFig. 3: Learning deep Boltzmann machines.\n\na The architecture of the p-computer for learning. The digital p-bits in FPGA\nare fed by sMTJ-based p-bits output similar to probabilistic inference. The\nweights J_ij and biases h_i are updated in the CPU for a specified number of\nepochs. b (Top) The 32-node Chimera graph is used as a deep BM. (Bottom) An\nasynchronous clocking scheme is shown with node coloring. c KL divergence as a\nfunction of the number of epochs for LFSR (red line), LFSR clocked by sMTJ-\nbased p-bit (blue line), and Xoshiro (green line). d The distribution of full\nadder with learned weights and biases at epoch = 400 where the number of\nsweeps per epoch = 400 for LFSR-only and the number of sweeps per epoch =\n16000 for sMTJ-clocked LFSR. The Boltzmann distribution was obtained with \u03b2 =\n3. The red, blue, and yellow bars show LFSR and LFSR clocked by sMTJ-based\np-bit, and Boltzmann, respectively. The histogram shows 4 correct (0, 6, 18,\n25) and 2 incorrect (2, 29) states, out of the 32 possible states. sMTJ-based\np-bit closely approximates the ideal Boltzmann distribution, whereas the LFSR\nunderestimates correct states and completely fails with states 2 and 29 (see\nSupplementary Note VII for full histograms for all PRNGs, including Xoshiro).\n\nFull size image\n\nFigure 3c, d show the KL divergence and the probability distribution of the\nfull adder Boltzmann machines based on the fully digital LFSR/Xoshiro and the\nheterogeneous sMTJ-clocked LFSR RNGs. The KL divergence in the learning\nexperiment is performed like this: after each epoch during training, we save\nthe weights in the classical computer and perform probabilistic inference to\nmeasure the KL distance between the learned and ideal distributions. The sMTJ-\nclocked LFSR and the Xoshiro-based Boltzmann machines produce probability\ndistributions that eventually closely approximate the Boltzmann distribution\nof the full adder. On the other hand, the fully digital LFSR-based Boltzmann\nmachine produces the incorrect states [A B C_in S C_out] = 2 and 29 with a\nsignificantly higher probability than the correct peaks, and grossly\nunderestimates the probabilities of states 0, 6, 18, and 25 (see Supplementary\nFig. 4 for full histograms that are avoided here for clarity). As in the\ninference experiment (Fig. 2a), the KL divergence of the LFSR saturates and\nnever improves beyond a point. The increase in the KL divergence for Xoshiro\nand sMTJ-clocked LFSR towards the end is related to hyperparameter selection\nand unrelated to RNG quality^57. For this reason, we select the weights at\nepoch=400 for testing to produce the histogram in Fig. 3d.\n\nIn line with our previous results, the learning experiments confirm the\ninferior quality of LFSR-based PRNGs, particularly for learning tasks (see\nSupplementary Note X for MNIST training comparisons between p-bits based on\nXoshiro and LFSR). While LFSRs can produce correct peaks with some bias in\noptimization problems, they fail to learn appropriate weights for sampling and\nlearning, rendering them unsuitable for these applications. In addition to\nthese results, statistical tests on the NIST test suite corroborate our\nfindings that sMTJ-clocked LFSRs and high-quality PRNGs such as Xoshiro\noutperform the pure LFSR-based p-bits (see Supplementary Note XII).\n\nOur learning result demonstrates how asynchronously interacting p-bits can\ncreatively combine with existing CMOS technology. Scaled and integrated\nimplementations of this concept could lead to a resurgence in training\npowerful DBMs^58.\n\n### Energy and transistor count comparisons\n\nGiven our prior results stressing how the quality of randomness can play a\ncritical role in probabilistic inference and learning, it is beneficial to\nperform precise, quantitative comparisons with the various digital PRNGs we\nbuilt in hardware FPGAs with sMTJ-based p-bits^15. Note that for this\ncomparison, we do not consider augmented CMOS p-bits, but directly compare\nsMTJ-based mixed signal p-bits with their digital counterparts (see\nSupplementary Note XVI for details on projections of integrated\nimplementations using sMTJ-based mixed signal p-bits). Moreover, instead of\nbenchmarking the voltage comparator-based p-bit circuit shown in Fig. 1 or\nother types of spin-orbit torque-based p-bits^3,59, we benchmark the 3T/1MTJ-\nbased p-bit first reported in ref. ^15. The reason for this choice is that\nthis design allows the use of fast in-plane sMTJs whose fluctuations can be as\nfast as micro to nanoseconds. We also note that the table-top components we\nuse in this work are not optimized but used for convenience.\n\nFor the purpose of benchmarking and characterization, we synthesize circuits\nfor LFSR and Xoshiro PRNGs and these PRNG-based p-bits using the ASAP 7nm\nPredictive process design kit (PDK) that uses SPICE-compatible FinFET device\nmodels^60. Our synthesis flow, explained in detail in Supplementary Note XII,\nstarts from hardware description level (HDL) coding of these PRNGs and leads\nto transistor-level circuits using the experimentally benchmarked ASAP 7nm\nPDK. As such, the analysis we perform here offers a high degree of precision\nin terms of transistor counts and quantitative energy consumption.\n\nFigure 4a shows the transistor count for p-bits using 32-bit PRNGs. Three\npieces make up a digital p-bit: PRNG, LUT (for the activation function) and a\ndigital comparator (typically small). To understand how each piece contributes\nto the transistor count, we separate the PRNG from the LUT contributions in\nFig. 4a.\n\nFig. 4: Transistor counts and energy consumption for p-bit and RNG\nimplementations.\n\nThe digital p-bits and PRNGs are synthesized by the ASAP7 PDK and simulated in\nHSPICE in transistor-level simulations. a Transistor count for p-bits and RNGs\nand (b) Energy Consumption per random bit of p-bits and RNGs. The PRNGs are\n32-bits long and LUTs store 2^8 words that are 32-bits long to be compared\nwith 32-bit RNGs. The sMTJ-based p-bit result is repeated from ref. ^28. To\nactivate the LUT, a periodic input signal with low inputs to the p-bit has\nbeen used. See the text and Supplementary Note XV for details on the energy\ncalculation.\n\nFull size image\n\nFirst, we reproduce earlier results reported in ref. ^28, corresponding to the\nbenchmarking of the design reported in ref. ^15 and find that a 32-bit LFSR\nrequires 1122 transistors which is very close to the custom-designed 32-bit\nLFSR with 1194 transistors in ref. ^28. However, we find that the addition of\nan LUT, ignored in ref. ^28, adds significantly more transistors. Even though\nthe inputs to the p-bit are 10-bits (s[6][3]), the saturating behavior of the\ntanh activation allows reductions in LUT size. In our design, the LUT stores\n2^8 words of 32-bit length that are compared to the 32-bit PRNG. Under this\nprecision, the LUT increases the transistor count to 5150, and more would be\nneeded for finer representations. Note that the compact sMTJ-based p-bit\ndesign proposed in ref. ^15 uses 3 transistors plus an sMTJ which we estimate\nas having an area of 4 transistors, following ref. ^28. In this case, there is\nno explicit need for a LUT or a PRNG.\n\nAdditionally, the results presented in Figs. 2 and 3 indicate that to match\nthe performance of the sMTJ-based p-bits, more sophisticated PRNGs like\nXoshiro must be used. In this case, merely the PRNG cost of a 32-bit Xoshiro\nis 7516 transistors. The LUT costs are the same as LFSR-based p-bits which is\nabout \u22484029 transistors.\n\nCollectively, these results indicate that to truly replicate the performance\nof an sMTJ-based p-bit, the actual transistor cost of a digital design is\n~11,000 transistors which is an order of magnitude worse than the conservative\nestimation performed in ref. ^28.\n\nIn Fig. 4b, we show the energy costs of these differences. We focus on the\nenergy required to produce one random bit. Once again, our synthesis flow,\nfollowed by ASAP7-based HSPICE simulations, reproduces the results presented\nin ref. ^28. We estimate a 23 fJ energy per random bit from the LFSR-based\nPRNG where this number was reported to be 20 fJ in ref. ^28.\n\nSimilar to the transistor count analysis, we consider the effect of the LUT on\nthe energy consumption, which was absent in ref. ^28. We first observe that if\nthe LUT is not active, i.e., if the input I_i to the p-bit is not changing,\nthe LUT does not change the energy per random bit very much. In a real\np-circuit computation, however, I_i would be continuously changing activating\nthe LUT repeatedly. To simulate these working conditions, we create a variable\nI_i pulse that wanders around the stochastic window of the p-bit by changing\nthe least significant bits of the input (see Supplementary Note XV). We choose\na 1 GHz frequency for this pulse mimicking an sMTJ with a lifetime of 1 ns. We\nobserve that in this case, the total energy to create a random bit on average\nincreases by a factor of 6\u00d7 for the LFSR, reaching 145 fJ per bit.\n\nFor the practically more relevant Xoshiro, the average consumption per random\nbit reaches around 293 fJ. Once again, we conclude that the 20 fJ per random\nbit, reported in ref. ^28 underestimates the costs of RNG generation by about\nan order of magnitude when the RNG quality and other peripheries such as LUTs\nare carefully taken into account. In this paper, we do not reproduce the\nenergy estimation of the sMTJ-based p-bit but report the estimate in ref. ^28,\nwhich assumes an sMTJ-based p-bit with \u2248 nanosecond fluctuations.\n\nOur benchmarking results highlight the true expense of high-quality digital\np-bits in silicon implementations. Given that functionally interesting and\nsophisticated p-circuits require above 10,000 to 50,000 p-bits^5, using a\n32-bit Xoshiro-based p-bit in a digital design would consume up to 0.1 to 0.5\nBillion transistors, just for the p-bits. In addition, the limitation of not\nbeing able to parallelize or fit more random numbers in hardware would limit\nthe throughput^61 and the probabilistic flips per second, a key metric\nmeasuring the effective sampling speed of a probabilistic computer (see for\nexample, refs. ^62,63,64). As discussed in detail in Supplementary Note XVI,\nnear-term projections with N = 10^4 p-bits using sMTJs with in-plane magnetic\nanisotropy (IMA) (\u03c4 \u2248 1 ns^19) can reach \u2248 10^4 flips/ns in sampling\nthroughput. These results clearly indicate that a digital solution beyond\n10,000 to 50,000 p-bits, as required by large-scale optimization,\nprobabilistic machine learning, and optimization tasks, will remain\nprohibitive. To solve these traditionally expensive but practically useful\nproblems, the heterogeneous integration of sMTJs holds great promise both in\nterms of scalability and energy efficiency.\n\n## Discussions\n\nThis work demonstrates the first hardware demonstration of a heterogeneous\ncomputer combining versatile FPGAs with stochastic MTJs for probabilistic\ninference and deep Boltzmann learning. We introduce a new variation-tolerant\np-bit circuit that is used to create an asynchronous clock domain, driving\ndigital p-bits in the FPGA. In the process, the CMOS + sMTJ computer shows how\ncommonly used and inexpensive PRNGs can be augmented by magnetic nanodevices\nto perform as well as high-quality PRNGs (without the resource overhead), both\nin probabilistic inference and learning experiments. Our CMOS + sMTJ computer\nalso shows the first demonstration of training a deep Boltzmann network in a\n32-node Chimera topology, leveraging the asynchronous dynamics of sMTJs.\nCareful comparisons with existing digital circuits show the true potential of\nintegrated sMTJs, which can be scaled up to million p-bit densities far beyond\nthe capabilities of present-day CMOS technology (see Supplementary Note XVI\nfor detailed benchmarking and a p-computing roadmap).\n\n## Methods\n\n### sMTJ fabrication and circuit parameters\n\nWe employ a conventional fixed and free layer sMTJ, both having perpendicular\nmagnetic anisotropy. The reference layer thickness is 1 nm (CoFeB) while the\nfree layer is 1.8 nm (CoFeB), deliberately made thicker to reduce its energy\nbarrier^28,35. The stack structure of the sMTJs we use is, starting from the\nsubstrate side,\nTa(5)/Pt(5)/[Co(0.4)/Pt(0.4)]_6/Co(0.4)/Ru(0.4)/[Co(0.4)/Pt(0.4)]_2/Co(0.4)/Ta(0.2)/CoFeB(1)/MgO(1.1)/CoFeB(1.8)/Ta(5)/Ru(5),\nwhere the numbers are in nanometers (Fig. 1a). Films are deposited at room\ntemperature by dc/rf magnetron sputtering on a thermally oxidized Si\nsubstrate. The devices are fabricated into a circular shape with a 40\u201380 nm\ndiameter using electron beam lithography and Ar ion milling and annealed at\n300 \u00b0C for 1 hour by applying a 0.4 T magnetic field in the perpendicular\ndirection. The average tunnel magnetoresistance ratio (TMR) and resistance\narea product (RA) are 65% and 4.7 \u03a9 \u03bcm^2, respectively. The discrete sMTJs\nused in this work are first cut out from the wafer, and the electrode pads of\nthe sMTJs are bonded with wires to IC sockets. The following parameters are\nmeasured by sweeping DC current to the sMTJ and measuring the voltage. The\nresistance of the P state R_P is 4.4\u20135.7 k\u03a9, the resistance of the AP state\nR_AP is 5.9\u20137.4 k\u03a9, and the current at which P/AP fluctuations are 50% is\ndefined as I_50/50, in between 14\u201320 \u03bcA. At the output of the new p-bit\ndesign, we use an extra branch with a bipolar junction transistor that acts as\na buffer to the peripheral module pins of the Kintex UltraScale KU040 FPGA\nboard. Given the electrostatic sensitivity of the sMTJs, this branch also\nprotects the circuit from any transients that might originate from the FPGA.\n\n### Digital synthesis flow\n\nHDL codes are converted to gate-level models using the Synopsys Design\nCompiler. Conversion from these models to Spice netlists is done using Calibre\nVerilog-to-LVS. Netlist post-processing is done by a custom Mathematica script\nto make it HSPICE compatible. Details of the synthesis flow (shown in Fig. 4),\nfollowed by HSPICE simulation results for functional verification and power\nanalysis are provided in Supplementary Notes XIII, XIV, and XV.\n\n## Data availability\n\nAll processed data generated in this study are provided in the main text and\nSupplementary Information. The data that support the plots within this paper\nand other findings of this study are available from the corresponding author\nupon request.\n\n## Code availability\n\nThe computer code used in this study is available from the corresponding\nauthor upon request.\n\n## References\n\n  1. Theis, T. N. & Wong, H.-S. P. The end of Moore\u2019s law: a new beginning for information technology. Comput. Sci. Eng. 19, 41\u201350 (2017).\n\nArticle Google Scholar\n\n  2. Dongarra, J. & Sullivan, F. Guest editors introduction to the top 10 algorithms. Comput. Sci. Eng. 2, 22\u201323 (2000).\n\nArticle Google Scholar\n\n  3. Camsari, K. Y. et al. Stochastic p-bits for invertible logic. Phys. Rev. X 7, 031014 (2017).\n\nGoogle Scholar\n\n  4. Sutton, B. et al. Autonomous probabilistic coprocessing with petaflips per second. IEEE Access 8, 157238\u2013157252 (2020).\n\nArticle Google Scholar\n\n  5. Aadit, N. A. et al. Massively parallel probabilistic computing with sparse Ising machines. Nat. Electronics 5, 460\u2013468 (2022).\n\nArticle Google Scholar\n\n  6. Kaiser, J. & Datta, S. Probabilistic computing with p-bits. Appl. Phys. Lett.119, 150503 (2021).\n\nArticle ADS CAS Google Scholar\n\n  7. Camsari, K. Y., Sutton, B. M. & Datta, S. P-bits for probabilistic spin logic. Appl. Phys. Rev. 6, 011305 (2019).\n\nArticle ADS Google Scholar\n\n  8. Chowdhury, S. et al. A full-stack view of probabilistic computing with p-bits: devices, architectures and algorithms. IEEE J. Explor. Solid-State Comput. Devices Circuits 9, 1\u201311 (2023).\n\nArticle ADS Google Scholar\n\n  9. Woo, K. -S. et al. Probabilistic computing using Cu0.1Te0.9/HfO2/Pt diffusive memristors. Nat. Commun. 13, 5762 (2022).\n\nArticle ADS CAS PubMed PubMed Central Google Scholar\n\n  10. Liu, Y. et al. Probabilistic circuit implementation based on p-bits using the intrinsic random property of RRAM and p-bit multiplexing strategy. Micromachines 13, 924 (2022).\n\nArticle PubMed PubMed Central Google Scholar\n\n  11. Park, T.-J. et al. Efficient probabilistic computing with stochastic perovskite nickelates. Nano Lett. 22, 8654\u20138661 (2022).\n\nArticle ADS CAS PubMed Google Scholar\n\n  12. Luo, S., He, Y., Cai, B., Gong, X. & Liang, G. Probabilistic-bits based on ferroelectric field-effect transistors for probabilistic computing. IEEE Electron Device Lett. 44, 1356\u20131359 (2023).\n\nArticle ADS CAS Google Scholar\n\n  13. Whitehead, W., Nelson, Z., Camsari, K. Y. & Theogarajan, L. CMOS-compatible Ising and Potts annealing using single photon avalanche diodes. Nat. Electronics 6, 1009\u20131019 (2023).\n\nArticle Google Scholar\n\n  14. Roques-Carmes, C. et al. Biasing the quantum vacuum to control macroscopic probability distributions. Science 381, 205\u2013209 (2023).\n\nArticle ADS CAS PubMed Google Scholar\n\n  15. Camsari, K. Y., Salahuddin, S. & Datta, S. Implementing p-bits with embedded MTJ. IEEE Electron Device Lett. 38, 1767\u20131770 (2017).\n\nArticle ADS Google Scholar\n\n  16. Cheemalavagu, S., Korkmaz, P., Palem, K. V., Akgul, B. E. S., & Chakrapani, L. N. A probabilistic CMOS switch and its realization by exploiting noise. In IFIP International Conference on VLSI 535\u2013541 (2005).\n\n  17. Fukushima, A. et al. Spin dice: a scalable truly random number generator based on spintronics. Appl. Phys. Express 7, 083001 (2014).\n\nArticle ADS CAS Google Scholar\n\n  18. Rehm, L. et al. Stochastic magnetic actuated random transducer devices based on perpendicular magnetic tunnel junctions. Phys. Rev. Appl. 19, 024035 (2023).\n\nArticle ADS CAS Google Scholar\n\n  19. Safranski, C. et al. Demonstration of nanosecond operation in stochastic magnetic tunnel junctions. Nano Lett. 21, 2040\u20132045 (2021).\n\nArticle ADS CAS PubMed Google Scholar\n\n  20. Hayakawa, K. et al. Nanosecond random telegraph noise in in-plane magnetic tunnel junctions. Phys. Rev. Lett. 126, 117202 (2021).\n\nArticle ADS CAS PubMed Google Scholar\n\n  21. Schnitzspan, L., Kl\u00e4ui, M. & Jakob, G. Nanosecond true-random-number generation with superparamagnetic tunnel junctions: Identification of Joule heating and spin-transfer-torque effects. Phys. Rev. Appl. 20, 024002 (2023).\n\nArticle ADS CAS Google Scholar\n\n  22. Kaiser, J. et al. Subnanosecond fluctuations in low-barrier nanomagnets. Phys. Rev. Appl. 12, 054056 (2019).\n\nArticle ADS CAS Google Scholar\n\n  23. Hassan, O., Faria, R., Camsari, K. Y., Sun, J. Z. & Datta, S. Low-barrier magnet design for efficient hardware binary stochastic neurons. IEEE Magn. Lett. 10, 4502805 (2019).\n\nArticle Google Scholar\n\n  24. Kanai, S., Hayakawa, K., Ohno, H. & Fukami, S. Theory of relaxation time of stochastic nanomagnets. Phys. Rev. B 103, 094423 (2021).\n\nArticle ADS CAS Google Scholar\n\n  25. Funatsu, T., Kanai, S., Ieda, J., Fukami, S. & Ohno, H. Local bifurcation with spin-transfer torque in superparamagnetic tunnel junctions. Nat. Commun. 13, 4079 (2022).\n\nArticle ADS CAS PubMed PubMed Central Google Scholar\n\n  26. Camsari, K. Y., Torunbalci, M. M., Borders, W. A., Ohno, H. & Fukami, S. Double-free-layer magnetic tunnel junctions for probabilistic bits. Phys. Rev. Appl. 15, 044049 (2021).\n\nArticle ADS CAS Google Scholar\n\n  27. Kobayashi, K. et al. External-field-robust stochastic magnetic tunnel junctions using a free layer with synthetic antiferromagnetic coupling. Phys. Rev. Appl. 18, 054085 (2022).\n\nArticle ADS CAS Google Scholar\n\n  28. Borders, W. A. et al. Integer factorization using stochastic magnetic tunnel junctions. Nature 573, 390\u2013393 (2019).\n\nArticle ADS CAS PubMed Google Scholar\n\n  29. Kaiser, J. et al. Hardware-aware in situ learning based on stochastic magnetic tunnel junctions. Phys. Rev. Appl. 17, 014016 (2022).\n\nArticle ADS CAS Google Scholar\n\n  30. Si, J. et al. Energy-efficient superparamagnetic Ising machine and its application to traveling salesman problems. arXiv https://arxiv.org/abs/2306.11572 (2023).\n\n  31. Gibeault, S. et al. Programmable electrical coupling between stochastic magnetic tunnel junctions. arXiv https://arxiv.org/abs/2312.13171 (2023).\n\n  32. Daniel, J. et al. Experimental demonstration of an integrated on-chip p-bit core utilizing stochastic magnetic tunnel junctions and 2D-MoS2 FETs. arXiv https://arxiv.org/ftp/arxiv/papers/2308/2308.10989.pdf (2023).\n\n  33. Mohseni, N., McMahon, P. L. & Byrnes, T. Ising machines as hardware solvers of combinatorial optimization problems. Nat. Rev. Phys. 4, 363\u2013379 (2022).\n\nArticle Google Scholar\n\n  34. Vodenicarevic, D. et al. Low-energy truly random number generation with superparamagnetic tunnel junctions for unconventional computing. Phys. Rev. Appl. 8, 054045 (2017).\n\nArticle ADS Google Scholar\n\n  35. Parks, B. et al. Superparamagnetic perpendicular magnetic tunnel junctions for true random number generators. AIP Adv. 8, 055903 (2018).\n\nArticle ADS Google Scholar\n\n  36. Ostwal, V. & Appenzeller, J. Spin\u2013orbit torque-controlled magnetic tunnel junction with low thermal stability for tunable random number generation. IEEE Magn. Lett. 10, 1\u20135 (2019).\n\nArticle Google Scholar\n\n  37. Lv, Y., Zink, B. R. & Wang, J.-P. Bipolar random spike and bipolar random number generation by two magnetic tunnel junctions. IEEE Trans. Electron Devices 69, 1582\u20131587 (2022).\n\nArticle ADS Google Scholar\n\n  38. Fu, Z. et al. An overview of spintronic true random number generator. Front. Phys. 9, 638207 (2021).\n\nArticle Google Scholar\n\n  39. Coffey, W. T. & Kalmykov, Y. P. Thermal fluctuations of magnetic nanoparticles: fifty years after Brown. J. Appl. Phys. 112, 121301 (2012).\n\nArticle ADS Google Scholar\n\n  40. Goodfellow, I., Bengio, Y., & Courville, A. Deep learning. (MIT Press, 2016).\n\n  41. Friedman, N. & Koller, D. Being Bayesian about network structure. a Bayesian approach to structure discovery in Bayesian networks. Mach. Learn. 50, 95\u2013125 (2003).\n\nArticle Google Scholar\n\n  42. Long, P. M. & Servedio, R. A. Restricted Boltzmann machines are hard to approximately evaluate or simulate. In Proc. 27th International Conference on International Conference on Machine Learning, ICML\u201910, 703\u2013710. (Omnipress, 2010).\n\n  43. Krauth, W. Statistical mechanics: algorithms and computations. 13, OUP Oxford (2006).\n\n  44. Andrieu, C., De Freitas, N., Doucet, A. & Jordan, M. I. An introduction to MCMC for machine learning. Mach. Learn. 50, 5\u201343 (2003).\n\nArticle Google Scholar\n\n  45. Smithson, S. et al. Efficient CMOS invertible logic using stochastic computing. IEEE Trans. Circuits and Syst. I: Regul. Pap. 66, 2263\u20132274 (2019).\n\nArticle MathSciNet Google Scholar\n\n  46. Paar, C. & Pelzl, J. Understanding cryptography: a textbook for students and practitioners. Springer Science & Business Media (2009).\n\n  47. Blackman, D. & Vigna, S. Scrambled linear pseudorandom number generators. ACM Trans. Math. Softw. 47, https://arxiv.org/abs/1805.01407 (2021).\n\n  48. Kullback, S. & Leibler, R. A. On information and sufficiency. Ann. Math. Statist. 22, 79\u201386 (1951).\n\n  49. Rukhin, A. et al. A statistical test suite for random and pseudorandom number generators for cryptographic applications. Technical report (2010).\n\n  50. Press, W. H., Vetterling, W. T., Teukolsky, S. A., & Flannery, B.P. Numerical recipes. (Citeseer, 1988).\n\n  51. Knuth, D. The art of computer programming, 2 (Seminumerical Algorithms). Addison\u2013Wesley, https://www.haio.ir/app/uploads/2022/01/The-art-of-computer-programming.-Vol.2.-Seminumerical-algorithms-by-Knuth-Donald-E-z-lib.org_.pdf (1981).\n\n  52. Rajski, J. & Tyszer, J. Design of phase shifters for BIST applications. In Proceedings. 16th IEEE VLSI test symposium, 218\u2013224 (1998).\n\n  53. Parisi, G. & Rapuano, F. Effects of the random number generator on computer simulations. Phys. Lett. B 157, 301\u2013302 (1985).\n\nArticle ADS Google Scholar\n\n  54. Filk, T., Marcu, M. & Fredenhagen, K. Long range correlations in random number generators and their influence on Monte Carlo simulations. Phys. Lett. B 165, 125\u2013130 (1985).\n\nArticle ADS Google Scholar\n\n  55. Vattulainen, I., Ala-Nissila, T. & Kankaala, K. Physical tests for random numbers in simulations. Phys. Rev. Lett. 73, 2513\u20132516 (1994).\n\nArticle ADS CAS PubMed Google Scholar\n\n  56. Boothby, K., Bunyk, P., Raymond, J., & Roy, A. Next-generation topology of D-Wave quantum processors. arXiv https://arxiv.org/abs/2003.00133 (2020).\n\n  57. Dabelow, L. & Ueda, M. Three learning stages and accuracy\u2013efficiency tradeoff of restricted Boltzmann machines. Nat. Commun. 13, 5474 (2022).\n\nArticle ADS CAS PubMed PubMed Central Google Scholar\n\n  58. Niazi, S. et al. Training deep Boltzmann networks with sparse Ising machines. arXiv https://arxiv.org/abs/2303.10728 (2023).\n\n  59. Yin, J. et al. Scalable Ising computer based on ultra-fast field-free spin orbit torque stochastic device with extreme 1-bit quantization. In 2022 International Electron Devices Meeting (IEDM), 36\u20131, IEEE (2022).\n\n  60. Lawrence, T. et al. ASAP7: a 7-nm FinFET predictive process design kit. Microelectron. J. 53, 105\u2013115 (2016).\n\nArticle Google Scholar\n\n  61. Misra, S. et al. Probabilistic neural computing with stochastic devices. Adv. Mater. 35, 2204569 (2022).\n\n  62. Preis, T., Virnau, P., Paul, W. & Schneider, J. J. GPU accelerated Monte Carlo simulation of the 2D and 3D Ising model. J. Comput. Phys. 228, 4468\u20134477 (2009).\n\nArticle ADS Google Scholar\n\n  63. Yang, K., Chen, Yi-Fan, Roumpos, G., Colby, C., & Anderson, J. High performance Monte Carlo simulation of Ising model on TPU clusters. In Proceedings of the international conference for high performance computing, networking, storage and analysis. 1\u201315 (2019).\n\n  64. Romero, J. et al. High performance implementations of the 2D Ising model on GPUs. Comput. Phys. Commun. 256, 107473 (2020).\n\nArticle MathSciNet CAS Google Scholar\n\nDownload references\n\n## Acknowledgements\n\nWe are grateful to Subhasish Mitra and Carlo Gilardi for discussions regarding\nLFSRs and high-level synthesis. We gratefully acknowledge Kevin Cao and Mishel\nJyothis Paul for their help with the configuration of ASAP7 PDK. We are\ngrateful to Shuvro Chowdhury for his comments on an earlier version of this\nmanuscript. The U.S. National Science Foundation (NSF) grant CCF 2106260, the\nOffice of Naval Research Young Investigator Program (YIP) grant, SAMSUNG\nGlobal Research Outreach (GRO) grant, and an NSF CAREER grant are acknowledged\nby N.S.S., Q.C., K.S., T.H., S.N., N.A.A., and K.Y.C. for supporting this\nresearch. Murata Science Foundation and Marubun Research Promotion Foundation\nare acknowledged by K.K. JST-CREST Grant No. JPMJCR19K3, JST-AdCORP Grant No.\nJPMJKB2305 and MEXT X-NICS Grant No. JPJ011438 are acknowledged by S.F. JST-\nPRESTO Grant No. JPMJPR21B2 is acknowledged by S.K.\n\n## Author information\n\nAuthor notes\n\n  1. These authors contributed equally: Nihal Sanjay Singh, Keito Kobayashi, Qixuan Cao.\n\n### Authors and Affiliations\n\n  1. Department of Electrical and Computer Engineering, University of California Santa Barbara, Santa Barbara, 93106, CA, USA\n\nNihal Sanjay Singh, Keito Kobayashi, Qixuan Cao, Kemal Selcuk, Tianrui Hu,\nShaila Niazi, Navid Anjum Aadit & Kerem Y. Camsari\n\n  2. Research Institute of Electrical Communication, Tohoku University, 2-1-1 Katahira, Aoba-ku, Sendai, 980-8577, Japan\n\nKeito Kobayashi, Shun Kanai, Hideo Ohno & Shunsuke Fukami\n\n  3. Graduate School of Engineering, Tohoku University, 6-6 Aramaki Aza Aoba, Aoba-ku, Sendai, 980-0845, Japan\n\nKeito Kobayashi, Shun Kanai & Shunsuke Fukami\n\n  4. WPI Advanced Institute for Materials Research (WPI-AIMR), Tohoku University, 2-1-1 Katahira, Aoba-ku, Sendai, 980-8577, Japan\n\nShun Kanai, Hideo Ohno & Shunsuke Fukami\n\n  5. Center for Science and Innovation in Spintronics (CSIS), Tohoku University, 2-1-1 Katahira, Aoba-ku, Sendai, 980-8577, Japan\n\nShun Kanai, Hideo Ohno & Shunsuke Fukami\n\n  6. PRESTO, Japan Science and Technology Agency (JST), Kawaguchi, 332-0012, Japan\n\nShun Kanai\n\n  7. Division for the Establishment of Frontier Sciences of Organization for Advanced Studies at Tohoku University, Tohoku University, Sendai, 980-8577, Japan\n\nShun Kanai\n\n  8. National Institutes for Quantum Science and Technology, Takasaki, 370-1207, Japan\n\nShun Kanai\n\n  9. Center for Innovative Integrated Electronic Systems (CIES), Tohoku University, 468-1 Aramaki Aza Aoba, Aoba-ku, Sendai, 980-0845, Japan\n\nHideo Ohno & Shunsuke Fukami\n\n  10. Inamori Research Institute of Science (InaRIS), Kyoto, 600-8411, Japan\n\nShunsuke Fukami\n\nAuthors\n\n  1. Nihal Sanjay Singh\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  2. Keito Kobayashi\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  3. Qixuan Cao\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  4. Kemal Selcuk\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  5. Tianrui Hu\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  6. Shaila Niazi\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  7. Navid Anjum Aadit\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  8. Shun Kanai\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  9. Hideo Ohno\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  10. Shunsuke Fukami\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n  11. Kerem Y. Camsari\n\nView author publications\n\nYou can also search for this author in PubMed Google Scholar\n\n### Contributions\n\nK.Y.C. and S.F. conceived and supervised the study. N.S.S. developed the ASAP7\nsynthesis flow, ran SPICE simulations, and performed circuit-level experiments\nwith sMTJs along with K.K., Q.C., and K.S. K.K., S.K., S.F., and H.O.\nfabricated sMTJs. K.K., Q.C., and S.K. ran the device-level sMTJ experiments.\nN.A.A., S.N., and T.H. have implemented the FPGA design for the learning and\ninference experiments. All authors have discussed the results and participated\nin writing and improving the manuscript.\n\n### Corresponding authors\n\nCorrespondence to Shunsuke Fukami or Kerem Y. Camsari.\n\n## Ethics declarations\n\n### Competing interests\n\nThe authors declare no competing Interests.\n\n## Peer review\n\n### Peer review information\n\nNature Communications thanks James Aimone and the other anonymous reviewer(s)\nfor their contribution to the peer review of this work. A peer review file is\navailable\n\n## Additional information\n\nPublisher\u2019s note Springer Nature remains neutral with regard to jurisdictional\nclaims in published maps and institutional affiliations.\n\n## Supplementary information\n\n### Supplementary Information\n\n### Peer Review File\n\n## Rights and permissions\n\nOpen Access This article is licensed under a Creative Commons Attribution 4.0\nInternational License, which permits use, sharing, adaptation, distribution\nand reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the\nCreative Commons licence, and indicate if changes were made. The images or\nother third party material in this article are included in the article\u2019s\nCreative Commons licence, unless indicated otherwise in a credit line to the\nmaterial. If material is not included in the article\u2019s Creative Commons\nlicence and your intended use is not permitted by statutory regulation or\nexceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder. To view a copy of this licence, visit\nhttp://creativecommons.org/licenses/by/4.0/.\n\nReprints and permissions\n\n## About this article\n\n### Cite this article\n\nSingh, N.S., Kobayashi, K., Cao, Q. et al. CMOS plus stochastic nanomagnets\nenabling heterogeneous computers for probabilistic inference and learning. Nat\nCommun 15, 2685 (2024). https://doi.org/10.1038/s41467-024-46645-6\n\nDownload citation\n\n  * Received: 03 November 2023\n\n  * Accepted: 05 March 2024\n\n  * Published: 27 March 2024\n\n  * DOI: https://doi.org/10.1038/s41467-024-46645-6\n\n### Share this article\n\nAnyone you share the following link with will be able to read this content:\n\nSorry, a shareable link is not currently available for this article.\n\nProvided by the Springer Nature SharedIt content-sharing initiative\n\n### Subjects\n\n  * Computational science\n  * Magnetic devices\n\n## Comments\n\nBy submitting a comment you agree to abide by our Terms and Community\nGuidelines. If you find something abusive or that does not comply with our\nterms or guidelines please flag it as inappropriate.\n\nDownload PDF\n\n## Associated content\n\nFocus\n\n### Devices\n\nAdvertisement\n\nNature Communications (Nat Commun) ISSN 2041-1723 (online)\n\n## nature.com sitemap\n\n### About Nature Portfolio\n\n  * About us\n  * Press releases\n  * Press office\n  * Contact us\n\n### Discover content\n\n  * Journals A-Z\n  * Articles by subject\n  * protocols.io\n  * Nature Index\n\n### Publishing policies\n\n  * Nature portfolio policies\n  * Open access\n\n### Author & Researcher services\n\n  * Reprints & permissions\n  * Research data\n  * Language editing\n  * Scientific editing\n  * Nature Masterclasses\n  * Research Solutions\n\n### Libraries & institutions\n\n  * Librarian service & tools\n  * Librarian portal\n  * Open research\n  * Recommend to library\n\n### Advertising & partnerships\n\n  * Advertising\n  * Partnerships & Services\n  * Media kits\n  * Branded content\n\n### Professional development\n\n  * Nature Careers\n  * Nature Conferences\n\n### Regional websites\n\n  * Nature Africa\n  * Nature China\n  * Nature India\n  * Nature Italy\n  * Nature Japan\n  * Nature Middle East\n\n  * Privacy Policy\n  * Use of cookies\n  * Legal notice\n  * Accessibility statement\n  * Terms & Conditions\n  * Your US state privacy rights\n  * Cancel contracts here\n\n\u00a9 2024 Springer Nature Limited\n\nSign up for the Nature Briefing: AI and Robotics newsletter \u2014 what matters in\nAI and robotics research, free to your inbox weekly.\n\nGet the most important science stories of the day, free in your inbox. Sign up\nfor Nature Briefing: AI and Robotics\n\n", "frontpage": false}
