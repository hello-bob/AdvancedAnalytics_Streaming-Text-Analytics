{"aid": "40096310", "title": "Making Gaussian Splats Smaller", "url": "https://aras-p.info/blog/2023/09/13/Making-Gaussian-Splats-smaller/", "domain": "aras-p.info", "votes": 1, "user": "fanf2", "posted_at": "2024-04-20 10:42:04", "comments": 0, "source_title": "Making Gaussian Splats smaller", "source_text": "Making Gaussian Splats smaller \u00b7 Aras' website\n\nSubscribe Home Blog Talks Papers Projects\n\n# Making Gaussian Splats smaller\n\nPosted on Sep 13, 2023\n\n#rendering #code #gpu\n\nIn the previous post I started to look at Gaussian Splatting. One of the\nissues with it, is that the data sets are not exactly small. The renders look\nnice:\n\nBut each of the \u201cbike\u201d, \u201ctruck\u201d, \u201cgarden\u201d data sets is respectively a 1.42GB,\n0.59GB, 1.35GB PLY file. And they are loaded pretty much as-is into GPU memory\nas giant structured buffers, so at least that much VRAM is needed too (plus\nmore for sorting, plus in the official viewer implementation the tiled splat\nrasterizer uses some-hundreds-of-MB).\n\nI could tell you that I can make the data 19x smaller (78, 32, 74 MB\nrespectively), but then it looks not that great. Still recognizable, but\nreally not good (however, the artifacts are not your typical \u201cpolygonal mesh\nrendering at low LOD\u201d, they are more like \u201cJPG artifacts in space\"):\n\nHowever, in between these two extremes there are other configurations, that\nmake the data 5x-10x smaller while looking quite okay.\n\nSo we are starting at 248 bytes for each splat, and we want to get that down.\nNote: everywhere here I will be exploring both storage and runtime memory\nusage, i.e. not \u201cfile compression\u201d! Rather, I want to cut down on GPU memory\nconsumption too. Getting runtime data smaller also makes the data on disk\nsmaller as a side effect, but \u201cstorage size\u201d is a whole another and partially\nindependent topic. Maybe for some other day!\n\nOne obvious and easy thing to do with the splat data, is to notice that the\n\u201cnormal\u201d (12 bytes) is completely unused. That does not save much though. Then\nyou can of course try making all the numbers be Float16 instead of Float32,\nthis is acceptably good but only makes the data 2x smaller.\n\nYou could also throw away all the spherical harmonics data and leave only the\n\u201cbase color\u201d (i.e. SH0), and that would cut down 75% of the data size! This\ndoes change the lighting and removes some \u201creflections\u201d, and is more visible\nin motion, but progressively dropping SH bands with lower quality levels (or\nprogressively loading them in) is easy and sensible.\n\nSo of course, let\u2019s look at what else we can do :)\n\n#### Reorder and cut into chunks\n\nThe ordering of splats inside the data file does not matter; we are going to\nsort them by distance at rendering time anyway. In the PLY data file they are\neffectively random (each point here is one splat, and color is gradient based\non the point index):\n\nBut we could reorder them based on \u201clocality\u201d (or any other criteria). For\nexample, ordering them in a 3D Morton order, generally, makes nearby points in\nspace be near each other inside the data array:\n\nAnd then, I can group splats into chunks of N (N=256 was my choice), and hope\nthat since they would generally be close together, maybe they have lower\nvariance of their data, or at least their data can be somehow represented in\nfewer bits. If I visualize the chunk bounding boxes, they are generally small\nand scattered all over the scene:\n\nThis is pretty much slides 112-113 of \u201cLearning from Failure\u201d Dreams talk.\n\n> Future work: try Hilbert curve ordering instead of Morton. Also try\n> \u201cpartially filled chunks\u201d to break up large chunk bounds, that happen\n> whenever the Morton curve flips to the other side.\n\nBy the way, Morton reordering can also make the rendering faster, since even\nafter sorting by distance the nearby points are more likely to be nearby in\nthe original data array. And of course, nice code to do Morton calculations\nwithout relying on BMI or similar CPU instructions can be found on Fabian\u2019s\nblog, adapted here for 64 bit result case:\n\n    \n    \n    // Based on https://fgiesen.wordpress.com/2009/12/13/decoding-morton-codes/ // Insert two 0 bits after each of the 21 low bits of x static ulong MortonPart1By2(ulong x) { x &= 0x1fffff; x = (x ^ (x << 32)) & 0x1f00000000ffffUL; x = (x ^ (x << 16)) & 0x1f0000ff0000ffUL; x = (x ^ (x << 8)) & 0x100f00f00f00f00fUL; x = (x ^ (x << 4)) & 0x10c30c30c30c30c3UL; x = (x ^ (x << 2)) & 0x1249249249249249UL; return x; } // Encode three 21-bit integers into 3D Morton order public static ulong MortonEncode3(uint3 v) { return (MortonPart1By2(v.z) << 2) | (MortonPart1By2(v.y) << 1) | MortonPart1By2(v.x); }\n\n#### Make all data 0..1 relative to the chunk\n\nNow that all the splats are cut into 256-splat size chunks, we can compute\nminimum and maximum data values of everything (positions, scales, colors, SHs\netc.) for each chunk, and store that away. We don\u2019t care about data size of\nthat (yet?); just store them in full floats.\n\nAnd now, adjust the splat data so that all the numbers are in 0..1 range\nbetween chunk minimum & maximum values. If that is kept in Float32 as it was\nbefore, then this does not really change precision in any noticeable way, just\nadds a bit of indirection inside the rendering shader (to figure out final\nsplat data, you need to fetch chunk min & max, and interpolate between those\nbased on splat values).\n\nOh, and for rotations, I\u2019m encoding the quaternions in \u201csmallest three\u201d format\n(store smallest 3 components, plus index of which component was the largest).\n\nAnd now that the data is all in 0..1 range, we can try representing it with\nsmaller data types than full Float32!\n\nBut first, how does all that 0..1 data look like? The following is various\ndata displayed as RGB colors, one pixel per splat, in row major order. With\npositions, you can clearly see that it changes within the 256 sized chunk\n(it\u2019s two chunks per horizontal line):\n\nRotations do have some horizontal streaks but are way more random:\n\nScale has some horizontal patterns too, but we can also see that most of\nscales are towards smaller values:\n\nColor (SH0) is this:\n\nAnd opacity is often either almost transparent, or almost opaque:\n\nThere\u2019s a lot of spherical harmonics bands and they tend to look like a\nsimilar mess, so here\u2019s one of them:\n\n#### Hey this data looks a lot like textures!\n\nWe\u2019ve got 3 or 4 values per each \u201cthing\u201d (position, color, rotation, ...) that\nare all in 0..1 range now. I know! Let\u2019s put them into textures, one texel per\nsplat. And then we can easily experiment with using various texture formats on\nthem, and have the GPU texture sampling hardware do all the heavy lifting of\nturning the data into numbers.\n\nWe could even, I dunno, use something crazy like use compressed texture\nformats (e.g. BC1 or BC7) on these textures. Would that work well? Turns out,\nnot immediately. Here\u2019s turning all the data (position, rotation, scale,\ncolor/opacity, SH) into BC7 compressed texture. Data is just 122MB (12x\nsmaller), but PSNR is a low 21.71 compared to full Float32 data:\n\nHowever, we know that GPU texture compression formats are block based, e.g. on\ntypical PC the BCn compression formats are all based on 4x4 texel blocks. But\nour texture data is laid out in 256x1 stripes of splat chunks, one after\nanother. Let\u2019s reorder them some more, i.e. lay out each chunk in a 16x16\ntexel square, again arranged in Morton order within it.\n\n    \n    \n    uint EncodeMorton2D_16x16(uint2 c) { uint t = ((c.y & 0xF) << 8) | (c.x & 0xF); // ----EFGH----ABCD t = (t ^ (t << 2)) & 0x3333; // --EF--GH--AB--CD t = (t ^ (t << 1)) & 0x5555; // -E-F-G-H-A-B-C-D return (t | (t >> 7)) & 0xFF; // --------EAFBGCHD } uint2 DecodeMorton2D_16x16(uint t) // --------EAFBGCHD { t = (t & 0xFF) | ((t & 0xFE) << 7); // -EAFBGCHEAFBGCHD t &= 0x5555; // -E-F-G-H-A-B-C-D t = (t ^ (t >> 1)) & 0x3333; // --EF--GH--AB--CD t = (t ^ (t >> 2)) & 0x0f0f; // ----EFGH----ABCD return uint2(t & 0xF, t >> 8); // --------EFGHABCD }\n\nAnd if we rearrange all the texture data that way, then it looks like this now\n(position, rotation, scale, color, opacity, SH1):\n\nAnd encoding all that into BC7 improves the quality quite a bit (PSNR\n21.71\u219224.18):\n\n#### So what texture formats should be used?\n\nAfter playing around with a whole bunch of possible settings, here\u2019s the\nquality setting levels I came up with. Formats indicated in the table below:\n\n  * F32x4: 4x Float32 (128 bits). Since GPUs typically do not have a three-channel Float32 texture format, I expand the data quite uselessly in this case, when only three components are needed.\n  * F16x4: 4x Float16 (64 bits). Similar expansion to 4 components as above.\n  * Norm10_2: unsigned normalized 10.10.10.2 (32 bits). GPUs do support this, and Unity almost supports it \u2013 it exposes the format enum member, but actually does not allow you to create texture with said format (lol!). So I emulate it by pretending the texture is in a single component Float32 format, and manually \u201cunpack\u201d in the shader.\n  * Norm11: unsigned normalized 11.10.11 (32 bits). GPUs do not have it, but since I\u2019m emulating a similar format anyway (see above), then why not use more bits when we only need three components.\n  * Norm8x4: 4x unsigned normalized byte (32 bits).\n  * Norm565: unsigned normalized 5.6.5 (16 bits).\n  * BC7 and BC1: obvious, 8 and 4 bits respectively.\n\nQuality| Pos| Rot| Scl| Col| SH| Compr| PSNR  \n---|---|---|---|---|---|---|---  \nVery High| F32x4| F32x4| F32x4| F32x4| F32x4| 0.8x  \nHigh| F16x4| Norm10_2| Norm11| F16x4| Norm11| 2.9x| 54.82  \nMedium| Norm11| Norm10_2| Norm11| Norm8x4| Norm565| 5.2x| 47.82  \nLow| Norm11| Norm10_2| Norm565| BC7| BC1| 12.2x| 34.79  \nVery Low| BC7| BC7| BC7| BC7| BC1| 18.7x| 24.02  \n  \nHere are the \u201creference\u201d (\u201cVery High\u201d) images again (1.42GB, 0.59GB, 1.35GB\ndata size):\n\nThe \u201cMedium\u201d preset looks pretty good! (280MB, 116MB, 267MB \u2013 5.2x smaller;\nPSNR respectively 47.82, 48.73, 48.63):\n\nAt \u201cLow\u201d preset the color artifacts are more visible but not terribad (119MB,\n49MB, 113MB \u2013 12.2x smaller; PSNR respectively 34.72, 31.81, 33.05):\n\nAnd the \u201cVery Low\u201d one mostly for reference; it kinda becomes useless at such\nlow quality (74MB, 32MB, 74MB \u2013 18.7x smaller; PSNR 24.02, 22.28, 23.1):\n\nOh, and I also recorded an awkwardly-moving-camera video, since people like\nmoving pictures:\n\n#### Conclusions and future work\n\nThe gaussian splatting data size (both on-disk and in-memory) can be fairly\neasily cut down 5x-12x, at fairly acceptable rendering quality level. Say, for\nthat \u201cgarden\u201d scene 1.35GB data file is \u201ceek, sounds a bit excessive\u201d, but at\n110-260MB it\u2019s becoming more interesting. Definitely not small yet, but way\nmore within being usable.\n\nI think the idea of arranging the splat data \u201csomehow\u201d, and then compressing\nthem not by just individually encoding each spat into smaller amount of bits,\nbut also \u201cwithin neighbors\u201d (like using BC7 or BC1), is interesting. Spherical\nHarmonics data in particular looks quite ok even with BC1 compression (it\nhelps that unlike \u201cobviously wrong\u201d rotation or scale, it\u2019s much harder to\ntell when your spherical harmonics coefficient is wrong :)).\n\nThere\u2019s a bunch of small things I could try:\n\n  * Splat reordering: reorder splats not only based on position, but also based on \u201csomething else\u201d. Try Hilbert curve instead of Morton. Try using not-fully-256 size chunks whenever the curve flips to the other side.\n  * Color/Opacity encoding: maybe it\u2019s worth putting that into two separate textures, instead of trying to get BC7 to compress them both.\n  * I do wonder how would reducing the texture resolution work, maybe for some components (spherical harmonics? color if opacity is separate?) you could use lower resolution texture, i.e. below 1 texel per splat.\n\nAnd then of course there are larger questions, in a sense of whether this way\nlooking at reducing data size is sensible at all. Maybe something along the\nlines of \u201cRandom-Access Neural Compression of Material Textures\u201d\n(Vaidyanathan, Salvi, Wronski 2023) would work? If only I knew anything about\nthis \u201cneural/ML\u201d thing :)\n\nAll my code for the above is in this PR on github (merged 2023 Sep).\n\nIn the followup post I look at making them even smaller!\n\n  * \u2190 Older\n  * Newer \u2192\n\n##### Possibly Related Posts\n\n  * Gaussian explosion, from 2023 December\n  * Making Gaussian Splats more smaller, from 2023 September\n  * Gaussian Splatting is pretty cool!, from 2023 September\n\n### Recent Posts\n\n  * I accidentally Blender VSE\n  * Two years ago: left Unity\n  * Gaussian explosion\n  * Making Gaussian Splats more smaller\n  * Making Gaussian Splats smaller\n  * Gaussian Splatting is pretty cool!\n  * Float Compression 9: LZSSE and Lizard\n\n##### All Posts\n\n### Categories\n\n  * blender (5)\n  * code (124)\n  * compilers (16)\n  * conferences (10)\n  * d3d (20)\n  * demos (39)\n  * devtools (22)\n  * energy (1)\n  * games (20)\n  * giving (3)\n  * gpu (44)\n  * mobile (7)\n  * opengl (19)\n  * papers (12)\n  * performance (42)\n  * personal (13)\n  * random (65)\n  * rant (54)\n  * rendering (63)\n  * travel (6)\n  * unity (63)\n  * vulkan (3)\n  * web (2)\n  * work (64)\n\nText content \u00a9 Aras Pranckevi\u010dius. Code snippets are public domain, unless\nspecified otherwise.\n\n", "frontpage": false}
