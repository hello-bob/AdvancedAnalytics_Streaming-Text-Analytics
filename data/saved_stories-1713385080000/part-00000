{"aid": "40064951", "title": "A Practice Support System Using an Accelerometer to Reduce Preliminary Actions", "url": "https://www.mdpi.com/1424-8220/24/7/2306", "domain": "mdpi.com", "votes": 1, "user": "PaulHoule", "posted_at": "2024-04-17 14:16:09", "comments": 0, "source_title": "KARATECH: A Practice Support System Using an Accelerometer to Reduce the Preliminary Actions of Karate", "source_text": "Sensors | Free Full-Text | KARATECH: A Practice Support System Using an Accelerometer to Reduce the Preliminary Actions of Karate\n\nLoading web-font Gyre-Pagella/Normal/Regular\n\n  * Consent\n  * Details\n  * [#IABV2SETTINGS#]\n  * About\n\n## This website uses cookies\n\nWe use cookies to personalise content and ads, to provide social media\nfeatures and to analyse our traffic. We also share information about your use\nof our site with our social media, advertising and analytics partners who may\ncombine it with other information that you\u2019ve provided to them or that they\u2019ve\ncollected from your use of their services.\n\nShow details\n\n  * Necessary cookies help make a website usable by enabling basic functions like page navigation and access to secure areas of the website. The website cannot function properly without these cookies.\n\n    * Cookiebot\n\n1\n\nLearn more about this provider\n\n1.gifUsed to count the number of sessions to the website, necessary for\noptimizing CMP product delivery.\n\nExpiry: SessionType: Pixel\n\n    * Crazyegg\n\n2\n\nLearn more about this provider\n\n_ce.cchStores the user's cookie consent state for the current domain\n\nExpiry: SessionType: HTTP\n\nce_successful_csp_checkDetects whether user behaviour tracking should be\nactive on the website.\n\nExpiry: PersistentType: HTML\n\n    * Google\n\n1\n\nLearn more about this provider\n\ntest_cookieUsed to check if the user's browser supports cookies.\n\nExpiry: 1 dayType: HTTP\n\n    * LinkedIn\n\n2\n\nLearn more about this provider\n\nli_gcStores the user's cookie consent state for the current domain\n\nExpiry: 180 daysType: HTTP\n\nbscookieThis cookie is used to identify the visitor through an application.\nThis allows the visitor to login to a website through their LinkedIn\napplication for example.\n\nExpiry: 1 yearType: HTTP\n\n    * commenting.mdpi.com\n\n2\n\nSESS#Preserves users states across page requests.\n\nExpiry: SessionType: HTTP\n\nXSRF-TOKENEnsures visitor browsing-security by preventing cross-site request\nforgery. This cookie is essential for the security of the website and visitor.\n\nExpiry: SessionType: HTTP\n\n    * commenting.mdpi.com consent.cookiebot.com\n\n2\n\nCookieConsent [x2]Stores the user's cookie consent state for the current\ndomain\n\nExpiry: 1 yearType: HTTP\n\n    * matomo.mdpi.com\n\n1\n\n_pk_testcookie_domainThis cookie determines whether the browser accepts\ncookies.\n\nExpiry: 1 dayType: HTTP\n\n    * mdpi.com\n\n3\n\n__cfruidThis cookie is a part of the services provided by Cloudflare -\nIncluding load-balancing, deliverance of website content and serving DNS\nconnection for website operators.\n\nExpiry: SessionType: HTTP\n\ncf_clearanceThis cookie is used to distinguish between humans and bots.\n\nExpiry: 1 yearType: HTTP\n\nMDPIPHPSESSIDPending\n\nExpiry: SessionType: HTTP\n\n    * mdpi.com mdpi.org mdpi-res.com sciprofiles.com\n\n4\n\n__cf_bm [x4]This cookie is used to distinguish between humans and bots. This\nis beneficial for the website, in order to make valid reports on the use of\ntheir website.\n\nExpiry: 1 dayType: HTTP\n\n    * www.jisc.ac.uk\n\n2\n\nAWSALBRegisters which server-cluster is serving the visitor. This is used in\ncontext with load balancing, in order to optimize user experience.\n\nExpiry: 7 daysType: HTTP\n\nAWSALBCORSRegisters which server-cluster is serving the visitor. This is used\nin context with load balancing, in order to optimize user experience.\n\nExpiry: 7 daysType: HTTP\n\n    * www.mdpi.com\n\n7\n\ncf_chl_1This cookie is a part of the services provided by Cloudflare -\nIncluding load-balancing, deliverance of website content and serving DNS\nconnection for website operators.\n\nExpiry: 1 dayType: HTTP\n\niconify0Used by the website's content management system (CMS) to determine how\nthe website's menu-tabs should be displayed.\n\nExpiry: PersistentType: HTML\n\niconify1This cookie is set to ensure proper product displays on the website.\n\nExpiry: PersistentType: HTML\n\niconify2Used by the website's content management system (CMS) to determine how\nthe website's menu-tabs should be displayed.\n\nExpiry: PersistentType: HTML\n\niconify3Determines the device used to access the website. This allows the\nwebsite to be formatted accordingly.\n\nExpiry: PersistentType: HTML\n\niconify-countUsed by the website's content management system (CMS) to\ndetermine how the website's menu-tabs should be displayed.\n\nExpiry: PersistentType: HTML\n\niconify-versionUsed by the website's content management system (CMS) to\ndetermine how the website's menu-tabs should be displayed.\n\nExpiry: PersistentType: HTML\n\n  * Preference cookies enable a website to remember information that changes the way the website behaves or looks, like your preferred language or the region that you are in.\n\n    * LinkedIn\n\n1\n\nLearn more about this provider\n\nlidcRegisters which server-cluster is serving the visitor. This is used in\ncontext with load balancing, in order to optimize user experience.\n\nExpiry: 1 dayType: HTTP\n\n    * www.mdpi.com\n\n2\n\nmdpi_layout_typeThis cookie is used to store user setting of using fixed\ndesktop layout instead of the default responsive layout\n\nExpiry: 1 yearType: HTTP\n\nsettingsThis cookie is used to determine the preferred language of the visitor\nand sets the language accordingly on the website, if possible.\n\nExpiry: PersistentType: HTML\n\n  * Statistic cookies help website owners to understand how visitors interact with websites by collecting and reporting information anonymously.\n\n    * Crazyegg\n\n8\n\nLearn more about this provider\n\n_ce.clock_dataCollects data on the user\u2019s navigation and behavior on the\nwebsite. This is used to compile statistical reports and heatmaps for the\nwebsite owner.\n\nExpiry: 1 dayType: HTTP\n\n_ce.clock_eventCollects data on the user\u2019s navigation and behavior on the\nwebsite. This is used to compile statistical reports and heatmaps for the\nwebsite owner.\n\nExpiry: 1 dayType: HTTP\n\n_ce.gtldHolds which URL should be presented to the visitor when visiting the\nsite.\n\nExpiry: SessionType: HTTP\n\n_ce.sCollects data on the user\u2019s navigation and behavior on the website. This\nis used to compile statistical reports and heatmaps for the website owner.\n\nExpiry: 1 yearType: HTTP\n\ncebsTracks the individual sessions on the website, allowing the website to\ncompile statistical data from multiple visits. This data can also be used to\ncreate leads for marketing purposes.\n\nExpiry: SessionType: HTTP\n\ncebsp_Collects data on the user\u2019s navigation and behavior on the website. This\nis used to compile statistical reports and heatmaps for the website owner.\n\nExpiry: SessionType: HTTP\n\nce_fvdCollects data on the user\u2019s navigation and behavior on the website. This\nis used to compile statistical reports and heatmaps for the website owner.\n\nExpiry: PersistentType: HTML\n\ncetabidSets a unique ID for the session. This allows the website to obtain\ndata on visitor behaviour for statistical purposes.\n\nExpiry: SessionType: HTML\n\n    * Google\n\n5\n\nLearn more about this provider\n\ncollectUsed to send data to Google Analytics about the visitor's device and\nbehavior. Tracks the visitor across devices and marketing channels.\n\nExpiry: SessionType: Pixel\n\n_gaRegisters a unique ID that is used to generate statistical data on how the\nvisitor uses the website.\n\nExpiry: 2 yearsType: HTTP\n\n_ga_#Used by Google Analytics to collect data on the number of times a user\nhas visited the website as well as dates for the first and most recent visit.\n\nExpiry: 2 yearsType: HTTP\n\n_gatUsed by Google Analytics to throttle request rate\n\nExpiry: 1 dayType: HTTP\n\n_gidRegisters a unique ID that is used to generate statistical data on how the\nvisitor uses the website.\n\nExpiry: 1 dayType: HTTP\n\n    * Hotjar\n\n5\n\nLearn more about this provider\n\nhjActiveViewportIdsThis cookie contains an ID string on the current session.\nThis contains non-personal information on what subpages the visitor enters \u2013\nthis information is used to optimize the visitor's experience.\n\nExpiry: PersistentType: HTML\n\nhjViewportIdSaves the user's screen size in order to adjust the size of images\non the website.\n\nExpiry: SessionType: HTML\n\n_hjSession_#Collects statistics on the visitor's visits to the website, such\nas the number of visits, average time spent on the website and what pages have\nbeen read.\n\nExpiry: 1 dayType: HTTP\n\n_hjSessionUser_#Collects statistics on the visitor's visits to the website,\nsuch as the number of visits, average time spent on the website and what pages\nhave been read.\n\nExpiry: 1 yearType: HTTP\n\n_hjTLDTestRegisters statistical data on users' behaviour on the website. Used\nfor internal analytics by the website operator.\n\nExpiry: SessionType: HTTP\n\n    * LinkedIn\n\n1\n\nLearn more about this provider\n\nAnalyticsSyncHistoryUsed in connection with data-synchronization with third-\nparty analysis service.\n\nExpiry: 30 daysType: HTTP\n\n    * Twitter Inc.\n\n1\n\nLearn more about this provider\n\npersonalization_idThis cookie is set by Twitter - The cookie allows the\nvisitor to share content from the website onto their Twitter profile.\n\nExpiry: 400 daysType: HTTP\n\n    * matomo.mdpi.com\n\n2\n\n_pk_id#Collects statistics on the user's visits to the website, such as the\nnumber of visits, average time spent on the website and what pages have been\nread.\n\nExpiry: 1 yearType: HTTP\n\n_pk_ses#Used by Piwik Analytics Platform to track page requests from the\nvisitor during the session.\n\nExpiry: 1 dayType: HTTP\n\n    * www.mdpi.com\n\n1\n\nsentryReplaySessionRegisters data on visitors' website-behaviour. This is used\nfor internal analysis and website optimization.\n\nExpiry: SessionType: HTML\n\n  * Marketing cookies are used to track visitors across websites. The intention is to display ads that are relevant and engaging for the individual user and thereby more valuable for publishers and third party advertisers.\n\n    * Meta Platforms, Inc.\n\n3\n\nLearn more about this provider\n\nlastExternalReferrerDetects how the user reached the website by registering\ntheir last URL-address.\n\nExpiry: PersistentType: HTML\n\nlastExternalReferrerTimeDetects how the user reached the website by\nregistering their last URL-address.\n\nExpiry: PersistentType: HTML\n\n_fbpUsed by Facebook to deliver a series of advertisement products such as\nreal time bidding from third party advertisers.\n\nExpiry: 3 monthsType: HTTP\n\n    * Google\n\n2\n\nLearn more about this provider\n\npagead/1p-user-list/#Tracks if the user has shown interest in specific\nproducts or events across multiple websites and detects how the user navigates\nbetween sites. This is used for measurement of advertisement efforts and\nfacilitates payment of referral-fees between websites.\n\nExpiry: SessionType: Pixel\n\ntdRegisters statistical data on users' behaviour on the website. Used for\ninternal analytics by the website operator.\n\nExpiry: SessionType: Pixel\n\n    * LinkedIn\n\n4\n\nLearn more about this provider\n\nbcookieUsed by the social networking service, LinkedIn, for tracking the use\nof embedded services.\n\nExpiry: 1 yearType: HTTP\n\nli_sugrCollects data on user behaviour and interaction in order to optimize\nthe website and make advertisement on the website more relevant.\n\nExpiry: 3 monthsType: HTTP\n\nUserMatchHistoryEnsures visitor browsing-security by preventing cross-site\nrequest forgery. This cookie is essential for the security of the website and\nvisitor.\n\nExpiry: 30 daysType: HTTP\n\nli_adsIdCollects data on user behaviour and interaction in order to optimize\nthe website and make advertisement on the website more relevant.\n\nExpiry: PersistentType: HTML\n\n    * Twitter Inc.\n\n3\n\nLearn more about this provider\n\ni/adsct [x2]The cookie is used by Twitter.com in order to determine the number\nof visitors accessing the website through Twitter advertisement content.\n\nExpiry: SessionType: Pixel\n\nmuc_adsCollects data on user behaviour and interaction in order to optimize\nthe website and make advertisement on the website more relevant.\n\nExpiry: 400 daysType: HTTP\n\n    * YouTube\n\n22\n\nLearn more about this provider\n\n#-#Pending\n\nExpiry: SessionType: HTML\n\niU5q-!O9@$Registers a unique ID to keep statistics of what videos from YouTube\nthe user has seen.\n\nExpiry: SessionType: HTML\n\nLAST_RESULT_ENTRY_KEYUsed to track user\u2019s interaction with embedded content.\n\nExpiry: SessionType: HTTP\n\nLogsDatabaseV2:V#||LogsRequestsStorePending\n\nExpiry: PersistentType: IDB\n\nnextIdUsed to track user\u2019s interaction with embedded content.\n\nExpiry: SessionType: HTTP\n\nremote_sidNecessary for the implementation and functionality of YouTube video-\ncontent on the website.\n\nExpiry: SessionType: HTTP\n\nrequestsUsed to track user\u2019s interaction with embedded content.\n\nExpiry: SessionType: HTTP\n\nServiceWorkerLogsDatabase#SWHealthLogNecessary for the implementation and\nfunctionality of YouTube video-content on the website.\n\nExpiry: PersistentType: IDB\n\nTESTCOOKIESENABLEDUsed to track user\u2019s interaction with embedded content.\n\nExpiry: 1 dayType: HTTP\n\nVISITOR_INFO1_LIVETries to estimate the users' bandwidth on pages with\nintegrated YouTube videos.\n\nExpiry: 180 daysType: HTTP\n\nVISITOR_PRIVACY_METADATAStores the user's cookie consent state for the current\ndomain\n\nExpiry: 180 daysType: HTTP\n\nYSCRegisters a unique ID to keep statistics of what videos from YouTube the\nuser has seen.\n\nExpiry: SessionType: HTTP\n\nyt.innertube::nextIdRegisters a unique ID to keep statistics of what videos\nfrom YouTube the user has seen.\n\nExpiry: PersistentType: HTML\n\nytidb::LAST_RESULT_ENTRY_KEYStores the user's video player preferences using\nembedded YouTube video\n\nExpiry: PersistentType: HTML\n\nYtIdbMeta#databasesUsed to track user\u2019s interaction with embedded content.\n\nExpiry: PersistentType: IDB\n\nyt-remote-cast-availableStores the user's video player preferences using\nembedded YouTube video\n\nExpiry: SessionType: HTML\n\nyt-remote-cast-installedStores the user's video player preferences using\nembedded YouTube video\n\nExpiry: SessionType: HTML\n\nyt-remote-connected-devicesStores the user's video player preferences using\nembedded YouTube video\n\nExpiry: PersistentType: HTML\n\nyt-remote-device-idStores the user's video player preferences using embedded\nYouTube video\n\nExpiry: PersistentType: HTML\n\nyt-remote-fast-check-periodStores the user's video player preferences using\nembedded YouTube video\n\nExpiry: SessionType: HTML\n\nyt-remote-session-appStores the user's video player preferences using embedded\nYouTube video\n\nExpiry: SessionType: HTML\n\nyt-remote-session-nameStores the user's video player preferences using\nembedded YouTube video\n\nExpiry: SessionType: HTML\n\n    * cdn.pbgrd.com\n\n2\n\npagead/gen_204Collects data on visitor behaviour from multiple websites, in\norder to present more relevant advertisement - This also allows the website to\nlimit the number of times that they are shown the same advertisement.\n\nExpiry: SessionType: Pixel\n\ncsiCollects data on visitors' preferences and behaviour on the website - This\ninformation is used make content and advertisement more relevant to the\nspecific visitor.\n\nExpiry: SessionType: Pixel\n\n    * pub.mdpi-res.com\n\n1\n\nOAIDRegisters a unique ID that identifies a returning user's device. The ID is\nused for targeted ads.\n\nExpiry: 1 yearType: HTTP\n\n  * Unclassified cookies are cookies that we are in the process of classifying, together with the providers of individual cookies.\n\n    * Crazyegg\n\n1\n\nLearn more about this provider\n\n_ce.irvPending\n\nExpiry: SessionType: HTTP\n\n    * matomo.mdpi.com\n\n1\n\n_pk_hsr.0.01efPending\n\nExpiry: 1 dayType: HTTP\n\n    * www.mdpi.com\n\n3\n\nhypothesis.testKeyPending\n\nExpiry: PersistentType: HTML\n\nmdpi_layout_type_v2Pending\n\nExpiry: 1 yearType: HTTP\n\nsettings_cachedPending\n\nExpiry: SessionType: HTTP\n\nCross-domain consent[#BULK_CONSENT_DOMAINS_COUNT#] [#BULK_CONSENT_TITLE#]\n\nList of domains your consent applies to: [#BULK_CONSENT_DOMAINS#]\n\nCookie declaration last updated on 3/25/24 by Cookiebot\n\n## [#IABV2_TITLE#]\n\n[#IABV2_BODY_INTRO#]\n\n[#IABV2_BODY_LEGITIMATE_INTEREST_INTRO#]\n\n[#IABV2_BODY_PREFERENCE_INTRO#]\n\n[#IABV2_BODY_PURPOSES_INTRO#]\n\n[#IABV2_BODY_PURPOSES#]\n\n[#IABV2_BODY_FEATURES_INTRO#]\n\n[#IABV2_BODY_FEATURES#]\n\n[#IABV2_BODY_PARTNERS_INTRO#]\n\n[#IABV2_BODY_PARTNERS#]\n\nCookies are small text files that can be used by websites to make a user's\nexperience more efficient.\n\nThe law states that we can store cookies on your device if they are strictly\nnecessary for the operation of this site. For all other types of cookies we\nneed your permission.\n\nThis site uses different types of cookies. Some cookies are placed by third\nparty services that appear on our pages.\n\nYou can at any time change or withdraw your consent from the Cookie\nDeclaration on our website.\n\nLearn more about who we are, how you can contact us and how we process\npersonal data in our Privacy Policy.\n\nPlease state your consent ID and date when you contact us regarding your\nconsent.\n\nPowered by Cookiebot by Usercentrics\n\nNext Article in Journal\n\nDiscussion and Demonstration of RF-MEMS Attenuators Design Concepts and\nModules for Advanced Beamforming in the Beyond-5G and 6G Scenario\u2014Part 1\n\nPrevious Article in Journal\n\nA Two-Step Regional Ionospheric Modeling Approach for PPP-RTK\n\nPrevious Article in Special Issue\n\nDistributed IMU Sensors for In-Field Dynamic Measurements on an Alpine Ski\n\n## Journals\n\nActive Journals Find a Journal Proceedings Series\n\n## Topics\n\n## Information\n\nFor Authors For Reviewers For Editors For Librarians For Publishers For\nSocieties For Conference Organizers\n\nOpen Access Policy Institutional Open Access Program Special Issues Guidelines\nEditorial Process Research and Publication Ethics Article Processing Charges\nAwards Testimonials\n\n## Author Services\n\n## Initiatives\n\nSciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS\nProceedings Series\n\n## About\n\nOverview Contact Careers News Press Blog\n\nSign In / Sign Up\n\n## Notice\n\nclear\n\n## Notice\n\nYou are accessing a machine-readable page. In order to be human-readable,\nplease install an RSS reader.\n\nContinue Cancel\n\nclear\n\nAll articles published by MDPI are made immediately available worldwide under\nan open access license. No special permission is required to reuse all or part\nof the article published by MDPI, including figures and tables. For articles\npublished under an open access Creative Common CC BY license, any part of the\narticle may be reused without permission provided that the original article is\nclearly cited. For more information, please refer to\nhttps://www.mdpi.com/openaccess.\n\nFeature papers represent the most advanced research with significant potential\nfor high impact in the field. A Feature Paper should be a substantial original\nArticle that involves several techniques or approaches, provides an outlook\nfor future research directions and describes possible research applications.\n\nFeature papers are submitted upon individual invitation or recommendation by\nthe scientific editors and must receive positive feedback from the reviewers.\n\nEditor\u2019s Choice articles are based on recommendations by the scientific\neditors of MDPI journals from around the world. Editors select a small number\nof articles recently published in the journal that they believe will be\nparticularly interesting to readers, or important in the respective research\narea. The aim is to provide a snapshot of some of the most exciting work\npublished in the various research areas of the journal.\n\nOriginal Submission Date Received: .\n\n  * Journals\n\n    *       * Active Journals\n      * Find a Journal\n      * Proceedings Series\n\n  * Topics\n  * Information\n\n    *       * For Authors\n      * For Reviewers\n      * For Editors\n      * For Librarians\n      * For Publishers\n      * For Societies\n      * For Conference Organizers\n\n      * Open Access Policy\n      * Institutional Open Access Program\n      * Special Issues Guidelines\n      * Editorial Process\n      * Research and Publication Ethics\n      * Article Processing Charges\n      * Awards\n      * Testimonials\n\n  * Author Services\n  * Initiatives\n\n    *       * Sciforum\n      * MDPI Books\n      * Preprints.org\n      * Scilit\n      * SciProfiles\n      * Encyclopedia\n      * JAMS\n      * Proceedings Series\n\n  * About\n\n    *       * Overview\n      * Contact\n      * Careers\n      * News\n      * Press\n      * Blog\n\nSign In / Sign Up Submit\n\nJournals\n\nSensors\n\nVolume 24\n\nIssue 7\n\n10.3390/s24072306\n\nSubmit to this Journal Review for this Journal Propose a Special Issue\n\n\u25ba \u25bc Article Menu\n\n## Article Menu\n\n  * Academic Editor\n\nRobert Crowther\n\n  * Subscribe SciFeed\n  * Recommended Articles\n  * Related Info Links\n\n    * PubMed/Medline\n    * Google Scholar\n\n  * More by Authors Links\n\n    * on DOAJ\n\n      * Kim, K.\n      * Tsuchida, S.\n      * Terada, T.\n      * Tsukamoto, M.\n\n    * on Google Scholar\n\n      * Kim, K.\n      * Tsuchida, S.\n      * Terada, T.\n      * Tsukamoto, M.\n\n    * on PubMed\n\n      * Kim, K.\n      * Tsuchida, S.\n      * Terada, T.\n      * Tsukamoto, M.\n\n/ajax/scifeed/subscribe\n\nArticle Views 548\n\n  * Table of Contents\n\n    * Abstract\n    * Introduction\n    * Related Work\n    * Pre-Action Estimation Method\n    * Practice Support System\n    * Conclusions\n    * Author Contributions\n    * Funding\n    * Institutional Review Board Statement\n    * Informed Consent Statement\n    * Data Availability Statement\n    * Conflicts of Interest\n    * References\n\nAltmetric share Share announcement Help format_quote Cite question_answer\nDiscuss in SciProfiles thumb_up\n\n...\n\nEndorse textsms\n\n...\n\nComment\n\n## Need Help?\n\n### Support\n\nFind support for a specific problem in the support section of our website.\n\nGet Support\n\n### Feedback\n\nPlease let us know what you think of our products and services.\n\nGive Feedback\n\n### Information\n\nVisit our dedicated information section to learn more about MDPI.\n\nGet Information\n\nclear\n\n## JSmol Viewer\n\nclear\n\nfirst_page\n\nDownload PDF\n\nsettings\n\nOrder Article Reprints\n\nFont Type:\n\nArial Georgia Verdana\n\nFont Size:\n\nAa Aa Aa\n\nLine Spacing:\n\nColumn Width:\n\nBackground:\n\nOpen AccessArticle\n\n# KARATECH: A Practice Support System Using an Accelerometer to Reduce the\nPreliminary Actions of Karate\n\nby\n\nKwangyun Kim\n\nKwangyun Kim\n\nSciProfiles Scilit Preprints.org Google Scholar\n\n^ 1^,\n\nShuhei Tsuchida\n\nShuhei Tsuchida\n\nSciProfiles Scilit Preprints.org Google Scholar\n\n^ 2^,\n\nTsutomu Terada\n\nTsutomu Terada\n\nSciProfiles Scilit Preprints.org Google Scholar\n\n^ 1,*^ and\n\nMasahiko Tsukamoto\n\nMasahiko Tsukamoto\n\nSciProfiles Scilit Preprints.org Google Scholar\n\n^ 1^\n\n^1\n\nGraduate School of Engineering, Kobe University, 1-1 Rokkodai-Cho, Nada-Ku,\nKobe 657-8501, Hyogo, Japan\n\n^2\n\nCenter for Interdisciplinary AI and Data Science, Ochanomizu University, 2-1-1\nOtsuka, Bunkyo-Ku, Tokyo 112-8610, Japan\n\n^*\n\nAuthor to whom correspondence should be addressed.\n\nSensors 2024, 24(7), 2306; https://doi.org/10.3390/s24072306\n\nSubmission received: 19 February 2024 / Revised: 21 March 2024 / Accepted: 3\nApril 2024 / Published: 5 April 2024\n\n(This article belongs to the Special Issue Inertial Measurement Units in\nSport\u20142nd Edition)\n\nDownload keyboard_arrow_down\n\nDownload PDF Download PDF with Cover Download XML Download Epub\n\nBrowse Figures\n\nReview Reports Versions Notes\n\nArticle Views\n\nCitations -\n\n## Abstract\n\nKumite is a karate sparring competition in which two players face off and\nperform offensive and defensive techniques. Depending on the players, there\nmay be preliminary actions (hereinafter referred to as \u201cpre-actions\u201d), such as\npulling the arms or legs, lowering the shoulders, etc., just before a\ntechnique is performed. Since the presence of a pre-action allows the opponent\nto know the timing of the technique, it is important to reduce pre-actions in\norder to improve the kumite. However, it is difficult for beginners and\nintermediate players to accurately identify their pre-actions and to improve\nthem through practice. Therefore, this study aims to construct a practice\nsupport system that enables beginners and intermediate players to understand\ntheir pre-actions. In this paper, we focus on the forefist punch, one of\nkumite\u2019s punching techniques. We propose a method to estimate the presence or\nabsence of a pre-action based on the similarity between the acceleration data\nof an arbitrary forefist punch and a previously prepared dataset consisting of\nacceleration data of the forefist punch without a pre-action. We found that\nthe proposed method can estimate the presence or absence of a pre-action in an\narbitrary forefist punch with an accuracy of 86%. We also developed KARATECH\nas a system to support the practice of reducing pre-actions using the proposed\nmethod. KARATECH shows the presence or absence of pre-actions through videos\nand graphs. The evaluation results confirmed that the group using KARATECH had\na lower pre-action rate.\n\nKeywords:\n\nhuman motion analysis; accelerometer; sports support; karate; dynamic time\nwarping\n\n## 1\\. Introduction\n\nThere are two main types of karate competitions: kata and kumite. Kumite is a\nsparring competition in which two players face off and perform offensive and\ndefensive techniques. In kumite, the winner is determined by how well the\nplayer can attack the opponent and how well the player can cope with the\nopponent\u2019s attacks. Therefore, it is important to reduce preliminary actions\n(hereinafter referred to as \u201cpre-actions\u201d) during an attack, such as fist\nmotion, arm lowering, shoulder raising, etc., as these will inform the\nopponent of the timing of their punch or kick and give the opponent time to\nprevent the attack. Expert players can know their pre-actions and keep them\nsmall. However, it is difficult for beginners and intermediate players to\naccurately grasp their pre-actions, and it is difficult for them to minimize\ntheir pre-actions through self-practice. For beginners and intermediate\nplayers to deepen their understanding of pre-actions, it is useful to have a\nsystem that automatically detects only the pre-action part of a series of\nkumite motions and provides easy-to-understand feedback.\n\nIn this study, we developed KARATECH, a practice support system that enables\nbeginners and intermediate players to accurately grasp and understand their\npre-actions. KARATECH automatically extracts the pre-action part from the\nmeasured acceleration data during the forefist punch and shows the presence or\nabsence of pre-actions through videos and graphs. Gesture recognition using\nacceleration data is generally based on SVM (support vector machine) [1], RF\n(random forest) [2], HMM (hidden Markov model) [3], and DTW (dynamic time\nwarping) [4], etc.\n\nWe had difficulty identifying small gestures buried in large gestures, such as\npre-actions, in conventional algorithmic gesture recognition methods [5,6,7,8]\nbecause the identification result tends to be determined by large gestures in\na series of gestures. In this study, we propose a method for estimating the\npresence or absence of pre-actions. The proposed method analyzes the waveform\nof acceleration data in a punch by tracing back the time series from the peak\nvalue of the waveform of acceleration data to the beginning of the punch. The\nproposed method not only detects the presence or absence of a pre-action\nassociated with a punching motion, which has been difficult to recognize, but\nalso obtains the segment containing the pre-action.\n\nThe rest of this paper is organized as follows: Section 2 introduces related\nresearch, Section 3 explains the proposed method, Section 4 discusses the\nproposed system, and Section 5 summarizes the paper.\n\n## 2\\. Related Work\n\n#### 2.1. Evaluation of Karate Movements Using Sensors\n\nThere are many studies that use various sensors to evaluate karate motions and\nto assist in practice. Hachaj et al. presented a method for classifying\nvarious karate kicks using motion capture to analyze and visualize the 3D\ntrajectory of the lower body joints in human motor activity [9,10]. Dana et\nal. used DTW to analyze motion capture data of karate kata performed by\nmultiple participants with different timing and velocities [11]. Although\nmotion capture systems can visualize and evaluate detailed motions in karate,\nit has been pointed out that the use of many markers attached to the body\nlimits motion. They are also expensive, require large equipment, and are\nlimited in space, making them difficult for anyone to use. Ait-Bennacer et al.\nproposed a karate smart coaching system that applies deep learning and\ncomputer vision techniques [12]. The system can classify eight different\nkarate techniques with 96% accuracy. However, the system is limited in space,\nas is the motion capture system described above, because it requires multiple\ncameras.\n\nVencesbrito et al. used EMG (electromyography) to measure arm\nelectromyographic patterns during punches of experienced and inexperienced\nkarate players. With this, they characterized the kinematic and\nelectromyographic patterns of the experienced players\u2019 punches and compared\nhow these patterns differ from those of inexperienced karate players [13].\nHowever, EMG is not suitable for the measurement of intense gestures, and it\nis difficult to maintain contact between the electrode and the skin.\n\nIn this study, we analyze and evaluate karate motions using an accelerometer,\nwhich has become smaller and less expensive in recent years and is widely used\nin the sports field. The accelerometer is less spatially constrained than\noptical motion capture and less physically constrained than EMG. Therefore,\nthe accelerometer is suitable for measurement in sports practice.\n\nIn a study of karate motions using inertial sensors including the\naccelerometer, Vukovi\u0107 et al. analyzed in detail the punches of advanced\nplayers using two inertial sensors in order to highly improve their\nproficiency in kumite techniques [14]. Yadav et al. proposed MS-KARD, a multi-\nstream karate motion recognition dataset using two cameras and three inertial\nsensors [15]. They also proposed KarateNet, a fusion-based motion recognition\nnetwork trained on MS-KARD. The main purpose of these studies is to classify\nkarate techniques, and there are few studies on the recognition of pre-\nactions.\n\n#### 2.2. Motion Recognition Method Using the Inertial Sensor\n\nMany methods have been studied to recognize actions such as posture, motion,\nand gestures using the accelerometer, the gyroscope, and the IMU. Murao et al.\ninvestigated the effect on gesture recognition accuracy of changing the number\nand position of sensors and the number and type of gestures [16]. They\ncaptured data for 27 kinds of gestures by using a mobile device with nine\naccelerometers and nine gyroscopes for the investigation. They found the best\npositioning of the accelerometer and the gyroscope for effective recognition\naccuracy due to interdependence among gestures. Pernek et al. developed a\nsystem to recognize the type and intensity of arm muscle training with a\nbarbell using five IMUs [17]. They used a two-layered SVM to recognize six\ntypes of training with an accuracy of 85% and an intensity prediction error of\n6%. Otoda et al. developed a sensing chair with six IMUs on the seat and two\nIMUs on the back of the chair to estimate 18 different postures and the\npresence or absence of the seated person. A learning model was constructed\nusing RF and classified the sitting postures with an accuracy of 80%. Junker\net al. [18] and Georgi et al. [19] proposed a method to recognize specific\ngestures by HMM and achieved high recognition accuracy. HMM is highly\nversatile for recognizing various gesture patterns because it models the\nprobability distribution of state transitions and is suitable for modeling\nlong-term time dependence. On the other hand, it lacks ease of implementation\nbecause it is difficult to design an appropriate model, requires a large\namount of teaching data for parameter estimation, and is computationally\nexpensive.\n\nLike HMM, DTW handles time series information, and computation time increases\nfor long time series data because of the calculation of the distance among all\nthe data. However, since the time required for a pre-action in karate is very\nshort, DTW can keep the computation time down to a practically feasible level.\nTherefore, we use a recognition method based on DTW in this study. DTW is an\nalgorithm that can measure the similarity of time series data even if they\nhave different lengths and periods. DTW measures the similarity between two\ntime series by brute-force calculation of the distance between each point in\nthe time series data. The karate techniques and pre-actions that are the\nobjects of recognition in this study do not have a fixed time length or speed.\nTherefore, we believe that DTW is suitable for their recognition.\n\nMany studies have modified DTW to meet their research objectives. Gao et al.\nproposed a two-dimensional dynamic time warping algorithm (2D-DTW) that can\ndirectly measure the similarity between high-dimensional data such as matrices\n[20]. Xu et al. proposed comparative dynamic time warping (C-DTW) to solve the\nproblem that the accuracy of real-time action recognition by wearable sensors\ndepends on quasi-periodic characteristics [21]. Furthermore, Guo et al.\nproposed SegrDTW, a method for rapid detection of missing or false\ntransactions in highway ETC systems [22].\n\n#### 2.3. Time Series Data Analysis with Automatic Segmentation\n\nWe must accurately separate acceleration data for the forefist punch into\nparts of the forefist punch and any pre-actions in order to detect the\npresence or absence of pre-action. Much research has been conducted on\nautomatic segmentation of time series data to understand motion patterns and\ndetect change points where gestures switch. Darkhovsky et al. introduced the\nconcept of complexity of a continuous function defined on an interval and\ndetected and segmented change points in arbitrary nature time series data by\ncharacterizing classes of H\u00f6lder continuous functions [23]. Inoue et al.\nproposed an unsupervised layered segmentation that can be used as a pre-\nprocessing step for annotating time series data consisting of several types of\ngestures [24]. Moreover, V\u00f6gele et al. proposed an efficient method for fully\nautomatic temporal segmentation of human behavior [25]. Wang et al. utilized\nautomatic segmentation techniques to develop an efficient and accurate method\nfor behavior retrieval in real-time 3D animation [26]. They have made it\npossible to retrieve the relevant motion in real time by matching features for\nthe whole body and five body parts individually. In addition, automatic\nsegmentation techniques have been applied in pHMM (pattern-based hidden Markov\nmodel), which is an algorithm for detecting correlations in time series data\n[27], and in DeepSense, which is a classification model for time series data\nfrom multiple sensors [28].\n\nWe may be able to classify the acceleration data of the forefist punch parts\nand pre-action parts with automatic segmentation techniques. However,\nautomatic segmentation is only a technique for detecting the switch between\ngestures. Therefore, it is difficult to detect a pre-action, which is a very\nsmall action compared to the forefist punch. However, it is difficult to\ndetect the pre-action that occurs during a kumite because automatic\nsegmentation is only a technique for detecting the change between gestures and\nchanges in a situation.\n\n#### 2.4. Detection of Motion Occurrence Timing\n\nTo detect the pre-action that occurs during a forefist punch, a method for\nidentifying the timing of the occurrence of the pre-action can be considered.\nIn a study to detect the start of a gesture, Sideridis et al. proposed\nGesture-Keeper, a hand gesture recognition system based on RQA (recursive\nquantification analysis) and SVM [29]. The evaluation results showed that it\ncorrectly identified the start of a gesture with an accuracy of 87% and\nclassified the type of gesture with an accuracy of 96% for 12 hand gestures.\nYamada et al. developed a method for estimating the moment of acquiring a card\nin competitive karuta for contestants wearing an accelerometer and a gyroscope\non their wrists [30]. They also improved the method for estimating the time of\nacquiring cards and applied it to actions other than competitive karuta,\ndetecting the timing of the occurrence of arbitrary actions during various\ngestures [31]. They estimated the release points of three different actions: a\nbaseball throw, a basketball free throw, and a darts throw, using an IMU\nattached to the wrist. The percentage of release point estimation errors of\n\u00b112 ms or less was 100% for baseball, 87.6% for basketball, and 91.1% for\ndarts.\n\nBy applying these methods, we may be able to detect the timing of punches and\nkicks during kumite. However, it is difficult to apply existing methods of\ndetecting the timing of motion occurrence to pre-actions. This is because pre-\nactions are not specific, fixed actions, and the waveform of acceleration data\nchanges each time. In this study, we detected the timing of the forefist punch\nby applying DTW and estimated the presence or absence of a pre-action by\ntracing back the time series of the acceleration data and comparing it with a\ndataset without pre-actions.\n\n## 3\\. Pre-Action Estimation Method\n\nWe propose a method to estimate the presence or absence of a pre-action by\nanalyzing the acceleration data of karate punches to develop a practice\nsupport system to reduce pre-actions.\n\n#### 3.1. Overview\n\nIn this study, we focus on the forefist punch, the most basic kumite\ntechnique, explained in Figure 1.\n\nFigure 1. How to perform the forefist punch.\n\nThe forefist punch is a technique of punching with the hand on the same side\nas the foot that is in front of the stance. In this study, we define \u201cstriking\ntiming\u201d as when the arm is fully extended and the fist reaches the target\npoint. It is difficult to detect a pre-action in the forefist punch using the\nconventional gesture recognition method based on the accelerometer and the\ngyroscope because a pre-action has the following three features. First, the\nwaveform of pre-action acceleration data is smaller than other gestures such\nas punch and kick. This feature makes it difficult to detect only the pre-\naction part in a series of gestures. Next, as described in Section 2.3 and\nSection 2.4, the pre-action is included during the gesture; therefore, it is\ndifficult to detect the pre-action using methods that detect the point at\nwhich the gesture switches in a continuous motion, such as automatic\nsegmentation [23,24,25,26,27,28] or detection of motion occurrence timing\n[29,30,31]. Finally, the waveform of pre-action acceleration data in the\nforefist punch is not well-defined, as there are various motions such as fist\npulling, arm lowering, shoulder raising, etc., so it is difficult to construct\na dataset labeled for each type of pre-action.\n\nTherefore, we propose a method for estimating the presence or absence of a\npre-action in the forefist punch by taking these features into account. An\noverview of the proposed method is shown in Figure 2.\n\nFigure 2. Overview of methods for estimating the presence or absence of pre-\nactions.\n\nThe proposed method requires the preparation of a dataset consisting of only\nforefist punch acceleration data without pre-actions (hereinafter referred to\nas \u201cdataset without pre-actions\u201d). For any forefist punch acceleration data in\nwhich we want to recognize the presence or absence of a pre-action\n(hereinafter referred to as \u201cinput data\u201d). Let and be the index of the\nstriking timing in time series data of input data and data without pre-action\nin Figure 2. Moreover, let and be the length of the time series data of input\ndata and data without pre-action. The gray lines in 3. Calculating Similarity\nin Figure 2 are the lines connecting the points with the smallest DTW distance\nat each point of the two time series data. We cut out the input data from the\nstart of the pre-action to the striking timing in order to analyze the\nacceleration data that focus only on the pre-action part. Moreover, we reverse\nthe time series of the cut input data and calculate the similarity between the\ninput data and the dataset without pre-actions, from the striking timing to\nthe start of the pre-action. This is because the waveform of acceleration data\njust before the striking timing is similar regardless of the presence or\nabsence of a pre-action. Therefore, if there is a waveform not included in the\ndataset without pre-actions after the similar waveform part of the input data,\nwe consider the waveform to be the pre-action. Section 3.2 describes the\ndataset without pre-actions, and Section 3.3 describes the details of the\nproposed method. Section 3.4 evaluates the estimation accuracy of the proposed\nmethod.\n\n#### 3.2. Dataset without Pre-Actions\n\nAs a preliminary preparation for estimating the presence or absence of pre-\nactions in an arbitrary forefist punch, we prepared a dataset without pre-\nactions consisting only of acceleration data from the forefist punch without\npre-actions. We created the dataset without pre-actions by collecting the\nacceleration data of 30 forefist punches performed by seven karate experts\n(four males and three females in their 20 s) who had been practicing karate\nfor more than seven years. We measured the acceleration data with an\naccelerometer attached to a stretchable wristband on the wrist of the side\nperforming the forefist punch, as shown in Figure 3.\n\nFigure 3. Mounting position of accelerometer (WAA-010) and direction of the\nthree axes.\n\nWe used a compact wireless hybrid sensor II (WAA-010) from ATR-Promotions\n(Kyoto, Japan) for the measurements. The three axes of X, Y, and Z in the\naccelerometer are the directions shown in Figure 3. We used a ThinkPad X13 Gen\n2 PC (OS: Windows 10 Home, CPU: 11th Gen Intel\u00ae CoreTM i5-1135G7 @ 2.40 GHz,\nRAM: 16.0 GB) from Lenovo (Beijing, China). We obtained the acceleration data\nusing the AccelViewerHybrid-II (ver.2.4.0) WAA-010 dedicated data receiving\nsoftware. We generated one punch data series per participant by averaging data\nfrom 30 punches. This is because every punch, no matter how skilled, may\ninclude a small pre-action. Therefore, we constructed the dataset without pre-\nactions with seven punches, whose data consisted of one punch by seven\nseparate experts.\n\n#### 3.3. Estimation Method for the Presence or Absence of Pre-Actions\n\nWe propose a method for estimating the presence or absence of pre-actions\nbased on the similarity measured from the DTW distance between the input data\nand the dataset without pre-actions. Let the input data point be an arbitrary\nforefist punch for which we want to recognize the presence or absence of a\npre-action. We denote the dataset without pre-actions as , the data without\npre-actions as , and the input data as D, as follows:\n\nLet J be the number of the data without pre-actions that comprise the dataset\nwithout pre-actions . Furthermore, let H and I be the number of acceleration\ndata in the three axes of the data without pre-actions and the input data D,\nrespectively. We propose a method for estimating whether the input data D\ncontain pre-actions, shown in Figure 4. The proposed method is based on the\nDTW distance between the input data D and the dataset without pre-actions ,\nwhich is the reversed time series from the striking timing to the start of the\npre-action, as described in Section 3.1.\n\nFigure 4. Proposed method for estimating whether an arbitrary forefist punch\ncontains a pre-action.\n\nWe cut out the data from the start of the pre-action to the striking timing in\norder to analyze the acceleration data, focusing only on the pre-action part.\nAny punch can obtain a negative peak value in the acceleration data on the\nX-axis just before the striking timing. This is because the velocity of the\npunch rapidly approaches zero just before the striking timing in order to make\nthe punch more powerful. In order to detect the striking timing, we obtain\nindices and , which are, respectively, the index number at the negative peak\nin the acceleration data on the X-axis of the input data D and the X-axis of\nthe data without pre-actions . We obtain an array composed of the acceleration\ndata in the three axes of the data without pre-actions that were cut out from\nthe start of the pre-action to the striking timing. Moreover, we obtain an\narray that reverses the time series of the array . Then, we obtain an array\ncomposed of the acceleration data in the three axes of the cut out input data\nD from an arbitrary point i to the striking timing. Likewise, we obtain an\narray that reverses the time series of the array . The waveform of\nacceleration data just before the negative peak in the acceleration data of\nthe punch is similar regardless of the presence or absence of a pre-action.\nTherefore, we can estimate the presence or absence of a pre-action based on\nwhether the waveform that corresponds to a pre-action exists after a similar\nwaveform.\n\nIn order to detect the waveform that corresponds to a pre-action, we calculate\nthe DTW distance between the data without pre-actions and the input data in\nthe following four steps. First, we fix the time length of the data without\npre-actions and gradually increase the time length of the input data in the\ndirection from the striking timing to the start of the pre-action. Next, we\ncalculate the DTW distance in each time length of the input data and add the\nDTW distance to the . Then, we calculate the DTW distance in the three axes of\nX, Y, and Z at each time of the waveform using the algorithm by Myers et al.\n[4] and telescope the time of the waveform so that the total DTW distance is\nlowest. Then, we analyze a graph of the . The difference in the depending on\nwhether the input data contain the waveform that corresponds to a pre-action\nis shown in Figure 5.\n\nFigure 5. Comparison of DTW distance trend graphs in the presence and absence\nof pre-actions.\n\nConsider the case when the input data contain a pre-action, as shown in the\nleft part of Figure 5. When comparing similar waveform parts just before the\nstriking timing, the DTW distance decreases as the input data become longer.\nHowever, when the input data are lengthened to include the waveform that\ncorresponds to a pre-action, a similarity between the data without pre-actions\nand the input data decreases. Therefore, the DTW distance increases, and the\npositive peak of the waveform appears in the graph of . Then, consider the\ncase when the input data do not contain pre-actions, as shown in the right\npart of Figure 5. The positive peak value of the waveform in the graph of\nbecomes smaller because there are few waveforms that correspond to pre-\nactions. Finally, we obtain the difference between the first local minimum and\nthe first local maximum of the waveform in the graph of . Let be the index of\nthe first local maximum and be the index of the local minimum in . If this is\nlarge enough, we can consider that the input data contain pre-actions.\n\nAdditionally, we apply the same process to all data without pre-actions from\nthe 1st to the Jth in the dataset without pre-actions . The data without pre-\nactions with the smallest local minimum can be said to be the most similar to\nthe input data D in terms of motion just before the striking timing. Let be\nthe local maximum and be the local minimum at the data without pre-actions ,\nwith the smallest local minimum in the dataset without pre-actions . We obtain\nthe between and . Then, we can estimate the presence or absence of pre-actions\nby whether the is larger than the threshold T. If the is larger than the\nthreshold T, we estimate that there is a pre-action in the input data D. By\ncontrast, if the is smaller than the threshold T, we estimate that there is no\npre-action in the input data D. The threshold T is determined based on the\nexperimental results in Section 3.4.\n\nThe graphs of acceleration in the three axes and DTW distance trends, when the\nproposed method is applied to a forefist punch without a pre-action and a\nforefist punch with the three types of pre-action, are shown in Figure 6.\nFigure 6a shows the case of a forefist punch without a pre-action. The types\nof pre-actions are Figure 6b pre-action of pulling the fist, Figure 6c pre-\naction of lowering the arm, and Figure 6d pre-action of shaking the fist\nsideways.\n\nFigure 6. Comparison of graphs of the three axes of acceleration and DTW\ndistance trends for forefist punch without pre-actions and forefist punch with\nthe three types of pre-action.\n\nIn addition, we consider the time period between the local minimum and local\nmaximum to be the time period containing pre-actions. Therefore, we can know\nwhen the pre-action occurred in a series of forefist punches using the\nproposed method.\n\n#### 3.4. Experiments to Evaluate Estimation Accuracy\n\nWe conducted an experiment to verify whether the proposed method can detect\npre-actions in the following three steps. First, we compared the value of the\ncalculated in Section 3.3 for each presence and absence of a pre-action in the\ninput data. Next, we determined the threshold T in Section 3.3 based on the\nresult of the first step. Finally, we evaluated the accuracy of estimating the\npresence or absence of a pre-action while using the proposed method.\n\n#### 3.4.1. Experiment Details\n\nThe participants were 10 karate players (eight males and two females in their\n20 s) belonging to a university karate club. We divided them into two groups\nof those with a pre-action and those without a pre-action. Three expert karate\nplayers judged the presence or absence of a pre-action in the participants.\nThe environment for measuring the acceleration data was the same as when\ncreating the dataset without pre-actions described in Section 3.2. First, to\nverify whether the proposed method can detect a pre-action, we attached an\naccelerometer to the wrist of each participant performing a forefist punch and\nmeasured forefist punching data 10 times. We calculated the average value of\nthe using the proposed method, using the 10 punches\u2019 worth of data measured\nfor each participant as input data. We investigated whether the average value\nof the differed depending on the presence or absence of pre-actions by the\nparticipant.\n\nNext, to determine the threshold T, we set the five thresholds shown in Table\n1 based on the results of the above investigation and evaluated the accuracy\nof estimating the presence or absence of pre-actions at each threshold value.\nWe estimated the presence or absence of pre-actions using the proposed method\nfor 10 punches\u2019 worth of data measured for each participant. We evaluated the\nestimation accuracy for each of the five threshold values and defined the\nthreshold with the highest accuracy as the threshold T used in this study.\n\nTable 1. Five threshold patterns used in the experiment.\n\nFinally, to investigate the effectiveness of the proposed method, we compared\nthe estimation accuracy of the baseline method and the proposed method. Here,\nthe baseline method estimates the presence or absence of pre-actions by\nmeasuring the similarity only by the sum of the DTW distances for each of the\nthree axes in the input data and comparison data. A comparison of the methods\nfor estimating the presence or absence of pre-actions between the proposed\nmethod and the baseline method is shown in Figure 7 and Figure 8.\n\nFigure 7. Proposed method for estimating the presence or absence of a pre-\naction.\n\nFigure 8. Baseline method for estimating the presence or absence of a pre-\naction.\n\nIn the baseline method, we calculated the sum of the DTW distances in the\nthree axes across the whole dataset from the beginning of the punch to the end\nof the punch for each punch data series, without any processing, such as cut\nback to the striking timing or time series reversal. When the punch data from\none of the 10 participants were used as input data, the comparison data were\nthe punch data of the remaining nine participants. We measured the DTW\ndistance between the input data and the punch data of the other nine\nparticipants. Then, we estimated the presence or absence of pre-actions by\nreference to the participant group with the lowest DTW distance of the nine\nparticipants. When the mth punch by the nth participant is taken as input\ndata, we calculate the average of the DTW distance with the 10 punches\u2019 worth\nof data by each of the remaining nine participants. The method for estimating\nthe participant who has the lowest average among them is shown in Figure 9.\nLet denote any participant index among the nine participants and denote any\npunch\u2019s data index among the 10 punches\u2019 worth of data of the rth participant.\n\nFigure 9. Algorithm for estimating whether an arbitrary forefist punch\ncontains a pre-action by the baseline method.\n\n#### 3.4.2. Results and Discussion\n\nThe average value of the obtained for each participant is shown in Figure 10a.\n\nFigure 10. Investigation results for the in the presence or absence of a pre-\naction.\n\nThe experimental results show that participants with a pre-action have a\nlarger , and participants without a pre-action have a smaller . Individual\ndifferences between participants with pre-actions were large. We compared the\nacceleration data in the X, Y, and Z-axes for each participant and found that\nthe waveform of the acceleration data in the X-axis was similar regardless of\nthe presence or absence of a pre-action. Participants with higher average\nvalues for the showed more noise in the waveform of pre-actions on the Y-axis\nand Z-axis. As shown in Figure 10b, we conducted a t-test for the mean\ndifference between the overall local maximum and local minimum in the presence\nand absence of pre-actions and found a significant difference (t(5) = 3.7749,\np< 0.05).\n\nNext, the result of estimating the presence or absence of a pre-action using\nthe proposed method is shown in Figure 11. The results show that the precision\nincreases and the recall decreases as the threshold value increases. The\nthreshold value gave the best overall accuracy, with 86.1% accuracy, 84.7%\nprecision, 85.6% recall, and 85.2% F-measure. Therefore, the threshold in the\nproposed method is set to .\n\nFigure 11. Estimation accuracy by threshold value.\n\nFinally, a comparison of the estimation accuracy between the baseline method\nand the proposed method is shown in Table 2. The baseline method had a 46.0%\naccuracy, 46.4% precision, 52.0% recall, and 49.1% F-measure. The proposed\nmethod improved the accuracy by 40.1% and the F-measure by 36.1% compared to\nthe baseline method. Hence, we found that the proposed method is effective for\nestimating the presence or absence of a pre-action.\n\nTable 2. Comparison of the accuracy of estimating the presence or absence of a\npre-action by the baseline method and the proposed method.\n\n## 4\\. Practice Support System\n\nWe developed a system to support practice to reduce pre-actions called\nKARATECH using the proposed method described in Section 3. An overview of\nKARATECH is shown in Figure 12. As in Section 3.4, the user wears an\naccelerometer on the wrist that performs a forefist punch. When the system\nstarts, it measures the acceleration data during the forefist punch and\nestimates the presence or absence of a pre-action using the proposed method.\nKARATECH shows the user the result in the video with the pre-action part\nslowed down, and the graph of the acceleration data of each axis is compared\nto the data without pre-actions. The user practices with reference to the\nfeedback results and repeats the measurement. This allows the user to\nintuitively understand their pre-actions and to practice more efficiently.\nSection 4.1 describes the requirements for designing KARATECH, Section 4.2\ndescribes the implementation method, and Section 4.3 describes the procedure\nfor using KARATECH. Section 4.4 evaluates the effectiveness of KARATECH in\nreducing pre-actions.\n\nFigure 12. Overview of KARATECH, a system to support practices that reduce\npre-actions.\n\n#### 4.1. System Design\n\nIn the development of a system to support the practice of reducing pre-actions\nin the forefist punch, the following requirements were identified as\nnecessary: the system should be able to measure their motions, intuitively\nunderstand their pre-actions, and maintain the accuracy of the forefist punch.\nTherefore, KARATECH has the following functions: acceleration measurement,\nvideo recording/playback, graph display, and velocity display. In order to\nestimate whether the user\u2019s forefist punch includes a pre-action or not, it is\nnecessary to measure acceleration during the forefist punch. The system uses\nthe proposed method to estimate the presence or absence of a pre-action in the\nmeasured data and shows the results through video playback and the graph of\nacceleration data. We elaborate on the feedback of results. First, because a\npre-action in kumite techniques is momentary, it is difficult to observe\nthrough mirrors, etc. Therefore, it is necessary to provide feedback on the\nmotions that correspond to pre-actions in real-time and in an easy-to-\nunderstand manner. If there is a pre-action in the input data, the system\ncalculates the time period corresponding to the pre-action using the proposed\nmethod and plays back a slowed-down video of that part. The user can easily\nunderstand what kind of motions are included in their pre-action. Next, we\nfound from Section 3.4 that there is a large difference in the waveform of\nacceleration data on the Y-axis and Z-axis of the forefist punch between the\npresence and absence of a pre-action. Therefore, it is necessary to understand\nwhich axis in particular is causing the pre-action in the user\u2019s motion.\nKARATECH draws the graph comparing the acceleration data in the three axes of\nthe input data and the dataset without pre-actions. The displayed graph allows\nthe user to check which axis of the dataset is causing the most unnecessary\nmotions. In addition, when practicing with KARATECH, it is necessary to be\ncareful not to reduce the accuracy of the forefist punch by focusing too much\non reducing the pre-action. Therefore, the system uses the velocity of the\nforefist punch as an indicator of the accuracy of the forefist punch. KARATECH\ndisplays the estimated velocity calculated by the trapezoidal integration\nmethod after removing the effects of noise and gravitational acceleration. The\nuser uses the displayed velocity as a reference to maintain the accuracy of\nthe forefist punch.\n\nThe user interface of KARATECH is designed to satisfy the requirements\ndescribed in Figure 13. In order to satisfy these requirements, an\naccelerometer capable of measuring acceleration and a web camera capable of\ncapturing the user\u2019s motions are required.\n\nFigure 13. User interface of KARATECH.\n\n#### 4.2. System Implementation\n\nThe equipment used for the implementation of KARATECH is as follows. As in\nSection 3.2, we used compact wireless hybrid sensor II (WAA-010) from ATR-\nPromotions (Kyoto, Japan) as the accelerometer for measuring acceleration. We\nused a ThinkPad X13 Gen 2 PC (OS: Windows 10 Home, CPU: 11th Gen Intel\u00ae CoreTM\ni5-1135G7 @ 2.40 GHz, RAM: 16.0 GB) from Lenovo (Beijing, China), and the\ncommunication method between the accelerometer and the PC was Bluetooth\ncommunication. We used a C505 webcam from Logicool (Tokyo, Japan) to capture\nthe user\u2019s motions.\n\n#### 4.3. Usage Procedure\n\nThe procedure for practicing with the system that satisfies the above\nrequirements is described below.\n\n  * Camera Selection\n\nThe camera devices recognized by the PC are displayed in a pull-down list. The\nuser selects the camera to be used.\n\n  * Sensor Connection\n\nThe user clicks on the \u201cConnect\u201d button after wearing an accelerometer on the\narm and turning on the power to connect the PC and the accelerometer. After\nthat, the camera is activated, and the image is displayed on the screen.\n\n  * Motion Measurement\n\nA five-second countdown begins after the user clicks the \u201cMeasure\u201d button.\nDuring this time, the user performs a forefist punch in the camera position.\n\n  * Pre-action Estimation\n\nThe system estimates the presence or absence of pre-actions using the method\ndescribed in Section 3.3 referring to the measured data.\n\n  * Measurement Results Display\n\nThe system displays the presence or absence of pre-actions, the video with the\npre-action part slowed down, and the graph compared to the dataset without\npre-actions after the user clicks the \u201cPlay\u201d button. Furthermore, the system\nalso displays the estimated velocity of the forefist punch, which the user can\nuse as an indicator to maintain the accuracy of the forefist punch. The user\ncan view the video repeatedly by pressing the \u201cPlay\u201d button again.\n\n  * Repeat Practice\n\nThe user clicks the \u201cMeasure\u201d button again to practice the forefist punch,\nreferring to the displayed results. By repeating the process from 3. Motion\nMeasurement to 5. Measurement Results Display, the user can deepen their\nunderstanding of their pre-actions and practice more efficiently.\n\n#### 4.4. Experiments to Evaluate the Effectiveness of Pre-Action Reduction\n\nIn order to evaluate the effectiveness of using KARATECH for reducing pre-\nactions, we conducted a short-term experiment and a long-term experiment. In\nthis section, we first describe the short-term experiment, then explain the\nfunctional modifications of KARATECH, and finally describe the long-term\nexperiment.\n\n#### 4.4.1. Short-Term Experiment\n\nWe conducted a short-term experiment to test whether a one-off practice using\nthe proposed system would immediately reduce pre-actions and verify\nappropriate feedback methods. The participants were four intermediate karate\nplayers (two teenage males and two teenage females) belonging to a university\nkarate club and eight beginner karate players (eight males in their 20 s), for\na total of 12. The participants were different from the participants in\nSection 3.4. The experimental procedure is shown in Figure 14.\n\nFigure 14. Short-term experimental procedure.\n\nLet the pre-action rate be defined as the rate of pre-actions among the\nforefist punches performed an arbitrary number of times. First, we measured\nthe acceleration data in the forefist punch 50 times in order to investigate\nthe pre-action rate of the participants before practice. Next, we divided the\nparticipants into two groups: one group practiced using KARATECH (hereinafter\nreferred to as \u201cthe system-using group\u201d), and the other group practiced by\nthemselves while looking only at a mirror (hereinafter referred to as \u201cthe\nnon-using group\u201d). The practice time was 30 min. Finally, we measured the\nacceleration data of 50 forefist punches again to investigate how much the\npre-action rate had decreased compared to the first measurement. We estimated\nthe pre-action rate using the proposed method described in Section 3.\n\nWe experimented in the environment shown in Figure 15. In the environment of\nthe system-using group (upper portion of Figure 15), there was a PC for\ncontrolling KARATECH, a display for showing the system user interface, and a\nwebcam for recording the participant\u2019s motions. Similarly, in the experiment\nconducted in Section 3.4, the participant wears an accelerometer on the wrist\nof the side performing the forefist punch, and a mouse is placed near the\nparticipant to control the system. The non-using group (lower part of Figure\n15) practices while looking only at a mirror. This experiment was conducted\nwith the approval of the Ethical Review Committee for Research Directly\nInvolving Human Participants of the Graduate School of Engineering, Kobe\nUniversity (approval numbers 04\u201306).\n\nFigure 15. Experimental environment.\n\n#### Results of Short-Term Experiment\n\nThe averages of the estimated velocities of 50 forefist punches measured\nbefore and after practice for each participant are shown in Table 3. In this\nexperiment, the velocity of the forefist punch was displayed as one of the\nindicators to maintain the accuracy of the forefist punch. Table 3 shows that\nthe velocity of the forefist punch increased after practice compared to before\npractice for most participants. This result shows that the participants could\npractice without losing the accuracy of the forefist punch.\n\nTable 3. Average velocity of the forefist punch before and after practice\n(unit: km/h).\n\nThe differences between the pre-action rates in 50 forefist punches measured\nbefore and after practice are shown in Figure 16. We conducted a two-way\nbetween-participants ANOVA to analyze the differences between pre-action rates\nin 50 forefist punches measured before and after practice, using two factors:\nwhether or not KARATECH was used during practice and karate proficiency level.\nThe results showed no significant main effect due to the usage of KARATECH,\nbut a significant main effect was found for karate proficiency level (F(1,8) =\n5.39, p < 0.05). When we conducted tests for simple main effects, significant\nsimple main effects were found for the presence or absence of KARATECH use\namong beginners (F(1,8) = 8.42, p < 0.05) and for the level of proficiency in\nparticipants who did not use KARATECH (F(1,8) = 12.32, p < 0.01).\n\nFigure 16. Comparison of pre-action rates before and after practice.\n\n#### Discussion of Short-Term Experiment\n\nWe found that the effect of reducing pre-actions was high for beginners and\nlow for intermediate players by one-off practice using KARATECH. All beginners\nwere able to perform a powerful forefist punch after practice. All beginners\nin the system-using group showed a decrease in pre-actions after practice,\nwhereas all beginners in the non-using group showed an increase in pre-actions\nafter practice. The beginners in the system-using group could practice the\nforefist punch with fewer pre-actions because they could recognize their pre-\nactions during practice. In contrast, the effect of reducing pre-actions was\nlow for all intermediate players. Because it was difficult to reduce pre-\nactions in a short time, intermediate players had already formed their\nforefist punch form through practicing for a long time. Therefore, we found\nthat KARATECH was highly effective in reducing pre-actions even when used in\none-off practice with beginners in karate.\n\n#### 4.4.2. Functional Modifications to KARATECH\n\nBased on the results of the questionnaire for the short-term experimental\nparticipants in Section 4.4.1, we modified some of the feedback methods of\nKARATECH. The user interface of the modified KARATECH is shown in Figure 17.\n\nFigure 17. Modified KARATECH user interface.\n\nWe removed the feedback of graphs of acceleration data and added feedback of\ndiagrams and scores. We had displayed the graph of acceleration data to show\nwhich axis had the largest pre-action. However, some participants who do not\nusually use graphs preferred a more intuitive feedback method. Therefore, we\nadded a feedback method that displays a diagram of the axis with the largest\npre-action. Furthermore, if the acceleration data of the forefist punch\ninclude pre-actions, a \u201cpre-action level\u201d is displayed to show how large the\npre-action was. If the acceleration data of the forefist punch do not include\npre-action, a \u201cscore\u201d is displayed to show how small the pre-action was. We\ncalculated these regarding the and the threshold T in Section 3.\n\n#### 4.4.3. Long-Term Experiment\n\nWe conducted a long-term experiment to verify the reduction effect on the pre-\naction rate when practicing continuously with KARATECH. The participants were\nsix intermediate karate players (two teenage males and two teenage females)\nbelonging to a university karate club and eight beginner karate players (eight\nmales in their 20 s), for a total of 14. The experimental schedule is shown in\nFigure 18.\n\nFigure 18. Long-term experiment schedule.\n\nFirst, we conducted a test to measure the pre-action rate of the participants\nbefore practice. Next, the participants practiced twice a week and took a test\nonce a week for four weeks. Finally, one month after the fourth-week test, we\nconducted a test to investigate the retention of the effect of reducing the\npre-action rate. As in Section 4.4.1, we divided the participants into the\nsystem-using group and the non-using group, and each group practiced for 15\nmin to reduce the pre-action rate of the forefist punch. During the test, the\nparticipants wore an accelerometer on their arms to measure the acceleration\ndata of 50 forefist punches. We also recorded the test with a video camera. In\nthe long-term experiment, we evaluated the pre-action rate during the test by\nthe method described in Section 3 and by video evaluation with three karate\nexperts. The experimental environment was the same as in Section 4.4.1. This\nexperiment was conducted with the approval of the Ethical Review Committee for\nResearch Directly Involving Human Participants of the Graduate School of\nEngineering, Kobe University (approval numbers 05\u201311).\n\n#### Results of Long-Term Experiment\n\nBefore the results of the experiment, we note that we analyzed the results\nusing data from two intermediate participants in the system-using group and\nthree participants in the non-using group because one intermediate participant\nin the system-using group was unable to continue the experiment due to injury.\nThe averages of the forefist punch velocity for each participant during each\ntest, depending on whether KARATECH was used or not and proficiency level, are\nshown in Figure 19. In both groups, the velocity of the forefist punch was not\nsignificantly changed by the long-term practice for reducing pre-actions.\n\nFigure 19. Average of forefist punch velocity per test.\n\nThe differences in the pre-action rate between Test 0 and Test 4 by the\nevaluation of the proposed method and the video evaluation with the karate\nexperts are shown in Figure 20. We conducted a two-way between-participants\nANOVA to analyze the changes in pre-action rates from Test 0 to Test 4, as\ndetermined by both evaluation methods, using two factors: whether or not\nKARATECH was used during practice and the karate proficiency level. The\nresults showed no significant differences due to the usage of KARATECH,\nproficiency level, or their interaction for either evaluation method.\n\nFigure 20. Differences in pre-action rates between Test 0 and Test 4 for each\nevaluation method.\n\nThe pre-action rate for each test in each participant group evaluated by the\nproposed method is shown in Figure 21, and the rate evaluated by video\nevaluation with three karate experts is shown in Figure 22.\n\nFigure 21. The pre-action rate per test evaluated by the proposed method.\n\nFigure 22. The pre-action rate per test evaluated by the video.\n\nIn the evaluation of the proposed method, the system-using group showed that\nthe pre-action rate decreased with practice, regardless of proficiency level.\nOnly one intermediate player in the non-using group had a very high pre-action\nrate in Test 0, and this rate decreased significantly with practice. In the\nvideo evaluation by the karate experts, the pre-action rate showed a\ndecreasing trend regardless of whether KARATECH was used or not and regardless\nof the proficiency level. We evaluated the degree of retention of the pre-\naction reduction effect after one month of practice based on the change in the\npre-action rate from Test 4 to Test 5 for both evaluation methods. Because\nthere was no significant change in the pre-action rate, we confirmed that the\npre-action reduction effect was maintained when KARATECH was used.\n\nQuestionnaire survey questions about KARATECH for the system-using group are\nshown in Table 4, and the results are shown in Figure 23. In the results\nshown, 5 represents \u201ceasy to understand\u201d or \u201cfelt\u201d, and 1 represents\n\u201cdifficult to understand\u201d or did not feel in Figure 23. Many participants\nanswered that the use of KARATECH, the feedback methods, the video playback,\nand the velocity display were easy to understand. In addition, all\nparticipants answered that KARATECH assisted them in practicing to reduce pre-\nactions.\n\nFigure 23. Results of questionnaire survey on KARATECH.\n\nTable 4. Survey questions about KARATECH.\n\n#### Discussion of Long-Term Experimentsection\n\nBased on the results of the long-term experiment, we found that the reduction\nin the pre-action rate was greater when KARATECH was used in both evaluation\nmethods. The results also showed that the participants felt that KARATECH\nhelped them to reduce their pre-actions. This indicates that KARATECH is\neffective in reducing pre-action for beginners and intermediate karate\nplayers. In conclusion, we found that continuous use of KARATECH was effective\nnot only for beginners but also for intermediate karate players.\n\nWe verified the accuracy of the proposed method by comparing the pre-action\nrate between the proposed method evaluation and the video evaluation by karate\nexperts. The differences in pre-action rates between the two methods for each\nparticipant are shown in Table 5. Let the difference be the value created by\nsubtracting the pre-action rate of the video evaluation from the pre-action\nrate of the proposed method evaluation. Differences larger than 0.25 are shown\nin bold. The value that is the third quartile when all differences are\narranged in ascending order of their absolute values is 0.25. The table shows\nthat the differences were particularly large in the evaluation results of\nparticipants LD, LJ, and LN. Since these three participants were faster in the\nforefist punch than the other beginners, it may have been difficult for even\nthe experts to understand the pre-action by only video evaluation.\n\nTable 5. Difference in pre-action rates between proposed method evaluation and\nvideo evaluation.\n\n## 5\\. Conclusions\n\nIn this study, we developed KARATECH, which supports practice to reduce pre-\nactions, an important element in karate. The beginner and intermediate karate\nplayers can intuitively understand their pre-actions and practice efficiently\nby using KARATECH. First, we proposed a method for estimating the presence or\nabsence of pre-actions. The proposed method is based on the DTW distance\nbetween the acceleration data of arbitrary punches and a previously prepared\ndataset consisting of only acceleration data of punches without pre-actions.\nNext, we investigated the estimation accuracy of the proposed method. As a\nresult, we found that the proposed method could estimate the presence or\nabsence of pre-actions with an accuracy of 86.1%, 40.1% higher than that of\nthe baseline method. Finally, we developed KARATECH and experimented to\nevaluate the effect of the system in reducing pre-actions. The results showed\nthat continuous practice using KARATECH was more effective in reducing pre-\nactions than practice while looking at a mirror alone.\n\nIn the future, we plan to improve the estimation accuracy of pre-actions and\ninvestigate the accuracy of estimation in an active state. First, in order to\nimprove the accuracy of estimating the presence or absence of pre-actions, we\nwill expand the data registered in the dataset without pre-actions and\nconsider the position of the accelerometer. We will investigate the change in\nestimation accuracy by attaching accelerometers to different parts of the body\nand by increasing the number of sensors. Next, it is necessary to investigate\nwhether it is possible to accurately estimate the presence or absence of pre-\nactions even when the player is in an active state, such as during a kumite\nmatch, because we had estimated the presence or absence of pre-actions in a\nstatic state.\n\n## Author Contributions\n\nConceptualization, K.K., S.T., T.T. and M.T.; methodology, K.K., S.T., T.T.\nand M.T.; software, K.K.; validation, K.K.; formal analysis, K.K., S.T., T.T.\nand M.T.; investigation, K.K.; resources, K.K.; data curation, K.K.;\nwriting\u2014original draft preparation, K.K.; writing\u2014review and editing, K.K.,\nS.T., T.T. and M.T.; visualization, K.K., S.T., T.T. and M.T.; supervision,\nS.T., T.T. and M.T.; project administration, K.K., S.T., T.T. and M.T.;\nfunding acquisition, K.K. and T.T. All authors have read and agreed to the\npublished version of the manuscript.\n\n## Funding\n\nThis work was supported by JST CREST Grant Number JPMJCR18A3 and JST SPRING\nGrant Number JPMJSP2148, Japan.\n\n## Institutional Review Board Statement\n\nThe study was conducted according to the guidelines of the Declaration of\nHelsinki and approved by the Ethics Committee of Kobe University (No. 04\u201306,\nMay 2022).\n\n## Informed Consent Statement\n\nInformed consent was obtained from all subjects involved in the study.\n\n## Data Availability Statement\n\nNot published due to ethical restrictions. If you want to browse data, please\ncontact the author personally.\n\n## Conflicts of Interest\n\nThe authors declare no conflicts of interest.\n\n## References\n\n  1. Cortes, C.; Vapnik, V. Support-Vector Networks. Mach. Learn. 1995, 20, 273\u2013297. [Google Scholar] [CrossRef]\n  2. Breiman, L. Random Forests. Mach. Learn. 2001, 45, 5\u201332. [Google Scholar] [CrossRef]\n  3. Baum, L.E.; Petrie, T. Statistical Inference for Probabilistic Functions of Finite State Markov Chains. Ann. Math. Stat. 1966, 37, 1554\u20131563. [Google Scholar] [CrossRef]\n  4. Myers, C.S.; Rabiner, L.R. A Comparative Study of Several Dynamic Time-Warping Algorithms for Connected Word Recognition. Bell Syst. Tech. J. 1981, 60, 1389\u20131409. [Google Scholar] [CrossRef]\n  5. Jiang, W.; Yin, Z. Human Activity Recognition Using Wearable Sensors by deep Convolutional Neural Networks. In Proceedings of the 23rd ACM International Conference on Multimedia (MM 2015), New York, NY, USA, 26\u201330 October 2015; Association for Computing Machinery (ACM): New York, NY, USA; pp. 1307\u20131310. [Google Scholar]\n  6. Maurer, U.; Smailagic, A.; Siewiorek, D.P.; Deisher, M. Activit Recognition and Monitoring Using Multiple Sensors on Different Body Positions. In Proceedings of the International Workshop on Wearable and Implantable Body Sensor Networks (BSN 2006), Cambridge, MA, USA, 3\u20135 April 2006; Institute of Electrical and Electronics Engineers (IEEE): New York, NY, USA; pp. 113\u2013116. [Google Scholar]\n  7. Akl, A.; Valaee, S. Accelerometer-Based Gesture Recognition Via Dynamic-Time Warping, Affinity Propagation, & Compressive Sensing. In Proceedings of the 2010 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2010), Dallas, TX, USA, 15\u201319 March 2010; Institute of Electrical and Electronics Engineers (IEEE): New York, NY, USA, 2010; pp. 2270\u20132273. [Google Scholar]\n  8. Masnad, M.; MukitHasan, G.M.; Iftekhar, K.M.; Rahman, M.S. Human Activity Recognition Using DTW Algorithm. In Proceedings of the 2019 IEEE Region 10 Symposium (TENSYMP 2019), Kolkata, India, 7\u20139 June 2019; Institute of Electrical and Electronics Engineers (IEEE): New York, NY, USA; pp. 39\u201343. [Google Scholar]\n  9. Hachaj, T.; Ogiela, M.R.; Piekarczyk, M.; Koptyra, K. Advanced Human Motion Analysis and Visualization: Comparison of Mawashi-geri Kick of Two Elite Karate Athletes. In Proceedings of the 2017 IEEE Symposium Series on Computational Intelligence (SSCI 2017), Honolulu, HI, USA, 27 November\u20131 December 2017; Institute of Electrical and Electronics Engineers (IEEE): New York, NY, USA; pp. 1\u20137. [Google Scholar]\n  10. Hachaj, T.; Ogiela, M.R.; Piekarczyk, M.; Koptyra, K. Human Action Analysis: Templates Generation, Matching and Visualization Applied to Motion Capture of Highly-Skilled Karate Athletes. Sensors 2017, 17, 2590. [Google Scholar] [CrossRef] [PubMed]\n  11. Urribarri, D.; Larrea, M.; Castro, S.; Puppo, E. Visualization to Compare Karate Motion Captures. In Proceedings of the XXV Congreso Argentino de Ciencias de la Computaci\u00f3n (CACIC 2019), C\u00f3rdoba, Argentina, 14\u201318 October 2019; Universidad Nacional de R\u00edo Cuarto (UniR\u00edo) Editora: C\u00f3rdoba, Argentina; pp. 446\u2013455. [Google Scholar]\n  12. Ait-Bennacer, F.E.; Aaroud, A.; Akodadi, K.; Cherradi, B. Applying Deep Learning and Computer Vision Techniques for an e-Sport and Smart Coaching System Using a Multiview Dataset: Case of Shotokan Karate. Int. J. Online Biomed. Eng. 2022, 18, 35\u201353. [Google Scholar] [CrossRef]\n  13. Vencesbrito, A.M.; Ferreira, M.A.R.; Cortes, N.; Fernes, O.; Correia, P.P. Kinematic and Electromyographic Analyses of a Karate Punch. Electromyogr. Kinesiol. 2011, 21, 1023\u20131029. [Google Scholar] [CrossRef] [PubMed]\n  14. Vukovi\u0107, V.; Koropanovski, N.; Markovi\u0107, S.; Kos, A.; Dopsaj, M.; Umek, A. Specific Test Design for the In-Depth Technique Analysis of Elite Karate Competitors with the Application of Kinematic Sensors. Appl. Sci. 2022, 12, 8048. [Google Scholar] [CrossRef]\n  15. Yadav, S.K.; Deshmukh, A.; Gonela, R.V.; Kera, S.B.; Tiwari, K.; Pandey, H.M.; Akbar, S.A. MS-KARD: A Benchmark for Multimodal Karate Action Recognition. In Proceedings of the 2022 International Joint Conference on Neural Networks (IJCNN 2022), Padua, Italy, 18\u201323 July 2022; Institute of Electrical and Electronics Engineers (IEEE): New York, NY, USA; pp. 1\u20138. [Google Scholar]\n  16. Murao, K.; Terada, T.; Yano, A.; Matsukura, R. Evaluating Gesture Recognition by Multiple-Sensor-Containing Mobile Devices. In Proceedings of the 2011 15th Annual International Symposium on Wearable Computers (ISWC 2011), San Francisco, CA, USA, 12\u201315 June 2011; Institute of Electrical and Electronics Engineers (IEEE): New York, NY, USA; pp. 55\u201358. [Google Scholar]\n  17. Pernek, I.; Kurillo, G.; Stiglic, G.; Bajcsy, R. Recognizing the Intensity of Strength Training Exercises with Wearable Sensors. Biomed. Inform. 2015, 58, 145\u2013155. [Google Scholar] [CrossRef] [PubMed]\n  18. Junker, H.; Amft, O.; Lukowicz, P.; Troster, G. Gesture Spotting with Body-worn Inertial Sensors to Detect User Activities. Pattern Recognit. 2008, 41, 2010\u20132024. [Google Scholar] [CrossRef]\n  19. Georgi, M.; Amma, C.; Schultz, T. Recognizing Hand and Finger Gestures with IMU Based Motion and EMG Based Muscle Activity Sensing. In Proceedings of the International Conference on Bio-Inspired Systems and Signal Processing (BIOSIGNALS 2015), Lisbon, Portugal, 12\u201315 January 2015; Science and Technology Events (SCITEVENTS): Setubal, Portugal; pp. 99\u2013108. [Google Scholar]\n  20. Gao, C.; Li, J.; Shen, W.; Yin, P. Two-dimensional dynamic time warping algorithm for matrices similarity. Intell. Data Anal. 2022, 26, 859\u2013871. [Google Scholar] [CrossRef]\n  21. Xu, H.; Feng, R.; Zhang, W. C-DTW for Human Action Recognition Based on Nanogenerator. Sensors 2023, 23, 7230. [Google Scholar] [CrossRef] [PubMed]\n  22. Guo, F.; Zou, F.; Luo, S.; Liao, L.; Wu, J.; Yu, X.; Zhang, C. The Fast Detection of Abnormal ETC Data Based on an Improved DTW Algorithm. Electronics 2022, 11, 1981. [Google Scholar] [CrossRef]\n  23. Darkhovsky, B.S.; Piryatinska, A. New Approach to the Segmentation Problem for Time Series of Arbitrary Nature. Proc. Steklov Inst. Math. 2014, 287, 54\u201367. [Google Scholar] [CrossRef]\n  24. Inoue, S.; Hattori, Y. Towoard High-level Activity Recognition from Accelerometers on Mobile Phones. In Proceedings of the 2011 IEEE International Conferences on Internet of Things, and Cyber, Physical and Social Computing (CPSCom 2011), Dalian, China, 19\u201322 October 2011; Institute of Electrical and Electronics Engineers (IEEE): New York, NY, USA; pp. 225\u2013231. [Google Scholar]\n  25. V\u00f6gele, A.; Kr\u00fcger, B.; Klein, R. Efficient unsupervised temporal segmentation of human motion. In Proceedings of the 2014 the ACM SIGGRAPH/Eurographics Symposium on Computer Animation(SCA 2014), Copenhagen, Denmark, 21\u201323 July 2014; Association for Computing Machinery (ACM): New York, NY, USA; pp. 167\u2013176. [Google Scholar]\n  26. Wang, P.; Lau, R.W.H.; Pan, Z.; Wang, J.; Song, H. An Eigen-based Motion Retrieval Method for Real-time Animation. Comput. Graph. 2014, 38, 255\u2013267. [Google Scholar] [CrossRef]\n  27. Wang, P.; Wang, H.; Wang, W. Finding Semantics Intime Series. In Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data (SIGMOD 2011), Athens, Greece, 12\u201316 June 2011; Association for Computing Machinery (ACM): New York, NY, USA; pp. 385\u2013396. [Google Scholar]\n  28. Yao, S.; Hu, S.; Zhao, Y.; Zhang, A.; Abdelzaher, T. Deepsense: A UnifiedDdeep Learning Framework for Timeseries Mobile Sensing Data Processing. In Proceedings of the 26th International Conference on World Wide Web Companion (WWW 2017), Perth, Australia, 3\u20137 April 2017; Association for Computing Machinery (ACM): New York, NY, USA; pp. 351\u2013360. [Google Scholar]\n  29. Sideridis, V.; Zacharakis, A.; Tzagkarakis, G.; Papadopouli, M. GestureKeeper: Gesture Recognition for Controlling Devices in IoT Environments. In Proceedings of the 2019 27th European Signal Processing Conference (EUSIPCO 2019), A Coru\u00f1a, Spain, 2\u20136 September 2019; The European Association for Signal Processing (EURASIP). pp. 1\u20135. [Google Scholar]\n  30. Yamada, H.; Murao, K.; Terada, T.; Tsukamoto, M. A Method for Determining the Moment of Touching a Card Using Wrist-worn Sensor in Competitive Karuta. Inf. Process. 2018, 26, 38\u201347. [Google Scholar] [CrossRef]\n  31. Murao, K.; Yamada, H.; Terada, T.; Tsukamoto, M. Estimating Timing of Specific Motion in a Gesture Movement with a Wearable Sensor. Sens. Mater. 2021, 33, 109\u2013126. [Google Scholar] [CrossRef]\n\nFigure 1. How to perform the forefist punch.\n\nFigure 2. Overview of methods for estimating the presence or absence of pre-\nactions.\n\nFigure 3. Mounting position of accelerometer (WAA-010) and direction of the\nthree axes.\n\nFigure 4. Proposed method for estimating whether an arbitrary forefist punch\ncontains a pre-action.\n\nFigure 5. Comparison of DTW distance trend graphs in the presence and absence\nof pre-actions.\n\nFigure 6. Comparison of graphs of the three axes of acceleration and DTW\ndistance trends for forefist punch without pre-actions and forefist punch with\nthe three types of pre-action.\n\nFigure 7. Proposed method for estimating the presence or absence of a pre-\naction.\n\nFigure 8. Baseline method for estimating the presence or absence of a pre-\naction.\n\nFigure 9. Algorithm for estimating whether an arbitrary forefist punch\ncontains a pre-action by the baseline method.\n\nFigure 10. Investigation results for the in the presence or absence of a pre-\naction.\n\nFigure 11. Estimation accuracy by threshold value.\n\nFigure 12. Overview of KARATECH, a system to support practices that reduce\npre-actions.\n\nFigure 13. User interface of KARATECH.\n\nFigure 14. Short-term experimental procedure.\n\nFigure 15. Experimental environment.\n\nFigure 16. Comparison of pre-action rates before and after practice.\n\nFigure 17. Modified KARATECH user interface.\n\nFigure 18. Long-term experiment schedule.\n\nFigure 19. Average of forefist punch velocity per test.\n\nFigure 20. Differences in pre-action rates between Test 0 and Test 4 for each\nevaluation method.\n\nFigure 21. The pre-action rate per test evaluated by the proposed method.\n\nFigure 22. The pre-action rate per test evaluated by the video.\n\nFigure 23. Results of questionnaire survey on KARATECH.\n\nTable 1. Five threshold patterns used in the experiment.\n\nPattern| Threshold  \n---|---  \n  \nTable 2. Comparison of the accuracy of estimating the presence or absence of a\npre-action by the baseline method and the proposed method.\n\nBaseline Method| Proposed Method  \n---|---  \nAccuracy| 46.0%| 86.1%  \nPrecision| 46.4%| 84.7%  \nRecall| 52.0%| 85.6%  \nF-measure| 49.1%| 85.2%  \n  \nTable 3. Average velocity of the forefist punch before and after practice\n(unit: km/h).\n\nParticipants| Group| Proficiency| Before| After  \n---|---|---|---|---  \nA| System-using| Intermediate| 12.11| 9.28  \nB| Intermediate| 9.92| 10.31  \nC| Beginner| 13.30| 14.39  \nD| Beginner| 10.29| 13.00  \nE| Beginner| 13.21| 12.28  \nF| Beginner| 6.28| 10.92  \nG| Non-using| Intermediate| 12.89| 14.43  \nH| Intermediate| 11.31| 10.51  \nI| Beginner| 11.38| 12.32  \nJ| Beginner| 10.66| 11.99  \nK| Beginner| 11.24| 11.57  \nL| Beginner| 8.75| 10.85  \n  \nTable 4. Survey questions about KARATECH.\n\nNo.| Question  \n---|---  \nQ1| Was it easy to understand how to use the system?  \nQ2| Was the video feedback easy to understand?  \nQ3| Was the graphical feedback easy to understand?  \nQ4| Was the feedback by score easy to understand?  \nQ5| Was the feedback by velocity easy to understand?  \nQ6| Did you feel that it helped you practice reducing pre-action?  \n  \nTable 5. Difference in pre-action rates between proposed method evaluation and\nvideo evaluation.\n\nParticipants| Group| Proficiency| Test 0| Test 1| Test 2| Test 3| Test 4| Test\n5  \n---|---|---|---|---|---|---|---|---  \nLA| System-using| Intermediate| \u22120.153| \u22120.220| \u22120.187| \u22120.293| \u22120.187| \u22120.227  \nLB| Intermediate| \u22120.147| \u22120.107| \u22120.100| \u22120.067| \u22120.040| \u22120.013  \nLC| Beginner| \u22120.080| \u22120.093| 0.067| 0.073| 0.073| 0.040  \nLD| Beginner| 0.400| 0.647| 0.387| 0.560| 0.067| 0.207  \nLE| Beginner| 0.427| 0.093| \u22120.033| 0.027| 0.020| 0.073  \nLF| Beginner| \u22120.487| \u22120.020| \u22120.027| \u22120.027| 0.013| \u22120.027  \nLG| Non-using| Intermediate| 0.193| 0.180| 0.033| 0.033| \u22120.367| \u22120.013  \nLH| Intermediate| \u22120.067| \u22120.027| \u22120.047| 0.013| 0.000| \u22120.007  \nLI| Intermediate| 0.098| 0.213| 0.127| 0.140| 0.293| 0.107  \nLJ| Beginner| 0.240| 0.693| 0.253| 0.013| 0.547| 0.027  \nLK| Beginner| \u22120.353| \u22120.115| 0.107| 0.120| 0.280| 0.067  \nLM| Beginner| \u22120.360| \u22120.067| \u22120.040| 0.013| \u22120.047| \u22120.060  \nLN| Beginner| 0.167| 0.280| 0.376| 0.400| 0.507| 0.453  \n  \nDisclaimer/Publisher\u2019s Note: The statements, opinions and data contained in\nall publications are solely those of the individual author(s) and\ncontributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s)\ndisclaim responsibility for any injury to people or property resulting from\nany ideas, methods, instructions or products referred to in the content.  \n---  \n\u00a9 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an\nopen access article distributed under the terms and conditions of the Creative\nCommons Attribution (CC BY) license\n(https://creativecommons.org/licenses/by/4.0/).\n\n## Share and Cite\n\nMDPI and ACS Style\n\nKim, K.; Tsuchida, S.; Terada, T.; Tsukamoto, M. KARATECH: A Practice Support\nSystem Using an Accelerometer to Reduce the Preliminary Actions of Karate.\nSensors 2024, 24, 2306. https://doi.org/10.3390/s24072306\n\nAMA Style\n\nKim K, Tsuchida S, Terada T, Tsukamoto M. KARATECH: A Practice Support System\nUsing an Accelerometer to Reduce the Preliminary Actions of Karate. Sensors.\n2024; 24(7):2306. https://doi.org/10.3390/s24072306\n\nChicago/Turabian Style\n\nKim, Kwangyun, Shuhei Tsuchida, Tsutomu Terada, and Masahiko Tsukamoto. 2024.\n\"KARATECH: A Practice Support System Using an Accelerometer to Reduce the\nPreliminary Actions of Karate\" Sensors 24, no. 7: 2306.\nhttps://doi.org/10.3390/s24072306\n\nNote that from the first issue of 2016, this journal uses article numbers\ninstead of page numbers. See further details here.\n\n## Article Metrics\n\nYes\n\n### Citations\n\nNo citations were found for this article, but you may check on Google Scholar\n\nNo\n\n### Article Access Statistics\n\nFor more information on the journal statistics, click here.\n\nMultiple requests from the same IP address are counted as one view.\n\nZoom | Orient | As Lines | As Sticks | As Cartoon | As Surface | Previous Scene | Next Scene\n\n## Cite\n\nExport citation file: BibTeX | EndNote | RIS\n\nMDPI and ACS Style\n\nKim, K.; Tsuchida, S.; Terada, T.; Tsukamoto, M. KARATECH: A Practice Support\nSystem Using an Accelerometer to Reduce the Preliminary Actions of Karate.\nSensors 2024, 24, 2306. https://doi.org/10.3390/s24072306\n\nAMA Style\n\nKim K, Tsuchida S, Terada T, Tsukamoto M. KARATECH: A Practice Support System\nUsing an Accelerometer to Reduce the Preliminary Actions of Karate. Sensors.\n2024; 24(7):2306. https://doi.org/10.3390/s24072306\n\nChicago/Turabian Style\n\nKim, Kwangyun, Shuhei Tsuchida, Tsutomu Terada, and Masahiko Tsukamoto. 2024.\n\"KARATECH: A Practice Support System Using an Accelerometer to Reduce the\nPreliminary Actions of Karate\" Sensors 24, no. 7: 2306.\nhttps://doi.org/10.3390/s24072306\n\nNote that from the first issue of 2016, this journal uses article numbers\ninstead of page numbers. See further details here.\n\nclear\n\nSensors, EISSN 1424-8220, Published by MDPI\n\nRSS Content Alert\n\n### Further Information\n\nArticle Processing Charges Pay an Invoice Open Access Policy Contact MDPI Jobs\nat MDPI\n\n### Guidelines\n\nFor Authors For Reviewers For Editors For Librarians For Publishers For\nSocieties For Conference Organizers\n\n### MDPI Initiatives\n\nSciforum MDPI Books Preprints.org Scilit SciProfiles Encyclopedia JAMS\nProceedings Series\n\n### Follow MDPI\n\nLinkedIn Facebook Twitter\n\n\u00a9 1996-2024 MDPI (Basel, Switzerland) unless otherwise stated\n\nDisclaimer\n\nDisclaimer/Publisher\u2019s Note: The statements, opinions and data contained in\nall publications are solely those of the individual author(s) and\ncontributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s)\ndisclaim responsibility for any injury to people or property resulting from\nany ideas, methods, instructions or products referred to in the content.\n\nTerms and Conditions Privacy Policy\n\nWe use cookies on our website to ensure you get the best experience. Read more\nabout our cookies here.\n\nAccept\n\n## Share Link\n\nCopy\n\nclear\n\n## Share\n\nclear\n\nBack to TopTop\n\n", "frontpage": false}
