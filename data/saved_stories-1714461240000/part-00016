{"aid": "40203670", "title": "Questioning the Conventional Wisdom on Liability and Open Source Software", "url": "https://www.lawfaremedia.org/article/questioning-the-conventional-wisdom-on-liability-and-open-source-software", "domain": "lawfaremedia.org", "votes": 7, "user": "curmudgeon22", "posted_at": "2024-04-29 20:22:53", "comments": 2, "source_title": "Questioning the Conventional Wisdom on Liability and Open Source Software", "source_text": "Questioning the Conventional Wisdom on Liability and Open Source Software | Lawfare\n\nSkip to Main Content\n\n  * Facebook\n  * Twitter\n  * LinkedIn\n\nThe upcoming main navigation can be gotten through utilizing the tab key. Any\nbuttons that open a sub navigation can be triggered by the space or enter key.\n\n## Search Lawfare\n\n###### Suggestions\n\nAdvanced Search\n\nCybersecurity & Tech\n\n# Questioning the Conventional Wisdom on Liability and Open Source Software\n\nJohn Speed Meyers, Paul Gibert\n\nThursday, April 18, 2024, 1:00 PM\n\nShare On: Share on Facebook Share on Twitter Share on LinkedIn\n\nTo improve cybersecurity, open source software should not be completely exempt\nfrom software liability.\n\nModern laptop with program code on screen (Rodrigo Santos,\nhttps://freerangestock.com/photos/126560/software-developer-programming-code-\non-screen.html; Public Domain)\n\n  * ## John Speed Meyers\n\n  * ## Paul Gibert\n\nMeet The Authors\n\nPublished by The Lawfare Institute in Cooperation With\n\nSubscribe to Lawfare\n\nA key and occasionally fiery thread of the debate around software liability\nhas been the role of open source software. Most modern software applications\nare, under the hood, more than 80 percent open source software: software whose\nsource code is free to inspect, modify, and distribute and that is often\nmaintained by volunteers. What are the potential liability-related obligations\nof companies and open source software developers with respect to the open\nsource software in a software product? This question has become even more\nsalient because of the recent XZ Utils backdoor, in which a popular open\nsource software project was compromised by a malicious project maintainer.\n\nThere are at least three beliefs embedded in this debate that have become the\nmajority opinion, none without merit but all worthy of scrutiny. First, open\nsource software developers should bear no legal responsibility for the\nsoftware they create, modify, and distribute. Second, some analysts, when\ndiscussing a liability regime and open source software, have advanced the idea\nthat liability should focus primarily on preventing companies from shipping\nproducts with open source components that are known to have vulnerabilities or\nobvious code flaws, especially vulnerabilities that are known to have been\nexploited. Third, if and when software liability becomes law and covers open\nsource software included in a product, then companies will finally invest\nsubstantially in the open source software ecosystem.\n\nThis piece interrogates each claim, drawing in part on our experience as\nsoftware developers and in part on our background in empirical computer\nsecurity research, and offers three counterclaims.\n\nCounterclaim #1: Malicious open source software developers should potentially\nbear legal responsibility for malicious behavior.\n\nIt\u2019s a bedrock principle that open source software is provided \u201cas is.\u201d In\nfact, some, perhaps most, open source software advocates view open source code\nas an expression of free speech. In other words, open source software\nmaintainers should, in this view, not be held responsible for flaws or\nproblems (or anything, really) related to their code. These views are\nbolstered by a widespread belief that liability for open source software\ndevelopers would hinder innovation and economic growth. For instance, during\nthe debate over the European Union\u2019s Cyber Resilience Act and specifically the\nact\u2019s lacking a clause that exempts open source software developers form\nliability, one commentator wrote:\n\n> Holding open source developers whose components end up in commercial\n> products liable for security issues will stifle innovation and harm the EU\n> economy without providing a substantive improvement in security.\n\nMost moderate voices on open source software liability argue that \u201cfinal goods\nassemblers\u201d should be the party responsible for the security of open source.\nThat\u2019s legalese for software companies. The idea is that the companies that\npresumably profit from the use of the open source software within their\nproducts should be liable, including for security bugs in the open source\nsoftware included in their products.\n\nThese are rational views. Numerous critical, security-sensitive open source\nprojects are maintained by volunteers, and placing liability on these\nmaintainers could potentially discourage further contribution and weaken an\nalready-stretched open source ecosystem.\n\nBut there is an edge case: Should open source software developers that\nknowingly distribute malicious open source software also be exempt from\nliability? This isn\u2019t an academic question. The recent XZ backdoor, which\nhappened in between the first draft of this article and its publish date,\npoints to the fact that malicious open source software is a real threat.\nEstimating conservatively, there have been hundreds, if not thousands or even\ntens of thousands, of malicious open source software packages distributed via\npopular open source package repositories, the open source software equivalent\nof Apple\u2019s App Store. And the threat is not particularly new either. For\ninstance, in 2018, open source software users discovered that one open source\nproject (event-stream) with over 2 million downloads per week was harvesting\naccount details from Bitcoin wallets. Though this attack affected only a small\nset of Bitcon users, this episode points to the possibility that future\nattacks could compromise the privacy of millions of users in a wider context.\n\nAn absolutist view that open source software is provided \u201cas is\u201d implies that\nopen source software developers can distribute even malicious open source\nsoftware. There has never, to our knowledge, been a legal case against an\nentity or individual linked to these malicious packages. Purists presumably\nbelieve that \u201cas is\u201d clauses should offer protection or perhaps believe that\nany harm caused can be covered by existing laws such as the Computer Fraud and\nAbuse Act. Skeptics could think that this legal boundary\u2014assuming attribution\nis possible in such cases\u2014needs to be tested.\n\nCounterclaim #2: Liability related to open source software should potentially\ninclude avoiding end-of-life software.\n\nJim Dempsey expertly summarizes an emerging position that there should exist a\nsoftware liability \u201cfloor\u201d that explicitly defines software \u201cdos\u201d and\n\u201cdont\u2019s\u201d. Dempsey argues that some practices, like hardcoded passwords, are so\nobviously negligent that they could help define a standard of care. His\nanalysis stresses the usefulness of a standard that includes avoiding\nvulnerabilities known to have been exploited (such as those on the\nCybersecurity and Infrastructure Security Agency\u2019s known exploited\nvulnerabilities catalog) or weaknesses associated with the so-called OWASP Top\n10, a consensus-driven list of the most critical security risks for web\napplications. This focus on avoiding known vulnerabilities and insecure coding\npractices is welcome, but it raises the question of what practices should be\nincluded as \u201cinsecure,\u201d an area that is surprisingly devoid of systematic\nresearch.\n\nShould such an effort to define a floor gain steam, there is one practice,\nsometimes overlooked, that is increasingly getting attention: including end-\nof-life (EOL) open source software components in an application. EOL open\nsource software components are no longer supported, by either the open source\nmaintainers or the organization associated with that particular component. The\nproblem is that these components no longer receive security updates.\nConsequently, when a vulnerability is discovered and announced, there will be\nno easy way to patch the vulnerability. Importantly, EOL open source software\ncomponents are not a theoretical danger. One analysis of the top 10 open\nsource packages across eight programming language ecosystems found two\nexamples of EOL components (\u201cabandonware\u201d in their terminology.)\n\nFortunately there is a nascent movement, embodied in open source projects,\nstartups, and fledgling government initiatives, to identify, prevent, and\nreplace EOL open source software components. It\u2019s therefore worth considering\nadding the inclusion of EOL open source software into software applications as\na software \u201cdon\u2019t\u201d. This will naturally create questions about what exactly\nEOL open source software is: It can be hard to determine if a project is EOL,\npoorly maintained, or simply stable as a rock. But those questions are no more\nvexing than many others related to open source software security.\n\nCounterclaim #3: Software liability laws will not necessarily lead to broad\ncorporate investment in the open source software ecosystem.\n\nMost discourse assumes implicitly that, should companies face liability for\nthe security flaws in the open source code they use, they will use their\nfinancial and engineering resources to improve the security and health of the\nopen source projects they use, implicitly assuming that these companies will\ncontinue to use the same open source software projects. For instance, past\nanalysis (including by one of the co-authors) makes this case. Some authors,\nfor instance, argue:\n\n> [Clarifying liability] ... would encourage further growth in the role played\n> by bigger, well-resourced software vendors in improving the security of\n> commonly used open source packages.\n\nIt\u2019s plausible. But there are other possible outcomes. For example, companies\ncould reduce their use of open source software, depend on fewer packages, and\nwrite more of their own code. This would be a big change, but software\nliability is, relative to the status quo, a radical idea. Radical consequences\nseem at least plausible.\n\nAnother, likelier outcome is the rise of walled open source gardens. Instead\nof downloading code from unvetted GitHub code repositories and free-for-all\nnonprofit package registries (actions that most software developers, including\nourselves, do all the time), software developers would be forced by company\npolicy, itself a result of liability laws, to use only open source software on\na preapproved list. This list could be maintained internally, or it could be a\nlist of dependencies that are vetted by a trusted third party.\n\nThis sort of risk transfer, using walled open source gardens, arguably already\nexists, though it isn\u2019t necessarily widespread. For example, Anaconda, a\nPython development environment for machine learning and data science, does\nthis for a select group of widely used Python packages. Other companies do\nthis for key Linux distribution packages too, but there is much room for\nexpanding these walled gardens and making the \u201cwalls\u201d higher. There are now\nhundreds of thousands of widely used open source packages across many\nprogramming language ecosystems. Unfortunately, state-of-the-art techniques\nfor detecting open source package malware and for proactively detecting open\nsource vulnerabilities leave much to be desired. On the bright side, Linux\ndistributions like Wolfi are trying to be an open source walled garden of the\nfuture.\n\n* * *\n\nShould software liability ever become likely, legislators will need to grapple\nwith the role of open source software within such a regime. This is because\nmodern software applications are, by some estimates, over 80 percent open\nsource software. Part of this process will require analysts to confront\nassumptions that have mostly been implicit, such as the claim that placing\nliability on software companies as \u201cfinal assemblers\u201d will lead to broad\ninvestments across the current open source ecosystem. Should these assumptions\nnot be as solid as hoped for, then it\u2019s possible that advocates of software\nliability will be surprised by unforeseen consequences. And anyone who has\ndeveloped software knows software is nothing if not full of unforeseen\nconsequences.\n\nTopics:\n\nCybersecurity & Tech\n\nBack to Top\n\n### John Speed Meyers\n\nRead More\n\nJohn Speed Meyers is the head of Chainguard Labs within Chainguard. He leads a\nresearch team focused on open source software security. He is also a\nnonresident senior fellow at the Atlantic Council in the Cyber Statecraft\nInitiative within the Digital Forensic Research Lab. He previously worked at\nIn-Q-Tel and the RAND Corporation.\n\n### Paul Gibert\n\nRead More\n\nPaul Gibert is a researcher at Chainguard Labs within Chainguard. He\npreviously worked at Lockheed Martin.\n\n## More Articles\n\n  * ### Know-Your-Customer is Coming for the Cloud\u2014the Stakes are High\n\nKevin Allison Paul Triolo\n\nApr 29, 2024\n\nThe comment period for the Commerce Department\u2019s new rules for cloud service\nproviders ends today, and policymakers will sift through the feedback before\nissuing final rules before the end of the year.\n\n  * ### Sandworm, an Inspiration for Hostile Actors\n\nTom Uren\n\nApr 26, 2024\n\nThe latest edition of the Seriously Risky Business cybersecurity newsletter,\nnow on Lawfare.\n\n  * ### The False Choice in the Debate Over Artificial Intelligence Regulation\n\nMatthew Tokson Yonathan A. Arbel Albert Lin\n\nApr 26, 2024\n\nShould regulators focus on present-day or potential future AI risks? Both.\n\n## Other Topics\n\n  * Armed Conflict\n  * Congress\n  * Courts & Litigation\n  * Criminal Justice & Rule of Law\n  * Cybersecurity & Tech\n  * Democracy & Elections\n  * Executive Branch\n  * Foreign Relations & International Law\n  * Intelligence\n  * States & Localities\n  * Surveillance & Privacy\n  * Terrorism & Extremism\n\n## Subscribe to Lawfare\n\nHard National Security Choices\n\n  * Stay Connected\n  * Facebook\n  * Twitter\n  * LinkedIn\n  * Youtube\n\n## Lawfare\n\n## Resources\n\n## About\n\n\u00a9 2024\n\nThe Lawfare Institute\n\nPublished by The Lawfare Institute in Cooperation With\n\n\u00d7\n\n", "frontpage": true}
