{"aid": "40072258", "title": "How to Get More from Your Pinecone Vector Database", "url": "https://vectorize.io/how-to-get-more-from-your-pinecone-vector-database/", "domain": "vectorize.io", "votes": 1, "user": "bytearray", "posted_at": "2024-04-18 02:09:55", "comments": 0, "source_title": "How to Get More from Your Pinecone Vector Database", "source_text": "How to Get More from Your Pinecone Vector Database\n\nWe use essential cookies to make our site work. With your consent, we may also\nuse non-essential cookies to improve user experience, personalize content, and\nanalyze website traffic. For these reasons, we may share your site usage data\nwith our analytics partners. By clicking \u201cAccept,\u201d you agree to our website's\ncookie use as described in our Cookie Policy. You can change your cookie\nsettings at any time by clicking \u201cPreferences.\u201d\n\n  * Use Cases\n\n    * Question Answering Systems\n    * AI Copilots\n    * Call Center Automation\n    * Content Automation\n    * Hyper-personalization\n  * Blog\n  * About\n  * Learn\n\n    * Prompt Engineering\n    * Retrieval Augmented Generation (RAG)\n    * Vector Database Guide\n  * Contact\n\nContact Us\n\n#### Be on of the first to try Vectorize!\n\nEdit Content\n\nPinecone, Vector Database, Vector Search, Vectors\n\n# How to Get More from Your Pinecone Vector Database\n\nApril 11, 2024 Chris Latimer 1 comment\n\n## Why are vector databases so popular right now?\n\nJust a few years ago, vector databases were a niche technology that powered\ntraditional machine learning use cases like recommendation systems and fraud\ndetection algorithms. Today, the explosion in interest around generative AI\nhas elevated vector databases to new heights. Among the most popular options\nfor most developers and companies is Pinecone vector database.\n\nPinecone is a cloud native vector database. Interestingly, it is only\navailable as a cloud service compared to other products which are often times\navailable as self-hosted open source solutions.\n\nPinecone was one of the first vector database vendors to recognize how\ntransformative this technology would be for generative AI use cases. In\nparticular, techniques such as retrieval augmented generation (RAG) are\ndriving a lot of Pinecone adoption by developers who want a highly scalable\nsemantic search solution without the hassle of operating an open source\nalternative.\n\n## How do most people use Pinecone?\n\nFor a comprehensive explanation of vector databases, head over to our Ultimate\nVector Database Guide. In a nutshell, Pinecone is a specialized type of search\nengine that is purpose build to provide fast, efficient querying of\npotentially vast amounts of vector data.\n\nVectors in this context are typically generated using a text embedding model\nlike Open AI\u2019s text-embedding-v3 or ada-002 models. Text embedding models are\na type of machine learning model that is intended to accept some text as its\ninput and produce a vector.\n\nA vector is just an array of floating point numbers, but those numbers encode\nthe semantic meaning of the input text. This means that when you query\nPinecone, you\u2019ll create a text embedding for some string, and Pinecone will\nhand back a set of the most similar vectors. This will also include the text\nthat was used to create those vectors. In this way you can find the most\nsimilar content that Pinecone has in its search indexes.\n\nThis is a powerful technique that lets you connect your private data with your\nLLM to unlock new use cases.\n\nSo while ChatGPT doesn\u2019t have the customer service handbook that your customer\nsupport team uses, Pinecone lets you find the relevant parts of that handbook\nwhen a customer asks a question. And combining those relevant results with\nyour LLM integration, you can now improve the performance and accuracy of your\ngen AI applications.\n\n## Getting started with Pinecone and vector data\n\nThere are two ways to get started with Pinecone: the easy way and the hard\nway.\n\n### Pinecone the hard way\n\nThis approach involves writing code to populate your vector database with high\ndimensional vector data. You will typically accomplish this by identifying all\nthe data you want to include in your vector indexes. You will identify the\ncollections of documents from file systems, knowledge bases, traditional\ndatabases, and other SaaS tools.\n\nYou\u2019ll usually use either python or javascript along with natural language\nprocessing libraries to extract the text from your source data. You\u2019ll then\nbreak that text data into smaller pieces, called chunks.\n\nFor each of those chunks, you\u2019ll either leverage an open source embedding\nmodel from the MTEB leaderboard, or you\u2019ll use a commercial offering such as\nOpenAI or Voyage AI to generate text embedding vectors. Each vector\ncorresponds to a chunk from your source data.\n\nYou\u2019ll then use the user friendly api that is provided by Pinecone, often via\nthe python or javascript library, to write that data into your Pinecone\ndatabase index.\n\nAt that point, you are ready to start searching for similar vectors using the\nsemantic search algorithms provided by Pinecone.\n\nNow comes the hard part. You need to verify that the data stored in your\nindexes are going to deliver high performance, high accuracy results that are\ngoing to work well for your use cases in a real world environment.\n\nThis process involves creating a large number of example records, performing\nsimilarity search queries to retrieve your vector search results. You then\nmust perform an assessment of how relevant those results are, and whether or\nnot those values, along with any metadata, provide the necessary context to\nsatisfy your users and their requirements.\n\n### Pinecone the easy way\n\nThe easy way to get started with Pinecone is to use Vectorize. Vectorize\nprovides a simple step by step formula to ensure you end up with an optimized\nsearch index that is custom tailored for your data and your users.\n\n#### Step 1: Start with a data-driven approach\n\nThere are many different ways to chunk your documents and other source data\nthat you want to turn into vectors. There are also many embedding models you\ncan use to turn those chunks into vectors. A common mistake developers make is\nto not put enough thought into which approach will work best for their data\nand their use case.\n\nA better way is to leverage the free experiments feature in Vectorize. With\nexperiments, you can take a representative sample of your data and immediately\nsee how various vectorization strategies will perform for you.\n\nYou don\u2019t even need a Pinecone instance setup to try this out, Vectorize will\nprovide the vector database engine for you so you don\u2019t need to clutter up\nyour real database with experiment data.\n\nYou start by providing a description for your experiment and uploading a\nrepresentative sample of your data in the form of PDFs, HTML docs, text files,\nor other document formats:\n\nYou can then start the experiment. Vectorize will tell you immediately the\ntopics and categories of questions your data would be best at answering, then\nit will tell you which vectorization strategy is best at providing relevant\ncontext to help answer those questions.\n\nNow instead of relying on gut feel and optimism, you can make a decision on\nhow to vectorize your data using definitive evidence that shows which option\nwill perform best.\n\n#### Step 2: Assess the vector search performance directly\n\nUsing the Vectorize RAG Sandbox, you can \u201cchat with your experiment data\u201d to\nsee if the quantitative assessment of your semantic search results match up\nwith your personal experience.\n\nHere you can ask your pinecone vector database any of the questions generated\nin the experiment or anything you wish. Vectorize will automatically generate\na query vector, perform a vector search using the pinecone client, and show\nyou the top results. You\u2019ll be able to see relevancy scores and normalized\ndiscounted cumulative gain scores for your results to help further inform your\ndecision.\n\n#### Step 3: Promote your experiment results into a production-ready vector\npipeline\n\nOnce you are ready to populate your vector database with your real production\ndata, you can use Vectorize to create a vector pipeline.\n\nTo do this, you\u2019ll start by configuring access to your Pinecone using a\ndestination connector.\n\nHere you simply supply your API key and a name. For security, your api\ncredentials are stored in an encrypted secret storage.\n\nNext, you\u2019ll configure the source connector where your data lives. Here you\ncan select from the many file systems, knowledge bases, and SaaS platforms\nthat Vectorize supports.\n\nOnce your source system and your Pinecone configurations are set up, you can\ncreate a vector pipeline to automatically populate your search indexes.\n\nWithin the pipeline, you will be able to select the embedding model and\nchunking strategy that worked best for you in your experiment.\n\nOnce this is in place, Vectorize will automatically populate your vector\nindexes in Pinecone. It will also trigger a watch process that will capture\nany new data or data changes and perform real time updates as needed. This\nensures your Pinecone vector database remains up to date and your customers\nnever .\n\n## Key architectural designs for Pinecone vector databases\n\n### Serverless or Pod Based?\n\nPinecone comes with two deployment options: serverless and pod-based and\nfortunately you can try both options in their free tier.\n\nThe Pinecone serverless database has a usage based pricing structure that\nallows you to start small with a price structure that grows with you. A key\nattribute of serverless is its ability to let you to scale elastically in\nresponse to growing or shrinking workloads.\n\nPod-based, on the other hand provides you with fixed capacity. While it would\nbe nice if Pinecone could handle massive spikes in traffic instantly with no\ninstability, they too are subject to the laws of computing.\n\nWith pod-based vector databases, you will have an easier time pre-scaling your\nclusters for peak loads. And while Pinecone generally can provide a high-\nperformance search index in either deployment option, you have more control\nover the compute resources assigned to your database when using the pod-based\noption. Of course the trade off with this is that you will be paying for\ncapacity that goes unused.\n\nWith either option, your costs will scale with the dimension size of the\nvectors in your index. Each index will require more compute for vectors that\nhave a higher dimension size.\n\nHigh-dimension vectors require large amounts of object storage and are more\ncomputationally intensive to search. Each query must compare each dimension\nand while indexes help make this process more efficient, it does have a cost\nto perform similarity searches.\n\n### Namespaces vs Metadata filtering\n\n#### Using filtering\n\nMost vector databases provide metadata filtering to make similarity search\nmore efficient. The idea is to limit the number of values that must be\ncompared in each index to achieve high performance semantic search. This makes\nvector search more efficient, faster, with better scale.\n\n#### Using Namespaces\n\nPinecone extends the standard metadata filtering capabilities by also offering\nfull featured partitioning of your vector data. When you query your data in\nthis approach, you must specify the namespace. Pinecone will limit searching\nonly to the partition within the database that matches the namespace\nspecified. Compared to metadata filtering, this is not as flexible, but is\nmuch more scalable and help with use cases such as multi-tenancy or log data.\n\n## Implementing semantic search\n\n### Querying with a query vector value\n\nQuerying in Pinecone is very simple using either the JavaScript or Python\nclient.\n\nIn python, you would use this approach:\n\n    \n    \n    from pinecone import Pinecone pc = Pinecone(api_key=\"YOUR_API_KEY\") index = pc.Index(\"my-index\") index.query( namespace=\"my-namespace\", vector=[0.4, 0.7, -0.3, 0.1, 0.9, 0.4, 0.5, 0.8], top_k=5, include_values=True )\n\nHere, we are performing a similarity search using a query vector specified in\nthe vector field. It\u2019s important that the dimension size of your search vector\nmatches the dimension configured on your index.\n\n### Querying with a metadata filter\n\nMetadata filtering works very similar to the last example, but we can include\na filter parameter which will narrow down the values searched and only records\nwith matching metadata will be returned.\n\n    \n    \n    from pinecone import Pinecone pc = Pinecone(api_key=\"YOUR_API_KEY\") index = pc.Index(\"my-index\") index.query( namespace=\"my-namespace\", vector=[0.4, 0.7, -0.3, 0.1, 0.9, 0.4, 0.5, 0.8], filter={ \"color\": {\"$eq\": \"red\"} }, top_k=5, include_values=True )\n\n## Conclusion\n\nPinecone makes it easy to accomplish the task of building a similarity search\nbased on vector data. While the Pinecone client offerings are easy to use,\nPinecone has many of the same challenges as other vector databases when it\ncomes to ingestion and verifying that your vector indexes will perform well.\nHowever, using Vectorize with Pinecone makes this process a breeze.\n\n### Share this:\n\n  * Twitter\n  * LinkedIn\n  * Facebook\n  * Reddit\n  * Pinterest\n  * Threads\n  * X\n\n### Related\n\n### One comment\n\n  1. #### 5 RAG Vector Database Traps and How to Avoid Them - Vectorize\n\nApril 12, 2024 / 8:47 am Reply\n\n[...] databases are well suited to provide both core vector search\ncapabilities as well as metadata filtering. However, many developers are so\nfocused on [...]\n\n### Leave a ReplyCancel reply\n\n#### Search\n\n#### Categories\n\n#### Recent posts\n\n  * Triumph Over Data Obstacles In RAG: 8 Expert Tips\n\n  * How to build a better RAG pipeline\n\n  * How to Get More from Your Pinecone Vector Database\n\n#### Tags\n\nRAG Retrieval Augmented Generation\n\nThe easiest, fastest way to connect your data to your LLMs.\n\n##### Resources\n\n  * Support center\n  * Documentation\n  * Community\n  * Hosting\n\n##### Company\n\n  * About us\n  * Latest news\n  * Contact us\n  * Resources\n\n\u00a9 Vectorize AI, Inc, All Rights Reserved.\n\n  * Terms & Conditions\n  * Privacy Policy\n\n## Discover more from Vectorize\n\nSubscribe now to keep reading and get access to the full archive.\n\nContinue reading\n\nLoading Comments...\n\n", "frontpage": false}
