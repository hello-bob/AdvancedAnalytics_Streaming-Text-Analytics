{"aid": "40059946", "title": "Posteriors: Open-Source Library for Uncertainty-Aware LLMs with PyTorch", "url": "https://github.com/normal-computing/posteriors", "domain": "github.com/normal-computing", "votes": 1, "user": "amarchenkova", "posted_at": "2024-04-17 02:54:33", "comments": 0, "source_title": "GitHub - normal-computing/posteriors: Uncertainty quantification with PyTorch", "source_text": "GitHub - normal-computing/posteriors: Uncertainty quantification with PyTorch\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nnormal-computing / posteriors Public\n\n  * Notifications\n  * Fork 2\n  * Star 50\n\nUncertainty quantification with PyTorch\n\nnormal-computing.github.io/posteriors/\n\n### License\n\nApache-2.0 license\n\n50 stars 2 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# normal-computing/posteriors\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n3 Branches\n\n2 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nSamDuffieldMerge pull request #66 from normal-computing/subpackagesd3054b1 \u00b7\n\n## History\n\n10 Commits  \n  \n### .github/workflows\n\n|\n\n### .github/workflows\n\n| Add build test  \n  \n### docs\n\n|\n\n### docs\n\n| Public launch  \n  \n### examples\n\n|\n\n### examples\n\n| Public launch  \n  \n### posteriors\n\n|\n\n### posteriors\n\n| Update laplace init  \n  \n### tests\n\n|\n\n### tests\n\n| Public launch  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Public launch  \n  \n### .pre-commit-config.yaml\n\n|\n\n### .pre-commit-config.yaml\n\n| Use build_meta  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Public launch  \n  \n### README.md\n\n|\n\n### README.md\n\n| Public launch  \n  \n### mkdocs.yml\n\n|\n\n### mkdocs.yml\n\n| Public launch  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| Typo  \n  \n## Repository files navigation\n\nInstallation | Quickstart | Methods | Friends | Contributing | Documentation\n\n## What is posteriors?\n\nGeneral purpose python library for uncertainty quantification with PyTorch.\n\n  * Composable: Use with transformers, lightning, torchopt, torch.distributions and more!\n  * Extensible: Add new methods! Add new models!\n  * Functional: Easier to test, closer to mathematics!\n  * Scalable: Big model? Big data? No problem!\n  * Swappable: Swap between algorithms with ease!\n\n## Installation\n\nposteriors is available on PyPI and can be installed via pip:\n\n    \n    \n    pip install posteriors\n\n## Quickstart\n\nposteriors is functional first and aims to be easy to use and extend. Let's\ntry it out by training a simple model with variational inference:\n\n    \n    \n    from torchvision.datasets import MNIST from torchvision.transforms import ToTensor from torch import nn, utils, func import torchopt import posteriors dataset = MNIST(root=\"./data\", transform=ToTensor()) train_loader = utils.data.DataLoader(dataset, batch_size=32, shuffle=True) num_data = len(dataset) classifier = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 10)) params = dict(classifier.named_parameters()) def log_posterior(params, batch): images, labels = batch images = images.view(images.size(0), -1) output = func.functional_call(classifier, params, images) log_post_val = ( -nn.functional.cross_entropy(output, labels) + posteriors.diag_normal_log_prob(params) / num_data ) return log_post_val, output transform = posteriors.vi.diag.build( log_posterior, torchopt.adam(), temperature=1 / num_data ) # Can swap out for any posteriors algorithm state = transform.init(params) for batch in train_loader: state = transform.update(state, batch)\n\nObserve that posteriors recommends specifying log_posterior and temperature\nsuch that log_posterior remains on the same scale for different batch sizes.\nposteriors algorithms are designed to be stable as temperature goes to zero.\n\nFurther, the output of log_posterior is a tuple containing the evaluation\n(single-element Tensor) and an additional argument (TensorTree) containing any\nauxiliary information we'd like to retain from the model call, here the model\npredictions. If you have no auxiliary information, you can simply return\ntorch.tensor([]) as the second element. For more info see torch.func.grad\n(with has_aux=True) or the documentation.\n\nCheck out the tutorials for more detailed usage!\n\n## Methods\n\nposteriors supports a variety of methods for uncertainty quantification,\nincluding:\n\n  * Extended Kalman filter\n  * Laplace approximation\n  * Stochastic gradient MCMC\n  * Variational inference\n\nWith full details available in the API documentation.\n\nposteriors is designed to be easily extensible, if you're favorite method is\nnot listed above, raise an issue and we'll see what we can do!\n\n## Friends\n\nInterfaces seamlessly with:\n\n  * torch and in particular torch.func.\n  * torch.distributions for distributions and sampling, (note that it's typically required to set validate_args=False to conform with the control flows in torch.func).\n  * Functional and flexible torch optimizers from torchopt.\n  * transformers for pre-trained models.\n  * lightning for convenient training and logging, see examples/lightning_autoencoder.py.\n\nThe functional transform interface is strongly inspired by frameworks such as\noptax and blackjax.\n\nAs well as other UQ libraries fortuna, laplace, numpyro, pymc and uncertainty-\nbaselines.\n\n## Contributing\n\nYou can report a bug or request a feature by creating a new issue on GitHub.\n\nIf you want to contribute code, please check the contributing guide.\n\n## About\n\nUncertainty quantification with PyTorch\n\nnormal-computing.github.io/posteriors/\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\nActivity\n\nCustom properties\n\n### Stars\n\n50 stars\n\n### Watchers\n\n4 watching\n\n### Forks\n\n2 forks\n\nReport repository\n\n## Releases 2\n\nv0.0.2 Latest\n\nApr 16, 2024\n\n\\+ 1 release\n\n## Contributors 7\n\n## Languages\n\n  * Python 100.0%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
