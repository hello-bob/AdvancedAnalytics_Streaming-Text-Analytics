{"aid": "40237489", "title": "Let's Build An AI Agent: trendrBOT answers questions about Google Search trends", "url": "https://brettdidonato.substack.com/p/lets-build-an-ai-agent-trendrbot", "domain": "brettdidonato.substack.com", "votes": 1, "user": "bsdpython", "posted_at": "2024-05-02 15:40:14", "comments": 0, "source_title": "Let's Build An AI Agent: trendrBOT answers natural language questions based on Google Search trends", "source_text": "Let's Build An AI Agent: trendrBOT answers natural language questions based on\nGoogle Search trends\n\n# Brett DiDonato\n\nShare this post\n\n#### Let's Build An AI Agent: trendrBOT answers natural language questions\nbased on Google Search trends\n\nbrettdidonato.substack.com\n\n#### Discover more from Brett DiDonato\n\nLet's talk about the present and future of AI\n\nContinue reading\n\nSign in\n\n# Let's Build An AI Agent: trendrBOT answers natural language questions based\non Google Search trends\n\n### A lesson in why AI agents are so exciting but also so difficult to scale\n\nBrett DiDonato\n\nMay 02, 2024\n\nShare this post\n\n#### Let's Build An AI Agent: trendrBOT answers natural language questions\nbased on Google Search trends\n\nbrettdidonato.substack.com\n\nShare\n\n##\n\nBackground on AI Agents\n\nAs the popularity of LLMs took off with the launch of ChatGPT, the idea of\nAgents as the next big thing already started to form. The concept is to move\nbeyond a simple prompt-response workflow that relies solely on the model\u2019s own\ninternal logic. Programmatic libraries such as LangChain and productized\nservices like OpenAI GPTs have cropped up to address these needs at varying\nlevels of customization and complexity. Even the core LLM powered services\nthemselves such as ChatGPT and Google Gemini have integrated more advanced\nagent like workflows natively for popular use cases such as generating images\nand querying the web.\n\nGaudy demos showcasing more advanced agent like capabilities have continued to\nsurface to sell the idea of completing tasks such as designing user\ninterfaces, booking vacations, writing complex code and more. But the reality\nis that most advanced agents have not fully materialized just yet, and even\nfairly basic agents have not been adopted as quickly as expected. Why is that?\n\nTo understand why agents have been slower to evolve than many predicted, let\u2019s\nbuild a fairly basic agent from scratch. We will end by reviewing what lessons\nwe can learn and extrapolate what this means for the future of building\ncomplex AI agents.\n\nIt wouldn\u2019t be an AI project without a sleek AI generated logo\n\n##\n\nTrendrBOT\n\nThe purpose of our agent is to allow users to ask questions in natural\nlanguage about trending topics online. We want to be able to ask basic\nquestions such as \u201cWhat are the top 10 trends in the US?\u201d but also more\ncomplex, nuanced questions such as \u201cAre there noticeable differences in trends\nbetween European and Asian countries?\u201d.\n\nYou can skip directly to the trendrBOT Live Demo or deploy the code directly\nfrom the TrendrBOT Github repo. Here\u2019s a view of the Web UI:\n\nFor those interested, let\u2019s do a deeper dive on how trendrBOT works.\n\n##\n\nTrendrBOT Deep Dive\n\nTo make trendrBOT work we have to figure out how to best integrate a large\namount of structured data (our trends data) with an LLM. Because we are\ndealing with structured data, a vanilla RAG (Retrieval Augmented Generation)\narchicture would be less than ideal. Another option is to leverage text2SQL,\nor in other words prompting an LLM to generate a SQL query. This can work\nunder idealized circumstances, but my experience is that it is still very\nbrittle and error prone in most use cases today. A third option is to leverage\nthe increasingly available LLMs with large context windows to pass our\nstructured data directly to the LLM. I decided to use this third option, with\nan additional step to intelligently select and query the structured data\nbecause of still remaining context window limiations.\n\nHere is a logical view of the application:\n\ntrendrBOT logical application architecture\n\nAn explanation:\n\n  * Step 1: Based on user input, use an LLM to check for a relevant data source\n\n  * Step 2: Query the matched data source. If relevant data source does not exist, tell the user and bail out.\n\n  * Step 3: Take the data output results and provide it for context to ask the LLM to answer the question\n\n  * Step 4: Return the results to the user\n\nFor the LLM we will use Gemini 1.5 Pro. This model is a good choice for this\nuse case because we are dealing with large amounts of data, so the large 1M\ntoken context window will be critical.\n\nAs for our trends data source we will use the Google Trends BigQuery dataset,\nwhich provides top 25 overall and top 25 rising terms both in the United\nStates and internationally. This is part of the 200+ free to use publicly\navailable datasets hosted by Google Cloud.\n\nFor the UI we will use Streamlit, which can be deployed locally or in the\ncloud.\n\n##\n\nThe Data Sources\n\nThe public Google Trends datasets consist of four BigQuery tables:\n\n  * international_top_rising_terms: Fast rising terms for non US markets\n\n  * international_top_terms: Top terms for non US markets\n\n  * top_rising_terms: Fast rising terms for the US market\n\n  * top_terms: Top terms for the US market\n\nI decided to stick with the US and international top terms tables to start,\nand ignored the rising terms for this initial version.\n\n##\n\nStep 1: Initial Prompt Design\n\nLet\u2019s refer back to our already defined first step:\n\n  * Step 1: Based on user input, use an LLM to check for a relevant data source\n\nHere is a first attempt to prompt for the correct data source:\n\n    \n    \n    Based on the following question, determine which data source is best suited to provide an answer. Data Sources: International Google Trends US Google Trends Question: [User Question] Answer:\n\nWhen we run this against the question \u201cWhat's trending in the US?\u201d we get this\nresponse:\n\n> ## Data Source for US Trends\n>\n> For the question \"What's trending in the US?\", the most suitable data source\n> would be:\n>\n> US Google Trends\n>\n> Reason:\n>\n>   * Specificity: US Google Trends focuses specifically on search trends\n> within the United States, providing insights into the topics and queries\n> that are currently popular among American users.\n>\n>   * Relevance: It directly addresses the geographical scope of the question,\n> offering data that is relevant to the US audience.\n>\n>   * Granularity: US Google Trends allows for analysis at the national,\n> state, and even city level, providing a more detailed understanding of\n> regional trends within the US.\n>\n>\n\n>\n> While International Google Trends offers a broader perspective on global\n> search interests, it wouldn't provide the specific insights needed to answer\n> the question about US trends.\n\nThis answer is correct, but all we want is the data source name. Let\u2019s add the\nsentence \u201cRespond with just the data source\u201d to our prompt and try again:\n\n> US Google Trends\n\nThis example looks good but I noticed that sometimes the model would respond\nwith something like the following:\n\n> Answer: US Google Trends\n\nThis is acceptable for a basic chatbot, but since we need to use these results\ndownstream in the next step of our agent architecture, we either need to have\nstrict output enforcement or create custom parsing code. There was also a few\ncases where the wrong dataset was suggested, even though it was \u201cfairly\nobvious\u201d from my point of view. Luckily, we have a technique called few shot\nprompting that can help.\n\n##\n\nFew Shot Prompting\n\nFew shot prompting is just a fancy way of saying that we will provide our LLMs\nwith examples so that it better understands our expected output format.\nChoosing proper examples that demonstrate the structure of the output but that\ndo not overfit can be difficult. In general I would recommend investing in or\nbuilding a model evaluation framework and few shot prompt building process to\nfaciliate this optimization.\n\nLet\u2019s skip those fine details for now and jump right to the 3-shot prompt that\nwas built:\n\n    \n    \n    Based on the following question, determine which data source is best suited to provide an answer. Data Sources: International Google Trends US Google Trends Question: What was trending in the US? Answer: US Google Trends Based on the following question, determine which data source is best suited to provide an answer. Data Sources: International Google Trends US Google Trends Question: What has been trending outside of the US? Answer: International Google Trends Based on the following question, determine which data source is best suited to provide an answer. Data Sources: International Google Trends US Google Trends Question: What is popular in Africa? Answer: International Google Trends Based on the following question, determine which data source is best suited to provide an answer. Data Sources: International Google Trends US Google Trends Question: [User Question] Answer:\n\nThis prompt seemed to generate results consistently. One thing that was added\nfor the final version and not shown here is a list of countries to target. So\nnow, even this relatively simple prompt is starting to get complex as\nrequirements change. You can imagine what would be needed if we had, for\nexample, 100 data sources. In that scenario, we might have to create dozens or\nhundreds of examples to guide the LLM properly, and at that point model tuning\nstarts to make sense.\n\n##\n\nStep 2: Query the Database\n\nHere is our previously defined second step:\n\n  * Step 2: Query the matched data source. If relevant data source does not exist, tell the user and bail out.\n\nThis is where we choose between two data sources as output by the LLM in the\nprevious step and execute a SQL query. I wrote a pre-defined SQL query for\neach data source that return the most recent and highest ranking results\ntruncated to 50,000 rows. One feature added later is the country designation\ni.e. if the user input specifies an individual country we then modify the\nquery to add a condition in the WHERE clause. Here is the query for the\ninternational trends dataset:\n\n    \n    \n    WITH abc AS ( SELECT term, rank, week FROM `bigquery-public-data.google_trends.international_top_terms` GROUP BY term, rank, week ORDER BY week DESC, rank ASC ) SELECT DISTINCT term, rank, week FROM abc WHERE country_name = [COUNTRY] ORDER BY week DESC, rank ASC LIMIT 50000\n\nThese results are then stored as a CSV, with a header row pre-pended.\n\nI left out more advanced querying options for this version because of the\nnuance of the way the data is represented. As one example, I would love to\nfilter results based on US states, but the US dataset actually stores data in\nDMAs (see Designated Market Areas). These DMAs do not have strict state\nboundaries, so matching regional results to user expectatios would be\ndifficult. This type of nuance is typical in datasets which is what makes\ntext2SQL very difficult to accomplish as a generalized use case.\n\n##\n\nStep 3: Prompt for an answer\n\nHere is our previously defined third step:\n\n  * Step 3: Take the data output results and provide it for context to ask the LLM to answer the question\n\nHere is our prompt:\n\n    \n    \n    Answer the following question based on the provided trending topics. When in doubt, answer with the most recent data Question: [ORIGINAL USER QUESTION] Google Search trends data: [DATA GENERATED FROM STEP 2]\n\nThere is probably room for improvement here. We could better describe what\ntype of output we are expecting or to provided few shot examples. My\nexperience is that few shot prompting for this type of output risks\noverfitting so I decided to leave it as is for this version.\n\n##\n\nStep 4: Return the results\n\nThe final results look pretty good overall for many questions that I tried\nout. Here is one basic example:\n\n>\n>     Question: What are the top 10 trends in the US for the latest available\n> data? Simply list them in bullet points.\n\n> Answer:\n>\n>   * O.J. Simpson\n>\n>   * Real Madrid vs Man City\n>\n>   * Masters 2024\n>\n>   * Total eclipse 2024\n>\n>   * UFC 300\n>\n>   * Purdue basketball\n>\n>   * Powerball\n>\n>   * PSG vs Barcelona\n>\n>   * Champions League\n>\n>   * What time is the eclipse\n>\n>\n\nAnd here is a more complex example:\n\n>\n>     Question: Are there noticeable differences in trends between European\n> and Asian countries?\n\n> Answer:\n>\n> Trend Differences between Europe and Asia:\n>\n> Based on the provided Google Search trends data from the week of April 7,\n> 2024, we can observe some noticeable differences in trending topics between\n> European and Asian countries:\n>\n> Europe:\n>\n>   * Dominance of Football: A large portion of the top trends relates to\n> European football leagues and matches, like the Champions League (\"Ligue des\n> champions\", \"Liga Mistrz\u00f3w\", etc.), and specific games like \"Man United vs\n> Liverpool\". This indicates a strong interest in football within the European\n> region.\n>\n>   * Solar Eclipse Interest: Several European countries show interest in the\n> upcoming solar eclipse on April 8th, 2024, with searches like \"Eclipsa de\n> Soare 2024 romania\" and \"Sonnenfinsternis 2024\".\n>\n>   * Regional Events: Some trends highlight regional events or personalities,\n> such as \"Wybory samorz\u0105dowe 2024\" (Polish local elections) and \"\u05d0\u05d1\u05e9\u05dc\u05d5\u05dd \u05e4\u05dc\u05d3\"\n> (an Israeli personality).\n>\n>\n\n>\n> Asia:\n>\n>   * Variety of topics: Compared to Europe, the top trends in Asia exhibit a\n> wider variety of interests. While football (\"Man utd Liverpool\", \"Arsenal\n> \u0111\u1ea5u v\u1edbi Bayern\") and the solar eclipse (\"Gerhana matahari 8 April 2024\") are\n> present, there's also a mix of entertainment, cultural events and\n> personalities.\n>\n>   * Entertainment and Culture: Searches like \"\u685c\u82b1\u8cde\" (a Japanese horse race),\n> \"KKR vs CSK\" (an Indian Premier League cricket match), and \"\ubc84\uac70\ud0b9 \uc640\ud37c \ud310\ub9e4 \uc885\ub8cc \uc774\uc720\"\n> (reasons for Burger King Whopper discontinuation in Korea) point towards\n> diverse entertainment and cultural interests.\n>\n>   * Religious Observances: The presence of \"Idul Fitri 2024\" and related\n> searches like \"Niat sholat Idul Fitri\" in several Asian countries indicates\n> the significance of this religious holiday in the region.\n>\n>\n\n>\n> Conclusion:\n>\n> While there's some overlap in trending topics, particularly with major\n> events like the solar eclipse and popular sports, European trends lean more\n> heavily towards football, while Asian trends showcase a wider range of\n> interests encompassing entertainment, culture, and religion.\n\n##\n\nLimitations\n\nDo not expect perfect results for all types questions. Some limitations\ninclude:\n\n  * The Google Trends Public Dataset is sporadically updated\n\n  * Even the full 1M token context window provided by Gemini 1.5 Pro is not large enough to contain the entirety of the Google Trends public dataset, so query results are usually truncated when submitting for analysis\n\n  * With limited data points as provided, the LLM will often speculate rightly (or wrongly) on the categorization or context of trends\n\n  * Just based on the inherent architecture, the LLM's ability to perform precise calculations is limited\n\n  * Execution can take up to 1 minute. A simple optimization would be to cache the BigQuery results, but the two Gemini 1.5 Pro requests, the second of which has a large context, will take some time regardless.\n\n##\n\nFinal thoughts: The road to more complex agents\n\nWhew! That was a lot of work. Our trendrBOT agent, while imperfect, is\ncomplete for now.\n\nI hope this breakdown of building a relatively simple agent demonstrates why\nit is so difficult to scale these applications as scope and complexity\nincreases. It comes down to the combination of these factors:\n\n  * Large models are autoregressive which means they are non deterministic and are thus hard to predict and control\n\n  * Our current tools that can help mitigate the difficulty working with large models lack maturity. I purposely avoided using agent frameworks such as Langchain, but my opinion is that, in their current state, these tools can actually hinder development in a number of ways. Those details will have to be covered in a future article.\n\n  * As each additional step and feature is added to an agent application, defining, designing and validating each LLM dependent task becomes increasingly difficult. A single point of failure or unexpected behavior can cause a chain reaction, taking down a carefully crafted logical flow.\n\n### Subscribe to Brett DiDonato\n\nLaunched a month ago\n\nLet's talk about the present and future of AI\n\n1 Like\n\nShare this post\n\n#### Let's Build An AI Agent: trendrBOT answers natural language questions\nbased on Google Search trends\n\nbrettdidonato.substack.com\n\nShare\n\nComments\n\nOpenAI Sora: Are we all seeing the same thing?\n\nOne of the most hyped AI announcements this year was when OpenAI announced\ntheir proprietary video generation model Sora last month. The hype has...\n\nMar 27 \u2022\n\nBrett DiDonato\n\nShare this post\n\n#### OpenAI Sora: Are we all seeing the same thing?\n\nbrettdidonato.substack.com\n\nTeaching AI to 2nd Graders\n\nMy most challenging audience yet\n\nApr 22 \u2022\n\nBrett DiDonato\n\nShare this post\n\n#### Teaching AI to 2nd Graders\n\nbrettdidonato.substack.com\n\nAI Skepticism is Reasonable (And Recommended)\n\nI\u2019ve been excited about AI for years. Even studying the field back in college,\nwhen there was only so much you could do with the lack of processing...\n\nApr 17 \u2022\n\nBrett DiDonato\n\nShare this post\n\n#### AI Skepticism is Reasonable (And Recommended)\n\nbrettdidonato.substack.com\n\nReady for more?\n\n\u00a9 2024 Brett\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}
